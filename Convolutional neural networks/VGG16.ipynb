{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3619,
     "status": "ok",
     "timestamp": 1729269361711,
     "user": {
      "displayName": "Hiếu Phạm Đình Trung",
      "userId": "04488184884666032393"
     },
     "user_tz": -420
    },
    "id": "JKAgOVUI-NAt",
    "outputId": "9a3fe7df-32a9-448b-eb55-37f887b5b160"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Path to dataset files: /Users/phamdinhtrunghieu/.cache/kagglehub/datasets/marquis03/cats-and-dogs/versions/2/train\n",
      "['cat', '.DS_Store', 'classname.txt', 'dog']\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import kagglehub\n",
    "\n",
    "# Download latest version\n",
    "path = kagglehub.dataset_download(\"marquis03/cats-and-dogs\") + \"/train\"\n",
    "# path = \"/Users/phamdinhtrunghieu/.cache/kagglehub/datasets/marquis03/cats-and-dogs/versions/2/train\"\n",
    "\n",
    "print(\"Path to dataset files:\", path)\n",
    "print(os.listdir(path))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "executionInfo": {
     "elapsed": 6666,
     "status": "ok",
     "timestamp": 1729269368373,
     "user": {
      "displayName": "Hiếu Phạm Đình Trung",
      "userId": "04488184884666032393"
     },
     "user_tz": -420
    },
    "id": "9OYjRCScIS4G"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as f\n",
    "from PIL import Image\n",
    "from torchvision import transforms\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "INPUTSIZE = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_image(img):\n",
    "  resize_transform = transforms.Resize((INPUTSIZE,INPUTSIZE))\n",
    "\n",
    "  resized_img = resize_transform(img)\n",
    "\n",
    "  plt.figure(figsize=(8, 4))\n",
    "\n",
    "  plt.subplot(1, 2, 1)\n",
    "  plt.imshow(img)\n",
    "  plt.title('Original Image')\n",
    "\n",
    "  plt.subplot(1, 2, 2)\n",
    "  plt.imshow(resized_img)\n",
    "  plt.title('Resized Image (224x224)')\n",
    "\n",
    "  plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 10095,
     "status": "ok",
     "timestamp": 1729269378460,
     "user": {
      "displayName": "Hiếu Phạm Đình Trung",
      "userId": "04488184884666032393"
     },
     "user_tz": -420
    },
    "id": "Y1uTwZGbInQt",
    "outputId": "a3e6b19a-509d-4eb0-a7c4-60d7873ea241"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['cat', '.DS_Store', 'classname.txt', 'dog']\n"
     ]
    }
   ],
   "source": [
    "dataset_path = f\"{path}\"\n",
    "\n",
    "print(os.listdir(dataset_path))\n",
    "\n",
    "dataset = []\n",
    "\n",
    "count_label = 0\n",
    "\n",
    "number_of_label = 2\n",
    "\n",
    "labels = [\"cat\", \"dog\"]\n",
    "\n",
    "for label in labels:\n",
    "  data_path = f\"{dataset_path}/{label}\"\n",
    "  for example in os.listdir(data_path):\n",
    "    img = Image.open(f\"{data_path}/{example}\")\n",
    "    # show_image(img)\n",
    "    transform = transforms.Compose([\n",
    "                                    transforms.Resize((INPUTSIZE,INPUTSIZE)),\n",
    "                                    transforms.ToTensor()\n",
    "                                    ])\n",
    "    x = 1.0 * transform(img)\n",
    "    if (x.size()[0] != 3):\n",
    "      continue\n",
    "    y = torch.zeros(number_of_label)\n",
    "    y[count_label] = 1\n",
    "\n",
    "    # print(x,y)\n",
    "\n",
    "    dataset.append((x,y))\n",
    "\n",
    "  count_label += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "executionInfo": {
     "elapsed": 30,
     "status": "ok",
     "timestamp": 1729269378462,
     "user": {
      "displayName": "Hiếu Phạm Đình Trung",
      "userId": "04488184884666032393"
     },
     "user_tz": -420
    },
    "id": "DVTShB3AI6jd"
   },
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "random.shuffle(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 739,
     "status": "ok",
     "timestamp": 1729269379173,
     "user": {
      "displayName": "Hiếu Phạm Đình Trung",
      "userId": "04488184884666032393"
     },
     "user_tz": -420
    },
    "id": "lEkjtZEqJnx9",
    "outputId": "de04de73-e0df-4bec-e3a9-03a61bb5727d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 64, 64])\n",
      "torch.Size([2])\n",
      "torch.Size([3, 64, 64])\n",
      "torch.Size([2])\n",
      "torch.Size([3, 64, 64])\n",
      "torch.Size([2])\n",
      "torch.Size([3, 64, 64])\n",
      "torch.Size([2])\n",
      "torch.Size([3, 64, 64])\n",
      "torch.Size([2])\n",
      "torch.Size([3, 64, 64])\n",
      "torch.Size([2])\n",
      "torch.Size([3, 64, 64])\n",
      "torch.Size([2])\n",
      "torch.Size([3, 64, 64])\n",
      "torch.Size([2])\n",
      "torch.Size([3, 64, 64])\n",
      "torch.Size([2])\n",
      "torch.Size([3, 64, 64])\n",
      "torch.Size([2])\n",
      "torch.Size([3, 64, 64])\n",
      "torch.Size([2])\n",
      "torch.Size([3, 64, 64])\n",
      "torch.Size([2])\n",
      "torch.Size([3, 64, 64])\n",
      "torch.Size([2])\n",
      "torch.Size([3, 64, 64])\n",
      "torch.Size([2])\n",
      "torch.Size([3, 64, 64])\n",
      "torch.Size([2])\n",
      "torch.Size([3, 64, 64])\n",
      "torch.Size([2])\n",
      "torch.Size([3, 64, 64])\n",
      "torch.Size([2])\n",
      "torch.Size([3, 64, 64])\n",
      "torch.Size([2])\n",
      "torch.Size([3, 64, 64])\n",
      "torch.Size([2])\n",
      "torch.Size([3, 64, 64])\n",
      "torch.Size([2])\n",
      "torch.Size([3, 64, 64])\n",
      "torch.Size([2])\n",
      "torch.Size([3, 64, 64])\n",
      "torch.Size([2])\n",
      "torch.Size([3, 64, 64])\n",
      "torch.Size([2])\n",
      "torch.Size([3, 64, 64])\n",
      "torch.Size([2])\n",
      "torch.Size([3, 64, 64])\n",
      "torch.Size([2])\n",
      "torch.Size([3, 64, 64])\n",
      "torch.Size([2])\n",
      "torch.Size([3, 64, 64])\n",
      "torch.Size([2])\n",
      "torch.Size([3, 64, 64])\n",
      "torch.Size([2])\n",
      "torch.Size([3, 64, 64])\n",
      "torch.Size([2])\n",
      "torch.Size([3, 64, 64])\n",
      "torch.Size([2])\n",
      "torch.Size([3, 64, 64])\n",
      "torch.Size([2])\n",
      "torch.Size([3, 64, 64])\n",
      "torch.Size([2])\n",
      "torch.Size([3, 64, 64])\n",
      "torch.Size([2])\n",
      "torch.Size([3, 64, 64])\n",
      "torch.Size([2])\n",
      "torch.Size([3, 64, 64])\n",
      "torch.Size([2])\n",
      "torch.Size([3, 64, 64])\n",
      "torch.Size([2])\n",
      "torch.Size([3, 64, 64])\n",
      "torch.Size([2])\n",
      "torch.Size([3, 64, 64])\n",
      "torch.Size([2])\n",
      "torch.Size([3, 64, 64])\n",
      "torch.Size([2])\n",
      "torch.Size([3, 64, 64])\n",
      "torch.Size([2])\n",
      "torch.Size([3, 64, 64])\n",
      "torch.Size([2])\n",
      "torch.Size([3, 64, 64])\n",
      "torch.Size([2])\n",
      "torch.Size([3, 64, 64])\n",
      "torch.Size([2])\n",
      "torch.Size([3, 64, 64])\n",
      "torch.Size([2])\n",
      "torch.Size([3, 64, 64])\n",
      "torch.Size([2])\n",
      "torch.Size([3, 64, 64])\n",
      "torch.Size([2])\n",
      "torch.Size([3, 64, 64])\n",
      "torch.Size([2])\n",
      "torch.Size([3, 64, 64])\n",
      "torch.Size([2])\n",
      "torch.Size([3, 64, 64])\n",
      "torch.Size([2])\n",
      "torch.Size([3, 64, 64])\n",
      "torch.Size([2])\n",
      "torch.Size([3, 64, 64])\n",
      "torch.Size([2])\n",
      "torch.Size([3, 64, 64])\n",
      "torch.Size([2])\n",
      "torch.Size([3, 64, 64])\n",
      "torch.Size([2])\n",
      "torch.Size([3, 64, 64])\n",
      "torch.Size([2])\n",
      "torch.Size([3, 64, 64])\n",
      "torch.Size([2])\n",
      "torch.Size([3, 64, 64])\n",
      "torch.Size([2])\n",
      "torch.Size([3, 64, 64])\n",
      "torch.Size([2])\n",
      "torch.Size([3, 64, 64])\n",
      "torch.Size([2])\n",
      "torch.Size([3, 64, 64])\n",
      "torch.Size([2])\n",
      "torch.Size([3, 64, 64])\n",
      "torch.Size([2])\n",
      "torch.Size([3, 64, 64])\n",
      "torch.Size([2])\n",
      "torch.Size([3, 64, 64])\n",
      "torch.Size([2])\n",
      "torch.Size([3, 64, 64])\n",
      "torch.Size([2])\n",
      "torch.Size([3, 64, 64])\n",
      "torch.Size([2])\n",
      "torch.Size([3, 64, 64])\n",
      "torch.Size([2])\n",
      "torch.Size([3, 64, 64])\n",
      "torch.Size([2])\n",
      "torch.Size([3, 64, 64])\n",
      "torch.Size([2])\n",
      "torch.Size([3, 64, 64])\n",
      "torch.Size([2])\n",
      "torch.Size([3, 64, 64])\n",
      "torch.Size([2])\n",
      "torch.Size([3, 64, 64])\n",
      "torch.Size([2])\n",
      "torch.Size([3, 64, 64])\n",
      "torch.Size([2])\n",
      "torch.Size([3, 64, 64])\n",
      "torch.Size([2])\n",
      "torch.Size([3, 64, 64])\n",
      "torch.Size([2])\n",
      "torch.Size([3, 64, 64])\n",
      "torch.Size([2])\n",
      "torch.Size([3, 64, 64])\n",
      "torch.Size([2])\n",
      "torch.Size([3, 64, 64])\n",
      "torch.Size([2])\n",
      "torch.Size([3, 64, 64])\n",
      "torch.Size([2])\n",
      "torch.Size([3, 64, 64])\n",
      "torch.Size([2])\n",
      "torch.Size([3, 64, 64])\n",
      "torch.Size([2])\n",
      "torch.Size([3, 64, 64])\n",
      "torch.Size([2])\n",
      "torch.Size([3, 64, 64])\n",
      "torch.Size([2])\n",
      "torch.Size([3, 64, 64])\n",
      "torch.Size([2])\n",
      "torch.Size([3, 64, 64])\n",
      "torch.Size([2])\n",
      "torch.Size([3, 64, 64])\n",
      "torch.Size([2])\n",
      "torch.Size([3, 64, 64])\n",
      "torch.Size([2])\n",
      "torch.Size([3, 64, 64])\n",
      "torch.Size([2])\n",
      "torch.Size([3, 64, 64])\n",
      "torch.Size([2])\n",
      "torch.Size([3, 64, 64])\n",
      "torch.Size([2])\n",
      "torch.Size([3, 64, 64])\n",
      "torch.Size([2])\n",
      "torch.Size([3, 64, 64])\n",
      "torch.Size([2])\n",
      "torch.Size([3, 64, 64])\n",
      "torch.Size([2])\n",
      "torch.Size([3, 64, 64])\n",
      "torch.Size([2])\n",
      "torch.Size([3, 64, 64])\n",
      "torch.Size([2])\n",
      "torch.Size([3, 64, 64])\n",
      "torch.Size([2])\n",
      "torch.Size([3, 64, 64])\n",
      "torch.Size([2])\n",
      "torch.Size([3, 64, 64])\n",
      "torch.Size([2])\n",
      "torch.Size([3, 64, 64])\n",
      "torch.Size([2])\n",
      "torch.Size([3, 64, 64])\n",
      "torch.Size([2])\n",
      "torch.Size([3, 64, 64])\n",
      "torch.Size([2])\n",
      "torch.Size([3, 64, 64])\n",
      "torch.Size([2])\n",
      "torch.Size([3, 64, 64])\n",
      "torch.Size([2])\n",
      "torch.Size([3, 64, 64])\n",
      "torch.Size([2])\n",
      "torch.Size([3, 64, 64])\n",
      "torch.Size([2])\n",
      "torch.Size([3, 64, 64])\n",
      "torch.Size([2])\n",
      "torch.Size([3, 64, 64])\n",
      "torch.Size([2])\n",
      "torch.Size([3, 64, 64])\n",
      "torch.Size([2])\n",
      "torch.Size([3, 64, 64])\n",
      "torch.Size([2])\n",
      "torch.Size([3, 64, 64])\n",
      "torch.Size([2])\n",
      "torch.Size([3, 64, 64])\n",
      "torch.Size([2])\n",
      "torch.Size([3, 64, 64])\n",
      "torch.Size([2])\n",
      "torch.Size([3, 64, 64])\n",
      "torch.Size([2])\n",
      "torch.Size([3, 64, 64])\n",
      "torch.Size([2])\n",
      "torch.Size([3, 64, 64])\n",
      "torch.Size([2])\n",
      "torch.Size([3, 64, 64])\n",
      "torch.Size([2])\n",
      "torch.Size([3, 64, 64])\n",
      "torch.Size([2])\n",
      "torch.Size([3, 64, 64])\n",
      "torch.Size([2])\n",
      "torch.Size([3, 64, 64])\n",
      "torch.Size([2])\n",
      "torch.Size([3, 64, 64])\n",
      "torch.Size([2])\n",
      "torch.Size([3, 64, 64])\n",
      "torch.Size([2])\n",
      "torch.Size([3, 64, 64])\n",
      "torch.Size([2])\n",
      "torch.Size([3, 64, 64])\n",
      "torch.Size([2])\n",
      "torch.Size([3, 64, 64])\n",
      "torch.Size([2])\n",
      "torch.Size([3, 64, 64])\n",
      "torch.Size([2])\n",
      "torch.Size([3, 64, 64])\n",
      "torch.Size([2])\n",
      "torch.Size([3, 64, 64])\n",
      "torch.Size([2])\n",
      "torch.Size([3, 64, 64])\n",
      "torch.Size([2])\n",
      "torch.Size([3, 64, 64])\n",
      "torch.Size([2])\n",
      "torch.Size([3, 64, 64])\n",
      "torch.Size([2])\n",
      "torch.Size([3, 64, 64])\n",
      "torch.Size([2])\n",
      "torch.Size([3, 64, 64])\n",
      "torch.Size([2])\n",
      "torch.Size([3, 64, 64])\n",
      "torch.Size([2])\n",
      "torch.Size([3, 64, 64])\n",
      "torch.Size([2])\n",
      "torch.Size([3, 64, 64])\n",
      "torch.Size([2])\n",
      "torch.Size([3, 64, 64])\n",
      "torch.Size([2])\n",
      "torch.Size([3, 64, 64])\n",
      "torch.Size([2])\n",
      "torch.Size([3, 64, 64])\n",
      "torch.Size([2])\n",
      "torch.Size([3, 64, 64])\n",
      "torch.Size([2])\n",
      "torch.Size([3, 64, 64])\n",
      "torch.Size([2])\n",
      "torch.Size([3, 64, 64])\n",
      "torch.Size([2])\n",
      "torch.Size([3, 64, 64])\n",
      "torch.Size([2])\n",
      "torch.Size([3, 64, 64])\n",
      "torch.Size([2])\n",
      "torch.Size([3, 64, 64])\n",
      "torch.Size([2])\n",
      "torch.Size([3, 64, 64])\n",
      "torch.Size([2])\n",
      "torch.Size([3, 64, 64])\n",
      "torch.Size([2])\n",
      "torch.Size([3, 64, 64])\n",
      "torch.Size([2])\n",
      "torch.Size([3, 64, 64])\n",
      "torch.Size([2])\n",
      "torch.Size([3, 64, 64])\n",
      "torch.Size([2])\n",
      "torch.Size([3, 64, 64])\n",
      "torch.Size([2])\n",
      "torch.Size([3, 64, 64])\n",
      "torch.Size([2])\n",
      "torch.Size([3, 64, 64])\n",
      "torch.Size([2])\n",
      "torch.Size([3, 64, 64])\n",
      "torch.Size([2])\n",
      "torch.Size([3, 64, 64])\n",
      "torch.Size([2])\n",
      "torch.Size([3, 64, 64])\n",
      "torch.Size([2])\n",
      "torch.Size([3, 64, 64])\n",
      "torch.Size([2])\n",
      "torch.Size([3, 64, 64])\n",
      "torch.Size([2])\n",
      "torch.Size([3, 64, 64])\n",
      "torch.Size([2])\n",
      "torch.Size([3, 64, 64])\n",
      "torch.Size([2])\n",
      "torch.Size([3, 64, 64])\n",
      "torch.Size([2])\n",
      "torch.Size([3, 64, 64])\n",
      "torch.Size([2])\n",
      "torch.Size([3, 64, 64])\n",
      "torch.Size([2])\n",
      "torch.Size([3, 64, 64])\n",
      "torch.Size([2])\n",
      "torch.Size([3, 64, 64])\n",
      "torch.Size([2])\n",
      "torch.Size([3, 64, 64])\n",
      "torch.Size([2])\n",
      "torch.Size([3, 64, 64])\n",
      "torch.Size([2])\n",
      "torch.Size([3, 64, 64])\n",
      "torch.Size([2])\n",
      "torch.Size([3, 64, 64])\n",
      "torch.Size([2])\n",
      "torch.Size([3, 64, 64])\n",
      "torch.Size([2])\n",
      "torch.Size([3, 64, 64])\n",
      "torch.Size([2])\n",
      "torch.Size([3, 64, 64])\n",
      "torch.Size([2])\n",
      "torch.Size([3, 64, 64])\n",
      "torch.Size([2])\n",
      "torch.Size([3, 64, 64])\n",
      "torch.Size([2])\n",
      "torch.Size([3, 64, 64])\n",
      "torch.Size([2])\n",
      "torch.Size([3, 64, 64])\n",
      "torch.Size([2])\n",
      "torch.Size([3, 64, 64])\n",
      "torch.Size([2])\n",
      "torch.Size([3, 64, 64])\n",
      "torch.Size([2])\n",
      "torch.Size([3, 64, 64])\n",
      "torch.Size([2])\n",
      "torch.Size([3, 64, 64])\n",
      "torch.Size([2])\n",
      "torch.Size([3, 64, 64])\n",
      "torch.Size([2])\n",
      "torch.Size([3, 64, 64])\n",
      "torch.Size([2])\n",
      "torch.Size([3, 64, 64])\n",
      "torch.Size([2])\n",
      "torch.Size([3, 64, 64])\n",
      "torch.Size([2])\n",
      "torch.Size([3, 64, 64])\n",
      "torch.Size([2])\n",
      "torch.Size([3, 64, 64])\n",
      "torch.Size([2])\n",
      "torch.Size([3, 64, 64])\n",
      "torch.Size([2])\n",
      "torch.Size([3, 64, 64])\n",
      "torch.Size([2])\n",
      "torch.Size([3, 64, 64])\n",
      "torch.Size([2])\n",
      "torch.Size([3, 64, 64])\n",
      "torch.Size([2])\n",
      "torch.Size([3, 64, 64])\n",
      "torch.Size([2])\n",
      "torch.Size([3, 64, 64])\n",
      "torch.Size([2])\n",
      "torch.Size([3, 64, 64])\n",
      "torch.Size([2])\n",
      "torch.Size([3, 64, 64])\n",
      "torch.Size([2])\n",
      "torch.Size([3, 64, 64])\n",
      "torch.Size([2])\n",
      "torch.Size([3, 64, 64])\n",
      "torch.Size([2])\n",
      "torch.Size([3, 64, 64])\n",
      "torch.Size([2])\n",
      "torch.Size([3, 64, 64])\n",
      "torch.Size([2])\n",
      "torch.Size([3, 64, 64])\n",
      "torch.Size([2])\n",
      "torch.Size([3, 64, 64])\n",
      "torch.Size([2])\n",
      "torch.Size([3, 64, 64])\n",
      "torch.Size([2])\n",
      "torch.Size([3, 64, 64])\n",
      "torch.Size([2])\n",
      "torch.Size([3, 64, 64])\n",
      "torch.Size([2])\n",
      "torch.Size([3, 64, 64])\n",
      "torch.Size([2])\n",
      "torch.Size([3, 64, 64])\n",
      "torch.Size([2])\n",
      "torch.Size([3, 64, 64])\n",
      "torch.Size([2])\n",
      "torch.Size([3, 64, 64])\n",
      "torch.Size([2])\n",
      "torch.Size([3, 64, 64])\n",
      "torch.Size([2])\n",
      "torch.Size([3, 64, 64])\n",
      "torch.Size([2])\n",
      "torch.Size([3, 64, 64])\n",
      "torch.Size([2])\n",
      "torch.Size([3, 64, 64])\n",
      "torch.Size([2])\n",
      "torch.Size([3, 64, 64])\n",
      "torch.Size([2])\n",
      "torch.Size([3, 64, 64])\n",
      "torch.Size([2])\n",
      "torch.Size([3, 64, 64])\n",
      "torch.Size([2])\n",
      "torch.Size([3, 64, 64])\n",
      "torch.Size([2])\n",
      "torch.Size([3, 64, 64])\n",
      "torch.Size([2])\n",
      "torch.Size([3, 64, 64])\n",
      "torch.Size([2])\n",
      "torch.Size([3, 64, 64])\n",
      "torch.Size([2])\n",
      "torch.Size([3, 64, 64])\n",
      "torch.Size([2])\n",
      "torch.Size([3, 64, 64])\n",
      "torch.Size([2])\n",
      "torch.Size([3, 64, 64])\n",
      "torch.Size([2])\n",
      "torch.Size([3, 64, 64])\n",
      "torch.Size([2])\n",
      "torch.Size([3, 64, 64])\n",
      "torch.Size([2])\n",
      "torch.Size([3, 64, 64])\n",
      "torch.Size([2])\n",
      "torch.Size([3, 64, 64])\n",
      "torch.Size([2])\n",
      "torch.Size([3, 64, 64])\n",
      "torch.Size([2])\n",
      "torch.Size([3, 64, 64])\n",
      "torch.Size([2])\n",
      "torch.Size([3, 64, 64])\n",
      "torch.Size([2])\n",
      "torch.Size([3, 64, 64])\n",
      "torch.Size([2])\n",
      "torch.Size([3, 64, 64])\n",
      "torch.Size([2])\n",
      "torch.Size([3, 64, 64])\n",
      "torch.Size([2])\n",
      "torch.Size([3, 64, 64])\n",
      "torch.Size([2])\n",
      "torch.Size([3, 64, 64])\n",
      "torch.Size([2])\n",
      "torch.Size([3, 64, 64])\n",
      "torch.Size([2])\n",
      "torch.Size([3, 64, 64])\n",
      "torch.Size([2])\n",
      "torch.Size([3, 64, 64])\n",
      "torch.Size([2])\n",
      "torch.Size([3, 64, 64])\n",
      "torch.Size([2])\n",
      "torch.Size([3, 64, 64])\n",
      "torch.Size([2])\n",
      "torch.Size([3, 64, 64])\n",
      "torch.Size([2])\n",
      "torch.Size([3, 64, 64])\n",
      "torch.Size([2])\n",
      "torch.Size([3, 64, 64])\n",
      "torch.Size([2])\n",
      "torch.Size([3, 64, 64])\n",
      "torch.Size([2])\n",
      "torch.Size([3, 64, 64])\n",
      "torch.Size([2])\n",
      "torch.Size([3, 64, 64])\n",
      "torch.Size([2])\n",
      "torch.Size([3, 64, 64])\n",
      "torch.Size([2])\n",
      "torch.Size([3, 64, 64])\n",
      "torch.Size([2])\n",
      "torch.Size([3, 64, 64])\n",
      "torch.Size([2])\n",
      "torch.Size([3, 64, 64])\n",
      "torch.Size([2])\n",
      "torch.Size([3, 64, 64])\n",
      "torch.Size([2])\n",
      "torch.Size([3, 64, 64])\n",
      "torch.Size([2])\n",
      "torch.Size([3, 64, 64])\n",
      "torch.Size([2])\n",
      "torch.Size([3, 64, 64])\n",
      "torch.Size([2])\n",
      "torch.Size([3, 64, 64])\n",
      "torch.Size([2])\n",
      "torch.Size([3, 64, 64])\n",
      "torch.Size([2])\n",
      "torch.Size([3, 64, 64])\n",
      "torch.Size([2])\n",
      "torch.Size([3, 64, 64])\n",
      "torch.Size([2])\n",
      "torch.Size([3, 64, 64])\n",
      "torch.Size([2])\n",
      "torch.Size([3, 64, 64])\n",
      "torch.Size([2])\n",
      "torch.Size([3, 64, 64])\n",
      "torch.Size([2])\n",
      "torch.Size([3, 64, 64])\n",
      "torch.Size([2])\n",
      "torch.Size([3, 64, 64])\n",
      "torch.Size([2])\n",
      "torch.Size([3, 64, 64])\n",
      "torch.Size([2])\n",
      "torch.Size([3, 64, 64])\n",
      "torch.Size([2])\n",
      "torch.Size([3, 64, 64])\n",
      "torch.Size([2])\n",
      "torch.Size([3, 64, 64])\n",
      "torch.Size([2])\n",
      "torch.Size([3, 64, 64])\n",
      "torch.Size([2])\n",
      "torch.Size([3, 64, 64])\n",
      "torch.Size([2])\n",
      "torch.Size([3, 64, 64])\n",
      "torch.Size([2])\n",
      "torch.Size([3, 64, 64])\n",
      "torch.Size([2])\n",
      "torch.Size([3, 64, 64])\n",
      "torch.Size([2])\n",
      "torch.Size([3, 64, 64])\n",
      "torch.Size([2])\n",
      "torch.Size([3, 64, 64])\n",
      "torch.Size([2])\n",
      "torch.Size([3, 64, 64])\n",
      "torch.Size([2])\n",
      "torch.Size([3, 64, 64])\n",
      "torch.Size([2])\n",
      "torch.Size([3, 64, 64])\n",
      "torch.Size([2])\n",
      "torch.Size([3, 64, 64])\n",
      "torch.Size([2])\n",
      "torch.Size([3, 64, 64])\n",
      "torch.Size([2])\n",
      "torch.Size([3, 64, 64])\n",
      "torch.Size([2])\n",
      "torch.Size([3, 64, 64])\n",
      "torch.Size([2])\n",
      "torch.Size([3, 64, 64])\n",
      "torch.Size([2])\n",
      "torch.Size([3, 64, 64])\n",
      "torch.Size([2])\n",
      "torch.Size([3, 64, 64])\n",
      "torch.Size([2])\n",
      "torch.Size([3, 64, 64])\n",
      "torch.Size([2])\n",
      "torch.Size([3, 64, 64])\n",
      "torch.Size([2])\n",
      "torch.Size([3, 64, 64])\n",
      "torch.Size([2])\n",
      "torch.Size([3, 64, 64])\n",
      "torch.Size([2])\n",
      "torch.Size([3, 64, 64])\n",
      "torch.Size([2])\n",
      "torch.Size([3, 64, 64])\n",
      "torch.Size([2])\n",
      "torch.Size([3, 64, 64])\n",
      "torch.Size([2])\n",
      "torch.Size([3, 64, 64])\n",
      "torch.Size([2])\n",
      "torch.Size([3, 64, 64])\n",
      "torch.Size([2])\n",
      "torch.Size([3, 64, 64])\n",
      "torch.Size([2])\n",
      "torch.Size([3, 64, 64])\n",
      "torch.Size([2])\n",
      "torch.Size([3, 64, 64])\n",
      "torch.Size([2])\n",
      "torch.Size([3, 64, 64])\n",
      "torch.Size([2])\n",
      "torch.Size([3, 64, 64])\n",
      "torch.Size([2])\n",
      "torch.Size([3, 64, 64])\n",
      "torch.Size([2])\n",
      "torch.Size([3, 64, 64])\n",
      "torch.Size([2])\n",
      "torch.Size([3, 64, 64])\n",
      "torch.Size([2])\n",
      "torch.Size([3, 64, 64])\n",
      "torch.Size([2])\n",
      "torch.Size([3, 64, 64])\n",
      "torch.Size([2])\n",
      "torch.Size([3, 64, 64])\n",
      "torch.Size([2])\n",
      "torch.Size([3, 64, 64])\n",
      "torch.Size([2])\n",
      "torch.Size([3, 64, 64])\n",
      "torch.Size([2])\n",
      "torch.Size([3, 64, 64])\n",
      "torch.Size([2])\n",
      "torch.Size([3, 64, 64])\n",
      "torch.Size([2])\n",
      "torch.Size([3, 64, 64])\n",
      "torch.Size([2])\n",
      "torch.Size([3, 64, 64])\n",
      "torch.Size([2])\n",
      "torch.Size([3, 64, 64])\n",
      "torch.Size([2])\n",
      "torch.Size([3, 64, 64])\n",
      "torch.Size([2])\n",
      "torch.Size([3, 64, 64])\n",
      "torch.Size([2])\n",
      "torch.Size([3, 64, 64])\n",
      "torch.Size([2])\n",
      "torch.Size([3, 64, 64])\n",
      "torch.Size([2])\n",
      "torch.Size([3, 64, 64])\n",
      "torch.Size([2])\n",
      "torch.Size([3, 64, 64])\n",
      "torch.Size([2])\n",
      "torch.Size([3, 64, 64])\n",
      "torch.Size([2])\n",
      "torch.Size([3, 64, 64])\n",
      "torch.Size([2])\n",
      "torch.Size([3, 64, 64])\n",
      "torch.Size([2])\n",
      "torch.Size([3, 64, 64])\n",
      "torch.Size([2])\n",
      "torch.Size([3, 64, 64])\n",
      "torch.Size([2])\n",
      "torch.Size([3, 64, 64])\n",
      "torch.Size([2])\n",
      "torch.Size([3, 64, 64])\n",
      "torch.Size([2])\n",
      "torch.Size([3, 64, 64])\n",
      "torch.Size([2])\n",
      "torch.Size([3, 64, 64])\n",
      "torch.Size([2])\n",
      "torch.Size([3, 64, 64])\n",
      "torch.Size([2])\n",
      "torch.Size([3, 64, 64])\n",
      "torch.Size([2])\n",
      "torch.Size([3, 64, 64])\n",
      "torch.Size([2])\n",
      "torch.Size([3, 64, 64])\n",
      "torch.Size([2])\n",
      "torch.Size([3, 64, 64])\n",
      "torch.Size([2])\n",
      "torch.Size([3, 64, 64])\n",
      "torch.Size([2])\n",
      "torch.Size([3, 64, 64])\n",
      "torch.Size([2])\n",
      "torch.Size([3, 64, 64])\n",
      "torch.Size([2])\n",
      "torch.Size([3, 64, 64])\n",
      "torch.Size([2])\n",
      "torch.Size([3, 64, 64])\n",
      "torch.Size([2])\n",
      "torch.Size([3, 64, 64])\n",
      "torch.Size([2])\n",
      "torch.Size([3, 64, 64])\n",
      "torch.Size([2])\n",
      "torch.Size([3, 64, 64])\n",
      "torch.Size([2])\n",
      "torch.Size([3, 64, 64])\n",
      "torch.Size([2])\n",
      "torch.Size([3, 64, 64])\n",
      "torch.Size([2])\n",
      "torch.Size([3, 64, 64])\n",
      "torch.Size([2])\n",
      "torch.Size([3, 64, 64])\n",
      "torch.Size([2])\n",
      "torch.Size([3, 64, 64])\n",
      "torch.Size([2])\n",
      "torch.Size([3, 64, 64])\n",
      "torch.Size([2])\n",
      "torch.Size([3, 64, 64])\n",
      "torch.Size([2])\n",
      "torch.Size([3, 64, 64])\n",
      "torch.Size([2])\n",
      "torch.Size([3, 64, 64])\n",
      "torch.Size([2])\n",
      "torch.Size([3, 64, 64])\n",
      "torch.Size([2])\n",
      "torch.Size([3, 64, 64])\n",
      "torch.Size([2])\n",
      "torch.Size([3, 64, 64])\n",
      "torch.Size([2])\n",
      "torch.Size([3, 64, 64])\n",
      "torch.Size([2])\n",
      "torch.Size([3, 64, 64])\n",
      "torch.Size([2])\n",
      "torch.Size([3, 64, 64])\n",
      "torch.Size([2])\n",
      "torch.Size([3, 64, 64])\n",
      "torch.Size([2])\n",
      "torch.Size([3, 64, 64])\n",
      "torch.Size([2])\n",
      "torch.Size([3, 64, 64])\n",
      "torch.Size([2])\n",
      "torch.Size([3, 64, 64])\n",
      "torch.Size([2])\n",
      "torch.Size([3, 64, 64])\n",
      "torch.Size([2])\n",
      "torch.Size([3, 64, 64])\n",
      "torch.Size([2])\n",
      "torch.Size([3, 64, 64])\n",
      "torch.Size([2])\n",
      "torch.Size([3, 64, 64])\n",
      "torch.Size([2])\n",
      "torch.Size([3, 64, 64])\n",
      "torch.Size([2])\n",
      "torch.Size([3, 64, 64])\n",
      "torch.Size([2])\n",
      "torch.Size([3, 64, 64])\n",
      "torch.Size([2])\n",
      "torch.Size([3, 64, 64])\n",
      "torch.Size([2])\n",
      "torch.Size([3, 64, 64])\n",
      "torch.Size([2])\n",
      "torch.Size([3, 64, 64])\n",
      "torch.Size([2])\n",
      "torch.Size([3, 64, 64])\n",
      "torch.Size([2])\n",
      "torch.Size([3, 64, 64])\n",
      "torch.Size([2])\n",
      "torch.Size([3, 64, 64])\n",
      "torch.Size([2])\n",
      "torch.Size([3, 64, 64])\n",
      "torch.Size([2])\n",
      "torch.Size([3, 64, 64])\n",
      "torch.Size([2])\n",
      "torch.Size([3, 64, 64])\n",
      "torch.Size([2])\n",
      "torch.Size([3, 64, 64])\n",
      "torch.Size([2])\n"
     ]
    }
   ],
   "source": [
    "max_w, max_h = 0, 0\n",
    "for x, y in dataset:\n",
    "  print(x.size())\n",
    "  print(y.size())\n",
    "  max_w = max(max_w, x.size()[1])\n",
    "  max_h = max(max_h, x.size()[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 19,
     "status": "ok",
     "timestamp": 1729269379173,
     "user": {
      "displayName": "Hiếu Phạm Đình Trung",
      "userId": "04488184884666032393"
     },
     "user_tz": -420
    },
    "id": "rI_DMvbqJrLV",
    "outputId": "c6446750-fad6-46ef-d432-ef858248ac12"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64 64\n"
     ]
    }
   ],
   "source": [
    "print(max_h, max_w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1729269379173,
     "user": {
      "displayName": "Hiếu Phạm Đình Trung",
      "userId": "04488184884666032393"
     },
     "user_tz": -420
    },
    "id": "aKob6pd1KhjZ"
   },
   "outputs": [],
   "source": [
    "class ClassifierVGG16(nn.Module):\n",
    "  def __init__(self):\n",
    "    super().__init__()\n",
    "    tensor_size = INPUTSIZE\n",
    "    self.conv11 = nn.Conv2d(3, 64, 3, 1, 1) # 224 / 64\n",
    "    self.conv12 = nn.Conv2d(64, 64, 3, 1, 1)\n",
    "    self.maxpool1 = nn.MaxPool2d(2,2) # 112 / 32\n",
    "    tensor_size /= 2\n",
    "    \n",
    "    self.conv21 = nn.Conv2d(64, 128, 3, 1, 1) # 112 / 32\n",
    "    self.conv22 = nn.Conv2d(128, 128, 3, 1, 1)\n",
    "    self.maxpool2 = nn.MaxPool2d(2,2) # 56 / 16\n",
    "    tensor_size //= 2\n",
    "    \n",
    "    self.conv31 = nn.Conv2d(128, 256, 3, 1, 1) # 56 / 16\n",
    "    self.conv32 = nn.Conv2d(256, 256, 3, 1, 1)\n",
    "    self.conv33 = nn.Conv2d(256, 256, 3, 1, 1)\n",
    "    self.maxpool3 = nn.MaxPool2d(2,2) # 28 / 8\n",
    "    tensor_size //= 2\n",
    "    \n",
    "    self.conv41 = nn.Conv2d(256, 512, 3, 1, 1) # 28 / 8\n",
    "    self.conv42 = nn.Conv2d(512, 512, 3, 1, 1)\n",
    "    self.conv43 = nn.Conv2d(512, 512, 3, 1, 1)\n",
    "    self.maxpool4 = nn.MaxPool2d(2,2) # 14 / 4\n",
    "    tensor_size //= 2\n",
    "    \n",
    "    self.conv51 = nn.Conv2d(512, 512, 3, 1, 1) # 14\n",
    "    self.conv52 = nn.Conv2d(512, 512, 3, 1, 1)\n",
    "    self.conv53 = nn.Conv2d(512, 512, 3, 1, 1)\n",
    "    self.maxpool5 = nn.MaxPool2d(2,2) # 7 / 2\n",
    "    tensor_size //= 2\n",
    "    tensor_size = int(tensor_size)\n",
    "    \n",
    "    self.fc1 = nn.Linear(tensor_size * tensor_size * 512, 4096)\n",
    "    self.fc2 = nn.Linear(4096, 4096)\n",
    "    self.fc2 = nn.Linear(4096, 2)\n",
    "    \n",
    "\n",
    "  def forward(self,x):\n",
    "    x = f.relu(self.conv11(x))\n",
    "    x = f.relu(self.conv12(x))\n",
    "    x = self.maxpool1(x)\n",
    "    # print(x.size())\n",
    "    \n",
    "    x = f.relu(self.conv21(x))\n",
    "    x = f.relu(self.conv22(x))\n",
    "    x = self.maxpool2(x)\n",
    "    # print(x.size())\n",
    "    \n",
    "    x = f.relu(self.conv31(x))\n",
    "    x = f.relu(self.conv32(x))\n",
    "    x = f.relu(self.conv33(x))\n",
    "    x = self.maxpool3(x)\n",
    "    # print(x.size())\n",
    "    \n",
    "    x = f.relu(self.conv41(x))\n",
    "    x = f.relu(self.conv42(x))\n",
    "    x = f.relu(self.conv43(x))\n",
    "    x = self.maxpool4(x)\n",
    "    # print(x.size())\n",
    "    \n",
    "    x = f.relu(self.conv51(x))\n",
    "    x = f.relu(self.conv52(x))\n",
    "    x = f.relu(self.conv53(x))\n",
    "    x = self.maxpool5(x)\n",
    "    # print(x.size())\n",
    "\n",
    "    x = torch.flatten(x)\n",
    "    \n",
    "    x = f.relu(self.fc1(x))\n",
    "    x = f.relu(self.fc2(x))\n",
    "\n",
    "    return f.softmax(x, dim = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1729269379173,
     "user": {
      "displayName": "Hiếu Phạm Đình Trung",
      "userId": "04488184884666032393"
     },
     "user_tz": -420
    },
    "id": "StYAEZFgcOiR"
   },
   "outputs": [],
   "source": [
    "def get_label(y):\n",
    "  res = 0\n",
    "\n",
    "  for id in range(number_of_label):\n",
    "    if y[res].item() < y[id].item():\n",
    "      res = id\n",
    "\n",
    "\n",
    "\n",
    "  return labels[res]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "executionInfo": {
     "elapsed": 144303,
     "status": "error",
     "timestamp": 1729269523814,
     "user": {
      "displayName": "Hiếu Phạm Đình Trung",
      "userId": "04488184884666032393"
     },
     "user_tz": -420
    },
    "id": "wcGpl0P6SoTQ",
    "outputId": "0938091b-ae60-4af5-8e6a-5db62d0d3d78"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dog\n",
      "=====epoch:0=====\n",
      "Epoch 0 - 0: cat - dog || Loss: 0.8138421177864075\n",
      "tensor([1., 0.]) tensor([0.4994, 0.5006], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 0 - 1: cat - dog || Loss: 0.813646137714386\n",
      "tensor([1., 0.]) tensor([0.4996, 0.5004], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 0 - 2: cat - dog || Loss: 0.8132734298706055\n",
      "tensor([1., 0.]) tensor([0.5000, 0.5000], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 0 - 3: cat - cat || Loss: 0.8127418756484985\n",
      "tensor([1., 0.]) tensor([0.5005, 0.4995], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 0 - 4: cat - cat || Loss: 0.8120675086975098\n",
      "tensor([1., 0.]) tensor([0.5012, 0.4988], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 0 - 5: cat - cat || Loss: 0.8115184307098389\n",
      "tensor([1., 0.]) tensor([0.5017, 0.4983], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 0 - 6: cat - cat || Loss: 0.8110581636428833\n",
      "tensor([1., 0.]) tensor([0.5022, 0.4978], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 0 - 7: cat - cat || Loss: 0.8105453848838806\n",
      "tensor([1., 0.]) tensor([0.5027, 0.4973], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 0 - 8: cat - cat || Loss: 0.8099855184555054\n",
      "tensor([1., 0.]) tensor([0.5033, 0.4967], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 0 - 9: cat - cat || Loss: 0.8093833923339844\n",
      "tensor([1., 0.]) tensor([0.5039, 0.4961], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 0 - 10: cat - cat || Loss: 0.8087427020072937\n",
      "tensor([1., 0.]) tensor([0.5045, 0.4955], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 0 - 11: cat - cat || Loss: 0.8080679178237915\n",
      "tensor([1., 0.]) tensor([0.5052, 0.4948], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 0 - 12: cat - cat || Loss: 0.8073623180389404\n",
      "tensor([1., 0.]) tensor([0.5059, 0.4941], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 0 - 13: cat - cat || Loss: 0.8066287636756897\n",
      "tensor([1., 0.]) tensor([0.5066, 0.4934], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 0 - 14: cat - cat || Loss: 0.8058704137802124\n",
      "tensor([1., 0.]) tensor([0.5074, 0.4926], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 0 - 15: cat - cat || Loss: 0.80508953332901\n",
      "tensor([1., 0.]) tensor([0.5082, 0.4918], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 0 - 16: cat - cat || Loss: 0.8042886853218079\n",
      "tensor([1., 0.]) tensor([0.5090, 0.4910], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 0 - 17: cat - cat || Loss: 0.803469717502594\n",
      "tensor([1., 0.]) tensor([0.5098, 0.4902], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 0 - 18: cat - cat || Loss: 0.8026342988014221\n",
      "tensor([1., 0.]) tensor([0.5106, 0.4894], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 0 - 19: cat - cat || Loss: 0.8017842173576355\n",
      "tensor([1., 0.]) tensor([0.5115, 0.4885], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 0 - 20: cat - cat || Loss: 0.8009211421012878\n",
      "tensor([1., 0.]) tensor([0.5123, 0.4877], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 0 - 21: cat - cat || Loss: 0.8000459671020508\n",
      "tensor([1., 0.]) tensor([0.5132, 0.4868], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 0 - 22: cat - cat || Loss: 0.7991605401039124\n",
      "tensor([1., 0.]) tensor([0.5141, 0.4859], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 0 - 23: cat - cat || Loss: 0.7982654571533203\n",
      "tensor([1., 0.]) tensor([0.5150, 0.4850], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 0 - 24: cat - cat || Loss: 0.7973617911338806\n",
      "tensor([1., 0.]) tensor([0.5159, 0.4841], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 0 - 25: cat - cat || Loss: 0.7964504361152649\n",
      "tensor([1., 0.]) tensor([0.5168, 0.4832], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 0 - 26: cat - cat || Loss: 0.7955324649810791\n",
      "tensor([1., 0.]) tensor([0.5177, 0.4823], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 0 - 27: cat - cat || Loss: 0.7946081757545471\n",
      "tensor([1., 0.]) tensor([0.5187, 0.4813], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 0 - 28: cat - cat || Loss: 0.7936784029006958\n",
      "tensor([1., 0.]) tensor([0.5196, 0.4804], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 0 - 29: cat - cat || Loss: 0.7927433252334595\n",
      "tensor([1., 0.]) tensor([0.5205, 0.4795], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 0 - 30: cat - cat || Loss: 0.7918038368225098\n",
      "tensor([1., 0.]) tensor([0.5215, 0.4785], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 0 - 31: cat - cat || Loss: 0.7908605337142944\n",
      "tensor([1., 0.]) tensor([0.5224, 0.4776], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 0 - 32: cat - cat || Loss: 0.7899134159088135\n",
      "tensor([1., 0.]) tensor([0.5233, 0.4767], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 0 - 33: cat - cat || Loss: 0.7889635562896729\n",
      "tensor([1., 0.]) tensor([0.5243, 0.4757], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 0 - 34: cat - cat || Loss: 0.7880109548568726\n",
      "tensor([1., 0.]) tensor([0.5253, 0.4747], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 0 - 35: cat - cat || Loss: 0.7870556712150574\n",
      "tensor([1., 0.]) tensor([0.5262, 0.4738], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 0 - 36: cat - cat || Loss: 0.7860981822013855\n",
      "tensor([1., 0.]) tensor([0.5272, 0.4728], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 0 - 37: cat - cat || Loss: 0.785138726234436\n",
      "tensor([1., 0.]) tensor([0.5281, 0.4719], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 0 - 38: cat - cat || Loss: 0.7841775417327881\n",
      "tensor([1., 0.]) tensor([0.5291, 0.4709], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 0 - 39: cat - cat || Loss: 0.7832148671150208\n",
      "tensor([1., 0.]) tensor([0.5300, 0.4700], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 0 - 40: cat - cat || Loss: 0.7822509407997131\n",
      "tensor([1., 0.]) tensor([0.5310, 0.4690], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 0 - 41: cat - cat || Loss: 0.7812857031822205\n",
      "tensor([1., 0.]) tensor([0.5320, 0.4680], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 0 - 42: cat - cat || Loss: 0.7803195714950562\n",
      "tensor([1., 0.]) tensor([0.5329, 0.4671], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 0 - 43: cat - cat || Loss: 0.7793524265289307\n",
      "tensor([1., 0.]) tensor([0.5339, 0.4661], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 0 - 44: cat - cat || Loss: 0.7783849239349365\n",
      "tensor([1., 0.]) tensor([0.5349, 0.4651], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 0 - 45: cat - cat || Loss: 0.7774162888526917\n",
      "tensor([1., 0.]) tensor([0.5358, 0.4642], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 0 - 46: cat - cat || Loss: 0.7764471769332886\n",
      "tensor([1., 0.]) tensor([0.5368, 0.4632], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 0 - 47: cat - cat || Loss: 0.7754774689674377\n",
      "tensor([1., 0.]) tensor([0.5378, 0.4622], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 0 - 48: cat - cat || Loss: 0.774507462978363\n",
      "tensor([1., 0.]) tensor([0.5388, 0.4612], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 0 - 49: cat - cat || Loss: 0.773536741733551\n",
      "tensor([1., 0.]) tensor([0.5397, 0.4603], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 0 - 50: cat - cat || Loss: 0.7725656032562256\n",
      "tensor([1., 0.]) tensor([0.5407, 0.4593], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 0 - 51: cat - cat || Loss: 0.7715945839881897\n",
      "tensor([1., 0.]) tensor([0.5417, 0.4583], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 0 - 52: cat - cat || Loss: 0.7706232070922852\n",
      "tensor([1., 0.]) tensor([0.5426, 0.4574], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 0 - 53: cat - cat || Loss: 0.7696518898010254\n",
      "tensor([1., 0.]) tensor([0.5436, 0.4564], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 0 - 54: cat - cat || Loss: 0.7686802744865417\n",
      "tensor([1., 0.]) tensor([0.5446, 0.4554], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 0 - 55: cat - cat || Loss: 0.7677084803581238\n",
      "tensor([1., 0.]) tensor([0.5456, 0.4544], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 0 - 56: cat - cat || Loss: 0.7667365074157715\n",
      "tensor([1., 0.]) tensor([0.5465, 0.4535], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 0 - 57: cat - cat || Loss: 0.7657642960548401\n",
      "tensor([1., 0.]) tensor([0.5475, 0.4525], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 0 - 58: cat - cat || Loss: 0.7647920250892639\n",
      "tensor([1., 0.]) tensor([0.5485, 0.4515], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 0 - 59: cat - cat || Loss: 0.7638199329376221\n",
      "tensor([1., 0.]) tensor([0.5494, 0.4506], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 0 - 60: cat - cat || Loss: 0.7628474831581116\n",
      "tensor([1., 0.]) tensor([0.5504, 0.4496], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 0 - 61: cat - cat || Loss: 0.7618752121925354\n",
      "tensor([1., 0.]) tensor([0.5514, 0.4486], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 0 - 62: cat - cat || Loss: 0.7609026432037354\n",
      "tensor([1., 0.]) tensor([0.5524, 0.4476], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 0 - 63: cat - cat || Loss: 0.7599304914474487\n",
      "tensor([1., 0.]) tensor([0.5533, 0.4467], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 0 - 64: cat - cat || Loss: 0.7589583992958069\n",
      "tensor([1., 0.]) tensor([0.5543, 0.4457], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 0 - 65: cat - cat || Loss: 0.7579866647720337\n",
      "tensor([1., 0.]) tensor([0.5553, 0.4447], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 0 - 66: cat - cat || Loss: 0.7570149898529053\n",
      "tensor([1., 0.]) tensor([0.5562, 0.4438], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 0 - 67: cat - cat || Loss: 0.756044328212738\n",
      "tensor([1., 0.]) tensor([0.5572, 0.4428], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 0 - 68: cat - cat || Loss: 0.755074143409729\n",
      "tensor([1., 0.]) tensor([0.5582, 0.4418], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 0 - 69: cat - cat || Loss: 0.7541043758392334\n",
      "tensor([1., 0.]) tensor([0.5592, 0.4408], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 0 - 70: cat - cat || Loss: 0.7531347274780273\n",
      "tensor([1., 0.]) tensor([0.5601, 0.4399], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 0 - 71: cat - cat || Loss: 0.7521653771400452\n",
      "tensor([1., 0.]) tensor([0.5611, 0.4389], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 0 - 72: cat - cat || Loss: 0.7511958479881287\n",
      "tensor([1., 0.]) tensor([0.5621, 0.4379], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 0 - 73: cat - cat || Loss: 0.7502266764640808\n",
      "tensor([1., 0.]) tensor([0.5630, 0.4370], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 0 - 74: cat - cat || Loss: 0.7492573857307434\n",
      "tensor([1., 0.]) tensor([0.5640, 0.4360], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 0 - 75: cat - cat || Loss: 0.7482883334159851\n",
      "tensor([1., 0.]) tensor([0.5650, 0.4350], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 0 - 76: cat - cat || Loss: 0.7473193407058716\n",
      "tensor([1., 0.]) tensor([0.5659, 0.4341], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 0 - 77: cat - cat || Loss: 0.7463503479957581\n",
      "tensor([1., 0.]) tensor([0.5669, 0.4331], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 0 - 78: cat - cat || Loss: 0.7453813552856445\n",
      "tensor([1., 0.]) tensor([0.5679, 0.4321], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 0 - 79: cat - cat || Loss: 0.7444125413894653\n",
      "tensor([1., 0.]) tensor([0.5688, 0.4312], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 0 - 80: cat - cat || Loss: 0.7434440851211548\n",
      "tensor([1., 0.]) tensor([0.5698, 0.4302], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 0 - 81: cat - cat || Loss: 0.7424758076667786\n",
      "tensor([1., 0.]) tensor([0.5708, 0.4292], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 0 - 82: cat - cat || Loss: 0.7415078282356262\n",
      "tensor([1., 0.]) tensor([0.5718, 0.4282], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 0 - 83: cat - cat || Loss: 0.7405401468276978\n",
      "tensor([1., 0.]) tensor([0.5727, 0.4273], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 0 - 84: cat - cat || Loss: 0.7395727038383484\n",
      "tensor([1., 0.]) tensor([0.5737, 0.4263], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 0 - 85: cat - cat || Loss: 0.7386053800582886\n",
      "tensor([1., 0.]) tensor([0.5747, 0.4253], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 0 - 86: cat - cat || Loss: 0.7376382350921631\n",
      "tensor([1., 0.]) tensor([0.5756, 0.4244], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 0 - 87: cat - cat || Loss: 0.7366711497306824\n",
      "tensor([1., 0.]) tensor([0.5766, 0.4234], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 0 - 88: cat - cat || Loss: 0.7357043027877808\n",
      "tensor([1., 0.]) tensor([0.5776, 0.4224], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 0 - 89: cat - cat || Loss: 0.7347376346588135\n",
      "tensor([1., 0.]) tensor([0.5785, 0.4215], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 0 - 90: cat - cat || Loss: 0.7337713241577148\n",
      "tensor([1., 0.]) tensor([0.5795, 0.4205], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 0 - 91: cat - cat || Loss: 0.7328051328659058\n",
      "tensor([1., 0.]) tensor([0.5805, 0.4195], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 0 - 92: cat - cat || Loss: 0.7318394184112549\n",
      "tensor([1., 0.]) tensor([0.5814, 0.4186], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 0 - 93: cat - cat || Loss: 0.7308741211891174\n",
      "tensor([1., 0.]) tensor([0.5824, 0.4176], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 0 - 94: cat - cat || Loss: 0.7299090623855591\n",
      "tensor([1., 0.]) tensor([0.5834, 0.4166], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 0 - 95: cat - cat || Loss: 0.7289440631866455\n",
      "tensor([1., 0.]) tensor([0.5843, 0.4157], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 0 - 96: cat - cat || Loss: 0.7279794812202454\n",
      "tensor([1., 0.]) tensor([0.5853, 0.4147], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 0 - 97: cat - cat || Loss: 0.7270150184631348\n",
      "tensor([1., 0.]) tensor([0.5862, 0.4138], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 0 - 98: cat - cat || Loss: 0.7260513305664062\n",
      "tensor([1., 0.]) tensor([0.5872, 0.4128], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 0 - 99: cat - cat || Loss: 0.7250878810882568\n",
      "tensor([1., 0.]) tensor([0.5882, 0.4118], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 0 - 100: cat - cat || Loss: 0.7241244316101074\n",
      "tensor([1., 0.]) tensor([0.5891, 0.4109], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 0 - 101: cat - cat || Loss: 0.7231611013412476\n",
      "tensor([1., 0.]) tensor([0.5901, 0.4099], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 0 - 102: cat - cat || Loss: 0.7221981287002563\n",
      "tensor([1., 0.]) tensor([0.5911, 0.4089], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 0 - 103: cat - cat || Loss: 0.7212358117103577\n",
      "tensor([1., 0.]) tensor([0.5920, 0.4080], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 0 - 104: cat - cat || Loss: 0.7202735543251038\n",
      "tensor([1., 0.]) tensor([0.5930, 0.4070], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 0 - 105: cat - cat || Loss: 0.7193114757537842\n",
      "tensor([1., 0.]) tensor([0.5940, 0.4060], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 0 - 106: cat - cat || Loss: 0.7183496952056885\n",
      "tensor([1., 0.]) tensor([0.5949, 0.4051], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 0 - 107: cat - cat || Loss: 0.7173880338668823\n",
      "tensor([1., 0.]) tensor([0.5959, 0.4041], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 0 - 108: cat - cat || Loss: 0.7164266705513\n",
      "tensor([1., 0.]) tensor([0.5968, 0.4032], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 0 - 109: cat - cat || Loss: 0.7154654264450073\n",
      "tensor([1., 0.]) tensor([0.5978, 0.4022], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 0 - 110: cat - cat || Loss: 0.714504599571228\n",
      "tensor([1., 0.]) tensor([0.5988, 0.4012], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 0 - 111: cat - cat || Loss: 0.7135440707206726\n",
      "tensor([1., 0.]) tensor([0.5997, 0.4003], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 0 - 112: cat - cat || Loss: 0.7125838994979858\n",
      "tensor([1., 0.]) tensor([0.6007, 0.3993], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 0 - 113: cat - cat || Loss: 0.7116237878799438\n",
      "tensor([1., 0.]) tensor([0.6016, 0.3984], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 0 - 114: cat - cat || Loss: 0.7106639742851257\n",
      "tensor([1., 0.]) tensor([0.6026, 0.3974], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 0 - 115: cat - cat || Loss: 0.7097042202949524\n",
      "tensor([1., 0.]) tensor([0.6036, 0.3964], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 0 - 116: cat - cat || Loss: 0.7087450623512268\n",
      "tensor([1., 0.]) tensor([0.6045, 0.3955], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 0 - 117: cat - cat || Loss: 0.7077862620353699\n",
      "tensor([1., 0.]) tensor([0.6055, 0.3945], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 0 - 118: cat - cat || Loss: 0.7068275213241577\n",
      "tensor([1., 0.]) tensor([0.6064, 0.3936], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 0 - 119: cat - cat || Loss: 0.7058691382408142\n",
      "tensor([1., 0.]) tensor([0.6074, 0.3926], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 0 - 120: cat - cat || Loss: 0.7049112915992737\n",
      "tensor([1., 0.]) tensor([0.6084, 0.3916], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 0 - 121: cat - cat || Loss: 0.7039536237716675\n",
      "tensor([1., 0.]) tensor([0.6093, 0.3907], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 0 - 122: cat - cat || Loss: 0.7029963731765747\n",
      "tensor([1., 0.]) tensor([0.6103, 0.3897], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 0 - 123: cat - cat || Loss: 0.702039361000061\n",
      "tensor([1., 0.]) tensor([0.6112, 0.3888], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 0 - 124: cat - cat || Loss: 0.7010825872421265\n",
      "tensor([1., 0.]) tensor([0.6122, 0.3878], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 0 - 125: cat - cat || Loss: 0.7001261711120605\n",
      "tensor([1., 0.]) tensor([0.6131, 0.3869], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 0 - 126: cat - cat || Loss: 0.6991698145866394\n",
      "tensor([1., 0.]) tensor([0.6141, 0.3859], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 0 - 127: cat - cat || Loss: 0.6982137560844421\n",
      "tensor([1., 0.]) tensor([0.6150, 0.3850], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 0 - 128: cat - cat || Loss: 0.6972582936286926\n",
      "tensor([1., 0.]) tensor([0.6160, 0.3840], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 0 - 129: cat - cat || Loss: 0.6963028907775879\n",
      "tensor([1., 0.]) tensor([0.6170, 0.3830], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 0 - 130: cat - cat || Loss: 0.6953480243682861\n",
      "tensor([1., 0.]) tensor([0.6179, 0.3821], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 0 - 131: cat - cat || Loss: 0.694393515586853\n",
      "tensor([1., 0.]) tensor([0.6189, 0.3811], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 0 - 132: cat - cat || Loss: 0.693439245223999\n",
      "tensor([1., 0.]) tensor([0.6198, 0.3802], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 0 - 133: cat - cat || Loss: 0.6924850940704346\n",
      "tensor([1., 0.]) tensor([0.6208, 0.3792], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 0 - 134: cat - cat || Loss: 0.6915311813354492\n",
      "tensor([1., 0.]) tensor([0.6217, 0.3783], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 0 - 135: cat - cat || Loss: 0.6905775666236877\n",
      "tensor([1., 0.]) tensor([0.6227, 0.3773], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 0 - 136: cat - cat || Loss: 0.6896242499351501\n",
      "tensor([1., 0.]) tensor([0.6236, 0.3764], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 0 - 137: cat - cat || Loss: 0.6886709332466125\n",
      "tensor([1., 0.]) tensor([0.6246, 0.3754], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 0 - 138: cat - cat || Loss: 0.6877180933952332\n",
      "tensor([1., 0.]) tensor([0.6255, 0.3745], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 0 - 139: cat - cat || Loss: 0.6867654323577881\n",
      "tensor([1., 0.]) tensor([0.6265, 0.3735], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 0 - 140: cat - cat || Loss: 0.6858128309249878\n",
      "tensor([1., 0.]) tensor([0.6274, 0.3726], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 0 - 141: cat - cat || Loss: 0.6848607659339905\n",
      "tensor([1., 0.]) tensor([0.6284, 0.3716], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 0 - 142: cat - cat || Loss: 0.6839087009429932\n",
      "tensor([1., 0.]) tensor([0.6294, 0.3706], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 0 - 143: cat - cat || Loss: 0.6829569339752197\n",
      "tensor([1., 0.]) tensor([0.6303, 0.3697], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 0 - 144: cat - cat || Loss: 0.6820056438446045\n",
      "tensor([1., 0.]) tensor([0.6313, 0.3687], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 0 - 145: cat - cat || Loss: 0.6810543537139893\n",
      "tensor([1., 0.]) tensor([0.6322, 0.3678], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 0 - 146: cat - cat || Loss: 0.6801036596298218\n",
      "tensor([1., 0.]) tensor([0.6332, 0.3668], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 0 - 147: cat - cat || Loss: 0.6791531443595886\n",
      "tensor([1., 0.]) tensor([0.6341, 0.3659], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 0 - 148: cat - cat || Loss: 0.6782028079032898\n",
      "tensor([1., 0.]) tensor([0.6351, 0.3649], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 0 - 149: cat - cat || Loss: 0.6772531270980835\n",
      "tensor([1., 0.]) tensor([0.6360, 0.3640], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 0 - 150: cat - cat || Loss: 0.6763039231300354\n",
      "tensor([1., 0.]) tensor([0.6370, 0.3630], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 0 - 151: cat - cat || Loss: 0.6753550171852112\n",
      "tensor([1., 0.]) tensor([0.6379, 0.3621], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 0 - 152: cat - cat || Loss: 0.6744063496589661\n",
      "tensor([1., 0.]) tensor([0.6389, 0.3611], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 0 - 153: cat - cat || Loss: 0.6734582185745239\n",
      "tensor([1., 0.]) tensor([0.6398, 0.3602], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 0 - 154: cat - cat || Loss: 0.6725102066993713\n",
      "tensor([1., 0.]) tensor([0.6408, 0.3592], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 0 - 155: cat - cat || Loss: 0.671562671661377\n",
      "tensor([1., 0.]) tensor([0.6417, 0.3583], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 0 - 156: cat - cat || Loss: 0.6706156730651855\n",
      "tensor([1., 0.]) tensor([0.6426, 0.3574], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 0 - 157: cat - cat || Loss: 0.6696689128875732\n",
      "tensor([1., 0.]) tensor([0.6436, 0.3564], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 0 - 158: cat - cat || Loss: 0.66872239112854\n",
      "tensor([1., 0.]) tensor([0.6445, 0.3555], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 0 - 159: cat - cat || Loss: 0.6677762269973755\n",
      "tensor([1., 0.]) tensor([0.6455, 0.3545], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 0 - 160: cat - cat || Loss: 0.6668299436569214\n",
      "tensor([1., 0.]) tensor([0.6464, 0.3536], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 0 - 161: cat - cat || Loss: 0.6658836603164673\n",
      "tensor([1., 0.]) tensor([0.6474, 0.3526], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 0 - 162: cat - cat || Loss: 0.6649380922317505\n",
      "tensor([1., 0.]) tensor([0.6483, 0.3517], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 0 - 163: cat - cat || Loss: 0.6639926433563232\n",
      "tensor([1., 0.]) tensor([0.6493, 0.3507], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 0 - 164: cat - cat || Loss: 0.6630478501319885\n",
      "tensor([1., 0.]) tensor([0.6502, 0.3498], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 0 - 165: cat - cat || Loss: 0.6621031761169434\n",
      "tensor([1., 0.]) tensor([0.6512, 0.3488], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 0 - 166: cat - cat || Loss: 0.6611586809158325\n",
      "tensor([1., 0.]) tensor([0.6521, 0.3479], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 0 - 167: cat - cat || Loss: 0.6602148413658142\n",
      "tensor([1., 0.]) tensor([0.6530, 0.3470], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 0 - 168: cat - cat || Loss: 0.6592712998390198\n",
      "tensor([1., 0.]) tensor([0.6540, 0.3460], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 0 - 169: cat - cat || Loss: 0.6583278179168701\n",
      "tensor([1., 0.]) tensor([0.6549, 0.3451], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 0 - 170: cat - cat || Loss: 0.6573845148086548\n",
      "tensor([1., 0.]) tensor([0.6559, 0.3441], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 0 - 171: cat - cat || Loss: 0.6564418077468872\n",
      "tensor([1., 0.]) tensor([0.6568, 0.3432], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 0 - 172: cat - cat || Loss: 0.6554991006851196\n",
      "tensor([1., 0.]) tensor([0.6578, 0.3422], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 0 - 173: cat - cat || Loss: 0.6545570492744446\n",
      "tensor([1., 0.]) tensor([0.6587, 0.3413], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 0 - 174: cat - cat || Loss: 0.6536147594451904\n",
      "tensor([1., 0.]) tensor([0.6596, 0.3404], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 0 - 175: cat - cat || Loss: 0.6526730060577393\n",
      "tensor([1., 0.]) tensor([0.6606, 0.3394], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 0 - 176: cat - cat || Loss: 0.6517316102981567\n",
      "tensor([1., 0.]) tensor([0.6615, 0.3385], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 0 - 177: cat - cat || Loss: 0.6507906317710876\n",
      "tensor([1., 0.]) tensor([0.6625, 0.3375], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 0 - 178: cat - cat || Loss: 0.6498498916625977\n",
      "tensor([1., 0.]) tensor([0.6634, 0.3366], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 0 - 179: cat - cat || Loss: 0.6489099264144897\n",
      "tensor([1., 0.]) tensor([0.6644, 0.3356], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 0 - 180: cat - cat || Loss: 0.6479700207710266\n",
      "tensor([1., 0.]) tensor([0.6653, 0.3347], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 0 - 181: cat - cat || Loss: 0.6470305919647217\n",
      "tensor([1., 0.]) tensor([0.6662, 0.3338], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 0 - 182: cat - cat || Loss: 0.6460913419723511\n",
      "tensor([1., 0.]) tensor([0.6672, 0.3328], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 0 - 183: cat - cat || Loss: 0.6451525092124939\n",
      "tensor([1., 0.]) tensor([0.6681, 0.3319], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 0 - 184: cat - cat || Loss: 0.6442139148712158\n",
      "tensor([1., 0.]) tensor([0.6690, 0.3310], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 0 - 185: cat - cat || Loss: 0.6432758569717407\n",
      "tensor([1., 0.]) tensor([0.6700, 0.3300], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 0 - 186: cat - cat || Loss: 0.6423381567001343\n",
      "tensor([1., 0.]) tensor([0.6709, 0.3291], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 0 - 187: cat - cat || Loss: 0.6414006948471069\n",
      "tensor([1., 0.]) tensor([0.6719, 0.3281], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 0 - 188: cat - cat || Loss: 0.6404637098312378\n",
      "tensor([1., 0.]) tensor([0.6728, 0.3272], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 0 - 189: cat - cat || Loss: 0.6395272016525269\n",
      "tensor([1., 0.]) tensor([0.6737, 0.3263], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 0 - 190: dog - cat || Loss: 0.9879322648048401\n",
      "tensor([0., 1.]) tensor([0.6747, 0.3253], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 0 - 191: dog - cat || Loss: 0.9886810779571533\n",
      "tensor([0., 1.]) tensor([0.6754, 0.3246], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 0 - 192: dog - cat || Loss: 0.989261269569397\n",
      "tensor([0., 1.]) tensor([0.6760, 0.3240], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 0 - 193: dog - cat || Loss: 0.9896899461746216\n",
      "tensor([0., 1.]) tensor([0.6764, 0.3236], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 0 - 194: dog - cat || Loss: 0.989982008934021\n",
      "tensor([0., 1.]) tensor([0.6767, 0.3233], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 0 - 195: dog - cat || Loss: 0.9901514053344727\n",
      "tensor([0., 1.]) tensor([0.6769, 0.3231], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 0 - 196: dog - cat || Loss: 0.9902101755142212\n",
      "tensor([0., 1.]) tensor([0.6769, 0.3231], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 0 - 197: dog - cat || Loss: 0.9901696443557739\n",
      "tensor([0., 1.]) tensor([0.6769, 0.3231], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 0 - 198: dog - cat || Loss: 0.9900397062301636\n",
      "tensor([0., 1.]) tensor([0.6768, 0.3232], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 0 - 199: dog - cat || Loss: 0.9898290634155273\n",
      "tensor([0., 1.]) tensor([0.6766, 0.3234], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 0 - 200: dog - cat || Loss: 0.989546000957489\n",
      "tensor([0., 1.]) tensor([0.6763, 0.3237], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 0 - 201: dog - cat || Loss: 0.9891977310180664\n",
      "tensor([0., 1.]) tensor([0.6759, 0.3241], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 0 - 202: dog - cat || Loss: 0.9887908101081848\n",
      "tensor([0., 1.]) tensor([0.6755, 0.3245], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 0 - 203: dog - cat || Loss: 0.9883309006690979\n",
      "tensor([0., 1.]) tensor([0.6751, 0.3249], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 0 - 204: dog - cat || Loss: 0.987823486328125\n",
      "tensor([0., 1.]) tensor([0.6746, 0.3254], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 0 - 205: dog - cat || Loss: 0.9872729182243347\n",
      "tensor([0., 1.]) tensor([0.6740, 0.3260], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 0 - 206: dog - cat || Loss: 0.9866839051246643\n",
      "tensor([0., 1.]) tensor([0.6734, 0.3266], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 0 - 207: dog - cat || Loss: 0.9860603213310242\n",
      "tensor([0., 1.]) tensor([0.6728, 0.3272], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 0 - 208: dog - cat || Loss: 0.9854050278663635\n",
      "tensor([0., 1.]) tensor([0.6721, 0.3279], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 0 - 209: dog - cat || Loss: 0.9847216010093689\n",
      "tensor([0., 1.]) tensor([0.6715, 0.3285], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 0 - 210: dog - cat || Loss: 0.9840126633644104\n",
      "tensor([0., 1.]) tensor([0.6708, 0.3292], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 0 - 211: dog - cat || Loss: 0.9832812547683716\n",
      "tensor([0., 1.]) tensor([0.6700, 0.3300], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 0 - 212: dog - cat || Loss: 0.9825287461280823\n",
      "tensor([0., 1.]) tensor([0.6693, 0.3307], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 0 - 213: dog - cat || Loss: 0.9817578792572021\n",
      "tensor([0., 1.]) tensor([0.6685, 0.3315], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 0 - 214: dog - cat || Loss: 0.9809702038764954\n",
      "tensor([0., 1.]) tensor([0.6677, 0.3323], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 0 - 215: dog - cat || Loss: 0.9801674485206604\n",
      "tensor([0., 1.]) tensor([0.6669, 0.3331], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 0 - 216: dog - cat || Loss: 0.9793511033058167\n",
      "tensor([0., 1.]) tensor([0.6661, 0.3339], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 0 - 217: dog - cat || Loss: 0.9785223007202148\n",
      "tensor([0., 1.]) tensor([0.6653, 0.3347], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 0 - 218: dog - cat || Loss: 0.9776827692985535\n",
      "tensor([0., 1.]) tensor([0.6644, 0.3356], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 0 - 219: dog - cat || Loss: 0.9768331050872803\n",
      "tensor([0., 1.]) tensor([0.6636, 0.3364], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 0 - 220: dog - cat || Loss: 0.9759746193885803\n",
      "tensor([0., 1.]) tensor([0.6627, 0.3373], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 0 - 221: dog - cat || Loss: 0.9751083850860596\n",
      "tensor([0., 1.]) tensor([0.6618, 0.3382], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 0 - 222: dog - cat || Loss: 0.9742348194122314\n",
      "tensor([0., 1.]) tensor([0.6610, 0.3390], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 0 - 223: dog - cat || Loss: 0.9733545184135437\n",
      "tensor([0., 1.]) tensor([0.6601, 0.3399], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 0 - 224: dog - cat || Loss: 0.972468376159668\n",
      "tensor([0., 1.]) tensor([0.6592, 0.3408], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 0 - 225: dog - cat || Loss: 0.9715768694877625\n",
      "tensor([0., 1.]) tensor([0.6583, 0.3417], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 0 - 226: dog - cat || Loss: 0.9706804752349854\n",
      "tensor([0., 1.]) tensor([0.6574, 0.3426], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 0 - 227: dog - cat || Loss: 0.9697799682617188\n",
      "tensor([0., 1.]) tensor([0.6565, 0.3435], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 0 - 228: dog - cat || Loss: 0.9688752889633179\n",
      "tensor([0., 1.]) tensor([0.6556, 0.3444], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 0 - 229: dog - cat || Loss: 0.9679673314094543\n",
      "tensor([0., 1.]) tensor([0.6547, 0.3453], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 0 - 230: dog - cat || Loss: 0.9670559167861938\n",
      "tensor([0., 1.]) tensor([0.6538, 0.3462], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 0 - 231: dog - cat || Loss: 0.9661418199539185\n",
      "tensor([0., 1.]) tensor([0.6529, 0.3471], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 0 - 232: dog - cat || Loss: 0.9652249813079834\n",
      "tensor([0., 1.]) tensor([0.6520, 0.3480], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 0 - 233: dog - cat || Loss: 0.9643060564994812\n",
      "tensor([0., 1.]) tensor([0.6510, 0.3490], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 0 - 234: dog - cat || Loss: 0.9633846282958984\n",
      "tensor([0., 1.]) tensor([0.6501, 0.3499], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 0 - 235: dog - cat || Loss: 0.9624617099761963\n",
      "tensor([0., 1.]) tensor([0.6492, 0.3508], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 0 - 236: dog - cat || Loss: 0.9615369439125061\n",
      "tensor([0., 1.]) tensor([0.6483, 0.3517], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 0 - 237: dog - cat || Loss: 0.9606108069419861\n",
      "tensor([0., 1.]) tensor([0.6473, 0.3527], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 0 - 238: dog - cat || Loss: 0.9596832990646362\n",
      "tensor([0., 1.]) tensor([0.6464, 0.3536], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 0 - 239: dog - cat || Loss: 0.9587541818618774\n",
      "tensor([0., 1.]) tensor([0.6455, 0.3545], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 0 - 240: dog - cat || Loss: 0.9578239321708679\n",
      "tensor([0., 1.]) tensor([0.6446, 0.3554], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 0 - 241: dog - cat || Loss: 0.956892728805542\n",
      "tensor([0., 1.]) tensor([0.6436, 0.3564], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 0 - 242: dog - cat || Loss: 0.955960214138031\n",
      "tensor([0., 1.]) tensor([0.6427, 0.3573], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 0 - 243: dog - cat || Loss: 0.9550267457962036\n",
      "tensor([0., 1.]) tensor([0.6418, 0.3582], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 0 - 244: dog - cat || Loss: 0.9540925621986389\n",
      "tensor([0., 1.]) tensor([0.6408, 0.3592], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 0 - 245: dog - cat || Loss: 0.953157365322113\n",
      "tensor([0., 1.]) tensor([0.6399, 0.3601], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 0 - 246: dog - cat || Loss: 0.9522217512130737\n",
      "tensor([0., 1.]) tensor([0.6390, 0.3610], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 0 - 247: dog - cat || Loss: 0.9512852430343628\n",
      "tensor([0., 1.]) tensor([0.6380, 0.3620], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 0 - 248: dog - cat || Loss: 0.9503484964370728\n",
      "tensor([0., 1.]) tensor([0.6371, 0.3629], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 0 - 249: dog - cat || Loss: 0.9494109153747559\n",
      "tensor([0., 1.]) tensor([0.6361, 0.3639], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 0 - 250: dog - cat || Loss: 0.9484729170799255\n",
      "tensor([0., 1.]) tensor([0.6352, 0.3648], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 0 - 251: dog - cat || Loss: 0.947534441947937\n",
      "tensor([0., 1.]) tensor([0.6343, 0.3657], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 0 - 252: dog - cat || Loss: 0.9465956091880798\n",
      "tensor([0., 1.]) tensor([0.6333, 0.3667], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 0 - 253: dog - cat || Loss: 0.9456564784049988\n",
      "tensor([0., 1.]) tensor([0.6324, 0.3676], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 0 - 254: dog - cat || Loss: 0.9447168111801147\n",
      "tensor([0., 1.]) tensor([0.6315, 0.3685], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 0 - 255: dog - cat || Loss: 0.9437771439552307\n",
      "tensor([0., 1.]) tensor([0.6305, 0.3695], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 0 - 256: dog - cat || Loss: 0.9428370594978333\n",
      "tensor([0., 1.]) tensor([0.6296, 0.3704], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 0 - 257: dog - cat || Loss: 0.941896915435791\n",
      "tensor([0., 1.]) tensor([0.6286, 0.3714], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 0 - 258: dog - cat || Loss: 0.9409564733505249\n",
      "tensor([0., 1.]) tensor([0.6277, 0.3723], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 0 - 259: dog - cat || Loss: 0.9400156736373901\n",
      "tensor([0., 1.]) tensor([0.6268, 0.3732], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 0 - 260: dog - cat || Loss: 0.9390746355056763\n",
      "tensor([0., 1.]) tensor([0.6258, 0.3742], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 0 - 261: dog - cat || Loss: 0.9381333589553833\n",
      "tensor([0., 1.]) tensor([0.6249, 0.3751], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 0 - 262: dog - cat || Loss: 0.937191903591156\n",
      "tensor([0., 1.]) tensor([0.6239, 0.3761], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 0 - 263: dog - cat || Loss: 0.9362499713897705\n",
      "tensor([0., 1.]) tensor([0.6230, 0.3770], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 0 - 264: dog - cat || Loss: 0.935308039188385\n",
      "tensor([0., 1.]) tensor([0.6220, 0.3780], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 0 - 265: dog - cat || Loss: 0.9343655705451965\n",
      "tensor([0., 1.]) tensor([0.6211, 0.3789], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 0 - 266: dog - cat || Loss: 0.9334229826927185\n",
      "tensor([0., 1.]) tensor([0.6202, 0.3798], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 0 - 267: dog - cat || Loss: 0.9324802160263062\n",
      "tensor([0., 1.]) tensor([0.6192, 0.3808], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 0 - 268: dog - cat || Loss: 0.9315369129180908\n",
      "tensor([0., 1.]) tensor([0.6183, 0.3817], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 0 - 269: dog - cat || Loss: 0.9305934309959412\n",
      "tensor([0., 1.]) tensor([0.6173, 0.3827], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 0 - 270: dog - cat || Loss: 0.9296497106552124\n",
      "tensor([0., 1.]) tensor([0.6164, 0.3836], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 0 - 271: dog - cat || Loss: 0.9287058711051941\n",
      "tensor([0., 1.]) tensor([0.6154, 0.3846], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 0 - 272: dog - cat || Loss: 0.9277616739273071\n",
      "tensor([0., 1.]) tensor([0.6145, 0.3855], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 0 - 273: dog - cat || Loss: 0.9268172979354858\n",
      "tensor([0., 1.]) tensor([0.6136, 0.3864], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 0 - 274: dog - cat || Loss: 0.925872802734375\n",
      "tensor([0., 1.]) tensor([0.6126, 0.3874], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 0 - 275: dog - cat || Loss: 0.924927830696106\n",
      "tensor([0., 1.]) tensor([0.6117, 0.3883], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 0 - 276: dog - cat || Loss: 0.9239827394485474\n",
      "tensor([0., 1.]) tensor([0.6107, 0.3893], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 0 - 277: dog - cat || Loss: 0.923037588596344\n",
      "tensor([0., 1.]) tensor([0.6098, 0.3902], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 0 - 278: dog - cat || Loss: 0.9220921993255615\n",
      "tensor([0., 1.]) tensor([0.6088, 0.3912], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 0 - 279: dog - cat || Loss: 0.9211466908454895\n",
      "tensor([0., 1.]) tensor([0.6079, 0.3921], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 0 - 280: dog - cat || Loss: 0.9202010631561279\n",
      "tensor([0., 1.]) tensor([0.6069, 0.3931], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 0 - 281: dog - cat || Loss: 0.9192553758621216\n",
      "tensor([0., 1.]) tensor([0.6060, 0.3940], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 0 - 282: dog - cat || Loss: 0.9183095097541809\n",
      "tensor([0., 1.]) tensor([0.6050, 0.3950], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 0 - 283: dog - cat || Loss: 0.9173634648323059\n",
      "tensor([0., 1.]) tensor([0.6041, 0.3959], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 0 - 284: dog - cat || Loss: 0.9164173603057861\n",
      "tensor([0., 1.]) tensor([0.6032, 0.3968], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 0 - 285: dog - cat || Loss: 0.9154708981513977\n",
      "tensor([0., 1.]) tensor([0.6022, 0.3978], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 0 - 286: dog - cat || Loss: 0.914524495601654\n",
      "tensor([0., 1.]) tensor([0.6013, 0.3987], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 0 - 287: dog - cat || Loss: 0.913577675819397\n",
      "tensor([0., 1.]) tensor([0.6003, 0.3997], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 0 - 288: dog - cat || Loss: 0.9126307368278503\n",
      "tensor([0., 1.]) tensor([0.5994, 0.4006], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 0 - 289: dog - cat || Loss: 0.9116835594177246\n",
      "tensor([0., 1.]) tensor([0.5984, 0.4016], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 0 - 290: dog - cat || Loss: 0.9107367396354675\n",
      "tensor([0., 1.]) tensor([0.5975, 0.4025], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 0 - 291: dog - cat || Loss: 0.9097894430160522\n",
      "tensor([0., 1.]) tensor([0.5965, 0.4035], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 0 - 292: dog - cat || Loss: 0.9088419079780579\n",
      "tensor([0., 1.]) tensor([0.5956, 0.4044], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 0 - 293: dog - cat || Loss: 0.907894492149353\n",
      "tensor([0., 1.]) tensor([0.5946, 0.4054], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 0 - 294: dog - cat || Loss: 0.9069466590881348\n",
      "tensor([0., 1.]) tensor([0.5937, 0.4063], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 0 - 295: dog - cat || Loss: 0.9059988260269165\n",
      "tensor([0., 1.]) tensor([0.5927, 0.4073], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 0 - 296: dog - cat || Loss: 0.9050508737564087\n",
      "tensor([0., 1.]) tensor([0.5918, 0.4082], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 0 - 297: dog - cat || Loss: 0.9041027426719666\n",
      "tensor([0., 1.]) tensor([0.5908, 0.4092], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 0 - 298: dog - cat || Loss: 0.9031544923782349\n",
      "tensor([0., 1.]) tensor([0.5899, 0.4101], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 0 - 299: dog - cat || Loss: 0.9022062420845032\n",
      "tensor([0., 1.]) tensor([0.5889, 0.4111], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 0 - 300: dog - cat || Loss: 0.9012575745582581\n",
      "tensor([0., 1.]) tensor([0.5880, 0.4120], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 0 - 301: dog - cat || Loss: 0.9003088474273682\n",
      "tensor([0., 1.]) tensor([0.5870, 0.4130], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 0 - 302: dog - cat || Loss: 0.8993600606918335\n",
      "tensor([0., 1.]) tensor([0.5861, 0.4139], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 0 - 303: dog - cat || Loss: 0.8984108567237854\n",
      "tensor([0., 1.]) tensor([0.5851, 0.4149], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 0 - 304: dog - cat || Loss: 0.8974617123603821\n",
      "tensor([0., 1.]) tensor([0.5842, 0.4158], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 0 - 305: dog - cat || Loss: 0.8965121507644653\n",
      "tensor([0., 1.]) tensor([0.5833, 0.4167], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 0 - 306: dog - cat || Loss: 0.8955627083778381\n",
      "tensor([0., 1.]) tensor([0.5823, 0.4177], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 0 - 307: dog - cat || Loss: 0.8946130275726318\n",
      "tensor([0., 1.]) tensor([0.5814, 0.4186], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 0 - 308: dog - cat || Loss: 0.8936631679534912\n",
      "tensor([0., 1.]) tensor([0.5804, 0.4196], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 0 - 309: dog - cat || Loss: 0.892713189125061\n",
      "tensor([0., 1.]) tensor([0.5795, 0.4205], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 0 - 310: dog - cat || Loss: 0.8917627930641174\n",
      "tensor([0., 1.]) tensor([0.5785, 0.4215], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 0 - 311: dog - cat || Loss: 0.8908125162124634\n",
      "tensor([0., 1.]) tensor([0.5776, 0.4224], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 0 - 312: dog - cat || Loss: 0.8898620009422302\n",
      "tensor([0., 1.]) tensor([0.5766, 0.4234], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 0 - 313: dog - cat || Loss: 0.8889113068580627\n",
      "tensor([0., 1.]) tensor([0.5756, 0.4244], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 0 - 314: dog - cat || Loss: 0.8879606127738953\n",
      "tensor([0., 1.]) tensor([0.5747, 0.4253], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 0 - 315: dog - cat || Loss: 0.8870096206665039\n",
      "tensor([0., 1.]) tensor([0.5737, 0.4263], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 0 - 316: dog - cat || Loss: 0.8860585689544678\n",
      "tensor([0., 1.]) tensor([0.5728, 0.4272], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 0 - 317: dog - cat || Loss: 0.8851073980331421\n",
      "tensor([0., 1.]) tensor([0.5718, 0.4282], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 0 - 318: dog - cat || Loss: 0.8841560482978821\n",
      "tensor([0., 1.]) tensor([0.5709, 0.4291], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 0 - 319: dog - cat || Loss: 0.8832046985626221\n",
      "tensor([0., 1.]) tensor([0.5699, 0.4301], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 0 - 320: dog - cat || Loss: 0.8822529911994934\n",
      "tensor([0., 1.]) tensor([0.5690, 0.4310], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 0 - 321: dog - cat || Loss: 0.8813013434410095\n",
      "tensor([0., 1.]) tensor([0.5680, 0.4320], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 0 - 322: dog - cat || Loss: 0.8803495168685913\n",
      "tensor([0., 1.]) tensor([0.5671, 0.4329], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 0 - 323: dog - cat || Loss: 0.8793976306915283\n",
      "tensor([0., 1.]) tensor([0.5661, 0.4339], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 0 - 324: dog - cat || Loss: 0.8784455060958862\n",
      "tensor([0., 1.]) tensor([0.5652, 0.4348], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 0 - 325: dog - cat || Loss: 0.8774932622909546\n",
      "tensor([0., 1.]) tensor([0.5642, 0.4358], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 0 - 326: dog - cat || Loss: 0.8765408992767334\n",
      "tensor([0., 1.]) tensor([0.5633, 0.4367], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 0 - 327: dog - cat || Loss: 0.875588595867157\n",
      "tensor([0., 1.]) tensor([0.5623, 0.4377], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 0 - 328: dog - cat || Loss: 0.8746361136436462\n",
      "tensor([0., 1.]) tensor([0.5614, 0.4386], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 0 - 329: dog - cat || Loss: 0.8736835718154907\n",
      "tensor([0., 1.]) tensor([0.5604, 0.4396], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 0 - 330: dog - cat || Loss: 0.8727308511734009\n",
      "tensor([0., 1.]) tensor([0.5595, 0.4405], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 0 - 331: dog - cat || Loss: 0.8717782497406006\n",
      "tensor([0., 1.]) tensor([0.5585, 0.4415], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 0 - 332: dog - cat || Loss: 0.870825469493866\n",
      "tensor([0., 1.]) tensor([0.5576, 0.4424], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 0 - 333: dog - cat || Loss: 0.8698723316192627\n",
      "tensor([0., 1.]) tensor([0.5566, 0.4434], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 0 - 334: dog - cat || Loss: 0.8689192533493042\n",
      "tensor([0., 1.]) tensor([0.5557, 0.4443], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 0 - 335: dog - cat || Loss: 0.8679662942886353\n",
      "tensor([0., 1.]) tensor([0.5547, 0.4453], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 0 - 336: dog - cat || Loss: 0.8670132756233215\n",
      "tensor([0., 1.]) tensor([0.5538, 0.4462], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 0 - 337: dog - cat || Loss: 0.866060197353363\n",
      "tensor([0., 1.]) tensor([0.5528, 0.4472], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 0 - 338: dog - cat || Loss: 0.8651072978973389\n",
      "tensor([0., 1.]) tensor([0.5518, 0.4482], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 0 - 339: dog - cat || Loss: 0.8641542196273804\n",
      "tensor([0., 1.]) tensor([0.5509, 0.4491], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 0 - 340: dog - cat || Loss: 0.8632011413574219\n",
      "tensor([0., 1.]) tensor([0.5499, 0.4501], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 0 - 341: dog - cat || Loss: 0.8622480630874634\n",
      "tensor([0., 1.]) tensor([0.5490, 0.4510], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 0 - 342: dog - cat || Loss: 0.8612948656082153\n",
      "tensor([0., 1.]) tensor([0.5480, 0.4520], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 0 - 343: dog - cat || Loss: 0.8603417277336121\n",
      "tensor([0., 1.]) tensor([0.5471, 0.4529], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 0 - 344: dog - cat || Loss: 0.8593882918357849\n",
      "tensor([0., 1.]) tensor([0.5461, 0.4539], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 0 - 345: dog - cat || Loss: 0.8584350347518921\n",
      "tensor([0., 1.]) tensor([0.5452, 0.4548], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 0 - 346: dog - cat || Loss: 0.8574815988540649\n",
      "tensor([0., 1.]) tensor([0.5442, 0.4558], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 0 - 347: dog - cat || Loss: 0.8565282821655273\n",
      "tensor([0., 1.]) tensor([0.5433, 0.4567], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 0 - 348: dog - cat || Loss: 0.8555749654769897\n",
      "tensor([0., 1.]) tensor([0.5423, 0.4577], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 0 - 349: dog - cat || Loss: 0.8546217679977417\n",
      "tensor([0., 1.]) tensor([0.5414, 0.4586], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 0 - 350: dog - cat || Loss: 0.8536686897277832\n",
      "tensor([0., 1.]) tensor([0.5404, 0.4596], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 0 - 351: dog - cat || Loss: 0.8527154326438904\n",
      "tensor([0., 1.]) tensor([0.5395, 0.4605], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 0 - 352: dog - cat || Loss: 0.8517624139785767\n",
      "tensor([0., 1.]) tensor([0.5385, 0.4615], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 0 - 353: dog - cat || Loss: 0.8508092164993286\n",
      "tensor([0., 1.]) tensor([0.5375, 0.4625], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 0 - 354: dog - cat || Loss: 0.8498561382293701\n",
      "tensor([0., 1.]) tensor([0.5366, 0.4634], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 0 - 355: dog - cat || Loss: 0.8489030003547668\n",
      "tensor([0., 1.]) tensor([0.5356, 0.4644], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 0 - 356: dog - cat || Loss: 0.8479499220848083\n",
      "tensor([0., 1.]) tensor([0.5347, 0.4653], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 0 - 357: dog - cat || Loss: 0.8469969034194946\n",
      "tensor([0., 1.]) tensor([0.5337, 0.4663], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 0 - 358: dog - cat || Loss: 0.8460437059402466\n",
      "tensor([0., 1.]) tensor([0.5328, 0.4672], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 0 - 359: dog - cat || Loss: 0.8450905680656433\n",
      "tensor([0., 1.]) tensor([0.5318, 0.4682], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 0 - 360: dog - cat || Loss: 0.8441373705863953\n",
      "tensor([0., 1.]) tensor([0.5309, 0.4691], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 0 - 361: dog - cat || Loss: 0.843184232711792\n",
      "tensor([0., 1.]) tensor([0.5299, 0.4701], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 0 - 362: dog - cat || Loss: 0.8422307968139648\n",
      "tensor([0., 1.]) tensor([0.5290, 0.4710], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 0 - 363: dog - cat || Loss: 0.8412774205207825\n",
      "tensor([0., 1.]) tensor([0.5280, 0.4720], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 0 - 364: dog - cat || Loss: 0.8403240442276001\n",
      "tensor([0., 1.]) tensor([0.5271, 0.4729], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 0 - 365: dog - cat || Loss: 0.839370608329773\n",
      "tensor([0., 1.]) tensor([0.5261, 0.4739], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 0 - 366: dog - cat || Loss: 0.8384170532226562\n",
      "tensor([0., 1.]) tensor([0.5252, 0.4748], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 0 - 367: dog - cat || Loss: 0.8374637365341187\n",
      "tensor([0., 1.]) tensor([0.5242, 0.4758], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 0 - 368: dog - cat || Loss: 0.8365101218223572\n",
      "tensor([0., 1.]) tensor([0.5232, 0.4768], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 0 - 369: dog - cat || Loss: 0.8355564475059509\n",
      "tensor([0., 1.]) tensor([0.5223, 0.4777], grad_fn=<SoftmaxBackward0>)\n",
      "=====epoch:1=====\n",
      "Epoch 1 - 0: cat - cat || Loss: 0.7919206023216248\n",
      "tensor([1., 0.]) tensor([0.5213, 0.4787], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 1 - 1: cat - cat || Loss: 0.7926832437515259\n",
      "tensor([1., 0.]) tensor([0.5206, 0.4794], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 1 - 2: cat - cat || Loss: 0.7932742834091187\n",
      "tensor([1., 0.]) tensor([0.5200, 0.4800], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 1 - 3: cat - cat || Loss: 0.7937107086181641\n",
      "tensor([1., 0.]) tensor([0.5196, 0.4804], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 1 - 4: cat - cat || Loss: 0.7940080165863037\n",
      "tensor([1., 0.]) tensor([0.5193, 0.4807], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 1 - 5: cat - cat || Loss: 0.794180154800415\n",
      "tensor([1., 0.]) tensor([0.5191, 0.4809], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 1 - 6: cat - cat || Loss: 0.7942396402359009\n",
      "tensor([1., 0.]) tensor([0.5190, 0.4810], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 1 - 7: cat - cat || Loss: 0.7941975593566895\n",
      "tensor([1., 0.]) tensor([0.5191, 0.4809], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 1 - 8: cat - cat || Loss: 0.7940645813941956\n",
      "tensor([1., 0.]) tensor([0.5192, 0.4808], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 1 - 9: cat - cat || Loss: 0.7938494682312012\n",
      "tensor([1., 0.]) tensor([0.5194, 0.4806], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 1 - 10: cat - cat || Loss: 0.793560266494751\n",
      "tensor([1., 0.]) tensor([0.5197, 0.4803], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 1 - 11: cat - cat || Loss: 0.7932047843933105\n",
      "tensor([1., 0.]) tensor([0.5201, 0.4799], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 1 - 12: cat - cat || Loss: 0.7927894592285156\n",
      "tensor([1., 0.]) tensor([0.5205, 0.4795], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 1 - 13: cat - cat || Loss: 0.7923203110694885\n",
      "tensor([1., 0.]) tensor([0.5209, 0.4791], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 1 - 14: cat - cat || Loss: 0.7918030023574829\n",
      "tensor([1., 0.]) tensor([0.5215, 0.4785], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 1 - 15: cat - cat || Loss: 0.7912418842315674\n",
      "tensor([1., 0.]) tensor([0.5220, 0.4780], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 1 - 16: cat - cat || Loss: 0.7906417846679688\n",
      "tensor([1., 0.]) tensor([0.5226, 0.4774], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 1 - 17: cat - cat || Loss: 0.7900062799453735\n",
      "tensor([1., 0.]) tensor([0.5233, 0.4767], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 1 - 18: cat - cat || Loss: 0.7893393039703369\n",
      "tensor([1., 0.]) tensor([0.5239, 0.4761], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 1 - 19: cat - cat || Loss: 0.7886438369750977\n",
      "tensor([1., 0.]) tensor([0.5246, 0.4754], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 1 - 20: cat - cat || Loss: 0.787922739982605\n",
      "tensor([1., 0.]) tensor([0.5253, 0.4747], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 1 - 21: cat - cat || Loss: 0.7871784567832947\n",
      "tensor([1., 0.]) tensor([0.5261, 0.4739], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 1 - 22: cat - cat || Loss: 0.7864137291908264\n",
      "tensor([1., 0.]) tensor([0.5268, 0.4732], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 1 - 23: cat - cat || Loss: 0.7856301665306091\n",
      "tensor([1., 0.]) tensor([0.5276, 0.4724], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 1 - 24: cat - cat || Loss: 0.7848297357559204\n",
      "tensor([1., 0.]) tensor([0.5284, 0.4716], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 1 - 25: cat - cat || Loss: 0.7840143442153931\n",
      "tensor([1., 0.]) tensor([0.5292, 0.4708], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 1 - 26: cat - cat || Loss: 0.7831853628158569\n",
      "tensor([1., 0.]) tensor([0.5301, 0.4699], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 1 - 27: cat - cat || Loss: 0.7823442220687866\n",
      "tensor([1., 0.]) tensor([0.5309, 0.4691], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 1 - 28: cat - cat || Loss: 0.7814923524856567\n",
      "tensor([1., 0.]) tensor([0.5318, 0.4682], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 1 - 29: cat - cat || Loss: 0.7806305885314941\n",
      "tensor([1., 0.]) tensor([0.5326, 0.4674], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 1 - 30: cat - cat || Loss: 0.7797600030899048\n",
      "tensor([1., 0.]) tensor([0.5335, 0.4665], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 1 - 31: cat - cat || Loss: 0.7788814306259155\n",
      "tensor([1., 0.]) tensor([0.5344, 0.4656], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 1 - 32: cat - cat || Loss: 0.7779955863952637\n",
      "tensor([1., 0.]) tensor([0.5353, 0.4647], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 1 - 33: cat - cat || Loss: 0.7771035432815552\n",
      "tensor([1., 0.]) tensor([0.5362, 0.4638], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 1 - 34: cat - cat || Loss: 0.7762056589126587\n",
      "tensor([1., 0.]) tensor([0.5371, 0.4629], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 1 - 35: cat - cat || Loss: 0.7753024101257324\n",
      "tensor([1., 0.]) tensor([0.5380, 0.4620], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 1 - 36: cat - cat || Loss: 0.7743946313858032\n",
      "tensor([1., 0.]) tensor([0.5389, 0.4611], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 1 - 37: cat - cat || Loss: 0.7734827399253845\n",
      "tensor([1., 0.]) tensor([0.5398, 0.4602], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 1 - 38: cat - cat || Loss: 0.772567093372345\n",
      "tensor([1., 0.]) tensor([0.5407, 0.4593], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 1 - 39: cat - cat || Loss: 0.7716480493545532\n",
      "tensor([1., 0.]) tensor([0.5416, 0.4584], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 1 - 40: cat - cat || Loss: 0.7707262635231018\n",
      "tensor([1., 0.]) tensor([0.5425, 0.4575], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 1 - 41: cat - cat || Loss: 0.7698017358779907\n",
      "tensor([1., 0.]) tensor([0.5435, 0.4565], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 1 - 42: cat - cat || Loss: 0.7688751220703125\n",
      "tensor([1., 0.]) tensor([0.5444, 0.4556], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 1 - 43: cat - cat || Loss: 0.7679461240768433\n",
      "tensor([1., 0.]) tensor([0.5453, 0.4547], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 1 - 44: cat - cat || Loss: 0.7670155763626099\n",
      "tensor([1., 0.]) tensor([0.5462, 0.4538], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 1 - 45: cat - cat || Loss: 0.7660831212997437\n",
      "tensor([1., 0.]) tensor([0.5472, 0.4528], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 1 - 46: cat - cat || Loss: 0.7651490569114685\n",
      "tensor([1., 0.]) tensor([0.5481, 0.4519], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 1 - 47: cat - cat || Loss: 0.7642138004302979\n",
      "tensor([1., 0.]) tensor([0.5490, 0.4510], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 1 - 48: cat - cat || Loss: 0.7632775902748108\n",
      "tensor([1., 0.]) tensor([0.5500, 0.4500], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 1 - 49: cat - cat || Loss: 0.7623400092124939\n",
      "tensor([1., 0.]) tensor([0.5509, 0.4491], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 1 - 50: cat - cat || Loss: 0.7614015936851501\n",
      "tensor([1., 0.]) tensor([0.5519, 0.4481], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 1 - 51: cat - cat || Loss: 0.7604623436927795\n",
      "tensor([1., 0.]) tensor([0.5528, 0.4472], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 1 - 52: cat - cat || Loss: 0.7595223188400269\n",
      "tensor([1., 0.]) tensor([0.5537, 0.4463], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 1 - 53: cat - cat || Loss: 0.7585816383361816\n",
      "tensor([1., 0.]) tensor([0.5547, 0.4453], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 1 - 54: cat - cat || Loss: 0.757640540599823\n",
      "tensor([1., 0.]) tensor([0.5556, 0.4444], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 1 - 55: cat - cat || Loss: 0.7566990256309509\n",
      "tensor([1., 0.]) tensor([0.5566, 0.4434], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 1 - 56: cat - cat || Loss: 0.7557570934295654\n",
      "tensor([1., 0.]) tensor([0.5575, 0.4425], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 1 - 57: cat - cat || Loss: 0.7548150420188904\n",
      "tensor([1., 0.]) tensor([0.5584, 0.4416], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 1 - 58: cat - cat || Loss: 0.7538726329803467\n",
      "tensor([1., 0.]) tensor([0.5594, 0.4406], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 1 - 59: cat - cat || Loss: 0.7529301643371582\n",
      "tensor([1., 0.]) tensor([0.5603, 0.4397], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 1 - 60: cat - cat || Loss: 0.7519872784614563\n",
      "tensor([1., 0.]) tensor([0.5613, 0.4387], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 1 - 61: cat - cat || Loss: 0.7510441541671753\n",
      "tensor([1., 0.]) tensor([0.5622, 0.4378], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 1 - 62: cat - cat || Loss: 0.7501007914543152\n",
      "tensor([1., 0.]) tensor([0.5632, 0.4368], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 1 - 63: cat - cat || Loss: 0.7491574883460999\n",
      "tensor([1., 0.]) tensor([0.5641, 0.4359], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 1 - 64: cat - cat || Loss: 0.7482141852378845\n",
      "tensor([1., 0.]) tensor([0.5650, 0.4350], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 1 - 65: cat - cat || Loss: 0.7472708225250244\n",
      "tensor([1., 0.]) tensor([0.5660, 0.4340], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 1 - 66: cat - cat || Loss: 0.7463273406028748\n",
      "tensor([1., 0.]) tensor([0.5669, 0.4331], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 1 - 67: cat - cat || Loss: 0.7453838586807251\n",
      "tensor([1., 0.]) tensor([0.5679, 0.4321], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 1 - 68: cat - cat || Loss: 0.7444402575492859\n",
      "tensor([1., 0.]) tensor([0.5688, 0.4312], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 1 - 69: cat - cat || Loss: 0.7434965372085571\n",
      "tensor([1., 0.]) tensor([0.5698, 0.4302], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 1 - 70: cat - cat || Loss: 0.7425529360771179\n",
      "tensor([1., 0.]) tensor([0.5707, 0.4293], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 1 - 71: cat - cat || Loss: 0.7416096925735474\n",
      "tensor([1., 0.]) tensor([0.5717, 0.4283], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 1 - 72: cat - cat || Loss: 0.7406665086746216\n",
      "tensor([1., 0.]) tensor([0.5726, 0.4274], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 1 - 73: cat - cat || Loss: 0.7397235631942749\n",
      "tensor([1., 0.]) tensor([0.5735, 0.4265], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 1 - 74: cat - cat || Loss: 0.7387806177139282\n",
      "tensor([1., 0.]) tensor([0.5745, 0.4255], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 1 - 75: cat - cat || Loss: 0.7378379702568054\n",
      "tensor([1., 0.]) tensor([0.5754, 0.4246], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 1 - 76: cat - cat || Loss: 0.7368953824043274\n",
      "tensor([1., 0.]) tensor([0.5764, 0.4236], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 1 - 77: cat - cat || Loss: 0.7359530925750732\n",
      "tensor([1., 0.]) tensor([0.5773, 0.4227], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 1 - 78: cat - cat || Loss: 0.7350109815597534\n",
      "tensor([1., 0.]) tensor([0.5783, 0.4217], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 1 - 79: cat - cat || Loss: 0.7340694665908813\n",
      "tensor([1., 0.]) tensor([0.5792, 0.4208], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 1 - 80: cat - cat || Loss: 0.7331281304359436\n",
      "tensor([1., 0.]) tensor([0.5801, 0.4199], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 1 - 81: cat - cat || Loss: 0.7321867942810059\n",
      "tensor([1., 0.]) tensor([0.5811, 0.4189], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 1 - 82: cat - cat || Loss: 0.7312458157539368\n",
      "tensor([1., 0.]) tensor([0.5820, 0.4180], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 1 - 83: cat - cat || Loss: 0.730305016040802\n",
      "tensor([1., 0.]) tensor([0.5830, 0.4170], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 1 - 84: cat - cat || Loss: 0.7293643951416016\n",
      "tensor([1., 0.]) tensor([0.5839, 0.4161], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 1 - 85: cat - cat || Loss: 0.7284240126609802\n",
      "tensor([1., 0.]) tensor([0.5848, 0.4152], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 1 - 86: cat - cat || Loss: 0.7274837493896484\n",
      "tensor([1., 0.]) tensor([0.5858, 0.4142], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 1 - 87: cat - cat || Loss: 0.7265434265136719\n",
      "tensor([1., 0.]) tensor([0.5867, 0.4133], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 1 - 88: cat - cat || Loss: 0.7256034016609192\n",
      "tensor([1., 0.]) tensor([0.5877, 0.4123], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 1 - 89: cat - cat || Loss: 0.7246637344360352\n",
      "tensor([1., 0.]) tensor([0.5886, 0.4114], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 1 - 90: cat - cat || Loss: 0.7237241864204407\n",
      "tensor([1., 0.]) tensor([0.5895, 0.4105], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 1 - 91: cat - cat || Loss: 0.7227850556373596\n",
      "tensor([1., 0.]) tensor([0.5905, 0.4095], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 1 - 92: cat - cat || Loss: 0.7218462228775024\n",
      "tensor([1., 0.]) tensor([0.5914, 0.4086], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 1 - 93: cat - cat || Loss: 0.7209079265594482\n",
      "tensor([1., 0.]) tensor([0.5924, 0.4076], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 1 - 94: cat - cat || Loss: 0.7199698686599731\n",
      "tensor([1., 0.]) tensor([0.5933, 0.4067], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 1 - 95: cat - cat || Loss: 0.7190321087837219\n",
      "tensor([1., 0.]) tensor([0.5942, 0.4058], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 1 - 96: cat - cat || Loss: 0.7180946469306946\n",
      "tensor([1., 0.]) tensor([0.5952, 0.4048], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 1 - 97: cat - cat || Loss: 0.717157244682312\n",
      "tensor([1., 0.]) tensor([0.5961, 0.4039], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 1 - 98: cat - cat || Loss: 0.7162202596664429\n",
      "tensor([1., 0.]) tensor([0.5970, 0.4030], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 1 - 99: cat - cat || Loss: 0.7152835726737976\n",
      "tensor([1., 0.]) tensor([0.5980, 0.4020], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 1 - 100: cat - cat || Loss: 0.7143469452857971\n",
      "tensor([1., 0.]) tensor([0.5989, 0.4011], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 1 - 101: cat - cat || Loss: 0.7134107947349548\n",
      "tensor([1., 0.]) tensor([0.5999, 0.4001], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 1 - 102: cat - cat || Loss: 0.7124748229980469\n",
      "tensor([1., 0.]) tensor([0.6008, 0.3992], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 1 - 103: cat - cat || Loss: 0.7115391492843628\n",
      "tensor([1., 0.]) tensor([0.6017, 0.3983], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 1 - 104: cat - cat || Loss: 0.7106035947799683\n",
      "tensor([1., 0.]) tensor([0.6027, 0.3973], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 1 - 105: cat - cat || Loss: 0.7096683382987976\n",
      "tensor([1., 0.]) tensor([0.6036, 0.3964], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 1 - 106: cat - cat || Loss: 0.708733320236206\n",
      "tensor([1., 0.]) tensor([0.6045, 0.3955], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 1 - 107: cat - cat || Loss: 0.7077984809875488\n",
      "tensor([1., 0.]) tensor([0.6055, 0.3945], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 1 - 108: cat - cat || Loss: 0.7068639993667603\n",
      "tensor([1., 0.]) tensor([0.6064, 0.3936], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 1 - 109: cat - cat || Loss: 0.7059296369552612\n",
      "tensor([1., 0.]) tensor([0.6073, 0.3927], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 1 - 110: cat - cat || Loss: 0.7049955725669861\n",
      "tensor([1., 0.]) tensor([0.6083, 0.3917], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 1 - 111: cat - cat || Loss: 0.70406174659729\n",
      "tensor([1., 0.]) tensor([0.6092, 0.3908], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 1 - 112: cat - cat || Loss: 0.7031283974647522\n",
      "tensor([1., 0.]) tensor([0.6101, 0.3899], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 1 - 113: cat - cat || Loss: 0.7021953463554382\n",
      "tensor([1., 0.]) tensor([0.6111, 0.3889], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 1 - 114: cat - cat || Loss: 0.7012627720832825\n",
      "tensor([1., 0.]) tensor([0.6120, 0.3880], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 1 - 115: cat - cat || Loss: 0.7003306150436401\n",
      "tensor([1., 0.]) tensor([0.6129, 0.3871], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 1 - 116: cat - cat || Loss: 0.6993987560272217\n",
      "tensor([1., 0.]) tensor([0.6139, 0.3861], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 1 - 117: cat - cat || Loss: 0.6984674334526062\n",
      "tensor([1., 0.]) tensor([0.6148, 0.3852], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 1 - 118: cat - cat || Loss: 0.6975361108779907\n",
      "tensor([1., 0.]) tensor([0.6157, 0.3843], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 1 - 119: cat - cat || Loss: 0.6966053247451782\n",
      "tensor([1., 0.]) tensor([0.6167, 0.3833], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 1 - 120: cat - cat || Loss: 0.6956747770309448\n",
      "tensor([1., 0.]) tensor([0.6176, 0.3824], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 1 - 121: cat - cat || Loss: 0.694744348526001\n",
      "tensor([1., 0.]) tensor([0.6185, 0.3815], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 1 - 122: cat - cat || Loss: 0.6938142776489258\n",
      "tensor([1., 0.]) tensor([0.6194, 0.3806], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 1 - 123: cat - cat || Loss: 0.6928844451904297\n",
      "tensor([1., 0.]) tensor([0.6204, 0.3796], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 1 - 124: cat - cat || Loss: 0.6919549703598022\n",
      "tensor([1., 0.]) tensor([0.6213, 0.3787], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 1 - 125: cat - cat || Loss: 0.6910259127616882\n",
      "tensor([1., 0.]) tensor([0.6222, 0.3778], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 1 - 126: cat - cat || Loss: 0.6900968551635742\n",
      "tensor([1., 0.]) tensor([0.6232, 0.3768], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 1 - 127: cat - cat || Loss: 0.6891681551933289\n",
      "tensor([1., 0.]) tensor([0.6241, 0.3759], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 1 - 128: cat - cat || Loss: 0.6882399320602417\n",
      "tensor([1., 0.]) tensor([0.6250, 0.3750], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 1 - 129: cat - cat || Loss: 0.6873119473457336\n",
      "tensor([1., 0.]) tensor([0.6259, 0.3741], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 1 - 130: cat - cat || Loss: 0.6863844394683838\n",
      "tensor([1., 0.]) tensor([0.6269, 0.3731], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 1 - 131: cat - cat || Loss: 0.6854571104049683\n",
      "tensor([1., 0.]) tensor([0.6278, 0.3722], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 1 - 132: cat - cat || Loss: 0.6845300793647766\n",
      "tensor([1., 0.]) tensor([0.6287, 0.3713], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 1 - 133: cat - cat || Loss: 0.6836034655570984\n",
      "tensor([1., 0.]) tensor([0.6297, 0.3703], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 1 - 134: cat - cat || Loss: 0.682677149772644\n",
      "tensor([1., 0.]) tensor([0.6306, 0.3694], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 1 - 135: cat - cat || Loss: 0.6817511320114136\n",
      "tensor([1., 0.]) tensor([0.6315, 0.3685], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 1 - 136: cat - cat || Loss: 0.6808255910873413\n",
      "tensor([1., 0.]) tensor([0.6324, 0.3676], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 1 - 137: cat - cat || Loss: 0.6799001693725586\n",
      "tensor([1., 0.]) tensor([0.6334, 0.3666], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 1 - 138: cat - cat || Loss: 0.6789751052856445\n",
      "tensor([1., 0.]) tensor([0.6343, 0.3657], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 1 - 139: cat - cat || Loss: 0.6780505180358887\n",
      "tensor([1., 0.]) tensor([0.6352, 0.3648], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 1 - 140: cat - cat || Loss: 0.6771262884140015\n",
      "tensor([1., 0.]) tensor([0.6361, 0.3639], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 1 - 141: cat - cat || Loss: 0.6762025356292725\n",
      "tensor([1., 0.]) tensor([0.6371, 0.3629], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 1 - 142: cat - cat || Loss: 0.6752788424491882\n",
      "tensor([1., 0.]) tensor([0.6380, 0.3620], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 1 - 143: cat - cat || Loss: 0.6743555068969727\n",
      "tensor([1., 0.]) tensor([0.6389, 0.3611], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 1 - 144: cat - cat || Loss: 0.6734327077865601\n",
      "tensor([1., 0.]) tensor([0.6398, 0.3602], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 1 - 145: cat - cat || Loss: 0.6725101470947266\n",
      "tensor([1., 0.]) tensor([0.6408, 0.3592], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 1 - 146: cat - cat || Loss: 0.671588122844696\n",
      "tensor([1., 0.]) tensor([0.6417, 0.3583], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 1 - 147: cat - cat || Loss: 0.6706663966178894\n",
      "tensor([1., 0.]) tensor([0.6426, 0.3574], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 1 - 148: cat - cat || Loss: 0.6697448492050171\n",
      "tensor([1., 0.]) tensor([0.6435, 0.3565], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 1 - 149: cat - cat || Loss: 0.668823778629303\n",
      "tensor([1., 0.]) tensor([0.6444, 0.3556], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 1 - 150: cat - cat || Loss: 0.6679028272628784\n",
      "tensor([1., 0.]) tensor([0.6454, 0.3546], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 1 - 151: cat - cat || Loss: 0.6669826507568359\n",
      "tensor([1., 0.]) tensor([0.6463, 0.3537], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 1 - 152: cat - cat || Loss: 0.6660626530647278\n",
      "tensor([1., 0.]) tensor([0.6472, 0.3528], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 1 - 153: cat - cat || Loss: 0.6651430130004883\n",
      "tensor([1., 0.]) tensor([0.6481, 0.3519], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 1 - 154: cat - cat || Loss: 0.6642236709594727\n",
      "tensor([1., 0.]) tensor([0.6490, 0.3510], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 1 - 155: cat - cat || Loss: 0.6633045673370361\n",
      "tensor([1., 0.]) tensor([0.6500, 0.3500], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 1 - 156: cat - cat || Loss: 0.6623860001564026\n",
      "tensor([1., 0.]) tensor([0.6509, 0.3491], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 1 - 157: cat - cat || Loss: 0.661467432975769\n",
      "tensor([1., 0.]) tensor([0.6518, 0.3482], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 1 - 158: cat - cat || Loss: 0.6605493426322937\n",
      "tensor([1., 0.]) tensor([0.6527, 0.3473], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 1 - 159: cat - cat || Loss: 0.659631609916687\n",
      "tensor([1., 0.]) tensor([0.6536, 0.3464], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 1 - 160: cat - cat || Loss: 0.6587141752243042\n",
      "tensor([1., 0.]) tensor([0.6545, 0.3455], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 1 - 161: cat - cat || Loss: 0.6577968597412109\n",
      "tensor([1., 0.]) tensor([0.6555, 0.3445], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 1 - 162: cat - cat || Loss: 0.656880259513855\n",
      "tensor([1., 0.]) tensor([0.6564, 0.3436], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 1 - 163: cat - cat || Loss: 0.6559637784957886\n",
      "tensor([1., 0.]) tensor([0.6573, 0.3427], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 1 - 164: cat - cat || Loss: 0.6550480127334595\n",
      "tensor([1., 0.]) tensor([0.6582, 0.3418], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 1 - 165: cat - cat || Loss: 0.6541323661804199\n",
      "tensor([1., 0.]) tensor([0.6591, 0.3409], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 1 - 166: cat - cat || Loss: 0.653217077255249\n",
      "tensor([1., 0.]) tensor([0.6600, 0.3400], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 1 - 167: cat - cat || Loss: 0.6523022055625916\n",
      "tensor([1., 0.]) tensor([0.6610, 0.3390], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 1 - 168: cat - cat || Loss: 0.6513878107070923\n",
      "tensor([1., 0.]) tensor([0.6619, 0.3381], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 1 - 169: cat - cat || Loss: 0.6504736542701721\n",
      "tensor([1., 0.]) tensor([0.6628, 0.3372], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 1 - 170: cat - cat || Loss: 0.6495597958564758\n",
      "tensor([1., 0.]) tensor([0.6637, 0.3363], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 1 - 171: cat - cat || Loss: 0.6486464738845825\n",
      "tensor([1., 0.]) tensor([0.6646, 0.3354], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 1 - 172: cat - cat || Loss: 0.6477332711219788\n",
      "tensor([1., 0.]) tensor([0.6655, 0.3345], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 1 - 173: cat - cat || Loss: 0.6468206644058228\n",
      "tensor([1., 0.]) tensor([0.6664, 0.3336], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 1 - 174: cat - cat || Loss: 0.6459082365036011\n",
      "tensor([1., 0.]) tensor([0.6674, 0.3326], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 1 - 175: cat - cat || Loss: 0.6449961066246033\n",
      "tensor([1., 0.]) tensor([0.6683, 0.3317], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 1 - 176: cat - cat || Loss: 0.6440843343734741\n",
      "tensor([1., 0.]) tensor([0.6692, 0.3308], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 1 - 177: cat - cat || Loss: 0.6431730389595032\n",
      "tensor([1., 0.]) tensor([0.6701, 0.3299], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 1 - 178: cat - cat || Loss: 0.6422621011734009\n",
      "tensor([1., 0.]) tensor([0.6710, 0.3290], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 1 - 179: cat - cat || Loss: 0.641351580619812\n",
      "tensor([1., 0.]) tensor([0.6719, 0.3281], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 1 - 180: cat - cat || Loss: 0.6404415965080261\n",
      "tensor([1., 0.]) tensor([0.6728, 0.3272], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 1 - 181: cat - cat || Loss: 0.6395319104194641\n",
      "tensor([1., 0.]) tensor([0.6737, 0.3263], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 1 - 182: cat - cat || Loss: 0.638622522354126\n",
      "tensor([1., 0.]) tensor([0.6746, 0.3254], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 1 - 183: cat - cat || Loss: 0.6377135515213013\n",
      "tensor([1., 0.]) tensor([0.6755, 0.3245], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 1 - 184: cat - cat || Loss: 0.6368046998977661\n",
      "tensor([1., 0.]) tensor([0.6765, 0.3235], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 1 - 185: cat - cat || Loss: 0.6358965635299683\n",
      "tensor([1., 0.]) tensor([0.6774, 0.3226], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 1 - 186: cat - cat || Loss: 0.6349889039993286\n",
      "tensor([1., 0.]) tensor([0.6783, 0.3217], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 1 - 187: cat - cat || Loss: 0.6340821981430054\n",
      "tensor([1., 0.]) tensor([0.6792, 0.3208], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 1 - 188: cat - cat || Loss: 0.6331759095191956\n",
      "tensor([1., 0.]) tensor([0.6801, 0.3199], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 1 - 189: cat - cat || Loss: 0.632270097732544\n",
      "tensor([1., 0.]) tensor([0.6810, 0.3190], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 1 - 190: dog - cat || Loss: 0.9951585531234741\n",
      "tensor([0., 1.]) tensor([0.6819, 0.3181], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 1 - 191: dog - cat || Loss: 0.9958828091621399\n",
      "tensor([0., 1.]) tensor([0.6826, 0.3174], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 1 - 192: dog - cat || Loss: 0.9964439868927002\n",
      "tensor([0., 1.]) tensor([0.6832, 0.3168], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 1 - 193: dog - cat || Loss: 0.9968585968017578\n",
      "tensor([0., 1.]) tensor([0.6836, 0.3164], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 1 - 194: dog - cat || Loss: 0.9971410036087036\n",
      "tensor([0., 1.]) tensor([0.6839, 0.3161], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 1 - 195: dog - cat || Loss: 0.9973050355911255\n",
      "tensor([0., 1.]) tensor([0.6840, 0.3160], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 1 - 196: dog - cat || Loss: 0.9973622560501099\n",
      "tensor([0., 1.]) tensor([0.6841, 0.3159], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 1 - 197: dog - cat || Loss: 0.9973231554031372\n",
      "tensor([0., 1.]) tensor([0.6841, 0.3159], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 1 - 198: dog - cat || Loss: 0.9971979260444641\n",
      "tensor([0., 1.]) tensor([0.6839, 0.3161], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 1 - 199: dog - cat || Loss: 0.9969949126243591\n",
      "tensor([0., 1.]) tensor([0.6837, 0.3163], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 1 - 200: dog - cat || Loss: 0.9967218637466431\n",
      "tensor([0., 1.]) tensor([0.6835, 0.3165], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 1 - 201: dog - cat || Loss: 0.9963858127593994\n",
      "tensor([0., 1.]) tensor([0.6831, 0.3169], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 1 - 202: dog - cat || Loss: 0.9959932565689087\n",
      "tensor([0., 1.]) tensor([0.6827, 0.3173], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 1 - 203: dog - cat || Loss: 0.9955493807792664\n",
      "tensor([0., 1.]) tensor([0.6823, 0.3177], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 1 - 204: dog - cat || Loss: 0.995059609413147\n",
      "tensor([0., 1.]) tensor([0.6818, 0.3182], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 1 - 205: dog - cat || Loss: 0.9945282340049744\n",
      "tensor([0., 1.]) tensor([0.6813, 0.3187], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 1 - 206: dog - cat || Loss: 0.9939597249031067\n",
      "tensor([0., 1.]) tensor([0.6807, 0.3193], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 1 - 207: dog - cat || Loss: 0.99335777759552\n",
      "tensor([0., 1.]) tensor([0.6801, 0.3199], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 1 - 208: dog - cat || Loss: 0.9927253127098083\n",
      "tensor([0., 1.]) tensor([0.6795, 0.3205], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 1 - 209: dog - cat || Loss: 0.9920659065246582\n",
      "tensor([0., 1.]) tensor([0.6788, 0.3212], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 1 - 210: dog - cat || Loss: 0.9913817048072815\n",
      "tensor([0., 1.]) tensor([0.6781, 0.3219], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 1 - 211: dog - cat || Loss: 0.9906759262084961\n",
      "tensor([0., 1.]) tensor([0.6774, 0.3226], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 1 - 212: dog - cat || Loss: 0.9899497032165527\n",
      "tensor([0., 1.]) tensor([0.6767, 0.3233], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 1 - 213: dog - cat || Loss: 0.9892059564590454\n",
      "tensor([0., 1.]) tensor([0.6759, 0.3241], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 1 - 214: dog - cat || Loss: 0.9884457588195801\n",
      "tensor([0., 1.]) tensor([0.6752, 0.3248], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 1 - 215: dog - cat || Loss: 0.9876710176467896\n",
      "tensor([0., 1.]) tensor([0.6744, 0.3256], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 1 - 216: dog - cat || Loss: 0.9868832230567932\n",
      "tensor([0., 1.]) tensor([0.6736, 0.3264], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 1 - 217: dog - cat || Loss: 0.9860833287239075\n",
      "tensor([0., 1.]) tensor([0.6728, 0.3272], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 1 - 218: dog - cat || Loss: 0.9852730631828308\n",
      "tensor([0., 1.]) tensor([0.6720, 0.3280], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 1 - 219: dog - cat || Loss: 0.9844529628753662\n",
      "tensor([0., 1.]) tensor([0.6712, 0.3288], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 1 - 220: dog - cat || Loss: 0.9836241006851196\n",
      "tensor([0., 1.]) tensor([0.6704, 0.3296], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 1 - 221: dog - cat || Loss: 0.9827873110771179\n",
      "tensor([0., 1.]) tensor([0.6695, 0.3305], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 1 - 222: dog - cat || Loss: 0.9819434285163879\n",
      "tensor([0., 1.]) tensor([0.6687, 0.3313], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 1 - 223: dog - cat || Loss: 0.9810933470726013\n",
      "tensor([0., 1.]) tensor([0.6678, 0.3322], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 1 - 224: dog - cat || Loss: 0.9802373051643372\n",
      "tensor([0., 1.]) tensor([0.6670, 0.3330], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 1 - 225: dog - cat || Loss: 0.9793763160705566\n",
      "tensor([0., 1.]) tensor([0.6661, 0.3339], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 1 - 226: dog - cat || Loss: 0.978510320186615\n",
      "tensor([0., 1.]) tensor([0.6652, 0.3348], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 1 - 227: dog - cat || Loss: 0.9776402711868286\n",
      "tensor([0., 1.]) tensor([0.6644, 0.3356], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 1 - 228: dog - cat || Loss: 0.9767661690711975\n",
      "tensor([0., 1.]) tensor([0.6635, 0.3365], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 1 - 229: dog - cat || Loss: 0.9758884906768799\n",
      "tensor([0., 1.]) tensor([0.6626, 0.3374], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 1 - 230: dog - cat || Loss: 0.9750075936317444\n",
      "tensor([0., 1.]) tensor([0.6617, 0.3383], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 1 - 231: dog - cat || Loss: 0.9741238951683044\n",
      "tensor([0., 1.]) tensor([0.6609, 0.3391], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 1 - 232: dog - cat || Loss: 0.9732373952865601\n",
      "tensor([0., 1.]) tensor([0.6600, 0.3400], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 1 - 233: dog - cat || Loss: 0.9723486304283142\n",
      "tensor([0., 1.]) tensor([0.6591, 0.3409], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 1 - 234: dog - cat || Loss: 0.9714577794075012\n",
      "tensor([0., 1.]) tensor([0.6582, 0.3418], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 1 - 235: dog - cat || Loss: 0.9705650806427002\n",
      "tensor([0., 1.]) tensor([0.6573, 0.3427], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 1 - 236: dog - cat || Loss: 0.9696704745292664\n",
      "tensor([0., 1.]) tensor([0.6564, 0.3436], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 1 - 237: dog - cat || Loss: 0.9687742590904236\n",
      "tensor([0., 1.]) tensor([0.6555, 0.3445], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 1 - 238: dog - cat || Loss: 0.9678767919540405\n",
      "tensor([0., 1.]) tensor([0.6546, 0.3454], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 1 - 239: dog - cat || Loss: 0.9669779539108276\n",
      "tensor([0., 1.]) tensor([0.6537, 0.3463], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 1 - 240: dog - cat || Loss: 0.9660779237747192\n",
      "tensor([0., 1.]) tensor([0.6528, 0.3472], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 1 - 241: dog - cat || Loss: 0.9651766419410706\n",
      "tensor([0., 1.]) tensor([0.6519, 0.3481], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 1 - 242: dog - cat || Loss: 0.9642742872238159\n",
      "tensor([0., 1.]) tensor([0.6510, 0.3490], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 1 - 243: dog - cat || Loss: 0.9633708000183105\n",
      "tensor([0., 1.]) tensor([0.6501, 0.3499], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 1 - 244: dog - cat || Loss: 0.9624665379524231\n",
      "tensor([0., 1.]) tensor([0.6492, 0.3508], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 1 - 245: dog - cat || Loss: 0.9615613222122192\n",
      "tensor([0., 1.]) tensor([0.6483, 0.3517], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 1 - 246: dog - cat || Loss: 0.9606552124023438\n",
      "tensor([0., 1.]) tensor([0.6474, 0.3526], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 1 - 247: dog - cat || Loss: 0.959748387336731\n",
      "tensor([0., 1.]) tensor([0.6465, 0.3535], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 1 - 248: dog - cat || Loss: 0.9588409066200256\n",
      "tensor([0., 1.]) tensor([0.6456, 0.3544], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 1 - 249: dog - cat || Loss: 0.9579324126243591\n",
      "tensor([0., 1.]) tensor([0.6447, 0.3553], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 1 - 250: dog - cat || Loss: 0.9570237398147583\n",
      "tensor([0., 1.]) tensor([0.6438, 0.3562], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 1 - 251: dog - cat || Loss: 0.9561142325401306\n",
      "tensor([0., 1.]) tensor([0.6429, 0.3571], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 1 - 252: dog - cat || Loss: 0.9552042484283447\n",
      "tensor([0., 1.]) tensor([0.6419, 0.3581], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 1 - 253: dog - cat || Loss: 0.9542936682701111\n",
      "tensor([0., 1.]) tensor([0.6410, 0.3590], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 1 - 254: dog - cat || Loss: 0.953382670879364\n",
      "tensor([0., 1.]) tensor([0.6401, 0.3599], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 1 - 255: dog - cat || Loss: 0.9524713158607483\n",
      "tensor([0., 1.]) tensor([0.6392, 0.3608], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 1 - 256: dog - cat || Loss: 0.9515594840049744\n",
      "tensor([0., 1.]) tensor([0.6383, 0.3617], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 1 - 257: dog - cat || Loss: 0.9506474733352661\n",
      "tensor([0., 1.]) tensor([0.6374, 0.3626], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 1 - 258: dog - cat || Loss: 0.9497349858283997\n",
      "tensor([0., 1.]) tensor([0.6365, 0.3635], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 1 - 259: dog - cat || Loss: 0.9488222002983093\n",
      "tensor([0., 1.]) tensor([0.6356, 0.3644], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 1 - 260: dog - cat || Loss: 0.9479089379310608\n",
      "tensor([0., 1.]) tensor([0.6346, 0.3654], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 1 - 261: dog - cat || Loss: 0.9469955563545227\n",
      "tensor([0., 1.]) tensor([0.6337, 0.3663], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 1 - 262: dog - cat || Loss: 0.9460818767547607\n",
      "tensor([0., 1.]) tensor([0.6328, 0.3672], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 1 - 263: dog - cat || Loss: 0.9451677203178406\n",
      "tensor([0., 1.]) tensor([0.6319, 0.3681], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 1 - 264: dog - cat || Loss: 0.9442534446716309\n",
      "tensor([0., 1.]) tensor([0.6310, 0.3690], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 1 - 265: dog - cat || Loss: 0.9433385729789734\n",
      "tensor([0., 1.]) tensor([0.6301, 0.3699], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 1 - 266: dog - cat || Loss: 0.9424235224723816\n",
      "tensor([0., 1.]) tensor([0.6292, 0.3708], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 1 - 267: dog - cat || Loss: 0.9415085315704346\n",
      "tensor([0., 1.]) tensor([0.6282, 0.3718], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 1 - 268: dog - cat || Loss: 0.9405929446220398\n",
      "tensor([0., 1.]) tensor([0.6273, 0.3727], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 1 - 269: dog - cat || Loss: 0.939677357673645\n",
      "tensor([0., 1.]) tensor([0.6264, 0.3736], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 1 - 270: dog - cat || Loss: 0.9387612342834473\n",
      "tensor([0., 1.]) tensor([0.6255, 0.3745], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 1 - 271: dog - cat || Loss: 0.9378450512886047\n",
      "tensor([0., 1.]) tensor([0.6246, 0.3754], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 1 - 272: dog - cat || Loss: 0.9369283318519592\n",
      "tensor([0., 1.]) tensor([0.6237, 0.3763], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 1 - 273: dog - cat || Loss: 0.9360116124153137\n",
      "tensor([0., 1.]) tensor([0.6227, 0.3773], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 1 - 274: dog - cat || Loss: 0.9350946545600891\n",
      "tensor([0., 1.]) tensor([0.6218, 0.3782], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 1 - 275: dog - cat || Loss: 0.9341774582862854\n",
      "tensor([0., 1.]) tensor([0.6209, 0.3791], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 1 - 276: dog - cat || Loss: 0.9332601428031921\n",
      "tensor([0., 1.]) tensor([0.6200, 0.3800], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 1 - 277: dog - cat || Loss: 0.9323426485061646\n",
      "tensor([0., 1.]) tensor([0.6191, 0.3809], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 1 - 278: dog - cat || Loss: 0.931425154209137\n",
      "tensor([0., 1.]) tensor([0.6182, 0.3818], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 1 - 279: dog - cat || Loss: 0.9305071234703064\n",
      "tensor([0., 1.]) tensor([0.6172, 0.3828], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 1 - 280: dog - cat || Loss: 0.9295889735221863\n",
      "tensor([0., 1.]) tensor([0.6163, 0.3837], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 1 - 281: dog - cat || Loss: 0.9286707639694214\n",
      "tensor([0., 1.]) tensor([0.6154, 0.3846], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 1 - 282: dog - cat || Loss: 0.9277523159980774\n",
      "tensor([0., 1.]) tensor([0.6145, 0.3855], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 1 - 283: dog - cat || Loss: 0.9268333911895752\n",
      "tensor([0., 1.]) tensor([0.6136, 0.3864], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 1 - 284: dog - cat || Loss: 0.9259143471717834\n",
      "tensor([0., 1.]) tensor([0.6127, 0.3873], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 1 - 285: dog - cat || Loss: 0.9249953031539917\n",
      "tensor([0., 1.]) tensor([0.6117, 0.3883], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 1 - 286: dog - cat || Loss: 0.9240759015083313\n",
      "tensor([0., 1.]) tensor([0.6108, 0.3892], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 1 - 287: dog - cat || Loss: 0.9231563806533813\n",
      "tensor([0., 1.]) tensor([0.6099, 0.3901], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 1 - 288: dog - cat || Loss: 0.9222367405891418\n",
      "tensor([0., 1.]) tensor([0.6090, 0.3910], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 1 - 289: dog - cat || Loss: 0.9213166832923889\n",
      "tensor([0., 1.]) tensor([0.6081, 0.3919], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 1 - 290: dog - cat || Loss: 0.9203966856002808\n",
      "tensor([0., 1.]) tensor([0.6071, 0.3929], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 1 - 291: dog - cat || Loss: 0.9194764494895935\n",
      "tensor([0., 1.]) tensor([0.6062, 0.3938], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 1 - 292: dog - cat || Loss: 0.9185561537742615\n",
      "tensor([0., 1.]) tensor([0.6053, 0.3947], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 1 - 293: dog - cat || Loss: 0.9176357984542847\n",
      "tensor([0., 1.]) tensor([0.6044, 0.3956], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 1 - 294: dog - cat || Loss: 0.9167150259017944\n",
      "tensor([0., 1.]) tensor([0.6035, 0.3965], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 1 - 295: dog - cat || Loss: 0.9157942533493042\n",
      "tensor([0., 1.]) tensor([0.6025, 0.3975], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 1 - 296: dog - cat || Loss: 0.9148732423782349\n",
      "tensor([0., 1.]) tensor([0.6016, 0.3984], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 1 - 297: dog - cat || Loss: 0.9139519929885864\n",
      "tensor([0., 1.]) tensor([0.6007, 0.3993], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 1 - 298: dog - cat || Loss: 0.9130305647850037\n",
      "tensor([0., 1.]) tensor([0.5998, 0.4002], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 1 - 299: dog - cat || Loss: 0.9121090173721313\n",
      "tensor([0., 1.]) tensor([0.5988, 0.4012], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 1 - 300: dog - cat || Loss: 0.9111871719360352\n",
      "tensor([0., 1.]) tensor([0.5979, 0.4021], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 1 - 301: dog - cat || Loss: 0.9102650880813599\n",
      "tensor([0., 1.]) tensor([0.5970, 0.4030], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 1 - 302: dog - cat || Loss: 0.9093430042266846\n",
      "tensor([0., 1.]) tensor([0.5961, 0.4039], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 1 - 303: dog - cat || Loss: 0.9084203243255615\n",
      "tensor([0., 1.]) tensor([0.5952, 0.4048], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 1 - 304: dog - cat || Loss: 0.9074976444244385\n",
      "tensor([0., 1.]) tensor([0.5942, 0.4058], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 1 - 305: dog - cat || Loss: 0.9065746068954468\n",
      "tensor([0., 1.]) tensor([0.5933, 0.4067], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 1 - 306: dog - cat || Loss: 0.9056515693664551\n",
      "tensor([0., 1.]) tensor([0.5924, 0.4076], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 1 - 307: dog - cat || Loss: 0.9047284126281738\n",
      "tensor([0., 1.]) tensor([0.5915, 0.4085], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 1 - 308: dog - cat || Loss: 0.9038050174713135\n",
      "tensor([0., 1.]) tensor([0.5905, 0.4095], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 1 - 309: dog - cat || Loss: 0.902881383895874\n",
      "tensor([0., 1.]) tensor([0.5896, 0.4104], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 1 - 310: dog - cat || Loss: 0.9019574522972107\n",
      "tensor([0., 1.]) tensor([0.5887, 0.4113], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 1 - 311: dog - cat || Loss: 0.9010335803031921\n",
      "tensor([0., 1.]) tensor([0.5878, 0.4122], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 1 - 312: dog - cat || Loss: 0.9001095294952393\n",
      "tensor([0., 1.]) tensor([0.5868, 0.4132], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 1 - 313: dog - cat || Loss: 0.8991854190826416\n",
      "tensor([0., 1.]) tensor([0.5859, 0.4141], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 1 - 314: dog - cat || Loss: 0.8982612490653992\n",
      "tensor([0., 1.]) tensor([0.5850, 0.4150], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 1 - 315: dog - cat || Loss: 0.8973369002342224\n",
      "tensor([0., 1.]) tensor([0.5841, 0.4159], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 1 - 316: dog - cat || Loss: 0.8964125514030457\n",
      "tensor([0., 1.]) tensor([0.5832, 0.4168], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 1 - 317: dog - cat || Loss: 0.8954880237579346\n",
      "tensor([0., 1.]) tensor([0.5822, 0.4178], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 1 - 318: dog - cat || Loss: 0.8945631384849548\n",
      "tensor([0., 1.]) tensor([0.5813, 0.4187], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 1 - 319: dog - cat || Loss: 0.8936383128166199\n",
      "tensor([0., 1.]) tensor([0.5804, 0.4196], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 1 - 320: dog - cat || Loss: 0.8927133679389954\n",
      "tensor([0., 1.]) tensor([0.5795, 0.4205], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 1 - 321: dog - cat || Loss: 0.891788125038147\n",
      "tensor([0., 1.]) tensor([0.5785, 0.4215], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 1 - 322: dog - cat || Loss: 0.8908628225326538\n",
      "tensor([0., 1.]) tensor([0.5776, 0.4224], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 1 - 323: dog - cat || Loss: 0.889937162399292\n",
      "tensor([0., 1.]) tensor([0.5767, 0.4233], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 1 - 324: dog - cat || Loss: 0.8890113830566406\n",
      "tensor([0., 1.]) tensor([0.5757, 0.4243], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 1 - 325: dog - cat || Loss: 0.8880853652954102\n",
      "tensor([0., 1.]) tensor([0.5748, 0.4252], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 1 - 326: dog - cat || Loss: 0.8871591687202454\n",
      "tensor([0., 1.]) tensor([0.5739, 0.4261], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 1 - 327: dog - cat || Loss: 0.8862326741218567\n",
      "tensor([0., 1.]) tensor([0.5730, 0.4270], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 1 - 328: dog - cat || Loss: 0.8853061199188232\n",
      "tensor([0., 1.]) tensor([0.5720, 0.4280], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 1 - 329: dog - cat || Loss: 0.8843792676925659\n",
      "tensor([0., 1.]) tensor([0.5711, 0.4289], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 1 - 330: dog - cat || Loss: 0.8834524154663086\n",
      "tensor([0., 1.]) tensor([0.5702, 0.4298], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 1 - 331: dog - cat || Loss: 0.8825253248214722\n",
      "tensor([0., 1.]) tensor([0.5693, 0.4307], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 1 - 332: dog - cat || Loss: 0.8815980553627014\n",
      "tensor([0., 1.]) tensor([0.5683, 0.4317], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 1 - 333: dog - cat || Loss: 0.8806706666946411\n",
      "tensor([0., 1.]) tensor([0.5674, 0.4326], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 1 - 334: dog - cat || Loss: 0.8797431588172913\n",
      "tensor([0., 1.]) tensor([0.5665, 0.4335], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 1 - 335: dog - cat || Loss: 0.8788155317306519\n",
      "tensor([0., 1.]) tensor([0.5656, 0.4344], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 1 - 336: dog - cat || Loss: 0.8778878450393677\n",
      "tensor([0., 1.]) tensor([0.5646, 0.4354], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 1 - 337: dog - cat || Loss: 0.876960039138794\n",
      "tensor([0., 1.]) tensor([0.5637, 0.4363], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 1 - 338: dog - cat || Loss: 0.8760320544242859\n",
      "tensor([0., 1.]) tensor([0.5628, 0.4372], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 1 - 339: dog - cat || Loss: 0.8751041293144226\n",
      "tensor([0., 1.]) tensor([0.5618, 0.4382], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 1 - 340: dog - cat || Loss: 0.8741758465766907\n",
      "tensor([0., 1.]) tensor([0.5609, 0.4391], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 1 - 341: dog - cat || Loss: 0.8732473254203796\n",
      "tensor([0., 1.]) tensor([0.5600, 0.4400], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 1 - 342: dog - cat || Loss: 0.8723189830780029\n",
      "tensor([0., 1.]) tensor([0.5591, 0.4409], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 1 - 343: dog - cat || Loss: 0.8713904619216919\n",
      "tensor([0., 1.]) tensor([0.5581, 0.4419], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 1 - 344: dog - cat || Loss: 0.8704619407653809\n",
      "tensor([0., 1.]) tensor([0.5572, 0.4428], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 1 - 345: dog - cat || Loss: 0.8695331811904907\n",
      "tensor([0., 1.]) tensor([0.5563, 0.4437], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 1 - 346: dog - cat || Loss: 0.8686044216156006\n",
      "tensor([0., 1.]) tensor([0.5553, 0.4447], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 1 - 347: dog - cat || Loss: 0.8676757216453552\n",
      "tensor([0., 1.]) tensor([0.5544, 0.4456], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 1 - 348: dog - cat || Loss: 0.866746723651886\n",
      "tensor([0., 1.]) tensor([0.5535, 0.4465], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 1 - 349: dog - cat || Loss: 0.8658179044723511\n",
      "tensor([0., 1.]) tensor([0.5526, 0.4474], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 1 - 350: dog - cat || Loss: 0.8648888468742371\n",
      "tensor([0., 1.]) tensor([0.5516, 0.4484], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 1 - 351: dog - cat || Loss: 0.863959789276123\n",
      "tensor([0., 1.]) tensor([0.5507, 0.4493], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 1 - 352: dog - cat || Loss: 0.863030731678009\n",
      "tensor([0., 1.]) tensor([0.5498, 0.4502], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 1 - 353: dog - cat || Loss: 0.8621013760566711\n",
      "tensor([0., 1.]) tensor([0.5488, 0.4512], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 1 - 354: dog - cat || Loss: 0.8611719608306885\n",
      "tensor([0., 1.]) tensor([0.5479, 0.4521], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 1 - 355: dog - cat || Loss: 0.8602426052093506\n",
      "tensor([0., 1.]) tensor([0.5470, 0.4530], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 1 - 356: dog - cat || Loss: 0.8593130111694336\n",
      "tensor([0., 1.]) tensor([0.5461, 0.4539], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 1 - 357: dog - cat || Loss: 0.8583832383155823\n",
      "tensor([0., 1.]) tensor([0.5451, 0.4549], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 1 - 358: dog - cat || Loss: 0.857453465461731\n",
      "tensor([0., 1.]) tensor([0.5442, 0.4558], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 1 - 359: dog - cat || Loss: 0.8565236330032349\n",
      "tensor([0., 1.]) tensor([0.5433, 0.4567], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 1 - 360: dog - cat || Loss: 0.8555936217308044\n",
      "tensor([0., 1.]) tensor([0.5423, 0.4577], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 1 - 361: dog - cat || Loss: 0.8546636700630188\n",
      "tensor([0., 1.]) tensor([0.5414, 0.4586], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 1 - 362: dog - cat || Loss: 0.8537334203720093\n",
      "tensor([0., 1.]) tensor([0.5405, 0.4595], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 1 - 363: dog - cat || Loss: 0.8528031706809998\n",
      "tensor([0., 1.]) tensor([0.5395, 0.4605], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 1 - 364: dog - cat || Loss: 0.8518726825714111\n",
      "tensor([0., 1.]) tensor([0.5386, 0.4614], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 1 - 365: dog - cat || Loss: 0.8509422540664673\n",
      "tensor([0., 1.]) tensor([0.5377, 0.4623], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 1 - 366: dog - cat || Loss: 0.8500117063522339\n",
      "tensor([0., 1.]) tensor([0.5368, 0.4632], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 1 - 367: dog - cat || Loss: 0.8490811586380005\n",
      "tensor([0., 1.]) tensor([0.5358, 0.4642], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 1 - 368: dog - cat || Loss: 0.8481506109237671\n",
      "tensor([0., 1.]) tensor([0.5349, 0.4651], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 1 - 369: dog - cat || Loss: 0.847219705581665\n",
      "tensor([0., 1.]) tensor([0.5340, 0.4660], grad_fn=<SoftmaxBackward0>)\n",
      "=====epoch:2=====\n",
      "Epoch 2 - 0: cat - cat || Loss: 0.7802343964576721\n",
      "tensor([1., 0.]) tensor([0.5330, 0.4670], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 2 - 1: cat - cat || Loss: 0.7809789180755615\n",
      "tensor([1., 0.]) tensor([0.5323, 0.4677], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 2 - 2: cat - cat || Loss: 0.7815558910369873\n",
      "tensor([1., 0.]) tensor([0.5317, 0.4683], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 2 - 3: cat - cat || Loss: 0.781981885433197\n",
      "tensor([1., 0.]) tensor([0.5313, 0.4687], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 2 - 4: cat - cat || Loss: 0.7822719812393188\n",
      "tensor([1., 0.]) tensor([0.5310, 0.4690], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 2 - 5: cat - cat || Loss: 0.7824400663375854\n",
      "tensor([1., 0.]) tensor([0.5308, 0.4692], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 2 - 6: cat - cat || Loss: 0.7824982404708862\n",
      "tensor([1., 0.]) tensor([0.5308, 0.4692], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 2 - 7: cat - cat || Loss: 0.7824573516845703\n",
      "tensor([1., 0.]) tensor([0.5308, 0.4692], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 2 - 8: cat - cat || Loss: 0.7823274731636047\n",
      "tensor([1., 0.]) tensor([0.5309, 0.4691], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 2 - 9: cat - cat || Loss: 0.7821176052093506\n",
      "tensor([1., 0.]) tensor([0.5311, 0.4689], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 2 - 10: cat - cat || Loss: 0.7818353772163391\n",
      "tensor([1., 0.]) tensor([0.5314, 0.4686], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 2 - 11: cat - cat || Loss: 0.7814884781837463\n",
      "tensor([1., 0.]) tensor([0.5318, 0.4682], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 2 - 12: cat - cat || Loss: 0.7810830473899841\n",
      "tensor([1., 0.]) tensor([0.5322, 0.4678], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 2 - 13: cat - cat || Loss: 0.7806251049041748\n",
      "tensor([1., 0.]) tensor([0.5326, 0.4674], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 2 - 14: cat - cat || Loss: 0.7801200747489929\n",
      "tensor([1., 0.]) tensor([0.5331, 0.4669], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 2 - 15: cat - cat || Loss: 0.7795721888542175\n",
      "tensor([1., 0.]) tensor([0.5337, 0.4663], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 2 - 16: cat - cat || Loss: 0.7789862155914307\n",
      "tensor([1., 0.]) tensor([0.5343, 0.4657], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 2 - 17: cat - cat || Loss: 0.7783656120300293\n",
      "tensor([1., 0.]) tensor([0.5349, 0.4651], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 2 - 18: cat - cat || Loss: 0.777714192867279\n",
      "tensor([1., 0.]) tensor([0.5355, 0.4645], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 2 - 19: cat - cat || Loss: 0.7770348787307739\n",
      "tensor([1., 0.]) tensor([0.5362, 0.4638], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 2 - 20: cat - cat || Loss: 0.7763306498527527\n",
      "tensor([1., 0.]) tensor([0.5369, 0.4631], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 2 - 21: cat - cat || Loss: 0.7756038308143616\n",
      "tensor([1., 0.]) tensor([0.5377, 0.4623], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 2 - 22: cat - cat || Loss: 0.7748567461967468\n",
      "tensor([1., 0.]) tensor([0.5384, 0.4616], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 2 - 23: cat - cat || Loss: 0.7740914225578308\n",
      "tensor([1., 0.]) tensor([0.5392, 0.4608], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 2 - 24: cat - cat || Loss: 0.7733098268508911\n",
      "tensor([1., 0.]) tensor([0.5400, 0.4600], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 2 - 25: cat - cat || Loss: 0.7725133299827576\n",
      "tensor([1., 0.]) tensor([0.5407, 0.4593], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 2 - 26: cat - cat || Loss: 0.7717037200927734\n",
      "tensor([1., 0.]) tensor([0.5416, 0.4584], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 2 - 27: cat - cat || Loss: 0.7708821296691895\n",
      "tensor([1., 0.]) tensor([0.5424, 0.4576], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 2 - 28: cat - cat || Loss: 0.7700499296188354\n",
      "tensor([1., 0.]) tensor([0.5432, 0.4568], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 2 - 29: cat - cat || Loss: 0.7692083716392517\n",
      "tensor([1., 0.]) tensor([0.5441, 0.4559], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 2 - 30: cat - cat || Loss: 0.7683583498001099\n",
      "tensor([1., 0.]) tensor([0.5449, 0.4551], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 2 - 31: cat - cat || Loss: 0.7675008773803711\n",
      "tensor([1., 0.]) tensor([0.5458, 0.4542], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 2 - 32: cat - cat || Loss: 0.766636312007904\n",
      "tensor([1., 0.]) tensor([0.5466, 0.4534], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 2 - 33: cat - cat || Loss: 0.7657654881477356\n",
      "tensor([1., 0.]) tensor([0.5475, 0.4525], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 2 - 34: cat - cat || Loss: 0.7648890018463135\n",
      "tensor([1., 0.]) tensor([0.5484, 0.4516], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 2 - 35: cat - cat || Loss: 0.7640073299407959\n",
      "tensor([1., 0.]) tensor([0.5493, 0.4507], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 2 - 36: cat - cat || Loss: 0.7631213665008545\n",
      "tensor([1., 0.]) tensor([0.5501, 0.4499], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 2 - 37: cat - cat || Loss: 0.7622312307357788\n",
      "tensor([1., 0.]) tensor([0.5510, 0.4490], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 2 - 38: cat - cat || Loss: 0.7613376975059509\n",
      "tensor([1., 0.]) tensor([0.5519, 0.4481], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 2 - 39: cat - cat || Loss: 0.7604405879974365\n",
      "tensor([1., 0.]) tensor([0.5528, 0.4472], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 2 - 40: cat - cat || Loss: 0.7595409154891968\n",
      "tensor([1., 0.]) tensor([0.5537, 0.4463], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 2 - 41: cat - cat || Loss: 0.7586382627487183\n",
      "tensor([1., 0.]) tensor([0.5546, 0.4454], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 2 - 42: cat - cat || Loss: 0.7577336430549622\n",
      "tensor([1., 0.]) tensor([0.5555, 0.4445], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 2 - 43: cat - cat || Loss: 0.7568267583847046\n",
      "tensor([1., 0.]) tensor([0.5564, 0.4436], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 2 - 44: cat - cat || Loss: 0.7559183835983276\n",
      "tensor([1., 0.]) tensor([0.5573, 0.4427], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 2 - 45: cat - cat || Loss: 0.7550082206726074\n",
      "tensor([1., 0.]) tensor([0.5583, 0.4417], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 2 - 46: cat - cat || Loss: 0.7540966272354126\n",
      "tensor([1., 0.]) tensor([0.5592, 0.4408], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 2 - 47: cat - cat || Loss: 0.7531837821006775\n",
      "tensor([1., 0.]) tensor([0.5601, 0.4399], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 2 - 48: cat - cat || Loss: 0.7522698640823364\n",
      "tensor([1., 0.]) tensor([0.5610, 0.4390], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 2 - 49: cat - cat || Loss: 0.7513547539710999\n",
      "tensor([1., 0.]) tensor([0.5619, 0.4381], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 2 - 50: cat - cat || Loss: 0.7504387497901917\n",
      "tensor([1., 0.]) tensor([0.5628, 0.4372], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 2 - 51: cat - cat || Loss: 0.7495220303535461\n",
      "tensor([1., 0.]) tensor([0.5637, 0.4363], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 2 - 52: cat - cat || Loss: 0.7486045956611633\n",
      "tensor([1., 0.]) tensor([0.5647, 0.4353], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 2 - 53: cat - cat || Loss: 0.7476867437362671\n",
      "tensor([1., 0.]) tensor([0.5656, 0.4344], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 2 - 54: cat - cat || Loss: 0.7467684745788574\n",
      "tensor([1., 0.]) tensor([0.5665, 0.4335], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 2 - 55: cat - cat || Loss: 0.7458497285842896\n",
      "tensor([1., 0.]) tensor([0.5674, 0.4326], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 2 - 56: cat - cat || Loss: 0.7449305653572083\n",
      "tensor([1., 0.]) tensor([0.5683, 0.4317], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 2 - 57: cat - cat || Loss: 0.7440111637115479\n",
      "tensor([1., 0.]) tensor([0.5693, 0.4307], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 2 - 58: cat - cat || Loss: 0.7430915236473083\n",
      "tensor([1., 0.]) tensor([0.5702, 0.4298], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 2 - 59: cat - cat || Loss: 0.7421718239784241\n",
      "tensor([1., 0.]) tensor([0.5711, 0.4289], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 2 - 60: cat - cat || Loss: 0.7412520051002502\n",
      "tensor([1., 0.]) tensor([0.5720, 0.4280], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 2 - 61: cat - cat || Loss: 0.7403321862220764\n",
      "tensor([1., 0.]) tensor([0.5729, 0.4271], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 2 - 62: cat - cat || Loss: 0.7394124269485474\n",
      "tensor([1., 0.]) tensor([0.5738, 0.4262], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 2 - 63: cat - cat || Loss: 0.7384928464889526\n",
      "tensor([1., 0.]) tensor([0.5748, 0.4252], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 2 - 64: cat - cat || Loss: 0.737573504447937\n",
      "tensor([1., 0.]) tensor([0.5757, 0.4243], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 2 - 65: cat - cat || Loss: 0.7366541624069214\n",
      "tensor([1., 0.]) tensor([0.5766, 0.4234], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 2 - 66: cat - cat || Loss: 0.7357351183891296\n",
      "tensor([1., 0.]) tensor([0.5775, 0.4225], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 2 - 67: cat - cat || Loss: 0.7348162531852722\n",
      "tensor([1., 0.]) tensor([0.5784, 0.4216], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 2 - 68: cat - cat || Loss: 0.7338972091674805\n",
      "tensor([1., 0.]) tensor([0.5794, 0.4206], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 2 - 69: cat - cat || Loss: 0.732978343963623\n",
      "tensor([1., 0.]) tensor([0.5803, 0.4197], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 2 - 70: cat - cat || Loss: 0.7320595383644104\n",
      "tensor([1., 0.]) tensor([0.5812, 0.4188], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 2 - 71: cat - cat || Loss: 0.7311409711837769\n",
      "tensor([1., 0.]) tensor([0.5821, 0.4179], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 2 - 72: cat - cat || Loss: 0.7302223443984985\n",
      "tensor([1., 0.]) tensor([0.5830, 0.4170], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 2 - 73: cat - cat || Loss: 0.7293038368225098\n",
      "tensor([1., 0.]) tensor([0.5840, 0.4160], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 2 - 74: cat - cat || Loss: 0.7283855080604553\n",
      "tensor([1., 0.]) tensor([0.5849, 0.4151], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 2 - 75: cat - cat || Loss: 0.7274673581123352\n",
      "tensor([1., 0.]) tensor([0.5858, 0.4142], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 2 - 76: cat - cat || Loss: 0.726549506187439\n",
      "tensor([1., 0.]) tensor([0.5867, 0.4133], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 2 - 77: cat - cat || Loss: 0.7256317138671875\n",
      "tensor([1., 0.]) tensor([0.5876, 0.4124], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 2 - 78: cat - cat || Loss: 0.7247139811515808\n",
      "tensor([1., 0.]) tensor([0.5885, 0.4115], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 2 - 79: cat - cat || Loss: 0.7237964868545532\n",
      "tensor([1., 0.]) tensor([0.5895, 0.4105], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 2 - 80: cat - cat || Loss: 0.72287917137146\n",
      "tensor([1., 0.]) tensor([0.5904, 0.4096], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 2 - 81: cat - cat || Loss: 0.7219622135162354\n",
      "tensor([1., 0.]) tensor([0.5913, 0.4087], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 2 - 82: cat - cat || Loss: 0.7210455536842346\n",
      "tensor([1., 0.]) tensor([0.5922, 0.4078], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 2 - 83: cat - cat || Loss: 0.7201290130615234\n",
      "tensor([1., 0.]) tensor([0.5931, 0.4069], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 2 - 84: cat - cat || Loss: 0.7192128896713257\n",
      "tensor([1., 0.]) tensor([0.5940, 0.4060], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 2 - 85: cat - cat || Loss: 0.7182973623275757\n",
      "tensor([1., 0.]) tensor([0.5950, 0.4050], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 2 - 86: cat - cat || Loss: 0.7173821330070496\n",
      "tensor([1., 0.]) tensor([0.5959, 0.4041], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 2 - 87: cat - cat || Loss: 0.7164670825004578\n",
      "tensor([1., 0.]) tensor([0.5968, 0.4032], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 2 - 88: cat - cat || Loss: 0.7155523300170898\n",
      "tensor([1., 0.]) tensor([0.5977, 0.4023], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 2 - 89: cat - cat || Loss: 0.7146376967430115\n",
      "tensor([1., 0.]) tensor([0.5986, 0.4014], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 2 - 90: cat - cat || Loss: 0.7137235999107361\n",
      "tensor([1., 0.]) tensor([0.5995, 0.4005], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 2 - 91: cat - cat || Loss: 0.7128094434738159\n",
      "tensor([1., 0.]) tensor([0.6005, 0.3995], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 2 - 92: cat - cat || Loss: 0.7118957042694092\n",
      "tensor([1., 0.]) tensor([0.6014, 0.3986], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 2 - 93: cat - cat || Loss: 0.7109822034835815\n",
      "tensor([1., 0.]) tensor([0.6023, 0.3977], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 2 - 94: cat - cat || Loss: 0.710068941116333\n",
      "tensor([1., 0.]) tensor([0.6032, 0.3968], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 2 - 95: cat - cat || Loss: 0.7091559171676636\n",
      "tensor([1., 0.]) tensor([0.6041, 0.3959], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 2 - 96: cat - cat || Loss: 0.7082432508468628\n",
      "tensor([1., 0.]) tensor([0.6050, 0.3950], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 2 - 97: cat - cat || Loss: 0.7073307037353516\n",
      "tensor([1., 0.]) tensor([0.6059, 0.3941], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 2 - 98: cat - cat || Loss: 0.7064186334609985\n",
      "tensor([1., 0.]) tensor([0.6068, 0.3932], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 2 - 99: cat - cat || Loss: 0.7055069208145142\n",
      "tensor([1., 0.]) tensor([0.6078, 0.3922], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 2 - 100: cat - cat || Loss: 0.7045954465866089\n",
      "tensor([1., 0.]) tensor([0.6087, 0.3913], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 2 - 101: cat - cat || Loss: 0.7036843299865723\n",
      "tensor([1., 0.]) tensor([0.6096, 0.3904], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 2 - 102: cat - cat || Loss: 0.7027732729911804\n",
      "tensor([1., 0.]) tensor([0.6105, 0.3895], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 2 - 103: cat - cat || Loss: 0.7018625736236572\n",
      "tensor([1., 0.]) tensor([0.6114, 0.3886], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 2 - 104: cat - cat || Loss: 0.7009521722793579\n",
      "tensor([1., 0.]) tensor([0.6123, 0.3877], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 2 - 105: cat - cat || Loss: 0.7000420689582825\n",
      "tensor([1., 0.]) tensor([0.6132, 0.3868], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 2 - 106: cat - cat || Loss: 0.6991322040557861\n",
      "tensor([1., 0.]) tensor([0.6141, 0.3859], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 2 - 107: cat - cat || Loss: 0.6982226967811584\n",
      "tensor([1., 0.]) tensor([0.6150, 0.3850], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 2 - 108: cat - cat || Loss: 0.6973134279251099\n",
      "tensor([1., 0.]) tensor([0.6159, 0.3841], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 2 - 109: cat - cat || Loss: 0.6964043974876404\n",
      "tensor([1., 0.]) tensor([0.6169, 0.3831], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 2 - 110: cat - cat || Loss: 0.6954955458641052\n",
      "tensor([1., 0.]) tensor([0.6178, 0.3822], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 2 - 111: cat - cat || Loss: 0.6945873498916626\n",
      "tensor([1., 0.]) tensor([0.6187, 0.3813], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 2 - 112: cat - cat || Loss: 0.6936794519424438\n",
      "tensor([1., 0.]) tensor([0.6196, 0.3804], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 2 - 113: cat - cat || Loss: 0.6927719712257385\n",
      "tensor([1., 0.]) tensor([0.6205, 0.3795], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 2 - 114: cat - cat || Loss: 0.6918647289276123\n",
      "tensor([1., 0.]) tensor([0.6214, 0.3786], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 2 - 115: cat - cat || Loss: 0.69095778465271\n",
      "tensor([1., 0.]) tensor([0.6223, 0.3777], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 2 - 116: cat - cat || Loss: 0.6900511980056763\n",
      "tensor([1., 0.]) tensor([0.6232, 0.3768], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 2 - 117: cat - cat || Loss: 0.6891449093818665\n",
      "tensor([1., 0.]) tensor([0.6241, 0.3759], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 2 - 118: cat - cat || Loss: 0.6882388591766357\n",
      "tensor([1., 0.]) tensor([0.6250, 0.3750], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 2 - 119: cat - cat || Loss: 0.6873332262039185\n",
      "tensor([1., 0.]) tensor([0.6259, 0.3741], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 2 - 120: cat - cat || Loss: 0.6864279508590698\n",
      "tensor([1., 0.]) tensor([0.6268, 0.3732], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 2 - 121: cat - cat || Loss: 0.6855226755142212\n",
      "tensor([1., 0.]) tensor([0.6277, 0.3723], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 2 - 122: cat - cat || Loss: 0.6846180558204651\n",
      "tensor([1., 0.]) tensor([0.6286, 0.3714], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 2 - 123: cat - cat || Loss: 0.6837136745452881\n",
      "tensor([1., 0.]) tensor([0.6295, 0.3705], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 2 - 124: cat - cat || Loss: 0.6828096508979797\n",
      "tensor([1., 0.]) tensor([0.6305, 0.3695], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 2 - 125: cat - cat || Loss: 0.68190598487854\n",
      "tensor([1., 0.]) tensor([0.6314, 0.3686], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 2 - 126: cat - cat || Loss: 0.6810025572776794\n",
      "tensor([1., 0.]) tensor([0.6323, 0.3677], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 2 - 127: cat - cat || Loss: 0.6800994277000427\n",
      "tensor([1., 0.]) tensor([0.6332, 0.3668], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 2 - 128: cat - cat || Loss: 0.6791967153549194\n",
      "tensor([1., 0.]) tensor([0.6341, 0.3659], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 2 - 129: cat - cat || Loss: 0.6782943606376648\n",
      "tensor([1., 0.]) tensor([0.6350, 0.3650], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 2 - 130: cat - cat || Loss: 0.6773922443389893\n",
      "tensor([1., 0.]) tensor([0.6359, 0.3641], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 2 - 131: cat - cat || Loss: 0.6764903664588928\n",
      "tensor([1., 0.]) tensor([0.6368, 0.3632], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 2 - 132: cat - cat || Loss: 0.675588846206665\n",
      "tensor([1., 0.]) tensor([0.6377, 0.3623], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 2 - 133: cat - cat || Loss: 0.6746876835823059\n",
      "tensor([1., 0.]) tensor([0.6386, 0.3614], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 2 - 134: cat - cat || Loss: 0.6737869381904602\n",
      "tensor([1., 0.]) tensor([0.6395, 0.3605], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 2 - 135: cat - cat || Loss: 0.6728864312171936\n",
      "tensor([1., 0.]) tensor([0.6404, 0.3596], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 2 - 136: cat - cat || Loss: 0.6719864010810852\n",
      "tensor([1., 0.]) tensor([0.6413, 0.3587], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 2 - 137: cat - cat || Loss: 0.6710864901542664\n",
      "tensor([1., 0.]) tensor([0.6422, 0.3578], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 2 - 138: cat - cat || Loss: 0.6701868772506714\n",
      "tensor([1., 0.]) tensor([0.6431, 0.3569], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 2 - 139: cat - cat || Loss: 0.6692877411842346\n",
      "tensor([1., 0.]) tensor([0.6440, 0.3560], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 2 - 140: cat - cat || Loss: 0.668388843536377\n",
      "tensor([1., 0.]) tensor([0.6449, 0.3551], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 2 - 141: cat - cat || Loss: 0.6674904823303223\n",
      "tensor([1., 0.]) tensor([0.6458, 0.3542], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 2 - 142: cat - cat || Loss: 0.6665922999382019\n",
      "tensor([1., 0.]) tensor([0.6467, 0.3533], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 2 - 143: cat - cat || Loss: 0.6656945943832397\n",
      "tensor([1., 0.]) tensor([0.6476, 0.3524], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 2 - 144: cat - cat || Loss: 0.6647972464561462\n",
      "tensor([1., 0.]) tensor([0.6485, 0.3515], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 2 - 145: cat - cat || Loss: 0.6639002561569214\n",
      "tensor([1., 0.]) tensor([0.6494, 0.3506], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 2 - 146: cat - cat || Loss: 0.6630038619041443\n",
      "tensor([1., 0.]) tensor([0.6503, 0.3497], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 2 - 147: cat - cat || Loss: 0.6621077656745911\n",
      "tensor([1., 0.]) tensor([0.6512, 0.3488], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 2 - 148: cat - cat || Loss: 0.6612120866775513\n",
      "tensor([1., 0.]) tensor([0.6520, 0.3480], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 2 - 149: cat - cat || Loss: 0.660317063331604\n",
      "tensor([1., 0.]) tensor([0.6529, 0.3471], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 2 - 150: cat - cat || Loss: 0.6594222187995911\n",
      "tensor([1., 0.]) tensor([0.6538, 0.3462], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 2 - 151: cat - cat || Loss: 0.6585280299186707\n",
      "tensor([1., 0.]) tensor([0.6547, 0.3453], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 2 - 152: cat - cat || Loss: 0.6576341390609741\n",
      "tensor([1., 0.]) tensor([0.6556, 0.3444], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 2 - 153: cat - cat || Loss: 0.656740665435791\n",
      "tensor([1., 0.]) tensor([0.6565, 0.3435], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 2 - 154: cat - cat || Loss: 0.6558476686477661\n",
      "tensor([1., 0.]) tensor([0.6574, 0.3426], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 2 - 155: cat - cat || Loss: 0.6549550890922546\n",
      "tensor([1., 0.]) tensor([0.6583, 0.3417], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 2 - 156: cat - cat || Loss: 0.6540631055831909\n",
      "tensor([1., 0.]) tensor([0.6592, 0.3408], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 2 - 157: cat - cat || Loss: 0.6531713604927063\n",
      "tensor([1., 0.]) tensor([0.6601, 0.3399], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 2 - 158: cat - cat || Loss: 0.6522800922393799\n",
      "tensor([1., 0.]) tensor([0.6610, 0.3390], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 2 - 159: cat - cat || Loss: 0.6513891220092773\n",
      "tensor([1., 0.]) tensor([0.6619, 0.3381], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 2 - 160: cat - cat || Loss: 0.6504986882209778\n",
      "tensor([1., 0.]) tensor([0.6628, 0.3372], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 2 - 161: cat - cat || Loss: 0.6496086120605469\n",
      "tensor([1., 0.]) tensor([0.6637, 0.3363], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 2 - 162: cat - cat || Loss: 0.6487191319465637\n",
      "tensor([1., 0.]) tensor([0.6645, 0.3355], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 2 - 163: cat - cat || Loss: 0.6478298306465149\n",
      "tensor([1., 0.]) tensor([0.6654, 0.3346], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 2 - 164: cat - cat || Loss: 0.6469411253929138\n",
      "tensor([1., 0.]) tensor([0.6663, 0.3337], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 2 - 165: cat - cat || Loss: 0.6460528373718262\n",
      "tensor([1., 0.]) tensor([0.6672, 0.3328], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 2 - 166: cat - cat || Loss: 0.6451648473739624\n",
      "tensor([1., 0.]) tensor([0.6681, 0.3319], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 2 - 167: cat - cat || Loss: 0.6442774534225464\n",
      "tensor([1., 0.]) tensor([0.6690, 0.3310], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 2 - 168: cat - cat || Loss: 0.6433906555175781\n",
      "tensor([1., 0.]) tensor([0.6699, 0.3301], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 2 - 169: cat - cat || Loss: 0.6425040364265442\n",
      "tensor([1., 0.]) tensor([0.6708, 0.3292], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 2 - 170: cat - cat || Loss: 0.6416179537773132\n",
      "tensor([1., 0.]) tensor([0.6716, 0.3284], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 2 - 171: cat - cat || Loss: 0.6407324075698853\n",
      "tensor([1., 0.]) tensor([0.6725, 0.3275], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 2 - 172: cat - cat || Loss: 0.6398472785949707\n",
      "tensor([1., 0.]) tensor([0.6734, 0.3266], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 2 - 173: cat - cat || Loss: 0.6389628052711487\n",
      "tensor([1., 0.]) tensor([0.6743, 0.3257], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 2 - 174: cat - cat || Loss: 0.6380786299705505\n",
      "tensor([1., 0.]) tensor([0.6752, 0.3248], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 2 - 175: cat - cat || Loss: 0.6371949315071106\n",
      "tensor([1., 0.]) tensor([0.6761, 0.3239], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 2 - 176: cat - cat || Loss: 0.6363116502761841\n",
      "tensor([1., 0.]) tensor([0.6769, 0.3231], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 2 - 177: cat - cat || Loss: 0.6354290246963501\n",
      "tensor([1., 0.]) tensor([0.6778, 0.3222], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 2 - 178: cat - cat || Loss: 0.6345468163490295\n",
      "tensor([1., 0.]) tensor([0.6787, 0.3213], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 2 - 179: cat - cat || Loss: 0.6336652040481567\n",
      "tensor([1., 0.]) tensor([0.6796, 0.3204], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 2 - 180: cat - cat || Loss: 0.6327839493751526\n",
      "tensor([1., 0.]) tensor([0.6805, 0.3195], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 2 - 181: cat - cat || Loss: 0.6319032907485962\n",
      "tensor([1., 0.]) tensor([0.6814, 0.3186], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 2 - 182: cat - cat || Loss: 0.6310231685638428\n",
      "tensor([1., 0.]) tensor([0.6822, 0.3178], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 2 - 183: cat - cat || Loss: 0.6301436424255371\n",
      "tensor([1., 0.]) tensor([0.6831, 0.3169], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 2 - 184: cat - cat || Loss: 0.6292644143104553\n",
      "tensor([1., 0.]) tensor([0.6840, 0.3160], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 2 - 185: cat - cat || Loss: 0.6283860206604004\n",
      "tensor([1., 0.]) tensor([0.6849, 0.3151], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 2 - 186: cat - cat || Loss: 0.627507746219635\n",
      "tensor([1., 0.]) tensor([0.6858, 0.3142], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 2 - 187: cat - cat || Loss: 0.6266301274299622\n",
      "tensor([1., 0.]) tensor([0.6866, 0.3134], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 2 - 188: cat - cat || Loss: 0.6257530450820923\n",
      "tensor([1., 0.]) tensor([0.6875, 0.3125], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 2 - 189: cat - cat || Loss: 0.6248763799667358\n",
      "tensor([1., 0.]) tensor([0.6884, 0.3116], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 2 - 190: dog - cat || Loss: 1.0025231838226318\n",
      "tensor([0., 1.]) tensor([0.6893, 0.3107], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 2 - 191: dog - cat || Loss: 1.0032240152359009\n",
      "tensor([0., 1.]) tensor([0.6900, 0.3100], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 2 - 192: dog - cat || Loss: 1.0037671327590942\n",
      "tensor([0., 1.]) tensor([0.6905, 0.3095], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 2 - 193: dog - cat || Loss: 1.0041685104370117\n",
      "tensor([0., 1.]) tensor([0.6909, 0.3091], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 2 - 194: dog - cat || Loss: 1.0044422149658203\n",
      "tensor([0., 1.]) tensor([0.6912, 0.3088], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 2 - 195: dog - cat || Loss: 1.0046014785766602\n",
      "tensor([0., 1.]) tensor([0.6913, 0.3087], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 2 - 196: dog - cat || Loss: 1.00465726852417\n",
      "tensor([0., 1.]) tensor([0.6914, 0.3086], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 2 - 197: dog - cat || Loss: 1.0046201944351196\n",
      "tensor([0., 1.]) tensor([0.6914, 0.3086], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 2 - 198: dog - cat || Loss: 1.0044995546340942\n",
      "tensor([0., 1.]) tensor([0.6912, 0.3088], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 2 - 199: dog - cat || Loss: 1.0043038129806519\n",
      "tensor([0., 1.]) tensor([0.6910, 0.3090], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 2 - 200: dog - cat || Loss: 1.004040241241455\n",
      "tensor([0., 1.]) tensor([0.6908, 0.3092], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 2 - 201: dog - cat || Loss: 1.0037157535552979\n",
      "tensor([0., 1.]) tensor([0.6905, 0.3095], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 2 - 202: dog - cat || Loss: 1.0033361911773682\n",
      "tensor([0., 1.]) tensor([0.6901, 0.3099], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 2 - 203: dog - cat || Loss: 1.002907395362854\n",
      "tensor([0., 1.]) tensor([0.6896, 0.3104], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 2 - 204: dog - cat || Loss: 1.0024340152740479\n",
      "tensor([0., 1.]) tensor([0.6892, 0.3108], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 2 - 205: dog - cat || Loss: 1.0019203424453735\n",
      "tensor([0., 1.]) tensor([0.6887, 0.3113], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 2 - 206: dog - cat || Loss: 1.0013706684112549\n",
      "tensor([0., 1.]) tensor([0.6881, 0.3119], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 2 - 207: dog - cat || Loss: 1.000788688659668\n",
      "tensor([0., 1.]) tensor([0.6875, 0.3125], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 2 - 208: dog - cat || Loss: 1.000177025794983\n",
      "tensor([0., 1.]) tensor([0.6869, 0.3131], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 2 - 209: dog - cat || Loss: 0.9995391368865967\n",
      "tensor([0., 1.]) tensor([0.6863, 0.3137], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 2 - 210: dog - cat || Loss: 0.998877227306366\n",
      "tensor([0., 1.]) tensor([0.6856, 0.3144], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 2 - 211: dog - cat || Loss: 0.99819415807724\n",
      "tensor([0., 1.]) tensor([0.6849, 0.3151], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 2 - 212: dog - cat || Loss: 0.997491717338562\n",
      "tensor([0., 1.]) tensor([0.6842, 0.3158], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 2 - 213: dog - cat || Loss: 0.9967717528343201\n",
      "tensor([0., 1.]) tensor([0.6835, 0.3165], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 2 - 214: dog - cat || Loss: 0.9960361123085022\n",
      "tensor([0., 1.]) tensor([0.6828, 0.3172], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 2 - 215: dog - cat || Loss: 0.9952864646911621\n",
      "tensor([0., 1.]) tensor([0.6820, 0.3180], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 2 - 216: dog - cat || Loss: 0.9945240616798401\n",
      "tensor([0., 1.]) tensor([0.6813, 0.3187], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 2 - 217: dog - cat || Loss: 0.9937498569488525\n",
      "tensor([0., 1.]) tensor([0.6805, 0.3195], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 2 - 218: dog - cat || Loss: 0.9929654598236084\n",
      "tensor([0., 1.]) tensor([0.6797, 0.3203], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 2 - 219: dog - cat || Loss: 0.9921715259552002\n",
      "tensor([0., 1.]) tensor([0.6789, 0.3211], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 2 - 220: dog - cat || Loss: 0.9913689494132996\n",
      "tensor([0., 1.]) tensor([0.6781, 0.3219], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 2 - 221: dog - cat || Loss: 0.9905588626861572\n",
      "tensor([0., 1.]) tensor([0.6773, 0.3227], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 2 - 222: dog - cat || Loss: 0.9897415637969971\n",
      "tensor([0., 1.]) tensor([0.6765, 0.3235], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 2 - 223: dog - cat || Loss: 0.9889180660247803\n",
      "tensor([0., 1.]) tensor([0.6757, 0.3243], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 2 - 224: dog - cat || Loss: 0.988088846206665\n",
      "tensor([0., 1.]) tensor([0.6748, 0.3252], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 2 - 225: dog - cat || Loss: 0.9872545003890991\n",
      "tensor([0., 1.]) tensor([0.6740, 0.3260], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 2 - 226: dog - cat || Loss: 0.9864152669906616\n",
      "tensor([0., 1.]) tensor([0.6732, 0.3268], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 2 - 227: dog - cat || Loss: 0.9855719208717346\n",
      "tensor([0., 1.]) tensor([0.6723, 0.3277], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 2 - 228: dog - cat || Loss: 0.9847247004508972\n",
      "tensor([0., 1.]) tensor([0.6715, 0.3285], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 2 - 229: dog - cat || Loss: 0.9838740229606628\n",
      "tensor([0., 1.]) tensor([0.6706, 0.3294], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 2 - 230: dog - cat || Loss: 0.9830198884010315\n",
      "tensor([0., 1.]) tensor([0.6698, 0.3302], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 2 - 231: dog - cat || Loss: 0.9821630120277405\n",
      "tensor([0., 1.]) tensor([0.6689, 0.3311], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 2 - 232: dog - cat || Loss: 0.9813033938407898\n",
      "tensor([0., 1.]) tensor([0.6680, 0.3320], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 2 - 233: dog - cat || Loss: 0.9804415106773376\n",
      "tensor([0., 1.]) tensor([0.6672, 0.3328], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 2 - 234: dog - cat || Loss: 0.9795773029327393\n",
      "tensor([0., 1.]) tensor([0.6663, 0.3337], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 2 - 235: dog - cat || Loss: 0.9787111878395081\n",
      "tensor([0., 1.]) tensor([0.6654, 0.3346], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 2 - 236: dog - cat || Loss: 0.9778430461883545\n",
      "tensor([0., 1.]) tensor([0.6646, 0.3354], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 2 - 237: dog - cat || Loss: 0.9769733548164368\n",
      "tensor([0., 1.]) tensor([0.6637, 0.3363], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 2 - 238: dog - cat || Loss: 0.9761019349098206\n",
      "tensor([0., 1.]) tensor([0.6628, 0.3372], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 2 - 239: dog - cat || Loss: 0.9752290844917297\n",
      "tensor([0., 1.]) tensor([0.6620, 0.3380], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 2 - 240: dog - cat || Loss: 0.9743550419807434\n",
      "tensor([0., 1.]) tensor([0.6611, 0.3389], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 2 - 241: dog - cat || Loss: 0.9734798073768616\n",
      "tensor([0., 1.]) tensor([0.6602, 0.3398], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 2 - 242: dog - cat || Loss: 0.9726032614707947\n",
      "tensor([0., 1.]) tensor([0.6593, 0.3407], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 2 - 243: dog - cat || Loss: 0.9717258810997009\n",
      "tensor([0., 1.]) tensor([0.6585, 0.3415], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 2 - 244: dog - cat || Loss: 0.9708474278450012\n",
      "tensor([0., 1.]) tensor([0.6576, 0.3424], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 2 - 245: dog - cat || Loss: 0.9699679613113403\n",
      "tensor([0., 1.]) tensor([0.6567, 0.3433], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 2 - 246: dog - cat || Loss: 0.9690876007080078\n",
      "tensor([0., 1.]) tensor([0.6558, 0.3442], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 2 - 247: dog - cat || Loss: 0.9682066440582275\n",
      "tensor([0., 1.]) tensor([0.6549, 0.3451], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 2 - 248: dog - cat || Loss: 0.9673249125480652\n",
      "tensor([0., 1.]) tensor([0.6541, 0.3459], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 2 - 249: dog - cat || Loss: 0.9664422273635864\n",
      "tensor([0., 1.]) tensor([0.6532, 0.3468], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 2 - 250: dog - cat || Loss: 0.9655590057373047\n",
      "tensor([0., 1.]) tensor([0.6523, 0.3477], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 2 - 251: dog - cat || Loss: 0.9646753072738647\n",
      "tensor([0., 1.]) tensor([0.6514, 0.3486], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 2 - 252: dog - cat || Loss: 0.9637909531593323\n",
      "tensor([0., 1.]) tensor([0.6505, 0.3495], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 2 - 253: dog - cat || Loss: 0.9629059433937073\n",
      "tensor([0., 1.]) tensor([0.6496, 0.3504], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 2 - 254: dog - cat || Loss: 0.9620205163955688\n",
      "tensor([0., 1.]) tensor([0.6488, 0.3512], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 2 - 255: dog - cat || Loss: 0.961134672164917\n",
      "tensor([0., 1.]) tensor([0.6479, 0.3521], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 2 - 256: dog - cat || Loss: 0.9602481722831726\n",
      "tensor([0., 1.]) tensor([0.6470, 0.3530], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 2 - 257: dog - cat || Loss: 0.9593611359596252\n",
      "tensor([0., 1.]) tensor([0.6461, 0.3539], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 2 - 258: dog - cat || Loss: 0.9584738612174988\n",
      "tensor([0., 1.]) tensor([0.6452, 0.3548], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 2 - 259: dog - cat || Loss: 0.9575859904289246\n",
      "tensor([0., 1.]) tensor([0.6443, 0.3557], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 2 - 260: dog - cat || Loss: 0.9566976428031921\n",
      "tensor([0., 1.]) tensor([0.6434, 0.3566], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 2 - 261: dog - cat || Loss: 0.9558091163635254\n",
      "tensor([0., 1.]) tensor([0.6425, 0.3575], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 2 - 262: dog - cat || Loss: 0.9549199938774109\n",
      "tensor([0., 1.]) tensor([0.6417, 0.3583], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 2 - 263: dog - cat || Loss: 0.9540303349494934\n",
      "tensor([0., 1.]) tensor([0.6408, 0.3592], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 2 - 264: dog - cat || Loss: 0.9531404376029968\n",
      "tensor([0., 1.]) tensor([0.6399, 0.3601], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 2 - 265: dog - cat || Loss: 0.9522501230239868\n",
      "tensor([0., 1.]) tensor([0.6390, 0.3610], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 2 - 266: dog - cat || Loss: 0.9513596296310425\n",
      "tensor([0., 1.]) tensor([0.6381, 0.3619], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 2 - 267: dog - cat || Loss: 0.950468897819519\n",
      "tensor([0., 1.]) tensor([0.6372, 0.3628], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 2 - 268: dog - cat || Loss: 0.9495776891708374\n",
      "tensor([0., 1.]) tensor([0.6363, 0.3637], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 2 - 269: dog - cat || Loss: 0.9486863613128662\n",
      "tensor([0., 1.]) tensor([0.6354, 0.3646], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 2 - 270: dog - cat || Loss: 0.947794497013092\n",
      "tensor([0., 1.]) tensor([0.6345, 0.3655], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 2 - 271: dog - cat || Loss: 0.9469025135040283\n",
      "tensor([0., 1.]) tensor([0.6336, 0.3664], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 2 - 272: dog - cat || Loss: 0.9460100531578064\n",
      "tensor([0., 1.]) tensor([0.6327, 0.3673], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 2 - 273: dog - cat || Loss: 0.9451174139976501\n",
      "tensor([0., 1.]) tensor([0.6319, 0.3681], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 2 - 274: dog - cat || Loss: 0.9442245364189148\n",
      "tensor([0., 1.]) tensor([0.6310, 0.3690], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 2 - 275: dog - cat || Loss: 0.943331241607666\n",
      "tensor([0., 1.]) tensor([0.6301, 0.3699], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 2 - 276: dog - cat || Loss: 0.9424377083778381\n",
      "tensor([0., 1.]) tensor([0.6292, 0.3708], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 2 - 277: dog - cat || Loss: 0.9415437579154968\n",
      "tensor([0., 1.]) tensor([0.6283, 0.3717], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 2 - 278: dog - cat || Loss: 0.9406498074531555\n",
      "tensor([0., 1.]) tensor([0.6274, 0.3726], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 2 - 279: dog - cat || Loss: 0.9397556185722351\n",
      "tensor([0., 1.]) tensor([0.6265, 0.3735], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 2 - 280: dog - cat || Loss: 0.9388611912727356\n",
      "tensor([0., 1.]) tensor([0.6256, 0.3744], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 2 - 281: dog - cat || Loss: 0.9379664659500122\n",
      "tensor([0., 1.]) tensor([0.6247, 0.3753], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 2 - 282: dog - cat || Loss: 0.9370714426040649\n",
      "tensor([0., 1.]) tensor([0.6238, 0.3762], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 2 - 283: dog - cat || Loss: 0.9361762404441833\n",
      "tensor([0., 1.]) tensor([0.6229, 0.3771], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 2 - 284: dog - cat || Loss: 0.9352807998657227\n",
      "tensor([0., 1.]) tensor([0.6220, 0.3780], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 2 - 285: dog - cat || Loss: 0.9343849420547485\n",
      "tensor([0., 1.]) tensor([0.6211, 0.3789], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 2 - 286: dog - cat || Loss: 0.9334890246391296\n",
      "tensor([0., 1.]) tensor([0.6202, 0.3798], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 2 - 287: dog - cat || Loss: 0.9325924515724182\n",
      "tensor([0., 1.]) tensor([0.6193, 0.3807], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 2 - 288: dog - cat || Loss: 0.9316959381103516\n",
      "tensor([0., 1.]) tensor([0.6184, 0.3816], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 2 - 289: dog - cat || Loss: 0.9307988882064819\n",
      "tensor([0., 1.]) tensor([0.6175, 0.3825], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 2 - 290: dog - cat || Loss: 0.9299018979072571\n",
      "tensor([0., 1.]) tensor([0.6166, 0.3834], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 2 - 291: dog - cat || Loss: 0.9290044903755188\n",
      "tensor([0., 1.]) tensor([0.6157, 0.3843], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 2 - 292: dog - cat || Loss: 0.9281067848205566\n",
      "tensor([0., 1.]) tensor([0.6148, 0.3852], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 2 - 293: dog - cat || Loss: 0.9272089004516602\n",
      "tensor([0., 1.]) tensor([0.6139, 0.3861], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 2 - 294: dog - cat || Loss: 0.9263107776641846\n",
      "tensor([0., 1.]) tensor([0.6130, 0.3870], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 2 - 295: dog - cat || Loss: 0.9254124760627747\n",
      "tensor([0., 1.]) tensor([0.6122, 0.3878], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 2 - 296: dog - cat || Loss: 0.9245138764381409\n",
      "tensor([0., 1.]) tensor([0.6113, 0.3887], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 2 - 297: dog - cat || Loss: 0.9236153364181519\n",
      "tensor([0., 1.]) tensor([0.6104, 0.3896], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 2 - 298: dog - cat || Loss: 0.922716498374939\n",
      "tensor([0., 1.]) tensor([0.6095, 0.3905], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 2 - 299: dog - cat || Loss: 0.9218174815177917\n",
      "tensor([0., 1.]) tensor([0.6086, 0.3914], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 2 - 300: dog - cat || Loss: 0.9209182858467102\n",
      "tensor([0., 1.]) tensor([0.6077, 0.3923], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 2 - 301: dog - cat || Loss: 0.9200189709663391\n",
      "tensor([0., 1.]) tensor([0.6068, 0.3932], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 2 - 302: dog - cat || Loss: 0.9191197156906128\n",
      "tensor([0., 1.]) tensor([0.6059, 0.3941], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 2 - 303: dog - cat || Loss: 0.9182199835777283\n",
      "tensor([0., 1.]) tensor([0.6050, 0.3950], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 2 - 304: dog - cat || Loss: 0.917320191860199\n",
      "tensor([0., 1.]) tensor([0.6041, 0.3959], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 2 - 305: dog - cat || Loss: 0.916420042514801\n",
      "tensor([0., 1.]) tensor([0.6032, 0.3968], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 2 - 306: dog - cat || Loss: 0.9155199527740479\n",
      "tensor([0., 1.]) tensor([0.6023, 0.3977], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 2 - 307: dog - cat || Loss: 0.9146196842193604\n",
      "tensor([0., 1.]) tensor([0.6014, 0.3986], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 2 - 308: dog - cat || Loss: 0.9137190580368042\n",
      "tensor([0., 1.]) tensor([0.6005, 0.3995], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 2 - 309: dog - cat || Loss: 0.912818431854248\n",
      "tensor([0., 1.]) tensor([0.5996, 0.4004], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 2 - 310: dog - cat || Loss: 0.9119175672531128\n",
      "tensor([0., 1.]) tensor([0.5987, 0.4013], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 2 - 311: dog - cat || Loss: 0.9110164642333984\n",
      "tensor([0., 1.]) tensor([0.5978, 0.4022], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 2 - 312: dog - cat || Loss: 0.9101152420043945\n",
      "tensor([0., 1.]) tensor([0.5969, 0.4031], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 2 - 313: dog - cat || Loss: 0.9092138409614563\n",
      "tensor([0., 1.]) tensor([0.5960, 0.4040], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 2 - 314: dog - cat || Loss: 0.9083123207092285\n",
      "tensor([0., 1.]) tensor([0.5951, 0.4049], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 2 - 315: dog - cat || Loss: 0.9074104428291321\n",
      "tensor([0., 1.]) tensor([0.5941, 0.4059], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 2 - 316: dog - cat || Loss: 0.9065085649490356\n",
      "tensor([0., 1.]) tensor([0.5932, 0.4068], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 2 - 317: dog - cat || Loss: 0.9056063890457153\n",
      "tensor([0., 1.]) tensor([0.5923, 0.4077], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 2 - 318: dog - cat || Loss: 0.9047040939331055\n",
      "tensor([0., 1.]) tensor([0.5914, 0.4086], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 2 - 319: dog - cat || Loss: 0.903801679611206\n",
      "tensor([0., 1.]) tensor([0.5905, 0.4095], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 2 - 320: dog - cat || Loss: 0.9028989672660828\n",
      "tensor([0., 1.]) tensor([0.5896, 0.4104], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 2 - 321: dog - cat || Loss: 0.9019962549209595\n",
      "tensor([0., 1.]) tensor([0.5887, 0.4113], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 2 - 322: dog - cat || Loss: 0.9010932445526123\n",
      "tensor([0., 1.]) tensor([0.5878, 0.4122], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 2 - 323: dog - cat || Loss: 0.900189995765686\n",
      "tensor([0., 1.]) tensor([0.5869, 0.4131], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 2 - 324: dog - cat || Loss: 0.8992866277694702\n",
      "tensor([0., 1.]) tensor([0.5860, 0.4140], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 2 - 325: dog - cat || Loss: 0.8983830213546753\n",
      "tensor([0., 1.]) tensor([0.5851, 0.4149], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 2 - 326: dog - cat || Loss: 0.8974792957305908\n",
      "tensor([0., 1.]) tensor([0.5842, 0.4158], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 2 - 327: dog - cat || Loss: 0.8965754508972168\n",
      "tensor([0., 1.]) tensor([0.5833, 0.4167], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 2 - 328: dog - cat || Loss: 0.8956714868545532\n",
      "tensor([0., 1.]) tensor([0.5824, 0.4176], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 2 - 329: dog - cat || Loss: 0.8947672843933105\n",
      "tensor([0., 1.]) tensor([0.5815, 0.4185], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 2 - 330: dog - cat || Loss: 0.8938629627227783\n",
      "tensor([0., 1.]) tensor([0.5806, 0.4194], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 2 - 331: dog - cat || Loss: 0.892958402633667\n",
      "tensor([0., 1.]) tensor([0.5797, 0.4203], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 2 - 332: dog - cat || Loss: 0.8920539021492004\n",
      "tensor([0., 1.]) tensor([0.5788, 0.4212], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 2 - 333: dog - cat || Loss: 0.8911490440368652\n",
      "tensor([0., 1.]) tensor([0.5779, 0.4221], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 2 - 334: dog - cat || Loss: 0.8902442455291748\n",
      "tensor([0., 1.]) tensor([0.5770, 0.4230], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 2 - 335: dog - cat || Loss: 0.8893393278121948\n",
      "tensor([0., 1.]) tensor([0.5761, 0.4239], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 2 - 336: dog - cat || Loss: 0.8884345293045044\n",
      "tensor([0., 1.]) tensor([0.5752, 0.4248], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 2 - 337: dog - cat || Loss: 0.8875293731689453\n",
      "tensor([0., 1.]) tensor([0.5743, 0.4257], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 2 - 338: dog - cat || Loss: 0.8866241574287415\n",
      "tensor([0., 1.]) tensor([0.5734, 0.4266], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 2 - 339: dog - cat || Loss: 0.8857189416885376\n",
      "tensor([0., 1.]) tensor([0.5725, 0.4275], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 2 - 340: dog - cat || Loss: 0.8848135471343994\n",
      "tensor([0., 1.]) tensor([0.5716, 0.4284], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 2 - 341: dog - cat || Loss: 0.8839077949523926\n",
      "tensor([0., 1.]) tensor([0.5706, 0.4294], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 2 - 342: dog - cat || Loss: 0.8830021023750305\n",
      "tensor([0., 1.]) tensor([0.5697, 0.4303], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 2 - 343: dog - cat || Loss: 0.8820962905883789\n",
      "tensor([0., 1.]) tensor([0.5688, 0.4312], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 2 - 344: dog - cat || Loss: 0.8811904191970825\n",
      "tensor([0., 1.]) tensor([0.5679, 0.4321], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 2 - 345: dog - cat || Loss: 0.8802844285964966\n",
      "tensor([0., 1.]) tensor([0.5670, 0.4330], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 2 - 346: dog - cat || Loss: 0.8793783187866211\n",
      "tensor([0., 1.]) tensor([0.5661, 0.4339], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 2 - 347: dog - cat || Loss: 0.8784721493721008\n",
      "tensor([0., 1.]) tensor([0.5652, 0.4348], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 2 - 348: dog - cat || Loss: 0.8775656819343567\n",
      "tensor([0., 1.]) tensor([0.5643, 0.4357], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 2 - 349: dog - cat || Loss: 0.8766592144966125\n",
      "tensor([0., 1.]) tensor([0.5634, 0.4366], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 2 - 350: dog - cat || Loss: 0.875752329826355\n",
      "tensor([0., 1.]) tensor([0.5625, 0.4375], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 2 - 351: dog - cat || Loss: 0.8748453259468079\n",
      "tensor([0., 1.]) tensor([0.5616, 0.4384], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 2 - 352: dog - cat || Loss: 0.8739383220672607\n",
      "tensor([0., 1.]) tensor([0.5607, 0.4393], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 2 - 353: dog - cat || Loss: 0.873030960559845\n",
      "tensor([0., 1.]) tensor([0.5598, 0.4402], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 2 - 354: dog - cat || Loss: 0.8721235394477844\n",
      "tensor([0., 1.]) tensor([0.5589, 0.4411], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 2 - 355: dog - cat || Loss: 0.8712161183357239\n",
      "tensor([0., 1.]) tensor([0.5580, 0.4420], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 2 - 356: dog - cat || Loss: 0.8703083395957947\n",
      "tensor([0., 1.]) tensor([0.5570, 0.4430], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 2 - 357: dog - cat || Loss: 0.8694004416465759\n",
      "tensor([0., 1.]) tensor([0.5561, 0.4439], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 2 - 358: dog - cat || Loss: 0.8684924244880676\n",
      "tensor([0., 1.]) tensor([0.5552, 0.4448], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 2 - 359: dog - cat || Loss: 0.8675842881202698\n",
      "tensor([0., 1.]) tensor([0.5543, 0.4457], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 2 - 360: dog - cat || Loss: 0.8666760325431824\n",
      "tensor([0., 1.]) tensor([0.5534, 0.4466], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 2 - 361: dog - cat || Loss: 0.8657675385475159\n",
      "tensor([0., 1.]) tensor([0.5525, 0.4475], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 2 - 362: dog - cat || Loss: 0.8648591041564941\n",
      "tensor([0., 1.]) tensor([0.5516, 0.4484], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 2 - 363: dog - cat || Loss: 0.8639503717422485\n",
      "tensor([0., 1.]) tensor([0.5507, 0.4493], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 2 - 364: dog - cat || Loss: 0.8630414605140686\n",
      "tensor([0., 1.]) tensor([0.5498, 0.4502], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 2 - 365: dog - cat || Loss: 0.8621326088905334\n",
      "tensor([0., 1.]) tensor([0.5489, 0.4511], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 2 - 366: dog - cat || Loss: 0.8612233996391296\n",
      "tensor([0., 1.]) tensor([0.5480, 0.4520], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 2 - 367: dog - cat || Loss: 0.8603142499923706\n",
      "tensor([0., 1.]) tensor([0.5471, 0.4529], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 2 - 368: dog - cat || Loss: 0.8594050407409668\n",
      "tensor([0., 1.]) tensor([0.5461, 0.4539], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 2 - 369: dog - cat || Loss: 0.8584954738616943\n",
      "tensor([0., 1.]) tensor([0.5452, 0.4548], grad_fn=<SoftmaxBackward0>)\n",
      "=====epoch:3=====\n",
      "Epoch 3 - 0: cat - cat || Loss: 0.7689372897148132\n",
      "tensor([1., 0.]) tensor([0.5443, 0.4557], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 3 - 1: cat - cat || Loss: 0.7696647047996521\n",
      "tensor([1., 0.]) tensor([0.5436, 0.4564], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 3 - 2: cat - cat || Loss: 0.7702285051345825\n",
      "tensor([1., 0.]) tensor([0.5430, 0.4570], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 3 - 3: cat - cat || Loss: 0.7706446051597595\n",
      "tensor([1., 0.]) tensor([0.5426, 0.4574], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 3 - 4: cat - cat || Loss: 0.7709280848503113\n",
      "tensor([1., 0.]) tensor([0.5423, 0.4577], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 3 - 5: cat - cat || Loss: 0.7710922360420227\n",
      "tensor([1., 0.]) tensor([0.5422, 0.4578], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 3 - 6: cat - cat || Loss: 0.7711488008499146\n",
      "tensor([1., 0.]) tensor([0.5421, 0.4579], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 3 - 7: cat - cat || Loss: 0.7711086869239807\n",
      "tensor([1., 0.]) tensor([0.5422, 0.4578], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 3 - 8: cat - cat || Loss: 0.7709814310073853\n",
      "tensor([1., 0.]) tensor([0.5423, 0.4577], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 3 - 9: cat - cat || Loss: 0.7707762122154236\n",
      "tensor([1., 0.]) tensor([0.5425, 0.4575], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 3 - 10: cat - cat || Loss: 0.7705000638961792\n",
      "tensor([1., 0.]) tensor([0.5428, 0.4572], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 3 - 11: cat - cat || Loss: 0.7701608538627625\n",
      "tensor([1., 0.]) tensor([0.5431, 0.4569], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 3 - 12: cat - cat || Loss: 0.7697645425796509\n",
      "tensor([1., 0.]) tensor([0.5435, 0.4565], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 3 - 13: cat - cat || Loss: 0.7693167924880981\n",
      "tensor([1., 0.]) tensor([0.5439, 0.4561], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 3 - 14: cat - cat || Loss: 0.768822968006134\n",
      "tensor([1., 0.]) tensor([0.5444, 0.4556], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 3 - 15: cat - cat || Loss: 0.7682873606681824\n",
      "tensor([1., 0.]) tensor([0.5450, 0.4550], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 3 - 16: cat - cat || Loss: 0.7677145004272461\n",
      "tensor([1., 0.]) tensor([0.5455, 0.4545], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 3 - 17: cat - cat || Loss: 0.7671080827713013\n",
      "tensor([1., 0.]) tensor([0.5462, 0.4538], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 3 - 18: cat - cat || Loss: 0.7664713859558105\n",
      "tensor([1., 0.]) tensor([0.5468, 0.4532], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 3 - 19: cat - cat || Loss: 0.765807569026947\n",
      "tensor([1., 0.]) tensor([0.5475, 0.4525], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 3 - 20: cat - cat || Loss: 0.7651192545890808\n",
      "tensor([1., 0.]) tensor([0.5481, 0.4519], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 3 - 21: cat - cat || Loss: 0.7644090056419373\n",
      "tensor([1., 0.]) tensor([0.5489, 0.4511], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 3 - 22: cat - cat || Loss: 0.7636789679527283\n",
      "tensor([1., 0.]) tensor([0.5496, 0.4504], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 3 - 23: cat - cat || Loss: 0.7629311084747314\n",
      "tensor([1., 0.]) tensor([0.5503, 0.4497], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 3 - 24: cat - cat || Loss: 0.7621673941612244\n",
      "tensor([1., 0.]) tensor([0.5511, 0.4489], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 3 - 25: cat - cat || Loss: 0.7613891363143921\n",
      "tensor([1., 0.]) tensor([0.5519, 0.4481], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 3 - 26: cat - cat || Loss: 0.7605983018875122\n",
      "tensor([1., 0.]) tensor([0.5527, 0.4473], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 3 - 27: cat - cat || Loss: 0.7597956657409668\n",
      "tensor([1., 0.]) tensor([0.5535, 0.4465], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 3 - 28: cat - cat || Loss: 0.7589825391769409\n",
      "tensor([1., 0.]) tensor([0.5543, 0.4457], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 3 - 29: cat - cat || Loss: 0.7581602334976196\n",
      "tensor([1., 0.]) tensor([0.5551, 0.4449], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 3 - 30: cat - cat || Loss: 0.7573294639587402\n",
      "tensor([1., 0.]) tensor([0.5559, 0.4441], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 3 - 31: cat - cat || Loss: 0.7564912438392639\n",
      "tensor([1., 0.]) tensor([0.5568, 0.4432], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 3 - 32: cat - cat || Loss: 0.7556464076042175\n",
      "tensor([1., 0.]) tensor([0.5576, 0.4424], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 3 - 33: cat - cat || Loss: 0.7547956705093384\n",
      "tensor([1., 0.]) tensor([0.5585, 0.4415], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 3 - 34: cat - cat || Loss: 0.7539394497871399\n",
      "tensor([1., 0.]) tensor([0.5593, 0.4407], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 3 - 35: cat - cat || Loss: 0.7530785202980042\n",
      "tensor([1., 0.]) tensor([0.5602, 0.4398], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 3 - 36: cat - cat || Loss: 0.7522133588790894\n",
      "tensor([1., 0.]) tensor([0.5610, 0.4390], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 3 - 37: cat - cat || Loss: 0.7513442039489746\n",
      "tensor([1., 0.]) tensor([0.5619, 0.4381], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 3 - 38: cat - cat || Loss: 0.7504714727401733\n",
      "tensor([1., 0.]) tensor([0.5628, 0.4372], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 3 - 39: cat - cat || Loss: 0.7495957612991333\n",
      "tensor([1., 0.]) tensor([0.5637, 0.4363], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 3 - 40: cat - cat || Loss: 0.7487173676490784\n",
      "tensor([1., 0.]) tensor([0.5645, 0.4355], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 3 - 41: cat - cat || Loss: 0.747836172580719\n",
      "tensor([1., 0.]) tensor([0.5654, 0.4346], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 3 - 42: cat - cat || Loss: 0.7469529509544373\n",
      "tensor([1., 0.]) tensor([0.5663, 0.4337], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 3 - 43: cat - cat || Loss: 0.746067464351654\n",
      "tensor([1., 0.]) tensor([0.5672, 0.4328], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 3 - 44: cat - cat || Loss: 0.7451807260513306\n",
      "tensor([1., 0.]) tensor([0.5681, 0.4319], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 3 - 45: cat - cat || Loss: 0.744292140007019\n",
      "tensor([1., 0.]) tensor([0.5690, 0.4310], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 3 - 46: cat - cat || Loss: 0.7434022426605225\n",
      "tensor([1., 0.]) tensor([0.5699, 0.4301], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 3 - 47: cat - cat || Loss: 0.7425110340118408\n",
      "tensor([1., 0.]) tensor([0.5708, 0.4292], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 3 - 48: cat - cat || Loss: 0.7416189312934875\n",
      "tensor([1., 0.]) tensor([0.5716, 0.4284], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 3 - 49: cat - cat || Loss: 0.7407257556915283\n",
      "tensor([1., 0.]) tensor([0.5725, 0.4275], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 3 - 50: cat - cat || Loss: 0.7398315668106079\n",
      "tensor([1., 0.]) tensor([0.5734, 0.4266], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 3 - 51: cat - cat || Loss: 0.7389368414878845\n",
      "tensor([1., 0.]) tensor([0.5743, 0.4257], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 3 - 52: cat - cat || Loss: 0.7380414009094238\n",
      "tensor([1., 0.]) tensor([0.5752, 0.4248], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 3 - 53: cat - cat || Loss: 0.7371453046798706\n",
      "tensor([1., 0.]) tensor([0.5761, 0.4239], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 3 - 54: cat - cat || Loss: 0.7362488508224487\n",
      "tensor([1., 0.]) tensor([0.5770, 0.4230], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 3 - 55: cat - cat || Loss: 0.7353519797325134\n",
      "tensor([1., 0.]) tensor([0.5779, 0.4221], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 3 - 56: cat - cat || Loss: 0.7344549298286438\n",
      "tensor([1., 0.]) tensor([0.5788, 0.4212], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 3 - 57: cat - cat || Loss: 0.7335574626922607\n",
      "tensor([1., 0.]) tensor([0.5797, 0.4203], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 3 - 58: cat - cat || Loss: 0.7326599359512329\n",
      "tensor([1., 0.]) tensor([0.5806, 0.4194], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 3 - 59: cat - cat || Loss: 0.7317622900009155\n",
      "tensor([1., 0.]) tensor([0.5815, 0.4185], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 3 - 60: cat - cat || Loss: 0.730864405632019\n",
      "tensor([1., 0.]) tensor([0.5824, 0.4176], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 3 - 61: cat - cat || Loss: 0.7299664616584778\n",
      "tensor([1., 0.]) tensor([0.5833, 0.4167], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 3 - 62: cat - cat || Loss: 0.729068398475647\n",
      "tensor([1., 0.]) tensor([0.5842, 0.4158], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 3 - 63: cat - cat || Loss: 0.7281703948974609\n",
      "tensor([1., 0.]) tensor([0.5851, 0.4149], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 3 - 64: cat - cat || Loss: 0.7272724509239197\n",
      "tensor([1., 0.]) tensor([0.5860, 0.4140], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 3 - 65: cat - cat || Loss: 0.7263747453689575\n",
      "tensor([1., 0.]) tensor([0.5869, 0.4131], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 3 - 66: cat - cat || Loss: 0.725476861000061\n",
      "tensor([1., 0.]) tensor([0.5878, 0.4122], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 3 - 67: cat - cat || Loss: 0.7245793342590332\n",
      "tensor([1., 0.]) tensor([0.5887, 0.4113], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 3 - 68: cat - cat || Loss: 0.723681628704071\n",
      "tensor([1., 0.]) tensor([0.5896, 0.4104], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 3 - 69: cat - cat || Loss: 0.722784161567688\n",
      "tensor([1., 0.]) tensor([0.5905, 0.4095], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 3 - 70: cat - cat || Loss: 0.7218867540359497\n",
      "tensor([1., 0.]) tensor([0.5914, 0.4086], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 3 - 71: cat - cat || Loss: 0.7209895849227905\n",
      "tensor([1., 0.]) tensor([0.5923, 0.4077], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 3 - 72: cat - cat || Loss: 0.7200924158096313\n",
      "tensor([1., 0.]) tensor([0.5932, 0.4068], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 3 - 73: cat - cat || Loss: 0.7191954255104065\n",
      "tensor([1., 0.]) tensor([0.5941, 0.4059], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 3 - 74: cat - cat || Loss: 0.7182985544204712\n",
      "tensor([1., 0.]) tensor([0.5950, 0.4050], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 3 - 75: cat - cat || Loss: 0.7174019813537598\n",
      "tensor([1., 0.]) tensor([0.5959, 0.4041], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 3 - 76: cat - cat || Loss: 0.716505765914917\n",
      "tensor([1., 0.]) tensor([0.5968, 0.4032], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 3 - 77: cat - cat || Loss: 0.715609610080719\n",
      "tensor([1., 0.]) tensor([0.5977, 0.4023], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 3 - 78: cat - cat || Loss: 0.7147137522697449\n",
      "tensor([1., 0.]) tensor([0.5985, 0.4015], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 3 - 79: cat - cat || Loss: 0.7138180136680603\n",
      "tensor([1., 0.]) tensor([0.5994, 0.4006], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 3 - 80: cat - cat || Loss: 0.7129228115081787\n",
      "tensor([1., 0.]) tensor([0.6003, 0.3997], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 3 - 81: cat - cat || Loss: 0.7120275497436523\n",
      "tensor([1., 0.]) tensor([0.6012, 0.3988], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 3 - 82: cat - cat || Loss: 0.711132824420929\n",
      "tensor([1., 0.]) tensor([0.6021, 0.3979], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 3 - 83: cat - cat || Loss: 0.7102382779121399\n",
      "tensor([1., 0.]) tensor([0.6030, 0.3970], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 3 - 84: cat - cat || Loss: 0.7093440294265747\n",
      "tensor([1., 0.]) tensor([0.6039, 0.3961], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 3 - 85: cat - cat || Loss: 0.7084500789642334\n",
      "tensor([1., 0.]) tensor([0.6048, 0.3952], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 3 - 86: cat - cat || Loss: 0.7075563669204712\n",
      "tensor([1., 0.]) tensor([0.6057, 0.3943], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 3 - 87: cat - cat || Loss: 0.7066628932952881\n",
      "tensor([1., 0.]) tensor([0.6066, 0.3934], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 3 - 88: cat - cat || Loss: 0.7057696580886841\n",
      "tensor([1., 0.]) tensor([0.6075, 0.3925], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 3 - 89: cat - cat || Loss: 0.7048766613006592\n",
      "tensor([1., 0.]) tensor([0.6084, 0.3916], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 3 - 90: cat - cat || Loss: 0.7039840221405029\n",
      "tensor([1., 0.]) tensor([0.6093, 0.3907], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 3 - 91: cat - cat || Loss: 0.7030915021896362\n",
      "tensor([1., 0.]) tensor([0.6102, 0.3898], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 3 - 92: cat - cat || Loss: 0.7021992206573486\n",
      "tensor([1., 0.]) tensor([0.6111, 0.3889], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 3 - 93: cat - cat || Loss: 0.7013071775436401\n",
      "tensor([1., 0.]) tensor([0.6120, 0.3880], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 3 - 94: cat - cat || Loss: 0.7004154324531555\n",
      "tensor([1., 0.]) tensor([0.6128, 0.3872], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 3 - 95: cat - cat || Loss: 0.6995238661766052\n",
      "tensor([1., 0.]) tensor([0.6137, 0.3863], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 3 - 96: cat - cat || Loss: 0.6986326575279236\n",
      "tensor([1., 0.]) tensor([0.6146, 0.3854], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 3 - 97: cat - cat || Loss: 0.6977417469024658\n",
      "tensor([1., 0.]) tensor([0.6155, 0.3845], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 3 - 98: cat - cat || Loss: 0.6968510746955872\n",
      "tensor([1., 0.]) tensor([0.6164, 0.3836], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 3 - 99: cat - cat || Loss: 0.6959607005119324\n",
      "tensor([1., 0.]) tensor([0.6173, 0.3827], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 3 - 100: cat - cat || Loss: 0.6950706243515015\n",
      "tensor([1., 0.]) tensor([0.6182, 0.3818], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 3 - 101: cat - cat || Loss: 0.694180965423584\n",
      "tensor([1., 0.]) tensor([0.6191, 0.3809], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 3 - 102: cat - cat || Loss: 0.6932914853096008\n",
      "tensor([1., 0.]) tensor([0.6200, 0.3800], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 3 - 103: cat - cat || Loss: 0.6924024224281311\n",
      "tensor([1., 0.]) tensor([0.6209, 0.3791], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 3 - 104: cat - cat || Loss: 0.6915137767791748\n",
      "tensor([1., 0.]) tensor([0.6217, 0.3783], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 3 - 105: cat - cat || Loss: 0.6906255483627319\n",
      "tensor([1., 0.]) tensor([0.6226, 0.3774], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 3 - 106: cat - cat || Loss: 0.6897376179695129\n",
      "tensor([1., 0.]) tensor([0.6235, 0.3765], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 3 - 107: cat - cat || Loss: 0.6888499855995178\n",
      "tensor([1., 0.]) tensor([0.6244, 0.3756], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 3 - 108: cat - cat || Loss: 0.6879627704620361\n",
      "tensor([1., 0.]) tensor([0.6253, 0.3747], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 3 - 109: cat - cat || Loss: 0.6870759725570679\n",
      "tensor([1., 0.]) tensor([0.6262, 0.3738], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 3 - 110: cat - cat || Loss: 0.6861892342567444\n",
      "tensor([1., 0.]) tensor([0.6271, 0.3729], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 3 - 111: cat - cat || Loss: 0.6853030920028687\n",
      "tensor([1., 0.]) tensor([0.6280, 0.3720], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 3 - 112: cat - cat || Loss: 0.6844172477722168\n",
      "tensor([1., 0.]) tensor([0.6288, 0.3712], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 3 - 113: cat - cat || Loss: 0.6835319399833679\n",
      "tensor([1., 0.]) tensor([0.6297, 0.3703], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 3 - 114: cat - cat || Loss: 0.6826466917991638\n",
      "tensor([1., 0.]) tensor([0.6306, 0.3694], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 3 - 115: cat - cat || Loss: 0.6817619800567627\n",
      "tensor([1., 0.]) tensor([0.6315, 0.3685], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 3 - 116: cat - cat || Loss: 0.6808775663375854\n",
      "tensor([1., 0.]) tensor([0.6324, 0.3676], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 3 - 117: cat - cat || Loss: 0.6799935698509216\n",
      "tensor([1., 0.]) tensor([0.6333, 0.3667], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 3 - 118: cat - cat || Loss: 0.6791098117828369\n",
      "tensor([1., 0.]) tensor([0.6342, 0.3658], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 3 - 119: cat - cat || Loss: 0.6782265901565552\n",
      "tensor([1., 0.]) tensor([0.6350, 0.3650], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 3 - 120: cat - cat || Loss: 0.6773436665534973\n",
      "tensor([1., 0.]) tensor([0.6359, 0.3641], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 3 - 121: cat - cat || Loss: 0.6764609813690186\n",
      "tensor([1., 0.]) tensor([0.6368, 0.3632], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 3 - 122: cat - cat || Loss: 0.6755787134170532\n",
      "tensor([1., 0.]) tensor([0.6377, 0.3623], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 3 - 123: cat - cat || Loss: 0.6746968030929565\n",
      "tensor([1., 0.]) tensor([0.6386, 0.3614], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 3 - 124: cat - cat || Loss: 0.6738153100013733\n",
      "tensor([1., 0.]) tensor([0.6394, 0.3606], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 3 - 125: cat - cat || Loss: 0.6729342937469482\n",
      "tensor([1., 0.]) tensor([0.6403, 0.3597], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 3 - 126: cat - cat || Loss: 0.6720535755157471\n",
      "tensor([1., 0.]) tensor([0.6412, 0.3588], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 3 - 127: cat - cat || Loss: 0.6711731553077698\n",
      "tensor([1., 0.]) tensor([0.6421, 0.3579], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 3 - 128: cat - cat || Loss: 0.6702933311462402\n",
      "tensor([1., 0.]) tensor([0.6430, 0.3570], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 3 - 129: cat - cat || Loss: 0.6694138050079346\n",
      "tensor([1., 0.]) tensor([0.6438, 0.3562], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 3 - 130: cat - cat || Loss: 0.6685347557067871\n",
      "tensor([1., 0.]) tensor([0.6447, 0.3553], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 3 - 131: cat - cat || Loss: 0.6676560640335083\n",
      "tensor([1., 0.]) tensor([0.6456, 0.3544], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 3 - 132: cat - cat || Loss: 0.6667777895927429\n",
      "tensor([1., 0.]) tensor([0.6465, 0.3535], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 3 - 133: cat - cat || Loss: 0.6658998131752014\n",
      "tensor([1., 0.]) tensor([0.6474, 0.3526], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 3 - 134: cat - cat || Loss: 0.6650221943855286\n",
      "tensor([1., 0.]) tensor([0.6482, 0.3518], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 3 - 135: cat - cat || Loss: 0.6641451120376587\n",
      "tensor([1., 0.]) tensor([0.6491, 0.3509], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 3 - 136: cat - cat || Loss: 0.6632684469223022\n",
      "tensor([1., 0.]) tensor([0.6500, 0.3500], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 3 - 137: cat - cat || Loss: 0.6623921394348145\n",
      "tensor([1., 0.]) tensor([0.6509, 0.3491], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 3 - 138: cat - cat || Loss: 0.6615163683891296\n",
      "tensor([1., 0.]) tensor([0.6517, 0.3483], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 3 - 139: cat - cat || Loss: 0.6606410145759583\n",
      "tensor([1., 0.]) tensor([0.6526, 0.3474], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 3 - 140: cat - cat || Loss: 0.6597660183906555\n",
      "tensor([1., 0.]) tensor([0.6535, 0.3465], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 3 - 141: cat - cat || Loss: 0.6588915586471558\n",
      "tensor([1., 0.]) tensor([0.6544, 0.3456], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 3 - 142: cat - cat || Loss: 0.6580175161361694\n",
      "tensor([1., 0.]) tensor([0.6552, 0.3448], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 3 - 143: cat - cat || Loss: 0.657143771648407\n",
      "tensor([1., 0.]) tensor([0.6561, 0.3439], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 3 - 144: cat - cat || Loss: 0.6562707424163818\n",
      "tensor([1., 0.]) tensor([0.6570, 0.3430], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 3 - 145: cat - cat || Loss: 0.655397891998291\n",
      "tensor([1., 0.]) tensor([0.6579, 0.3421], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 3 - 146: cat - cat || Loss: 0.6545257568359375\n",
      "tensor([1., 0.]) tensor([0.6587, 0.3413], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 3 - 147: cat - cat || Loss: 0.6536539793014526\n",
      "tensor([1., 0.]) tensor([0.6596, 0.3404], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 3 - 148: cat - cat || Loss: 0.6527825593948364\n",
      "tensor([1., 0.]) tensor([0.6605, 0.3395], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 3 - 149: cat - cat || Loss: 0.6519116163253784\n",
      "tensor([1., 0.]) tensor([0.6613, 0.3386], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 3 - 150: cat - cat || Loss: 0.6510409712791443\n",
      "tensor([1., 0.]) tensor([0.6622, 0.3378], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 3 - 151: cat - cat || Loss: 0.6501709818840027\n",
      "tensor([1., 0.]) tensor([0.6631, 0.3369], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 3 - 152: cat - cat || Loss: 0.649301290512085\n",
      "tensor([1., 0.]) tensor([0.6640, 0.3360], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 3 - 153: cat - cat || Loss: 0.6484321355819702\n",
      "tensor([1., 0.]) tensor([0.6648, 0.3352], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 3 - 154: cat - cat || Loss: 0.6475632786750793\n",
      "tensor([1., 0.]) tensor([0.6657, 0.3343], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 3 - 155: cat - cat || Loss: 0.646695077419281\n",
      "tensor([1., 0.]) tensor([0.6666, 0.3334], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 3 - 156: cat - cat || Loss: 0.6458272337913513\n",
      "tensor([1., 0.]) tensor([0.6674, 0.3326], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 3 - 157: cat - cat || Loss: 0.6449599266052246\n",
      "tensor([1., 0.]) tensor([0.6683, 0.3317], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 3 - 158: cat - cat || Loss: 0.6440929770469666\n",
      "tensor([1., 0.]) tensor([0.6692, 0.3308], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 3 - 159: cat - cat || Loss: 0.6432265043258667\n",
      "tensor([1., 0.]) tensor([0.6700, 0.3300], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 3 - 160: cat - cat || Loss: 0.6423605680465698\n",
      "tensor([1., 0.]) tensor([0.6709, 0.3291], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 3 - 161: cat - cat || Loss: 0.6414951086044312\n",
      "tensor([1., 0.]) tensor([0.6718, 0.3282], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 3 - 162: cat - cat || Loss: 0.6406303644180298\n",
      "tensor([1., 0.]) tensor([0.6726, 0.3274], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 3 - 163: cat - cat || Loss: 0.6397657990455627\n",
      "tensor([1., 0.]) tensor([0.6735, 0.3265], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 3 - 164: cat - cat || Loss: 0.6389017701148987\n",
      "tensor([1., 0.]) tensor([0.6744, 0.3256], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 3 - 165: cat - cat || Loss: 0.6380382776260376\n",
      "tensor([1., 0.]) tensor([0.6752, 0.3248], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 3 - 166: cat - cat || Loss: 0.6371751427650452\n",
      "tensor([1., 0.]) tensor([0.6761, 0.3239], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 3 - 167: cat - cat || Loss: 0.6363126039505005\n",
      "tensor([1., 0.]) tensor([0.6769, 0.3231], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 3 - 168: cat - cat || Loss: 0.6354507207870483\n",
      "tensor([1., 0.]) tensor([0.6778, 0.3222], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 3 - 169: cat - cat || Loss: 0.6345891952514648\n",
      "tensor([1., 0.]) tensor([0.6787, 0.3213], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 3 - 170: cat - cat || Loss: 0.6337281465530396\n",
      "tensor([1., 0.]) tensor([0.6795, 0.3205], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 3 - 171: cat - cat || Loss: 0.6328678727149963\n",
      "tensor([1., 0.]) tensor([0.6804, 0.3196], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 3 - 172: cat - cat || Loss: 0.6320079565048218\n",
      "tensor([1., 0.]) tensor([0.6813, 0.3187], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 3 - 173: cat - cat || Loss: 0.6311486959457397\n",
      "tensor([1., 0.]) tensor([0.6821, 0.3179], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 3 - 174: cat - cat || Loss: 0.6302898526191711\n",
      "tensor([1., 0.]) tensor([0.6830, 0.3170], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 3 - 175: cat - cat || Loss: 0.629431426525116\n",
      "tensor([1., 0.]) tensor([0.6838, 0.3162], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 3 - 176: cat - cat || Loss: 0.628573477268219\n",
      "tensor([1., 0.]) tensor([0.6847, 0.3153], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 3 - 177: cat - cat || Loss: 0.6277161836624146\n",
      "tensor([1., 0.]) tensor([0.6855, 0.3145], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 3 - 178: cat - cat || Loss: 0.6268592476844788\n",
      "tensor([1., 0.]) tensor([0.6864, 0.3136], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 3 - 179: cat - cat || Loss: 0.6260029673576355\n",
      "tensor([1., 0.]) tensor([0.6873, 0.3127], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 3 - 180: cat - cat || Loss: 0.6251472234725952\n",
      "tensor([1., 0.]) tensor([0.6881, 0.3119], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 3 - 181: cat - cat || Loss: 0.6242919564247131\n",
      "tensor([1., 0.]) tensor([0.6890, 0.3110], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 3 - 182: cat - cat || Loss: 0.6234372854232788\n",
      "tensor([1., 0.]) tensor([0.6898, 0.3102], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 3 - 183: cat - cat || Loss: 0.622583270072937\n",
      "tensor([1., 0.]) tensor([0.6907, 0.3093], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 3 - 184: cat - cat || Loss: 0.6217296719551086\n",
      "tensor([1., 0.]) tensor([0.6915, 0.3085], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 3 - 185: cat - cat || Loss: 0.6208767890930176\n",
      "tensor([1., 0.]) tensor([0.6924, 0.3076], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 3 - 186: cat - cat || Loss: 0.6200243234634399\n",
      "tensor([1., 0.]) tensor([0.6932, 0.3068], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 3 - 187: cat - cat || Loss: 0.6191725730895996\n",
      "tensor([1., 0.]) tensor([0.6941, 0.3059], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 3 - 188: cat - cat || Loss: 0.6183215379714966\n",
      "tensor([1., 0.]) tensor([0.6949, 0.3051], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 3 - 189: cat - cat || Loss: 0.6174710392951965\n",
      "tensor([1., 0.]) tensor([0.6958, 0.3042], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 3 - 190: dog - cat || Loss: 1.0099021196365356\n",
      "tensor([0., 1.]) tensor([0.6966, 0.3034], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 3 - 191: dog - cat || Loss: 1.0105819702148438\n",
      "tensor([0., 1.]) tensor([0.6973, 0.3027], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 3 - 192: dog - cat || Loss: 1.0111087560653687\n",
      "tensor([0., 1.]) tensor([0.6978, 0.3022], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 3 - 193: dog - cat || Loss: 1.0114980936050415\n",
      "tensor([0., 1.]) tensor([0.6982, 0.3018], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 3 - 194: dog - cat || Loss: 1.0117636919021606\n",
      "tensor([0., 1.]) tensor([0.6985, 0.3015], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 3 - 195: dog - cat || Loss: 1.0119181871414185\n",
      "tensor([0., 1.]) tensor([0.6987, 0.3013], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 3 - 196: dog - cat || Loss: 1.0119729042053223\n",
      "tensor([0., 1.]) tensor([0.6987, 0.3013], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 3 - 197: dog - cat || Loss: 1.0119372606277466\n",
      "tensor([0., 1.]) tensor([0.6987, 0.3013], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 3 - 198: dog - cat || Loss: 1.0118207931518555\n",
      "tensor([0., 1.]) tensor([0.6986, 0.3014], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 3 - 199: dog - cat || Loss: 1.0116312503814697\n",
      "tensor([0., 1.]) tensor([0.6984, 0.3016], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 3 - 200: dog - cat || Loss: 1.011376142501831\n",
      "tensor([0., 1.]) tensor([0.6981, 0.3019], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 3 - 201: dog - cat || Loss: 1.0110620260238647\n",
      "tensor([0., 1.]) tensor([0.6978, 0.3022], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 3 - 202: dog - cat || Loss: 1.0106947422027588\n",
      "tensor([0., 1.]) tensor([0.6974, 0.3026], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 3 - 203: dog - cat || Loss: 1.0102794170379639\n",
      "tensor([0., 1.]) tensor([0.6970, 0.3030], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 3 - 204: dog - cat || Loss: 1.0098210573196411\n",
      "tensor([0., 1.]) tensor([0.6966, 0.3034], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 3 - 205: dog - cat || Loss: 1.0093234777450562\n",
      "tensor([0., 1.]) tensor([0.6961, 0.3039], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 3 - 206: dog - cat || Loss: 1.0087910890579224\n",
      "tensor([0., 1.]) tensor([0.6955, 0.3045], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 3 - 207: dog - cat || Loss: 1.0082272291183472\n",
      "tensor([0., 1.]) tensor([0.6950, 0.3050], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 3 - 208: dog - cat || Loss: 1.0076345205307007\n",
      "tensor([0., 1.]) tensor([0.6944, 0.3056], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 3 - 209: dog - cat || Loss: 1.0070164203643799\n",
      "tensor([0., 1.]) tensor([0.6938, 0.3062], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 3 - 210: dog - cat || Loss: 1.0063750743865967\n",
      "tensor([0., 1.]) tensor([0.6931, 0.3069], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 3 - 211: dog - cat || Loss: 1.005712866783142\n",
      "tensor([0., 1.]) tensor([0.6925, 0.3075], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 3 - 212: dog - cat || Loss: 1.005031943321228\n",
      "tensor([0., 1.]) tensor([0.6918, 0.3082], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 3 - 213: dog - cat || Loss: 1.004333734512329\n",
      "tensor([0., 1.]) tensor([0.6911, 0.3089], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 3 - 214: dog - cat || Loss: 1.0036205053329468\n",
      "tensor([0., 1.]) tensor([0.6904, 0.3096], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 3 - 215: dog - cat || Loss: 1.002893328666687\n",
      "tensor([0., 1.]) tensor([0.6896, 0.3104], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 3 - 216: dog - cat || Loss: 1.0021536350250244\n",
      "tensor([0., 1.]) tensor([0.6889, 0.3111], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 3 - 217: dog - cat || Loss: 1.001402735710144\n",
      "tensor([0., 1.]) tensor([0.6881, 0.3119], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 3 - 218: dog - cat || Loss: 1.0006417036056519\n",
      "tensor([0., 1.]) tensor([0.6874, 0.3126], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 3 - 219: dog - cat || Loss: 0.999871551990509\n",
      "tensor([0., 1.]) tensor([0.6866, 0.3134], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 3 - 220: dog - cat || Loss: 0.9990927577018738\n",
      "tensor([0., 1.]) tensor([0.6858, 0.3142], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 3 - 221: dog - cat || Loss: 0.9983066916465759\n",
      "tensor([0., 1.]) tensor([0.6850, 0.3150], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 3 - 222: dog - cat || Loss: 0.9975137710571289\n",
      "tensor([0., 1.]) tensor([0.6843, 0.3157], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 3 - 223: dog - cat || Loss: 0.9967144131660461\n",
      "tensor([0., 1.]) tensor([0.6835, 0.3165], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 3 - 224: dog - cat || Loss: 0.995909571647644\n",
      "tensor([0., 1.]) tensor([0.6826, 0.3174], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 3 - 225: dog - cat || Loss: 0.9950996041297913\n",
      "tensor([0., 1.]) tensor([0.6818, 0.3182], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 3 - 226: dog - cat || Loss: 0.9942848682403564\n",
      "tensor([0., 1.]) tensor([0.6810, 0.3190], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 3 - 227: dog - cat || Loss: 0.9934660196304321\n",
      "tensor([0., 1.]) tensor([0.6802, 0.3198], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 3 - 228: dog - cat || Loss: 0.9926431775093079\n",
      "tensor([0., 1.]) tensor([0.6794, 0.3206], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 3 - 229: dog - cat || Loss: 0.991817057132721\n",
      "tensor([0., 1.]) tensor([0.6786, 0.3214], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 3 - 230: dog - cat || Loss: 0.9909874200820923\n",
      "tensor([0., 1.]) tensor([0.6777, 0.3223], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 3 - 231: dog - cat || Loss: 0.9901551604270935\n",
      "tensor([0., 1.]) tensor([0.6769, 0.3231], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 3 - 232: dog - cat || Loss: 0.989319920539856\n",
      "tensor([0., 1.]) tensor([0.6761, 0.3239], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 3 - 233: dog - cat || Loss: 0.9884825944900513\n",
      "tensor([0., 1.]) tensor([0.6752, 0.3248], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 3 - 234: dog - cat || Loss: 0.9876428842544556\n",
      "tensor([0., 1.]) tensor([0.6744, 0.3256], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 3 - 235: dog - cat || Loss: 0.9868011474609375\n",
      "tensor([0., 1.]) tensor([0.6735, 0.3265], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 3 - 236: dog - cat || Loss: 0.9859573841094971\n",
      "tensor([0., 1.]) tensor([0.6727, 0.3273], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 3 - 237: dog - cat || Loss: 0.9851117730140686\n",
      "tensor([0., 1.]) tensor([0.6719, 0.3281], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 3 - 238: dog - cat || Loss: 0.9842647314071655\n",
      "tensor([0., 1.]) tensor([0.6710, 0.3290], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 3 - 239: dog - cat || Loss: 0.9834158420562744\n",
      "tensor([0., 1.]) tensor([0.6702, 0.3298], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 3 - 240: dog - cat || Loss: 0.9825658798217773\n",
      "tensor([0., 1.]) tensor([0.6693, 0.3307], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 3 - 241: dog - cat || Loss: 0.9817144274711609\n",
      "tensor([0., 1.]) tensor([0.6685, 0.3315], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 3 - 242: dog - cat || Loss: 0.9808617830276489\n",
      "tensor([0., 1.]) tensor([0.6676, 0.3324], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 3 - 243: dog - cat || Loss: 0.980008065700531\n",
      "tensor([0., 1.]) tensor([0.6667, 0.3333], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 3 - 244: dog - cat || Loss: 0.9791535139083862\n",
      "tensor([0., 1.]) tensor([0.6659, 0.3341], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 3 - 245: dog - cat || Loss: 0.9782978892326355\n",
      "tensor([0., 1.]) tensor([0.6650, 0.3350], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 3 - 246: dog - cat || Loss: 0.9774412512779236\n",
      "tensor([0., 1.]) tensor([0.6642, 0.3358], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 3 - 247: dog - cat || Loss: 0.9765839576721191\n",
      "tensor([0., 1.]) tensor([0.6633, 0.3367], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 3 - 248: dog - cat || Loss: 0.9757257103919983\n",
      "tensor([0., 1.]) tensor([0.6625, 0.3375], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 3 - 249: dog - cat || Loss: 0.9748667478561401\n",
      "tensor([0., 1.]) tensor([0.6616, 0.3384], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 3 - 250: dog - cat || Loss: 0.9740071296691895\n",
      "tensor([0., 1.]) tensor([0.6607, 0.3393], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 3 - 251: dog - cat || Loss: 0.9731467962265015\n",
      "tensor([0., 1.]) tensor([0.6599, 0.3401], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 3 - 252: dog - cat || Loss: 0.9722858667373657\n",
      "tensor([0., 1.]) tensor([0.6590, 0.3410], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 3 - 253: dog - cat || Loss: 0.9714241027832031\n",
      "tensor([0., 1.]) tensor([0.6582, 0.3418], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 3 - 254: dog - cat || Loss: 0.970561683177948\n",
      "tensor([0., 1.]) tensor([0.6573, 0.3427], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 3 - 255: dog - cat || Loss: 0.9696990251541138\n",
      "tensor([0., 1.]) tensor([0.6564, 0.3436], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 3 - 256: dog - cat || Loss: 0.968835711479187\n",
      "tensor([0., 1.]) tensor([0.6556, 0.3444], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 3 - 257: dog - cat || Loss: 0.9679718017578125\n",
      "tensor([0., 1.]) tensor([0.6547, 0.3453], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 3 - 258: dog - cat || Loss: 0.9671075940132141\n",
      "tensor([0., 1.]) tensor([0.6538, 0.3462], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 3 - 259: dog - cat || Loss: 0.9662427306175232\n",
      "tensor([0., 1.]) tensor([0.6530, 0.3470], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 3 - 260: dog - cat || Loss: 0.9653773307800293\n",
      "tensor([0., 1.]) tensor([0.6521, 0.3479], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 3 - 261: dog - cat || Loss: 0.964511513710022\n",
      "tensor([0., 1.]) tensor([0.6512, 0.3488], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 3 - 262: dog - cat || Loss: 0.9636454582214355\n",
      "tensor([0., 1.]) tensor([0.6504, 0.3496], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 3 - 263: dog - cat || Loss: 0.9627787470817566\n",
      "tensor([0., 1.]) tensor([0.6495, 0.3505], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 3 - 264: dog - cat || Loss: 0.961911678314209\n",
      "tensor([0., 1.]) tensor([0.6486, 0.3514], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 3 - 265: dog - cat || Loss: 0.9610438942909241\n",
      "tensor([0., 1.]) tensor([0.6478, 0.3522], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 3 - 266: dog - cat || Loss: 0.9601759314537048\n",
      "tensor([0., 1.]) tensor([0.6469, 0.3531], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 3 - 267: dog - cat || Loss: 0.9593076705932617\n",
      "tensor([0., 1.]) tensor([0.6460, 0.3540], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 3 - 268: dog - cat || Loss: 0.9584386944770813\n",
      "tensor([0., 1.]) tensor([0.6452, 0.3548], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 3 - 269: dog - cat || Loss: 0.9575695395469666\n",
      "tensor([0., 1.]) tensor([0.6443, 0.3557], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 3 - 270: dog - cat || Loss: 0.9567000865936279\n",
      "tensor([0., 1.]) tensor([0.6434, 0.3566], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 3 - 271: dog - cat || Loss: 0.9558302760124207\n",
      "tensor([0., 1.]) tensor([0.6426, 0.3574], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 3 - 272: dog - cat || Loss: 0.9549599885940552\n",
      "tensor([0., 1.]) tensor([0.6417, 0.3583], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 3 - 273: dog - cat || Loss: 0.9540894627571106\n",
      "tensor([0., 1.]) tensor([0.6408, 0.3592], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 3 - 274: dog - cat || Loss: 0.9532186388969421\n",
      "tensor([0., 1.]) tensor([0.6400, 0.3600], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 3 - 275: dog - cat || Loss: 0.9523473381996155\n",
      "tensor([0., 1.]) tensor([0.6391, 0.3609], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 3 - 276: dog - cat || Loss: 0.9514756798744202\n",
      "tensor([0., 1.]) tensor([0.6382, 0.3618], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 3 - 277: dog - cat || Loss: 0.9506036639213562\n",
      "tensor([0., 1.]) tensor([0.6373, 0.3627], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 3 - 278: dog - cat || Loss: 0.9497315287590027\n",
      "tensor([0., 1.]) tensor([0.6365, 0.3635], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 3 - 279: dog - cat || Loss: 0.9488587975502014\n",
      "tensor([0., 1.]) tensor([0.6356, 0.3644], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 3 - 280: dog - cat || Loss: 0.9479857683181763\n",
      "tensor([0., 1.]) tensor([0.6347, 0.3653], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 3 - 281: dog - cat || Loss: 0.9471123814582825\n",
      "tensor([0., 1.]) tensor([0.6339, 0.3661], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 3 - 282: dog - cat || Loss: 0.9462389349937439\n",
      "tensor([0., 1.]) tensor([0.6330, 0.3670], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 3 - 283: dog - cat || Loss: 0.9453649520874023\n",
      "tensor([0., 1.]) tensor([0.6321, 0.3679], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 3 - 284: dog - cat || Loss: 0.9444905519485474\n",
      "tensor([0., 1.]) tensor([0.6312, 0.3688], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 3 - 285: dog - cat || Loss: 0.9436160326004028\n",
      "tensor([0., 1.]) tensor([0.6304, 0.3696], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 3 - 286: dog - cat || Loss: 0.942741334438324\n",
      "tensor([0., 1.]) tensor([0.6295, 0.3705], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 3 - 287: dog - cat || Loss: 0.9418661594390869\n",
      "tensor([0., 1.]) tensor([0.6286, 0.3714], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 3 - 288: dog - cat || Loss: 0.9409908056259155\n",
      "tensor([0., 1.]) tensor([0.6277, 0.3723], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 3 - 289: dog - cat || Loss: 0.9401149749755859\n",
      "tensor([0., 1.]) tensor([0.6269, 0.3731], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 3 - 290: dog - cat || Loss: 0.9392390251159668\n",
      "tensor([0., 1.]) tensor([0.6260, 0.3740], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 3 - 291: dog - cat || Loss: 0.9383626580238342\n",
      "tensor([0., 1.]) tensor([0.6251, 0.3749], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 3 - 292: dog - cat || Loss: 0.937485933303833\n",
      "tensor([0., 1.]) tensor([0.6242, 0.3758], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 3 - 293: dog - cat || Loss: 0.9366090297698975\n",
      "tensor([0., 1.]) tensor([0.6233, 0.3767], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 3 - 294: dog - cat || Loss: 0.9357317090034485\n",
      "tensor([0., 1.]) tensor([0.6225, 0.3775], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 3 - 295: dog - cat || Loss: 0.9348543882369995\n",
      "tensor([0., 1.]) tensor([0.6216, 0.3784], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 3 - 296: dog - cat || Loss: 0.9339767098426819\n",
      "tensor([0., 1.]) tensor([0.6207, 0.3793], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 3 - 297: dog - cat || Loss: 0.9330988526344299\n",
      "tensor([0., 1.]) tensor([0.6198, 0.3802], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 3 - 298: dog - cat || Loss: 0.9322206377983093\n",
      "tensor([0., 1.]) tensor([0.6190, 0.3810], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 3 - 299: dog - cat || Loss: 0.9313421845436096\n",
      "tensor([0., 1.]) tensor([0.6181, 0.3819], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 3 - 300: dog - cat || Loss: 0.930463433265686\n",
      "tensor([0., 1.]) tensor([0.6172, 0.3828], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 3 - 301: dog - cat || Loss: 0.9295846819877625\n",
      "tensor([0., 1.]) tensor([0.6163, 0.3837], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 3 - 302: dog - cat || Loss: 0.9287055730819702\n",
      "tensor([0., 1.]) tensor([0.6154, 0.3846], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 3 - 303: dog - cat || Loss: 0.9278258681297302\n",
      "tensor([0., 1.]) tensor([0.6146, 0.3854], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 3 - 304: dog - cat || Loss: 0.926946222782135\n",
      "tensor([0., 1.]) tensor([0.6137, 0.3863], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 3 - 305: dog - cat || Loss: 0.926065981388092\n",
      "tensor([0., 1.]) tensor([0.6128, 0.3872], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 3 - 306: dog - cat || Loss: 0.9251857995986938\n",
      "tensor([0., 1.]) tensor([0.6119, 0.3881], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 3 - 307: dog - cat || Loss: 0.9243052005767822\n",
      "tensor([0., 1.]) tensor([0.6110, 0.3890], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 3 - 308: dog - cat || Loss: 0.9234243035316467\n",
      "tensor([0., 1.]) tensor([0.6102, 0.3898], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 3 - 309: dog - cat || Loss: 0.9225432872772217\n",
      "tensor([0., 1.]) tensor([0.6093, 0.3907], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 3 - 310: dog - cat || Loss: 0.921661913394928\n",
      "tensor([0., 1.]) tensor([0.6084, 0.3916], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 3 - 311: dog - cat || Loss: 0.9207801818847656\n",
      "tensor([0., 1.]) tensor([0.6075, 0.3925], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 3 - 312: dog - cat || Loss: 0.9198983311653137\n",
      "tensor([0., 1.]) tensor([0.6066, 0.3934], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 3 - 313: dog - cat || Loss: 0.9190162420272827\n",
      "tensor([0., 1.]) tensor([0.6058, 0.3942], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 3 - 314: dog - cat || Loss: 0.9181337356567383\n",
      "tensor([0., 1.]) tensor([0.6049, 0.3951], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 3 - 315: dog - cat || Loss: 0.9172510504722595\n",
      "tensor([0., 1.]) tensor([0.6040, 0.3960], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 3 - 316: dog - cat || Loss: 0.9163680672645569\n",
      "tensor([0., 1.]) tensor([0.6031, 0.3969], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 3 - 317: dog - cat || Loss: 0.9154850244522095\n",
      "tensor([0., 1.]) tensor([0.6022, 0.3978], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 3 - 318: dog - cat || Loss: 0.9146016836166382\n",
      "tensor([0., 1.]) tensor([0.6013, 0.3987], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 3 - 319: dog - cat || Loss: 0.9137181639671326\n",
      "tensor([0., 1.]) tensor([0.6005, 0.3995], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 3 - 320: dog - cat || Loss: 0.9128344058990479\n",
      "tensor([0., 1.]) tensor([0.5996, 0.4004], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 3 - 321: dog - cat || Loss: 0.9119504690170288\n",
      "tensor([0., 1.]) tensor([0.5987, 0.4013], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 3 - 322: dog - cat || Loss: 0.9110664129257202\n",
      "tensor([0., 1.]) tensor([0.5978, 0.4022], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 3 - 323: dog - cat || Loss: 0.9101818799972534\n",
      "tensor([0., 1.]) tensor([0.5969, 0.4031], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 3 - 324: dog - cat || Loss: 0.9092973470687866\n",
      "tensor([0., 1.]) tensor([0.5960, 0.4040], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 3 - 325: dog - cat || Loss: 0.9084125757217407\n",
      "tensor([0., 1.]) tensor([0.5952, 0.4048], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 3 - 326: dog - cat || Loss: 0.9075274467468262\n",
      "tensor([0., 1.]) tensor([0.5943, 0.4057], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 3 - 327: dog - cat || Loss: 0.9066421389579773\n",
      "tensor([0., 1.]) tensor([0.5934, 0.4066], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 3 - 328: dog - cat || Loss: 0.9057567119598389\n",
      "tensor([0., 1.]) tensor([0.5925, 0.4075], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 3 - 329: dog - cat || Loss: 0.9048711061477661\n",
      "tensor([0., 1.]) tensor([0.5916, 0.4084], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 3 - 330: dog - cat || Loss: 0.9039852023124695\n",
      "tensor([0., 1.]) tensor([0.5907, 0.4093], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 3 - 331: dog - cat || Loss: 0.9030991792678833\n",
      "tensor([0., 1.]) tensor([0.5898, 0.4102], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 3 - 332: dog - cat || Loss: 0.9022129774093628\n",
      "tensor([0., 1.]) tensor([0.5890, 0.4110], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 3 - 333: dog - cat || Loss: 0.9013264179229736\n",
      "tensor([0., 1.]) tensor([0.5881, 0.4119], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 3 - 334: dog - cat || Loss: 0.9004398584365845\n",
      "tensor([0., 1.]) tensor([0.5872, 0.4128], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 3 - 335: dog - cat || Loss: 0.8995530009269714\n",
      "tensor([0., 1.]) tensor([0.5863, 0.4137], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 3 - 336: dog - cat || Loss: 0.8986660838127136\n",
      "tensor([0., 1.]) tensor([0.5854, 0.4146], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 3 - 337: dog - cat || Loss: 0.8977789282798767\n",
      "tensor([0., 1.]) tensor([0.5845, 0.4155], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 3 - 338: dog - cat || Loss: 0.8968915939331055\n",
      "tensor([0., 1.]) tensor([0.5836, 0.4164], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 3 - 339: dog - cat || Loss: 0.8960041403770447\n",
      "tensor([0., 1.]) tensor([0.5827, 0.4173], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 3 - 340: dog - cat || Loss: 0.8951164484024048\n",
      "tensor([0., 1.]) tensor([0.5819, 0.4181], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 3 - 341: dog - cat || Loss: 0.894228458404541\n",
      "tensor([0., 1.]) tensor([0.5810, 0.4190], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 3 - 342: dog - cat || Loss: 0.893340528011322\n",
      "tensor([0., 1.]) tensor([0.5801, 0.4199], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 3 - 343: dog - cat || Loss: 0.8924523591995239\n",
      "tensor([0., 1.]) tensor([0.5792, 0.4208], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 3 - 344: dog - cat || Loss: 0.8915640115737915\n",
      "tensor([0., 1.]) tensor([0.5783, 0.4217], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 3 - 345: dog - cat || Loss: 0.89067542552948\n",
      "tensor([0., 1.]) tensor([0.5774, 0.4226], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 3 - 346: dog - cat || Loss: 0.8897867798805237\n",
      "tensor([0., 1.]) tensor([0.5765, 0.4235], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 3 - 347: dog - cat || Loss: 0.8888978958129883\n",
      "tensor([0., 1.]) tensor([0.5756, 0.4244], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 3 - 348: dog - cat || Loss: 0.8880086541175842\n",
      "tensor([0., 1.]) tensor([0.5747, 0.4253], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 3 - 349: dog - cat || Loss: 0.8871194124221802\n",
      "tensor([0., 1.]) tensor([0.5739, 0.4261], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 3 - 350: dog - cat || Loss: 0.886229932308197\n",
      "tensor([0., 1.]) tensor([0.5730, 0.4270], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 3 - 351: dog - cat || Loss: 0.88534015417099\n",
      "tensor([0., 1.]) tensor([0.5721, 0.4279], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 3 - 352: dog - cat || Loss: 0.8844504356384277\n",
      "tensor([0., 1.]) tensor([0.5712, 0.4288], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 3 - 353: dog - cat || Loss: 0.883560299873352\n",
      "tensor([0., 1.]) tensor([0.5703, 0.4297], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 3 - 354: dog - cat || Loss: 0.8826701045036316\n",
      "tensor([0., 1.]) tensor([0.5694, 0.4306], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 3 - 355: dog - cat || Loss: 0.8817798495292664\n",
      "tensor([0., 1.]) tensor([0.5685, 0.4315], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 3 - 356: dog - cat || Loss: 0.880889356136322\n",
      "tensor([0., 1.]) tensor([0.5676, 0.4324], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 3 - 357: dog - cat || Loss: 0.8799986839294434\n",
      "tensor([0., 1.]) tensor([0.5667, 0.4333], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 3 - 358: dog - cat || Loss: 0.8791077136993408\n",
      "tensor([0., 1.]) tensor([0.5658, 0.4342], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 3 - 359: dog - cat || Loss: 0.8782166242599487\n",
      "tensor([0., 1.]) tensor([0.5650, 0.4350], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 3 - 360: dog - cat || Loss: 0.877325177192688\n",
      "tensor([0., 1.]) tensor([0.5641, 0.4359], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 3 - 361: dog - cat || Loss: 0.8764336109161377\n",
      "tensor([0., 1.]) tensor([0.5632, 0.4368], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 3 - 362: dog - cat || Loss: 0.8755419254302979\n",
      "tensor([0., 1.]) tensor([0.5623, 0.4377], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 3 - 363: dog - cat || Loss: 0.8746498823165894\n",
      "tensor([0., 1.]) tensor([0.5614, 0.4386], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 3 - 364: dog - cat || Loss: 0.8737577199935913\n",
      "tensor([0., 1.]) tensor([0.5605, 0.4395], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 3 - 365: dog - cat || Loss: 0.8728654384613037\n",
      "tensor([0., 1.]) tensor([0.5596, 0.4404], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 3 - 366: dog - cat || Loss: 0.8719727993011475\n",
      "tensor([0., 1.]) tensor([0.5587, 0.4413], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 3 - 367: dog - cat || Loss: 0.8710800409317017\n",
      "tensor([0., 1.]) tensor([0.5578, 0.4422], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 3 - 368: dog - cat || Loss: 0.8701870441436768\n",
      "tensor([0., 1.]) tensor([0.5569, 0.4431], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 3 - 369: dog - cat || Loss: 0.8692939281463623\n",
      "tensor([0., 1.]) tensor([0.5560, 0.4440], grad_fn=<SoftmaxBackward0>)\n",
      "=====epoch:4=====\n",
      "Epoch 4 - 0: cat - cat || Loss: 0.7581226229667664\n",
      "tensor([1., 0.]) tensor([0.5551, 0.4449], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 4 - 1: cat - cat || Loss: 0.7588369846343994\n",
      "tensor([1., 0.]) tensor([0.5544, 0.4456], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 4 - 2: cat - cat || Loss: 0.7593905925750732\n",
      "tensor([1., 0.]) tensor([0.5539, 0.4461], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 4 - 3: cat - cat || Loss: 0.7597991824150085\n",
      "tensor([1., 0.]) tensor([0.5535, 0.4465], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 4 - 4: cat - cat || Loss: 0.7600775957107544\n",
      "tensor([1., 0.]) tensor([0.5532, 0.4468], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 4 - 5: cat - cat || Loss: 0.7602384686470032\n",
      "tensor([1., 0.]) tensor([0.5530, 0.4470], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 4 - 6: cat - cat || Loss: 0.7602939605712891\n",
      "tensor([1., 0.]) tensor([0.5530, 0.4470], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 4 - 7: cat - cat || Loss: 0.7602542638778687\n",
      "tensor([1., 0.]) tensor([0.5530, 0.4470], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 4 - 8: cat - cat || Loss: 0.7601291537284851\n",
      "tensor([1., 0.]) tensor([0.5531, 0.4469], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 4 - 9: cat - cat || Loss: 0.7599272131919861\n",
      "tensor([1., 0.]) tensor([0.5533, 0.4467], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 4 - 10: cat - cat || Loss: 0.759655773639679\n",
      "tensor([1., 0.]) tensor([0.5536, 0.4464], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 4 - 11: cat - cat || Loss: 0.7593221664428711\n",
      "tensor([1., 0.]) tensor([0.5539, 0.4461], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 4 - 12: cat - cat || Loss: 0.7589326500892639\n",
      "tensor([1., 0.]) tensor([0.5543, 0.4457], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 4 - 13: cat - cat || Loss: 0.7584925889968872\n",
      "tensor([1., 0.]) tensor([0.5548, 0.4452], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 4 - 14: cat - cat || Loss: 0.7580073475837708\n",
      "tensor([1., 0.]) tensor([0.5553, 0.4447], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 4 - 15: cat - cat || Loss: 0.7574813365936279\n",
      "tensor([1., 0.]) tensor([0.5558, 0.4442], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 4 - 16: cat - cat || Loss: 0.7569185495376587\n",
      "tensor([1., 0.]) tensor([0.5563, 0.4437], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 4 - 17: cat - cat || Loss: 0.7563228607177734\n",
      "tensor([1., 0.]) tensor([0.5569, 0.4431], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 4 - 18: cat - cat || Loss: 0.7556974291801453\n",
      "tensor([1., 0.]) tensor([0.5576, 0.4424], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 4 - 19: cat - cat || Loss: 0.7550454139709473\n",
      "tensor([1., 0.]) tensor([0.5582, 0.4418], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 4 - 20: cat - cat || Loss: 0.7543693780899048\n",
      "tensor([1., 0.]) tensor([0.5589, 0.4411], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 4 - 21: cat - cat || Loss: 0.7536718845367432\n",
      "tensor([1., 0.]) tensor([0.5596, 0.4404], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 4 - 22: cat - cat || Loss: 0.7529550790786743\n",
      "tensor([1., 0.]) tensor([0.5603, 0.4397], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 4 - 23: cat - cat || Loss: 0.7522207498550415\n",
      "tensor([1., 0.]) tensor([0.5610, 0.4390], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 4 - 24: cat - cat || Loss: 0.7514709234237671\n",
      "tensor([1., 0.]) tensor([0.5618, 0.4382], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 4 - 25: cat - cat || Loss: 0.7507071495056152\n",
      "tensor([1., 0.]) tensor([0.5626, 0.4374], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 4 - 26: cat - cat || Loss: 0.7499307990074158\n",
      "tensor([1., 0.]) tensor([0.5633, 0.4367], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 4 - 27: cat - cat || Loss: 0.7491430044174194\n",
      "tensor([1., 0.]) tensor([0.5641, 0.4359], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 4 - 28: cat - cat || Loss: 0.7483450174331665\n",
      "tensor([1., 0.]) tensor([0.5649, 0.4351], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 4 - 29: cat - cat || Loss: 0.7475377321243286\n",
      "tensor([1., 0.]) tensor([0.5657, 0.4343], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 4 - 30: cat - cat || Loss: 0.7467224597930908\n",
      "tensor([1., 0.]) tensor([0.5665, 0.4335], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 4 - 31: cat - cat || Loss: 0.7458995580673218\n",
      "tensor([1., 0.]) tensor([0.5674, 0.4326], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 4 - 32: cat - cat || Loss: 0.7450701594352722\n",
      "tensor([1., 0.]) tensor([0.5682, 0.4318], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 4 - 33: cat - cat || Loss: 0.7442349791526794\n",
      "tensor([1., 0.]) tensor([0.5690, 0.4310], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 4 - 34: cat - cat || Loss: 0.7433944940567017\n",
      "tensor([1., 0.]) tensor([0.5699, 0.4301], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 4 - 35: cat - cat || Loss: 0.7425491809844971\n",
      "tensor([1., 0.]) tensor([0.5707, 0.4293], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 4 - 36: cat - cat || Loss: 0.7416998744010925\n",
      "tensor([1., 0.]) tensor([0.5716, 0.4284], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 4 - 37: cat - cat || Loss: 0.7408466935157776\n",
      "tensor([1., 0.]) tensor([0.5724, 0.4276], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 4 - 38: cat - cat || Loss: 0.7399901151657104\n",
      "tensor([1., 0.]) tensor([0.5733, 0.4267], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 4 - 39: cat - cat || Loss: 0.7391303181648254\n",
      "tensor([1., 0.]) tensor([0.5741, 0.4259], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 4 - 40: cat - cat || Loss: 0.7382681369781494\n",
      "tensor([1., 0.]) tensor([0.5750, 0.4250], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 4 - 41: cat - cat || Loss: 0.7374032735824585\n",
      "tensor([1., 0.]) tensor([0.5759, 0.4241], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 4 - 42: cat - cat || Loss: 0.7365365028381348\n",
      "tensor([1., 0.]) tensor([0.5767, 0.4233], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 4 - 43: cat - cat || Loss: 0.7356675863265991\n",
      "tensor([1., 0.]) tensor([0.5776, 0.4224], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 4 - 44: cat - cat || Loss: 0.7347972393035889\n",
      "tensor([1., 0.]) tensor([0.5785, 0.4215], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 4 - 45: cat - cat || Loss: 0.7339251041412354\n",
      "tensor([1., 0.]) tensor([0.5793, 0.4207], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 4 - 46: cat - cat || Loss: 0.7330517768859863\n",
      "tensor([1., 0.]) tensor([0.5802, 0.4198], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 4 - 47: cat - cat || Loss: 0.7321771383285522\n",
      "tensor([1., 0.]) tensor([0.5811, 0.4189], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 4 - 48: cat - cat || Loss: 0.7313016057014465\n",
      "tensor([1., 0.]) tensor([0.5820, 0.4180], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 4 - 49: cat - cat || Loss: 0.7304250597953796\n",
      "tensor([1., 0.]) tensor([0.5828, 0.4172], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 4 - 50: cat - cat || Loss: 0.7295477986335754\n",
      "tensor([1., 0.]) tensor([0.5837, 0.4163], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 4 - 51: cat - cat || Loss: 0.7286699414253235\n",
      "tensor([1., 0.]) tensor([0.5846, 0.4154], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 4 - 52: cat - cat || Loss: 0.7277913689613342\n",
      "tensor([1., 0.]) tensor([0.5855, 0.4145], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 4 - 53: cat - cat || Loss: 0.7269123792648315\n",
      "tensor([1., 0.]) tensor([0.5863, 0.4137], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 4 - 54: cat - cat || Loss: 0.7260331511497498\n",
      "tensor([1., 0.]) tensor([0.5872, 0.4128], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 4 - 55: cat - cat || Loss: 0.725153386592865\n",
      "tensor([1., 0.]) tensor([0.5881, 0.4119], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 4 - 56: cat - cat || Loss: 0.7242733836174011\n",
      "tensor([1., 0.]) tensor([0.5890, 0.4110], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 4 - 57: cat - cat || Loss: 0.7233930826187134\n",
      "tensor([1., 0.]) tensor([0.5899, 0.4101], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 4 - 58: cat - cat || Loss: 0.7225126028060913\n",
      "tensor([1., 0.]) tensor([0.5907, 0.4093], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 4 - 59: cat - cat || Loss: 0.7216320633888245\n",
      "tensor([1., 0.]) tensor([0.5916, 0.4084], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 4 - 60: cat - cat || Loss: 0.7207512855529785\n",
      "tensor([1., 0.]) tensor([0.5925, 0.4075], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 4 - 61: cat - cat || Loss: 0.7198705673217773\n",
      "tensor([1., 0.]) tensor([0.5934, 0.4066], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 4 - 62: cat - cat || Loss: 0.7189896702766418\n",
      "tensor([1., 0.]) tensor([0.5943, 0.4057], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 4 - 63: cat - cat || Loss: 0.718109130859375\n",
      "tensor([1., 0.]) tensor([0.5952, 0.4048], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 4 - 64: cat - cat || Loss: 0.7172284126281738\n",
      "tensor([1., 0.]) tensor([0.5960, 0.4040], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 4 - 65: cat - cat || Loss: 0.716347873210907\n",
      "tensor([1., 0.]) tensor([0.5969, 0.4031], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 4 - 66: cat - cat || Loss: 0.7154675126075745\n",
      "tensor([1., 0.]) tensor([0.5978, 0.4022], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 4 - 67: cat - cat || Loss: 0.7145875096321106\n",
      "tensor([1., 0.]) tensor([0.5987, 0.4013], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 4 - 68: cat - cat || Loss: 0.7137072682380676\n",
      "tensor([1., 0.]) tensor([0.5996, 0.4004], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 4 - 69: cat - cat || Loss: 0.7128272652626038\n",
      "tensor([1., 0.]) tensor([0.6004, 0.3996], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 4 - 70: cat - cat || Loss: 0.711947500705719\n",
      "tensor([1., 0.]) tensor([0.6013, 0.3987], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 4 - 71: cat - cat || Loss: 0.7110679149627686\n",
      "tensor([1., 0.]) tensor([0.6022, 0.3978], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 4 - 72: cat - cat || Loss: 0.7101885080337524\n",
      "tensor([1., 0.]) tensor([0.6031, 0.3969], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 4 - 73: cat - cat || Loss: 0.7093092203140259\n",
      "tensor([1., 0.]) tensor([0.6040, 0.3960], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 4 - 74: cat - cat || Loss: 0.7084301710128784\n",
      "tensor([1., 0.]) tensor([0.6048, 0.3952], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 4 - 75: cat - cat || Loss: 0.7075515985488892\n",
      "tensor([1., 0.]) tensor([0.6057, 0.3943], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 4 - 76: cat - cat || Loss: 0.7066733837127686\n",
      "tensor([1., 0.]) tensor([0.6066, 0.3934], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 4 - 77: cat - cat || Loss: 0.7057952284812927\n",
      "tensor([1., 0.]) tensor([0.6075, 0.3925], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 4 - 78: cat - cat || Loss: 0.7049174308776855\n",
      "tensor([1., 0.]) tensor([0.6083, 0.3917], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 4 - 79: cat - cat || Loss: 0.7040399312973022\n",
      "tensor([1., 0.]) tensor([0.6092, 0.3908], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 4 - 80: cat - cat || Loss: 0.7031627893447876\n",
      "tensor([1., 0.]) tensor([0.6101, 0.3899], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 4 - 81: cat - cat || Loss: 0.7022859454154968\n",
      "tensor([1., 0.]) tensor([0.6110, 0.3890], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 4 - 82: cat - cat || Loss: 0.7014095783233643\n",
      "tensor([1., 0.]) tensor([0.6119, 0.3881], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 4 - 83: cat - cat || Loss: 0.7005334496498108\n",
      "tensor([1., 0.]) tensor([0.6127, 0.3873], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 4 - 84: cat - cat || Loss: 0.6996576189994812\n",
      "tensor([1., 0.]) tensor([0.6136, 0.3864], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 4 - 85: cat - cat || Loss: 0.6987821459770203\n",
      "tensor([1., 0.]) tensor([0.6145, 0.3855], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 4 - 86: cat - cat || Loss: 0.6979070901870728\n",
      "tensor([1., 0.]) tensor([0.6154, 0.3846], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 4 - 87: cat - cat || Loss: 0.6970323324203491\n",
      "tensor([1., 0.]) tensor([0.6162, 0.3838], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 4 - 88: cat - cat || Loss: 0.6961578130722046\n",
      "tensor([1., 0.]) tensor([0.6171, 0.3829], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 4 - 89: cat - cat || Loss: 0.6952836513519287\n",
      "tensor([1., 0.]) tensor([0.6180, 0.3820], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 4 - 90: cat - cat || Loss: 0.694409966468811\n",
      "tensor([1., 0.]) tensor([0.6189, 0.3811], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 4 - 91: cat - cat || Loss: 0.6935362815856934\n",
      "tensor([1., 0.]) tensor([0.6197, 0.3803], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 4 - 92: cat - cat || Loss: 0.6926631927490234\n",
      "tensor([1., 0.]) tensor([0.6206, 0.3794], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 4 - 93: cat - cat || Loss: 0.6917904615402222\n",
      "tensor([1., 0.]) tensor([0.6215, 0.3785], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 4 - 94: cat - cat || Loss: 0.6909180283546448\n",
      "tensor([1., 0.]) tensor([0.6223, 0.3777], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 4 - 95: cat - cat || Loss: 0.6900458931922913\n",
      "tensor([1., 0.]) tensor([0.6232, 0.3768], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 4 - 96: cat - cat || Loss: 0.6891742944717407\n",
      "tensor([1., 0.]) tensor([0.6241, 0.3759], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 4 - 97: cat - cat || Loss: 0.688302755355835\n",
      "tensor([1., 0.]) tensor([0.6250, 0.3750], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 4 - 98: cat - cat || Loss: 0.6874319314956665\n",
      "tensor([1., 0.]) tensor([0.6258, 0.3742], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 4 - 99: cat - cat || Loss: 0.6865614056587219\n",
      "tensor([1., 0.]) tensor([0.6267, 0.3733], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 4 - 100: cat - cat || Loss: 0.6856911778450012\n",
      "tensor([1., 0.]) tensor([0.6276, 0.3724], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 4 - 101: cat - cat || Loss: 0.6848214864730835\n",
      "tensor([1., 0.]) tensor([0.6284, 0.3716], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 4 - 102: cat - cat || Loss: 0.6839520931243896\n",
      "tensor([1., 0.]) tensor([0.6293, 0.3707], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 4 - 103: cat - cat || Loss: 0.6830830574035645\n",
      "tensor([1., 0.]) tensor([0.6302, 0.3698], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 4 - 104: cat - cat || Loss: 0.6822144389152527\n",
      "tensor([1., 0.]) tensor([0.6310, 0.3690], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 4 - 105: cat - cat || Loss: 0.6813462972640991\n",
      "tensor([1., 0.]) tensor([0.6319, 0.3681], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 4 - 106: cat - cat || Loss: 0.6804785132408142\n",
      "tensor([1., 0.]) tensor([0.6328, 0.3672], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 4 - 107: cat - cat || Loss: 0.6796109676361084\n",
      "tensor([1., 0.]) tensor([0.6337, 0.3663], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 4 - 108: cat - cat || Loss: 0.678743839263916\n",
      "tensor([1., 0.]) tensor([0.6345, 0.3655], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 4 - 109: cat - cat || Loss: 0.6778770685195923\n",
      "tensor([1., 0.]) tensor([0.6354, 0.3646], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 4 - 110: cat - cat || Loss: 0.6770107746124268\n",
      "tensor([1., 0.]) tensor([0.6363, 0.3637], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 4 - 111: cat - cat || Loss: 0.6761449575424194\n",
      "tensor([1., 0.]) tensor([0.6371, 0.3629], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 4 - 112: cat - cat || Loss: 0.6752796173095703\n",
      "tensor([1., 0.]) tensor([0.6380, 0.3620], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 4 - 113: cat - cat || Loss: 0.6744145750999451\n",
      "tensor([1., 0.]) tensor([0.6388, 0.3612], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 4 - 114: cat - cat || Loss: 0.6735501885414124\n",
      "tensor([1., 0.]) tensor([0.6397, 0.3603], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 4 - 115: cat - cat || Loss: 0.6726862192153931\n",
      "tensor([1., 0.]) tensor([0.6406, 0.3594], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 4 - 116: cat - cat || Loss: 0.6718226075172424\n",
      "tensor([1., 0.]) tensor([0.6414, 0.3586], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 4 - 117: cat - cat || Loss: 0.6709594130516052\n",
      "tensor([1., 0.]) tensor([0.6423, 0.3577], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 4 - 118: cat - cat || Loss: 0.6700966358184814\n",
      "tensor([1., 0.]) tensor([0.6432, 0.3568], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 4 - 119: cat - cat || Loss: 0.6692344546318054\n",
      "tensor([1., 0.]) tensor([0.6440, 0.3560], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 4 - 120: cat - cat || Loss: 0.6683727502822876\n",
      "tensor([1., 0.]) tensor([0.6449, 0.3551], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 4 - 121: cat - cat || Loss: 0.6675112247467041\n",
      "tensor([1., 0.]) tensor([0.6458, 0.3542], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 4 - 122: cat - cat || Loss: 0.6666502952575684\n",
      "tensor([1., 0.]) tensor([0.6466, 0.3534], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 4 - 123: cat - cat || Loss: 0.6657898426055908\n",
      "tensor([1., 0.]) tensor([0.6475, 0.3525], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 4 - 124: cat - cat || Loss: 0.6649298667907715\n",
      "tensor([1., 0.]) tensor([0.6483, 0.3517], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 4 - 125: cat - cat || Loss: 0.6640704274177551\n",
      "tensor([1., 0.]) tensor([0.6492, 0.3508], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 4 - 126: cat - cat || Loss: 0.6632113456726074\n",
      "tensor([1., 0.]) tensor([0.6501, 0.3499], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 4 - 127: cat - cat || Loss: 0.6623526811599731\n",
      "tensor([1., 0.]) tensor([0.6509, 0.3491], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 4 - 128: cat - cat || Loss: 0.6614944934844971\n",
      "tensor([1., 0.]) tensor([0.6518, 0.3482], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 4 - 129: cat - cat || Loss: 0.6606367826461792\n",
      "tensor([1., 0.]) tensor([0.6526, 0.3474], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 4 - 130: cat - cat || Loss: 0.65977942943573\n",
      "tensor([1., 0.]) tensor([0.6535, 0.3465], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 4 - 131: cat - cat || Loss: 0.658922553062439\n",
      "tensor([1., 0.]) tensor([0.6543, 0.3457], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 4 - 132: cat - cat || Loss: 0.6580662131309509\n",
      "tensor([1., 0.]) tensor([0.6552, 0.3448], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 4 - 133: cat - cat || Loss: 0.6572102308273315\n",
      "tensor([1., 0.]) tensor([0.6561, 0.3439], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 4 - 134: cat - cat || Loss: 0.6563546657562256\n",
      "tensor([1., 0.]) tensor([0.6569, 0.3431], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 4 - 135: cat - cat || Loss: 0.6554996967315674\n",
      "tensor([1., 0.]) tensor([0.6578, 0.3422], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 4 - 136: cat - cat || Loss: 0.6546451449394226\n",
      "tensor([1., 0.]) tensor([0.6586, 0.3414], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 4 - 137: cat - cat || Loss: 0.653791069984436\n",
      "tensor([1., 0.]) tensor([0.6595, 0.3405], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 4 - 138: cat - cat || Loss: 0.6529372930526733\n",
      "tensor([1., 0.]) tensor([0.6603, 0.3397], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 4 - 139: cat - cat || Loss: 0.6520841121673584\n",
      "tensor([1., 0.]) tensor([0.6612, 0.3388], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 4 - 140: cat - cat || Loss: 0.6512314081192017\n",
      "tensor([1., 0.]) tensor([0.6620, 0.3380], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 4 - 141: cat - cat || Loss: 0.6503793597221375\n",
      "tensor([1., 0.]) tensor([0.6629, 0.3371], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 4 - 142: cat - cat || Loss: 0.6495278477668762\n",
      "tensor([1., 0.]) tensor([0.6637, 0.3363], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 4 - 143: cat - cat || Loss: 0.6486767530441284\n",
      "tensor([1., 0.]) tensor([0.6646, 0.3354], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 4 - 144: cat - cat || Loss: 0.6478261947631836\n",
      "tensor([1., 0.]) tensor([0.6654, 0.3346], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 4 - 145: cat - cat || Loss: 0.6469759941101074\n",
      "tensor([1., 0.]) tensor([0.6663, 0.3337], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 4 - 146: cat - cat || Loss: 0.6461264491081238\n",
      "tensor([1., 0.]) tensor([0.6671, 0.3329], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 4 - 147: cat - cat || Loss: 0.6452775001525879\n",
      "tensor([1., 0.]) tensor([0.6680, 0.3320], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 4 - 148: cat - cat || Loss: 0.6444288492202759\n",
      "tensor([1., 0.]) tensor([0.6688, 0.3312], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 4 - 149: cat - cat || Loss: 0.6435809135437012\n",
      "tensor([1., 0.]) tensor([0.6697, 0.3303], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 4 - 150: cat - cat || Loss: 0.6427333354949951\n",
      "tensor([1., 0.]) tensor([0.6705, 0.3295], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 4 - 151: cat - cat || Loss: 0.6418864130973816\n",
      "tensor([1., 0.]) tensor([0.6714, 0.3286], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 4 - 152: cat - cat || Loss: 0.6410399079322815\n",
      "tensor([1., 0.]) tensor([0.6722, 0.3278], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 4 - 153: cat - cat || Loss: 0.6401941776275635\n",
      "tensor([1., 0.]) tensor([0.6731, 0.3269], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 4 - 154: cat - cat || Loss: 0.6393487453460693\n",
      "tensor([1., 0.]) tensor([0.6739, 0.3261], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 4 - 155: cat - cat || Loss: 0.6385040283203125\n",
      "tensor([1., 0.]) tensor([0.6748, 0.3252], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 4 - 156: cat - cat || Loss: 0.6376597285270691\n",
      "tensor([1., 0.]) tensor([0.6756, 0.3244], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 4 - 157: cat - cat || Loss: 0.6368160247802734\n",
      "tensor([1., 0.]) tensor([0.6764, 0.3236], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 4 - 158: cat - cat || Loss: 0.6359727382659912\n",
      "tensor([1., 0.]) tensor([0.6773, 0.3227], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 4 - 159: cat - cat || Loss: 0.635129988193512\n",
      "tensor([1., 0.]) tensor([0.6781, 0.3219], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 4 - 160: cat - cat || Loss: 0.6342877149581909\n",
      "tensor([1., 0.]) tensor([0.6790, 0.3210], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 4 - 161: cat - cat || Loss: 0.6334460973739624\n",
      "tensor([1., 0.]) tensor([0.6798, 0.3202], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 4 - 162: cat - cat || Loss: 0.6326051950454712\n",
      "tensor([1., 0.]) tensor([0.6807, 0.3193], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 4 - 163: cat - cat || Loss: 0.6317645907402039\n",
      "tensor([1., 0.]) tensor([0.6815, 0.3185], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 4 - 164: cat - cat || Loss: 0.630924642086029\n",
      "tensor([1., 0.]) tensor([0.6823, 0.3177], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 4 - 165: cat - cat || Loss: 0.6300852298736572\n",
      "tensor([1., 0.]) tensor([0.6832, 0.3168], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 4 - 166: cat - cat || Loss: 0.6292462944984436\n",
      "tensor([1., 0.]) tensor([0.6840, 0.3160], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 4 - 167: cat - cat || Loss: 0.628407895565033\n",
      "tensor([1., 0.]) tensor([0.6849, 0.3151], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 4 - 168: cat - cat || Loss: 0.6275702714920044\n",
      "tensor([1., 0.]) tensor([0.6857, 0.3143], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 4 - 169: cat - cat || Loss: 0.6267329454421997\n",
      "tensor([1., 0.]) tensor([0.6865, 0.3135], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 4 - 170: cat - cat || Loss: 0.6258964538574219\n",
      "tensor([1., 0.]) tensor([0.6874, 0.3126], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 4 - 171: cat - cat || Loss: 0.6250605583190918\n",
      "tensor([1., 0.]) tensor([0.6882, 0.3118], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 4 - 172: cat - cat || Loss: 0.6242250800132751\n",
      "tensor([1., 0.]) tensor([0.6890, 0.3110], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 4 - 173: cat - cat || Loss: 0.6233903765678406\n",
      "tensor([1., 0.]) tensor([0.6899, 0.3101], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 4 - 174: cat - cat || Loss: 0.6225560307502747\n",
      "tensor([1., 0.]) tensor([0.6907, 0.3093], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 4 - 175: cat - cat || Loss: 0.6217222809791565\n",
      "tensor([1., 0.]) tensor([0.6915, 0.3085], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 4 - 176: cat - cat || Loss: 0.6208890676498413\n",
      "tensor([1., 0.]) tensor([0.6924, 0.3076], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 4 - 177: cat - cat || Loss: 0.6200566291809082\n",
      "tensor([1., 0.]) tensor([0.6932, 0.3068], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 4 - 178: cat - cat || Loss: 0.6192246675491333\n",
      "tensor([1., 0.]) tensor([0.6940, 0.3060], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 4 - 179: cat - cat || Loss: 0.6183934807777405\n",
      "tensor([1., 0.]) tensor([0.6949, 0.3051], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 4 - 180: cat - cat || Loss: 0.6175627708435059\n",
      "tensor([1., 0.]) tensor([0.6957, 0.3043], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 4 - 181: cat - cat || Loss: 0.6167327165603638\n",
      "tensor([1., 0.]) tensor([0.6965, 0.3035], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 4 - 182: cat - cat || Loss: 0.6159032583236694\n",
      "tensor([1., 0.]) tensor([0.6974, 0.3026], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 4 - 183: cat - cat || Loss: 0.6150744557380676\n",
      "tensor([1., 0.]) tensor([0.6982, 0.3018], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 4 - 184: cat - cat || Loss: 0.6142461895942688\n",
      "tensor([1., 0.]) tensor([0.6990, 0.3010], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 4 - 185: cat - cat || Loss: 0.6134186387062073\n",
      "tensor([1., 0.]) tensor([0.6998, 0.3002], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 4 - 186: cat - cat || Loss: 0.6125915050506592\n",
      "tensor([1., 0.]) tensor([0.7007, 0.2993], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 4 - 187: cat - cat || Loss: 0.6117652654647827\n",
      "tensor([1., 0.]) tensor([0.7015, 0.2985], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 4 - 188: cat - cat || Loss: 0.610939621925354\n",
      "tensor([1., 0.]) tensor([0.7023, 0.2977], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 4 - 189: cat - cat || Loss: 0.6101146936416626\n",
      "tensor([1., 0.]) tensor([0.7031, 0.2969], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 4 - 190: dog - cat || Loss: 1.017232894897461\n",
      "tensor([0., 1.]) tensor([0.7040, 0.2960], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 4 - 191: dog - cat || Loss: 1.0178921222686768\n",
      "tensor([0., 1.]) tensor([0.7046, 0.2954], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 4 - 192: dog - cat || Loss: 1.0184032917022705\n",
      "tensor([0., 1.]) tensor([0.7051, 0.2949], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 4 - 193: dog - cat || Loss: 1.018781065940857\n",
      "tensor([0., 1.]) tensor([0.7055, 0.2945], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 4 - 194: dog - cat || Loss: 1.0190389156341553\n",
      "tensor([0., 1.]) tensor([0.7058, 0.2942], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 4 - 195: dog - cat || Loss: 1.0191890001296997\n",
      "tensor([0., 1.]) tensor([0.7059, 0.2941], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 4 - 196: dog - cat || Loss: 1.0192421674728394\n",
      "tensor([0., 1.]) tensor([0.7060, 0.2940], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 4 - 197: dog - cat || Loss: 1.0192077159881592\n",
      "tensor([0., 1.]) tensor([0.7059, 0.2941], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 4 - 198: dog - cat || Loss: 1.0190950632095337\n",
      "tensor([0., 1.]) tensor([0.7058, 0.2942], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 4 - 199: dog - cat || Loss: 1.0189117193222046\n",
      "tensor([0., 1.]) tensor([0.7057, 0.2944], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 4 - 200: dog - cat || Loss: 1.0186643600463867\n",
      "tensor([0., 1.]) tensor([0.7054, 0.2946], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 4 - 201: dog - cat || Loss: 1.0183600187301636\n",
      "tensor([0., 1.]) tensor([0.7051, 0.2949], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 4 - 202: dog - cat || Loss: 1.018004059791565\n",
      "tensor([0., 1.]) tensor([0.7047, 0.2953], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 4 - 203: dog - cat || Loss: 1.017601728439331\n",
      "tensor([0., 1.]) tensor([0.7043, 0.2957], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 4 - 204: dog - cat || Loss: 1.0171571969985962\n",
      "tensor([0., 1.]) tensor([0.7039, 0.2961], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 4 - 205: dog - cat || Loss: 1.0166749954223633\n",
      "tensor([0., 1.]) tensor([0.7034, 0.2966], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 4 - 206: dog - cat || Loss: 1.016158938407898\n",
      "tensor([0., 1.]) tensor([0.7029, 0.2971], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 4 - 207: dog - cat || Loss: 1.0156123638153076\n",
      "tensor([0., 1.]) tensor([0.7024, 0.2976], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 4 - 208: dog - cat || Loss: 1.0150377750396729\n",
      "tensor([0., 1.]) tensor([0.7018, 0.2982], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 4 - 209: dog - cat || Loss: 1.014438509941101\n",
      "tensor([0., 1.]) tensor([0.7012, 0.2988], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 4 - 210: dog - cat || Loss: 1.0138165950775146\n",
      "tensor([0., 1.]) tensor([0.7006, 0.2994], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 4 - 211: dog - cat || Loss: 1.0131745338439941\n",
      "tensor([0., 1.]) tensor([0.6999, 0.3001], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 4 - 212: dog - cat || Loss: 1.0125141143798828\n",
      "tensor([0., 1.]) tensor([0.6993, 0.3007], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 4 - 213: dog - cat || Loss: 1.0118370056152344\n",
      "tensor([0., 1.]) tensor([0.6986, 0.3014], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 4 - 214: dog - cat || Loss: 1.011144995689392\n",
      "tensor([0., 1.]) tensor([0.6979, 0.3021], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 4 - 215: dog - cat || Loss: 1.0104395151138306\n",
      "tensor([0., 1.]) tensor([0.6972, 0.3028], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 4 - 216: dog - cat || Loss: 1.0097217559814453\n",
      "tensor([0., 1.]) tensor([0.6965, 0.3035], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 4 - 217: dog - cat || Loss: 1.0089929103851318\n",
      "tensor([0., 1.]) tensor([0.6957, 0.3043], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 4 - 218: dog - cat || Loss: 1.0082544088363647\n",
      "tensor([0., 1.]) tensor([0.6950, 0.3050], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 4 - 219: dog - cat || Loss: 1.0075067281723022\n",
      "tensor([0., 1.]) tensor([0.6942, 0.3058], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 4 - 220: dog - cat || Loss: 1.0067508220672607\n",
      "tensor([0., 1.]) tensor([0.6935, 0.3065], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 4 - 221: dog - cat || Loss: 1.0059874057769775\n",
      "tensor([0., 1.]) tensor([0.6927, 0.3073], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 4 - 222: dog - cat || Loss: 1.005217432975769\n",
      "tensor([0., 1.]) tensor([0.6920, 0.3080], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 4 - 223: dog - cat || Loss: 1.004441261291504\n",
      "tensor([0., 1.]) tensor([0.6912, 0.3088], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 4 - 224: dog - cat || Loss: 1.003659725189209\n",
      "tensor([0., 1.]) tensor([0.6904, 0.3096], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 4 - 225: dog - cat || Loss: 1.0028733015060425\n",
      "tensor([0., 1.]) tensor([0.6896, 0.3104], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 4 - 226: dog - cat || Loss: 1.0020822286605835\n",
      "tensor([0., 1.]) tensor([0.6888, 0.3112], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 4 - 227: dog - cat || Loss: 1.0012869834899902\n",
      "tensor([0., 1.]) tensor([0.6880, 0.3120], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 4 - 228: dog - cat || Loss: 1.0004876852035522\n",
      "tensor([0., 1.]) tensor([0.6872, 0.3128], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 4 - 229: dog - cat || Loss: 0.9996852874755859\n",
      "tensor([0., 1.]) tensor([0.6864, 0.3136], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 4 - 230: dog - cat || Loss: 0.9988794326782227\n",
      "tensor([0., 1.]) tensor([0.6856, 0.3144], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 4 - 231: dog - cat || Loss: 0.9980708360671997\n",
      "tensor([0., 1.]) tensor([0.6848, 0.3152], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 4 - 232: dog - cat || Loss: 0.9972595572471619\n",
      "tensor([0., 1.]) tensor([0.6840, 0.3160], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 4 - 233: dog - cat || Loss: 0.996445894241333\n",
      "tensor([0., 1.]) tensor([0.6832, 0.3168], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 4 - 234: dog - cat || Loss: 0.9956299066543579\n",
      "tensor([0., 1.]) tensor([0.6824, 0.3176], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 4 - 235: dog - cat || Loss: 0.9948120713233948\n",
      "tensor([0., 1.]) tensor([0.6816, 0.3184], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 4 - 236: dog - cat || Loss: 0.9939922094345093\n",
      "tensor([0., 1.]) tensor([0.6807, 0.3193], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 4 - 237: dog - cat || Loss: 0.9931706190109253\n",
      "tensor([0., 1.]) tensor([0.6799, 0.3201], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 4 - 238: dog - cat || Loss: 0.9923473000526428\n",
      "tensor([0., 1.]) tensor([0.6791, 0.3209], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 4 - 239: dog - cat || Loss: 0.9915225505828857\n",
      "tensor([0., 1.]) tensor([0.6783, 0.3217], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 4 - 240: dog - cat || Loss: 0.9906963109970093\n",
      "tensor([0., 1.]) tensor([0.6774, 0.3226], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 4 - 241: dog - cat || Loss: 0.989868700504303\n",
      "tensor([0., 1.]) tensor([0.6766, 0.3234], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 4 - 242: dog - cat || Loss: 0.9890398383140564\n",
      "tensor([0., 1.]) tensor([0.6758, 0.3242], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 4 - 243: dog - cat || Loss: 0.9882100224494934\n",
      "tensor([0., 1.]) tensor([0.6749, 0.3251], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 4 - 244: dog - cat || Loss: 0.9873791337013245\n",
      "tensor([0., 1.]) tensor([0.6741, 0.3259], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 4 - 245: dog - cat || Loss: 0.9865472316741943\n",
      "tensor([0., 1.]) tensor([0.6733, 0.3267], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 4 - 246: dog - cat || Loss: 0.9857141971588135\n",
      "tensor([0., 1.]) tensor([0.6725, 0.3275], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 4 - 247: dog - cat || Loss: 0.9848804473876953\n",
      "tensor([0., 1.]) tensor([0.6716, 0.3284], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 4 - 248: dog - cat || Loss: 0.9840459227561951\n",
      "tensor([0., 1.]) tensor([0.6708, 0.3292], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 4 - 249: dog - cat || Loss: 0.9832102656364441\n",
      "tensor([0., 1.]) tensor([0.6699, 0.3301], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 4 - 250: dog - cat || Loss: 0.9823740720748901\n",
      "tensor([0., 1.]) tensor([0.6691, 0.3309], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 4 - 251: dog - cat || Loss: 0.9815371036529541\n",
      "tensor([0., 1.]) tensor([0.6683, 0.3317], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 4 - 252: dog - cat || Loss: 0.9806994199752808\n",
      "tensor([0., 1.]) tensor([0.6674, 0.3326], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 4 - 253: dog - cat || Loss: 0.9798609018325806\n",
      "tensor([0., 1.]) tensor([0.6666, 0.3334], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 4 - 254: dog - cat || Loss: 0.9790218472480774\n",
      "tensor([0., 1.]) tensor([0.6658, 0.3342], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 4 - 255: dog - cat || Loss: 0.9781822562217712\n",
      "tensor([0., 1.]) tensor([0.6649, 0.3351], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 4 - 256: dog - cat || Loss: 0.9773419499397278\n",
      "tensor([0., 1.]) tensor([0.6641, 0.3359], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 4 - 257: dog - cat || Loss: 0.9765009880065918\n",
      "tensor([0., 1.]) tensor([0.6632, 0.3368], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 4 - 258: dog - cat || Loss: 0.9756597876548767\n",
      "tensor([0., 1.]) tensor([0.6624, 0.3376], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 4 - 259: dog - cat || Loss: 0.97481769323349\n",
      "tensor([0., 1.]) tensor([0.6616, 0.3384], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 4 - 260: dog - cat || Loss: 0.9739750623703003\n",
      "tensor([0., 1.]) tensor([0.6607, 0.3393], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 4 - 261: dog - cat || Loss: 0.9731319546699524\n",
      "tensor([0., 1.]) tensor([0.6599, 0.3401], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 4 - 262: dog - cat || Loss: 0.9722883105278015\n",
      "tensor([0., 1.]) tensor([0.6590, 0.3410], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 4 - 263: dog - cat || Loss: 0.9714440107345581\n",
      "tensor([0., 1.]) tensor([0.6582, 0.3418], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 4 - 264: dog - cat || Loss: 0.9705994725227356\n",
      "tensor([0., 1.]) tensor([0.6573, 0.3427], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 4 - 265: dog - cat || Loss: 0.9697540998458862\n",
      "tensor([0., 1.]) tensor([0.6565, 0.3435], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 4 - 266: dog - cat || Loss: 0.9689084887504578\n",
      "tensor([0., 1.]) tensor([0.6556, 0.3444], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 4 - 267: dog - cat || Loss: 0.9680624604225159\n",
      "tensor([0., 1.]) tensor([0.6548, 0.3452], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 4 - 268: dog - cat || Loss: 0.9672157168388367\n",
      "tensor([0., 1.]) tensor([0.6540, 0.3460], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 4 - 269: dog - cat || Loss: 0.9663687944412231\n",
      "tensor([0., 1.]) tensor([0.6531, 0.3469], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 4 - 270: dog - cat || Loss: 0.9655211567878723\n",
      "tensor([0., 1.]) tensor([0.6523, 0.3477], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 4 - 271: dog - cat || Loss: 0.9646732807159424\n",
      "tensor([0., 1.]) tensor([0.6514, 0.3486], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 4 - 272: dog - cat || Loss: 0.9638247489929199\n",
      "tensor([0., 1.]) tensor([0.6506, 0.3494], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 4 - 273: dog - cat || Loss: 0.9629760980606079\n",
      "tensor([0., 1.]) tensor([0.6497, 0.3503], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 4 - 274: dog - cat || Loss: 0.9621269106864929\n",
      "tensor([0., 1.]) tensor([0.6489, 0.3511], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 4 - 275: dog - cat || Loss: 0.9612773060798645\n",
      "tensor([0., 1.]) tensor([0.6480, 0.3520], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 4 - 276: dog - cat || Loss: 0.960427463054657\n",
      "tensor([0., 1.]) tensor([0.6472, 0.3528], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 4 - 277: dog - cat || Loss: 0.9595771431922913\n",
      "tensor([0., 1.]) tensor([0.6463, 0.3537], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 4 - 278: dog - cat || Loss: 0.9587265253067017\n",
      "tensor([0., 1.]) tensor([0.6455, 0.3545], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 4 - 279: dog - cat || Loss: 0.9578754901885986\n",
      "tensor([0., 1.]) tensor([0.6446, 0.3554], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 4 - 280: dog - cat || Loss: 0.9570240378379822\n",
      "tensor([0., 1.]) tensor([0.6438, 0.3562], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 4 - 281: dog - cat || Loss: 0.9561723470687866\n",
      "tensor([0., 1.]) tensor([0.6429, 0.3571], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 4 - 282: dog - cat || Loss: 0.9553201198577881\n",
      "tensor([0., 1.]) tensor([0.6421, 0.3579], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 4 - 283: dog - cat || Loss: 0.9544675946235657\n",
      "tensor([0., 1.]) tensor([0.6412, 0.3588], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 4 - 284: dog - cat || Loss: 0.9536147713661194\n",
      "tensor([0., 1.]) tensor([0.6404, 0.3596], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 4 - 285: dog - cat || Loss: 0.9527615308761597\n",
      "tensor([0., 1.]) tensor([0.6395, 0.3605], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 4 - 286: dog - cat || Loss: 0.9519080519676208\n",
      "tensor([0., 1.]) tensor([0.6386, 0.3614], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 4 - 287: dog - cat || Loss: 0.951054036617279\n",
      "tensor([0., 1.]) tensor([0.6378, 0.3622], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 4 - 288: dog - cat || Loss: 0.9501996040344238\n",
      "tensor([0., 1.]) tensor([0.6369, 0.3631], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 4 - 289: dog - cat || Loss: 0.9493448138237\n",
      "tensor([0., 1.]) tensor([0.6361, 0.3639], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 4 - 290: dog - cat || Loss: 0.948489785194397\n",
      "tensor([0., 1.]) tensor([0.6352, 0.3648], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 4 - 291: dog - cat || Loss: 0.947634220123291\n",
      "tensor([0., 1.]) tensor([0.6344, 0.3656], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 4 - 292: dog - cat || Loss: 0.9467781782150269\n",
      "tensor([0., 1.]) tensor([0.6335, 0.3665], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 4 - 293: dog - cat || Loss: 0.9459218978881836\n",
      "tensor([0., 1.]) tensor([0.6327, 0.3673], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 4 - 294: dog - cat || Loss: 0.9450651407241821\n",
      "tensor([0., 1.]) tensor([0.6318, 0.3682], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 4 - 295: dog - cat || Loss: 0.9442081451416016\n",
      "tensor([0., 1.]) tensor([0.6309, 0.3691], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 4 - 296: dog - cat || Loss: 0.9433505535125732\n",
      "tensor([0., 1.]) tensor([0.6301, 0.3699], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 4 - 297: dog - cat || Loss: 0.9424929022789001\n",
      "tensor([0., 1.]) tensor([0.6292, 0.3708], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 4 - 298: dog - cat || Loss: 0.9416346549987793\n",
      "tensor([0., 1.]) tensor([0.6284, 0.3716], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 4 - 299: dog - cat || Loss: 0.9407761693000793\n",
      "tensor([0., 1.]) tensor([0.6275, 0.3725], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 4 - 300: dog - cat || Loss: 0.9399172067642212\n",
      "tensor([0., 1.]) tensor([0.6267, 0.3733], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 4 - 301: dog - cat || Loss: 0.9390579462051392\n",
      "tensor([0., 1.]) tensor([0.6258, 0.3742], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 4 - 302: dog - cat || Loss: 0.9381985664367676\n",
      "tensor([0., 1.]) tensor([0.6249, 0.3751], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 4 - 303: dog - cat || Loss: 0.9373385310173035\n",
      "tensor([0., 1.]) tensor([0.6241, 0.3759], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 4 - 304: dog - cat || Loss: 0.9364783763885498\n",
      "tensor([0., 1.]) tensor([0.6232, 0.3768], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 4 - 305: dog - cat || Loss: 0.9356176257133484\n",
      "tensor([0., 1.]) tensor([0.6224, 0.3776], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 4 - 306: dog - cat || Loss: 0.9347568154335022\n",
      "tensor([0., 1.]) tensor([0.6215, 0.3785], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 4 - 307: dog - cat || Loss: 0.9338955879211426\n",
      "tensor([0., 1.]) tensor([0.6206, 0.3794], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 4 - 308: dog - cat || Loss: 0.9330337643623352\n",
      "tensor([0., 1.]) tensor([0.6198, 0.3802], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 4 - 309: dog - cat || Loss: 0.9321719408035278\n",
      "tensor([0., 1.]) tensor([0.6189, 0.3811], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 4 - 310: dog - cat || Loss: 0.9313095211982727\n",
      "tensor([0., 1.]) tensor([0.6180, 0.3820], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 4 - 311: dog - cat || Loss: 0.9304469227790833\n",
      "tensor([0., 1.]) tensor([0.6172, 0.3828], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 4 - 312: dog - cat || Loss: 0.9295840859413147\n",
      "tensor([0., 1.]) tensor([0.6163, 0.3837], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 4 - 313: dog - cat || Loss: 0.9287206530570984\n",
      "tensor([0., 1.]) tensor([0.6155, 0.3845], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 4 - 314: dog - cat || Loss: 0.9278572201728821\n",
      "tensor([0., 1.]) tensor([0.6146, 0.3854], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 4 - 315: dog - cat || Loss: 0.9269930720329285\n",
      "tensor([0., 1.]) tensor([0.6137, 0.3863], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 4 - 316: dog - cat || Loss: 0.9261289238929749\n",
      "tensor([0., 1.]) tensor([0.6129, 0.3871], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 4 - 317: dog - cat || Loss: 0.9252641797065735\n",
      "tensor([0., 1.]) tensor([0.6120, 0.3880], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 4 - 318: dog - cat || Loss: 0.9243991374969482\n",
      "tensor([0., 1.]) tensor([0.6111, 0.3889], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 4 - 319: dog - cat || Loss: 0.9235340356826782\n",
      "tensor([0., 1.]) tensor([0.6103, 0.3897], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 4 - 320: dog - cat || Loss: 0.9226682782173157\n",
      "tensor([0., 1.]) tensor([0.6094, 0.3906], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 4 - 321: dog - cat || Loss: 0.9218023419380188\n",
      "tensor([0., 1.]) tensor([0.6085, 0.3915], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 4 - 322: dog - cat || Loss: 0.920936107635498\n",
      "tensor([0., 1.]) tensor([0.6077, 0.3923], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 4 - 323: dog - cat || Loss: 0.9200693964958191\n",
      "tensor([0., 1.]) tensor([0.6068, 0.3932], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 4 - 324: dog - cat || Loss: 0.9192025065422058\n",
      "tensor([0., 1.]) tensor([0.6059, 0.3941], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 4 - 325: dog - cat || Loss: 0.9183350801467896\n",
      "tensor([0., 1.]) tensor([0.6051, 0.3949], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 4 - 326: dog - cat || Loss: 0.9174674153327942\n",
      "tensor([0., 1.]) tensor([0.6042, 0.3958], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 4 - 327: dog - cat || Loss: 0.9165993928909302\n",
      "tensor([0., 1.]) tensor([0.6033, 0.3967], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 4 - 328: dog - cat || Loss: 0.9157311916351318\n",
      "tensor([0., 1.]) tensor([0.6025, 0.3975], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 4 - 329: dog - cat || Loss: 0.9148626327514648\n",
      "tensor([0., 1.]) tensor([0.6016, 0.3984], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 4 - 330: dog - cat || Loss: 0.9139938354492188\n",
      "tensor([0., 1.]) tensor([0.6007, 0.3993], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 4 - 331: dog - cat || Loss: 0.9131246209144592\n",
      "tensor([0., 1.]) tensor([0.5999, 0.4001], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 4 - 332: dog - cat || Loss: 0.9122552871704102\n",
      "tensor([0., 1.]) tensor([0.5990, 0.4010], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 4 - 333: dog - cat || Loss: 0.9113855361938477\n",
      "tensor([0., 1.]) tensor([0.5981, 0.4019], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 4 - 334: dog - cat || Loss: 0.9105156660079956\n",
      "tensor([0., 1.]) tensor([0.5973, 0.4027], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 4 - 335: dog - cat || Loss: 0.9096454381942749\n",
      "tensor([0., 1.]) tensor([0.5964, 0.4036], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 4 - 336: dog - cat || Loss: 0.9087749719619751\n",
      "tensor([0., 1.]) tensor([0.5955, 0.4045], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 4 - 337: dog - cat || Loss: 0.9079042077064514\n",
      "tensor([0., 1.]) tensor([0.5946, 0.4054], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 4 - 338: dog - cat || Loss: 0.9070332050323486\n",
      "tensor([0., 1.]) tensor([0.5938, 0.4062], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 4 - 339: dog - cat || Loss: 0.906161904335022\n",
      "tensor([0., 1.]) tensor([0.5929, 0.4071], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 4 - 340: dog - cat || Loss: 0.9052904844284058\n",
      "tensor([0., 1.]) tensor([0.5920, 0.4080], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 4 - 341: dog - cat || Loss: 0.9044186472892761\n",
      "tensor([0., 1.]) tensor([0.5912, 0.4088], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 4 - 342: dog - cat || Loss: 0.9035465717315674\n",
      "tensor([0., 1.]) tensor([0.5903, 0.4097], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 4 - 343: dog - cat || Loss: 0.9026742577552795\n",
      "tensor([0., 1.]) tensor([0.5894, 0.4106], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 4 - 344: dog - cat || Loss: 0.9018018245697021\n",
      "tensor([0., 1.]) tensor([0.5885, 0.4115], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 4 - 345: dog - cat || Loss: 0.9009290933609009\n",
      "tensor([0., 1.]) tensor([0.5877, 0.4123], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 4 - 346: dog - cat || Loss: 0.9000561237335205\n",
      "tensor([0., 1.]) tensor([0.5868, 0.4132], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 4 - 347: dog - cat || Loss: 0.899182915687561\n",
      "tensor([0., 1.]) tensor([0.5859, 0.4141], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 4 - 348: dog - cat || Loss: 0.8983093500137329\n",
      "tensor([0., 1.]) tensor([0.5850, 0.4150], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 4 - 349: dog - cat || Loss: 0.89743572473526\n",
      "tensor([0., 1.]) tensor([0.5842, 0.4158], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 4 - 350: dog - cat || Loss: 0.8965619206428528\n",
      "tensor([0., 1.]) tensor([0.5833, 0.4167], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 4 - 351: dog - cat || Loss: 0.8956878185272217\n",
      "tensor([0., 1.]) tensor([0.5824, 0.4176], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 4 - 352: dog - cat || Loss: 0.8948137164115906\n",
      "tensor([0., 1.]) tensor([0.5816, 0.4184], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 4 - 353: dog - cat || Loss: 0.8939391374588013\n",
      "tensor([0., 1.]) tensor([0.5807, 0.4193], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 4 - 354: dog - cat || Loss: 0.8930643796920776\n",
      "tensor([0., 1.]) tensor([0.5798, 0.4202], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 4 - 355: dog - cat || Loss: 0.8921893835067749\n",
      "tensor([0., 1.]) tensor([0.5789, 0.4211], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 4 - 356: dog - cat || Loss: 0.8913143277168274\n",
      "tensor([0., 1.]) tensor([0.5781, 0.4219], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 4 - 357: dog - cat || Loss: 0.890438973903656\n",
      "tensor([0., 1.]) tensor([0.5772, 0.4228], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 4 - 358: dog - cat || Loss: 0.8895635604858398\n",
      "tensor([0., 1.]) tensor([0.5763, 0.4237], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 4 - 359: dog - cat || Loss: 0.8886879682540894\n",
      "tensor([0., 1.]) tensor([0.5754, 0.4246], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 4 - 360: dog - cat || Loss: 0.8878120183944702\n",
      "tensor([0., 1.]) tensor([0.5746, 0.4254], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 4 - 361: dog - cat || Loss: 0.886935830116272\n",
      "tensor([0., 1.]) tensor([0.5737, 0.4263], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 4 - 362: dog - cat || Loss: 0.8860596418380737\n",
      "tensor([0., 1.]) tensor([0.5728, 0.4272], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 4 - 363: dog - cat || Loss: 0.8851833939552307\n",
      "tensor([0., 1.]) tensor([0.5719, 0.4281], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 4 - 364: dog - cat || Loss: 0.8843068480491638\n",
      "tensor([0., 1.]) tensor([0.5710, 0.4290], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 4 - 365: dog - cat || Loss: 0.8834301829338074\n",
      "tensor([0., 1.]) tensor([0.5702, 0.4298], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 4 - 366: dog - cat || Loss: 0.8825533986091614\n",
      "tensor([0., 1.]) tensor([0.5693, 0.4307], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 4 - 367: dog - cat || Loss: 0.8816763162612915\n",
      "tensor([0., 1.]) tensor([0.5684, 0.4316], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 4 - 368: dog - cat || Loss: 0.8807991743087769\n",
      "tensor([0., 1.]) tensor([0.5675, 0.4325], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 4 - 369: dog - cat || Loss: 0.8799216747283936\n",
      "tensor([0., 1.]) tensor([0.5667, 0.4333], grad_fn=<SoftmaxBackward0>)\n",
      "=====epoch:5=====\n",
      "Epoch 5 - 0: cat - cat || Loss: 0.7474792003631592\n",
      "tensor([1., 0.]) tensor([0.5658, 0.4342], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 5 - 1: cat - cat || Loss: 0.7481811046600342\n",
      "tensor([1., 0.]) tensor([0.5651, 0.4349], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 5 - 2: cat - cat || Loss: 0.7487250566482544\n",
      "tensor([1., 0.]) tensor([0.5645, 0.4355], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 5 - 3: cat - cat || Loss: 0.7491265535354614\n",
      "tensor([1., 0.]) tensor([0.5641, 0.4359], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 5 - 4: cat - cat || Loss: 0.7494000792503357\n",
      "tensor([1., 0.]) tensor([0.5639, 0.4361], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 5 - 5: cat - cat || Loss: 0.7495582699775696\n",
      "tensor([1., 0.]) tensor([0.5637, 0.4363], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 5 - 6: cat - cat || Loss: 0.7496128678321838\n",
      "tensor([1., 0.]) tensor([0.5636, 0.4364], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 5 - 7: cat - cat || Loss: 0.7495739459991455\n",
      "tensor([1., 0.]) tensor([0.5637, 0.4363], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 5 - 8: cat - cat || Loss: 0.7494509816169739\n",
      "tensor([1., 0.]) tensor([0.5638, 0.4362], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 5 - 9: cat - cat || Loss: 0.7492526769638062\n",
      "tensor([1., 0.]) tensor([0.5640, 0.4360], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 5 - 10: cat - cat || Loss: 0.748986005783081\n",
      "tensor([1., 0.]) tensor([0.5643, 0.4357], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 5 - 11: cat - cat || Loss: 0.7486583590507507\n",
      "tensor([1., 0.]) tensor([0.5646, 0.4354], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 5 - 12: cat - cat || Loss: 0.748275637626648\n",
      "tensor([1., 0.]) tensor([0.5650, 0.4350], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 5 - 13: cat - cat || Loss: 0.7478435039520264\n",
      "tensor([1., 0.]) tensor([0.5654, 0.4346], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 5 - 14: cat - cat || Loss: 0.7473667860031128\n",
      "tensor([1., 0.]) tensor([0.5659, 0.4341], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 5 - 15: cat - cat || Loss: 0.7468499541282654\n",
      "tensor([1., 0.]) tensor([0.5664, 0.4336], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 5 - 16: cat - cat || Loss: 0.7462970018386841\n",
      "tensor([1., 0.]) tensor([0.5670, 0.4330], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 5 - 17: cat - cat || Loss: 0.7457118034362793\n",
      "tensor([1., 0.]) tensor([0.5675, 0.4325], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 5 - 18: cat - cat || Loss: 0.7450972199440002\n",
      "tensor([1., 0.]) tensor([0.5682, 0.4318], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 5 - 19: cat - cat || Loss: 0.74445641040802\n",
      "tensor([1., 0.]) tensor([0.5688, 0.4312], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 5 - 20: cat - cat || Loss: 0.7437920570373535\n",
      "tensor([1., 0.]) tensor([0.5695, 0.4305], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 5 - 21: cat - cat || Loss: 0.7431065440177917\n",
      "tensor([1., 0.]) tensor([0.5702, 0.4298], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 5 - 22: cat - cat || Loss: 0.7424018979072571\n",
      "tensor([1., 0.]) tensor([0.5709, 0.4291], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 5 - 23: cat - cat || Loss: 0.7416801452636719\n",
      "tensor([1., 0.]) tensor([0.5716, 0.4284], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 5 - 24: cat - cat || Loss: 0.7409428358078003\n",
      "tensor([1., 0.]) tensor([0.5723, 0.4277], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 5 - 25: cat - cat || Loss: 0.7401919364929199\n",
      "tensor([1., 0.]) tensor([0.5731, 0.4269], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 5 - 26: cat - cat || Loss: 0.7394286394119263\n",
      "tensor([1., 0.]) tensor([0.5738, 0.4262], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 5 - 27: cat - cat || Loss: 0.7386539578437805\n",
      "tensor([1., 0.]) tensor([0.5746, 0.4254], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 5 - 28: cat - cat || Loss: 0.7378695607185364\n",
      "tensor([1., 0.]) tensor([0.5754, 0.4246], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 5 - 29: cat - cat || Loss: 0.7370761632919312\n",
      "tensor([1., 0.]) tensor([0.5762, 0.4238], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 5 - 30: cat - cat || Loss: 0.7362747192382812\n",
      "tensor([1., 0.]) tensor([0.5770, 0.4230], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 5 - 31: cat - cat || Loss: 0.735465943813324\n",
      "tensor([1., 0.]) tensor([0.5778, 0.4222], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 5 - 32: cat - cat || Loss: 0.7346506714820862\n",
      "tensor([1., 0.]) tensor([0.5786, 0.4214], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 5 - 33: cat - cat || Loss: 0.7338297963142395\n",
      "tensor([1., 0.]) tensor([0.5794, 0.4206], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 5 - 34: cat - cat || Loss: 0.7330034971237183\n",
      "tensor([1., 0.]) tensor([0.5803, 0.4197], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 5 - 35: cat - cat || Loss: 0.7321724891662598\n",
      "tensor([1., 0.]) tensor([0.5811, 0.4189], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 5 - 36: cat - cat || Loss: 0.7313375473022461\n",
      "tensor([1., 0.]) tensor([0.5819, 0.4181], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 5 - 37: cat - cat || Loss: 0.7304986715316772\n",
      "tensor([1., 0.]) tensor([0.5828, 0.4172], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 5 - 38: cat - cat || Loss: 0.7296566963195801\n",
      "tensor([1., 0.]) tensor([0.5836, 0.4164], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 5 - 39: cat - cat || Loss: 0.7288115620613098\n",
      "tensor([1., 0.]) tensor([0.5845, 0.4155], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 5 - 40: cat - cat || Loss: 0.7279640436172485\n",
      "tensor([1., 0.]) tensor([0.5853, 0.4147], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 5 - 41: cat - cat || Loss: 0.7271137833595276\n",
      "tensor([1., 0.]) tensor([0.5861, 0.4139], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 5 - 42: cat - cat || Loss: 0.7262618541717529\n",
      "tensor([1., 0.]) tensor([0.5870, 0.4130], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 5 - 43: cat - cat || Loss: 0.7254077792167664\n",
      "tensor([1., 0.]) tensor([0.5879, 0.4121], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 5 - 44: cat - cat || Loss: 0.7245523929595947\n",
      "tensor([1., 0.]) tensor([0.5887, 0.4113], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 5 - 45: cat - cat || Loss: 0.7236955165863037\n",
      "tensor([1., 0.]) tensor([0.5896, 0.4104], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 5 - 46: cat - cat || Loss: 0.7228373289108276\n",
      "tensor([1., 0.]) tensor([0.5904, 0.4096], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 5 - 47: cat - cat || Loss: 0.7219780683517456\n",
      "tensor([1., 0.]) tensor([0.5913, 0.4087], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 5 - 48: cat - cat || Loss: 0.7211179733276367\n",
      "tensor([1., 0.]) tensor([0.5921, 0.4079], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 5 - 49: cat - cat || Loss: 0.7202569842338562\n",
      "tensor([1., 0.]) tensor([0.5930, 0.4070], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 5 - 50: cat - cat || Loss: 0.7193952202796936\n",
      "tensor([1., 0.]) tensor([0.5939, 0.4061], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 5 - 51: cat - cat || Loss: 0.718532919883728\n",
      "tensor([1., 0.]) tensor([0.5947, 0.4053], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 5 - 52: cat - cat || Loss: 0.7176700830459595\n",
      "tensor([1., 0.]) tensor([0.5956, 0.4044], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 5 - 53: cat - cat || Loss: 0.716806948184967\n",
      "tensor([1., 0.]) tensor([0.5965, 0.4035], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 5 - 54: cat - cat || Loss: 0.715943455696106\n",
      "tensor([1., 0.]) tensor([0.5973, 0.4027], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 5 - 55: cat - cat || Loss: 0.715079665184021\n",
      "tensor([1., 0.]) tensor([0.5982, 0.4018], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 5 - 56: cat - cat || Loss: 0.7142155766487122\n",
      "tensor([1., 0.]) tensor([0.5990, 0.4010], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 5 - 57: cat - cat || Loss: 0.7133512496948242\n",
      "tensor([1., 0.]) tensor([0.5999, 0.4001], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 5 - 58: cat - cat || Loss: 0.712486982345581\n",
      "tensor([1., 0.]) tensor([0.6008, 0.3992], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 5 - 59: cat - cat || Loss: 0.7116227149963379\n",
      "tensor([1., 0.]) tensor([0.6016, 0.3984], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 5 - 60: cat - cat || Loss: 0.7107583284378052\n",
      "tensor([1., 0.]) tensor([0.6025, 0.3975], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 5 - 61: cat - cat || Loss: 0.7098942399024963\n",
      "tensor([1., 0.]) tensor([0.6034, 0.3966], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 5 - 62: cat - cat || Loss: 0.709030032157898\n",
      "tensor([1., 0.]) tensor([0.6042, 0.3958], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 5 - 63: cat - cat || Loss: 0.7081663012504578\n",
      "tensor([1., 0.]) tensor([0.6051, 0.3949], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 5 - 64: cat - cat || Loss: 0.707302451133728\n",
      "tensor([1., 0.]) tensor([0.6060, 0.3940], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 5 - 65: cat - cat || Loss: 0.7064388990402222\n",
      "tensor([1., 0.]) tensor([0.6068, 0.3932], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 5 - 66: cat - cat || Loss: 0.705575704574585\n",
      "tensor([1., 0.]) tensor([0.6077, 0.3923], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 5 - 67: cat - cat || Loss: 0.7047125697135925\n",
      "tensor([1., 0.]) tensor([0.6085, 0.3915], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 5 - 68: cat - cat || Loss: 0.7038496732711792\n",
      "tensor([1., 0.]) tensor([0.6094, 0.3906], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 5 - 69: cat - cat || Loss: 0.702987015247345\n",
      "tensor([1., 0.]) tensor([0.6103, 0.3897], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 5 - 70: cat - cat || Loss: 0.7021247744560242\n",
      "tensor([1., 0.]) tensor([0.6111, 0.3889], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 5 - 71: cat - cat || Loss: 0.7012627720832825\n",
      "tensor([1., 0.]) tensor([0.6120, 0.3880], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 5 - 72: cat - cat || Loss: 0.7004009485244751\n",
      "tensor([1., 0.]) tensor([0.6129, 0.3871], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 5 - 73: cat - cat || Loss: 0.6995394825935364\n",
      "tensor([1., 0.]) tensor([0.6137, 0.3863], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 5 - 74: cat - cat || Loss: 0.6986783146858215\n",
      "tensor([1., 0.]) tensor([0.6146, 0.3854], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 5 - 75: cat - cat || Loss: 0.6978175640106201\n",
      "tensor([1., 0.]) tensor([0.6154, 0.3846], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 5 - 76: cat - cat || Loss: 0.6969571709632874\n",
      "tensor([1., 0.]) tensor([0.6163, 0.3837], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 5 - 77: cat - cat || Loss: 0.6960970759391785\n",
      "tensor([1., 0.]) tensor([0.6172, 0.3828], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 5 - 78: cat - cat || Loss: 0.6952371597290039\n",
      "tensor([1., 0.]) tensor([0.6180, 0.3820], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 5 - 79: cat - cat || Loss: 0.6943777799606323\n",
      "tensor([1., 0.]) tensor([0.6189, 0.3811], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 5 - 80: cat - cat || Loss: 0.6935186982154846\n",
      "tensor([1., 0.]) tensor([0.6197, 0.3803], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 5 - 81: cat - cat || Loss: 0.6926600337028503\n",
      "tensor([1., 0.]) tensor([0.6206, 0.3794], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 5 - 82: cat - cat || Loss: 0.6918016076087952\n",
      "tensor([1., 0.]) tensor([0.6215, 0.3785], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 5 - 83: cat - cat || Loss: 0.690943717956543\n",
      "tensor([1., 0.]) tensor([0.6223, 0.3777], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 5 - 84: cat - cat || Loss: 0.6900861859321594\n",
      "tensor([1., 0.]) tensor([0.6232, 0.3768], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 5 - 85: cat - cat || Loss: 0.6892289519309998\n",
      "tensor([1., 0.]) tensor([0.6240, 0.3760], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 5 - 86: cat - cat || Loss: 0.6883724331855774\n",
      "tensor([1., 0.]) tensor([0.6249, 0.3751], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 5 - 87: cat - cat || Loss: 0.6875161528587341\n",
      "tensor([1., 0.]) tensor([0.6257, 0.3743], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 5 - 88: cat - cat || Loss: 0.6866603493690491\n",
      "tensor([1., 0.]) tensor([0.6266, 0.3734], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 5 - 89: cat - cat || Loss: 0.6858047842979431\n",
      "tensor([1., 0.]) tensor([0.6275, 0.3725], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 5 - 90: cat - cat || Loss: 0.6849498152732849\n",
      "tensor([1., 0.]) tensor([0.6283, 0.3717], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 5 - 91: cat - cat || Loss: 0.6840949058532715\n",
      "tensor([1., 0.]) tensor([0.6292, 0.3708], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 5 - 92: cat - cat || Loss: 0.6832406520843506\n",
      "tensor([1., 0.]) tensor([0.6300, 0.3700], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 5 - 93: cat - cat || Loss: 0.6823867559432983\n",
      "tensor([1., 0.]) tensor([0.6309, 0.3691], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 5 - 94: cat - cat || Loss: 0.6815332174301147\n",
      "tensor([1., 0.]) tensor([0.6317, 0.3683], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 5 - 95: cat - cat || Loss: 0.6806802749633789\n",
      "tensor([1., 0.]) tensor([0.6326, 0.3674], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 5 - 96: cat - cat || Loss: 0.6798276901245117\n",
      "tensor([1., 0.]) tensor([0.6334, 0.3666], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 5 - 97: cat - cat || Loss: 0.6789755821228027\n",
      "tensor([1., 0.]) tensor([0.6343, 0.3657], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 5 - 98: cat - cat || Loss: 0.678123950958252\n",
      "tensor([1., 0.]) tensor([0.6351, 0.3649], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 5 - 99: cat - cat || Loss: 0.6772727966308594\n",
      "tensor([1., 0.]) tensor([0.6360, 0.3640], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 5 - 100: cat - cat || Loss: 0.6764219999313354\n",
      "tensor([1., 0.]) tensor([0.6368, 0.3632], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 5 - 101: cat - cat || Loss: 0.6755717396736145\n",
      "tensor([1., 0.]) tensor([0.6377, 0.3623], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 5 - 102: cat - cat || Loss: 0.6747220158576965\n",
      "tensor([1., 0.]) tensor([0.6385, 0.3615], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 5 - 103: cat - cat || Loss: 0.673872709274292\n",
      "tensor([1., 0.]) tensor([0.6394, 0.3606], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 5 - 104: cat - cat || Loss: 0.6730238199234009\n",
      "tensor([1., 0.]) tensor([0.6402, 0.3598], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 5 - 105: cat - cat || Loss: 0.672175407409668\n",
      "tensor([1., 0.]) tensor([0.6411, 0.3589], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 5 - 106: cat - cat || Loss: 0.6713274717330933\n",
      "tensor([1., 0.]) tensor([0.6419, 0.3581], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 5 - 107: cat - cat || Loss: 0.6704798340797424\n",
      "tensor([1., 0.]) tensor([0.6428, 0.3572], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 5 - 108: cat - cat || Loss: 0.6696327328681946\n",
      "tensor([1., 0.]) tensor([0.6436, 0.3564], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 5 - 109: cat - cat || Loss: 0.6687859892845154\n",
      "tensor([1., 0.]) tensor([0.6445, 0.3555], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 5 - 110: cat - cat || Loss: 0.6679396629333496\n",
      "tensor([1., 0.]) tensor([0.6453, 0.3547], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 5 - 111: cat - cat || Loss: 0.6670939922332764\n",
      "tensor([1., 0.]) tensor([0.6462, 0.3538], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 5 - 112: cat - cat || Loss: 0.6662486791610718\n",
      "tensor([1., 0.]) tensor([0.6470, 0.3530], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 5 - 113: cat - cat || Loss: 0.6654039025306702\n",
      "tensor([1., 0.]) tensor([0.6479, 0.3521], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 5 - 114: cat - cat || Loss: 0.6645594835281372\n",
      "tensor([1., 0.]) tensor([0.6487, 0.3513], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 5 - 115: cat - cat || Loss: 0.6637154817581177\n",
      "tensor([1., 0.]) tensor([0.6495, 0.3505], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 5 - 116: cat - cat || Loss: 0.6628720760345459\n",
      "tensor([1., 0.]) tensor([0.6504, 0.3496], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 5 - 117: cat - cat || Loss: 0.6620291471481323\n",
      "tensor([1., 0.]) tensor([0.6512, 0.3488], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 5 - 118: cat - cat || Loss: 0.6611865758895874\n",
      "tensor([1., 0.]) tensor([0.6521, 0.3479], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 5 - 119: cat - cat || Loss: 0.6603447198867798\n",
      "tensor([1., 0.]) tensor([0.6529, 0.3471], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 5 - 120: cat - cat || Loss: 0.6595032811164856\n",
      "tensor([1., 0.]) tensor([0.6538, 0.3462], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 5 - 121: cat - cat || Loss: 0.6586623191833496\n",
      "tensor([1., 0.]) tensor([0.6546, 0.3454], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 5 - 122: cat - cat || Loss: 0.6578219532966614\n",
      "tensor([1., 0.]) tensor([0.6554, 0.3446], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 5 - 123: cat - cat || Loss: 0.6569820046424866\n",
      "tensor([1., 0.]) tensor([0.6563, 0.3437], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 5 - 124: cat - cat || Loss: 0.6561425924301147\n",
      "tensor([1., 0.]) tensor([0.6571, 0.3429], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 5 - 125: cat - cat || Loss: 0.6553037166595459\n",
      "tensor([1., 0.]) tensor([0.6580, 0.3420], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 5 - 126: cat - cat || Loss: 0.6544651389122009\n",
      "tensor([1., 0.]) tensor([0.6588, 0.3412], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 5 - 127: cat - cat || Loss: 0.6536270380020142\n",
      "tensor([1., 0.]) tensor([0.6596, 0.3404], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 5 - 128: cat - cat || Loss: 0.6527896523475647\n",
      "tensor([1., 0.]) tensor([0.6605, 0.3395], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 5 - 129: cat - cat || Loss: 0.6519526839256287\n",
      "tensor([1., 0.]) tensor([0.6613, 0.3387], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 5 - 130: cat - cat || Loss: 0.6511161923408508\n",
      "tensor([1., 0.]) tensor([0.6621, 0.3379], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 5 - 131: cat - cat || Loss: 0.6502801179885864\n",
      "tensor([1., 0.]) tensor([0.6630, 0.3370], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 5 - 132: cat - cat || Loss: 0.6494446396827698\n",
      "tensor([1., 0.]) tensor([0.6638, 0.3362], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 5 - 133: cat - cat || Loss: 0.6486096382141113\n",
      "tensor([1., 0.]) tensor([0.6647, 0.3353], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 5 - 134: cat - cat || Loss: 0.6477751135826111\n",
      "tensor([1., 0.]) tensor([0.6655, 0.3345], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 5 - 135: cat - cat || Loss: 0.6469411849975586\n",
      "tensor([1., 0.]) tensor([0.6663, 0.3337], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 5 - 136: cat - cat || Loss: 0.6461079120635986\n",
      "tensor([1., 0.]) tensor([0.6672, 0.3328], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 5 - 137: cat - cat || Loss: 0.6452749371528625\n",
      "tensor([1., 0.]) tensor([0.6680, 0.3320], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 5 - 138: cat - cat || Loss: 0.6444424986839294\n",
      "tensor([1., 0.]) tensor([0.6688, 0.3312], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 5 - 139: cat - cat || Loss: 0.6436106562614441\n",
      "tensor([1., 0.]) tensor([0.6697, 0.3303], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 5 - 140: cat - cat || Loss: 0.6427793502807617\n",
      "tensor([1., 0.]) tensor([0.6705, 0.3295], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 5 - 141: cat - cat || Loss: 0.6419485807418823\n",
      "tensor([1., 0.]) tensor([0.6713, 0.3287], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 5 - 142: cat - cat || Loss: 0.6411183476448059\n",
      "tensor([1., 0.]) tensor([0.6721, 0.3279], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 5 - 143: cat - cat || Loss: 0.6402885913848877\n",
      "tensor([1., 0.]) tensor([0.6730, 0.3270], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 5 - 144: cat - cat || Loss: 0.6394594311714172\n",
      "tensor([1., 0.]) tensor([0.6738, 0.3262], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 5 - 145: cat - cat || Loss: 0.638630747795105\n",
      "tensor([1., 0.]) tensor([0.6746, 0.3254], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 5 - 146: cat - cat || Loss: 0.63780277967453\n",
      "tensor([1., 0.]) tensor([0.6755, 0.3245], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 5 - 147: cat - cat || Loss: 0.6369752287864685\n",
      "tensor([1., 0.]) tensor([0.6763, 0.3237], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 5 - 148: cat - cat || Loss: 0.63614821434021\n",
      "tensor([1., 0.]) tensor([0.6771, 0.3229], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 5 - 149: cat - cat || Loss: 0.6353219151496887\n",
      "tensor([1., 0.]) tensor([0.6779, 0.3221], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 5 - 150: cat - cat || Loss: 0.6344960331916809\n",
      "tensor([1., 0.]) tensor([0.6788, 0.3212], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 5 - 151: cat - cat || Loss: 0.6336708664894104\n",
      "tensor([1., 0.]) tensor([0.6796, 0.3204], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 5 - 152: cat - cat || Loss: 0.6328462362289429\n",
      "tensor([1., 0.]) tensor([0.6804, 0.3196], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 5 - 153: cat - cat || Loss: 0.6320221424102783\n",
      "tensor([1., 0.]) tensor([0.6812, 0.3188], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 5 - 154: cat - cat || Loss: 0.6311986446380615\n",
      "tensor([1., 0.]) tensor([0.6821, 0.3179], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 5 - 155: cat - cat || Loss: 0.6303756833076477\n",
      "tensor([1., 0.]) tensor([0.6829, 0.3171], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 5 - 156: cat - cat || Loss: 0.6295534372329712\n",
      "tensor([1., 0.]) tensor([0.6837, 0.3163], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 5 - 157: cat - cat || Loss: 0.6287317276000977\n",
      "tensor([1., 0.]) tensor([0.6845, 0.3155], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 5 - 158: cat - cat || Loss: 0.6279104948043823\n",
      "tensor([1., 0.]) tensor([0.6854, 0.3146], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 5 - 159: cat - cat || Loss: 0.6270899772644043\n",
      "tensor([1., 0.]) tensor([0.6862, 0.3138], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 5 - 160: cat - cat || Loss: 0.6262699365615845\n",
      "tensor([1., 0.]) tensor([0.6870, 0.3130], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 5 - 161: cat - cat || Loss: 0.6254504919052124\n",
      "tensor([1., 0.]) tensor([0.6878, 0.3122], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 5 - 162: cat - cat || Loss: 0.6246317625045776\n",
      "tensor([1., 0.]) tensor([0.6886, 0.3114], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 5 - 163: cat - cat || Loss: 0.6238133907318115\n",
      "tensor([1., 0.]) tensor([0.6894, 0.3106], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 5 - 164: cat - cat || Loss: 0.6229960322380066\n",
      "tensor([1., 0.]) tensor([0.6903, 0.3097], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 5 - 165: cat - cat || Loss: 0.6221790909767151\n",
      "tensor([1., 0.]) tensor([0.6911, 0.3089], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 5 - 166: cat - cat || Loss: 0.6213628053665161\n",
      "tensor([1., 0.]) tensor([0.6919, 0.3081], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 5 - 167: cat - cat || Loss: 0.6205471158027649\n",
      "tensor([1., 0.]) tensor([0.6927, 0.3073], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 5 - 168: cat - cat || Loss: 0.619732141494751\n",
      "tensor([1., 0.]) tensor([0.6935, 0.3065], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 5 - 169: cat - cat || Loss: 0.6189175844192505\n",
      "tensor([1., 0.]) tensor([0.6943, 0.3057], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 5 - 170: cat - cat || Loss: 0.6181036829948425\n",
      "tensor([1., 0.]) tensor([0.6952, 0.3048], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 5 - 171: cat - cat || Loss: 0.6172905564308167\n",
      "tensor([1., 0.]) tensor([0.6960, 0.3040], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 5 - 172: cat - cat || Loss: 0.616477906703949\n",
      "tensor([1., 0.]) tensor([0.6968, 0.3032], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 5 - 173: cat - cat || Loss: 0.6156661510467529\n",
      "tensor([1., 0.]) tensor([0.6976, 0.3024], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 5 - 174: cat - cat || Loss: 0.6148548126220703\n",
      "tensor([1., 0.]) tensor([0.6984, 0.3016], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 5 - 175: cat - cat || Loss: 0.6140440702438354\n",
      "tensor([1., 0.]) tensor([0.6992, 0.3008], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 5 - 176: cat - cat || Loss: 0.6132339835166931\n",
      "tensor([1., 0.]) tensor([0.7000, 0.3000], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 5 - 177: cat - cat || Loss: 0.6124245524406433\n",
      "tensor([1., 0.]) tensor([0.7008, 0.2992], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 5 - 178: cat - cat || Loss: 0.6116157174110413\n",
      "tensor([1., 0.]) tensor([0.7016, 0.2984], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 5 - 179: cat - cat || Loss: 0.6108075380325317\n",
      "tensor([1., 0.]) tensor([0.7025, 0.2975], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 5 - 180: cat - cat || Loss: 0.6099998950958252\n",
      "tensor([1., 0.]) tensor([0.7033, 0.2967], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 5 - 181: cat - cat || Loss: 0.609192967414856\n",
      "tensor([1., 0.]) tensor([0.7041, 0.2959], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 5 - 182: cat - cat || Loss: 0.6083868145942688\n",
      "tensor([1., 0.]) tensor([0.7049, 0.2951], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 5 - 183: cat - cat || Loss: 0.607581377029419\n",
      "tensor([1., 0.]) tensor([0.7057, 0.2943], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 5 - 184: cat - cat || Loss: 0.6067764759063721\n",
      "tensor([1., 0.]) tensor([0.7065, 0.2935], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 5 - 185: cat - cat || Loss: 0.6059726476669312\n",
      "tensor([1., 0.]) tensor([0.7073, 0.2927], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 5 - 186: cat - cat || Loss: 0.6051691770553589\n",
      "tensor([1., 0.]) tensor([0.7081, 0.2919], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 5 - 187: cat - cat || Loss: 0.6043666005134583\n",
      "tensor([1., 0.]) tensor([0.7089, 0.2911], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 5 - 188: cat - cat || Loss: 0.6035646796226501\n",
      "tensor([1., 0.]) tensor([0.7097, 0.2903], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 5 - 189: cat - cat || Loss: 0.6027633547782898\n",
      "tensor([1., 0.]) tensor([0.7105, 0.2895], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 5 - 190: dog - cat || Loss: 1.024560570716858\n",
      "tensor([0., 1.]) tensor([0.7113, 0.2887], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 5 - 191: dog - cat || Loss: 1.0252012014389038\n",
      "tensor([0., 1.]) tensor([0.7119, 0.2881], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 5 - 192: dog - cat || Loss: 1.0256975889205933\n",
      "tensor([0., 1.]) tensor([0.7124, 0.2876], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 5 - 193: dog - cat || Loss: 1.0260648727416992\n",
      "tensor([0., 1.]) tensor([0.7128, 0.2872], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 5 - 194: dog - cat || Loss: 1.026315450668335\n",
      "tensor([0., 1.]) tensor([0.7131, 0.2869], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 5 - 195: dog - cat || Loss: 1.0264616012573242\n",
      "tensor([0., 1.]) tensor([0.7132, 0.2868], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 5 - 196: dog - cat || Loss: 1.0265133380889893\n",
      "tensor([0., 1.]) tensor([0.7133, 0.2867], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 5 - 197: dog - cat || Loss: 1.0264801979064941\n",
      "tensor([0., 1.]) tensor([0.7132, 0.2868], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 5 - 198: dog - cat || Loss: 1.0263710021972656\n",
      "tensor([0., 1.]) tensor([0.7131, 0.2869], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 5 - 199: dog - cat || Loss: 1.0261932611465454\n",
      "tensor([0., 1.]) tensor([0.7129, 0.2871], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 5 - 200: dog - cat || Loss: 1.0259532928466797\n",
      "tensor([0., 1.]) tensor([0.7127, 0.2873], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 5 - 201: dog - cat || Loss: 1.0256578922271729\n",
      "tensor([0., 1.]) tensor([0.7124, 0.2876], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 5 - 202: dog - cat || Loss: 1.0253124237060547\n",
      "tensor([0., 1.]) tensor([0.7121, 0.2879], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 5 - 203: dog - cat || Loss: 1.0249215364456177\n",
      "tensor([0., 1.]) tensor([0.7117, 0.2883], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 5 - 204: dog - cat || Loss: 1.024490237236023\n",
      "tensor([0., 1.]) tensor([0.7112, 0.2888], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 5 - 205: dog - cat || Loss: 1.024022102355957\n",
      "tensor([0., 1.]) tensor([0.7108, 0.2892], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 5 - 206: dog - cat || Loss: 1.023521065711975\n",
      "tensor([0., 1.]) tensor([0.7103, 0.2897], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 5 - 207: dog - cat || Loss: 1.022990345954895\n",
      "tensor([0., 1.]) tensor([0.7097, 0.2903], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 5 - 208: dog - cat || Loss: 1.022432565689087\n",
      "tensor([0., 1.]) tensor([0.7092, 0.2908], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 5 - 209: dog - cat || Loss: 1.0218507051467896\n",
      "tensor([0., 1.]) tensor([0.7086, 0.2914], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 5 - 210: dog - cat || Loss: 1.0212469100952148\n",
      "tensor([0., 1.]) tensor([0.7080, 0.2920], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 5 - 211: dog - cat || Loss: 1.0206234455108643\n",
      "tensor([0., 1.]) tensor([0.7074, 0.2926], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 5 - 212: dog - cat || Loss: 1.0199819803237915\n",
      "tensor([0., 1.]) tensor([0.7067, 0.2933], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 5 - 213: dog - cat || Loss: 1.0193246603012085\n",
      "tensor([0., 1.]) tensor([0.7061, 0.2939], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 5 - 214: dog - cat || Loss: 1.0186526775360107\n",
      "tensor([0., 1.]) tensor([0.7054, 0.2946], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 5 - 215: dog - cat || Loss: 1.017967700958252\n",
      "tensor([0., 1.]) tensor([0.7047, 0.2953], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 5 - 216: dog - cat || Loss: 1.0172709226608276\n",
      "tensor([0., 1.]) tensor([0.7040, 0.2960], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 5 - 217: dog - cat || Loss: 1.0165631771087646\n",
      "tensor([0., 1.]) tensor([0.7033, 0.2967], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 5 - 218: dog - cat || Loss: 1.015845775604248\n",
      "tensor([0., 1.]) tensor([0.7026, 0.2974], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 5 - 219: dog - cat || Loss: 1.0151196718215942\n",
      "tensor([0., 1.]) tensor([0.7019, 0.2981], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 5 - 220: dog - cat || Loss: 1.01438570022583\n",
      "tensor([0., 1.]) tensor([0.7011, 0.2989], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 5 - 221: dog - cat || Loss: 1.0136443376541138\n",
      "tensor([0., 1.]) tensor([0.7004, 0.2996], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 5 - 222: dog - cat || Loss: 1.0128964185714722\n",
      "tensor([0., 1.]) tensor([0.6996, 0.3004], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 5 - 223: dog - cat || Loss: 1.0121424198150635\n",
      "tensor([0., 1.]) tensor([0.6989, 0.3011], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 5 - 224: dog - cat || Loss: 1.0113831758499146\n",
      "tensor([0., 1.]) tensor([0.6981, 0.3019], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 5 - 225: dog - cat || Loss: 1.010619044303894\n",
      "tensor([0., 1.]) tensor([0.6974, 0.3026], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 5 - 226: dog - cat || Loss: 1.0098503828048706\n",
      "tensor([0., 1.]) tensor([0.6966, 0.3034], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 5 - 227: dog - cat || Loss: 1.009077548980713\n",
      "tensor([0., 1.]) tensor([0.6958, 0.3042], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 5 - 228: dog - cat || Loss: 1.0083009004592896\n",
      "tensor([0., 1.]) tensor([0.6950, 0.3050], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 5 - 229: dog - cat || Loss: 1.0075210332870483\n",
      "tensor([0., 1.]) tensor([0.6943, 0.3057], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 5 - 230: dog - cat || Loss: 1.0067377090454102\n",
      "tensor([0., 1.]) tensor([0.6935, 0.3065], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 5 - 231: dog - cat || Loss: 1.0059517621994019\n",
      "tensor([0., 1.]) tensor([0.6927, 0.3073], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 5 - 232: dog - cat || Loss: 1.0051630735397339\n",
      "tensor([0., 1.]) tensor([0.6919, 0.3081], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 5 - 233: dog - cat || Loss: 1.0043718814849854\n",
      "tensor([0., 1.]) tensor([0.6911, 0.3089], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 5 - 234: dog - cat || Loss: 1.003578543663025\n",
      "tensor([0., 1.]) tensor([0.6903, 0.3097], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 5 - 235: dog - cat || Loss: 1.0027830600738525\n",
      "tensor([0., 1.]) tensor([0.6895, 0.3105], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 5 - 236: dog - cat || Loss: 1.0019854307174683\n",
      "tensor([0., 1.]) tensor([0.6887, 0.3113], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 5 - 237: dog - cat || Loss: 1.0011861324310303\n",
      "tensor([0., 1.]) tensor([0.6879, 0.3121], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 5 - 238: dog - cat || Loss: 1.0003854036331177\n",
      "tensor([0., 1.]) tensor([0.6871, 0.3129], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 5 - 239: dog - cat || Loss: 0.9995827674865723\n",
      "tensor([0., 1.]) tensor([0.6863, 0.3137], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 5 - 240: dog - cat || Loss: 0.9987788200378418\n",
      "tensor([0., 1.]) tensor([0.6855, 0.3145], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 5 - 241: dog - cat || Loss: 0.9979735612869263\n",
      "tensor([0., 1.]) tensor([0.6847, 0.3153], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 5 - 242: dog - cat || Loss: 0.9971669912338257\n",
      "tensor([0., 1.]) tensor([0.6839, 0.3161], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 5 - 243: dog - cat || Loss: 0.9963593482971191\n",
      "tensor([0., 1.]) tensor([0.6831, 0.3169], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 5 - 244: dog - cat || Loss: 0.9955506920814514\n",
      "tensor([0., 1.]) tensor([0.6823, 0.3177], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 5 - 245: dog - cat || Loss: 0.9947407245635986\n",
      "tensor([0., 1.]) tensor([0.6815, 0.3185], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 5 - 246: dog - cat || Loss: 0.9939298033714294\n",
      "tensor([0., 1.]) tensor([0.6807, 0.3193], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 5 - 247: dog - cat || Loss: 0.9931180477142334\n",
      "tensor([0., 1.]) tensor([0.6799, 0.3201], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 5 - 248: dog - cat || Loss: 0.9923053979873657\n",
      "tensor([0., 1.]) tensor([0.6790, 0.3210], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 5 - 249: dog - cat || Loss: 0.9914916753768921\n",
      "tensor([0., 1.]) tensor([0.6782, 0.3218], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 5 - 250: dog - cat || Loss: 0.9906773567199707\n",
      "tensor([0., 1.]) tensor([0.6774, 0.3226], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 5 - 251: dog - cat || Loss: 0.9898622035980225\n",
      "tensor([0., 1.]) tensor([0.6766, 0.3234], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 5 - 252: dog - cat || Loss: 0.9890462756156921\n",
      "tensor([0., 1.]) tensor([0.6758, 0.3242], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 5 - 253: dog - cat || Loss: 0.988229513168335\n",
      "tensor([0., 1.]) tensor([0.6750, 0.3250], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 5 - 254: dog - cat || Loss: 0.9874120354652405\n",
      "tensor([0., 1.]) tensor([0.6742, 0.3258], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 5 - 255: dog - cat || Loss: 0.9865939617156982\n",
      "tensor([0., 1.]) tensor([0.6733, 0.3267], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 5 - 256: dog - cat || Loss: 0.9857751727104187\n",
      "tensor([0., 1.]) tensor([0.6725, 0.3275], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 5 - 257: dog - cat || Loss: 0.9849557876586914\n",
      "tensor([0., 1.]) tensor([0.6717, 0.3283], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 5 - 258: dog - cat || Loss: 0.9841357469558716\n",
      "tensor([0., 1.]) tensor([0.6709, 0.3291], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 5 - 259: dog - cat || Loss: 0.9833151698112488\n",
      "tensor([0., 1.]) tensor([0.6701, 0.3299], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 5 - 260: dog - cat || Loss: 0.9824939370155334\n",
      "tensor([0., 1.]) tensor([0.6692, 0.3308], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 5 - 261: dog - cat || Loss: 0.9816722869873047\n",
      "tensor([0., 1.]) tensor([0.6684, 0.3316], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 5 - 262: dog - cat || Loss: 0.9808499217033386\n",
      "tensor([0., 1.]) tensor([0.6676, 0.3324], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 5 - 263: dog - cat || Loss: 0.9800270199775696\n",
      "tensor([0., 1.]) tensor([0.6668, 0.3332], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 5 - 264: dog - cat || Loss: 0.9792035818099976\n",
      "tensor([0., 1.]) tensor([0.6659, 0.3341], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 5 - 265: dog - cat || Loss: 0.9783795475959778\n",
      "tensor([0., 1.]) tensor([0.6651, 0.3349], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 5 - 266: dog - cat || Loss: 0.9775552153587341\n",
      "tensor([0., 1.]) tensor([0.6643, 0.3357], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 5 - 267: dog - cat || Loss: 0.9767303466796875\n",
      "tensor([0., 1.]) tensor([0.6635, 0.3365], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 5 - 268: dog - cat || Loss: 0.9759048223495483\n",
      "tensor([0., 1.]) tensor([0.6626, 0.3374], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 5 - 269: dog - cat || Loss: 0.975078821182251\n",
      "tensor([0., 1.]) tensor([0.6618, 0.3382], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 5 - 270: dog - cat || Loss: 0.974252462387085\n",
      "tensor([0., 1.]) tensor([0.6610, 0.3390], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 5 - 271: dog - cat || Loss: 0.973425567150116\n",
      "tensor([0., 1.]) tensor([0.6602, 0.3398], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 5 - 272: dog - cat || Loss: 0.9725980758666992\n",
      "tensor([0., 1.]) tensor([0.6593, 0.3407], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 5 - 273: dog - cat || Loss: 0.9717701077461243\n",
      "tensor([0., 1.]) tensor([0.6585, 0.3415], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 5 - 274: dog - cat || Loss: 0.9709417819976807\n",
      "tensor([0., 1.]) tensor([0.6577, 0.3423], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 5 - 275: dog - cat || Loss: 0.9701128602027893\n",
      "tensor([0., 1.]) tensor([0.6569, 0.3431], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 5 - 276: dog - cat || Loss: 0.9692835807800293\n",
      "tensor([0., 1.]) tensor([0.6560, 0.3440], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 5 - 277: dog - cat || Loss: 0.9684538245201111\n",
      "tensor([0., 1.]) tensor([0.6552, 0.3448], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 5 - 278: dog - cat || Loss: 0.9676237106323242\n",
      "tensor([0., 1.]) tensor([0.6544, 0.3456], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 5 - 279: dog - cat || Loss: 0.9667931199073792\n",
      "tensor([0., 1.]) tensor([0.6535, 0.3465], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 5 - 280: dog - cat || Loss: 0.9659620523452759\n",
      "tensor([0., 1.]) tensor([0.6527, 0.3473], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 5 - 281: dog - cat || Loss: 0.9651306867599487\n",
      "tensor([0., 1.]) tensor([0.6519, 0.3481], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 5 - 282: dog - cat || Loss: 0.9642989039421082\n",
      "tensor([0., 1.]) tensor([0.6510, 0.3490], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 5 - 283: dog - cat || Loss: 0.9634666442871094\n",
      "tensor([0., 1.]) tensor([0.6502, 0.3498], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 5 - 284: dog - cat || Loss: 0.9626338481903076\n",
      "tensor([0., 1.]) tensor([0.6494, 0.3506], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 5 - 285: dog - cat || Loss: 0.9618006944656372\n",
      "tensor([0., 1.]) tensor([0.6485, 0.3515], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 5 - 286: dog - cat || Loss: 0.9609672427177429\n",
      "tensor([0., 1.]) tensor([0.6477, 0.3523], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 5 - 287: dog - cat || Loss: 0.9601330757141113\n",
      "tensor([0., 1.]) tensor([0.6469, 0.3531], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 5 - 288: dog - cat || Loss: 0.9592987298965454\n",
      "tensor([0., 1.]) tensor([0.6460, 0.3540], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 5 - 289: dog - cat || Loss: 0.9584637880325317\n",
      "tensor([0., 1.]) tensor([0.6452, 0.3548], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 5 - 290: dog - cat || Loss: 0.957628607749939\n",
      "tensor([0., 1.]) tensor([0.6444, 0.3556], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 5 - 291: dog - cat || Loss: 0.9567930698394775\n",
      "tensor([0., 1.]) tensor([0.6435, 0.3565], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 5 - 292: dog - cat || Loss: 0.9559569954872131\n",
      "tensor([0., 1.]) tensor([0.6427, 0.3573], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 5 - 293: dog - cat || Loss: 0.9551206231117249\n",
      "tensor([0., 1.]) tensor([0.6419, 0.3581], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 5 - 294: dog - cat || Loss: 0.9542838335037231\n",
      "tensor([0., 1.]) tensor([0.6410, 0.3590], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 5 - 295: dog - cat || Loss: 0.9534465670585632\n",
      "tensor([0., 1.]) tensor([0.6402, 0.3598], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 5 - 296: dog - cat || Loss: 0.9526088237762451\n",
      "tensor([0., 1.]) tensor([0.6393, 0.3607], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 5 - 297: dog - cat || Loss: 0.9517707824707031\n",
      "tensor([0., 1.]) tensor([0.6385, 0.3615], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 5 - 298: dog - cat || Loss: 0.9509323239326477\n",
      "tensor([0., 1.]) tensor([0.6377, 0.3623], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 5 - 299: dog - cat || Loss: 0.9500935673713684\n",
      "tensor([0., 1.]) tensor([0.6368, 0.3632], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 5 - 300: dog - cat || Loss: 0.9492542743682861\n",
      "tensor([0., 1.]) tensor([0.6360, 0.3640], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 5 - 301: dog - cat || Loss: 0.9484146237373352\n",
      "tensor([0., 1.]) tensor([0.6352, 0.3648], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 5 - 302: dog - cat || Loss: 0.9475746750831604\n",
      "tensor([0., 1.]) tensor([0.6343, 0.3657], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 5 - 303: dog - cat || Loss: 0.9467342495918274\n",
      "tensor([0., 1.]) tensor([0.6335, 0.3665], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 5 - 304: dog - cat || Loss: 0.9458937048912048\n",
      "tensor([0., 1.]) tensor([0.6326, 0.3674], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 5 - 305: dog - cat || Loss: 0.9450523853302002\n",
      "tensor([0., 1.]) tensor([0.6318, 0.3682], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 5 - 306: dog - cat || Loss: 0.9442110657691956\n",
      "tensor([0., 1.]) tensor([0.6309, 0.3691], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 5 - 307: dog - cat || Loss: 0.9433692693710327\n",
      "tensor([0., 1.]) tensor([0.6301, 0.3699], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 5 - 308: dog - cat || Loss: 0.9425270557403564\n",
      "tensor([0., 1.]) tensor([0.6293, 0.3707], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 5 - 309: dog - cat || Loss: 0.9416847229003906\n",
      "tensor([0., 1.]) tensor([0.6284, 0.3716], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 5 - 310: dog - cat || Loss: 0.940841794013977\n",
      "tensor([0., 1.]) tensor([0.6276, 0.3724], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 5 - 311: dog - cat || Loss: 0.9399985671043396\n",
      "tensor([0., 1.]) tensor([0.6267, 0.3733], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 5 - 312: dog - cat || Loss: 0.9391550421714783\n",
      "tensor([0., 1.]) tensor([0.6259, 0.3741], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 5 - 313: dog - cat || Loss: 0.9383111000061035\n",
      "tensor([0., 1.]) tensor([0.6250, 0.3750], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 5 - 314: dog - cat || Loss: 0.9374667406082153\n",
      "tensor([0., 1.]) tensor([0.6242, 0.3758], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 5 - 315: dog - cat || Loss: 0.936621904373169\n",
      "tensor([0., 1.]) tensor([0.6234, 0.3766], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 5 - 316: dog - cat || Loss: 0.9357768893241882\n",
      "tensor([0., 1.]) tensor([0.6225, 0.3775], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 5 - 317: dog - cat || Loss: 0.9349313974380493\n",
      "tensor([0., 1.]) tensor([0.6217, 0.3783], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 5 - 318: dog - cat || Loss: 0.9340856671333313\n",
      "tensor([0., 1.]) tensor([0.6208, 0.3792], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 5 - 319: dog - cat || Loss: 0.9332395195960999\n",
      "tensor([0., 1.]) tensor([0.6200, 0.3800], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 5 - 320: dog - cat || Loss: 0.9323930740356445\n",
      "tensor([0., 1.]) tensor([0.6191, 0.3809], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 5 - 321: dog - cat || Loss: 0.9315462112426758\n",
      "tensor([0., 1.]) tensor([0.6183, 0.3817], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 5 - 322: dog - cat || Loss: 0.9306991100311279\n",
      "tensor([0., 1.]) tensor([0.6174, 0.3826], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 5 - 323: dog - cat || Loss: 0.9298516511917114\n",
      "tensor([0., 1.]) tensor([0.6166, 0.3834], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 5 - 324: dog - cat || Loss: 0.929003894329071\n",
      "tensor([0., 1.]) tensor([0.6157, 0.3843], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 5 - 325: dog - cat || Loss: 0.9281558990478516\n",
      "tensor([0., 1.]) tensor([0.6149, 0.3851], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 5 - 326: dog - cat || Loss: 0.9273075461387634\n",
      "tensor([0., 1.]) tensor([0.6140, 0.3860], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 5 - 327: dog - cat || Loss: 0.9264587163925171\n",
      "tensor([0., 1.]) tensor([0.6132, 0.3868], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 5 - 328: dog - cat || Loss: 0.925609827041626\n",
      "tensor([0., 1.]) tensor([0.6123, 0.3877], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 5 - 329: dog - cat || Loss: 0.9247605800628662\n",
      "tensor([0., 1.]) tensor([0.6115, 0.3885], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 5 - 330: dog - cat || Loss: 0.9239109754562378\n",
      "tensor([0., 1.]) tensor([0.6106, 0.3894], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 5 - 331: dog - cat || Loss: 0.9230608940124512\n",
      "tensor([0., 1.]) tensor([0.6098, 0.3902], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 5 - 332: dog - cat || Loss: 0.922210693359375\n",
      "tensor([0., 1.]) tensor([0.6089, 0.3911], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 5 - 333: dog - cat || Loss: 0.9213600158691406\n",
      "tensor([0., 1.]) tensor([0.6081, 0.3919], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 5 - 334: dog - cat || Loss: 0.9205090403556824\n",
      "tensor([0., 1.]) tensor([0.6072, 0.3928], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 5 - 335: dog - cat || Loss: 0.919657826423645\n",
      "tensor([0., 1.]) tensor([0.6064, 0.3936], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 5 - 336: dog - cat || Loss: 0.9188061952590942\n",
      "tensor([0., 1.]) tensor([0.6055, 0.3945], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 5 - 337: dog - cat || Loss: 0.9179543256759644\n",
      "tensor([0., 1.]) tensor([0.6047, 0.3953], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 5 - 338: dog - cat || Loss: 0.9171020984649658\n",
      "tensor([0., 1.]) tensor([0.6038, 0.3962], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 5 - 339: dog - cat || Loss: 0.9162495136260986\n",
      "tensor([0., 1.]) tensor([0.6030, 0.3970], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 5 - 340: dog - cat || Loss: 0.9153966903686523\n",
      "tensor([0., 1.]) tensor([0.6021, 0.3979], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 5 - 341: dog - cat || Loss: 0.9145434498786926\n",
      "tensor([0., 1.]) tensor([0.6013, 0.3987], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 5 - 342: dog - cat || Loss: 0.9136900305747986\n",
      "tensor([0., 1.]) tensor([0.6004, 0.3996], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 5 - 343: dog - cat || Loss: 0.9128362536430359\n",
      "tensor([0., 1.]) tensor([0.5996, 0.4004], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 5 - 344: dog - cat || Loss: 0.9119822978973389\n",
      "tensor([0., 1.]) tensor([0.5987, 0.4013], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 5 - 345: dog - cat || Loss: 0.9111279249191284\n",
      "tensor([0., 1.]) tensor([0.5979, 0.4021], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 5 - 346: dog - cat || Loss: 0.9102733135223389\n",
      "tensor([0., 1.]) tensor([0.5970, 0.4030], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 5 - 347: dog - cat || Loss: 0.9094184041023254\n",
      "tensor([0., 1.]) tensor([0.5962, 0.4038], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 5 - 348: dog - cat || Loss: 0.9085631966590881\n",
      "tensor([0., 1.]) tensor([0.5953, 0.4047], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 5 - 349: dog - cat || Loss: 0.907707691192627\n",
      "tensor([0., 1.]) tensor([0.5944, 0.4056], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 5 - 350: dog - cat || Loss: 0.9068520069122314\n",
      "tensor([0., 1.]) tensor([0.5936, 0.4064], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 5 - 351: dog - cat || Loss: 0.9059958457946777\n",
      "tensor([0., 1.]) tensor([0.5927, 0.4073], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 5 - 352: dog - cat || Loss: 0.9051395654678345\n",
      "tensor([0., 1.]) tensor([0.5919, 0.4081], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 5 - 353: dog - cat || Loss: 0.9042829275131226\n",
      "tensor([0., 1.]) tensor([0.5910, 0.4090], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 5 - 354: dog - cat || Loss: 0.9034260511398315\n",
      "tensor([0., 1.]) tensor([0.5902, 0.4098], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 5 - 355: dog - cat || Loss: 0.9025689959526062\n",
      "tensor([0., 1.]) tensor([0.5893, 0.4107], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 5 - 356: dog - cat || Loss: 0.9017114639282227\n",
      "tensor([0., 1.]) tensor([0.5884, 0.4116], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 5 - 357: dog - cat || Loss: 0.9008537530899048\n",
      "tensor([0., 1.]) tensor([0.5876, 0.4124], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 5 - 358: dog - cat || Loss: 0.8999958038330078\n",
      "tensor([0., 1.]) tensor([0.5867, 0.4133], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 5 - 359: dog - cat || Loss: 0.8991377353668213\n",
      "tensor([0., 1.]) tensor([0.5859, 0.4141], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 5 - 360: dog - cat || Loss: 0.8982791900634766\n",
      "tensor([0., 1.]) tensor([0.5850, 0.4150], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 5 - 361: dog - cat || Loss: 0.8974204063415527\n",
      "tensor([0., 1.]) tensor([0.5842, 0.4158], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 5 - 362: dog - cat || Loss: 0.8965613842010498\n",
      "tensor([0., 1.]) tensor([0.5833, 0.4167], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 5 - 363: dog - cat || Loss: 0.8957021832466125\n",
      "tensor([0., 1.]) tensor([0.5824, 0.4176], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 5 - 364: dog - cat || Loss: 0.8948426246643066\n",
      "tensor([0., 1.]) tensor([0.5816, 0.4184], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 5 - 365: dog - cat || Loss: 0.8939828276634216\n",
      "tensor([0., 1.]) tensor([0.5807, 0.4193], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 5 - 366: dog - cat || Loss: 0.8931227922439575\n",
      "tensor([0., 1.]) tensor([0.5799, 0.4201], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 5 - 367: dog - cat || Loss: 0.8922623991966248\n",
      "tensor([0., 1.]) tensor([0.5790, 0.4210], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 5 - 368: dog - cat || Loss: 0.8914017677307129\n",
      "tensor([0., 1.]) tensor([0.5781, 0.4219], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 5 - 369: dog - cat || Loss: 0.8905408382415771\n",
      "tensor([0., 1.]) tensor([0.5773, 0.4227], grad_fn=<SoftmaxBackward0>)\n",
      "=====epoch:6=====\n",
      "Epoch 6 - 0: cat - cat || Loss: 0.7368435263633728\n",
      "tensor([1., 0.]) tensor([0.5764, 0.4236], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 6 - 1: cat - cat || Loss: 0.7375321984291077\n",
      "tensor([1., 0.]) tensor([0.5757, 0.4243], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 6 - 2: cat - cat || Loss: 0.7380658984184265\n",
      "tensor([1., 0.]) tensor([0.5752, 0.4248], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 6 - 3: cat - cat || Loss: 0.7384597659111023\n",
      "tensor([1., 0.]) tensor([0.5748, 0.4252], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 6 - 4: cat - cat || Loss: 0.7387279272079468\n",
      "tensor([1., 0.]) tensor([0.5745, 0.4255], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 6 - 5: cat - cat || Loss: 0.7388830184936523\n",
      "tensor([1., 0.]) tensor([0.5744, 0.4256], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 6 - 6: cat - cat || Loss: 0.7389363050460815\n",
      "tensor([1., 0.]) tensor([0.5743, 0.4257], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 6 - 7: cat - cat || Loss: 0.7388977408409119\n",
      "tensor([1., 0.]) tensor([0.5744, 0.4256], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 6 - 8: cat - cat || Loss: 0.7387769222259521\n",
      "tensor([1., 0.]) tensor([0.5745, 0.4255], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 6 - 9: cat - cat || Loss: 0.7385820150375366\n",
      "tensor([1., 0.]) tensor([0.5747, 0.4253], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 6 - 10: cat - cat || Loss: 0.738319993019104\n",
      "tensor([1., 0.]) tensor([0.5749, 0.4251], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 6 - 11: cat - cat || Loss: 0.7379981279373169\n",
      "tensor([1., 0.]) tensor([0.5753, 0.4247], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 6 - 12: cat - cat || Loss: 0.7376223206520081\n",
      "tensor([1., 0.]) tensor([0.5756, 0.4244], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 6 - 13: cat - cat || Loss: 0.737197756767273\n",
      "tensor([1., 0.]) tensor([0.5761, 0.4239], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 6 - 14: cat - cat || Loss: 0.7367295622825623\n",
      "tensor([1., 0.]) tensor([0.5765, 0.4235], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 6 - 15: cat - cat || Loss: 0.7362220287322998\n",
      "tensor([1., 0.]) tensor([0.5770, 0.4230], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 6 - 16: cat - cat || Loss: 0.7356792688369751\n",
      "tensor([1., 0.]) tensor([0.5776, 0.4224], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 6 - 17: cat - cat || Loss: 0.7351045608520508\n",
      "tensor([1., 0.]) tensor([0.5782, 0.4218], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 6 - 18: cat - cat || Loss: 0.734501302242279\n",
      "tensor([1., 0.]) tensor([0.5788, 0.4212], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 6 - 19: cat - cat || Loss: 0.7338722944259644\n",
      "tensor([1., 0.]) tensor([0.5794, 0.4206], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 6 - 20: cat - cat || Loss: 0.7332202196121216\n",
      "tensor([1., 0.]) tensor([0.5800, 0.4200], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 6 - 21: cat - cat || Loss: 0.732547402381897\n",
      "tensor([1., 0.]) tensor([0.5807, 0.4193], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 6 - 22: cat - cat || Loss: 0.731856107711792\n",
      "tensor([1., 0.]) tensor([0.5814, 0.4186], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 6 - 23: cat - cat || Loss: 0.7311480045318604\n",
      "tensor([1., 0.]) tensor([0.5821, 0.4179], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 6 - 24: cat - cat || Loss: 0.7304247617721558\n",
      "tensor([1., 0.]) tensor([0.5828, 0.4172], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 6 - 25: cat - cat || Loss: 0.7296880483627319\n",
      "tensor([1., 0.]) tensor([0.5836, 0.4164], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 6 - 26: cat - cat || Loss: 0.7289391756057739\n",
      "tensor([1., 0.]) tensor([0.5843, 0.4157], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 6 - 27: cat - cat || Loss: 0.7281794548034668\n",
      "tensor([1., 0.]) tensor([0.5851, 0.4149], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 6 - 28: cat - cat || Loss: 0.7274100184440613\n",
      "tensor([1., 0.]) tensor([0.5859, 0.4141], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 6 - 29: cat - cat || Loss: 0.7266316413879395\n",
      "tensor([1., 0.]) tensor([0.5866, 0.4134], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 6 - 30: cat - cat || Loss: 0.7258456349372864\n",
      "tensor([1., 0.]) tensor([0.5874, 0.4126], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 6 - 31: cat - cat || Loss: 0.7250524759292603\n",
      "tensor([1., 0.]) tensor([0.5882, 0.4118], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 6 - 32: cat - cat || Loss: 0.7242529392242432\n",
      "tensor([1., 0.]) tensor([0.5890, 0.4110], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 6 - 33: cat - cat || Loss: 0.723447859287262\n",
      "tensor([1., 0.]) tensor([0.5898, 0.4102], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 6 - 34: cat - cat || Loss: 0.7226377129554749\n",
      "tensor([1., 0.]) tensor([0.5906, 0.4094], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 6 - 35: cat - cat || Loss: 0.7218229174613953\n",
      "tensor([1., 0.]) tensor([0.5914, 0.4086], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 6 - 36: cat - cat || Loss: 0.7210043668746948\n",
      "tensor([1., 0.]) tensor([0.5923, 0.4077], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 6 - 37: cat - cat || Loss: 0.7201820015907288\n",
      "tensor([1., 0.]) tensor([0.5931, 0.4069], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 6 - 38: cat - cat || Loss: 0.7193565368652344\n",
      "tensor([1., 0.]) tensor([0.5939, 0.4061], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 6 - 39: cat - cat || Loss: 0.7185280323028564\n",
      "tensor([1., 0.]) tensor([0.5947, 0.4053], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 6 - 40: cat - cat || Loss: 0.717697262763977\n",
      "tensor([1., 0.]) tensor([0.5956, 0.4044], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 6 - 41: cat - cat || Loss: 0.7168641090393066\n",
      "tensor([1., 0.]) tensor([0.5964, 0.4036], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 6 - 42: cat - cat || Loss: 0.7160292863845825\n",
      "tensor([1., 0.]) tensor([0.5972, 0.4028], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 6 - 43: cat - cat || Loss: 0.7151925563812256\n",
      "tensor([1., 0.]) tensor([0.5981, 0.4019], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 6 - 44: cat - cat || Loss: 0.7143542766571045\n",
      "tensor([1., 0.]) tensor([0.5989, 0.4011], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 6 - 45: cat - cat || Loss: 0.7135147452354431\n",
      "tensor([1., 0.]) tensor([0.5997, 0.4003], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 6 - 46: cat - cat || Loss: 0.7126739621162415\n",
      "tensor([1., 0.]) tensor([0.6006, 0.3994], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 6 - 47: cat - cat || Loss: 0.7118322253227234\n",
      "tensor([1., 0.]) tensor([0.6014, 0.3986], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 6 - 48: cat - cat || Loss: 0.7109895944595337\n",
      "tensor([1., 0.]) tensor([0.6023, 0.3977], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 6 - 49: cat - cat || Loss: 0.7101461887359619\n",
      "tensor([1., 0.]) tensor([0.6031, 0.3969], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 6 - 50: cat - cat || Loss: 0.7093020677566528\n",
      "tensor([1., 0.]) tensor([0.6040, 0.3960], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 6 - 51: cat - cat || Loss: 0.7084575891494751\n",
      "tensor([1., 0.]) tensor([0.6048, 0.3952], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 6 - 52: cat - cat || Loss: 0.7076128125190735\n",
      "tensor([1., 0.]) tensor([0.6056, 0.3944], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 6 - 53: cat - cat || Loss: 0.7067676186561584\n",
      "tensor([1., 0.]) tensor([0.6065, 0.3935], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 6 - 54: cat - cat || Loss: 0.7059222459793091\n",
      "tensor([1., 0.]) tensor([0.6073, 0.3927], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 6 - 55: cat - cat || Loss: 0.7050765752792358\n",
      "tensor([1., 0.]) tensor([0.6082, 0.3918], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 6 - 56: cat - cat || Loss: 0.7042306661605835\n",
      "tensor([1., 0.]) tensor([0.6090, 0.3910], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 6 - 57: cat - cat || Loss: 0.7033848166465759\n",
      "tensor([1., 0.]) tensor([0.6099, 0.3901], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 6 - 58: cat - cat || Loss: 0.702538788318634\n",
      "tensor([1., 0.]) tensor([0.6107, 0.3893], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 6 - 59: cat - cat || Loss: 0.7016928195953369\n",
      "tensor([1., 0.]) tensor([0.6116, 0.3884], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 6 - 60: cat - cat || Loss: 0.700846791267395\n",
      "tensor([1., 0.]) tensor([0.6124, 0.3876], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 6 - 61: cat - cat || Loss: 0.7000008225440979\n",
      "tensor([1., 0.]) tensor([0.6133, 0.3867], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 6 - 62: cat - cat || Loss: 0.6991547346115112\n",
      "tensor([1., 0.]) tensor([0.6141, 0.3859], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 6 - 63: cat - cat || Loss: 0.698309063911438\n",
      "tensor([1., 0.]) tensor([0.6150, 0.3850], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 6 - 64: cat - cat || Loss: 0.6974634528160095\n",
      "tensor([1., 0.]) tensor([0.6158, 0.3842], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 6 - 65: cat - cat || Loss: 0.6966180801391602\n",
      "tensor([1., 0.]) tensor([0.6166, 0.3834], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 6 - 66: cat - cat || Loss: 0.6957728862762451\n",
      "tensor([1., 0.]) tensor([0.6175, 0.3825], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 6 - 67: cat - cat || Loss: 0.6949279308319092\n",
      "tensor([1., 0.]) tensor([0.6183, 0.3817], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 6 - 68: cat - cat || Loss: 0.6940832734107971\n",
      "tensor([1., 0.]) tensor([0.6192, 0.3808], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 6 - 69: cat - cat || Loss: 0.6932388544082642\n",
      "tensor([1., 0.]) tensor([0.6200, 0.3800], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 6 - 70: cat - cat || Loss: 0.6923946142196655\n",
      "tensor([1., 0.]) tensor([0.6209, 0.3791], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 6 - 71: cat - cat || Loss: 0.6915508508682251\n",
      "tensor([1., 0.]) tensor([0.6217, 0.3783], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 6 - 72: cat - cat || Loss: 0.6907070875167847\n",
      "tensor([1., 0.]) tensor([0.6226, 0.3774], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 6 - 73: cat - cat || Loss: 0.689863920211792\n",
      "tensor([1., 0.]) tensor([0.6234, 0.3766], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 6 - 74: cat - cat || Loss: 0.6890207529067993\n",
      "tensor([1., 0.]) tensor([0.6242, 0.3758], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 6 - 75: cat - cat || Loss: 0.6881782412528992\n",
      "tensor([1., 0.]) tensor([0.6251, 0.3749], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 6 - 76: cat - cat || Loss: 0.6873362064361572\n",
      "tensor([1., 0.]) tensor([0.6259, 0.3741], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 6 - 77: cat - cat || Loss: 0.6864944696426392\n",
      "tensor([1., 0.]) tensor([0.6268, 0.3732], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 6 - 78: cat - cat || Loss: 0.6856530904769897\n",
      "tensor([1., 0.]) tensor([0.6276, 0.3724], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 6 - 79: cat - cat || Loss: 0.684812068939209\n",
      "tensor([1., 0.]) tensor([0.6284, 0.3716], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 6 - 80: cat - cat || Loss: 0.683971643447876\n",
      "tensor([1., 0.]) tensor([0.6293, 0.3707], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 6 - 81: cat - cat || Loss: 0.6831313371658325\n",
      "tensor([1., 0.]) tensor([0.6301, 0.3699], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 6 - 82: cat - cat || Loss: 0.6822915077209473\n",
      "tensor([1., 0.]) tensor([0.6310, 0.3690], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 6 - 83: cat - cat || Loss: 0.6814521551132202\n",
      "tensor([1., 0.]) tensor([0.6318, 0.3682], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 6 - 84: cat - cat || Loss: 0.680613100528717\n",
      "tensor([1., 0.]) tensor([0.6326, 0.3674], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 6 - 85: cat - cat || Loss: 0.6797745227813721\n",
      "tensor([1., 0.]) tensor([0.6335, 0.3665], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 6 - 86: cat - cat || Loss: 0.6789364218711853\n",
      "tensor([1., 0.]) tensor([0.6343, 0.3657], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 6 - 87: cat - cat || Loss: 0.6780986785888672\n",
      "tensor([1., 0.]) tensor([0.6352, 0.3648], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 6 - 88: cat - cat || Loss: 0.6772613525390625\n",
      "tensor([1., 0.]) tensor([0.6360, 0.3640], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 6 - 89: cat - cat || Loss: 0.676424503326416\n",
      "tensor([1., 0.]) tensor([0.6368, 0.3632], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 6 - 90: cat - cat || Loss: 0.6755881309509277\n",
      "tensor([1., 0.]) tensor([0.6377, 0.3623], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 6 - 91: cat - cat || Loss: 0.6747520565986633\n",
      "tensor([1., 0.]) tensor([0.6385, 0.3615], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 6 - 92: cat - cat || Loss: 0.6739166975021362\n",
      "tensor([1., 0.]) tensor([0.6393, 0.3607], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 6 - 93: cat - cat || Loss: 0.6730816960334778\n",
      "tensor([1., 0.]) tensor([0.6402, 0.3598], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 6 - 94: cat - cat || Loss: 0.672247052192688\n",
      "tensor([1., 0.]) tensor([0.6410, 0.3590], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 6 - 95: cat - cat || Loss: 0.6714129447937012\n",
      "tensor([1., 0.]) tensor([0.6418, 0.3582], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 6 - 96: cat - cat || Loss: 0.6705794334411621\n",
      "tensor([1., 0.]) tensor([0.6427, 0.3573], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 6 - 97: cat - cat || Loss: 0.6697462797164917\n",
      "tensor([1., 0.]) tensor([0.6435, 0.3565], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 6 - 98: cat - cat || Loss: 0.668913722038269\n",
      "tensor([1., 0.]) tensor([0.6443, 0.3557], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 6 - 99: cat - cat || Loss: 0.6680816411972046\n",
      "tensor([1., 0.]) tensor([0.6452, 0.3548], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 6 - 100: cat - cat || Loss: 0.6672499179840088\n",
      "tensor([1., 0.]) tensor([0.6460, 0.3540], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 6 - 101: cat - cat || Loss: 0.6664188504219055\n",
      "tensor([1., 0.]) tensor([0.6468, 0.3532], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 6 - 102: cat - cat || Loss: 0.6655882000923157\n",
      "tensor([1., 0.]) tensor([0.6477, 0.3523], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 6 - 103: cat - cat || Loss: 0.6647579073905945\n",
      "tensor([1., 0.]) tensor([0.6485, 0.3515], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 6 - 104: cat - cat || Loss: 0.6639282703399658\n",
      "tensor([1., 0.]) tensor([0.6493, 0.3507], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 6 - 105: cat - cat || Loss: 0.6630990505218506\n",
      "tensor([1., 0.]) tensor([0.6502, 0.3498], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 6 - 106: cat - cat || Loss: 0.6622703075408936\n",
      "tensor([1., 0.]) tensor([0.6510, 0.3490], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 6 - 107: cat - cat || Loss: 0.66144198179245\n",
      "tensor([1., 0.]) tensor([0.6518, 0.3482], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 6 - 108: cat - cat || Loss: 0.6606141924858093\n",
      "tensor([1., 0.]) tensor([0.6526, 0.3474], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 6 - 109: cat - cat || Loss: 0.6597867608070374\n",
      "tensor([1., 0.]) tensor([0.6535, 0.3465], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 6 - 110: cat - cat || Loss: 0.6589598655700684\n",
      "tensor([1., 0.]) tensor([0.6543, 0.3457], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 6 - 111: cat - cat || Loss: 0.6581336855888367\n",
      "tensor([1., 0.]) tensor([0.6551, 0.3449], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 6 - 112: cat - cat || Loss: 0.6573079824447632\n",
      "tensor([1., 0.]) tensor([0.6560, 0.3440], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 6 - 113: cat - cat || Loss: 0.6564828157424927\n",
      "tensor([1., 0.]) tensor([0.6568, 0.3432], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 6 - 114: cat - cat || Loss: 0.6556580662727356\n",
      "tensor([1., 0.]) tensor([0.6576, 0.3424], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 6 - 115: cat - cat || Loss: 0.6548337936401367\n",
      "tensor([1., 0.]) tensor([0.6584, 0.3416], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 6 - 116: cat - cat || Loss: 0.6540099382400513\n",
      "tensor([1., 0.]) tensor([0.6593, 0.3407], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 6 - 117: cat - cat || Loss: 0.6531867384910583\n",
      "tensor([1., 0.]) tensor([0.6601, 0.3399], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 6 - 118: cat - cat || Loss: 0.6523640155792236\n",
      "tensor([1., 0.]) tensor([0.6609, 0.3391], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 6 - 119: cat - cat || Loss: 0.6515417695045471\n",
      "tensor([1., 0.]) tensor([0.6617, 0.3383], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 6 - 120: cat - cat || Loss: 0.6507200598716736\n",
      "tensor([1., 0.]) tensor([0.6625, 0.3375], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 6 - 121: cat - cat || Loss: 0.6498987674713135\n",
      "tensor([1., 0.]) tensor([0.6634, 0.3366], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 6 - 122: cat - cat || Loss: 0.6490781903266907\n",
      "tensor([1., 0.]) tensor([0.6642, 0.3358], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 6 - 123: cat - cat || Loss: 0.6482580304145813\n",
      "tensor([1., 0.]) tensor([0.6650, 0.3350], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 6 - 124: cat - cat || Loss: 0.6474385261535645\n",
      "tensor([1., 0.]) tensor([0.6658, 0.3342], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 6 - 125: cat - cat || Loss: 0.6466196179389954\n",
      "tensor([1., 0.]) tensor([0.6666, 0.3334], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 6 - 126: cat - cat || Loss: 0.6458010673522949\n",
      "tensor([1., 0.]) tensor([0.6675, 0.3325], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 6 - 127: cat - cat || Loss: 0.6449830532073975\n",
      "tensor([1., 0.]) tensor([0.6683, 0.3317], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 6 - 128: cat - cat || Loss: 0.6441658139228821\n",
      "tensor([1., 0.]) tensor([0.6691, 0.3309], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 6 - 129: cat - cat || Loss: 0.6433489918708801\n",
      "tensor([1., 0.]) tensor([0.6699, 0.3301], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 6 - 130: cat - cat || Loss: 0.6425327062606812\n",
      "tensor([1., 0.]) tensor([0.6707, 0.3293], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 6 - 131: cat - cat || Loss: 0.6417168974876404\n",
      "tensor([1., 0.]) tensor([0.6715, 0.3285], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 6 - 132: cat - cat || Loss: 0.6409016847610474\n",
      "tensor([1., 0.]) tensor([0.6724, 0.3276], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 6 - 133: cat - cat || Loss: 0.6400871872901917\n",
      "tensor([1., 0.]) tensor([0.6732, 0.3268], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 6 - 134: cat - cat || Loss: 0.6392731666564941\n",
      "tensor([1., 0.]) tensor([0.6740, 0.3260], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 6 - 135: cat - cat || Loss: 0.6384598016738892\n",
      "tensor([1., 0.]) tensor([0.6748, 0.3252], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 6 - 136: cat - cat || Loss: 0.6376470327377319\n",
      "tensor([1., 0.]) tensor([0.6756, 0.3244], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 6 - 137: cat - cat || Loss: 0.6368346810340881\n",
      "tensor([1., 0.]) tensor([0.6764, 0.3236], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 6 - 138: cat - cat || Loss: 0.6360229253768921\n",
      "tensor([1., 0.]) tensor([0.6772, 0.3228], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 6 - 139: cat - cat || Loss: 0.6352118253707886\n",
      "tensor([1., 0.]) tensor([0.6780, 0.3220], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 6 - 140: cat - cat || Loss: 0.6344012022018433\n",
      "tensor([1., 0.]) tensor([0.6789, 0.3211], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 6 - 141: cat - cat || Loss: 0.6335912942886353\n",
      "tensor([1., 0.]) tensor([0.6797, 0.3203], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 6 - 142: cat - cat || Loss: 0.6327818632125854\n",
      "tensor([1., 0.]) tensor([0.6805, 0.3195], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 6 - 143: cat - cat || Loss: 0.6319729089736938\n",
      "tensor([1., 0.]) tensor([0.6813, 0.3187], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 6 - 144: cat - cat || Loss: 0.6311646699905396\n",
      "tensor([1., 0.]) tensor([0.6821, 0.3179], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 6 - 145: cat - cat || Loss: 0.6303569674491882\n",
      "tensor([1., 0.]) tensor([0.6829, 0.3171], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 6 - 146: cat - cat || Loss: 0.6295499801635742\n",
      "tensor([1., 0.]) tensor([0.6837, 0.3163], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 6 - 147: cat - cat || Loss: 0.6287435293197632\n",
      "tensor([1., 0.]) tensor([0.6845, 0.3155], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 6 - 148: cat - cat || Loss: 0.6279376149177551\n",
      "tensor([1., 0.]) tensor([0.6853, 0.3147], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 6 - 149: cat - cat || Loss: 0.6271324157714844\n",
      "tensor([1., 0.]) tensor([0.6861, 0.3139], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 6 - 150: cat - cat || Loss: 0.6263276934623718\n",
      "tensor([1., 0.]) tensor([0.6869, 0.3131], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 6 - 151: cat - cat || Loss: 0.6255236864089966\n",
      "tensor([1., 0.]) tensor([0.6877, 0.3123], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 6 - 152: cat - cat || Loss: 0.6247203350067139\n",
      "tensor([1., 0.]) tensor([0.6885, 0.3115], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 6 - 153: cat - cat || Loss: 0.6239175200462341\n",
      "tensor([1., 0.]) tensor([0.6893, 0.3107], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 6 - 154: cat - cat || Loss: 0.6231153011322021\n",
      "tensor([1., 0.]) tensor([0.6901, 0.3099], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 6 - 155: cat - cat || Loss: 0.622313916683197\n",
      "tensor([1., 0.]) tensor([0.6909, 0.3091], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 6 - 156: cat - cat || Loss: 0.6215130090713501\n",
      "tensor([1., 0.]) tensor([0.6917, 0.3083], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 6 - 157: cat - cat || Loss: 0.6207128167152405\n",
      "tensor([1., 0.]) tensor([0.6925, 0.3075], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 6 - 158: cat - cat || Loss: 0.6199131608009338\n",
      "tensor([1., 0.]) tensor([0.6933, 0.3067], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 6 - 159: cat - cat || Loss: 0.6191141605377197\n",
      "tensor([1., 0.]) tensor([0.6941, 0.3059], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 6 - 160: cat - cat || Loss: 0.6183158755302429\n",
      "tensor([1., 0.]) tensor([0.6949, 0.3051], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 6 - 161: cat - cat || Loss: 0.6175183057785034\n",
      "tensor([1., 0.]) tensor([0.6957, 0.3043], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 6 - 162: cat - cat || Loss: 0.6167216300964355\n",
      "tensor([1., 0.]) tensor([0.6965, 0.3035], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 6 - 163: cat - cat || Loss: 0.6159252524375916\n",
      "tensor([1., 0.]) tensor([0.6973, 0.3027], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 6 - 164: cat - cat || Loss: 0.6151297688484192\n",
      "tensor([1., 0.]) tensor([0.6981, 0.3019], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 6 - 165: cat - cat || Loss: 0.6143348217010498\n",
      "tensor([1., 0.]) tensor([0.6989, 0.3011], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 6 - 166: cat - cat || Loss: 0.6135405898094177\n",
      "tensor([1., 0.]) tensor([0.6997, 0.3003], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 6 - 167: cat - cat || Loss: 0.6127469539642334\n",
      "tensor([1., 0.]) tensor([0.7005, 0.2995], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 6 - 168: cat - cat || Loss: 0.6119542121887207\n",
      "tensor([1., 0.]) tensor([0.7013, 0.2987], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 6 - 169: cat - cat || Loss: 0.6111618280410767\n",
      "tensor([1., 0.]) tensor([0.7021, 0.2979], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 6 - 170: cat - cat || Loss: 0.610370397567749\n",
      "tensor([1., 0.]) tensor([0.7029, 0.2971], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 6 - 171: cat - cat || Loss: 0.6095796227455139\n",
      "tensor([1., 0.]) tensor([0.7037, 0.2963], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 6 - 172: cat - cat || Loss: 0.6087895631790161\n",
      "tensor([1., 0.]) tensor([0.7045, 0.2955], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 6 - 173: cat - cat || Loss: 0.6080001592636108\n",
      "tensor([1., 0.]) tensor([0.7053, 0.2947], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 6 - 174: cat - cat || Loss: 0.6072115302085876\n",
      "tensor([1., 0.]) tensor([0.7061, 0.2939], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 6 - 175: cat - cat || Loss: 0.6064233779907227\n",
      "tensor([1., 0.]) tensor([0.7068, 0.2932], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 6 - 176: cat - cat || Loss: 0.6056360602378845\n",
      "tensor([1., 0.]) tensor([0.7076, 0.2924], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 6 - 177: cat - cat || Loss: 0.6048495173454285\n",
      "tensor([1., 0.]) tensor([0.7084, 0.2916], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 6 - 178: cat - cat || Loss: 0.6040636301040649\n",
      "tensor([1., 0.]) tensor([0.7092, 0.2908], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 6 - 179: cat - cat || Loss: 0.6032785177230835\n",
      "tensor([1., 0.]) tensor([0.7100, 0.2900], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 6 - 180: cat - cat || Loss: 0.6024941802024841\n",
      "tensor([1., 0.]) tensor([0.7108, 0.2892], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 6 - 181: cat - cat || Loss: 0.6017105579376221\n",
      "tensor([1., 0.]) tensor([0.7116, 0.2884], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 6 - 182: cat - cat || Loss: 0.6009278297424316\n",
      "tensor([1., 0.]) tensor([0.7123, 0.2877], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 6 - 183: cat - cat || Loss: 0.6001458168029785\n",
      "tensor([1., 0.]) tensor([0.7131, 0.2869], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 6 - 184: cat - cat || Loss: 0.5993642210960388\n",
      "tensor([1., 0.]) tensor([0.7139, 0.2861], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 6 - 185: cat - cat || Loss: 0.5985836386680603\n",
      "tensor([1., 0.]) tensor([0.7147, 0.2853], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 6 - 186: cat - cat || Loss: 0.5978035926818848\n",
      "tensor([1., 0.]) tensor([0.7155, 0.2845], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 6 - 187: cat - cat || Loss: 0.5970244407653809\n",
      "tensor([1., 0.]) tensor([0.7162, 0.2838], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 6 - 188: cat - cat || Loss: 0.5962460041046143\n",
      "tensor([1., 0.]) tensor([0.7170, 0.2830], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 6 - 189: cat - cat || Loss: 0.595468282699585\n",
      "tensor([1., 0.]) tensor([0.7178, 0.2822], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 6 - 190: dog - cat || Loss: 1.031831979751587\n",
      "tensor([0., 1.]) tensor([0.7186, 0.2814], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 6 - 191: dog - cat || Loss: 1.0324535369873047\n",
      "tensor([0., 1.]) tensor([0.7192, 0.2808], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 6 - 192: dog - cat || Loss: 1.0329355001449585\n",
      "tensor([0., 1.]) tensor([0.7197, 0.2803], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 6 - 193: dog - cat || Loss: 1.0332919359207153\n",
      "tensor([0., 1.]) tensor([0.7200, 0.2800], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 6 - 194: dog - cat || Loss: 1.033535361289978\n",
      "tensor([0., 1.]) tensor([0.7203, 0.2797], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 6 - 195: dog - cat || Loss: 1.0336772203445435\n",
      "tensor([0., 1.]) tensor([0.7204, 0.2796], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 6 - 196: dog - cat || Loss: 1.0337276458740234\n",
      "tensor([0., 1.]) tensor([0.7205, 0.2795], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 6 - 197: dog - cat || Loss: 1.033695936203003\n",
      "tensor([0., 1.]) tensor([0.7204, 0.2796], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 6 - 198: dog - cat || Loss: 1.033590316772461\n",
      "tensor([0., 1.]) tensor([0.7203, 0.2797], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 6 - 199: dog - cat || Loss: 1.0334179401397705\n",
      "tensor([0., 1.]) tensor([0.7202, 0.2798], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 6 - 200: dog - cat || Loss: 1.0331857204437256\n",
      "tensor([0., 1.]) tensor([0.7199, 0.2801], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 6 - 201: dog - cat || Loss: 1.0328993797302246\n",
      "tensor([0., 1.]) tensor([0.7196, 0.2804], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 6 - 202: dog - cat || Loss: 1.032564401626587\n",
      "tensor([0., 1.]) tensor([0.7193, 0.2807], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 6 - 203: dog - cat || Loss: 1.032185673713684\n",
      "tensor([0., 1.]) tensor([0.7189, 0.2811], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 6 - 204: dog - cat || Loss: 1.0317673683166504\n",
      "tensor([0., 1.]) tensor([0.7185, 0.2815], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 6 - 205: dog - cat || Loss: 1.031313419342041\n",
      "tensor([0., 1.]) tensor([0.7181, 0.2819], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 6 - 206: dog - cat || Loss: 1.030827522277832\n",
      "tensor([0., 1.]) tensor([0.7176, 0.2824], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 6 - 207: dog - cat || Loss: 1.0303127765655518\n",
      "tensor([0., 1.]) tensor([0.7171, 0.2829], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 6 - 208: dog - cat || Loss: 1.0297718048095703\n",
      "tensor([0., 1.]) tensor([0.7165, 0.2835], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 6 - 209: dog - cat || Loss: 1.0292073488235474\n",
      "tensor([0., 1.]) tensor([0.7159, 0.2841], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 6 - 210: dog - cat || Loss: 1.028621792793274\n",
      "tensor([0., 1.]) tensor([0.7154, 0.2846], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 6 - 211: dog - cat || Loss: 1.0280169248580933\n",
      "tensor([0., 1.]) tensor([0.7148, 0.2852], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 6 - 212: dog - cat || Loss: 1.0273945331573486\n",
      "tensor([0., 1.]) tensor([0.7141, 0.2859], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 6 - 213: dog - cat || Loss: 1.0267565250396729\n",
      "tensor([0., 1.]) tensor([0.7135, 0.2865], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 6 - 214: dog - cat || Loss: 1.0261045694351196\n",
      "tensor([0., 1.]) tensor([0.7128, 0.2872], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 6 - 215: dog - cat || Loss: 1.0254396200180054\n",
      "tensor([0., 1.]) tensor([0.7122, 0.2878], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 6 - 216: dog - cat || Loss: 1.0247632265090942\n",
      "tensor([0., 1.]) tensor([0.7115, 0.2885], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 6 - 217: dog - cat || Loss: 1.0240761041641235\n",
      "tensor([0., 1.]) tensor([0.7108, 0.2892], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 6 - 218: dog - cat || Loss: 1.0233795642852783\n",
      "tensor([0., 1.]) tensor([0.7101, 0.2899], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 6 - 219: dog - cat || Loss: 1.0226744413375854\n",
      "tensor([0., 1.]) tensor([0.7094, 0.2906], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 6 - 220: dog - cat || Loss: 1.0219614505767822\n",
      "tensor([0., 1.]) tensor([0.7087, 0.2913], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 6 - 221: dog - cat || Loss: 1.0212414264678955\n",
      "tensor([0., 1.]) tensor([0.7080, 0.2920], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 6 - 222: dog - cat || Loss: 1.020514965057373\n",
      "tensor([0., 1.]) tensor([0.7073, 0.2927], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 6 - 223: dog - cat || Loss: 1.019782543182373\n",
      "tensor([0., 1.]) tensor([0.7065, 0.2935], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 6 - 224: dog - cat || Loss: 1.0190446376800537\n",
      "tensor([0., 1.]) tensor([0.7058, 0.2942], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 6 - 225: dog - cat || Loss: 1.0183019638061523\n",
      "tensor([0., 1.]) tensor([0.7050, 0.2950], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 6 - 226: dog - cat || Loss: 1.0175548791885376\n",
      "tensor([0., 1.]) tensor([0.7043, 0.2957], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 6 - 227: dog - cat || Loss: 1.016803503036499\n",
      "tensor([0., 1.]) tensor([0.7035, 0.2965], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 6 - 228: dog - cat || Loss: 1.0160486698150635\n",
      "tensor([0., 1.]) tensor([0.7028, 0.2972], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 6 - 229: dog - cat || Loss: 1.0152904987335205\n",
      "tensor([0., 1.]) tensor([0.7020, 0.2980], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 6 - 230: dog - cat || Loss: 1.0145288705825806\n",
      "tensor([0., 1.]) tensor([0.7013, 0.2987], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 6 - 231: dog - cat || Loss: 1.0137646198272705\n",
      "tensor([0., 1.]) tensor([0.7005, 0.2995], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 6 - 232: dog - cat || Loss: 1.0129976272583008\n",
      "tensor([0., 1.]) tensor([0.6997, 0.3003], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 6 - 233: dog - cat || Loss: 1.0122283697128296\n",
      "tensor([0., 1.]) tensor([0.6990, 0.3010], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 6 - 234: dog - cat || Loss: 1.0114566087722778\n",
      "tensor([0., 1.]) tensor([0.6982, 0.3018], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 6 - 235: dog - cat || Loss: 1.0106828212738037\n",
      "tensor([0., 1.]) tensor([0.6974, 0.3026], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 6 - 236: dog - cat || Loss: 1.0099068880081177\n",
      "tensor([0., 1.]) tensor([0.6966, 0.3034], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 6 - 237: dog - cat || Loss: 1.009129285812378\n",
      "tensor([0., 1.]) tensor([0.6959, 0.3041], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 6 - 238: dog - cat || Loss: 1.0083500146865845\n",
      "tensor([0., 1.]) tensor([0.6951, 0.3049], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 6 - 239: dog - cat || Loss: 1.0075689554214478\n",
      "tensor([0., 1.]) tensor([0.6943, 0.3057], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 6 - 240: dog - cat || Loss: 1.0067863464355469\n",
      "tensor([0., 1.]) tensor([0.6935, 0.3065], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 6 - 241: dog - cat || Loss: 1.00600266456604\n",
      "tensor([0., 1.]) tensor([0.6927, 0.3073], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 6 - 242: dog - cat || Loss: 1.0052173137664795\n",
      "tensor([0., 1.]) tensor([0.6920, 0.3080], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 6 - 243: dog - cat || Loss: 1.004430890083313\n",
      "tensor([0., 1.]) tensor([0.6912, 0.3088], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 6 - 244: dog - cat || Loss: 1.0036433935165405\n",
      "tensor([0., 1.]) tensor([0.6904, 0.3096], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 6 - 245: dog - cat || Loss: 1.0028547048568726\n",
      "tensor([0., 1.]) tensor([0.6896, 0.3104], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 6 - 246: dog - cat || Loss: 1.0020649433135986\n",
      "tensor([0., 1.]) tensor([0.6888, 0.3112], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 6 - 247: dog - cat || Loss: 1.0012741088867188\n",
      "tensor([0., 1.]) tensor([0.6880, 0.3120], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 6 - 248: dog - cat || Loss: 1.0004825592041016\n",
      "tensor([0., 1.]) tensor([0.6872, 0.3128], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 6 - 249: dog - cat || Loss: 0.9996896982192993\n",
      "tensor([0., 1.]) tensor([0.6864, 0.3136], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 6 - 250: dog - cat || Loss: 0.9988963007926941\n",
      "tensor([0., 1.]) tensor([0.6856, 0.3144], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 6 - 251: dog - cat || Loss: 0.9981020092964172\n",
      "tensor([0., 1.]) tensor([0.6848, 0.3152], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 6 - 252: dog - cat || Loss: 0.9973069429397583\n",
      "tensor([0., 1.]) tensor([0.6840, 0.3160], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 6 - 253: dog - cat || Loss: 0.9965111613273621\n",
      "tensor([0., 1.]) tensor([0.6832, 0.3168], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 6 - 254: dog - cat || Loss: 0.9957144856452942\n",
      "tensor([0., 1.]) tensor([0.6825, 0.3175], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 6 - 255: dog - cat || Loss: 0.9949172139167786\n",
      "tensor([0., 1.]) tensor([0.6817, 0.3183], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 6 - 256: dog - cat || Loss: 0.9941192269325256\n",
      "tensor([0., 1.]) tensor([0.6809, 0.3191], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 6 - 257: dog - cat || Loss: 0.9933205842971802\n",
      "tensor([0., 1.]) tensor([0.6801, 0.3199], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 6 - 258: dog - cat || Loss: 0.9925210475921631\n",
      "tensor([0., 1.]) tensor([0.6793, 0.3207], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 6 - 259: dog - cat || Loss: 0.9917210340499878\n",
      "tensor([0., 1.]) tensor([0.6785, 0.3215], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 6 - 260: dog - cat || Loss: 0.9909202456474304\n",
      "tensor([0., 1.]) tensor([0.6777, 0.3223], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 6 - 261: dog - cat || Loss: 0.9901188611984253\n",
      "tensor([0., 1.]) tensor([0.6769, 0.3231], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 6 - 262: dog - cat || Loss: 0.9893169403076172\n",
      "tensor([0., 1.]) tensor([0.6761, 0.3239], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 6 - 263: dog - cat || Loss: 0.988514244556427\n",
      "tensor([0., 1.]) tensor([0.6753, 0.3247], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 6 - 264: dog - cat || Loss: 0.9877110719680786\n",
      "tensor([0., 1.]) tensor([0.6744, 0.3256], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 6 - 265: dog - cat || Loss: 0.9869072437286377\n",
      "tensor([0., 1.]) tensor([0.6736, 0.3264], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 6 - 266: dog - cat || Loss: 0.9861030578613281\n",
      "tensor([0., 1.]) tensor([0.6728, 0.3272], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 6 - 267: dog - cat || Loss: 0.985298216342926\n",
      "tensor([0., 1.]) tensor([0.6720, 0.3280], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 6 - 268: dog - cat || Loss: 0.9844926595687866\n",
      "tensor([0., 1.]) tensor([0.6712, 0.3288], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 6 - 269: dog - cat || Loss: 0.983686625957489\n",
      "tensor([0., 1.]) tensor([0.6704, 0.3296], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 6 - 270: dog - cat || Loss: 0.9828801155090332\n",
      "tensor([0., 1.]) tensor([0.6696, 0.3304], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 6 - 271: dog - cat || Loss: 0.9820730686187744\n",
      "tensor([0., 1.]) tensor([0.6688, 0.3312], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 6 - 272: dog - cat || Loss: 0.9812653660774231\n",
      "tensor([0., 1.]) tensor([0.6680, 0.3320], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 6 - 273: dog - cat || Loss: 0.9804571866989136\n",
      "tensor([0., 1.]) tensor([0.6672, 0.3328], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 6 - 274: dog - cat || Loss: 0.9796484708786011\n",
      "tensor([0., 1.]) tensor([0.6664, 0.3336], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 6 - 275: dog - cat || Loss: 0.9788392186164856\n",
      "tensor([0., 1.]) tensor([0.6656, 0.3344], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 6 - 276: dog - cat || Loss: 0.9780295491218567\n",
      "tensor([0., 1.]) tensor([0.6648, 0.3352], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 6 - 277: dog - cat || Loss: 0.97721928358078\n",
      "tensor([0., 1.]) tensor([0.6640, 0.3360], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 6 - 278: dog - cat || Loss: 0.9764084815979004\n",
      "tensor([0., 1.]) tensor([0.6631, 0.3369], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 6 - 279: dog - cat || Loss: 0.9755973219871521\n",
      "tensor([0., 1.]) tensor([0.6623, 0.3377], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 6 - 280: dog - cat || Loss: 0.9747855067253113\n",
      "tensor([0., 1.]) tensor([0.6615, 0.3385], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 6 - 281: dog - cat || Loss: 0.9739732146263123\n",
      "tensor([0., 1.]) tensor([0.6607, 0.3393], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 6 - 282: dog - cat || Loss: 0.9731606245040894\n",
      "tensor([0., 1.]) tensor([0.6599, 0.3401], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 6 - 283: dog - cat || Loss: 0.9723474979400635\n",
      "tensor([0., 1.]) tensor([0.6591, 0.3409], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 6 - 284: dog - cat || Loss: 0.9715338945388794\n",
      "tensor([0., 1.]) tensor([0.6583, 0.3417], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 6 - 285: dog - cat || Loss: 0.9707199335098267\n",
      "tensor([0., 1.]) tensor([0.6575, 0.3425], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 6 - 286: dog - cat || Loss: 0.9699053764343262\n",
      "tensor([0., 1.]) tensor([0.6566, 0.3434], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 6 - 287: dog - cat || Loss: 0.9690902829170227\n",
      "tensor([0., 1.]) tensor([0.6558, 0.3442], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 6 - 288: dog - cat || Loss: 0.9682749509811401\n",
      "tensor([0., 1.]) tensor([0.6550, 0.3450], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 6 - 289: dog - cat || Loss: 0.9674588441848755\n",
      "tensor([0., 1.]) tensor([0.6542, 0.3458], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 6 - 290: dog - cat || Loss: 0.9666426181793213\n",
      "tensor([0., 1.]) tensor([0.6534, 0.3466], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 6 - 291: dog - cat || Loss: 0.9658257961273193\n",
      "tensor([0., 1.]) tensor([0.6526, 0.3474], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 6 - 292: dog - cat || Loss: 0.9650084972381592\n",
      "tensor([0., 1.]) tensor([0.6517, 0.3483], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 6 - 293: dog - cat || Loss: 0.9641907215118408\n",
      "tensor([0., 1.]) tensor([0.6509, 0.3491], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 6 - 294: dog - cat || Loss: 0.9633725881576538\n",
      "tensor([0., 1.]) tensor([0.6501, 0.3499], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 6 - 295: dog - cat || Loss: 0.9625539779663086\n",
      "tensor([0., 1.]) tensor([0.6493, 0.3507], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 6 - 296: dog - cat || Loss: 0.9617348313331604\n",
      "tensor([0., 1.]) tensor([0.6485, 0.3515], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 6 - 297: dog - cat || Loss: 0.9609152674674988\n",
      "tensor([0., 1.]) tensor([0.6477, 0.3523], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 6 - 298: dog - cat || Loss: 0.9600952863693237\n",
      "tensor([0., 1.]) tensor([0.6468, 0.3532], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 6 - 299: dog - cat || Loss: 0.9592748284339905\n",
      "tensor([0., 1.]) tensor([0.6460, 0.3540], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 6 - 300: dog - cat || Loss: 0.958453893661499\n",
      "tensor([0., 1.]) tensor([0.6452, 0.3548], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 6 - 301: dog - cat || Loss: 0.9576326012611389\n",
      "tensor([0., 1.]) tensor([0.6444, 0.3556], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 6 - 302: dog - cat || Loss: 0.9568109512329102\n",
      "tensor([0., 1.]) tensor([0.6435, 0.3565], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 6 - 303: dog - cat || Loss: 0.9559887647628784\n",
      "tensor([0., 1.]) tensor([0.6427, 0.3573], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 6 - 304: dog - cat || Loss: 0.9551660418510437\n",
      "tensor([0., 1.]) tensor([0.6419, 0.3581], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 6 - 305: dog - cat || Loss: 0.9543427228927612\n",
      "tensor([0., 1.]) tensor([0.6411, 0.3589], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 6 - 306: dog - cat || Loss: 0.9535192251205444\n",
      "tensor([0., 1.]) tensor([0.6403, 0.3597], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 6 - 307: dog - cat || Loss: 0.9526953101158142\n",
      "tensor([0., 1.]) tensor([0.6394, 0.3606], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 6 - 308: dog - cat || Loss: 0.9518709182739258\n",
      "tensor([0., 1.]) tensor([0.6386, 0.3614], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 6 - 309: dog - cat || Loss: 0.9510461688041687\n",
      "tensor([0., 1.]) tensor([0.6378, 0.3622], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 6 - 310: dog - cat || Loss: 0.9502208828926086\n",
      "tensor([0., 1.]) tensor([0.6370, 0.3630], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 6 - 311: dog - cat || Loss: 0.9493952989578247\n",
      "tensor([0., 1.]) tensor([0.6361, 0.3639], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 6 - 312: dog - cat || Loss: 0.9485692977905273\n",
      "tensor([0., 1.]) tensor([0.6353, 0.3647], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 6 - 313: dog - cat || Loss: 0.9477428197860718\n",
      "tensor([0., 1.]) tensor([0.6345, 0.3655], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 6 - 314: dog - cat || Loss: 0.9469161033630371\n",
      "tensor([0., 1.]) tensor([0.6337, 0.3663], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 6 - 315: dog - cat || Loss: 0.9460887908935547\n",
      "tensor([0., 1.]) tensor([0.6328, 0.3672], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 6 - 316: dog - cat || Loss: 0.9452611207962036\n",
      "tensor([0., 1.]) tensor([0.6320, 0.3680], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 6 - 317: dog - cat || Loss: 0.9444330334663391\n",
      "tensor([0., 1.]) tensor([0.6312, 0.3688], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 6 - 318: dog - cat || Loss: 0.9436044692993164\n",
      "tensor([0., 1.]) tensor([0.6303, 0.3697], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 6 - 319: dog - cat || Loss: 0.9427756071090698\n",
      "tensor([0., 1.]) tensor([0.6295, 0.3705], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 6 - 320: dog - cat || Loss: 0.941946268081665\n",
      "tensor([0., 1.]) tensor([0.6287, 0.3713], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 6 - 321: dog - cat || Loss: 0.9411165714263916\n",
      "tensor([0., 1.]) tensor([0.6279, 0.3721], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 6 - 322: dog - cat || Loss: 0.9402864575386047\n",
      "tensor([0., 1.]) tensor([0.6270, 0.3730], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 6 - 323: dog - cat || Loss: 0.9394559264183044\n",
      "tensor([0., 1.]) tensor([0.6262, 0.3738], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 6 - 324: dog - cat || Loss: 0.9386249780654907\n",
      "tensor([0., 1.]) tensor([0.6254, 0.3746], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 6 - 325: dog - cat || Loss: 0.9377935528755188\n",
      "tensor([0., 1.]) tensor([0.6245, 0.3755], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 6 - 326: dog - cat || Loss: 0.9369616508483887\n",
      "tensor([0., 1.]) tensor([0.6237, 0.3763], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 6 - 327: dog - cat || Loss: 0.9361295104026794\n",
      "tensor([0., 1.]) tensor([0.6229, 0.3771], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 6 - 328: dog - cat || Loss: 0.935296893119812\n",
      "tensor([0., 1.]) tensor([0.6220, 0.3780], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 6 - 329: dog - cat || Loss: 0.9344638586044312\n",
      "tensor([0., 1.]) tensor([0.6212, 0.3788], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 6 - 330: dog - cat || Loss: 0.9336305856704712\n",
      "tensor([0., 1.]) tensor([0.6204, 0.3796], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 6 - 331: dog - cat || Loss: 0.9327966570854187\n",
      "tensor([0., 1.]) tensor([0.6195, 0.3805], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 6 - 332: dog - cat || Loss: 0.9319624304771423\n",
      "tensor([0., 1.]) tensor([0.6187, 0.3813], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 6 - 333: dog - cat || Loss: 0.9311279058456421\n",
      "tensor([0., 1.]) tensor([0.6179, 0.3821], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 6 - 334: dog - cat || Loss: 0.9302927851676941\n",
      "tensor([0., 1.]) tensor([0.6170, 0.3830], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 6 - 335: dog - cat || Loss: 0.9294575452804565\n",
      "tensor([0., 1.]) tensor([0.6162, 0.3838], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 6 - 336: dog - cat || Loss: 0.9286218881607056\n",
      "tensor([0., 1.]) tensor([0.6154, 0.3846], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 6 - 337: dog - cat || Loss: 0.9277858138084412\n",
      "tensor([0., 1.]) tensor([0.6145, 0.3855], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 6 - 338: dog - cat || Loss: 0.9269493818283081\n",
      "tensor([0., 1.]) tensor([0.6137, 0.3863], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 6 - 339: dog - cat || Loss: 0.9261125922203064\n",
      "tensor([0., 1.]) tensor([0.6129, 0.3871], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 6 - 340: dog - cat || Loss: 0.925275444984436\n",
      "tensor([0., 1.]) tensor([0.6120, 0.3880], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 6 - 341: dog - cat || Loss: 0.9244378805160522\n",
      "tensor([0., 1.]) tensor([0.6112, 0.3888], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 6 - 342: dog - cat || Loss: 0.9236000776290894\n",
      "tensor([0., 1.]) tensor([0.6103, 0.3897], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 6 - 343: dog - cat || Loss: 0.9227619767189026\n",
      "tensor([0., 1.]) tensor([0.6095, 0.3905], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 6 - 344: dog - cat || Loss: 0.9219235181808472\n",
      "tensor([0., 1.]) tensor([0.6087, 0.3913], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 6 - 345: dog - cat || Loss: 0.9210846424102783\n",
      "tensor([0., 1.]) tensor([0.6078, 0.3922], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 6 - 346: dog - cat || Loss: 0.9202454090118408\n",
      "tensor([0., 1.]) tensor([0.6070, 0.3930], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 6 - 347: dog - cat || Loss: 0.919405996799469\n",
      "tensor([0., 1.]) tensor([0.6061, 0.3939], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 6 - 348: dog - cat || Loss: 0.9185662269592285\n",
      "tensor([0., 1.]) tensor([0.6053, 0.3947], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 6 - 349: dog - cat || Loss: 0.9177259206771851\n",
      "tensor([0., 1.]) tensor([0.6045, 0.3955], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 6 - 350: dog - cat || Loss: 0.9168854355812073\n",
      "tensor([0., 1.]) tensor([0.6036, 0.3964], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 6 - 351: dog - cat || Loss: 0.9160445928573608\n",
      "tensor([0., 1.]) tensor([0.6028, 0.3972], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 6 - 352: dog - cat || Loss: 0.9152032732963562\n",
      "tensor([0., 1.]) tensor([0.6019, 0.3981], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 6 - 353: dog - cat || Loss: 0.9143617153167725\n",
      "tensor([0., 1.]) tensor([0.6011, 0.3989], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 6 - 354: dog - cat || Loss: 0.9135197401046753\n",
      "tensor([0., 1.]) tensor([0.6003, 0.3997], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 6 - 355: dog - cat || Loss: 0.912677526473999\n",
      "tensor([0., 1.]) tensor([0.5994, 0.4006], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 6 - 356: dog - cat || Loss: 0.9118348956108093\n",
      "tensor([0., 1.]) tensor([0.5986, 0.4014], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 6 - 357: dog - cat || Loss: 0.910991907119751\n",
      "tensor([0., 1.]) tensor([0.5977, 0.4023], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 6 - 358: dog - cat || Loss: 0.9101486206054688\n",
      "tensor([0., 1.]) tensor([0.5969, 0.4031], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 6 - 359: dog - cat || Loss: 0.9093049168586731\n",
      "tensor([0., 1.]) tensor([0.5960, 0.4040], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 6 - 360: dog - cat || Loss: 0.9084609150886536\n",
      "tensor([0., 1.]) tensor([0.5952, 0.4048], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 6 - 361: dog - cat || Loss: 0.9076166749000549\n",
      "tensor([0., 1.]) tensor([0.5944, 0.4056], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 6 - 362: dog - cat || Loss: 0.9067720770835876\n",
      "tensor([0., 1.]) tensor([0.5935, 0.4065], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 6 - 363: dog - cat || Loss: 0.9059270620346069\n",
      "tensor([0., 1.]) tensor([0.5927, 0.4073], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 6 - 364: dog - cat || Loss: 0.9050818681716919\n",
      "tensor([0., 1.]) tensor([0.5918, 0.4082], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 6 - 365: dog - cat || Loss: 0.9042365550994873\n",
      "tensor([0., 1.]) tensor([0.5910, 0.4090], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 6 - 366: dog - cat || Loss: 0.9033905863761902\n",
      "tensor([0., 1.]) tensor([0.5901, 0.4099], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 6 - 367: dog - cat || Loss: 0.9025444984436035\n",
      "tensor([0., 1.]) tensor([0.5893, 0.4107], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 6 - 368: dog - cat || Loss: 0.901698112487793\n",
      "tensor([0., 1.]) tensor([0.5884, 0.4116], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 6 - 369: dog - cat || Loss: 0.9008513689041138\n",
      "tensor([0., 1.]) tensor([0.5876, 0.4124], grad_fn=<SoftmaxBackward0>)\n",
      "=====epoch:7=====\n",
      "Epoch 7 - 0: cat - cat || Loss: 0.726518988609314\n",
      "tensor([1., 0.]) tensor([0.5867, 0.4133], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 7 - 1: cat - cat || Loss: 0.727196455001831\n",
      "tensor([1., 0.]) tensor([0.5861, 0.4139], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 7 - 2: cat - cat || Loss: 0.7277213335037231\n",
      "tensor([1., 0.]) tensor([0.5855, 0.4145], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 7 - 3: cat - cat || Loss: 0.728108823299408\n",
      "tensor([1., 0.]) tensor([0.5852, 0.4148], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 7 - 4: cat - cat || Loss: 0.7283725142478943\n",
      "tensor([1., 0.]) tensor([0.5849, 0.4151], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 7 - 5: cat - cat || Loss: 0.728524923324585\n",
      "tensor([1., 0.]) tensor([0.5847, 0.4153], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 7 - 6: cat - cat || Loss: 0.7285770773887634\n",
      "tensor([1., 0.]) tensor([0.5847, 0.4153], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 7 - 7: cat - cat || Loss: 0.7285391092300415\n",
      "tensor([1., 0.]) tensor([0.5847, 0.4153], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 7 - 8: cat - cat || Loss: 0.7284200191497803\n",
      "tensor([1., 0.]) tensor([0.5848, 0.4152], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 7 - 9: cat - cat || Loss: 0.728227972984314\n",
      "tensor([1., 0.]) tensor([0.5850, 0.4150], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 7 - 10: cat - cat || Loss: 0.7279701828956604\n",
      "tensor([1., 0.]) tensor([0.5853, 0.4147], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 7 - 11: cat - cat || Loss: 0.7276535034179688\n",
      "tensor([1., 0.]) tensor([0.5856, 0.4144], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 7 - 12: cat - cat || Loss: 0.7272837162017822\n",
      "tensor([1., 0.]) tensor([0.5860, 0.4140], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 7 - 13: cat - cat || Loss: 0.7268660068511963\n",
      "tensor([1., 0.]) tensor([0.5864, 0.4136], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 7 - 14: cat - cat || Loss: 0.7264054417610168\n",
      "tensor([1., 0.]) tensor([0.5869, 0.4131], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 7 - 15: cat - cat || Loss: 0.7259060740470886\n",
      "tensor([1., 0.]) tensor([0.5874, 0.4126], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 7 - 16: cat - cat || Loss: 0.7253718972206116\n",
      "tensor([1., 0.]) tensor([0.5879, 0.4121], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 7 - 17: cat - cat || Loss: 0.7248064875602722\n",
      "tensor([1., 0.]) tensor([0.5885, 0.4115], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 7 - 18: cat - cat || Loss: 0.7242130041122437\n",
      "tensor([1., 0.]) tensor([0.5890, 0.4110], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 7 - 19: cat - cat || Loss: 0.723594069480896\n",
      "tensor([1., 0.]) tensor([0.5897, 0.4103], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 7 - 20: cat - cat || Loss: 0.7229523658752441\n",
      "tensor([1., 0.]) tensor([0.5903, 0.4097], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 7 - 21: cat - cat || Loss: 0.7222903966903687\n",
      "tensor([1., 0.]) tensor([0.5910, 0.4090], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 7 - 22: cat - cat || Loss: 0.7216101288795471\n",
      "tensor([1., 0.]) tensor([0.5917, 0.4083], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 7 - 23: cat - cat || Loss: 0.7209131717681885\n",
      "tensor([1., 0.]) tensor([0.5923, 0.4077], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 7 - 24: cat - cat || Loss: 0.7202014923095703\n",
      "tensor([1., 0.]) tensor([0.5931, 0.4069], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 7 - 25: cat - cat || Loss: 0.7194766402244568\n",
      "tensor([1., 0.]) tensor([0.5938, 0.4062], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 7 - 26: cat - cat || Loss: 0.7187402248382568\n",
      "tensor([1., 0.]) tensor([0.5945, 0.4055], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 7 - 27: cat - cat || Loss: 0.7179928421974182\n",
      "tensor([1., 0.]) tensor([0.5953, 0.4047], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 7 - 28: cat - cat || Loss: 0.7172359228134155\n",
      "tensor([1., 0.]) tensor([0.5960, 0.4040], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 7 - 29: cat - cat || Loss: 0.71647047996521\n",
      "tensor([1., 0.]) tensor([0.5968, 0.4032], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 7 - 30: cat - cat || Loss: 0.7156973481178284\n",
      "tensor([1., 0.]) tensor([0.5976, 0.4024], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 7 - 31: cat - cat || Loss: 0.7149173021316528\n",
      "tensor([1., 0.]) tensor([0.5983, 0.4017], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 7 - 32: cat - cat || Loss: 0.7141309976577759\n",
      "tensor([1., 0.]) tensor([0.5991, 0.4009], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 7 - 33: cat - cat || Loss: 0.7133394479751587\n",
      "tensor([1., 0.]) tensor([0.5999, 0.4001], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 7 - 34: cat - cat || Loss: 0.7125428915023804\n",
      "tensor([1., 0.]) tensor([0.6007, 0.3993], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 7 - 35: cat - cat || Loss: 0.7117419242858887\n",
      "tensor([1., 0.]) tensor([0.6015, 0.3985], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 7 - 36: cat - cat || Loss: 0.7109373211860657\n",
      "tensor([1., 0.]) tensor([0.6023, 0.3977], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 7 - 37: cat - cat || Loss: 0.7101292610168457\n",
      "tensor([1., 0.]) tensor([0.6031, 0.3969], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 7 - 38: cat - cat || Loss: 0.7093180418014526\n",
      "tensor([1., 0.]) tensor([0.6039, 0.3961], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 7 - 39: cat - cat || Loss: 0.7085039615631104\n",
      "tensor([1., 0.]) tensor([0.6048, 0.3952], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 7 - 40: cat - cat || Loss: 0.7076877951622009\n",
      "tensor([1., 0.]) tensor([0.6056, 0.3944], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 7 - 41: cat - cat || Loss: 0.7068692445755005\n",
      "tensor([1., 0.]) tensor([0.6064, 0.3936], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 7 - 42: cat - cat || Loss: 0.7060489058494568\n",
      "tensor([1., 0.]) tensor([0.6072, 0.3928], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 7 - 43: cat - cat || Loss: 0.7052266597747803\n",
      "tensor([1., 0.]) tensor([0.6080, 0.3920], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 7 - 44: cat - cat || Loss: 0.704403281211853\n",
      "tensor([1., 0.]) tensor([0.6089, 0.3911], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 7 - 45: cat - cat || Loss: 0.703578531742096\n",
      "tensor([1., 0.]) tensor([0.6097, 0.3903], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 7 - 46: cat - cat || Loss: 0.7027525901794434\n",
      "tensor([1., 0.]) tensor([0.6105, 0.3895], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 7 - 47: cat - cat || Loss: 0.7019256949424744\n",
      "tensor([1., 0.]) tensor([0.6113, 0.3887], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 7 - 48: cat - cat || Loss: 0.7010980844497681\n",
      "tensor([1., 0.]) tensor([0.6122, 0.3878], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 7 - 49: cat - cat || Loss: 0.7002698183059692\n",
      "tensor([1., 0.]) tensor([0.6130, 0.3870], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 7 - 50: cat - cat || Loss: 0.6994409561157227\n",
      "tensor([1., 0.]) tensor([0.6138, 0.3862], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 7 - 51: cat - cat || Loss: 0.6986116170883179\n",
      "tensor([1., 0.]) tensor([0.6147, 0.3853], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 7 - 52: cat - cat || Loss: 0.6977818012237549\n",
      "tensor([1., 0.]) tensor([0.6155, 0.3845], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 7 - 53: cat - cat || Loss: 0.6969515085220337\n",
      "tensor([1., 0.]) tensor([0.6163, 0.3837], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 7 - 54: cat - cat || Loss: 0.6961212158203125\n",
      "tensor([1., 0.]) tensor([0.6171, 0.3829], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 7 - 55: cat - cat || Loss: 0.6952906847000122\n",
      "tensor([1., 0.]) tensor([0.6180, 0.3820], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 7 - 56: cat - cat || Loss: 0.6944601535797119\n",
      "tensor([1., 0.]) tensor([0.6188, 0.3812], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 7 - 57: cat - cat || Loss: 0.6936294436454773\n",
      "tensor([1., 0.]) tensor([0.6196, 0.3804], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 7 - 58: cat - cat || Loss: 0.6927989721298218\n",
      "tensor([1., 0.]) tensor([0.6205, 0.3795], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 7 - 59: cat - cat || Loss: 0.6919686794281006\n",
      "tensor([1., 0.]) tensor([0.6213, 0.3787], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 7 - 60: cat - cat || Loss: 0.6911383867263794\n",
      "tensor([1., 0.]) tensor([0.6221, 0.3779], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 7 - 61: cat - cat || Loss: 0.690308153629303\n",
      "tensor([1., 0.]) tensor([0.6230, 0.3770], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 7 - 62: cat - cat || Loss: 0.6894780397415161\n",
      "tensor([1., 0.]) tensor([0.6238, 0.3762], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 7 - 63: cat - cat || Loss: 0.6886483430862427\n",
      "tensor([1., 0.]) tensor([0.6246, 0.3754], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 7 - 64: cat - cat || Loss: 0.6878187656402588\n",
      "tensor([1., 0.]) tensor([0.6254, 0.3746], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 7 - 65: cat - cat || Loss: 0.6869893670082092\n",
      "tensor([1., 0.]) tensor([0.6263, 0.3737], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 7 - 66: cat - cat || Loss: 0.6861602067947388\n",
      "tensor([1., 0.]) tensor([0.6271, 0.3729], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 7 - 67: cat - cat || Loss: 0.6853315234184265\n",
      "tensor([1., 0.]) tensor([0.6279, 0.3721], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 7 - 68: cat - cat || Loss: 0.6845030784606934\n",
      "tensor([1., 0.]) tensor([0.6288, 0.3712], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 7 - 69: cat - cat || Loss: 0.6836750507354736\n",
      "tensor([1., 0.]) tensor([0.6296, 0.3704], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 7 - 70: cat - cat || Loss: 0.682847261428833\n",
      "tensor([1., 0.]) tensor([0.6304, 0.3696], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 7 - 71: cat - cat || Loss: 0.6820200085639954\n",
      "tensor([1., 0.]) tensor([0.6312, 0.3688], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 7 - 72: cat - cat || Loss: 0.681192934513092\n",
      "tensor([1., 0.]) tensor([0.6321, 0.3679], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 7 - 73: cat - cat || Loss: 0.6803663969039917\n",
      "tensor([1., 0.]) tensor([0.6329, 0.3671], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 7 - 74: cat - cat || Loss: 0.6795400977134705\n",
      "tensor([1., 0.]) tensor([0.6337, 0.3663], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 7 - 75: cat - cat || Loss: 0.6787141561508179\n",
      "tensor([1., 0.]) tensor([0.6345, 0.3655], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 7 - 76: cat - cat || Loss: 0.677888810634613\n",
      "tensor([1., 0.]) tensor([0.6354, 0.3646], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 7 - 77: cat - cat || Loss: 0.6770637631416321\n",
      "tensor([1., 0.]) tensor([0.6362, 0.3638], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 7 - 78: cat - cat || Loss: 0.6762391328811646\n",
      "tensor([1., 0.]) tensor([0.6370, 0.3630], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 7 - 79: cat - cat || Loss: 0.6754148602485657\n",
      "tensor([1., 0.]) tensor([0.6378, 0.3622], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 7 - 80: cat - cat || Loss: 0.6745911836624146\n",
      "tensor([1., 0.]) tensor([0.6387, 0.3613], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 7 - 81: cat - cat || Loss: 0.6737678050994873\n",
      "tensor([1., 0.]) tensor([0.6395, 0.3605], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 7 - 82: cat - cat || Loss: 0.672944962978363\n",
      "tensor([1., 0.]) tensor([0.6403, 0.3597], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 7 - 83: cat - cat || Loss: 0.672122597694397\n",
      "tensor([1., 0.]) tensor([0.6411, 0.3589], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 7 - 84: cat - cat || Loss: 0.6713008284568787\n",
      "tensor([1., 0.]) tensor([0.6420, 0.3580], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 7 - 85: cat - cat || Loss: 0.6704792976379395\n",
      "tensor([1., 0.]) tensor([0.6428, 0.3572], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 7 - 86: cat - cat || Loss: 0.6696584820747375\n",
      "tensor([1., 0.]) tensor([0.6436, 0.3564], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 7 - 87: cat - cat || Loss: 0.6688379645347595\n",
      "tensor([1., 0.]) tensor([0.6444, 0.3556], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 7 - 88: cat - cat || Loss: 0.6680179834365845\n",
      "tensor([1., 0.]) tensor([0.6452, 0.3548], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 7 - 89: cat - cat || Loss: 0.6671985387802124\n",
      "tensor([1., 0.]) tensor([0.6461, 0.3539], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 7 - 90: cat - cat || Loss: 0.6663796901702881\n",
      "tensor([1., 0.]) tensor([0.6469, 0.3531], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 7 - 91: cat - cat || Loss: 0.6655610203742981\n",
      "tensor([1., 0.]) tensor([0.6477, 0.3523], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 7 - 92: cat - cat || Loss: 0.6647431254386902\n",
      "tensor([1., 0.]) tensor([0.6485, 0.3515], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 7 - 93: cat - cat || Loss: 0.6639255881309509\n",
      "tensor([1., 0.]) tensor([0.6493, 0.3507], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 7 - 94: cat - cat || Loss: 0.6631085872650146\n",
      "tensor([1., 0.]) tensor([0.6502, 0.3498], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 7 - 95: cat - cat || Loss: 0.6622921228408813\n",
      "tensor([1., 0.]) tensor([0.6510, 0.3490], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 7 - 96: cat - cat || Loss: 0.6614760756492615\n",
      "tensor([1., 0.]) tensor([0.6518, 0.3482], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 7 - 97: cat - cat || Loss: 0.6606605648994446\n",
      "tensor([1., 0.]) tensor([0.6526, 0.3474], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 7 - 98: cat - cat || Loss: 0.6598456501960754\n",
      "tensor([1., 0.]) tensor([0.6534, 0.3466], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 7 - 99: cat - cat || Loss: 0.6590311527252197\n",
      "tensor([1., 0.]) tensor([0.6542, 0.3458], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 7 - 100: cat - cat || Loss: 0.658217191696167\n",
      "tensor([1., 0.]) tensor([0.6550, 0.3450], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 7 - 101: cat - cat || Loss: 0.6574038863182068\n",
      "tensor([1., 0.]) tensor([0.6559, 0.3441], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 7 - 102: cat - cat || Loss: 0.6565910577774048\n",
      "tensor([1., 0.]) tensor([0.6567, 0.3433], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 7 - 103: cat - cat || Loss: 0.6557785868644714\n",
      "tensor([1., 0.]) tensor([0.6575, 0.3425], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 7 - 104: cat - cat || Loss: 0.6549668312072754\n",
      "tensor([1., 0.]) tensor([0.6583, 0.3417], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 7 - 105: cat - cat || Loss: 0.6541554927825928\n",
      "tensor([1., 0.]) tensor([0.6591, 0.3409], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 7 - 106: cat - cat || Loss: 0.6533447504043579\n",
      "tensor([1., 0.]) tensor([0.6599, 0.3401], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 7 - 107: cat - cat || Loss: 0.6525346040725708\n",
      "tensor([1., 0.]) tensor([0.6607, 0.3393], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 7 - 108: cat - cat || Loss: 0.6517249941825867\n",
      "tensor([1., 0.]) tensor([0.6615, 0.3385], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 7 - 109: cat - cat || Loss: 0.6509159803390503\n",
      "tensor([1., 0.]) tensor([0.6623, 0.3377], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 7 - 110: cat - cat || Loss: 0.6501075029373169\n",
      "tensor([1., 0.]) tensor([0.6632, 0.3368], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 7 - 111: cat - cat || Loss: 0.6492995619773865\n",
      "tensor([1., 0.]) tensor([0.6640, 0.3360], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 7 - 112: cat - cat || Loss: 0.6484922170639038\n",
      "tensor([1., 0.]) tensor([0.6648, 0.3352], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 7 - 113: cat - cat || Loss: 0.6476854085922241\n",
      "tensor([1., 0.]) tensor([0.6656, 0.3344], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 7 - 114: cat - cat || Loss: 0.6468790769577026\n",
      "tensor([1., 0.]) tensor([0.6664, 0.3336], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 7 - 115: cat - cat || Loss: 0.6460734605789185\n",
      "tensor([1., 0.]) tensor([0.6672, 0.3328], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 7 - 116: cat - cat || Loss: 0.6452681422233582\n",
      "tensor([1., 0.]) tensor([0.6680, 0.3320], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 7 - 117: cat - cat || Loss: 0.6444636583328247\n",
      "tensor([1., 0.]) tensor([0.6688, 0.3312], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 7 - 118: cat - cat || Loss: 0.6436594724655151\n",
      "tensor([1., 0.]) tensor([0.6696, 0.3304], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 7 - 119: cat - cat || Loss: 0.6428561210632324\n",
      "tensor([1., 0.]) tensor([0.6704, 0.3296], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 7 - 120: cat - cat || Loss: 0.6420532464981079\n",
      "tensor([1., 0.]) tensor([0.6712, 0.3288], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 7 - 121: cat - cat || Loss: 0.641250729560852\n",
      "tensor([1., 0.]) tensor([0.6720, 0.3280], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 7 - 122: cat - cat || Loss: 0.640449047088623\n",
      "tensor([1., 0.]) tensor([0.6728, 0.3272], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 7 - 123: cat - cat || Loss: 0.6396477222442627\n",
      "tensor([1., 0.]) tensor([0.6736, 0.3264], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 7 - 124: cat - cat || Loss: 0.6388471126556396\n",
      "tensor([1., 0.]) tensor([0.6744, 0.3256], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 7 - 125: cat - cat || Loss: 0.6380470991134644\n",
      "tensor([1., 0.]) tensor([0.6752, 0.3248], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 7 - 126: cat - cat || Loss: 0.6372475028038025\n",
      "tensor([1., 0.]) tensor([0.6760, 0.3240], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 7 - 127: cat - cat || Loss: 0.6364485621452332\n",
      "tensor([1., 0.]) tensor([0.6768, 0.3232], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 7 - 128: cat - cat || Loss: 0.6356503367424011\n",
      "tensor([1., 0.]) tensor([0.6776, 0.3224], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 7 - 129: cat - cat || Loss: 0.6348526477813721\n",
      "tensor([1., 0.]) tensor([0.6784, 0.3216], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 7 - 130: cat - cat || Loss: 0.6340555548667908\n",
      "tensor([1., 0.]) tensor([0.6792, 0.3208], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 7 - 131: cat - cat || Loss: 0.6332589387893677\n",
      "tensor([1., 0.]) tensor([0.6800, 0.3200], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 7 - 132: cat - cat || Loss: 0.6324632167816162\n",
      "tensor([1., 0.]) tensor([0.6808, 0.3192], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 7 - 133: cat - cat || Loss: 0.6316680312156677\n",
      "tensor([1., 0.]) tensor([0.6816, 0.3184], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 7 - 134: cat - cat || Loss: 0.6308735609054565\n",
      "tensor([1., 0.]) tensor([0.6824, 0.3176], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 7 - 135: cat - cat || Loss: 0.6300796270370483\n",
      "tensor([1., 0.]) tensor([0.6832, 0.3168], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 7 - 136: cat - cat || Loss: 0.6292864084243774\n",
      "tensor([1., 0.]) tensor([0.6840, 0.3160], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 7 - 137: cat - cat || Loss: 0.6284937262535095\n",
      "tensor([1., 0.]) tensor([0.6848, 0.3152], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 7 - 138: cat - cat || Loss: 0.6277016997337341\n",
      "tensor([1., 0.]) tensor([0.6856, 0.3144], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 7 - 139: cat - cat || Loss: 0.6269102692604065\n",
      "tensor([1., 0.]) tensor([0.6864, 0.3136], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 7 - 140: cat - cat || Loss: 0.6261195540428162\n",
      "tensor([1., 0.]) tensor([0.6871, 0.3129], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 7 - 141: cat - cat || Loss: 0.6253294944763184\n",
      "tensor([1., 0.]) tensor([0.6879, 0.3121], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 7 - 142: cat - cat || Loss: 0.6245401501655579\n",
      "tensor([1., 0.]) tensor([0.6887, 0.3113], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 7 - 143: cat - cat || Loss: 0.6237514019012451\n",
      "tensor([1., 0.]) tensor([0.6895, 0.3105], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 7 - 144: cat - cat || Loss: 0.6229633092880249\n",
      "tensor([1., 0.]) tensor([0.6903, 0.3097], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 7 - 145: cat - cat || Loss: 0.6221758127212524\n",
      "tensor([1., 0.]) tensor([0.6911, 0.3089], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 7 - 146: cat - cat || Loss: 0.6213891506195068\n",
      "tensor([1., 0.]) tensor([0.6919, 0.3081], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 7 - 147: cat - cat || Loss: 0.6206031441688538\n",
      "tensor([1., 0.]) tensor([0.6927, 0.3073], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 7 - 148: cat - cat || Loss: 0.6198176741600037\n",
      "tensor([1., 0.]) tensor([0.6934, 0.3066], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 7 - 149: cat - cat || Loss: 0.6190329790115356\n",
      "tensor([1., 0.]) tensor([0.6942, 0.3058], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 7 - 150: cat - cat || Loss: 0.6182488799095154\n",
      "tensor([1., 0.]) tensor([0.6950, 0.3050], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 7 - 151: cat - cat || Loss: 0.6174654960632324\n",
      "tensor([1., 0.]) tensor([0.6958, 0.3042], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 7 - 152: cat - cat || Loss: 0.616682767868042\n",
      "tensor([1., 0.]) tensor([0.6966, 0.3034], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 7 - 153: cat - cat || Loss: 0.6159006953239441\n",
      "tensor([1., 0.]) tensor([0.6974, 0.3026], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 7 - 154: cat - cat || Loss: 0.6151192784309387\n",
      "tensor([1., 0.]) tensor([0.6981, 0.3019], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 7 - 155: cat - cat || Loss: 0.6143384575843811\n",
      "tensor([1., 0.]) tensor([0.6989, 0.3011], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 7 - 156: cat - cat || Loss: 0.6135584115982056\n",
      "tensor([1., 0.]) tensor([0.6997, 0.3003], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 7 - 157: cat - cat || Loss: 0.6127790212631226\n",
      "tensor([1., 0.]) tensor([0.7005, 0.2995], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 7 - 158: cat - cat || Loss: 0.6120002865791321\n",
      "tensor([1., 0.]) tensor([0.7013, 0.2987], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 7 - 159: cat - cat || Loss: 0.6112222671508789\n",
      "tensor([1., 0.]) tensor([0.7020, 0.2980], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 7 - 160: cat - cat || Loss: 0.6104449033737183\n",
      "tensor([1., 0.]) tensor([0.7028, 0.2972], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 7 - 161: cat - cat || Loss: 0.6096683144569397\n",
      "tensor([1., 0.]) tensor([0.7036, 0.2964], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 7 - 162: cat - cat || Loss: 0.6088924407958984\n",
      "tensor([1., 0.]) tensor([0.7044, 0.2956], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 7 - 163: cat - cat || Loss: 0.6081171631813049\n",
      "tensor([1., 0.]) tensor([0.7051, 0.2949], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 7 - 164: cat - cat || Loss: 0.6073426008224487\n",
      "tensor([1., 0.]) tensor([0.7059, 0.2941], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 7 - 165: cat - cat || Loss: 0.6065688729286194\n",
      "tensor([1., 0.]) tensor([0.7067, 0.2933], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 7 - 166: cat - cat || Loss: 0.6057958006858826\n",
      "tensor([1., 0.]) tensor([0.7075, 0.2925], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 7 - 167: cat - cat || Loss: 0.6050235033035278\n",
      "tensor([1., 0.]) tensor([0.7082, 0.2918], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 7 - 168: cat - cat || Loss: 0.6042520403862\n",
      "tensor([1., 0.]) tensor([0.7090, 0.2910], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 7 - 169: cat - cat || Loss: 0.6034810543060303\n",
      "tensor([1., 0.]) tensor([0.7098, 0.2902], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 7 - 170: cat - cat || Loss: 0.6027109622955322\n",
      "tensor([1., 0.]) tensor([0.7106, 0.2894], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 7 - 171: cat - cat || Loss: 0.601941704750061\n",
      "tensor([1., 0.]) tensor([0.7113, 0.2887], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 7 - 172: cat - cat || Loss: 0.6011730432510376\n",
      "tensor([1., 0.]) tensor([0.7121, 0.2879], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 7 - 173: cat - cat || Loss: 0.600405216217041\n",
      "tensor([1., 0.]) tensor([0.7129, 0.2871], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 7 - 174: cat - cat || Loss: 0.5996381640434265\n",
      "tensor([1., 0.]) tensor([0.7136, 0.2864], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 7 - 175: cat - cat || Loss: 0.5988717079162598\n",
      "tensor([1., 0.]) tensor([0.7144, 0.2856], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 7 - 176: cat - cat || Loss: 0.5981060862541199\n",
      "tensor([1., 0.]) tensor([0.7152, 0.2848], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 7 - 177: cat - cat || Loss: 0.5973412990570068\n",
      "tensor([1., 0.]) tensor([0.7159, 0.2841], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 7 - 178: cat - cat || Loss: 0.5965772271156311\n",
      "tensor([1., 0.]) tensor([0.7167, 0.2833], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 7 - 179: cat - cat || Loss: 0.5958139896392822\n",
      "tensor([1., 0.]) tensor([0.7174, 0.2826], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 7 - 180: cat - cat || Loss: 0.5950512886047363\n",
      "tensor([1., 0.]) tensor([0.7182, 0.2818], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 7 - 181: cat - cat || Loss: 0.5942895412445068\n",
      "tensor([1., 0.]) tensor([0.7190, 0.2810], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 7 - 182: cat - cat || Loss: 0.5935285091400146\n",
      "tensor([1., 0.]) tensor([0.7197, 0.2803], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 7 - 183: cat - cat || Loss: 0.5927683115005493\n",
      "tensor([1., 0.]) tensor([0.7205, 0.2795], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 7 - 184: cat - cat || Loss: 0.592008650302887\n",
      "tensor([1., 0.]) tensor([0.7213, 0.2787], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 7 - 185: cat - cat || Loss: 0.5912500023841858\n",
      "tensor([1., 0.]) tensor([0.7220, 0.2780], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 7 - 186: cat - cat || Loss: 0.5904918313026428\n",
      "tensor([1., 0.]) tensor([0.7228, 0.2772], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 7 - 187: cat - cat || Loss: 0.589734673500061\n",
      "tensor([1., 0.]) tensor([0.7235, 0.2765], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 7 - 188: cat - cat || Loss: 0.5889782905578613\n",
      "tensor([1., 0.]) tensor([0.7243, 0.2757], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 7 - 189: cat - cat || Loss: 0.5882226228713989\n",
      "tensor([1., 0.]) tensor([0.7250, 0.2750], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 7 - 190: dog - cat || Loss: 1.039055585861206\n",
      "tensor([0., 1.]) tensor([0.7258, 0.2742], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 7 - 191: dog - cat || Loss: 1.0396593809127808\n",
      "tensor([0., 1.]) tensor([0.7264, 0.2736], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 7 - 192: dog - cat || Loss: 1.0401275157928467\n",
      "tensor([0., 1.]) tensor([0.7269, 0.2731], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 7 - 193: dog - cat || Loss: 1.0404738187789917\n",
      "tensor([0., 1.]) tensor([0.7272, 0.2728], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 7 - 194: dog - cat || Loss: 1.04071044921875\n",
      "tensor([0., 1.]) tensor([0.7274, 0.2726], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 7 - 195: dog - cat || Loss: 1.0408483743667603\n",
      "tensor([0., 1.]) tensor([0.7276, 0.2724], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 7 - 196: dog - cat || Loss: 1.0408977270126343\n",
      "tensor([0., 1.]) tensor([0.7276, 0.2724], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 7 - 197: dog - cat || Loss: 1.0408669710159302\n",
      "tensor([0., 1.]) tensor([0.7276, 0.2724], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 7 - 198: dog - cat || Loss: 1.0407644510269165\n",
      "tensor([0., 1.]) tensor([0.7275, 0.2725], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 7 - 199: dog - cat || Loss: 1.0405974388122559\n",
      "tensor([0., 1.]) tensor([0.7273, 0.2727], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 7 - 200: dog - cat || Loss: 1.0403718948364258\n",
      "tensor([0., 1.]) tensor([0.7271, 0.2729], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 7 - 201: dog - cat || Loss: 1.040094017982483\n",
      "tensor([0., 1.]) tensor([0.7268, 0.2732], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 7 - 202: dog - cat || Loss: 1.039768934249878\n",
      "tensor([0., 1.]) tensor([0.7265, 0.2735], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 7 - 203: dog - cat || Loss: 1.0394011735916138\n",
      "tensor([0., 1.]) tensor([0.7261, 0.2739], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 7 - 204: dog - cat || Loss: 1.0389951467514038\n",
      "tensor([0., 1.]) tensor([0.7257, 0.2743], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 7 - 205: dog - cat || Loss: 1.038554310798645\n",
      "tensor([0., 1.]) tensor([0.7253, 0.2747], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 7 - 206: dog - cat || Loss: 1.038082480430603\n",
      "tensor([0., 1.]) tensor([0.7248, 0.2752], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 7 - 207: dog - cat || Loss: 1.037582516670227\n",
      "tensor([0., 1.]) tensor([0.7243, 0.2757], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 7 - 208: dog - cat || Loss: 1.0370570421218872\n",
      "tensor([0., 1.]) tensor([0.7238, 0.2762], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 7 - 209: dog - cat || Loss: 1.0365089178085327\n",
      "tensor([0., 1.]) tensor([0.7232, 0.2768], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 7 - 210: dog - cat || Loss: 1.035940170288086\n",
      "tensor([0., 1.]) tensor([0.7227, 0.2773], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 7 - 211: dog - cat || Loss: 1.0353527069091797\n",
      "tensor([0., 1.]) tensor([0.7221, 0.2779], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 7 - 212: dog - cat || Loss: 1.0347483158111572\n",
      "tensor([0., 1.]) tensor([0.7215, 0.2785], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 7 - 213: dog - cat || Loss: 1.0341286659240723\n",
      "tensor([0., 1.]) tensor([0.7209, 0.2791], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 7 - 214: dog - cat || Loss: 1.033495306968689\n",
      "tensor([0., 1.]) tensor([0.7202, 0.2798], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 7 - 215: dog - cat || Loss: 1.0328493118286133\n",
      "tensor([0., 1.]) tensor([0.7196, 0.2804], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 7 - 216: dog - cat || Loss: 1.0321922302246094\n",
      "tensor([0., 1.]) tensor([0.7189, 0.2811], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 7 - 217: dog - cat || Loss: 1.031524658203125\n",
      "tensor([0., 1.]) tensor([0.7183, 0.2817], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 7 - 218: dog - cat || Loss: 1.0308479070663452\n",
      "tensor([0., 1.]) tensor([0.7176, 0.2824], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 7 - 219: dog - cat || Loss: 1.0301625728607178\n",
      "tensor([0., 1.]) tensor([0.7169, 0.2831], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 7 - 220: dog - cat || Loss: 1.0294698476791382\n",
      "tensor([0., 1.]) tensor([0.7162, 0.2838], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 7 - 221: dog - cat || Loss: 1.028770089149475\n",
      "tensor([0., 1.]) tensor([0.7155, 0.2845], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 7 - 222: dog - cat || Loss: 1.0280638933181763\n",
      "tensor([0., 1.]) tensor([0.7148, 0.2852], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 7 - 223: dog - cat || Loss: 1.027351975440979\n",
      "tensor([0., 1.]) tensor([0.7141, 0.2859], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 7 - 224: dog - cat || Loss: 1.0266348123550415\n",
      "tensor([0., 1.]) tensor([0.7134, 0.2866], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 7 - 225: dog - cat || Loss: 1.025912880897522\n",
      "tensor([0., 1.]) tensor([0.7127, 0.2873], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 7 - 226: dog - cat || Loss: 1.025186538696289\n",
      "tensor([0., 1.]) tensor([0.7119, 0.2881], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 7 - 227: dog - cat || Loss: 1.0244561433792114\n",
      "tensor([0., 1.]) tensor([0.7112, 0.2888], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 7 - 228: dog - cat || Loss: 1.0237220525741577\n",
      "tensor([0., 1.]) tensor([0.7105, 0.2895], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 7 - 229: dog - cat || Loss: 1.0229847431182861\n",
      "tensor([0., 1.]) tensor([0.7097, 0.2903], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 7 - 230: dog - cat || Loss: 1.0222440958023071\n",
      "tensor([0., 1.]) tensor([0.7090, 0.2910], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 7 - 231: dog - cat || Loss: 1.021500587463379\n",
      "tensor([0., 1.]) tensor([0.7082, 0.2918], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 7 - 232: dog - cat || Loss: 1.0207545757293701\n",
      "tensor([0., 1.]) tensor([0.7075, 0.2925], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 7 - 233: dog - cat || Loss: 1.0200060606002808\n",
      "tensor([0., 1.]) tensor([0.7067, 0.2933], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 7 - 234: dog - cat || Loss: 1.01925528049469\n",
      "tensor([0., 1.]) tensor([0.7060, 0.2940], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 7 - 235: dog - cat || Loss: 1.0185023546218872\n",
      "tensor([0., 1.]) tensor([0.7052, 0.2948], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 7 - 236: dog - cat || Loss: 1.017747402191162\n",
      "tensor([0., 1.]) tensor([0.7045, 0.2955], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 7 - 237: dog - cat || Loss: 1.0169907808303833\n",
      "tensor([0., 1.]) tensor([0.7037, 0.2963], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 7 - 238: dog - cat || Loss: 1.0162324905395508\n",
      "tensor([0., 1.]) tensor([0.7030, 0.2970], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 7 - 239: dog - cat || Loss: 1.015472412109375\n",
      "tensor([0., 1.]) tensor([0.7022, 0.2978], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 7 - 240: dog - cat || Loss: 1.0147110223770142\n",
      "tensor([0., 1.]) tensor([0.7014, 0.2986], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 7 - 241: dog - cat || Loss: 1.0139482021331787\n",
      "tensor([0., 1.]) tensor([0.7007, 0.2993], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 7 - 242: dog - cat || Loss: 1.0131839513778687\n",
      "tensor([0., 1.]) tensor([0.6999, 0.3001], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 7 - 243: dog - cat || Loss: 1.012418508529663\n",
      "tensor([0., 1.]) tensor([0.6992, 0.3008], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 7 - 244: dog - cat || Loss: 1.0116521120071411\n",
      "tensor([0., 1.]) tensor([0.6984, 0.3016], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 7 - 245: dog - cat || Loss: 1.010884404182434\n",
      "tensor([0., 1.]) tensor([0.6976, 0.3024], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 7 - 246: dog - cat || Loss: 1.0101157426834106\n",
      "tensor([0., 1.]) tensor([0.6969, 0.3031], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 7 - 247: dog - cat || Loss: 1.0093460083007812\n",
      "tensor([0., 1.]) tensor([0.6961, 0.3039], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 7 - 248: dog - cat || Loss: 1.0085753202438354\n",
      "tensor([0., 1.]) tensor([0.6953, 0.3047], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 7 - 249: dog - cat || Loss: 1.0078035593032837\n",
      "tensor([0., 1.]) tensor([0.6945, 0.3055], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 7 - 250: dog - cat || Loss: 1.007030963897705\n",
      "tensor([0., 1.]) tensor([0.6938, 0.3062], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 7 - 251: dog - cat || Loss: 1.0062576532363892\n",
      "tensor([0., 1.]) tensor([0.6930, 0.3070], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 7 - 252: dog - cat || Loss: 1.0054832696914673\n",
      "tensor([0., 1.]) tensor([0.6922, 0.3078], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 7 - 253: dog - cat || Loss: 1.004707932472229\n",
      "tensor([0., 1.]) tensor([0.6914, 0.3086], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 7 - 254: dog - cat || Loss: 1.003931999206543\n",
      "tensor([0., 1.]) tensor([0.6907, 0.3093], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 7 - 255: dog - cat || Loss: 1.0031551122665405\n",
      "tensor([0., 1.]) tensor([0.6899, 0.3101], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 7 - 256: dog - cat || Loss: 1.0023776292800903\n",
      "tensor([0., 1.]) tensor([0.6891, 0.3109], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 7 - 257: dog - cat || Loss: 1.0015993118286133\n",
      "tensor([0., 1.]) tensor([0.6883, 0.3117], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 7 - 258: dog - cat || Loss: 1.000820279121399\n",
      "tensor([0., 1.]) tensor([0.6876, 0.3124], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 7 - 259: dog - cat || Loss: 1.0000405311584473\n",
      "tensor([0., 1.]) tensor([0.6868, 0.3132], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 7 - 260: dog - cat || Loss: 0.999259889125824\n",
      "tensor([0., 1.]) tensor([0.6860, 0.3140], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 7 - 261: dog - cat || Loss: 0.9984787702560425\n",
      "tensor([0., 1.]) tensor([0.6852, 0.3148], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 7 - 262: dog - cat || Loss: 0.9976969361305237\n",
      "tensor([0., 1.]) tensor([0.6844, 0.3156], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 7 - 263: dog - cat || Loss: 0.9969143271446228\n",
      "tensor([0., 1.]) tensor([0.6837, 0.3163], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 7 - 264: dog - cat || Loss: 0.996131181716919\n",
      "tensor([0., 1.]) tensor([0.6829, 0.3171], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 7 - 265: dog - cat || Loss: 0.995347261428833\n",
      "tensor([0., 1.]) tensor([0.6821, 0.3179], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 7 - 266: dog - cat || Loss: 0.9945628643035889\n",
      "tensor([0., 1.]) tensor([0.6813, 0.3187], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 7 - 267: dog - cat || Loss: 0.9937778115272522\n",
      "tensor([0., 1.]) tensor([0.6805, 0.3195], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 7 - 268: dog - cat || Loss: 0.9929919242858887\n",
      "tensor([0., 1.]) tensor([0.6797, 0.3203], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 7 - 269: dog - cat || Loss: 0.9922056198120117\n",
      "tensor([0., 1.]) tensor([0.6789, 0.3211], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 7 - 270: dog - cat || Loss: 0.9914185404777527\n",
      "tensor([0., 1.]) tensor([0.6782, 0.3218], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 7 - 271: dog - cat || Loss: 0.9906309843063354\n",
      "tensor([0., 1.]) tensor([0.6774, 0.3226], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 7 - 272: dog - cat || Loss: 0.9898427724838257\n",
      "tensor([0., 1.]) tensor([0.6766, 0.3234], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 7 - 273: dog - cat || Loss: 0.9890540838241577\n",
      "tensor([0., 1.]) tensor([0.6758, 0.3242], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 7 - 274: dog - cat || Loss: 0.9882646203041077\n",
      "tensor([0., 1.]) tensor([0.6750, 0.3250], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 7 - 275: dog - cat || Loss: 0.987474799156189\n",
      "tensor([0., 1.]) tensor([0.6742, 0.3258], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 7 - 276: dog - cat || Loss: 0.9866843223571777\n",
      "tensor([0., 1.]) tensor([0.6734, 0.3266], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 7 - 277: dog - cat || Loss: 0.9858933091163635\n",
      "tensor([0., 1.]) tensor([0.6726, 0.3274], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 7 - 278: dog - cat || Loss: 0.9851016998291016\n",
      "tensor([0., 1.]) tensor([0.6718, 0.3282], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 7 - 279: dog - cat || Loss: 0.9843095541000366\n",
      "tensor([0., 1.]) tensor([0.6710, 0.3290], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 7 - 280: dog - cat || Loss: 0.9835168719291687\n",
      "tensor([0., 1.]) tensor([0.6703, 0.3297], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 7 - 281: dog - cat || Loss: 0.9827236533164978\n",
      "tensor([0., 1.]) tensor([0.6695, 0.3305], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 7 - 282: dog - cat || Loss: 0.9819298982620239\n",
      "tensor([0., 1.]) tensor([0.6687, 0.3313], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 7 - 283: dog - cat || Loss: 0.9811355471611023\n",
      "tensor([0., 1.]) tensor([0.6679, 0.3321], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 7 - 284: dog - cat || Loss: 0.9803406596183777\n",
      "tensor([0., 1.]) tensor([0.6671, 0.3329], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 7 - 285: dog - cat || Loss: 0.9795452356338501\n",
      "tensor([0., 1.]) tensor([0.6663, 0.3337], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 7 - 286: dog - cat || Loss: 0.9787493944168091\n",
      "tensor([0., 1.]) tensor([0.6655, 0.3345], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 7 - 287: dog - cat || Loss: 0.977952778339386\n",
      "tensor([0., 1.]) tensor([0.6647, 0.3353], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 7 - 288: dog - cat || Loss: 0.9771558046340942\n",
      "tensor([0., 1.]) tensor([0.6639, 0.3361], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 7 - 289: dog - cat || Loss: 0.97635817527771\n",
      "tensor([0., 1.]) tensor([0.6631, 0.3369], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 7 - 290: dog - cat || Loss: 0.9755603075027466\n",
      "tensor([0., 1.]) tensor([0.6623, 0.3377], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 7 - 291: dog - cat || Loss: 0.9747616648674011\n",
      "tensor([0., 1.]) tensor([0.6615, 0.3385], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 7 - 292: dog - cat || Loss: 0.9739624857902527\n",
      "tensor([0., 1.]) tensor([0.6607, 0.3393], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 7 - 293: dog - cat || Loss: 0.9731628894805908\n",
      "tensor([0., 1.]) tensor([0.6599, 0.3401], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 7 - 294: dog - cat || Loss: 0.9723628163337708\n",
      "tensor([0., 1.]) tensor([0.6591, 0.3409], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 7 - 295: dog - cat || Loss: 0.9715622067451477\n",
      "tensor([0., 1.]) tensor([0.6583, 0.3417], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 7 - 296: dog - cat || Loss: 0.9707610607147217\n",
      "tensor([0., 1.]) tensor([0.6575, 0.3425], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 7 - 297: dog - cat || Loss: 0.9699596166610718\n",
      "tensor([0., 1.]) tensor([0.6567, 0.3433], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 7 - 298: dog - cat || Loss: 0.969157338142395\n",
      "tensor([0., 1.]) tensor([0.6559, 0.3441], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 7 - 299: dog - cat || Loss: 0.9683547019958496\n",
      "tensor([0., 1.]) tensor([0.6551, 0.3449], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 7 - 300: dog - cat || Loss: 0.9675516486167908\n",
      "tensor([0., 1.]) tensor([0.6543, 0.3457], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 7 - 301: dog - cat || Loss: 0.966748058795929\n",
      "tensor([0., 1.]) tensor([0.6535, 0.3465], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 7 - 302: dog - cat || Loss: 0.9659441709518433\n",
      "tensor([0., 1.]) tensor([0.6527, 0.3473], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 7 - 303: dog - cat || Loss: 0.965139627456665\n",
      "tensor([0., 1.]) tensor([0.6519, 0.3481], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 7 - 304: dog - cat || Loss: 0.9643346667289734\n",
      "tensor([0., 1.]) tensor([0.6511, 0.3489], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 7 - 305: dog - cat || Loss: 0.9635289907455444\n",
      "tensor([0., 1.]) tensor([0.6503, 0.3497], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 7 - 306: dog - cat || Loss: 0.9627230763435364\n",
      "tensor([0., 1.]) tensor([0.6495, 0.3505], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 7 - 307: dog - cat || Loss: 0.9619166851043701\n",
      "tensor([0., 1.]) tensor([0.6487, 0.3513], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 7 - 308: dog - cat || Loss: 0.9611096382141113\n",
      "tensor([0., 1.]) tensor([0.6478, 0.3522], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 7 - 309: dog - cat || Loss: 0.9603024125099182\n",
      "tensor([0., 1.]) tensor([0.6470, 0.3530], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 7 - 310: dog - cat || Loss: 0.9594944715499878\n",
      "tensor([0., 1.]) tensor([0.6462, 0.3538], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 7 - 311: dog - cat || Loss: 0.958686113357544\n",
      "tensor([0., 1.]) tensor([0.6454, 0.3546], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 7 - 312: dog - cat || Loss: 0.9578773975372314\n",
      "tensor([0., 1.]) tensor([0.6446, 0.3554], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 7 - 313: dog - cat || Loss: 0.957068145275116\n",
      "tensor([0., 1.]) tensor([0.6438, 0.3562], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 7 - 314: dog - cat || Loss: 0.9562585949897766\n",
      "tensor([0., 1.]) tensor([0.6430, 0.3570], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 7 - 315: dog - cat || Loss: 0.9554482698440552\n",
      "tensor([0., 1.]) tensor([0.6422, 0.3578], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 7 - 316: dog - cat || Loss: 0.9546376466751099\n",
      "tensor([0., 1.]) tensor([0.6414, 0.3586], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 7 - 317: dog - cat || Loss: 0.9538264870643616\n",
      "tensor([0., 1.]) tensor([0.6406, 0.3594], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 7 - 318: dog - cat || Loss: 0.9530148506164551\n",
      "tensor([0., 1.]) tensor([0.6398, 0.3602], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 7 - 319: dog - cat || Loss: 0.9522029161453247\n",
      "tensor([0., 1.]) tensor([0.6389, 0.3611], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 7 - 320: dog - cat || Loss: 0.9513904452323914\n",
      "tensor([0., 1.]) tensor([0.6381, 0.3619], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 7 - 321: dog - cat || Loss: 0.9505773186683655\n",
      "tensor([0., 1.]) tensor([0.6373, 0.3627], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 7 - 322: dog - cat || Loss: 0.9497640132904053\n",
      "tensor([0., 1.]) tensor([0.6365, 0.3635], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 7 - 323: dog - cat || Loss: 0.948949933052063\n",
      "tensor([0., 1.]) tensor([0.6357, 0.3643], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 7 - 324: dog - cat || Loss: 0.9481357336044312\n",
      "tensor([0., 1.]) tensor([0.6349, 0.3651], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 7 - 325: dog - cat || Loss: 0.9473211765289307\n",
      "tensor([0., 1.]) tensor([0.6341, 0.3659], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 7 - 326: dog - cat || Loss: 0.9465060234069824\n",
      "tensor([0., 1.]) tensor([0.6332, 0.3668], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 7 - 327: dog - cat || Loss: 0.945690393447876\n",
      "tensor([0., 1.]) tensor([0.6324, 0.3676], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 7 - 328: dog - cat || Loss: 0.9448744654655457\n",
      "tensor([0., 1.]) tensor([0.6316, 0.3684], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 7 - 329: dog - cat || Loss: 0.9440581798553467\n",
      "tensor([0., 1.]) tensor([0.6308, 0.3692], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 7 - 330: dog - cat || Loss: 0.9432412385940552\n",
      "tensor([0., 1.]) tensor([0.6300, 0.3700], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 7 - 331: dog - cat || Loss: 0.9424238204956055\n",
      "tensor([0., 1.]) tensor([0.6292, 0.3708], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 7 - 332: dog - cat || Loss: 0.9416061639785767\n",
      "tensor([0., 1.]) tensor([0.6283, 0.3717], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 7 - 333: dog - cat || Loss: 0.9407877922058105\n",
      "tensor([0., 1.]) tensor([0.6275, 0.3725], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 7 - 334: dog - cat || Loss: 0.9399691224098206\n",
      "tensor([0., 1.]) tensor([0.6267, 0.3733], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 7 - 335: dog - cat || Loss: 0.9391500353813171\n",
      "tensor([0., 1.]) tensor([0.6259, 0.3741], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 7 - 336: dog - cat || Loss: 0.9383306503295898\n",
      "tensor([0., 1.]) tensor([0.6251, 0.3749], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 7 - 337: dog - cat || Loss: 0.93751060962677\n",
      "tensor([0., 1.]) tensor([0.6242, 0.3758], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 7 - 338: dog - cat || Loss: 0.9366903305053711\n",
      "tensor([0., 1.]) tensor([0.6234, 0.3766], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 7 - 339: dog - cat || Loss: 0.9358695149421692\n",
      "tensor([0., 1.]) tensor([0.6226, 0.3774], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 7 - 340: dog - cat || Loss: 0.9350483417510986\n",
      "tensor([0., 1.]) tensor([0.6218, 0.3782], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 7 - 341: dog - cat || Loss: 0.9342266917228699\n",
      "tensor([0., 1.]) tensor([0.6210, 0.3790], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 7 - 342: dog - cat || Loss: 0.9334047436714172\n",
      "tensor([0., 1.]) tensor([0.6201, 0.3799], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 7 - 343: dog - cat || Loss: 0.9325823783874512\n",
      "tensor([0., 1.]) tensor([0.6193, 0.3807], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 7 - 344: dog - cat || Loss: 0.9317596554756165\n",
      "tensor([0., 1.]) tensor([0.6185, 0.3815], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 7 - 345: dog - cat || Loss: 0.9309363961219788\n",
      "tensor([0., 1.]) tensor([0.6177, 0.3823], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 7 - 346: dog - cat || Loss: 0.9301128387451172\n",
      "tensor([0., 1.]) tensor([0.6169, 0.3831], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 7 - 347: dog - cat || Loss: 0.9292890429496765\n",
      "tensor([0., 1.]) tensor([0.6160, 0.3840], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 7 - 348: dog - cat || Loss: 0.9284647107124329\n",
      "tensor([0., 1.]) tensor([0.6152, 0.3848], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 7 - 349: dog - cat || Loss: 0.927639901638031\n",
      "tensor([0., 1.]) tensor([0.6144, 0.3856], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 7 - 350: dog - cat || Loss: 0.92681485414505\n",
      "tensor([0., 1.]) tensor([0.6136, 0.3864], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 7 - 351: dog - cat || Loss: 0.9259893298149109\n",
      "tensor([0., 1.]) tensor([0.6127, 0.3873], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 7 - 352: dog - cat || Loss: 0.9251635074615479\n",
      "tensor([0., 1.]) tensor([0.6119, 0.3881], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 7 - 353: dog - cat || Loss: 0.9243373274803162\n",
      "tensor([0., 1.]) tensor([0.6111, 0.3889], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 7 - 354: dog - cat || Loss: 0.9235106110572815\n",
      "tensor([0., 1.]) tensor([0.6102, 0.3898], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 7 - 355: dog - cat || Loss: 0.9226837158203125\n",
      "tensor([0., 1.]) tensor([0.6094, 0.3906], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 7 - 356: dog - cat || Loss: 0.9218563437461853\n",
      "tensor([0., 1.]) tensor([0.6086, 0.3914], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 7 - 357: dog - cat || Loss: 0.9210286140441895\n",
      "tensor([0., 1.]) tensor([0.6078, 0.3922], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 7 - 358: dog - cat || Loss: 0.9202005863189697\n",
      "tensor([0., 1.]) tensor([0.6069, 0.3931], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 7 - 359: dog - cat || Loss: 0.9193722605705261\n",
      "tensor([0., 1.]) tensor([0.6061, 0.3939], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 7 - 360: dog - cat || Loss: 0.9185435771942139\n",
      "tensor([0., 1.]) tensor([0.6053, 0.3947], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 7 - 361: dog - cat || Loss: 0.9177145957946777\n",
      "tensor([0., 1.]) tensor([0.6045, 0.3955], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 7 - 362: dog - cat || Loss: 0.9168851375579834\n",
      "tensor([0., 1.]) tensor([0.6036, 0.3964], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 7 - 363: dog - cat || Loss: 0.9160555005073547\n",
      "tensor([0., 1.]) tensor([0.6028, 0.3972], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 7 - 364: dog - cat || Loss: 0.9152255058288574\n",
      "tensor([0., 1.]) tensor([0.6020, 0.3980], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 7 - 365: dog - cat || Loss: 0.9143953323364258\n",
      "tensor([0., 1.]) tensor([0.6011, 0.3989], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 7 - 366: dog - cat || Loss: 0.9135645627975464\n",
      "tensor([0., 1.]) tensor([0.6003, 0.3997], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 7 - 367: dog - cat || Loss: 0.9127334952354431\n",
      "tensor([0., 1.]) tensor([0.5995, 0.4005], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 7 - 368: dog - cat || Loss: 0.9119022488594055\n",
      "tensor([0., 1.]) tensor([0.5986, 0.4014], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 7 - 369: dog - cat || Loss: 0.911070704460144\n",
      "tensor([0., 1.]) tensor([0.5978, 0.4022], grad_fn=<SoftmaxBackward0>)\n",
      "=====epoch:8=====\n",
      "Epoch 8 - 0: cat - cat || Loss: 0.7162843942642212\n",
      "tensor([1., 0.]) tensor([0.5970, 0.4030], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 8 - 1: cat - cat || Loss: 0.7169497013092041\n",
      "tensor([1., 0.]) tensor([0.5963, 0.4037], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 8 - 2: cat - cat || Loss: 0.7174651026725769\n",
      "tensor([1., 0.]) tensor([0.5958, 0.4042], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 8 - 3: cat - cat || Loss: 0.7178455591201782\n",
      "tensor([1., 0.]) tensor([0.5954, 0.4046], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 8 - 4: cat - cat || Loss: 0.7181044816970825\n",
      "tensor([1., 0.]) tensor([0.5952, 0.4048], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 8 - 5: cat - cat || Loss: 0.7182542085647583\n",
      "tensor([1., 0.]) tensor([0.5950, 0.4050], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 8 - 6: cat - cat || Loss: 0.7183053493499756\n",
      "tensor([1., 0.]) tensor([0.5950, 0.4050], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 8 - 7: cat - cat || Loss: 0.718268096446991\n",
      "tensor([1., 0.]) tensor([0.5950, 0.4050], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 8 - 8: cat - cat || Loss: 0.7181510329246521\n",
      "tensor([1., 0.]) tensor([0.5951, 0.4049], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 8 - 9: cat - cat || Loss: 0.7179623246192932\n",
      "tensor([1., 0.]) tensor([0.5953, 0.4047], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 8 - 10: cat - cat || Loss: 0.717708945274353\n",
      "tensor([1., 0.]) tensor([0.5956, 0.4044], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 8 - 11: cat - cat || Loss: 0.7173976302146912\n",
      "tensor([1., 0.]) tensor([0.5959, 0.4041], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 8 - 12: cat - cat || Loss: 0.7170342206954956\n",
      "tensor([1., 0.]) tensor([0.5962, 0.4038], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 8 - 13: cat - cat || Loss: 0.7166237235069275\n",
      "tensor([1., 0.]) tensor([0.5966, 0.4034], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 8 - 14: cat - cat || Loss: 0.7161709666252136\n",
      "tensor([1., 0.]) tensor([0.5971, 0.4029], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 8 - 15: cat - cat || Loss: 0.7156803607940674\n",
      "tensor([1., 0.]) tensor([0.5976, 0.4024], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 8 - 16: cat - cat || Loss: 0.7151556015014648\n",
      "tensor([1., 0.]) tensor([0.5981, 0.4019], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 8 - 17: cat - cat || Loss: 0.7146000862121582\n",
      "tensor([1., 0.]) tensor([0.5987, 0.4013], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 8 - 18: cat - cat || Loss: 0.7140169739723206\n",
      "tensor([1., 0.]) tensor([0.5992, 0.4008], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 8 - 19: cat - cat || Loss: 0.7134089469909668\n",
      "tensor([1., 0.]) tensor([0.5999, 0.4001], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 8 - 20: cat - cat || Loss: 0.7127786874771118\n",
      "tensor([1., 0.]) tensor([0.6005, 0.3995], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 8 - 21: cat - cat || Loss: 0.7121284008026123\n",
      "tensor([1., 0.]) tensor([0.6011, 0.3989], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 8 - 22: cat - cat || Loss: 0.7114599943161011\n",
      "tensor([1., 0.]) tensor([0.6018, 0.3982], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 8 - 23: cat - cat || Loss: 0.7107754945755005\n",
      "tensor([1., 0.]) tensor([0.6025, 0.3975], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 8 - 24: cat - cat || Loss: 0.7100764513015747\n",
      "tensor([1., 0.]) tensor([0.6032, 0.3968], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 8 - 25: cat - cat || Loss: 0.7093644738197327\n",
      "tensor([1., 0.]) tensor([0.6039, 0.3961], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 8 - 26: cat - cat || Loss: 0.7086407542228699\n",
      "tensor([1., 0.]) tensor([0.6046, 0.3954], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 8 - 27: cat - cat || Loss: 0.7079066038131714\n",
      "tensor([1., 0.]) tensor([0.6054, 0.3946], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 8 - 28: cat - cat || Loss: 0.7071629762649536\n",
      "tensor([1., 0.]) tensor([0.6061, 0.3939], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 8 - 29: cat - cat || Loss: 0.7064109444618225\n",
      "tensor([1., 0.]) tensor([0.6069, 0.3931], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 8 - 30: cat - cat || Loss: 0.7056515216827393\n",
      "tensor([1., 0.]) tensor([0.6076, 0.3924], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 8 - 31: cat - cat || Loss: 0.7048852443695068\n",
      "tensor([1., 0.]) tensor([0.6084, 0.3916], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 8 - 32: cat - cat || Loss: 0.7041128873825073\n",
      "tensor([1., 0.]) tensor([0.6091, 0.3909], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 8 - 33: cat - cat || Loss: 0.7033354043960571\n",
      "tensor([1., 0.]) tensor([0.6099, 0.3901], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 8 - 34: cat - cat || Loss: 0.7025530338287354\n",
      "tensor([1., 0.]) tensor([0.6107, 0.3893], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 8 - 35: cat - cat || Loss: 0.7017661333084106\n",
      "tensor([1., 0.]) tensor([0.6115, 0.3885], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 8 - 36: cat - cat || Loss: 0.7009756565093994\n",
      "tensor([1., 0.]) tensor([0.6123, 0.3877], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 8 - 37: cat - cat || Loss: 0.7001818418502808\n",
      "tensor([1., 0.]) tensor([0.6131, 0.3869], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 8 - 38: cat - cat || Loss: 0.6993849277496338\n",
      "tensor([1., 0.]) tensor([0.6139, 0.3861], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 8 - 39: cat - cat || Loss: 0.6985853910446167\n",
      "tensor([1., 0.]) tensor([0.6147, 0.3853], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 8 - 40: cat - cat || Loss: 0.6977837681770325\n",
      "tensor([1., 0.]) tensor([0.6155, 0.3845], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 8 - 41: cat - cat || Loss: 0.696979820728302\n",
      "tensor([1., 0.]) tensor([0.6163, 0.3837], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 8 - 42: cat - cat || Loss: 0.696174144744873\n",
      "tensor([1., 0.]) tensor([0.6171, 0.3829], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 8 - 43: cat - cat || Loss: 0.6953667402267456\n",
      "tensor([1., 0.]) tensor([0.6179, 0.3821], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 8 - 44: cat - cat || Loss: 0.6945581436157227\n",
      "tensor([1., 0.]) tensor([0.6187, 0.3813], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 8 - 45: cat - cat || Loss: 0.6937481760978699\n",
      "tensor([1., 0.]) tensor([0.6195, 0.3805], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 8 - 46: cat - cat || Loss: 0.6929371356964111\n",
      "tensor([1., 0.]) tensor([0.6203, 0.3797], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 8 - 47: cat - cat || Loss: 0.6921253204345703\n",
      "tensor([1., 0.]) tensor([0.6211, 0.3789], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 8 - 48: cat - cat || Loss: 0.6913127899169922\n",
      "tensor([1., 0.]) tensor([0.6219, 0.3781], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 8 - 49: cat - cat || Loss: 0.6904995441436768\n",
      "tensor([1., 0.]) tensor([0.6228, 0.3772], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 8 - 50: cat - cat || Loss: 0.6896859407424927\n",
      "tensor([1., 0.]) tensor([0.6236, 0.3764], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 8 - 51: cat - cat || Loss: 0.6888718605041504\n",
      "tensor([1., 0.]) tensor([0.6244, 0.3756], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 8 - 52: cat - cat || Loss: 0.6880574226379395\n",
      "tensor([1., 0.]) tensor([0.6252, 0.3748], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 8 - 53: cat - cat || Loss: 0.6872427463531494\n",
      "tensor([1., 0.]) tensor([0.6260, 0.3740], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 8 - 54: cat - cat || Loss: 0.6864279508590698\n",
      "tensor([1., 0.]) tensor([0.6268, 0.3732], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 8 - 55: cat - cat || Loss: 0.6856130957603455\n",
      "tensor([1., 0.]) tensor([0.6276, 0.3724], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 8 - 56: cat - cat || Loss: 0.6847981214523315\n",
      "tensor([1., 0.]) tensor([0.6285, 0.3715], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 8 - 57: cat - cat || Loss: 0.6839832663536072\n",
      "tensor([1., 0.]) tensor([0.6293, 0.3707], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 8 - 58: cat - cat || Loss: 0.6831685900688171\n",
      "tensor([1., 0.]) tensor([0.6301, 0.3699], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 8 - 59: cat - cat || Loss: 0.6823540925979614\n",
      "tensor([1., 0.]) tensor([0.6309, 0.3691], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 8 - 60: cat - cat || Loss: 0.6815395951271057\n",
      "tensor([1., 0.]) tensor([0.6317, 0.3683], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 8 - 61: cat - cat || Loss: 0.6807253360748291\n",
      "tensor([1., 0.]) tensor([0.6325, 0.3675], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 8 - 62: cat - cat || Loss: 0.6799112558364868\n",
      "tensor([1., 0.]) tensor([0.6334, 0.3666], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 8 - 63: cat - cat || Loss: 0.6790974736213684\n",
      "tensor([1., 0.]) tensor([0.6342, 0.3658], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 8 - 64: cat - cat || Loss: 0.6782839298248291\n",
      "tensor([1., 0.]) tensor([0.6350, 0.3650], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 8 - 65: cat - cat || Loss: 0.6774706244468689\n",
      "tensor([1., 0.]) tensor([0.6358, 0.3642], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 8 - 66: cat - cat || Loss: 0.6766577363014221\n",
      "tensor([1., 0.]) tensor([0.6366, 0.3634], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 8 - 67: cat - cat || Loss: 0.6758452653884888\n",
      "tensor([1., 0.]) tensor([0.6374, 0.3626], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 8 - 68: cat - cat || Loss: 0.6750329732894897\n",
      "tensor([1., 0.]) tensor([0.6382, 0.3618], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 8 - 69: cat - cat || Loss: 0.6742210388183594\n",
      "tensor([1., 0.]) tensor([0.6390, 0.3610], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 8 - 70: cat - cat || Loss: 0.673409640789032\n",
      "tensor([1., 0.]) tensor([0.6399, 0.3601], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 8 - 71: cat - cat || Loss: 0.672598659992218\n",
      "tensor([1., 0.]) tensor([0.6407, 0.3593], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 8 - 72: cat - cat || Loss: 0.6717879772186279\n",
      "tensor([1., 0.]) tensor([0.6415, 0.3585], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 8 - 73: cat - cat || Loss: 0.670977771282196\n",
      "tensor([1., 0.]) tensor([0.6423, 0.3577], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 8 - 74: cat - cat || Loss: 0.6701679825782776\n",
      "tensor([1., 0.]) tensor([0.6431, 0.3569], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 8 - 75: cat - cat || Loss: 0.6693587303161621\n",
      "tensor([1., 0.]) tensor([0.6439, 0.3561], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 8 - 76: cat - cat || Loss: 0.6685498952865601\n",
      "tensor([1., 0.]) tensor([0.6447, 0.3553], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 8 - 77: cat - cat || Loss: 0.667741596698761\n",
      "tensor([1., 0.]) tensor([0.6455, 0.3545], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 8 - 78: cat - cat || Loss: 0.6669336557388306\n",
      "tensor([1., 0.]) tensor([0.6463, 0.3537], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 8 - 79: cat - cat || Loss: 0.6661263108253479\n",
      "tensor([1., 0.]) tensor([0.6471, 0.3529], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 8 - 80: cat - cat || Loss: 0.6653193831443787\n",
      "tensor([1., 0.]) tensor([0.6479, 0.3521], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 8 - 81: cat - cat || Loss: 0.6645128726959229\n",
      "tensor([1., 0.]) tensor([0.6487, 0.3513], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 8 - 82: cat - cat || Loss: 0.6637068390846252\n",
      "tensor([1., 0.]) tensor([0.6496, 0.3504], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 8 - 83: cat - cat || Loss: 0.6629015207290649\n",
      "tensor([1., 0.]) tensor([0.6504, 0.3496], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 8 - 84: cat - cat || Loss: 0.6620965600013733\n",
      "tensor([1., 0.]) tensor([0.6512, 0.3488], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 8 - 85: cat - cat || Loss: 0.6612920761108398\n",
      "tensor([1., 0.]) tensor([0.6520, 0.3480], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 8 - 86: cat - cat || Loss: 0.6604883074760437\n",
      "tensor([1., 0.]) tensor([0.6528, 0.3472], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 8 - 87: cat - cat || Loss: 0.659684956073761\n",
      "tensor([1., 0.]) tensor([0.6536, 0.3464], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 8 - 88: cat - cat || Loss: 0.6588820219039917\n",
      "tensor([1., 0.]) tensor([0.6544, 0.3456], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 8 - 89: cat - cat || Loss: 0.6580797433853149\n",
      "tensor([1., 0.]) tensor([0.6552, 0.3448], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 8 - 90: cat - cat || Loss: 0.6572779417037964\n",
      "tensor([1., 0.]) tensor([0.6560, 0.3440], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 8 - 91: cat - cat || Loss: 0.6564764976501465\n",
      "tensor([1., 0.]) tensor([0.6568, 0.3432], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 8 - 92: cat - cat || Loss: 0.6556757688522339\n",
      "tensor([1., 0.]) tensor([0.6576, 0.3424], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 8 - 93: cat - cat || Loss: 0.6548755764961243\n",
      "tensor([1., 0.]) tensor([0.6584, 0.3416], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 8 - 94: cat - cat || Loss: 0.6540759801864624\n",
      "tensor([1., 0.]) tensor([0.6592, 0.3408], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 8 - 95: cat - cat || Loss: 0.6532767415046692\n",
      "tensor([1., 0.]) tensor([0.6600, 0.3400], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 8 - 96: cat - cat || Loss: 0.6524782180786133\n",
      "tensor([1., 0.]) tensor([0.6608, 0.3392], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 8 - 97: cat - cat || Loss: 0.6516801714897156\n",
      "tensor([1., 0.]) tensor([0.6616, 0.3384], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 8 - 98: cat - cat || Loss: 0.6508827209472656\n",
      "tensor([1., 0.]) tensor([0.6624, 0.3376], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 8 - 99: cat - cat || Loss: 0.6500859260559082\n",
      "tensor([1., 0.]) tensor([0.6632, 0.3368], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 8 - 100: cat - cat || Loss: 0.649289608001709\n",
      "tensor([1., 0.]) tensor([0.6640, 0.3360], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 8 - 101: cat - cat || Loss: 0.6484938859939575\n",
      "tensor([1., 0.]) tensor([0.6648, 0.3352], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 8 - 102: cat - cat || Loss: 0.6476987600326538\n",
      "tensor([1., 0.]) tensor([0.6656, 0.3344], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 8 - 103: cat - cat || Loss: 0.6469041109085083\n",
      "tensor([1., 0.]) tensor([0.6664, 0.3336], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 8 - 104: cat - cat || Loss: 0.6461102962493896\n",
      "tensor([1., 0.]) tensor([0.6672, 0.3328], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 8 - 105: cat - cat || Loss: 0.6453168988227844\n",
      "tensor([1., 0.]) tensor([0.6679, 0.3321], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 8 - 106: cat - cat || Loss: 0.6445242166519165\n",
      "tensor([1., 0.]) tensor([0.6687, 0.3313], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 8 - 107: cat - cat || Loss: 0.6437320709228516\n",
      "tensor([1., 0.]) tensor([0.6695, 0.3305], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 8 - 108: cat - cat || Loss: 0.6429404616355896\n",
      "tensor([1., 0.]) tensor([0.6703, 0.3297], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 8 - 109: cat - cat || Loss: 0.6421495079994202\n",
      "tensor([1., 0.]) tensor([0.6711, 0.3289], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 8 - 110: cat - cat || Loss: 0.6413589715957642\n",
      "tensor([1., 0.]) tensor([0.6719, 0.3281], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 8 - 111: cat - cat || Loss: 0.640569269657135\n",
      "tensor([1., 0.]) tensor([0.6727, 0.3273], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 8 - 112: cat - cat || Loss: 0.6397799849510193\n",
      "tensor([1., 0.]) tensor([0.6735, 0.3265], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 8 - 113: cat - cat || Loss: 0.6389913558959961\n",
      "tensor([1., 0.]) tensor([0.6743, 0.3257], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 8 - 114: cat - cat || Loss: 0.6382033228874207\n",
      "tensor([1., 0.]) tensor([0.6751, 0.3249], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 8 - 115: cat - cat || Loss: 0.6374159455299377\n",
      "tensor([1., 0.]) tensor([0.6758, 0.3242], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 8 - 116: cat - cat || Loss: 0.6366289854049683\n",
      "tensor([1., 0.]) tensor([0.6766, 0.3234], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 8 - 117: cat - cat || Loss: 0.6358428001403809\n",
      "tensor([1., 0.]) tensor([0.6774, 0.3226], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 8 - 118: cat - cat || Loss: 0.6350572109222412\n",
      "tensor([1., 0.]) tensor([0.6782, 0.3218], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 8 - 119: cat - cat || Loss: 0.6342722773551941\n",
      "tensor([1., 0.]) tensor([0.6790, 0.3210], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 8 - 120: cat - cat || Loss: 0.6334878206253052\n",
      "tensor([1., 0.]) tensor([0.6798, 0.3202], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 8 - 121: cat - cat || Loss: 0.6327040791511536\n",
      "tensor([1., 0.]) tensor([0.6806, 0.3194], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 8 - 122: cat - cat || Loss: 0.6319209933280945\n",
      "tensor([1., 0.]) tensor([0.6813, 0.3187], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 8 - 123: cat - cat || Loss: 0.6311385035514832\n",
      "tensor([1., 0.]) tensor([0.6821, 0.3179], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 8 - 124: cat - cat || Loss: 0.6303567886352539\n",
      "tensor([1., 0.]) tensor([0.6829, 0.3171], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 8 - 125: cat - cat || Loss: 0.6295757293701172\n",
      "tensor([1., 0.]) tensor([0.6837, 0.3163], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 8 - 126: cat - cat || Loss: 0.6287951469421387\n",
      "tensor([1., 0.]) tensor([0.6845, 0.3155], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 8 - 127: cat - cat || Loss: 0.6280151605606079\n",
      "tensor([1., 0.]) tensor([0.6852, 0.3148], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 8 - 128: cat - cat || Loss: 0.6272360682487488\n",
      "tensor([1., 0.]) tensor([0.6860, 0.3140], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 8 - 129: cat - cat || Loss: 0.6264574527740479\n",
      "tensor([1., 0.]) tensor([0.6868, 0.3132], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 8 - 130: cat - cat || Loss: 0.6256794929504395\n",
      "tensor([1., 0.]) tensor([0.6876, 0.3124], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 8 - 131: cat - cat || Loss: 0.6249022483825684\n",
      "tensor([1., 0.]) tensor([0.6884, 0.3116], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 8 - 132: cat - cat || Loss: 0.6241256594657898\n",
      "tensor([1., 0.]) tensor([0.6891, 0.3109], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 8 - 133: cat - cat || Loss: 0.6233497262001038\n",
      "tensor([1., 0.]) tensor([0.6899, 0.3101], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 8 - 134: cat - cat || Loss: 0.6225744485855103\n",
      "tensor([1., 0.]) tensor([0.6907, 0.3093], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 8 - 135: cat - cat || Loss: 0.621799886226654\n",
      "tensor([1., 0.]) tensor([0.6915, 0.3085], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 8 - 136: cat - cat || Loss: 0.6210260391235352\n",
      "tensor([1., 0.]) tensor([0.6922, 0.3078], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 8 - 137: cat - cat || Loss: 0.6202527284622192\n",
      "tensor([1., 0.]) tensor([0.6930, 0.3070], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 8 - 138: cat - cat || Loss: 0.6194801926612854\n",
      "tensor([1., 0.]) tensor([0.6938, 0.3062], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 8 - 139: cat - cat || Loss: 0.6187082529067993\n",
      "tensor([1., 0.]) tensor([0.6946, 0.3054], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 8 - 140: cat - cat || Loss: 0.6179370284080505\n",
      "tensor([1., 0.]) tensor([0.6953, 0.3047], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 8 - 141: cat - cat || Loss: 0.6171666979789734\n",
      "tensor([1., 0.]) tensor([0.6961, 0.3039], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 8 - 142: cat - cat || Loss: 0.6163969039916992\n",
      "tensor([1., 0.]) tensor([0.6969, 0.3031], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 8 - 143: cat - cat || Loss: 0.6156280040740967\n",
      "tensor([1., 0.]) tensor([0.6976, 0.3024], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 8 - 144: cat - cat || Loss: 0.6148597598075867\n",
      "tensor([1., 0.]) tensor([0.6984, 0.3016], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 8 - 145: cat - cat || Loss: 0.6140919923782349\n",
      "tensor([1., 0.]) tensor([0.6992, 0.3008], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 8 - 146: cat - cat || Loss: 0.6133251786231995\n",
      "tensor([1., 0.]) tensor([0.6999, 0.3001], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 8 - 147: cat - cat || Loss: 0.6125589609146118\n",
      "tensor([1., 0.]) tensor([0.7007, 0.2993], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 8 - 148: cat - cat || Loss: 0.6117934584617615\n",
      "tensor([1., 0.]) tensor([0.7015, 0.2985], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 8 - 149: cat - cat || Loss: 0.6110286116600037\n",
      "tensor([1., 0.]) tensor([0.7022, 0.2978], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 8 - 150: cat - cat || Loss: 0.6102643013000488\n",
      "tensor([1., 0.]) tensor([0.7030, 0.2970], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 8 - 151: cat - cat || Loss: 0.6095008850097656\n",
      "tensor([1., 0.]) tensor([0.7038, 0.2962], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 8 - 152: cat - cat || Loss: 0.6087381839752197\n",
      "tensor([1., 0.]) tensor([0.7045, 0.2955], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 8 - 153: cat - cat || Loss: 0.6079760789871216\n",
      "tensor([1., 0.]) tensor([0.7053, 0.2947], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 8 - 154: cat - cat || Loss: 0.6072146892547607\n",
      "tensor([1., 0.]) tensor([0.7060, 0.2940], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 8 - 155: cat - cat || Loss: 0.606454074382782\n",
      "tensor([1., 0.]) tensor([0.7068, 0.2932], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 8 - 156: cat - cat || Loss: 0.6056941747665405\n",
      "tensor([1., 0.]) tensor([0.7076, 0.2924], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 8 - 157: cat - cat || Loss: 0.6049351096153259\n",
      "tensor([1., 0.]) tensor([0.7083, 0.2917], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 8 - 158: cat - cat || Loss: 0.6041765809059143\n",
      "tensor([1., 0.]) tensor([0.7091, 0.2909], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 8 - 159: cat - cat || Loss: 0.6034188270568848\n",
      "tensor([1., 0.]) tensor([0.7098, 0.2902], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 8 - 160: cat - cat || Loss: 0.6026618480682373\n",
      "tensor([1., 0.]) tensor([0.7106, 0.2894], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 8 - 161: cat - cat || Loss: 0.6019056439399719\n",
      "tensor([1., 0.]) tensor([0.7114, 0.2886], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 8 - 162: cat - cat || Loss: 0.6011502146720886\n",
      "tensor([1., 0.]) tensor([0.7121, 0.2879], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 8 - 163: cat - cat || Loss: 0.6003953218460083\n",
      "tensor([1., 0.]) tensor([0.7129, 0.2871], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 8 - 164: cat - cat || Loss: 0.5996413230895996\n",
      "tensor([1., 0.]) tensor([0.7136, 0.2864], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 8 - 165: cat - cat || Loss: 0.5988881587982178\n",
      "tensor([1., 0.]) tensor([0.7144, 0.2856], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 8 - 166: cat - cat || Loss: 0.5981355905532837\n",
      "tensor([1., 0.]) tensor([0.7151, 0.2849], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 8 - 167: cat - cat || Loss: 0.5973837375640869\n",
      "tensor([1., 0.]) tensor([0.7159, 0.2841], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 8 - 168: cat - cat || Loss: 0.596632719039917\n",
      "tensor([1., 0.]) tensor([0.7166, 0.2834], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 8 - 169: cat - cat || Loss: 0.5958824157714844\n",
      "tensor([1., 0.]) tensor([0.7174, 0.2826], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 8 - 170: cat - cat || Loss: 0.5951329469680786\n",
      "tensor([1., 0.]) tensor([0.7181, 0.2819], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 8 - 171: cat - cat || Loss: 0.5943841934204102\n",
      "tensor([1., 0.]) tensor([0.7189, 0.2811], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 8 - 172: cat - cat || Loss: 0.5936362743377686\n",
      "tensor([1., 0.]) tensor([0.7196, 0.2804], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 8 - 173: cat - cat || Loss: 0.592889130115509\n",
      "tensor([1., 0.]) tensor([0.7204, 0.2796], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 8 - 174: cat - cat || Loss: 0.5921427607536316\n",
      "tensor([1., 0.]) tensor([0.7211, 0.2789], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 8 - 175: cat - cat || Loss: 0.5913971662521362\n",
      "tensor([1., 0.]) tensor([0.7219, 0.2781], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 8 - 176: cat - cat || Loss: 0.590652346611023\n",
      "tensor([1., 0.]) tensor([0.7226, 0.2774], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 8 - 177: cat - cat || Loss: 0.5899084210395813\n",
      "tensor([1., 0.]) tensor([0.7234, 0.2766], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 8 - 178: cat - cat || Loss: 0.5891651511192322\n",
      "tensor([1., 0.]) tensor([0.7241, 0.2759], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 8 - 179: cat - cat || Loss: 0.588422954082489\n",
      "tensor([1., 0.]) tensor([0.7248, 0.2752], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 8 - 180: cat - cat || Loss: 0.587681233882904\n",
      "tensor([1., 0.]) tensor([0.7256, 0.2744], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 8 - 181: cat - cat || Loss: 0.586940586566925\n",
      "tensor([1., 0.]) tensor([0.7263, 0.2737], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 8 - 182: cat - cat || Loss: 0.5862006545066833\n",
      "tensor([1., 0.]) tensor([0.7271, 0.2729], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 8 - 183: cat - cat || Loss: 0.5854616165161133\n",
      "tensor([1., 0.]) tensor([0.7278, 0.2722], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 8 - 184: cat - cat || Loss: 0.5847232341766357\n",
      "tensor([1., 0.]) tensor([0.7285, 0.2715], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 8 - 185: cat - cat || Loss: 0.5839858055114746\n",
      "tensor([1., 0.]) tensor([0.7293, 0.2707], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 8 - 186: cat - cat || Loss: 0.5832489728927612\n",
      "tensor([1., 0.]) tensor([0.7300, 0.2700], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 8 - 187: cat - cat || Loss: 0.5825130939483643\n",
      "tensor([1., 0.]) tensor([0.7307, 0.2693], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 8 - 188: cat - cat || Loss: 0.5817779898643494\n",
      "tensor([1., 0.]) tensor([0.7315, 0.2685], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 8 - 189: cat - cat || Loss: 0.5810437202453613\n",
      "tensor([1., 0.]) tensor([0.7322, 0.2678], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 8 - 190: dog - cat || Loss: 1.0462132692337036\n",
      "tensor([0., 1.]) tensor([0.7330, 0.2670], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 8 - 191: dog - cat || Loss: 1.0468000173568726\n",
      "tensor([0., 1.]) tensor([0.7335, 0.2665], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 8 - 192: dog - cat || Loss: 1.047255039215088\n",
      "tensor([0., 1.]) tensor([0.7340, 0.2660], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 8 - 193: dog - cat || Loss: 1.0475915670394897\n",
      "tensor([0., 1.]) tensor([0.7343, 0.2657], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 8 - 194: dog - cat || Loss: 1.0478215217590332\n",
      "tensor([0., 1.]) tensor([0.7346, 0.2654], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 8 - 195: dog - cat || Loss: 1.047955870628357\n",
      "tensor([0., 1.]) tensor([0.7347, 0.2653], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 8 - 196: dog - cat || Loss: 1.048003911972046\n",
      "tensor([0., 1.]) tensor([0.7347, 0.2653], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 8 - 197: dog - cat || Loss: 1.0479744672775269\n",
      "tensor([0., 1.]) tensor([0.7347, 0.2653], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 8 - 198: dog - cat || Loss: 1.0478750467300415\n",
      "tensor([0., 1.]) tensor([0.7346, 0.2654], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 8 - 199: dog - cat || Loss: 1.047713041305542\n",
      "tensor([0., 1.]) tensor([0.7345, 0.2655], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 8 - 200: dog - cat || Loss: 1.0474942922592163\n",
      "tensor([0., 1.]) tensor([0.7342, 0.2658], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 8 - 201: dog - cat || Loss: 1.047224521636963\n",
      "tensor([0., 1.]) tensor([0.7340, 0.2660], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 8 - 202: dog - cat || Loss: 1.0469090938568115\n",
      "tensor([0., 1.]) tensor([0.7336, 0.2664], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 8 - 203: dog - cat || Loss: 1.046552062034607\n",
      "tensor([0., 1.]) tensor([0.7333, 0.2667], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 8 - 204: dog - cat || Loss: 1.0461578369140625\n",
      "tensor([0., 1.]) tensor([0.7329, 0.2671], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 8 - 205: dog - cat || Loss: 1.0457297563552856\n",
      "tensor([0., 1.]) tensor([0.7325, 0.2675], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 8 - 206: dog - cat || Loss: 1.045271635055542\n",
      "tensor([0., 1.]) tensor([0.7320, 0.2680], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 8 - 207: dog - cat || Loss: 1.0447862148284912\n",
      "tensor([0., 1.]) tensor([0.7315, 0.2685], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 8 - 208: dog - cat || Loss: 1.0442758798599243\n",
      "tensor([0., 1.]) tensor([0.7310, 0.2690], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 8 - 209: dog - cat || Loss: 1.0437434911727905\n",
      "tensor([0., 1.]) tensor([0.7305, 0.2695], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 8 - 210: dog - cat || Loss: 1.0431909561157227\n",
      "tensor([0., 1.]) tensor([0.7299, 0.2701], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 8 - 211: dog - cat || Loss: 1.0426201820373535\n",
      "tensor([0., 1.]) tensor([0.7294, 0.2706], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 8 - 212: dog - cat || Loss: 1.0420329570770264\n",
      "tensor([0., 1.]) tensor([0.7288, 0.2712], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 8 - 213: dog - cat || Loss: 1.041430950164795\n",
      "tensor([0., 1.]) tensor([0.7282, 0.2718], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 8 - 214: dog - cat || Loss: 1.0408154726028442\n",
      "tensor([0., 1.]) tensor([0.7276, 0.2724], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 8 - 215: dog - cat || Loss: 1.0401877164840698\n",
      "tensor([0., 1.]) tensor([0.7269, 0.2731], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 8 - 216: dog - cat || Loss: 1.0395491123199463\n",
      "tensor([0., 1.]) tensor([0.7263, 0.2737], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 8 - 217: dog - cat || Loss: 1.0389002561569214\n",
      "tensor([0., 1.]) tensor([0.7256, 0.2744], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 8 - 218: dog - cat || Loss: 1.0382424592971802\n",
      "tensor([0., 1.]) tensor([0.7250, 0.2750], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 8 - 219: dog - cat || Loss: 1.03757643699646\n",
      "tensor([0., 1.]) tensor([0.7243, 0.2757], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 8 - 220: dog - cat || Loss: 1.036902904510498\n",
      "tensor([0., 1.]) tensor([0.7236, 0.2764], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 8 - 221: dog - cat || Loss: 1.0362224578857422\n",
      "tensor([0., 1.]) tensor([0.7230, 0.2770], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 8 - 222: dog - cat || Loss: 1.0355358123779297\n",
      "tensor([0., 1.]) tensor([0.7223, 0.2777], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 8 - 223: dog - cat || Loss: 1.0348435640335083\n",
      "tensor([0., 1.]) tensor([0.7216, 0.2784], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 8 - 224: dog - cat || Loss: 1.0341460704803467\n",
      "tensor([0., 1.]) tensor([0.7209, 0.2791], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 8 - 225: dog - cat || Loss: 1.0334439277648926\n",
      "tensor([0., 1.]) tensor([0.7202, 0.2798], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 8 - 226: dog - cat || Loss: 1.0327376127243042\n",
      "tensor([0., 1.]) tensor([0.7195, 0.2805], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 8 - 227: dog - cat || Loss: 1.032027244567871\n",
      "tensor([0., 1.]) tensor([0.7188, 0.2812], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 8 - 228: dog - cat || Loss: 1.0313129425048828\n",
      "tensor([0., 1.]) tensor([0.7181, 0.2819], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 8 - 229: dog - cat || Loss: 1.0305957794189453\n",
      "tensor([0., 1.]) tensor([0.7173, 0.2827], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 8 - 230: dog - cat || Loss: 1.0298752784729004\n",
      "tensor([0., 1.]) tensor([0.7166, 0.2834], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 8 - 231: dog - cat || Loss: 1.0291520357131958\n",
      "tensor([0., 1.]) tensor([0.7159, 0.2841], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 8 - 232: dog - cat || Loss: 1.028426170349121\n",
      "tensor([0., 1.]) tensor([0.7152, 0.2848], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 8 - 233: dog - cat || Loss: 1.0276978015899658\n",
      "tensor([0., 1.]) tensor([0.7144, 0.2856], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 8 - 234: dog - cat || Loss: 1.0269672870635986\n",
      "tensor([0., 1.]) tensor([0.7137, 0.2863], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 8 - 235: dog - cat || Loss: 1.026234745979309\n",
      "tensor([0., 1.]) tensor([0.7130, 0.2870], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 8 - 236: dog - cat || Loss: 1.025499939918518\n",
      "tensor([0., 1.]) tensor([0.7122, 0.2878], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 8 - 237: dog - cat || Loss: 1.024763584136963\n",
      "tensor([0., 1.]) tensor([0.7115, 0.2885], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 8 - 238: dog - cat || Loss: 1.0240254402160645\n",
      "tensor([0., 1.]) tensor([0.7108, 0.2892], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 8 - 239: dog - cat || Loss: 1.0232858657836914\n",
      "tensor([0., 1.]) tensor([0.7100, 0.2900], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 8 - 240: dog - cat || Loss: 1.022544503211975\n",
      "tensor([0., 1.]) tensor([0.7093, 0.2907], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 8 - 241: dog - cat || Loss: 1.0218018293380737\n",
      "tensor([0., 1.]) tensor([0.7085, 0.2915], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 8 - 242: dog - cat || Loss: 1.0210579633712769\n",
      "tensor([0., 1.]) tensor([0.7078, 0.2922], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 8 - 243: dog - cat || Loss: 1.0203125476837158\n",
      "tensor([0., 1.]) tensor([0.7071, 0.2929], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 8 - 244: dog - cat || Loss: 1.0195664167404175\n",
      "tensor([0., 1.]) tensor([0.7063, 0.2937], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 8 - 245: dog - cat || Loss: 1.018818974494934\n",
      "tensor([0., 1.]) tensor([0.7056, 0.2944], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 8 - 246: dog - cat || Loss: 1.0180702209472656\n",
      "tensor([0., 1.]) tensor([0.7048, 0.2952], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 8 - 247: dog - cat || Loss: 1.0173205137252808\n",
      "tensor([0., 1.]) tensor([0.7041, 0.2959], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 8 - 248: dog - cat || Loss: 1.016569972038269\n",
      "tensor([0., 1.]) tensor([0.7033, 0.2967], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 8 - 249: dog - cat || Loss: 1.0158179998397827\n",
      "tensor([0., 1.]) tensor([0.7026, 0.2974], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 8 - 250: dog - cat || Loss: 1.0150655508041382\n",
      "tensor([0., 1.]) tensor([0.7018, 0.2982], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 8 - 251: dog - cat || Loss: 1.0143119096755981\n",
      "tensor([0., 1.]) tensor([0.7011, 0.2989], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 8 - 252: dog - cat || Loss: 1.0135575532913208\n",
      "tensor([0., 1.]) tensor([0.7003, 0.2997], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 8 - 253: dog - cat || Loss: 1.012802004814148\n",
      "tensor([0., 1.]) tensor([0.6995, 0.3005], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 8 - 254: dog - cat || Loss: 1.0120458602905273\n",
      "tensor([0., 1.]) tensor([0.6988, 0.3012], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 8 - 255: dog - cat || Loss: 1.0112888813018799\n",
      "tensor([0., 1.]) tensor([0.6980, 0.3020], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 8 - 256: dog - cat || Loss: 1.0105310678482056\n",
      "tensor([0., 1.]) tensor([0.6973, 0.3027], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 8 - 257: dog - cat || Loss: 1.0097723007202148\n",
      "tensor([0., 1.]) tensor([0.6965, 0.3035], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 8 - 258: dog - cat || Loss: 1.0090129375457764\n",
      "tensor([0., 1.]) tensor([0.6958, 0.3042], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 8 - 259: dog - cat || Loss: 1.0082529783248901\n",
      "tensor([0., 1.]) tensor([0.6950, 0.3050], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 8 - 260: dog - cat || Loss: 1.007491946220398\n",
      "tensor([0., 1.]) tensor([0.6942, 0.3058], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 8 - 261: dog - cat || Loss: 1.0067306756973267\n",
      "tensor([0., 1.]) tensor([0.6935, 0.3065], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 8 - 262: dog - cat || Loss: 1.005968451499939\n",
      "tensor([0., 1.]) tensor([0.6927, 0.3073], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 8 - 263: dog - cat || Loss: 1.0052052736282349\n",
      "tensor([0., 1.]) tensor([0.6919, 0.3081], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 8 - 264: dog - cat || Loss: 1.0044416189193726\n",
      "tensor([0., 1.]) tensor([0.6912, 0.3088], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 8 - 265: dog - cat || Loss: 1.0036771297454834\n",
      "tensor([0., 1.]) tensor([0.6904, 0.3096], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 8 - 266: dog - cat || Loss: 1.0029120445251465\n",
      "tensor([0., 1.]) tensor([0.6897, 0.3103], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 8 - 267: dog - cat || Loss: 1.0021464824676514\n",
      "tensor([0., 1.]) tensor([0.6889, 0.3111], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 8 - 268: dog - cat || Loss: 1.0013798475265503\n",
      "tensor([0., 1.]) tensor([0.6881, 0.3119], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 8 - 269: dog - cat || Loss: 1.0006128549575806\n",
      "tensor([0., 1.]) tensor([0.6874, 0.3126], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 8 - 270: dog - cat || Loss: 0.9998450875282288\n",
      "tensor([0., 1.]) tensor([0.6866, 0.3134], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 8 - 271: dog - cat || Loss: 0.9990766644477844\n",
      "tensor([0., 1.]) tensor([0.6858, 0.3142], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 8 - 272: dog - cat || Loss: 0.9983076453208923\n",
      "tensor([0., 1.]) tensor([0.6850, 0.3150], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 8 - 273: dog - cat || Loss: 0.9975380897521973\n",
      "tensor([0., 1.]) tensor([0.6843, 0.3157], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 8 - 274: dog - cat || Loss: 0.9967676401138306\n",
      "tensor([0., 1.]) tensor([0.6835, 0.3165], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 8 - 275: dog - cat || Loss: 0.9959967732429504\n",
      "tensor([0., 1.]) tensor([0.6827, 0.3173], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 8 - 276: dog - cat || Loss: 0.9952253103256226\n",
      "tensor([0., 1.]) tensor([0.6820, 0.3180], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 8 - 277: dog - cat || Loss: 0.9944531917572021\n",
      "tensor([0., 1.]) tensor([0.6812, 0.3188], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 8 - 278: dog - cat || Loss: 0.9936804175376892\n",
      "tensor([0., 1.]) tensor([0.6804, 0.3196], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 8 - 279: dog - cat || Loss: 0.9929070472717285\n",
      "tensor([0., 1.]) tensor([0.6796, 0.3204], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 8 - 280: dog - cat || Loss: 0.9921330213546753\n",
      "tensor([0., 1.]) tensor([0.6789, 0.3211], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 8 - 281: dog - cat || Loss: 0.9913583993911743\n",
      "tensor([0., 1.]) tensor([0.6781, 0.3219], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 8 - 282: dog - cat || Loss: 0.9905833601951599\n",
      "tensor([0., 1.]) tensor([0.6773, 0.3227], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 8 - 283: dog - cat || Loss: 0.9898076057434082\n",
      "tensor([0., 1.]) tensor([0.6765, 0.3235], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 8 - 284: dog - cat || Loss: 0.9890313148498535\n",
      "tensor([0., 1.]) tensor([0.6758, 0.3242], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 8 - 285: dog - cat || Loss: 0.9882544279098511\n",
      "tensor([0., 1.]) tensor([0.6750, 0.3250], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 8 - 286: dog - cat || Loss: 0.9874770045280457\n",
      "tensor([0., 1.]) tensor([0.6742, 0.3258], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 8 - 287: dog - cat || Loss: 0.9866988658905029\n",
      "tensor([0., 1.]) tensor([0.6734, 0.3266], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 8 - 288: dog - cat || Loss: 0.9859203696250916\n",
      "tensor([0., 1.]) tensor([0.6727, 0.3273], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 8 - 289: dog - cat || Loss: 0.9851411581039429\n",
      "tensor([0., 1.]) tensor([0.6719, 0.3281], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 8 - 290: dog - cat || Loss: 0.984361469745636\n",
      "tensor([0., 1.]) tensor([0.6711, 0.3289], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 8 - 291: dog - cat || Loss: 0.9835813045501709\n",
      "tensor([0., 1.]) tensor([0.6703, 0.3297], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 8 - 292: dog - cat || Loss: 0.9828004240989685\n",
      "tensor([0., 1.]) tensor([0.6695, 0.3305], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 8 - 293: dog - cat || Loss: 0.9820190072059631\n",
      "tensor([0., 1.]) tensor([0.6688, 0.3312], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 8 - 294: dog - cat || Loss: 0.9812370538711548\n",
      "tensor([0., 1.]) tensor([0.6680, 0.3320], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 8 - 295: dog - cat || Loss: 0.9804547429084778\n",
      "tensor([0., 1.]) tensor([0.6672, 0.3328], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 8 - 296: dog - cat || Loss: 0.9796715974807739\n",
      "tensor([0., 1.]) tensor([0.6664, 0.3336], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 8 - 297: dog - cat || Loss: 0.9788880944252014\n",
      "tensor([0., 1.]) tensor([0.6656, 0.3344], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 8 - 298: dog - cat || Loss: 0.9781039357185364\n",
      "tensor([0., 1.]) tensor([0.6648, 0.3352], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 8 - 299: dog - cat || Loss: 0.9773193597793579\n",
      "tensor([0., 1.]) tensor([0.6641, 0.3359], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 8 - 300: dog - cat || Loss: 0.9765342473983765\n",
      "tensor([0., 1.]) tensor([0.6633, 0.3367], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 8 - 301: dog - cat || Loss: 0.9757482409477234\n",
      "tensor([0., 1.]) tensor([0.6625, 0.3375], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 8 - 302: dog - cat || Loss: 0.9749622344970703\n",
      "tensor([0., 1.]) tensor([0.6617, 0.3383], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 8 - 303: dog - cat || Loss: 0.9741753935813904\n",
      "tensor([0., 1.]) tensor([0.6609, 0.3391], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 8 - 304: dog - cat || Loss: 0.9733880758285522\n",
      "tensor([0., 1.]) tensor([0.6601, 0.3399], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 8 - 305: dog - cat || Loss: 0.9726001024246216\n",
      "tensor([0., 1.]) tensor([0.6593, 0.3407], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 8 - 306: dog - cat || Loss: 0.971811830997467\n",
      "tensor([0., 1.]) tensor([0.6586, 0.3414], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 8 - 307: dog - cat || Loss: 0.9710229635238647\n",
      "tensor([0., 1.]) tensor([0.6578, 0.3422], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 8 - 308: dog - cat || Loss: 0.9702335596084595\n",
      "tensor([0., 1.]) tensor([0.6570, 0.3430], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 8 - 309: dog - cat || Loss: 0.9694436192512512\n",
      "tensor([0., 1.]) tensor([0.6562, 0.3438], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 8 - 310: dog - cat || Loss: 0.9686532616615295\n",
      "tensor([0., 1.]) tensor([0.6554, 0.3446], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 8 - 311: dog - cat || Loss: 0.9678624272346497\n",
      "tensor([0., 1.]) tensor([0.6546, 0.3454], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 8 - 312: dog - cat || Loss: 0.967070996761322\n",
      "tensor([0., 1.]) tensor([0.6538, 0.3462], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 8 - 313: dog - cat || Loss: 0.9662790298461914\n",
      "tensor([0., 1.]) tensor([0.6530, 0.3470], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 8 - 314: dog - cat || Loss: 0.9654866456985474\n",
      "tensor([0., 1.]) tensor([0.6522, 0.3478], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 8 - 315: dog - cat || Loss: 0.9646937251091003\n",
      "tensor([0., 1.]) tensor([0.6514, 0.3486], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 8 - 316: dog - cat || Loss: 0.9639003872871399\n",
      "tensor([0., 1.]) tensor([0.6506, 0.3494], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 8 - 317: dog - cat || Loss: 0.9631064534187317\n",
      "tensor([0., 1.]) tensor([0.6498, 0.3502], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 8 - 318: dog - cat || Loss: 0.9623120427131653\n",
      "tensor([0., 1.]) tensor([0.6491, 0.3509], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 8 - 319: dog - cat || Loss: 0.9615172743797302\n",
      "tensor([0., 1.]) tensor([0.6483, 0.3517], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 8 - 320: dog - cat || Loss: 0.960722029209137\n",
      "tensor([0., 1.]) tensor([0.6475, 0.3525], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 8 - 321: dog - cat || Loss: 0.9599261283874512\n",
      "tensor([0., 1.]) tensor([0.6467, 0.3533], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 8 - 322: dog - cat || Loss: 0.959129810333252\n",
      "tensor([0., 1.]) tensor([0.6459, 0.3541], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 8 - 323: dog - cat || Loss: 0.9583330750465393\n",
      "tensor([0., 1.]) tensor([0.6451, 0.3549], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 8 - 324: dog - cat || Loss: 0.9575358629226685\n",
      "tensor([0., 1.]) tensor([0.6443, 0.3557], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 8 - 325: dog - cat || Loss: 0.9567380547523499\n",
      "tensor([0., 1.]) tensor([0.6435, 0.3565], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 8 - 326: dog - cat || Loss: 0.9559398293495178\n",
      "tensor([0., 1.]) tensor([0.6427, 0.3573], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 8 - 327: dog - cat || Loss: 0.9551411271095276\n",
      "tensor([0., 1.]) tensor([0.6419, 0.3581], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 8 - 328: dog - cat || Loss: 0.9543419480323792\n",
      "tensor([0., 1.]) tensor([0.6411, 0.3589], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 8 - 329: dog - cat || Loss: 0.9535423517227173\n",
      "tensor([0., 1.]) tensor([0.6403, 0.3597], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 8 - 330: dog - cat || Loss: 0.9527422189712524\n",
      "tensor([0., 1.]) tensor([0.6395, 0.3605], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 8 - 331: dog - cat || Loss: 0.9519416689872742\n",
      "tensor([0., 1.]) tensor([0.6387, 0.3613], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 8 - 332: dog - cat || Loss: 0.9511404633522034\n",
      "tensor([0., 1.]) tensor([0.6379, 0.3621], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 8 - 333: dog - cat || Loss: 0.9503388404846191\n",
      "tensor([0., 1.]) tensor([0.6371, 0.3629], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 8 - 334: dog - cat || Loss: 0.9495367407798767\n",
      "tensor([0., 1.]) tensor([0.6363, 0.3637], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 8 - 335: dog - cat || Loss: 0.9487342238426208\n",
      "tensor([0., 1.]) tensor([0.6355, 0.3645], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 8 - 336: dog - cat || Loss: 0.9479312300682068\n",
      "tensor([0., 1.]) tensor([0.6347, 0.3653], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 8 - 337: dog - cat || Loss: 0.9471276998519897\n",
      "tensor([0., 1.]) tensor([0.6339, 0.3661], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 8 - 338: dog - cat || Loss: 0.9463237524032593\n",
      "tensor([0., 1.]) tensor([0.6331, 0.3669], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 8 - 339: dog - cat || Loss: 0.9455193281173706\n",
      "tensor([0., 1.]) tensor([0.6323, 0.3677], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 8 - 340: dog - cat || Loss: 0.9447144269943237\n",
      "tensor([0., 1.]) tensor([0.6315, 0.3685], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 8 - 341: dog - cat || Loss: 0.9439090490341187\n",
      "tensor([0., 1.]) tensor([0.6306, 0.3694], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 8 - 342: dog - cat || Loss: 0.9431031942367554\n",
      "tensor([0., 1.]) tensor([0.6298, 0.3702], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 8 - 343: dog - cat || Loss: 0.9422969222068787\n",
      "tensor([0., 1.]) tensor([0.6290, 0.3710], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 8 - 344: dog - cat || Loss: 0.941490113735199\n",
      "tensor([0., 1.]) tensor([0.6282, 0.3718], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 8 - 345: dog - cat || Loss: 0.9406828284263611\n",
      "tensor([0., 1.]) tensor([0.6274, 0.3726], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 8 - 346: dog - cat || Loss: 0.9398751258850098\n",
      "tensor([0., 1.]) tensor([0.6266, 0.3734], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 8 - 347: dog - cat || Loss: 0.939067006111145\n",
      "tensor([0., 1.]) tensor([0.6258, 0.3742], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 8 - 348: dog - cat || Loss: 0.9382582306861877\n",
      "tensor([0., 1.]) tensor([0.6250, 0.3750], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 8 - 349: dog - cat || Loss: 0.9374490976333618\n",
      "tensor([0., 1.]) tensor([0.6242, 0.3758], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 8 - 350: dog - cat || Loss: 0.9366396069526672\n",
      "tensor([0., 1.]) tensor([0.6234, 0.3766], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 8 - 351: dog - cat || Loss: 0.9358295202255249\n",
      "tensor([0., 1.]) tensor([0.6226, 0.3774], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 8 - 352: dog - cat || Loss: 0.9350191354751587\n",
      "tensor([0., 1.]) tensor([0.6218, 0.3782], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 8 - 353: dog - cat || Loss: 0.9342082142829895\n",
      "tensor([0., 1.]) tensor([0.6209, 0.3791], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 8 - 354: dog - cat || Loss: 0.9333968162536621\n",
      "tensor([0., 1.]) tensor([0.6201, 0.3799], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 8 - 355: dog - cat || Loss: 0.9325850009918213\n",
      "tensor([0., 1.]) tensor([0.6193, 0.3807], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 8 - 356: dog - cat || Loss: 0.9317725896835327\n",
      "tensor([0., 1.]) tensor([0.6185, 0.3815], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 8 - 357: dog - cat || Loss: 0.9309597015380859\n",
      "tensor([0., 1.]) tensor([0.6177, 0.3823], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 8 - 358: dog - cat || Loss: 0.9301464557647705\n",
      "tensor([0., 1.]) tensor([0.6169, 0.3831], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 8 - 359: dog - cat || Loss: 0.9293327331542969\n",
      "tensor([0., 1.]) tensor([0.6161, 0.3839], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 8 - 360: dog - cat || Loss: 0.928518533706665\n",
      "tensor([0., 1.]) tensor([0.6153, 0.3847], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 8 - 361: dog - cat || Loss: 0.9277039766311646\n",
      "tensor([0., 1.]) tensor([0.6144, 0.3856], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 8 - 362: dog - cat || Loss: 0.9268888235092163\n",
      "tensor([0., 1.]) tensor([0.6136, 0.3864], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 8 - 363: dog - cat || Loss: 0.926073431968689\n",
      "tensor([0., 1.]) tensor([0.6128, 0.3872], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 8 - 364: dog - cat || Loss: 0.9252575635910034\n",
      "tensor([0., 1.]) tensor([0.6120, 0.3880], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 8 - 365: dog - cat || Loss: 0.9244412779808044\n",
      "tensor([0., 1.]) tensor([0.6112, 0.3888], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 8 - 366: dog - cat || Loss: 0.9236244559288025\n",
      "tensor([0., 1.]) tensor([0.6104, 0.3896], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 8 - 367: dog - cat || Loss: 0.9228072166442871\n",
      "tensor([0., 1.]) tensor([0.6095, 0.3905], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 8 - 368: dog - cat || Loss: 0.9219895601272583\n",
      "tensor([0., 1.]) tensor([0.6087, 0.3913], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 8 - 369: dog - cat || Loss: 0.9211714863777161\n",
      "tensor([0., 1.]) tensor([0.6079, 0.3921], grad_fn=<SoftmaxBackward0>)\n",
      "=====epoch:9=====\n",
      "Epoch 9 - 0: cat - cat || Loss: 0.7061701416969299\n",
      "tensor([1., 0.]) tensor([0.6071, 0.3929], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 9 - 1: cat - cat || Loss: 0.7068246603012085\n",
      "tensor([1., 0.]) tensor([0.6064, 0.3936], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 9 - 2: cat - cat || Loss: 0.7073317766189575\n",
      "tensor([1., 0.]) tensor([0.6059, 0.3941], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 9 - 3: cat - cat || Loss: 0.7077059149742126\n",
      "tensor([1., 0.]) tensor([0.6056, 0.3944], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 9 - 4: cat - cat || Loss: 0.7079604864120483\n",
      "tensor([1., 0.]) tensor([0.6053, 0.3947], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 9 - 5: cat - cat || Loss: 0.7081075310707092\n",
      "tensor([1., 0.]) tensor([0.6052, 0.3948], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 9 - 6: cat - cat || Loss: 0.708157479763031\n",
      "tensor([1., 0.]) tensor([0.6051, 0.3949], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 9 - 7: cat - cat || Loss: 0.7081204056739807\n",
      "tensor([1., 0.]) tensor([0.6051, 0.3949], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 9 - 8: cat - cat || Loss: 0.7080048322677612\n",
      "tensor([1., 0.]) tensor([0.6053, 0.3947], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 9 - 9: cat - cat || Loss: 0.7078187465667725\n",
      "tensor([1., 0.]) tensor([0.6054, 0.3946], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 9 - 10: cat - cat || Loss: 0.7075690031051636\n",
      "tensor([1., 0.]) tensor([0.6057, 0.3943], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 9 - 11: cat - cat || Loss: 0.7072623372077942\n",
      "tensor([1., 0.]) tensor([0.6060, 0.3940], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 9 - 12: cat - cat || Loss: 0.706904411315918\n",
      "tensor([1., 0.]) tensor([0.6064, 0.3936], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 9 - 13: cat - cat || Loss: 0.7065002918243408\n",
      "tensor([1., 0.]) tensor([0.6068, 0.3932], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 9 - 14: cat - cat || Loss: 0.7060545086860657\n",
      "tensor([1., 0.]) tensor([0.6072, 0.3928], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 9 - 15: cat - cat || Loss: 0.7055714726448059\n",
      "tensor([1., 0.]) tensor([0.6077, 0.3923], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 9 - 16: cat - cat || Loss: 0.705054759979248\n",
      "tensor([1., 0.]) tensor([0.6082, 0.3918], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 9 - 17: cat - cat || Loss: 0.7045080661773682\n",
      "tensor([1., 0.]) tensor([0.6088, 0.3912], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 9 - 18: cat - cat || Loss: 0.7039340734481812\n",
      "tensor([1., 0.]) tensor([0.6093, 0.3907], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 9 - 19: cat - cat || Loss: 0.7033357620239258\n",
      "tensor([1., 0.]) tensor([0.6099, 0.3901], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 9 - 20: cat - cat || Loss: 0.7027155160903931\n",
      "tensor([1., 0.]) tensor([0.6105, 0.3895], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 9 - 21: cat - cat || Loss: 0.7020756602287292\n",
      "tensor([1., 0.]) tensor([0.6112, 0.3888], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 9 - 22: cat - cat || Loss: 0.7014181017875671\n",
      "tensor([1., 0.]) tensor([0.6118, 0.3882], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 9 - 23: cat - cat || Loss: 0.7007445693016052\n",
      "tensor([1., 0.]) tensor([0.6125, 0.3875], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 9 - 24: cat - cat || Loss: 0.7000569701194763\n",
      "tensor([1., 0.]) tensor([0.6132, 0.3868], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 9 - 25: cat - cat || Loss: 0.6993564367294312\n",
      "tensor([1., 0.]) tensor([0.6139, 0.3861], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 9 - 26: cat - cat || Loss: 0.6986449956893921\n",
      "tensor([1., 0.]) tensor([0.6146, 0.3854], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 9 - 27: cat - cat || Loss: 0.6979231834411621\n",
      "tensor([1., 0.]) tensor([0.6153, 0.3847], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 9 - 28: cat - cat || Loss: 0.6971921920776367\n",
      "tensor([1., 0.]) tensor([0.6161, 0.3839], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 9 - 29: cat - cat || Loss: 0.6964529752731323\n",
      "tensor([1., 0.]) tensor([0.6168, 0.3832], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 9 - 30: cat - cat || Loss: 0.6957066655158997\n",
      "tensor([1., 0.]) tensor([0.6176, 0.3824], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 9 - 31: cat - cat || Loss: 0.6949537396430969\n",
      "tensor([1., 0.]) tensor([0.6183, 0.3817], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 9 - 32: cat - cat || Loss: 0.6941949129104614\n",
      "tensor([1., 0.]) tensor([0.6191, 0.3809], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 9 - 33: cat - cat || Loss: 0.69343101978302\n",
      "tensor([1., 0.]) tensor([0.6198, 0.3802], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 9 - 34: cat - cat || Loss: 0.6926623582839966\n",
      "tensor([1., 0.]) tensor([0.6206, 0.3794], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 9 - 35: cat - cat || Loss: 0.6918894648551941\n",
      "tensor([1., 0.]) tensor([0.6214, 0.3786], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 9 - 36: cat - cat || Loss: 0.6911129355430603\n",
      "tensor([1., 0.]) tensor([0.6221, 0.3779], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 9 - 37: cat - cat || Loss: 0.6903331279754639\n",
      "tensor([1., 0.]) tensor([0.6229, 0.3771], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 9 - 38: cat - cat || Loss: 0.689550518989563\n",
      "tensor([1., 0.]) tensor([0.6237, 0.3763], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 9 - 39: cat - cat || Loss: 0.688765287399292\n",
      "tensor([1., 0.]) tensor([0.6245, 0.3755], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 9 - 40: cat - cat || Loss: 0.6879781484603882\n",
      "tensor([1., 0.]) tensor([0.6253, 0.3747], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 9 - 41: cat - cat || Loss: 0.6871886849403381\n",
      "tensor([1., 0.]) tensor([0.6261, 0.3739], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 9 - 42: cat - cat || Loss: 0.6863977909088135\n",
      "tensor([1., 0.]) tensor([0.6269, 0.3731], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 9 - 43: cat - cat || Loss: 0.6856052875518799\n",
      "tensor([1., 0.]) tensor([0.6277, 0.3723], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 9 - 44: cat - cat || Loss: 0.6848115921020508\n",
      "tensor([1., 0.]) tensor([0.6285, 0.3715], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 9 - 45: cat - cat || Loss: 0.6840166449546814\n",
      "tensor([1., 0.]) tensor([0.6292, 0.3708], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 9 - 46: cat - cat || Loss: 0.6832206845283508\n",
      "tensor([1., 0.]) tensor([0.6300, 0.3700], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 9 - 47: cat - cat || Loss: 0.682424008846283\n",
      "tensor([1., 0.]) tensor([0.6308, 0.3692], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 9 - 48: cat - cat || Loss: 0.6816268563270569\n",
      "tensor([1., 0.]) tensor([0.6316, 0.3684], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 9 - 49: cat - cat || Loss: 0.6808291077613831\n",
      "tensor([1., 0.]) tensor([0.6324, 0.3676], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 9 - 50: cat - cat || Loss: 0.6800310611724854\n",
      "tensor([1., 0.]) tensor([0.6332, 0.3668], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 9 - 51: cat - cat || Loss: 0.6792327165603638\n",
      "tensor([1., 0.]) tensor([0.6340, 0.3660], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 9 - 52: cat - cat || Loss: 0.6784340143203735\n",
      "tensor([1., 0.]) tensor([0.6348, 0.3652], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 9 - 53: cat - cat || Loss: 0.6776350736618042\n",
      "tensor([1., 0.]) tensor([0.6356, 0.3644], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 9 - 54: cat - cat || Loss: 0.6768361330032349\n",
      "tensor([1., 0.]) tensor([0.6364, 0.3636], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 9 - 55: cat - cat || Loss: 0.6760371327400208\n",
      "tensor([1., 0.]) tensor([0.6372, 0.3628], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 9 - 56: cat - cat || Loss: 0.6752380728721619\n",
      "tensor([1., 0.]) tensor([0.6380, 0.3620], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 9 - 57: cat - cat || Loss: 0.6744392514228821\n",
      "tensor([1., 0.]) tensor([0.6388, 0.3612], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 9 - 58: cat - cat || Loss: 0.6736404895782471\n",
      "tensor([1., 0.]) tensor([0.6396, 0.3604], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 9 - 59: cat - cat || Loss: 0.6728420257568359\n",
      "tensor([1., 0.]) tensor([0.6404, 0.3596], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 9 - 60: cat - cat || Loss: 0.6720435619354248\n",
      "tensor([1., 0.]) tensor([0.6412, 0.3588], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 9 - 61: cat - cat || Loss: 0.6712453365325928\n",
      "tensor([1., 0.]) tensor([0.6420, 0.3580], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 9 - 62: cat - cat || Loss: 0.6704473495483398\n",
      "tensor([1., 0.]) tensor([0.6428, 0.3572], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 9 - 63: cat - cat || Loss: 0.6696496605873108\n",
      "tensor([1., 0.]) tensor([0.6436, 0.3564], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 9 - 64: cat - cat || Loss: 0.6688522100448608\n",
      "tensor([1., 0.]) tensor([0.6444, 0.3556], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 9 - 65: cat - cat || Loss: 0.6680552959442139\n",
      "tensor([1., 0.]) tensor([0.6452, 0.3548], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 9 - 66: cat - cat || Loss: 0.6672586798667908\n",
      "tensor([1., 0.]) tensor([0.6460, 0.3540], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 9 - 67: cat - cat || Loss: 0.6664624810218811\n",
      "tensor([1., 0.]) tensor([0.6468, 0.3532], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 9 - 68: cat - cat || Loss: 0.6656665205955505\n",
      "tensor([1., 0.]) tensor([0.6476, 0.3524], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 9 - 69: cat - cat || Loss: 0.6648709774017334\n",
      "tensor([1., 0.]) tensor([0.6484, 0.3516], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 9 - 70: cat - cat || Loss: 0.6640759706497192\n",
      "tensor([1., 0.]) tensor([0.6492, 0.3508], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 9 - 71: cat - cat || Loss: 0.6632813811302185\n",
      "tensor([1., 0.]) tensor([0.6500, 0.3500], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 9 - 72: cat - cat || Loss: 0.6624870896339417\n",
      "tensor([1., 0.]) tensor([0.6508, 0.3492], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 9 - 73: cat - cat || Loss: 0.6616933941841125\n",
      "tensor([1., 0.]) tensor([0.6516, 0.3484], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 9 - 74: cat - cat || Loss: 0.6608999967575073\n",
      "tensor([1., 0.]) tensor([0.6524, 0.3476], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 9 - 75: cat - cat || Loss: 0.6601072549819946\n",
      "tensor([1., 0.]) tensor([0.6532, 0.3468], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 9 - 76: cat - cat || Loss: 0.6593149304389954\n",
      "tensor([1., 0.]) tensor([0.6539, 0.3461], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 9 - 77: cat - cat || Loss: 0.6585230827331543\n",
      "tensor([1., 0.]) tensor([0.6547, 0.3453], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 9 - 78: cat - cat || Loss: 0.6577316522598267\n",
      "tensor([1., 0.]) tensor([0.6555, 0.3445], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 9 - 79: cat - cat || Loss: 0.6569409370422363\n",
      "tensor([1., 0.]) tensor([0.6563, 0.3437], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 9 - 80: cat - cat || Loss: 0.6561506986618042\n",
      "tensor([1., 0.]) tensor([0.6571, 0.3429], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 9 - 81: cat - cat || Loss: 0.655360996723175\n",
      "tensor([1., 0.]) tensor([0.6579, 0.3421], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 9 - 82: cat - cat || Loss: 0.6545717120170593\n",
      "tensor([1., 0.]) tensor([0.6587, 0.3413], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 9 - 83: cat - cat || Loss: 0.6537831425666809\n",
      "tensor([1., 0.]) tensor([0.6595, 0.3405], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 9 - 84: cat - cat || Loss: 0.6529950499534607\n",
      "tensor([1., 0.]) tensor([0.6603, 0.3397], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 9 - 85: cat - cat || Loss: 0.652207612991333\n",
      "tensor([1., 0.]) tensor([0.6611, 0.3389], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 9 - 86: cat - cat || Loss: 0.6514205932617188\n",
      "tensor([1., 0.]) tensor([0.6618, 0.3382], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 9 - 87: cat - cat || Loss: 0.6506341695785522\n",
      "tensor([1., 0.]) tensor([0.6626, 0.3374], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 9 - 88: cat - cat || Loss: 0.6498484015464783\n",
      "tensor([1., 0.]) tensor([0.6634, 0.3366], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 9 - 89: cat - cat || Loss: 0.6490631699562073\n",
      "tensor([1., 0.]) tensor([0.6642, 0.3358], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 9 - 90: cat - cat || Loss: 0.6482785940170288\n",
      "tensor([1., 0.]) tensor([0.6650, 0.3350], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 9 - 91: cat - cat || Loss: 0.6474943161010742\n",
      "tensor([1., 0.]) tensor([0.6658, 0.3342], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 9 - 92: cat - cat || Loss: 0.6467108130455017\n",
      "tensor([1., 0.]) tensor([0.6666, 0.3334], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 9 - 93: cat - cat || Loss: 0.645927906036377\n",
      "tensor([1., 0.]) tensor([0.6673, 0.3327], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 9 - 94: cat - cat || Loss: 0.6451455950737\n",
      "tensor([1., 0.]) tensor([0.6681, 0.3319], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 9 - 95: cat - cat || Loss: 0.6443638205528259\n",
      "tensor([1., 0.]) tensor([0.6689, 0.3311], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 9 - 96: cat - cat || Loss: 0.6435825824737549\n",
      "tensor([1., 0.]) tensor([0.6697, 0.3303], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 9 - 97: cat - cat || Loss: 0.6428020596504211\n",
      "tensor([1., 0.]) tensor([0.6705, 0.3295], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 9 - 98: cat - cat || Loss: 0.6420221924781799\n",
      "tensor([1., 0.]) tensor([0.6712, 0.3288], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 9 - 99: cat - cat || Loss: 0.6412428617477417\n",
      "tensor([1., 0.]) tensor([0.6720, 0.3280], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 9 - 100: cat - cat || Loss: 0.6404640674591064\n",
      "tensor([1., 0.]) tensor([0.6728, 0.3272], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 9 - 101: cat - cat || Loss: 0.6396859884262085\n",
      "tensor([1., 0.]) tensor([0.6736, 0.3264], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 9 - 102: cat - cat || Loss: 0.6389085054397583\n",
      "tensor([1., 0.]) tensor([0.6744, 0.3256], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 9 - 103: cat - cat || Loss: 0.6381314396858215\n",
      "tensor([1., 0.]) tensor([0.6751, 0.3249], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 9 - 104: cat - cat || Loss: 0.6373552083969116\n",
      "tensor([1., 0.]) tensor([0.6759, 0.3241], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 9 - 105: cat - cat || Loss: 0.6365796327590942\n",
      "tensor([1., 0.]) tensor([0.6767, 0.3233], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 9 - 106: cat - cat || Loss: 0.6358044743537903\n",
      "tensor([1., 0.]) tensor([0.6775, 0.3225], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 9 - 107: cat - cat || Loss: 0.6350300312042236\n",
      "tensor([1., 0.]) tensor([0.6782, 0.3218], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 9 - 108: cat - cat || Loss: 0.6342562437057495\n",
      "tensor([1., 0.]) tensor([0.6790, 0.3210], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 9 - 109: cat - cat || Loss: 0.6334831714630127\n",
      "tensor([1., 0.]) tensor([0.6798, 0.3202], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 9 - 110: cat - cat || Loss: 0.6327105760574341\n",
      "tensor([1., 0.]) tensor([0.6806, 0.3194], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 9 - 111: cat - cat || Loss: 0.6319387555122375\n",
      "tensor([1., 0.]) tensor([0.6813, 0.3187], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 9 - 112: cat - cat || Loss: 0.6311675310134888\n",
      "tensor([1., 0.]) tensor([0.6821, 0.3179], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 9 - 113: cat - cat || Loss: 0.6303969621658325\n",
      "tensor([1., 0.]) tensor([0.6829, 0.3171], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 9 - 114: cat - cat || Loss: 0.629626989364624\n",
      "tensor([1., 0.]) tensor([0.6836, 0.3164], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 9 - 115: cat - cat || Loss: 0.6288577318191528\n",
      "tensor([1., 0.]) tensor([0.6844, 0.3156], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 9 - 116: cat - cat || Loss: 0.6280891299247742\n",
      "tensor([1., 0.]) tensor([0.6852, 0.3148], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 9 - 117: cat - cat || Loss: 0.6273211240768433\n",
      "tensor([1., 0.]) tensor([0.6859, 0.3141], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 9 - 118: cat - cat || Loss: 0.6265537738800049\n",
      "tensor([1., 0.]) tensor([0.6867, 0.3133], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 9 - 119: cat - cat || Loss: 0.6257871389389038\n",
      "tensor([1., 0.]) tensor([0.6875, 0.3125], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 9 - 120: cat - cat || Loss: 0.6250211000442505\n",
      "tensor([1., 0.]) tensor([0.6882, 0.3118], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 9 - 121: cat - cat || Loss: 0.6242556571960449\n",
      "tensor([1., 0.]) tensor([0.6890, 0.3110], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 9 - 122: cat - cat || Loss: 0.6234911680221558\n",
      "tensor([1., 0.]) tensor([0.6898, 0.3102], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 9 - 123: cat - cat || Loss: 0.6227271556854248\n",
      "tensor([1., 0.]) tensor([0.6905, 0.3095], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 9 - 124: cat - cat || Loss: 0.6219639182090759\n",
      "tensor([1., 0.]) tensor([0.6913, 0.3087], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 9 - 125: cat - cat || Loss: 0.6212013959884644\n",
      "tensor([1., 0.]) tensor([0.6921, 0.3079], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 9 - 126: cat - cat || Loss: 0.6204394698143005\n",
      "tensor([1., 0.]) tensor([0.6928, 0.3072], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 9 - 127: cat - cat || Loss: 0.6196781992912292\n",
      "tensor([1., 0.]) tensor([0.6936, 0.3064], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 9 - 128: cat - cat || Loss: 0.61891770362854\n",
      "tensor([1., 0.]) tensor([0.6943, 0.3057], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 9 - 129: cat - cat || Loss: 0.6181579232215881\n",
      "tensor([1., 0.]) tensor([0.6951, 0.3049], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 9 - 130: cat - cat || Loss: 0.6173989176750183\n",
      "tensor([1., 0.]) tensor([0.6959, 0.3041], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 9 - 131: cat - cat || Loss: 0.616640567779541\n",
      "tensor([1., 0.]) tensor([0.6966, 0.3034], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 9 - 132: cat - cat || Loss: 0.615882933139801\n",
      "tensor([1., 0.]) tensor([0.6974, 0.3026], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 9 - 133: cat - cat || Loss: 0.6151261329650879\n",
      "tensor([1., 0.]) tensor([0.6981, 0.3019], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 9 - 134: cat - cat || Loss: 0.6143698692321777\n",
      "tensor([1., 0.]) tensor([0.6989, 0.3011], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 9 - 135: cat - cat || Loss: 0.613614559173584\n",
      "tensor([1., 0.]) tensor([0.6996, 0.3004], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 9 - 136: cat - cat || Loss: 0.6128597855567932\n",
      "tensor([1., 0.]) tensor([0.7004, 0.2996], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 9 - 137: cat - cat || Loss: 0.6121057271957397\n",
      "tensor([1., 0.]) tensor([0.7012, 0.2988], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 9 - 138: cat - cat || Loss: 0.6113524436950684\n",
      "tensor([1., 0.]) tensor([0.7019, 0.2981], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 9 - 139: cat - cat || Loss: 0.6105998754501343\n",
      "tensor([1., 0.]) tensor([0.7027, 0.2973], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 9 - 140: cat - cat || Loss: 0.6098480224609375\n",
      "tensor([1., 0.]) tensor([0.7034, 0.2966], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 9 - 141: cat - cat || Loss: 0.609096884727478\n",
      "tensor([1., 0.]) tensor([0.7042, 0.2958], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 9 - 142: cat - cat || Loss: 0.6083465218544006\n",
      "tensor([1., 0.]) tensor([0.7049, 0.2951], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 9 - 143: cat - cat || Loss: 0.607596755027771\n",
      "tensor([1., 0.]) tensor([0.7057, 0.2943], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 9 - 144: cat - cat || Loss: 0.606847882270813\n",
      "tensor([1., 0.]) tensor([0.7064, 0.2936], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 9 - 145: cat - cat || Loss: 0.6060996055603027\n",
      "tensor([1., 0.]) tensor([0.7072, 0.2928], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 9 - 146: cat - cat || Loss: 0.6053521633148193\n",
      "tensor([1., 0.]) tensor([0.7079, 0.2921], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 9 - 147: cat - cat || Loss: 0.6046053767204285\n",
      "tensor([1., 0.]) tensor([0.7087, 0.2913], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 9 - 148: cat - cat || Loss: 0.6038593053817749\n",
      "tensor([1., 0.]) tensor([0.7094, 0.2906], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 9 - 149: cat - cat || Loss: 0.603114128112793\n",
      "tensor([1., 0.]) tensor([0.7101, 0.2899], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 9 - 150: cat - cat || Loss: 0.6023696660995483\n",
      "tensor([1., 0.]) tensor([0.7109, 0.2891], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 9 - 151: cat - cat || Loss: 0.6016260385513306\n",
      "tensor([1., 0.]) tensor([0.7116, 0.2884], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 9 - 152: cat - cat || Loss: 0.6008831262588501\n",
      "tensor([1., 0.]) tensor([0.7124, 0.2876], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 9 - 153: cat - cat || Loss: 0.6001408100128174\n",
      "tensor([1., 0.]) tensor([0.7131, 0.2869], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 9 - 154: cat - cat || Loss: 0.5993993878364563\n",
      "tensor([1., 0.]) tensor([0.7139, 0.2861], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 9 - 155: cat - cat || Loss: 0.5986586809158325\n",
      "tensor([1., 0.]) tensor([0.7146, 0.2854], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 9 - 156: cat - cat || Loss: 0.5979187488555908\n",
      "tensor([1., 0.]) tensor([0.7153, 0.2847], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 9 - 157: cat - cat || Loss: 0.5971795916557312\n",
      "tensor([1., 0.]) tensor([0.7161, 0.2839], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 9 - 158: cat - cat || Loss: 0.5964412093162537\n",
      "tensor([1., 0.]) tensor([0.7168, 0.2832], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 9 - 159: cat - cat || Loss: 0.5957037210464478\n",
      "tensor([1., 0.]) tensor([0.7176, 0.2824], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 9 - 160: cat - cat || Loss: 0.5949668884277344\n",
      "tensor([1., 0.]) tensor([0.7183, 0.2817], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 9 - 161: cat - cat || Loss: 0.5942310094833374\n",
      "tensor([1., 0.]) tensor([0.7190, 0.2810], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 9 - 162: cat - cat || Loss: 0.5934960842132568\n",
      "tensor([1., 0.]) tensor([0.7198, 0.2802], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 9 - 163: cat - cat || Loss: 0.5927616357803345\n",
      "tensor([1., 0.]) tensor([0.7205, 0.2795], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 9 - 164: cat - cat || Loss: 0.5920282602310181\n",
      "tensor([1., 0.]) tensor([0.7212, 0.2788], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 9 - 165: cat - cat || Loss: 0.591295599937439\n",
      "tensor([1., 0.]) tensor([0.7220, 0.2780], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 9 - 166: cat - cat || Loss: 0.5905637741088867\n",
      "tensor([1., 0.]) tensor([0.7227, 0.2773], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 9 - 167: cat - cat || Loss: 0.5898326635360718\n",
      "tensor([1., 0.]) tensor([0.7234, 0.2766], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 9 - 168: cat - cat || Loss: 0.5891024470329285\n",
      "tensor([1., 0.]) tensor([0.7242, 0.2758], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 9 - 169: cat - cat || Loss: 0.5883728861808777\n",
      "tensor([1., 0.]) tensor([0.7249, 0.2751], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 9 - 170: cat - cat || Loss: 0.5876442193984985\n",
      "tensor([1., 0.]) tensor([0.7256, 0.2744], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 9 - 171: cat - cat || Loss: 0.5869165658950806\n",
      "tensor([1., 0.]) tensor([0.7263, 0.2737], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 9 - 172: cat - cat || Loss: 0.5861893892288208\n",
      "tensor([1., 0.]) tensor([0.7271, 0.2729], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 9 - 173: cat - cat || Loss: 0.5854634046554565\n",
      "tensor([1., 0.]) tensor([0.7278, 0.2722], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 9 - 174: cat - cat || Loss: 0.58473801612854\n",
      "tensor([1., 0.]) tensor([0.7285, 0.2715], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 9 - 175: cat - cat || Loss: 0.5840134024620056\n",
      "tensor([1., 0.]) tensor([0.7292, 0.2708], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 9 - 176: cat - cat || Loss: 0.5832896828651428\n",
      "tensor([1., 0.]) tensor([0.7300, 0.2700], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 9 - 177: cat - cat || Loss: 0.5825668573379517\n",
      "tensor([1., 0.]) tensor([0.7307, 0.2693], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 9 - 178: cat - cat || Loss: 0.581844687461853\n",
      "tensor([1., 0.]) tensor([0.7314, 0.2686], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 9 - 179: cat - cat || Loss: 0.5811235308647156\n",
      "tensor([1., 0.]) tensor([0.7321, 0.2679], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 9 - 180: cat - cat || Loss: 0.5804030895233154\n",
      "tensor([1., 0.]) tensor([0.7329, 0.2671], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 9 - 181: cat - cat || Loss: 0.5796835422515869\n",
      "tensor([1., 0.]) tensor([0.7336, 0.2664], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 9 - 182: cat - cat || Loss: 0.5789648294448853\n",
      "tensor([1., 0.]) tensor([0.7343, 0.2657], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 9 - 183: cat - cat || Loss: 0.5782470107078552\n",
      "tensor([1., 0.]) tensor([0.7350, 0.2650], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 9 - 184: cat - cat || Loss: 0.5775299072265625\n",
      "tensor([1., 0.]) tensor([0.7357, 0.2643], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 9 - 185: cat - cat || Loss: 0.5768137574195862\n",
      "tensor([1., 0.]) tensor([0.7364, 0.2636], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 9 - 186: cat - cat || Loss: 0.5760982036590576\n",
      "tensor([1., 0.]) tensor([0.7372, 0.2628], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 9 - 187: cat - cat || Loss: 0.5753836631774902\n",
      "tensor([1., 0.]) tensor([0.7379, 0.2621], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 9 - 188: cat - cat || Loss: 0.5746700763702393\n",
      "tensor([1., 0.]) tensor([0.7386, 0.2614], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 9 - 189: cat - cat || Loss: 0.5739572644233704\n",
      "tensor([1., 0.]) tensor([0.7393, 0.2607], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 9 - 190: dog - cat || Loss: 1.0532779693603516\n",
      "tensor([0., 1.]) tensor([0.7400, 0.2600], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 9 - 191: dog - cat || Loss: 1.0538476705551147\n",
      "tensor([0., 1.]) tensor([0.7406, 0.2594], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 9 - 192: dog - cat || Loss: 1.0542893409729004\n",
      "tensor([0., 1.]) tensor([0.7410, 0.2590], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 9 - 193: dog - cat || Loss: 1.0546159744262695\n",
      "tensor([0., 1.]) tensor([0.7414, 0.2586], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 9 - 194: dog - cat || Loss: 1.0548392534255981\n",
      "tensor([0., 1.]) tensor([0.7416, 0.2584], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 9 - 195: dog - cat || Loss: 1.0549696683883667\n",
      "tensor([0., 1.]) tensor([0.7417, 0.2583], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 9 - 196: dog - cat || Loss: 1.0550165176391602\n",
      "tensor([0., 1.]) tensor([0.7418, 0.2582], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 9 - 197: dog - cat || Loss: 1.0549880266189575\n",
      "tensor([0., 1.]) tensor([0.7417, 0.2583], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 9 - 198: dog - cat || Loss: 1.0548917055130005\n",
      "tensor([0., 1.]) tensor([0.7416, 0.2584], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 9 - 199: dog - cat || Loss: 1.054734706878662\n",
      "tensor([0., 1.]) tensor([0.7415, 0.2585], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 9 - 200: dog - cat || Loss: 1.0545225143432617\n",
      "tensor([0., 1.]) tensor([0.7413, 0.2587], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 9 - 201: dog - cat || Loss: 1.0542609691619873\n",
      "tensor([0., 1.]) tensor([0.7410, 0.2590], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 9 - 202: dog - cat || Loss: 1.0539549589157104\n",
      "tensor([0., 1.]) tensor([0.7407, 0.2593], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 9 - 203: dog - cat || Loss: 1.053608775138855\n",
      "tensor([0., 1.]) tensor([0.7403, 0.2597], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 9 - 204: dog - cat || Loss: 1.053226351737976\n",
      "tensor([0., 1.]) tensor([0.7400, 0.2600], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 9 - 205: dog - cat || Loss: 1.0528112649917603\n",
      "tensor([0., 1.]) tensor([0.7395, 0.2605], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 9 - 206: dog - cat || Loss: 1.0523667335510254\n",
      "tensor([0., 1.]) tensor([0.7391, 0.2609], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 9 - 207: dog - cat || Loss: 1.0518958568572998\n",
      "tensor([0., 1.]) tensor([0.7386, 0.2614], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 9 - 208: dog - cat || Loss: 1.0514006614685059\n",
      "tensor([0., 1.]) tensor([0.7381, 0.2619], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 9 - 209: dog - cat || Loss: 1.0508841276168823\n",
      "tensor([0., 1.]) tensor([0.7376, 0.2624], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 9 - 210: dog - cat || Loss: 1.050347924232483\n",
      "tensor([0., 1.]) tensor([0.7371, 0.2629], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 9 - 211: dog - cat || Loss: 1.0497941970825195\n",
      "tensor([0., 1.]) tensor([0.7365, 0.2635], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 9 - 212: dog - cat || Loss: 1.0492242574691772\n",
      "tensor([0., 1.]) tensor([0.7360, 0.2640], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 9 - 213: dog - cat || Loss: 1.0486400127410889\n",
      "tensor([0., 1.]) tensor([0.7354, 0.2646], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 9 - 214: dog - cat || Loss: 1.0480425357818604\n",
      "tensor([0., 1.]) tensor([0.7348, 0.2652], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 9 - 215: dog - cat || Loss: 1.0474334955215454\n",
      "tensor([0., 1.]) tensor([0.7342, 0.2658], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 9 - 216: dog - cat || Loss: 1.0468134880065918\n",
      "tensor([0., 1.]) tensor([0.7336, 0.2664], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 9 - 217: dog - cat || Loss: 1.0461838245391846\n",
      "tensor([0., 1.]) tensor([0.7329, 0.2671], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 9 - 218: dog - cat || Loss: 1.045545220375061\n",
      "tensor([0., 1.]) tensor([0.7323, 0.2677], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 9 - 219: dog - cat || Loss: 1.0448987483978271\n",
      "tensor([0., 1.]) tensor([0.7316, 0.2684], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 9 - 220: dog - cat || Loss: 1.0442448854446411\n",
      "tensor([0., 1.]) tensor([0.7310, 0.2690], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 9 - 221: dog - cat || Loss: 1.0435844659805298\n",
      "tensor([0., 1.]) tensor([0.7303, 0.2697], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 9 - 222: dog - cat || Loss: 1.0429179668426514\n",
      "tensor([0., 1.]) tensor([0.7297, 0.2703], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 9 - 223: dog - cat || Loss: 1.0422459840774536\n",
      "tensor([0., 1.]) tensor([0.7290, 0.2710], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 9 - 224: dog - cat || Loss: 1.0415687561035156\n",
      "tensor([0., 1.]) tensor([0.7283, 0.2717], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 9 - 225: dog - cat || Loss: 1.0408869981765747\n",
      "tensor([0., 1.]) tensor([0.7276, 0.2724], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 9 - 226: dog - cat || Loss: 1.0402010679244995\n",
      "tensor([0., 1.]) tensor([0.7269, 0.2731], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 9 - 227: dog - cat || Loss: 1.0395112037658691\n",
      "tensor([0., 1.]) tensor([0.7262, 0.2738], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 9 - 228: dog - cat || Loss: 1.0388176441192627\n",
      "tensor([0., 1.]) tensor([0.7256, 0.2744], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 9 - 229: dog - cat || Loss: 1.0381211042404175\n",
      "tensor([0., 1.]) tensor([0.7249, 0.2751], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 9 - 230: dog - cat || Loss: 1.0374209880828857\n",
      "tensor([0., 1.]) tensor([0.7242, 0.2758], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 9 - 231: dog - cat || Loss: 1.036718487739563\n",
      "tensor([0., 1.]) tensor([0.7235, 0.2765], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 9 - 232: dog - cat || Loss: 1.036013126373291\n",
      "tensor([0., 1.]) tensor([0.7228, 0.2772], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 9 - 233: dog - cat || Loss: 1.035305380821228\n",
      "tensor([0., 1.]) tensor([0.7220, 0.2780], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 9 - 234: dog - cat || Loss: 1.0345954895019531\n",
      "tensor([0., 1.]) tensor([0.7213, 0.2787], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 9 - 235: dog - cat || Loss: 1.0338834524154663\n",
      "tensor([0., 1.]) tensor([0.7206, 0.2794], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 9 - 236: dog - cat || Loss: 1.0331693887710571\n",
      "tensor([0., 1.]) tensor([0.7199, 0.2801], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 9 - 237: dog - cat || Loss: 1.0324534177780151\n",
      "tensor([0., 1.]) tensor([0.7192, 0.2808], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 9 - 238: dog - cat || Loss: 1.031735897064209\n",
      "tensor([0., 1.]) tensor([0.7185, 0.2815], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 9 - 239: dog - cat || Loss: 1.0310168266296387\n",
      "tensor([0., 1.]) tensor([0.7178, 0.2822], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 9 - 240: dog - cat || Loss: 1.030295968055725\n",
      "tensor([0., 1.]) tensor([0.7170, 0.2830], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 9 - 241: dog - cat || Loss: 1.0295737981796265\n",
      "tensor([0., 1.]) tensor([0.7163, 0.2837], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 9 - 242: dog - cat || Loss: 1.0288503170013428\n",
      "tensor([0., 1.]) tensor([0.7156, 0.2844], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 9 - 243: dog - cat || Loss: 1.0281254053115845\n",
      "tensor([0., 1.]) tensor([0.7149, 0.2851], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 9 - 244: dog - cat || Loss: 1.0273993015289307\n",
      "tensor([0., 1.]) tensor([0.7141, 0.2859], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 9 - 245: dog - cat || Loss: 1.026672124862671\n",
      "tensor([0., 1.]) tensor([0.7134, 0.2866], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 9 - 246: dog - cat || Loss: 1.025943636894226\n",
      "tensor([0., 1.]) tensor([0.7127, 0.2873], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 9 - 247: dog - cat || Loss: 1.0252139568328857\n",
      "tensor([0., 1.]) tensor([0.7120, 0.2880], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 9 - 248: dog - cat || Loss: 1.024483561515808\n",
      "tensor([0., 1.]) tensor([0.7112, 0.2888], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 9 - 249: dog - cat || Loss: 1.023751974105835\n",
      "tensor([0., 1.]) tensor([0.7105, 0.2895], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 9 - 250: dog - cat || Loss: 1.0230194330215454\n",
      "tensor([0., 1.]) tensor([0.7098, 0.2902], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 9 - 251: dog - cat || Loss: 1.0222859382629395\n",
      "tensor([0., 1.]) tensor([0.7090, 0.2910], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 9 - 252: dog - cat || Loss: 1.021551489830017\n",
      "tensor([0., 1.]) tensor([0.7083, 0.2917], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 9 - 253: dog - cat || Loss: 1.0208158493041992\n",
      "tensor([0., 1.]) tensor([0.7076, 0.2924], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 9 - 254: dog - cat || Loss: 1.0200796127319336\n",
      "tensor([0., 1.]) tensor([0.7068, 0.2932], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 9 - 255: dog - cat || Loss: 1.019342303276062\n",
      "tensor([0., 1.]) tensor([0.7061, 0.2939], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 9 - 256: dog - cat || Loss: 1.0186043977737427\n",
      "tensor([0., 1.]) tensor([0.7053, 0.2947], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 9 - 257: dog - cat || Loss: 1.017865538597107\n",
      "tensor([0., 1.]) tensor([0.7046, 0.2954], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 9 - 258: dog - cat || Loss: 1.0171259641647339\n",
      "tensor([0., 1.]) tensor([0.7039, 0.2961], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 9 - 259: dog - cat || Loss: 1.016385555267334\n",
      "tensor([0., 1.]) tensor([0.7031, 0.2969], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 9 - 260: dog - cat || Loss: 1.0156441926956177\n",
      "tensor([0., 1.]) tensor([0.7024, 0.2976], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 9 - 261: dog - cat || Loss: 1.0149022340774536\n",
      "tensor([0., 1.]) tensor([0.7016, 0.2984], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 9 - 262: dog - cat || Loss: 1.0141595602035522\n",
      "tensor([0., 1.]) tensor([0.7009, 0.2991], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 9 - 263: dog - cat || Loss: 1.0134159326553345\n",
      "tensor([0., 1.]) tensor([0.7002, 0.2998], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 9 - 264: dog - cat || Loss: 1.0126715898513794\n",
      "tensor([0., 1.]) tensor([0.6994, 0.3006], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 9 - 265: dog - cat || Loss: 1.0119266510009766\n",
      "tensor([0., 1.]) tensor([0.6987, 0.3013], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 9 - 266: dog - cat || Loss: 1.0111809968948364\n",
      "tensor([0., 1.]) tensor([0.6979, 0.3021], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 9 - 267: dog - cat || Loss: 1.010434627532959\n",
      "tensor([0., 1.]) tensor([0.6972, 0.3028], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 9 - 268: dog - cat || Loss: 1.0096874237060547\n",
      "tensor([0., 1.]) tensor([0.6964, 0.3036], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 9 - 269: dog - cat || Loss: 1.008939504623413\n",
      "tensor([0., 1.]) tensor([0.6957, 0.3043], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 9 - 270: dog - cat || Loss: 1.0081909894943237\n",
      "tensor([0., 1.]) tensor([0.6949, 0.3051], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 9 - 271: dog - cat || Loss: 1.0074418783187866\n",
      "tensor([0., 1.]) tensor([0.6942, 0.3058], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 9 - 272: dog - cat || Loss: 1.006691813468933\n",
      "tensor([0., 1.]) tensor([0.6934, 0.3066], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 9 - 273: dog - cat || Loss: 1.0059412717819214\n",
      "tensor([0., 1.]) tensor([0.6927, 0.3073], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 9 - 274: dog - cat || Loss: 1.0051898956298828\n",
      "tensor([0., 1.]) tensor([0.6919, 0.3081], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 9 - 275: dog - cat || Loss: 1.0044379234313965\n",
      "tensor([0., 1.]) tensor([0.6912, 0.3088], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 9 - 276: dog - cat || Loss: 1.0036852359771729\n",
      "tensor([0., 1.]) tensor([0.6904, 0.3096], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 9 - 277: dog - cat || Loss: 1.002931833267212\n",
      "tensor([0., 1.]) tensor([0.6897, 0.3103], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 9 - 278: dog - cat || Loss: 1.0021779537200928\n",
      "tensor([0., 1.]) tensor([0.6889, 0.3111], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 9 - 279: dog - cat || Loss: 1.0014232397079468\n",
      "tensor([0., 1.]) tensor([0.6882, 0.3118], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 9 - 280: dog - cat || Loss: 1.000667929649353\n",
      "tensor([0., 1.]) tensor([0.6874, 0.3126], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 9 - 281: dog - cat || Loss: 0.999911904335022\n",
      "tensor([0., 1.]) tensor([0.6867, 0.3133], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 9 - 282: dog - cat || Loss: 0.9991553425788879\n",
      "tensor([0., 1.]) tensor([0.6859, 0.3141], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 9 - 283: dog - cat || Loss: 0.9983980655670166\n",
      "tensor([0., 1.]) tensor([0.6851, 0.3149], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 9 - 284: dog - cat || Loss: 0.9976401329040527\n",
      "tensor([0., 1.]) tensor([0.6844, 0.3156], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 9 - 285: dog - cat || Loss: 0.9968816637992859\n",
      "tensor([0., 1.]) tensor([0.6836, 0.3164], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 9 - 286: dog - cat || Loss: 0.9961224794387817\n",
      "tensor([0., 1.]) tensor([0.6829, 0.3171], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 9 - 287: dog - cat || Loss: 0.9953626990318298\n",
      "tensor([0., 1.]) tensor([0.6821, 0.3179], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 9 - 288: dog - cat || Loss: 0.9946023225784302\n",
      "tensor([0., 1.]) tensor([0.6813, 0.3187], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 9 - 289: dog - cat || Loss: 0.9938411712646484\n",
      "tensor([0., 1.]) tensor([0.6806, 0.3194], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 9 - 290: dog - cat || Loss: 0.9930794835090637\n",
      "tensor([0., 1.]) tensor([0.6798, 0.3202], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 9 - 291: dog - cat || Loss: 0.9923173785209656\n",
      "tensor([0., 1.]) tensor([0.6791, 0.3209], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 9 - 292: dog - cat || Loss: 0.9915543794631958\n",
      "tensor([0., 1.]) tensor([0.6783, 0.3217], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 9 - 293: dog - cat || Loss: 0.990790843963623\n",
      "tensor([0., 1.]) tensor([0.6775, 0.3225], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 9 - 294: dog - cat || Loss: 0.9900268316268921\n",
      "tensor([0., 1.]) tensor([0.6768, 0.3232], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 9 - 295: dog - cat || Loss: 0.9892622232437134\n",
      "tensor([0., 1.]) tensor([0.6760, 0.3240], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 9 - 296: dog - cat || Loss: 0.9884967803955078\n",
      "tensor([0., 1.]) tensor([0.6752, 0.3248], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 9 - 297: dog - cat || Loss: 0.9877309203147888\n",
      "tensor([0., 1.]) tensor([0.6745, 0.3255], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 9 - 298: dog - cat || Loss: 0.9869643449783325\n",
      "tensor([0., 1.]) tensor([0.6737, 0.3263], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 9 - 299: dog - cat || Loss: 0.9861972332000732\n",
      "tensor([0., 1.]) tensor([0.6729, 0.3271], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 9 - 300: dog - cat || Loss: 0.9854294657707214\n",
      "tensor([0., 1.]) tensor([0.6722, 0.3278], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 9 - 301: dog - cat || Loss: 0.9846611618995667\n",
      "tensor([0., 1.]) tensor([0.6714, 0.3286], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 9 - 302: dog - cat || Loss: 0.9838923811912537\n",
      "tensor([0., 1.]) tensor([0.6706, 0.3294], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 9 - 303: dog - cat || Loss: 0.9831227660179138\n",
      "tensor([0., 1.]) tensor([0.6699, 0.3301], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 9 - 304: dog - cat || Loss: 0.9823527932167053\n",
      "tensor([0., 1.]) tensor([0.6691, 0.3309], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 9 - 305: dog - cat || Loss: 0.98158198595047\n",
      "tensor([0., 1.]) tensor([0.6683, 0.3317], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 9 - 306: dog - cat || Loss: 0.9808109402656555\n",
      "tensor([0., 1.]) tensor([0.6675, 0.3325], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 9 - 307: dog - cat || Loss: 0.9800390601158142\n",
      "tensor([0., 1.]) tensor([0.6668, 0.3332], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 9 - 308: dog - cat || Loss: 0.9792667031288147\n",
      "tensor([0., 1.]) tensor([0.6660, 0.3340], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 9 - 309: dog - cat || Loss: 0.9784938097000122\n",
      "tensor([0., 1.]) tensor([0.6652, 0.3348], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 9 - 310: dog - cat || Loss: 0.9777202606201172\n",
      "tensor([0., 1.]) tensor([0.6645, 0.3355], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 9 - 311: dog - cat || Loss: 0.9769461750984192\n",
      "tensor([0., 1.]) tensor([0.6637, 0.3363], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 9 - 312: dog - cat || Loss: 0.9761716723442078\n",
      "tensor([0., 1.]) tensor([0.6629, 0.3371], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 9 - 313: dog - cat || Loss: 0.9753965735435486\n",
      "tensor([0., 1.]) tensor([0.6621, 0.3379], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 9 - 314: dog - cat || Loss: 0.9746208190917969\n",
      "tensor([0., 1.]) tensor([0.6614, 0.3386], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 9 - 315: dog - cat || Loss: 0.973844587802887\n",
      "tensor([0., 1.]) tensor([0.6606, 0.3394], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 9 - 316: dog - cat || Loss: 0.9730677604675293\n",
      "tensor([0., 1.]) tensor([0.6598, 0.3402], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 9 - 317: dog - cat || Loss: 0.9722903966903687\n",
      "tensor([0., 1.]) tensor([0.6590, 0.3410], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 9 - 318: dog - cat || Loss: 0.971512496471405\n",
      "tensor([0., 1.]) tensor([0.6583, 0.3417], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 9 - 319: dog - cat || Loss: 0.9707340598106384\n",
      "tensor([0., 1.]) tensor([0.6575, 0.3425], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 9 - 320: dog - cat || Loss: 0.9699552059173584\n",
      "tensor([0., 1.]) tensor([0.6567, 0.3433], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 9 - 321: dog - cat || Loss: 0.9691755771636963\n",
      "tensor([0., 1.]) tensor([0.6559, 0.3441], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 9 - 322: dog - cat || Loss: 0.9683955907821655\n",
      "tensor([0., 1.]) tensor([0.6551, 0.3449], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 9 - 323: dog - cat || Loss: 0.9676149487495422\n",
      "tensor([0., 1.]) tensor([0.6544, 0.3456], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 9 - 324: dog - cat || Loss: 0.9668338894844055\n",
      "tensor([0., 1.]) tensor([0.6536, 0.3464], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 9 - 325: dog - cat || Loss: 0.9660524129867554\n",
      "tensor([0., 1.]) tensor([0.6528, 0.3472], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 9 - 326: dog - cat || Loss: 0.9652701616287231\n",
      "tensor([0., 1.]) tensor([0.6520, 0.3480], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 9 - 327: dog - cat || Loss: 0.964487612247467\n",
      "tensor([0., 1.]) tensor([0.6512, 0.3488], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 9 - 328: dog - cat || Loss: 0.9637044072151184\n",
      "tensor([0., 1.]) tensor([0.6504, 0.3496], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 9 - 329: dog - cat || Loss: 0.9629207849502563\n",
      "tensor([0., 1.]) tensor([0.6497, 0.3503], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 9 - 330: dog - cat || Loss: 0.9621366262435913\n",
      "tensor([0., 1.]) tensor([0.6489, 0.3511], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 9 - 331: dog - cat || Loss: 0.9613519906997681\n",
      "tensor([0., 1.]) tensor([0.6481, 0.3519], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 9 - 332: dog - cat || Loss: 0.9605668187141418\n",
      "tensor([0., 1.]) tensor([0.6473, 0.3527], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 9 - 333: dog - cat || Loss: 0.9597812294960022\n",
      "tensor([0., 1.]) tensor([0.6465, 0.3535], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 9 - 334: dog - cat || Loss: 0.9589949250221252\n",
      "tensor([0., 1.]) tensor([0.6457, 0.3543], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 9 - 335: dog - cat || Loss: 0.9582082629203796\n",
      "tensor([0., 1.]) tensor([0.6449, 0.3551], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 9 - 336: dog - cat || Loss: 0.9574211239814758\n",
      "tensor([0., 1.]) tensor([0.6442, 0.3558], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 9 - 337: dog - cat || Loss: 0.9566333889961243\n",
      "tensor([0., 1.]) tensor([0.6434, 0.3566], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 9 - 338: dog - cat || Loss: 0.9558451771736145\n",
      "tensor([0., 1.]) tensor([0.6426, 0.3574], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 9 - 339: dog - cat || Loss: 0.9550566673278809\n",
      "tensor([0., 1.]) tensor([0.6418, 0.3582], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 9 - 340: dog - cat || Loss: 0.9542673826217651\n",
      "tensor([0., 1.]) tensor([0.6410, 0.3590], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 9 - 341: dog - cat || Loss: 0.9534777402877808\n",
      "tensor([0., 1.]) tensor([0.6402, 0.3598], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 9 - 342: dog - cat || Loss: 0.9526875615119934\n",
      "tensor([0., 1.]) tensor([0.6394, 0.3606], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 9 - 343: dog - cat || Loss: 0.9518969058990479\n",
      "tensor([0., 1.]) tensor([0.6386, 0.3614], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 9 - 344: dog - cat || Loss: 0.9511057138442993\n",
      "tensor([0., 1.]) tensor([0.6378, 0.3622], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 9 - 345: dog - cat || Loss: 0.9503139853477478\n",
      "tensor([0., 1.]) tensor([0.6371, 0.3629], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 9 - 346: dog - cat || Loss: 0.9495217800140381\n",
      "tensor([0., 1.]) tensor([0.6363, 0.3637], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 9 - 347: dog - cat || Loss: 0.9487292170524597\n",
      "tensor([0., 1.]) tensor([0.6355, 0.3645], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 9 - 348: dog - cat || Loss: 0.947935938835144\n",
      "tensor([0., 1.]) tensor([0.6347, 0.3653], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 9 - 349: dog - cat || Loss: 0.9471423625946045\n",
      "tensor([0., 1.]) tensor([0.6339, 0.3661], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 9 - 350: dog - cat || Loss: 0.9463481307029724\n",
      "tensor([0., 1.]) tensor([0.6331, 0.3669], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 9 - 351: dog - cat || Loss: 0.9455534815788269\n",
      "tensor([0., 1.]) tensor([0.6323, 0.3677], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 9 - 352: dog - cat || Loss: 0.9447584748268127\n",
      "tensor([0., 1.]) tensor([0.6315, 0.3685], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 9 - 353: dog - cat || Loss: 0.943962812423706\n",
      "tensor([0., 1.]) tensor([0.6307, 0.3693], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 9 - 354: dog - cat || Loss: 0.9431668519973755\n",
      "tensor([0., 1.]) tensor([0.6299, 0.3701], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 9 - 355: dog - cat || Loss: 0.9423701167106628\n",
      "tensor([0., 1.]) tensor([0.6291, 0.3709], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 9 - 356: dog - cat || Loss: 0.9415732026100159\n",
      "tensor([0., 1.]) tensor([0.6283, 0.3717], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 9 - 357: dog - cat || Loss: 0.9407756924629211\n",
      "tensor([0., 1.]) tensor([0.6275, 0.3725], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 9 - 358: dog - cat || Loss: 0.9399776458740234\n",
      "tensor([0., 1.]) tensor([0.6267, 0.3733], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 9 - 359: dog - cat || Loss: 0.9391791820526123\n",
      "tensor([0., 1.]) tensor([0.6259, 0.3741], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 9 - 360: dog - cat || Loss: 0.9383801817893982\n",
      "tensor([0., 1.]) tensor([0.6251, 0.3749], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 9 - 361: dog - cat || Loss: 0.9375807642936707\n",
      "tensor([0., 1.]) tensor([0.6243, 0.3757], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 9 - 362: dog - cat || Loss: 0.9367809295654297\n",
      "tensor([0., 1.]) tensor([0.6235, 0.3765], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 9 - 363: dog - cat || Loss: 0.9359806180000305\n",
      "tensor([0., 1.]) tensor([0.6227, 0.3773], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 9 - 364: dog - cat || Loss: 0.9351797699928284\n",
      "tensor([0., 1.]) tensor([0.6219, 0.3781], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 9 - 365: dog - cat || Loss: 0.9343785047531128\n",
      "tensor([0., 1.]) tensor([0.6211, 0.3789], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 9 - 366: dog - cat || Loss: 0.9335767030715942\n",
      "tensor([0., 1.]) tensor([0.6203, 0.3797], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 9 - 367: dog - cat || Loss: 0.9327746033668518\n",
      "tensor([0., 1.]) tensor([0.6195, 0.3805], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 9 - 368: dog - cat || Loss: 0.9319720268249512\n",
      "tensor([0., 1.]) tensor([0.6187, 0.3813], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 9 - 369: dog - cat || Loss: 0.9311690330505371\n",
      "tensor([0., 1.]) tensor([0.6179, 0.3821], grad_fn=<SoftmaxBackward0>)\n",
      "=====epoch:10=====\n",
      "Epoch 10 - 0: cat - cat || Loss: 0.6961575746536255\n",
      "tensor([1., 0.]) tensor([0.6171, 0.3829], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 10 - 1: cat - cat || Loss: 0.6968001127243042\n",
      "tensor([1., 0.]) tensor([0.6165, 0.3835], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 10 - 2: cat - cat || Loss: 0.697297990322113\n",
      "tensor([1., 0.]) tensor([0.6160, 0.3840], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 10 - 3: cat - cat || Loss: 0.6976653337478638\n",
      "tensor([1., 0.]) tensor([0.6156, 0.3844], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 10 - 4: cat - cat || Loss: 0.6979153156280518\n",
      "tensor([1., 0.]) tensor([0.6153, 0.3847], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 10 - 5: cat - cat || Loss: 0.698059618473053\n",
      "tensor([1., 0.]) tensor([0.6152, 0.3848], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 10 - 6: cat - cat || Loss: 0.6981089115142822\n",
      "tensor([1., 0.]) tensor([0.6152, 0.3848], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 10 - 7: cat - cat || Loss: 0.6980724334716797\n",
      "tensor([1., 0.]) tensor([0.6152, 0.3848], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 10 - 8: cat - cat || Loss: 0.6979590654373169\n",
      "tensor([1., 0.]) tensor([0.6153, 0.3847], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 10 - 9: cat - cat || Loss: 0.6977763175964355\n",
      "tensor([1., 0.]) tensor([0.6155, 0.3845], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 10 - 10: cat - cat || Loss: 0.6975311636924744\n",
      "tensor([1., 0.]) tensor([0.6157, 0.3843], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 10 - 11: cat - cat || Loss: 0.6972300410270691\n",
      "tensor([1., 0.]) tensor([0.6160, 0.3840], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 10 - 12: cat - cat || Loss: 0.6968784332275391\n",
      "tensor([1., 0.]) tensor([0.6164, 0.3836], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 10 - 13: cat - cat || Loss: 0.696481466293335\n",
      "tensor([1., 0.]) tensor([0.6168, 0.3832], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 10 - 14: cat - cat || Loss: 0.6960436701774597\n",
      "tensor([1., 0.]) tensor([0.6172, 0.3828], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 10 - 15: cat - cat || Loss: 0.6955691576004028\n",
      "tensor([1., 0.]) tensor([0.6177, 0.3823], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 10 - 16: cat - cat || Loss: 0.6950616240501404\n",
      "tensor([1., 0.]) tensor([0.6182, 0.3818], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 10 - 17: cat - cat || Loss: 0.6945245265960693\n",
      "tensor([1., 0.]) tensor([0.6187, 0.3813], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 10 - 18: cat - cat || Loss: 0.6939607858657837\n",
      "tensor([1., 0.]) tensor([0.6193, 0.3807], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 10 - 19: cat - cat || Loss: 0.6933730840682983\n",
      "tensor([1., 0.]) tensor([0.6199, 0.3801], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 10 - 20: cat - cat || Loss: 0.6927639245986938\n",
      "tensor([1., 0.]) tensor([0.6205, 0.3795], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 10 - 21: cat - cat || Loss: 0.6921355724334717\n",
      "tensor([1., 0.]) tensor([0.6211, 0.3789], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 10 - 22: cat - cat || Loss: 0.6914899349212646\n",
      "tensor([1., 0.]) tensor([0.6218, 0.3782], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 10 - 23: cat - cat || Loss: 0.6908286809921265\n",
      "tensor([1., 0.]) tensor([0.6224, 0.3776], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 10 - 24: cat - cat || Loss: 0.6901535987854004\n",
      "tensor([1., 0.]) tensor([0.6231, 0.3769], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 10 - 25: cat - cat || Loss: 0.6894659996032715\n",
      "tensor([1., 0.]) tensor([0.6238, 0.3762], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 10 - 26: cat - cat || Loss: 0.6887673735618591\n",
      "tensor([1., 0.]) tensor([0.6245, 0.3755], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 10 - 27: cat - cat || Loss: 0.6880585551261902\n",
      "tensor([1., 0.]) tensor([0.6252, 0.3748], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 10 - 28: cat - cat || Loss: 0.6873408555984497\n",
      "tensor([1., 0.]) tensor([0.6259, 0.3741], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 10 - 29: cat - cat || Loss: 0.6866151094436646\n",
      "tensor([1., 0.]) tensor([0.6266, 0.3734], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 10 - 30: cat - cat || Loss: 0.6858824491500854\n",
      "tensor([1., 0.]) tensor([0.6274, 0.3726], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 10 - 31: cat - cat || Loss: 0.685143232345581\n",
      "tensor([1., 0.]) tensor([0.6281, 0.3719], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 10 - 32: cat - cat || Loss: 0.6843981742858887\n",
      "tensor([1., 0.]) tensor([0.6289, 0.3711], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 10 - 33: cat - cat || Loss: 0.6836481690406799\n",
      "tensor([1., 0.]) tensor([0.6296, 0.3704], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 10 - 34: cat - cat || Loss: 0.6828934550285339\n",
      "tensor([1., 0.]) tensor([0.6304, 0.3696], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 10 - 35: cat - cat || Loss: 0.682134747505188\n",
      "tensor([1., 0.]) tensor([0.6311, 0.3689], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 10 - 36: cat - cat || Loss: 0.6813726425170898\n",
      "tensor([1., 0.]) tensor([0.6319, 0.3681], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 10 - 37: cat - cat || Loss: 0.6806071996688843\n",
      "tensor([1., 0.]) tensor([0.6327, 0.3673], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 10 - 38: cat - cat || Loss: 0.6798390746116638\n",
      "tensor([1., 0.]) tensor([0.6334, 0.3666], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 10 - 39: cat - cat || Loss: 0.6790684461593628\n",
      "tensor([1., 0.]) tensor([0.6342, 0.3658], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 10 - 40: cat - cat || Loss: 0.6782960295677185\n",
      "tensor([1., 0.]) tensor([0.6350, 0.3650], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 10 - 41: cat - cat || Loss: 0.6775214672088623\n",
      "tensor([1., 0.]) tensor([0.6357, 0.3643], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 10 - 42: cat - cat || Loss: 0.6767454147338867\n",
      "tensor([1., 0.]) tensor([0.6365, 0.3635], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 10 - 43: cat - cat || Loss: 0.675967812538147\n",
      "tensor([1., 0.]) tensor([0.6373, 0.3627], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 10 - 44: cat - cat || Loss: 0.675189197063446\n",
      "tensor([1., 0.]) tensor([0.6381, 0.3619], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 10 - 45: cat - cat || Loss: 0.6744093894958496\n",
      "tensor([1., 0.]) tensor([0.6389, 0.3611], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 10 - 46: cat - cat || Loss: 0.673628568649292\n",
      "tensor([1., 0.]) tensor([0.6396, 0.3604], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 10 - 47: cat - cat || Loss: 0.6728470325469971\n",
      "tensor([1., 0.]) tensor([0.6404, 0.3596], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 10 - 48: cat - cat || Loss: 0.6720649600028992\n",
      "tensor([1., 0.]) tensor([0.6412, 0.3588], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 10 - 49: cat - cat || Loss: 0.6712823510169983\n",
      "tensor([1., 0.]) tensor([0.6420, 0.3580], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 10 - 50: cat - cat || Loss: 0.670499324798584\n",
      "tensor([1., 0.]) tensor([0.6428, 0.3572], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 10 - 51: cat - cat || Loss: 0.6697161197662354\n",
      "tensor([1., 0.]) tensor([0.6435, 0.3565], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 10 - 52: cat - cat || Loss: 0.6689326763153076\n",
      "tensor([1., 0.]) tensor([0.6443, 0.3557], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 10 - 53: cat - cat || Loss: 0.6681489944458008\n",
      "tensor([1., 0.]) tensor([0.6451, 0.3549], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 10 - 54: cat - cat || Loss: 0.6673653721809387\n",
      "tensor([1., 0.]) tensor([0.6459, 0.3541], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 10 - 55: cat - cat || Loss: 0.6665817499160767\n",
      "tensor([1., 0.]) tensor([0.6467, 0.3533], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 10 - 56: cat - cat || Loss: 0.665798008441925\n",
      "tensor([1., 0.]) tensor([0.6475, 0.3525], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 10 - 57: cat - cat || Loss: 0.6650143265724182\n",
      "tensor([1., 0.]) tensor([0.6482, 0.3518], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 10 - 58: cat - cat || Loss: 0.6642309427261353\n",
      "tensor([1., 0.]) tensor([0.6490, 0.3510], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 10 - 59: cat - cat || Loss: 0.6634477376937866\n",
      "tensor([1., 0.]) tensor([0.6498, 0.3502], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 10 - 60: cat - cat || Loss: 0.6626647114753723\n",
      "tensor([1., 0.]) tensor([0.6506, 0.3494], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 10 - 61: cat - cat || Loss: 0.6618819236755371\n",
      "tensor([1., 0.]) tensor([0.6514, 0.3486], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 10 - 62: cat - cat || Loss: 0.6610993146896362\n",
      "tensor([1., 0.]) tensor([0.6522, 0.3478], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 10 - 63: cat - cat || Loss: 0.6603172421455383\n",
      "tensor([1., 0.]) tensor([0.6529, 0.3471], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 10 - 64: cat - cat || Loss: 0.6595354080200195\n",
      "tensor([1., 0.]) tensor([0.6537, 0.3463], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 10 - 65: cat - cat || Loss: 0.6587538719177246\n",
      "tensor([1., 0.]) tensor([0.6545, 0.3455], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 10 - 66: cat - cat || Loss: 0.6579729318618774\n",
      "tensor([1., 0.]) tensor([0.6553, 0.3447], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 10 - 67: cat - cat || Loss: 0.6571923494338989\n",
      "tensor([1., 0.]) tensor([0.6561, 0.3439], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 10 - 68: cat - cat || Loss: 0.6564120650291443\n",
      "tensor([1., 0.]) tensor([0.6568, 0.3432], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 10 - 69: cat - cat || Loss: 0.6556322574615479\n",
      "tensor([1., 0.]) tensor([0.6576, 0.3424], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 10 - 70: cat - cat || Loss: 0.654853105545044\n",
      "tensor([1., 0.]) tensor([0.6584, 0.3416], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 10 - 71: cat - cat || Loss: 0.6540745496749878\n",
      "tensor([1., 0.]) tensor([0.6592, 0.3408], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 10 - 72: cat - cat || Loss: 0.6532962322235107\n",
      "tensor([1., 0.]) tensor([0.6600, 0.3400], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 10 - 73: cat - cat || Loss: 0.6525185108184814\n",
      "tensor([1., 0.]) tensor([0.6607, 0.3393], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 10 - 74: cat - cat || Loss: 0.6517411470413208\n",
      "tensor([1., 0.]) tensor([0.6615, 0.3385], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 10 - 75: cat - cat || Loss: 0.6509644985198975\n",
      "tensor([1., 0.]) tensor([0.6623, 0.3377], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 10 - 76: cat - cat || Loss: 0.6501883864402771\n",
      "tensor([1., 0.]) tensor([0.6631, 0.3369], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 10 - 77: cat - cat || Loss: 0.6494128704071045\n",
      "tensor([1., 0.]) tensor([0.6638, 0.3362], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 10 - 78: cat - cat || Loss: 0.6486376523971558\n",
      "tensor([1., 0.]) tensor([0.6646, 0.3354], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 10 - 79: cat - cat || Loss: 0.6478631496429443\n",
      "tensor([1., 0.]) tensor([0.6654, 0.3346], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 10 - 80: cat - cat || Loss: 0.6470891833305359\n",
      "tensor([1., 0.]) tensor([0.6662, 0.3338], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 10 - 81: cat - cat || Loss: 0.6463156938552856\n",
      "tensor([1., 0.]) tensor([0.6669, 0.3331], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 10 - 82: cat - cat || Loss: 0.6455428004264832\n",
      "tensor([1., 0.]) tensor([0.6677, 0.3323], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 10 - 83: cat - cat || Loss: 0.6447706818580627\n",
      "tensor([1., 0.]) tensor([0.6685, 0.3315], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 10 - 84: cat - cat || Loss: 0.6439989805221558\n",
      "tensor([1., 0.]) tensor([0.6693, 0.3307], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 10 - 85: cat - cat || Loss: 0.6432279348373413\n",
      "tensor([1., 0.]) tensor([0.6700, 0.3300], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 10 - 86: cat - cat || Loss: 0.6424574255943298\n",
      "tensor([1., 0.]) tensor([0.6708, 0.3292], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 10 - 87: cat - cat || Loss: 0.6416876316070557\n",
      "tensor([1., 0.]) tensor([0.6716, 0.3284], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 10 - 88: cat - cat || Loss: 0.6409183144569397\n",
      "tensor([1., 0.]) tensor([0.6723, 0.3277], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 10 - 89: cat - cat || Loss: 0.6401496529579163\n",
      "tensor([1., 0.]) tensor([0.6731, 0.3269], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 10 - 90: cat - cat || Loss: 0.6393817067146301\n",
      "tensor([1., 0.]) tensor([0.6739, 0.3261], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 10 - 91: cat - cat || Loss: 0.638614296913147\n",
      "tensor([1., 0.]) tensor([0.6746, 0.3254], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 10 - 92: cat - cat || Loss: 0.6378475427627563\n",
      "tensor([1., 0.]) tensor([0.6754, 0.3246], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 10 - 93: cat - cat || Loss: 0.6370815634727478\n",
      "tensor([1., 0.]) tensor([0.6762, 0.3238], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 10 - 94: cat - cat || Loss: 0.636316180229187\n",
      "tensor([1., 0.]) tensor([0.6769, 0.3231], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 10 - 95: cat - cat || Loss: 0.6355514526367188\n",
      "tensor([1., 0.]) tensor([0.6777, 0.3223], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 10 - 96: cat - cat || Loss: 0.6347874402999878\n",
      "tensor([1., 0.]) tensor([0.6785, 0.3215], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 10 - 97: cat - cat || Loss: 0.6340240836143494\n",
      "tensor([1., 0.]) tensor([0.6792, 0.3208], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 10 - 98: cat - cat || Loss: 0.6332612037658691\n",
      "tensor([1., 0.]) tensor([0.6800, 0.3200], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 10 - 99: cat - cat || Loss: 0.6324992179870605\n",
      "tensor([1., 0.]) tensor([0.6808, 0.3192], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 10 - 100: cat - cat || Loss: 0.6317376494407654\n",
      "tensor([1., 0.]) tensor([0.6815, 0.3185], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 10 - 101: cat - cat || Loss: 0.6309767961502075\n",
      "tensor([1., 0.]) tensor([0.6823, 0.3177], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 10 - 102: cat - cat || Loss: 0.6302165985107422\n",
      "tensor([1., 0.]) tensor([0.6830, 0.3170], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 10 - 103: cat - cat || Loss: 0.6294570565223694\n",
      "tensor([1., 0.]) tensor([0.6838, 0.3162], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 10 - 104: cat - cat || Loss: 0.6286982297897339\n",
      "tensor([1., 0.]) tensor([0.6846, 0.3154], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 10 - 105: cat - cat || Loss: 0.6279400587081909\n",
      "tensor([1., 0.]) tensor([0.6853, 0.3147], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 10 - 106: cat - cat || Loss: 0.6271826028823853\n",
      "tensor([1., 0.]) tensor([0.6861, 0.3139], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 10 - 107: cat - cat || Loss: 0.6264257431030273\n",
      "tensor([1., 0.]) tensor([0.6868, 0.3132], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 10 - 108: cat - cat || Loss: 0.625669538974762\n",
      "tensor([1., 0.]) tensor([0.6876, 0.3124], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 10 - 109: cat - cat || Loss: 0.6249141097068787\n",
      "tensor([1., 0.]) tensor([0.6883, 0.3117], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 10 - 110: cat - cat || Loss: 0.6241592764854431\n",
      "tensor([1., 0.]) tensor([0.6891, 0.3109], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 10 - 111: cat - cat || Loss: 0.6234051585197449\n",
      "tensor([1., 0.]) tensor([0.6899, 0.3101], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 10 - 112: cat - cat || Loss: 0.6226518154144287\n",
      "tensor([1., 0.]) tensor([0.6906, 0.3094], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 10 - 113: cat - cat || Loss: 0.6218991279602051\n",
      "tensor([1., 0.]) tensor([0.6914, 0.3086], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 10 - 114: cat - cat || Loss: 0.621147096157074\n",
      "tensor([1., 0.]) tensor([0.6921, 0.3079], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 10 - 115: cat - cat || Loss: 0.6203958988189697\n",
      "tensor([1., 0.]) tensor([0.6929, 0.3071], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 10 - 116: cat - cat || Loss: 0.6196452379226685\n",
      "tensor([1., 0.]) tensor([0.6936, 0.3064], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 10 - 117: cat - cat || Loss: 0.618895411491394\n",
      "tensor([1., 0.]) tensor([0.6944, 0.3056], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 10 - 118: cat - cat || Loss: 0.6181463003158569\n",
      "tensor([1., 0.]) tensor([0.6951, 0.3049], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 10 - 119: cat - cat || Loss: 0.6173979640007019\n",
      "tensor([1., 0.]) tensor([0.6959, 0.3041], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 10 - 120: cat - cat || Loss: 0.6166502237319946\n",
      "tensor([1., 0.]) tensor([0.6966, 0.3034], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 10 - 121: cat - cat || Loss: 0.6159031391143799\n",
      "tensor([1., 0.]) tensor([0.6974, 0.3026], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 10 - 122: cat - cat || Loss: 0.6151569485664368\n",
      "tensor([1., 0.]) tensor([0.6981, 0.3019], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 10 - 123: cat - cat || Loss: 0.6144113540649414\n",
      "tensor([1., 0.]) tensor([0.6989, 0.3011], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 10 - 124: cat - cat || Loss: 0.6136666536331177\n",
      "tensor([1., 0.]) tensor([0.6996, 0.3004], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 10 - 125: cat - cat || Loss: 0.6129226088523865\n",
      "tensor([1., 0.]) tensor([0.7003, 0.2997], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 10 - 126: cat - cat || Loss: 0.6121792197227478\n",
      "tensor([1., 0.]) tensor([0.7011, 0.2989], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 10 - 127: cat - cat || Loss: 0.6114366054534912\n",
      "tensor([1., 0.]) tensor([0.7018, 0.2982], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 10 - 128: cat - cat || Loss: 0.6106948256492615\n",
      "tensor([1., 0.]) tensor([0.7026, 0.2974], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 10 - 129: cat - cat || Loss: 0.6099537014961243\n",
      "tensor([1., 0.]) tensor([0.7033, 0.2967], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 10 - 130: cat - cat || Loss: 0.6092133522033691\n",
      "tensor([1., 0.]) tensor([0.7040, 0.2960], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 10 - 131: cat - cat || Loss: 0.6084736585617065\n",
      "tensor([1., 0.]) tensor([0.7048, 0.2952], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 10 - 132: cat - cat || Loss: 0.6077348589897156\n",
      "tensor([1., 0.]) tensor([0.7055, 0.2945], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 10 - 133: cat - cat || Loss: 0.6069967746734619\n",
      "tensor([1., 0.]) tensor([0.7063, 0.2937], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 10 - 134: cat - cat || Loss: 0.6062593460083008\n",
      "tensor([1., 0.]) tensor([0.7070, 0.2930], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 10 - 135: cat - cat || Loss: 0.605522871017456\n",
      "tensor([1., 0.]) tensor([0.7077, 0.2923], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 10 - 136: cat - cat || Loss: 0.6047869920730591\n",
      "tensor([1., 0.]) tensor([0.7085, 0.2915], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 10 - 137: cat - cat || Loss: 0.6040518879890442\n",
      "tensor([1., 0.]) tensor([0.7092, 0.2908], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 10 - 138: cat - cat || Loss: 0.6033176183700562\n",
      "tensor([1., 0.]) tensor([0.7099, 0.2901], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 10 - 139: cat - cat || Loss: 0.6025840044021606\n",
      "tensor([1., 0.]) tensor([0.7107, 0.2893], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 10 - 140: cat - cat || Loss: 0.601851224899292\n",
      "tensor([1., 0.]) tensor([0.7114, 0.2886], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 10 - 141: cat - cat || Loss: 0.6011192798614502\n",
      "tensor([1., 0.]) tensor([0.7121, 0.2879], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 10 - 142: cat - cat || Loss: 0.6003880500793457\n",
      "tensor([1., 0.]) tensor([0.7129, 0.2871], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 10 - 143: cat - cat || Loss: 0.5996576547622681\n",
      "tensor([1., 0.]) tensor([0.7136, 0.2864], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 10 - 144: cat - cat || Loss: 0.5989280343055725\n",
      "tensor([1., 0.]) tensor([0.7143, 0.2857], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 10 - 145: cat - cat || Loss: 0.5981991291046143\n",
      "tensor([1., 0.]) tensor([0.7151, 0.2849], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 10 - 146: cat - cat || Loss: 0.5974711179733276\n",
      "tensor([1., 0.]) tensor([0.7158, 0.2842], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 10 - 147: cat - cat || Loss: 0.5967438817024231\n",
      "tensor([1., 0.]) tensor([0.7165, 0.2835], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 10 - 148: cat - cat || Loss: 0.5960173010826111\n",
      "tensor([1., 0.]) tensor([0.7172, 0.2828], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 10 - 149: cat - cat || Loss: 0.5952917337417603\n",
      "tensor([1., 0.]) tensor([0.7180, 0.2820], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 10 - 150: cat - cat || Loss: 0.594566822052002\n",
      "tensor([1., 0.]) tensor([0.7187, 0.2813], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 10 - 151: cat - cat || Loss: 0.5938428044319153\n",
      "tensor([1., 0.]) tensor([0.7194, 0.2806], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 10 - 152: cat - cat || Loss: 0.5931195020675659\n",
      "tensor([1., 0.]) tensor([0.7201, 0.2799], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 10 - 153: cat - cat || Loss: 0.5923970937728882\n",
      "tensor([1., 0.]) tensor([0.7209, 0.2791], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 10 - 154: cat - cat || Loss: 0.5916754007339478\n",
      "tensor([1., 0.]) tensor([0.7216, 0.2784], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 10 - 155: cat - cat || Loss: 0.5909545421600342\n",
      "tensor([1., 0.]) tensor([0.7223, 0.2777], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 10 - 156: cat - cat || Loss: 0.590234637260437\n",
      "tensor([1., 0.]) tensor([0.7230, 0.2770], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 10 - 157: cat - cat || Loss: 0.5895154476165771\n",
      "tensor([1., 0.]) tensor([0.7237, 0.2763], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 10 - 158: cat - cat || Loss: 0.5887970924377441\n",
      "tensor([1., 0.]) tensor([0.7245, 0.2755], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 10 - 159: cat - cat || Loss: 0.588079571723938\n",
      "tensor([1., 0.]) tensor([0.7252, 0.2748], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 10 - 160: cat - cat || Loss: 0.5873627066612244\n",
      "tensor([1., 0.]) tensor([0.7259, 0.2741], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 10 - 161: cat - cat || Loss: 0.5866469144821167\n",
      "tensor([1., 0.]) tensor([0.7266, 0.2734], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 10 - 162: cat - cat || Loss: 0.5859318971633911\n",
      "tensor([1., 0.]) tensor([0.7273, 0.2727], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 10 - 163: cat - cat || Loss: 0.5852174758911133\n",
      "tensor([1., 0.]) tensor([0.7280, 0.2720], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 10 - 164: cat - cat || Loss: 0.584504246711731\n",
      "tensor([1., 0.]) tensor([0.7288, 0.2712], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 10 - 165: cat - cat || Loss: 0.5837917327880859\n",
      "tensor([1., 0.]) tensor([0.7295, 0.2705], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 10 - 166: cat - cat || Loss: 0.583079993724823\n",
      "tensor([1., 0.]) tensor([0.7302, 0.2698], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 10 - 167: cat - cat || Loss: 0.5823690891265869\n",
      "tensor([1., 0.]) tensor([0.7309, 0.2691], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 10 - 168: cat - cat || Loss: 0.5816590785980225\n",
      "tensor([1., 0.]) tensor([0.7316, 0.2684], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 10 - 169: cat - cat || Loss: 0.5809497833251953\n",
      "tensor([1., 0.]) tensor([0.7323, 0.2677], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 10 - 170: cat - cat || Loss: 0.5802415609359741\n",
      "tensor([1., 0.]) tensor([0.7330, 0.2670], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 10 - 171: cat - cat || Loss: 0.579534113407135\n",
      "tensor([1., 0.]) tensor([0.7337, 0.2663], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 10 - 172: cat - cat || Loss: 0.5788275003433228\n",
      "tensor([1., 0.]) tensor([0.7344, 0.2656], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 10 - 173: cat - cat || Loss: 0.5781217813491821\n",
      "tensor([1., 0.]) tensor([0.7351, 0.2649], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 10 - 174: cat - cat || Loss: 0.5774168968200684\n",
      "tensor([1., 0.]) tensor([0.7358, 0.2642], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 10 - 175: cat - cat || Loss: 0.5767128467559814\n",
      "tensor([1., 0.]) tensor([0.7365, 0.2635], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 10 - 176: cat - cat || Loss: 0.5760096311569214\n",
      "tensor([1., 0.]) tensor([0.7373, 0.2627], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 10 - 177: cat - cat || Loss: 0.5753073692321777\n",
      "tensor([1., 0.]) tensor([0.7380, 0.2620], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 10 - 178: cat - cat || Loss: 0.5746058821678162\n",
      "tensor([1., 0.]) tensor([0.7387, 0.2613], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 10 - 179: cat - cat || Loss: 0.573905348777771\n",
      "tensor([1., 0.]) tensor([0.7394, 0.2606], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 10 - 180: cat - cat || Loss: 0.5732055902481079\n",
      "tensor([1., 0.]) tensor([0.7401, 0.2599], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 10 - 181: cat - cat || Loss: 0.5725067853927612\n",
      "tensor([1., 0.]) tensor([0.7408, 0.2592], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 10 - 182: cat - cat || Loss: 0.571808934211731\n",
      "tensor([1., 0.]) tensor([0.7415, 0.2585], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 10 - 183: cat - cat || Loss: 0.5711119174957275\n",
      "tensor([1., 0.]) tensor([0.7421, 0.2579], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 10 - 184: cat - cat || Loss: 0.570415735244751\n",
      "tensor([1., 0.]) tensor([0.7428, 0.2572], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 10 - 185: cat - cat || Loss: 0.5697205066680908\n",
      "tensor([1., 0.]) tensor([0.7435, 0.2565], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 10 - 186: cat - cat || Loss: 0.569025993347168\n",
      "tensor([1., 0.]) tensor([0.7442, 0.2558], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 10 - 187: cat - cat || Loss: 0.5683325529098511\n",
      "tensor([1., 0.]) tensor([0.7449, 0.2551], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 10 - 188: cat - cat || Loss: 0.5676398873329163\n",
      "tensor([1., 0.]) tensor([0.7456, 0.2544], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 10 - 189: cat - cat || Loss: 0.5669480562210083\n",
      "tensor([1., 0.]) tensor([0.7463, 0.2537], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 10 - 190: dog - cat || Loss: 1.0602662563323975\n",
      "tensor([0., 1.]) tensor([0.7470, 0.2530], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 10 - 191: dog - cat || Loss: 1.0608190298080444\n",
      "tensor([0., 1.]) tensor([0.7476, 0.2524], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 10 - 192: dog - cat || Loss: 1.061247706413269\n",
      "tensor([0., 1.]) tensor([0.7480, 0.2520], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 10 - 193: dog - cat || Loss: 1.0615646839141846\n",
      "tensor([0., 1.]) tensor([0.7483, 0.2517], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 10 - 194: dog - cat || Loss: 1.061781406402588\n",
      "tensor([0., 1.]) tensor([0.7485, 0.2515], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 10 - 195: dog - cat || Loss: 1.0619081258773804\n",
      "tensor([0., 1.]) tensor([0.7486, 0.2514], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 10 - 196: dog - cat || Loss: 1.0619534254074097\n",
      "tensor([0., 1.]) tensor([0.7487, 0.2513], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 10 - 197: dog - cat || Loss: 1.0619258880615234\n",
      "tensor([0., 1.]) tensor([0.7487, 0.2513], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 10 - 198: dog - cat || Loss: 1.0618326663970947\n",
      "tensor([0., 1.]) tensor([0.7486, 0.2514], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 10 - 199: dog - cat || Loss: 1.0616801977157593\n",
      "tensor([0., 1.]) tensor([0.7484, 0.2516], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 10 - 200: dog - cat || Loss: 1.0614745616912842\n",
      "tensor([0., 1.]) tensor([0.7482, 0.2518], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 10 - 201: dog - cat || Loss: 1.0612208843231201\n",
      "tensor([0., 1.]) tensor([0.7480, 0.2520], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 10 - 202: dog - cat || Loss: 1.0609240531921387\n",
      "tensor([0., 1.]) tensor([0.7477, 0.2523], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 10 - 203: dog - cat || Loss: 1.0605882406234741\n",
      "tensor([0., 1.]) tensor([0.7473, 0.2527], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 10 - 204: dog - cat || Loss: 1.0602171421051025\n",
      "tensor([0., 1.]) tensor([0.7470, 0.2530], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 10 - 205: dog - cat || Loss: 1.059814453125\n",
      "tensor([0., 1.]) tensor([0.7466, 0.2534], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 10 - 206: dog - cat || Loss: 1.0593831539154053\n",
      "tensor([0., 1.]) tensor([0.7461, 0.2539], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 10 - 207: dog - cat || Loss: 1.0589264631271362\n",
      "tensor([0., 1.]) tensor([0.7457, 0.2543], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 10 - 208: dog - cat || Loss: 1.0584460496902466\n",
      "tensor([0., 1.]) tensor([0.7452, 0.2548], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 10 - 209: dog - cat || Loss: 1.0579447746276855\n",
      "tensor([0., 1.]) tensor([0.7447, 0.2553], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 10 - 210: dog - cat || Loss: 1.0574244260787964\n",
      "tensor([0., 1.]) tensor([0.7442, 0.2558], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 10 - 211: dog - cat || Loss: 1.056887149810791\n",
      "tensor([0., 1.]) tensor([0.7436, 0.2564], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 10 - 212: dog - cat || Loss: 1.0563338994979858\n",
      "tensor([0., 1.]) tensor([0.7431, 0.2569], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 10 - 213: dog - cat || Loss: 1.0557667016983032\n",
      "tensor([0., 1.]) tensor([0.7425, 0.2575], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 10 - 214: dog - cat || Loss: 1.0551869869232178\n",
      "tensor([0., 1.]) tensor([0.7419, 0.2581], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 10 - 215: dog - cat || Loss: 1.0545954704284668\n",
      "tensor([0., 1.]) tensor([0.7413, 0.2587], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 10 - 216: dog - cat || Loss: 1.0539937019348145\n",
      "tensor([0., 1.]) tensor([0.7407, 0.2593], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 10 - 217: dog - cat || Loss: 1.053382158279419\n",
      "tensor([0., 1.]) tensor([0.7401, 0.2599], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 10 - 218: dog - cat || Loss: 1.0527621507644653\n",
      "tensor([0., 1.]) tensor([0.7395, 0.2605], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 10 - 219: dog - cat || Loss: 1.0521342754364014\n",
      "tensor([0., 1.]) tensor([0.7389, 0.2611], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 10 - 220: dog - cat || Loss: 1.0514992475509644\n",
      "tensor([0., 1.]) tensor([0.7382, 0.2618], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 10 - 221: dog - cat || Loss: 1.0508577823638916\n",
      "tensor([0., 1.]) tensor([0.7376, 0.2624], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 10 - 222: dog - cat || Loss: 1.0502102375030518\n",
      "tensor([0., 1.]) tensor([0.7369, 0.2631], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 10 - 223: dog - cat || Loss: 1.0495573282241821\n",
      "tensor([0., 1.]) tensor([0.7363, 0.2637], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 10 - 224: dog - cat || Loss: 1.0488992929458618\n",
      "tensor([0., 1.]) tensor([0.7356, 0.2644], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 10 - 225: dog - cat || Loss: 1.0482369661331177\n",
      "tensor([0., 1.]) tensor([0.7350, 0.2650], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 10 - 226: dog - cat || Loss: 1.0475704669952393\n",
      "tensor([0., 1.]) tensor([0.7343, 0.2657], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 10 - 227: dog - cat || Loss: 1.0469000339508057\n",
      "tensor([0., 1.]) tensor([0.7336, 0.2664], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 10 - 228: dog - cat || Loss: 1.046226143836975\n",
      "tensor([0., 1.]) tensor([0.7330, 0.2670], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 10 - 229: dog - cat || Loss: 1.0455490350723267\n",
      "tensor([0., 1.]) tensor([0.7323, 0.2677], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 10 - 230: dog - cat || Loss: 1.0448687076568604\n",
      "tensor([0., 1.]) tensor([0.7316, 0.2684], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 10 - 231: dog - cat || Loss: 1.0441856384277344\n",
      "tensor([0., 1.]) tensor([0.7309, 0.2691], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 10 - 232: dog - cat || Loss: 1.0434999465942383\n",
      "tensor([0., 1.]) tensor([0.7302, 0.2698], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 10 - 233: dog - cat || Loss: 1.0428119897842407\n",
      "tensor([0., 1.]) tensor([0.7296, 0.2704], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 10 - 234: dog - cat || Loss: 1.0421218872070312\n",
      "tensor([0., 1.]) tensor([0.7289, 0.2711], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 10 - 235: dog - cat || Loss: 1.0414294004440308\n",
      "tensor([0., 1.]) tensor([0.7282, 0.2718], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 10 - 236: dog - cat || Loss: 1.0407352447509766\n",
      "tensor([0., 1.]) tensor([0.7275, 0.2725], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 10 - 237: dog - cat || Loss: 1.0400390625\n",
      "tensor([0., 1.]) tensor([0.7268, 0.2732], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 10 - 238: dog - cat || Loss: 1.0393412113189697\n",
      "tensor([0., 1.]) tensor([0.7261, 0.2739], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 10 - 239: dog - cat || Loss: 1.0386415719985962\n",
      "tensor([0., 1.]) tensor([0.7254, 0.2746], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 10 - 240: dog - cat || Loss: 1.0379406213760376\n",
      "tensor([0., 1.]) tensor([0.7247, 0.2753], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 10 - 241: dog - cat || Loss: 1.0372378826141357\n",
      "tensor([0., 1.]) tensor([0.7240, 0.2760], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 10 - 242: dog - cat || Loss: 1.0365339517593384\n",
      "tensor([0., 1.]) tensor([0.7233, 0.2767], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 10 - 243: dog - cat || Loss: 1.0358285903930664\n",
      "tensor([0., 1.]) tensor([0.7226, 0.2774], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 10 - 244: dog - cat || Loss: 1.035122275352478\n",
      "tensor([0., 1.]) tensor([0.7219, 0.2781], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 10 - 245: dog - cat || Loss: 1.0344144105911255\n",
      "tensor([0., 1.]) tensor([0.7212, 0.2788], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 10 - 246: dog - cat || Loss: 1.0337053537368774\n",
      "tensor([0., 1.]) tensor([0.7204, 0.2796], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 10 - 247: dog - cat || Loss: 1.0329951047897339\n",
      "tensor([0., 1.]) tensor([0.7197, 0.2803], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 10 - 248: dog - cat || Loss: 1.032283902168274\n",
      "tensor([0., 1.]) tensor([0.7190, 0.2810], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 10 - 249: dog - cat || Loss: 1.0315715074539185\n",
      "tensor([0., 1.]) tensor([0.7183, 0.2817], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 10 - 250: dog - cat || Loss: 1.0308583974838257\n",
      "tensor([0., 1.]) tensor([0.7176, 0.2824], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 10 - 251: dog - cat || Loss: 1.0301440954208374\n",
      "tensor([0., 1.]) tensor([0.7169, 0.2831], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 10 - 252: dog - cat || Loss: 1.0294286012649536\n",
      "tensor([0., 1.]) tensor([0.7162, 0.2838], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 10 - 253: dog - cat || Loss: 1.028712272644043\n",
      "tensor([0., 1.]) tensor([0.7155, 0.2845], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 10 - 254: dog - cat || Loss: 1.0279951095581055\n",
      "tensor([0., 1.]) tensor([0.7147, 0.2853], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 10 - 255: dog - cat || Loss: 1.0272771120071411\n",
      "tensor([0., 1.]) tensor([0.7140, 0.2860], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 10 - 256: dog - cat || Loss: 1.0265581607818604\n",
      "tensor([0., 1.]) tensor([0.7133, 0.2867], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 10 - 257: dog - cat || Loss: 1.0258383750915527\n",
      "tensor([0., 1.]) tensor([0.7126, 0.2874], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 10 - 258: dog - cat || Loss: 1.0251176357269287\n",
      "tensor([0., 1.]) tensor([0.7119, 0.2881], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 10 - 259: dog - cat || Loss: 1.0243961811065674\n",
      "tensor([0., 1.]) tensor([0.7111, 0.2889], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 10 - 260: dog - cat || Loss: 1.0236737728118896\n",
      "tensor([0., 1.]) tensor([0.7104, 0.2896], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 10 - 261: dog - cat || Loss: 1.0229506492614746\n",
      "tensor([0., 1.]) tensor([0.7097, 0.2903], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 10 - 262: dog - cat || Loss: 1.0222266912460327\n",
      "tensor([0., 1.]) tensor([0.7090, 0.2910], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 10 - 263: dog - cat || Loss: 1.021501898765564\n",
      "tensor([0., 1.]) tensor([0.7082, 0.2918], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 10 - 264: dog - cat || Loss: 1.020776391029358\n",
      "tensor([0., 1.]) tensor([0.7075, 0.2925], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 10 - 265: dog - cat || Loss: 1.020050048828125\n",
      "tensor([0., 1.]) tensor([0.7068, 0.2932], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 10 - 266: dog - cat || Loss: 1.0193228721618652\n",
      "tensor([0., 1.]) tensor([0.7061, 0.2939], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 10 - 267: dog - cat || Loss: 1.0185949802398682\n",
      "tensor([0., 1.]) tensor([0.7053, 0.2947], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 10 - 268: dog - cat || Loss: 1.0178662538528442\n",
      "tensor([0., 1.]) tensor([0.7046, 0.2954], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 10 - 269: dog - cat || Loss: 1.0171369314193726\n",
      "tensor([0., 1.]) tensor([0.7039, 0.2961], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 10 - 270: dog - cat || Loss: 1.0164066553115845\n",
      "tensor([0., 1.]) tensor([0.7031, 0.2969], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 10 - 271: dog - cat || Loss: 1.0156757831573486\n",
      "tensor([0., 1.]) tensor([0.7024, 0.2976], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 10 - 272: dog - cat || Loss: 1.014944076538086\n",
      "tensor([0., 1.]) tensor([0.7017, 0.2983], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 10 - 273: dog - cat || Loss: 1.014211654663086\n",
      "tensor([0., 1.]) tensor([0.7010, 0.2991], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 10 - 274: dog - cat || Loss: 1.0134785175323486\n",
      "tensor([0., 1.]) tensor([0.7002, 0.2998], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 10 - 275: dog - cat || Loss: 1.0127445459365845\n",
      "tensor([0., 1.]) tensor([0.6995, 0.3005], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 10 - 276: dog - cat || Loss: 1.012010097503662\n",
      "tensor([0., 1.]) tensor([0.6987, 0.3013], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 10 - 277: dog - cat || Loss: 1.0112746953964233\n",
      "tensor([0., 1.]) tensor([0.6980, 0.3020], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 10 - 278: dog - cat || Loss: 1.0105386972427368\n",
      "tensor([0., 1.]) tensor([0.6973, 0.3027], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 10 - 279: dog - cat || Loss: 1.0098021030426025\n",
      "tensor([0., 1.]) tensor([0.6965, 0.3035], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 10 - 280: dog - cat || Loss: 1.0090646743774414\n",
      "tensor([0., 1.]) tensor([0.6958, 0.3042], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 10 - 281: dog - cat || Loss: 1.0083266496658325\n",
      "tensor([0., 1.]) tensor([0.6951, 0.3049], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 10 - 282: dog - cat || Loss: 1.0075877904891968\n",
      "tensor([0., 1.]) tensor([0.6943, 0.3057], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 10 - 283: dog - cat || Loss: 1.0068482160568237\n",
      "tensor([0., 1.]) tensor([0.6936, 0.3064], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 10 - 284: dog - cat || Loss: 1.006108045578003\n",
      "tensor([0., 1.]) tensor([0.6928, 0.3072], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 10 - 285: dog - cat || Loss: 1.0053672790527344\n",
      "tensor([0., 1.]) tensor([0.6921, 0.3079], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 10 - 286: dog - cat || Loss: 1.004625678062439\n",
      "tensor([0., 1.]) tensor([0.6914, 0.3086], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 10 - 287: dog - cat || Loss: 1.0038836002349854\n",
      "tensor([0., 1.]) tensor([0.6906, 0.3094], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 10 - 288: dog - cat || Loss: 1.0031408071517944\n",
      "tensor([0., 1.]) tensor([0.6899, 0.3101], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 10 - 289: dog - cat || Loss: 1.002397060394287\n",
      "tensor([0., 1.]) tensor([0.6891, 0.3109], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 10 - 290: dog - cat || Loss: 1.0016530752182007\n",
      "tensor([0., 1.]) tensor([0.6884, 0.3116], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 10 - 291: dog - cat || Loss: 1.0009082555770874\n",
      "tensor([0., 1.]) tensor([0.6876, 0.3124], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 10 - 292: dog - cat || Loss: 1.0001626014709473\n",
      "tensor([0., 1.]) tensor([0.6869, 0.3131], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 10 - 293: dog - cat || Loss: 0.9994165301322937\n",
      "tensor([0., 1.]) tensor([0.6862, 0.3138], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 10 - 294: dog - cat || Loss: 0.9986697435379028\n",
      "tensor([0., 1.]) tensor([0.6854, 0.3146], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 10 - 295: dog - cat || Loss: 0.9979223608970642\n",
      "tensor([0., 1.]) tensor([0.6847, 0.3153], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 10 - 296: dog - cat || Loss: 0.9971742630004883\n",
      "tensor([0., 1.]) tensor([0.6839, 0.3161], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 10 - 297: dog - cat || Loss: 0.9964255690574646\n",
      "tensor([0., 1.]) tensor([0.6832, 0.3168], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 10 - 298: dog - cat || Loss: 0.9956763386726379\n",
      "tensor([0., 1.]) tensor([0.6824, 0.3176], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 10 - 299: dog - cat || Loss: 0.9949264526367188\n",
      "tensor([0., 1.]) tensor([0.6817, 0.3183], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 10 - 300: dog - cat || Loss: 0.9941757321357727\n",
      "tensor([0., 1.]) tensor([0.6809, 0.3191], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 10 - 301: dog - cat || Loss: 0.9934245944023132\n",
      "tensor([0., 1.]) tensor([0.6802, 0.3198], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 10 - 302: dog - cat || Loss: 0.9926728010177612\n",
      "tensor([0., 1.]) tensor([0.6794, 0.3206], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 10 - 303: dog - cat || Loss: 0.9919203519821167\n",
      "tensor([0., 1.]) tensor([0.6787, 0.3213], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 10 - 304: dog - cat || Loss: 0.9911673069000244\n",
      "tensor([0., 1.]) tensor([0.6779, 0.3221], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 10 - 305: dog - cat || Loss: 0.9904134273529053\n",
      "tensor([0., 1.]) tensor([0.6772, 0.3228], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 10 - 306: dog - cat || Loss: 0.9896591901779175\n",
      "tensor([0., 1.]) tensor([0.6764, 0.3236], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 10 - 307: dog - cat || Loss: 0.9889041185379028\n",
      "tensor([0., 1.]) tensor([0.6756, 0.3244], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 10 - 308: dog - cat || Loss: 0.9881486296653748\n",
      "tensor([0., 1.]) tensor([0.6749, 0.3251], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 10 - 309: dog - cat || Loss: 0.9873926043510437\n",
      "tensor([0., 1.]) tensor([0.6741, 0.3259], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 10 - 310: dog - cat || Loss: 0.9866357445716858\n",
      "tensor([0., 1.]) tensor([0.6734, 0.3266], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 10 - 311: dog - cat || Loss: 0.9858784079551697\n",
      "tensor([0., 1.]) tensor([0.6726, 0.3274], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 10 - 312: dog - cat || Loss: 0.9851205348968506\n",
      "tensor([0., 1.]) tensor([0.6719, 0.3281], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 10 - 313: dog - cat || Loss: 0.9843619465827942\n",
      "tensor([0., 1.]) tensor([0.6711, 0.3289], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 10 - 314: dog - cat || Loss: 0.9836028218269348\n",
      "tensor([0., 1.]) tensor([0.6703, 0.3297], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 10 - 315: dog - cat || Loss: 0.9828431010246277\n",
      "tensor([0., 1.]) tensor([0.6696, 0.3304], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 10 - 316: dog - cat || Loss: 0.9820827841758728\n",
      "tensor([0., 1.]) tensor([0.6688, 0.3312], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 10 - 317: dog - cat || Loss: 0.9813218712806702\n",
      "tensor([0., 1.]) tensor([0.6681, 0.3319], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 10 - 318: dog - cat || Loss: 0.980560302734375\n",
      "tensor([0., 1.]) tensor([0.6673, 0.3327], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 10 - 319: dog - cat || Loss: 0.9797983765602112\n",
      "tensor([0., 1.]) tensor([0.6665, 0.3335], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 10 - 320: dog - cat || Loss: 0.9790357351303101\n",
      "tensor([0., 1.]) tensor([0.6658, 0.3342], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 10 - 321: dog - cat || Loss: 0.9782723784446716\n",
      "tensor([0., 1.]) tensor([0.6650, 0.3350], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 10 - 322: dog - cat || Loss: 0.9775086045265198\n",
      "tensor([0., 1.]) tensor([0.6642, 0.3358], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 10 - 323: dog - cat || Loss: 0.9767441749572754\n",
      "tensor([0., 1.]) tensor([0.6635, 0.3365], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 10 - 324: dog - cat || Loss: 0.975979208946228\n",
      "tensor([0., 1.]) tensor([0.6627, 0.3373], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 10 - 325: dog - cat || Loss: 0.9752136468887329\n",
      "tensor([0., 1.]) tensor([0.6620, 0.3380], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 10 - 326: dog - cat || Loss: 0.9744475483894348\n",
      "tensor([0., 1.]) tensor([0.6612, 0.3388], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 10 - 327: dog - cat || Loss: 0.9736807346343994\n",
      "tensor([0., 1.]) tensor([0.6604, 0.3396], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 10 - 328: dog - cat || Loss: 0.9729135036468506\n",
      "tensor([0., 1.]) tensor([0.6597, 0.3403], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 10 - 329: dog - cat || Loss: 0.9721457958221436\n",
      "tensor([0., 1.]) tensor([0.6589, 0.3411], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 10 - 330: dog - cat || Loss: 0.9713772535324097\n",
      "tensor([0., 1.]) tensor([0.6581, 0.3419], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 10 - 331: dog - cat || Loss: 0.9706084132194519\n",
      "tensor([0., 1.]) tensor([0.6573, 0.3427], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 10 - 332: dog - cat || Loss: 0.9698389768600464\n",
      "tensor([0., 1.]) tensor([0.6566, 0.3434], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 10 - 333: dog - cat || Loss: 0.9690688252449036\n",
      "tensor([0., 1.]) tensor([0.6558, 0.3442], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 10 - 334: dog - cat || Loss: 0.9682982563972473\n",
      "tensor([0., 1.]) tensor([0.6550, 0.3450], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 10 - 335: dog - cat || Loss: 0.9675271511077881\n",
      "tensor([0., 1.]) tensor([0.6543, 0.3457], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 10 - 336: dog - cat || Loss: 0.9667555093765259\n",
      "tensor([0., 1.]) tensor([0.6535, 0.3465], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 10 - 337: dog - cat || Loss: 0.9659833908081055\n",
      "tensor([0., 1.]) tensor([0.6527, 0.3473], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 10 - 338: dog - cat || Loss: 0.9652106165885925\n",
      "tensor([0., 1.]) tensor([0.6519, 0.3481], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 10 - 339: dog - cat || Loss: 0.9644373059272766\n",
      "tensor([0., 1.]) tensor([0.6512, 0.3488], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 10 - 340: dog - cat || Loss: 0.9636635184288025\n",
      "tensor([0., 1.]) tensor([0.6504, 0.3496], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 10 - 341: dog - cat || Loss: 0.9628892540931702\n",
      "tensor([0., 1.]) tensor([0.6496, 0.3504], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 10 - 342: dog - cat || Loss: 0.9621144533157349\n",
      "tensor([0., 1.]) tensor([0.6489, 0.3511], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 10 - 343: dog - cat || Loss: 0.9613391757011414\n",
      "tensor([0., 1.]) tensor([0.6481, 0.3519], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 10 - 344: dog - cat || Loss: 0.9605634212493896\n",
      "tensor([0., 1.]) tensor([0.6473, 0.3527], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 10 - 345: dog - cat || Loss: 0.9597869515419006\n",
      "tensor([0., 1.]) tensor([0.6465, 0.3535], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 10 - 346: dog - cat || Loss: 0.9590102434158325\n",
      "tensor([0., 1.]) tensor([0.6457, 0.3543], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 10 - 347: dog - cat || Loss: 0.9582328796386719\n",
      "tensor([0., 1.]) tensor([0.6450, 0.3550], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 10 - 348: dog - cat || Loss: 0.9574549794197083\n",
      "tensor([0., 1.]) tensor([0.6442, 0.3558], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 10 - 349: dog - cat || Loss: 0.9566764235496521\n",
      "tensor([0., 1.]) tensor([0.6434, 0.3566], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 10 - 350: dog - cat || Loss: 0.9558974504470825\n",
      "tensor([0., 1.]) tensor([0.6426, 0.3574], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 10 - 351: dog - cat || Loss: 0.9551178812980652\n",
      "tensor([0., 1.]) tensor([0.6419, 0.3581], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 10 - 352: dog - cat || Loss: 0.9543378353118896\n",
      "tensor([0., 1.]) tensor([0.6411, 0.3589], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 10 - 353: dog - cat || Loss: 0.9535573124885559\n",
      "tensor([0., 1.]) tensor([0.6403, 0.3597], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 10 - 354: dog - cat || Loss: 0.9527760744094849\n",
      "tensor([0., 1.]) tensor([0.6395, 0.3605], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 10 - 355: dog - cat || Loss: 0.9519945383071899\n",
      "tensor([0., 1.]) tensor([0.6387, 0.3613], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 10 - 356: dog - cat || Loss: 0.9512124061584473\n",
      "tensor([0., 1.]) tensor([0.6380, 0.3620], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 10 - 357: dog - cat || Loss: 0.9504297971725464\n",
      "tensor([0., 1.]) tensor([0.6372, 0.3628], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 10 - 358: dog - cat || Loss: 0.9496466517448425\n",
      "tensor([0., 1.]) tensor([0.6364, 0.3636], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 10 - 359: dog - cat || Loss: 0.94886314868927\n",
      "tensor([0., 1.]) tensor([0.6356, 0.3644], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 10 - 360: dog - cat || Loss: 0.9480788707733154\n",
      "tensor([0., 1.]) tensor([0.6348, 0.3652], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 10 - 361: dog - cat || Loss: 0.947294294834137\n",
      "tensor([0., 1.]) tensor([0.6340, 0.3660], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 10 - 362: dog - cat || Loss: 0.9465092420578003\n",
      "tensor([0., 1.]) tensor([0.6332, 0.3668], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 10 - 363: dog - cat || Loss: 0.9457235336303711\n",
      "tensor([0., 1.]) tensor([0.6325, 0.3675], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 10 - 364: dog - cat || Loss: 0.9449374079704285\n",
      "tensor([0., 1.]) tensor([0.6317, 0.3683], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 10 - 365: dog - cat || Loss: 0.9441507458686829\n",
      "tensor([0., 1.]) tensor([0.6309, 0.3691], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 10 - 366: dog - cat || Loss: 0.9433634281158447\n",
      "tensor([0., 1.]) tensor([0.6301, 0.3699], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 10 - 367: dog - cat || Loss: 0.9425758123397827\n",
      "tensor([0., 1.]) tensor([0.6293, 0.3707], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 10 - 368: dog - cat || Loss: 0.941787600517273\n",
      "tensor([0., 1.]) tensor([0.6285, 0.3715], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 10 - 369: dog - cat || Loss: 0.9409989714622498\n",
      "tensor([0., 1.]) tensor([0.6277, 0.3723], grad_fn=<SoftmaxBackward0>)\n",
      "=====epoch:11=====\n",
      "Epoch 11 - 0: cat - cat || Loss: 0.6863134503364563\n",
      "tensor([1., 0.]) tensor([0.6269, 0.3731], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 11 - 1: cat - cat || Loss: 0.6869445443153381\n",
      "tensor([1., 0.]) tensor([0.6263, 0.3737], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 11 - 2: cat - cat || Loss: 0.6874334812164307\n",
      "tensor([1., 0.]) tensor([0.6258, 0.3742], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 11 - 3: cat - cat || Loss: 0.6877942085266113\n",
      "tensor([1., 0.]) tensor([0.6255, 0.3745], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 11 - 4: cat - cat || Loss: 0.6880396604537964\n",
      "tensor([1., 0.]) tensor([0.6252, 0.3748], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 11 - 5: cat - cat || Loss: 0.6881814002990723\n",
      "tensor([1., 0.]) tensor([0.6251, 0.3749], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 11 - 6: cat - cat || Loss: 0.6882295608520508\n",
      "tensor([1., 0.]) tensor([0.6250, 0.3750], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 11 - 7: cat - cat || Loss: 0.6881935596466064\n",
      "tensor([1., 0.]) tensor([0.6251, 0.3749], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 11 - 8: cat - cat || Loss: 0.6880819797515869\n",
      "tensor([1., 0.]) tensor([0.6252, 0.3748], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 11 - 9: cat - cat || Loss: 0.6879023313522339\n",
      "tensor([1., 0.]) tensor([0.6254, 0.3746], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 11 - 10: cat - cat || Loss: 0.6876612901687622\n",
      "tensor([1., 0.]) tensor([0.6256, 0.3744], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 11 - 11: cat - cat || Loss: 0.6873652338981628\n",
      "tensor([1., 0.]) tensor([0.6259, 0.3741], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 11 - 12: cat - cat || Loss: 0.6870195865631104\n",
      "tensor([1., 0.]) tensor([0.6262, 0.3738], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 11 - 13: cat - cat || Loss: 0.6866294741630554\n",
      "tensor([1., 0.]) tensor([0.6266, 0.3734], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 11 - 14: cat - cat || Loss: 0.6861992478370667\n",
      "tensor([1., 0.]) tensor([0.6271, 0.3729], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 11 - 15: cat - cat || Loss: 0.6857330203056335\n",
      "tensor([1., 0.]) tensor([0.6275, 0.3725], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 11 - 16: cat - cat || Loss: 0.6852341890335083\n",
      "tensor([1., 0.]) tensor([0.6280, 0.3720], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 11 - 17: cat - cat || Loss: 0.684706449508667\n",
      "tensor([1., 0.]) tensor([0.6286, 0.3714], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 11 - 18: cat - cat || Loss: 0.6841524839401245\n",
      "tensor([1., 0.]) tensor([0.6291, 0.3709], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 11 - 19: cat - cat || Loss: 0.6835751533508301\n",
      "tensor([1., 0.]) tensor([0.6297, 0.3703], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 11 - 20: cat - cat || Loss: 0.6829767227172852\n",
      "tensor([1., 0.]) tensor([0.6303, 0.3697], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 11 - 21: cat - cat || Loss: 0.6823595762252808\n",
      "tensor([1., 0.]) tensor([0.6309, 0.3691], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 11 - 22: cat - cat || Loss: 0.6817253828048706\n",
      "tensor([1., 0.]) tensor([0.6315, 0.3685], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 11 - 23: cat - cat || Loss: 0.6810759902000427\n",
      "tensor([1., 0.]) tensor([0.6322, 0.3678], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 11 - 24: cat - cat || Loss: 0.6804128885269165\n",
      "tensor([1., 0.]) tensor([0.6328, 0.3672], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 11 - 25: cat - cat || Loss: 0.6797376871109009\n",
      "tensor([1., 0.]) tensor([0.6335, 0.3665], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 11 - 26: cat - cat || Loss: 0.679051399230957\n",
      "tensor([1., 0.]) tensor([0.6342, 0.3658], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 11 - 27: cat - cat || Loss: 0.67835533618927\n",
      "tensor([1., 0.]) tensor([0.6349, 0.3651], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 11 - 28: cat - cat || Loss: 0.6776504516601562\n",
      "tensor([1., 0.]) tensor([0.6356, 0.3644], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 11 - 29: cat - cat || Loss: 0.6769375801086426\n",
      "tensor([1., 0.]) tensor([0.6363, 0.3637], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 11 - 30: cat - cat || Loss: 0.6762179136276245\n",
      "tensor([1., 0.]) tensor([0.6370, 0.3630], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 11 - 31: cat - cat || Loss: 0.6754919290542603\n",
      "tensor([1., 0.]) tensor([0.6378, 0.3622], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 11 - 32: cat - cat || Loss: 0.6747604608535767\n",
      "tensor([1., 0.]) tensor([0.6385, 0.3615], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 11 - 33: cat - cat || Loss: 0.6740241050720215\n",
      "tensor([1., 0.]) tensor([0.6392, 0.3608], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 11 - 34: cat - cat || Loss: 0.6732832789421082\n",
      "tensor([1., 0.]) tensor([0.6400, 0.3600], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 11 - 35: cat - cat || Loss: 0.6725383996963501\n",
      "tensor([1., 0.]) tensor([0.6407, 0.3593], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 11 - 36: cat - cat || Loss: 0.6717903017997742\n",
      "tensor([1., 0.]) tensor([0.6415, 0.3585], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 11 - 37: cat - cat || Loss: 0.671039342880249\n",
      "tensor([1., 0.]) tensor([0.6422, 0.3578], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 11 - 38: cat - cat || Loss: 0.6702854633331299\n",
      "tensor([1., 0.]) tensor([0.6430, 0.3570], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 11 - 39: cat - cat || Loss: 0.669529139995575\n",
      "tensor([1., 0.]) tensor([0.6437, 0.3563], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 11 - 40: cat - cat || Loss: 0.6687710285186768\n",
      "tensor([1., 0.]) tensor([0.6445, 0.3555], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 11 - 41: cat - cat || Loss: 0.6680108308792114\n",
      "tensor([1., 0.]) tensor([0.6453, 0.3547], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 11 - 42: cat - cat || Loss: 0.6672492027282715\n",
      "tensor([1., 0.]) tensor([0.6460, 0.3540], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 11 - 43: cat - cat || Loss: 0.6664860248565674\n",
      "tensor([1., 0.]) tensor([0.6468, 0.3532], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 11 - 44: cat - cat || Loss: 0.6657218933105469\n",
      "tensor([1., 0.]) tensor([0.6475, 0.3525], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 11 - 45: cat - cat || Loss: 0.6649565100669861\n",
      "tensor([1., 0.]) tensor([0.6483, 0.3517], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 11 - 46: cat - cat || Loss: 0.664190411567688\n",
      "tensor([1., 0.]) tensor([0.6491, 0.3509], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 11 - 47: cat - cat || Loss: 0.6634235978126526\n",
      "tensor([1., 0.]) tensor([0.6498, 0.3502], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 11 - 48: cat - cat || Loss: 0.6626561880111694\n",
      "tensor([1., 0.]) tensor([0.6506, 0.3494], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 11 - 49: cat - cat || Loss: 0.6618883609771729\n",
      "tensor([1., 0.]) tensor([0.6514, 0.3486], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 11 - 50: cat - cat || Loss: 0.6611200571060181\n",
      "tensor([1., 0.]) tensor([0.6521, 0.3479], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 11 - 51: cat - cat || Loss: 0.6603516936302185\n",
      "tensor([1., 0.]) tensor([0.6529, 0.3471], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 11 - 52: cat - cat || Loss: 0.6595830917358398\n",
      "tensor([1., 0.]) tensor([0.6537, 0.3463], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 11 - 53: cat - cat || Loss: 0.6588144302368164\n",
      "tensor([1., 0.]) tensor([0.6544, 0.3456], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 11 - 54: cat - cat || Loss: 0.6580455899238586\n",
      "tensor([1., 0.]) tensor([0.6552, 0.3448], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 11 - 55: cat - cat || Loss: 0.6572768688201904\n",
      "tensor([1., 0.]) tensor([0.6560, 0.3440], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 11 - 56: cat - cat || Loss: 0.656508207321167\n",
      "tensor([1., 0.]) tensor([0.6568, 0.3432], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 11 - 57: cat - cat || Loss: 0.6557397246360779\n",
      "tensor([1., 0.]) tensor([0.6575, 0.3425], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 11 - 58: cat - cat || Loss: 0.6549713611602783\n",
      "tensor([1., 0.]) tensor([0.6583, 0.3417], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 11 - 59: cat - cat || Loss: 0.6542034149169922\n",
      "tensor([1., 0.]) tensor([0.6591, 0.3409], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 11 - 60: cat - cat || Loss: 0.6534357070922852\n",
      "tensor([1., 0.]) tensor([0.6598, 0.3402], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 11 - 61: cat - cat || Loss: 0.6526682376861572\n",
      "tensor([1., 0.]) tensor([0.6606, 0.3394], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 11 - 62: cat - cat || Loss: 0.651901125907898\n",
      "tensor([1., 0.]) tensor([0.6614, 0.3386], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 11 - 63: cat - cat || Loss: 0.6511344909667969\n",
      "tensor([1., 0.]) tensor([0.6621, 0.3379], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 11 - 64: cat - cat || Loss: 0.6503680944442749\n",
      "tensor([1., 0.]) tensor([0.6629, 0.3371], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 11 - 65: cat - cat || Loss: 0.6496021747589111\n",
      "tensor([1., 0.]) tensor([0.6637, 0.3363], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 11 - 66: cat - cat || Loss: 0.6488366723060608\n",
      "tensor([1., 0.]) tensor([0.6644, 0.3356], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 11 - 67: cat - cat || Loss: 0.6480717658996582\n",
      "tensor([1., 0.]) tensor([0.6652, 0.3348], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 11 - 68: cat - cat || Loss: 0.6473072171211243\n",
      "tensor([1., 0.]) tensor([0.6660, 0.3340], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 11 - 69: cat - cat || Loss: 0.6465430855751038\n",
      "tensor([1., 0.]) tensor([0.6667, 0.3333], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 11 - 70: cat - cat || Loss: 0.6457796096801758\n",
      "tensor([1., 0.]) tensor([0.6675, 0.3325], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 11 - 71: cat - cat || Loss: 0.6450166702270508\n",
      "tensor([1., 0.]) tensor([0.6682, 0.3318], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 11 - 72: cat - cat || Loss: 0.644254207611084\n",
      "tensor([1., 0.]) tensor([0.6690, 0.3310], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 11 - 73: cat - cat || Loss: 0.6434923410415649\n",
      "tensor([1., 0.]) tensor([0.6698, 0.3302], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 11 - 74: cat - cat || Loss: 0.6427310109138489\n",
      "tensor([1., 0.]) tensor([0.6705, 0.3295], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 11 - 75: cat - cat || Loss: 0.6419702172279358\n",
      "tensor([1., 0.]) tensor([0.6713, 0.3287], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 11 - 76: cat - cat || Loss: 0.6412100195884705\n",
      "tensor([1., 0.]) tensor([0.6721, 0.3279], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 11 - 77: cat - cat || Loss: 0.6404504776000977\n",
      "tensor([1., 0.]) tensor([0.6728, 0.3272], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 11 - 78: cat - cat || Loss: 0.6396913528442383\n",
      "tensor([1., 0.]) tensor([0.6736, 0.3264], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 11 - 79: cat - cat || Loss: 0.6389329433441162\n",
      "tensor([1., 0.]) tensor([0.6743, 0.3257], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 11 - 80: cat - cat || Loss: 0.6381752490997314\n",
      "tensor([1., 0.]) tensor([0.6751, 0.3249], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 11 - 81: cat - cat || Loss: 0.6374180316925049\n",
      "tensor([1., 0.]) tensor([0.6758, 0.3242], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 11 - 82: cat - cat || Loss: 0.6366614699363708\n",
      "tensor([1., 0.]) tensor([0.6766, 0.3234], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 11 - 83: cat - cat || Loss: 0.6359055638313293\n",
      "tensor([1., 0.]) tensor([0.6774, 0.3226], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 11 - 84: cat - cat || Loss: 0.6351503133773804\n",
      "tensor([1., 0.]) tensor([0.6781, 0.3219], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 11 - 85: cat - cat || Loss: 0.6343957185745239\n",
      "tensor([1., 0.]) tensor([0.6789, 0.3211], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 11 - 86: cat - cat || Loss: 0.6336417198181152\n",
      "tensor([1., 0.]) tensor([0.6796, 0.3204], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 11 - 87: cat - cat || Loss: 0.6328883767127991\n",
      "tensor([1., 0.]) tensor([0.6804, 0.3196], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 11 - 88: cat - cat || Loss: 0.6321356296539307\n",
      "tensor([1., 0.]) tensor([0.6811, 0.3189], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 11 - 89: cat - cat || Loss: 0.6313835978507996\n",
      "tensor([1., 0.]) tensor([0.6819, 0.3181], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 11 - 90: cat - cat || Loss: 0.630632221698761\n",
      "tensor([1., 0.]) tensor([0.6826, 0.3174], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 11 - 91: cat - cat || Loss: 0.6298813819885254\n",
      "tensor([1., 0.]) tensor([0.6834, 0.3166], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 11 - 92: cat - cat || Loss: 0.6291313171386719\n",
      "tensor([1., 0.]) tensor([0.6841, 0.3159], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 11 - 93: cat - cat || Loss: 0.6283818483352661\n",
      "tensor([1., 0.]) tensor([0.6849, 0.3151], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 11 - 94: cat - cat || Loss: 0.6276331543922424\n",
      "tensor([1., 0.]) tensor([0.6856, 0.3144], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 11 - 95: cat - cat || Loss: 0.626884937286377\n",
      "tensor([1., 0.]) tensor([0.6864, 0.3136], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 11 - 96: cat - cat || Loss: 0.6261376142501831\n",
      "tensor([1., 0.]) tensor([0.6871, 0.3129], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 11 - 97: cat - cat || Loss: 0.625390887260437\n",
      "tensor([1., 0.]) tensor([0.6879, 0.3121], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 11 - 98: cat - cat || Loss: 0.6246448755264282\n",
      "tensor([1., 0.]) tensor([0.6886, 0.3114], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 11 - 99: cat - cat || Loss: 0.6238995790481567\n",
      "tensor([1., 0.]) tensor([0.6894, 0.3106], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 11 - 100: cat - cat || Loss: 0.6231548190116882\n",
      "tensor([1., 0.]) tensor([0.6901, 0.3099], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 11 - 101: cat - cat || Loss: 0.6224108934402466\n",
      "tensor([1., 0.]) tensor([0.6909, 0.3091], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 11 - 102: cat - cat || Loss: 0.6216676235198975\n",
      "tensor([1., 0.]) tensor([0.6916, 0.3084], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 11 - 103: cat - cat || Loss: 0.6209250092506409\n",
      "tensor([1., 0.]) tensor([0.6923, 0.3077], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 11 - 104: cat - cat || Loss: 0.6201831698417664\n",
      "tensor([1., 0.]) tensor([0.6931, 0.3069], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 11 - 105: cat - cat || Loss: 0.6194421648979187\n",
      "tensor([1., 0.]) tensor([0.6938, 0.3062], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 11 - 106: cat - cat || Loss: 0.618701696395874\n",
      "tensor([1., 0.]) tensor([0.6946, 0.3054], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 11 - 107: cat - cat || Loss: 0.6179619431495667\n",
      "tensor([1., 0.]) tensor([0.6953, 0.3047], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 11 - 108: cat - cat || Loss: 0.6172229051589966\n",
      "tensor([1., 0.]) tensor([0.6960, 0.3040], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 11 - 109: cat - cat || Loss: 0.6164847612380981\n",
      "tensor([1., 0.]) tensor([0.6968, 0.3032], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 11 - 110: cat - cat || Loss: 0.6157470941543579\n",
      "tensor([1., 0.]) tensor([0.6975, 0.3025], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 11 - 111: cat - cat || Loss: 0.6150103807449341\n",
      "tensor([1., 0.]) tensor([0.6983, 0.3017], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 11 - 112: cat - cat || Loss: 0.614274263381958\n",
      "tensor([1., 0.]) tensor([0.6990, 0.3010], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 11 - 113: cat - cat || Loss: 0.613538920879364\n",
      "tensor([1., 0.]) tensor([0.6997, 0.3003], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 11 - 114: cat - cat || Loss: 0.6128042936325073\n",
      "tensor([1., 0.]) tensor([0.7005, 0.2995], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 11 - 115: cat - cat || Loss: 0.6120705604553223\n",
      "tensor([1., 0.]) tensor([0.7012, 0.2988], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 11 - 116: cat - cat || Loss: 0.6113373041152954\n",
      "tensor([1., 0.]) tensor([0.7019, 0.2981], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 11 - 117: cat - cat || Loss: 0.6106051206588745\n",
      "tensor([1., 0.]) tensor([0.7027, 0.2973], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 11 - 118: cat - cat || Loss: 0.6098735928535461\n",
      "tensor([1., 0.]) tensor([0.7034, 0.2966], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 11 - 119: cat - cat || Loss: 0.6091428995132446\n",
      "tensor([1., 0.]) tensor([0.7041, 0.2959], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 11 - 120: cat - cat || Loss: 0.6084129810333252\n",
      "tensor([1., 0.]) tensor([0.7048, 0.2952], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 11 - 121: cat - cat || Loss: 0.6076836585998535\n",
      "tensor([1., 0.]) tensor([0.7056, 0.2944], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 11 - 122: cat - cat || Loss: 0.6069554090499878\n",
      "tensor([1., 0.]) tensor([0.7063, 0.2937], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 11 - 123: cat - cat || Loss: 0.6062278151512146\n",
      "tensor([1., 0.]) tensor([0.7070, 0.2930], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 11 - 124: cat - cat || Loss: 0.605501115322113\n",
      "tensor([1., 0.]) tensor([0.7078, 0.2922], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 11 - 125: cat - cat || Loss: 0.6047750115394592\n",
      "tensor([1., 0.]) tensor([0.7085, 0.2915], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 11 - 126: cat - cat || Loss: 0.6040496826171875\n",
      "tensor([1., 0.]) tensor([0.7092, 0.2908], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 11 - 127: cat - cat || Loss: 0.6033251285552979\n",
      "tensor([1., 0.]) tensor([0.7099, 0.2901], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 11 - 128: cat - cat || Loss: 0.6026013493537903\n",
      "tensor([1., 0.]) tensor([0.7107, 0.2893], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 11 - 129: cat - cat || Loss: 0.6018784046173096\n",
      "tensor([1., 0.]) tensor([0.7114, 0.2886], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 11 - 130: cat - cat || Loss: 0.6011562347412109\n",
      "tensor([1., 0.]) tensor([0.7121, 0.2879], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 11 - 131: cat - cat || Loss: 0.6004348397254944\n",
      "tensor([1., 0.]) tensor([0.7128, 0.2872], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 11 - 132: cat - cat || Loss: 0.5997142195701599\n",
      "tensor([1., 0.]) tensor([0.7135, 0.2865], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 11 - 133: cat - cat || Loss: 0.5989944934844971\n",
      "tensor([1., 0.]) tensor([0.7143, 0.2857], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 11 - 134: cat - cat || Loss: 0.5982754230499268\n",
      "tensor([1., 0.]) tensor([0.7150, 0.2850], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 11 - 135: cat - cat || Loss: 0.5975572466850281\n",
      "tensor([1., 0.]) tensor([0.7157, 0.2843], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 11 - 136: cat - cat || Loss: 0.5968398451805115\n",
      "tensor([1., 0.]) tensor([0.7164, 0.2836], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 11 - 137: cat - cat || Loss: 0.5961231589317322\n",
      "tensor([1., 0.]) tensor([0.7171, 0.2829], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 11 - 138: cat - cat || Loss: 0.5954073667526245\n",
      "tensor([1., 0.]) tensor([0.7179, 0.2821], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 11 - 139: cat - cat || Loss: 0.5946922898292542\n",
      "tensor([1., 0.]) tensor([0.7186, 0.2814], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 11 - 140: cat - cat || Loss: 0.5939780473709106\n",
      "tensor([1., 0.]) tensor([0.7193, 0.2807], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 11 - 141: cat - cat || Loss: 0.593264639377594\n",
      "tensor([1., 0.]) tensor([0.7200, 0.2800], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 11 - 142: cat - cat || Loss: 0.5925520658493042\n",
      "tensor([1., 0.]) tensor([0.7207, 0.2793], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 11 - 143: cat - cat || Loss: 0.5918402075767517\n",
      "tensor([1., 0.]) tensor([0.7214, 0.2786], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 11 - 144: cat - cat || Loss: 0.5911293029785156\n",
      "tensor([1., 0.]) tensor([0.7221, 0.2779], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 11 - 145: cat - cat || Loss: 0.5904190540313721\n",
      "tensor([1., 0.]) tensor([0.7228, 0.2772], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 11 - 146: cat - cat || Loss: 0.5897097587585449\n",
      "tensor([1., 0.]) tensor([0.7236, 0.2764], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 11 - 147: cat - cat || Loss: 0.5890012979507446\n",
      "tensor([1., 0.]) tensor([0.7243, 0.2757], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 11 - 148: cat - cat || Loss: 0.5882935523986816\n",
      "tensor([1., 0.]) tensor([0.7250, 0.2750], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 11 - 149: cat - cat || Loss: 0.5875867605209351\n",
      "tensor([1., 0.]) tensor([0.7257, 0.2743], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 11 - 150: cat - cat || Loss: 0.5868806838989258\n",
      "tensor([1., 0.]) tensor([0.7264, 0.2736], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 11 - 151: cat - cat || Loss: 0.5861755609512329\n",
      "tensor([1., 0.]) tensor([0.7271, 0.2729], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 11 - 152: cat - cat || Loss: 0.5854712724685669\n",
      "tensor([1., 0.]) tensor([0.7278, 0.2722], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 11 - 153: cat - cat || Loss: 0.5847678184509277\n",
      "tensor([1., 0.]) tensor([0.7285, 0.2715], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 11 - 154: cat - cat || Loss: 0.5840651988983154\n",
      "tensor([1., 0.]) tensor([0.7292, 0.2708], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 11 - 155: cat - cat || Loss: 0.58336341381073\n",
      "tensor([1., 0.]) tensor([0.7299, 0.2701], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 11 - 156: cat - cat || Loss: 0.5826625823974609\n",
      "tensor([1., 0.]) tensor([0.7306, 0.2694], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 11 - 157: cat - cat || Loss: 0.581962525844574\n",
      "tensor([1., 0.]) tensor([0.7313, 0.2687], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 11 - 158: cat - cat || Loss: 0.5812633037567139\n",
      "tensor([1., 0.]) tensor([0.7320, 0.2680], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 11 - 159: cat - cat || Loss: 0.5805649161338806\n",
      "tensor([1., 0.]) tensor([0.7327, 0.2673], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 11 - 160: cat - cat || Loss: 0.579867422580719\n",
      "tensor([1., 0.]) tensor([0.7334, 0.2666], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 11 - 161: cat - cat || Loss: 0.579170823097229\n",
      "tensor([1., 0.]) tensor([0.7341, 0.2659], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 11 - 162: cat - cat || Loss: 0.5784750580787659\n",
      "tensor([1., 0.]) tensor([0.7348, 0.2652], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 11 - 163: cat - cat || Loss: 0.5777800679206848\n",
      "tensor([1., 0.]) tensor([0.7355, 0.2645], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 11 - 164: cat - cat || Loss: 0.5770860910415649\n",
      "tensor([1., 0.]) tensor([0.7362, 0.2638], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 11 - 165: cat - cat || Loss: 0.5763928890228271\n",
      "tensor([1., 0.]) tensor([0.7369, 0.2631], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 11 - 166: cat - cat || Loss: 0.5757005214691162\n",
      "tensor([1., 0.]) tensor([0.7376, 0.2624], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 11 - 167: cat - cat || Loss: 0.5750091075897217\n",
      "tensor([1., 0.]) tensor([0.7383, 0.2617], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 11 - 168: cat - cat || Loss: 0.574318528175354\n",
      "tensor([1., 0.]) tensor([0.7389, 0.2611], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 11 - 169: cat - cat || Loss: 0.5736287832260132\n",
      "tensor([1., 0.]) tensor([0.7396, 0.2604], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 11 - 170: cat - cat || Loss: 0.5729399919509888\n",
      "tensor([1., 0.]) tensor([0.7403, 0.2597], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 11 - 171: cat - cat || Loss: 0.572252094745636\n",
      "tensor([1., 0.]) tensor([0.7410, 0.2590], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 11 - 172: cat - cat || Loss: 0.5715649724006653\n",
      "tensor([1., 0.]) tensor([0.7417, 0.2583], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 11 - 173: cat - cat || Loss: 0.5708787441253662\n",
      "tensor([1., 0.]) tensor([0.7424, 0.2576], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 11 - 174: cat - cat || Loss: 0.5701935291290283\n",
      "tensor([1., 0.]) tensor([0.7431, 0.2569], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 11 - 175: cat - cat || Loss: 0.569508969783783\n",
      "tensor([1., 0.]) tensor([0.7438, 0.2562], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 11 - 176: cat - cat || Loss: 0.5688254833221436\n",
      "tensor([1., 0.]) tensor([0.7444, 0.2556], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 11 - 177: cat - cat || Loss: 0.568142831325531\n",
      "tensor([1., 0.]) tensor([0.7451, 0.2549], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 11 - 178: cat - cat || Loss: 0.5674610137939453\n",
      "tensor([1., 0.]) tensor([0.7458, 0.2542], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 11 - 179: cat - cat || Loss: 0.5667803287506104\n",
      "tensor([1., 0.]) tensor([0.7465, 0.2535], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 11 - 180: cat - cat || Loss: 0.5661003589630127\n",
      "tensor([1., 0.]) tensor([0.7472, 0.2528], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 11 - 181: cat - cat || Loss: 0.5654213428497314\n",
      "tensor([1., 0.]) tensor([0.7478, 0.2522], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 11 - 182: cat - cat || Loss: 0.5647432804107666\n",
      "tensor([1., 0.]) tensor([0.7485, 0.2515], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 11 - 183: cat - cat || Loss: 0.5640662312507629\n",
      "tensor([1., 0.]) tensor([0.7492, 0.2508], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 11 - 184: cat - cat || Loss: 0.5633899569511414\n",
      "tensor([1., 0.]) tensor([0.7499, 0.2501], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 11 - 185: cat - cat || Loss: 0.5627146363258362\n",
      "tensor([1., 0.]) tensor([0.7505, 0.2495], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 11 - 186: cat - cat || Loss: 0.5620401501655579\n",
      "tensor([1., 0.]) tensor([0.7512, 0.2488], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 11 - 187: cat - cat || Loss: 0.5613667964935303\n",
      "tensor([1., 0.]) tensor([0.7519, 0.2481], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 11 - 188: cat - cat || Loss: 0.5606943964958191\n",
      "tensor([1., 0.]) tensor([0.7526, 0.2474], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 11 - 189: cat - cat || Loss: 0.5600228905677795\n",
      "tensor([1., 0.]) tensor([0.7532, 0.2468], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 11 - 190: dog - cat || Loss: 1.0671708583831787\n",
      "tensor([0., 1.]) tensor([0.7539, 0.2461], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 11 - 191: dog - cat || Loss: 1.0677075386047363\n",
      "tensor([0., 1.]) tensor([0.7544, 0.2456], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 11 - 192: dog - cat || Loss: 1.068123459815979\n",
      "tensor([0., 1.]) tensor([0.7549, 0.2451], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 11 - 193: dog - cat || Loss: 1.0684311389923096\n",
      "tensor([0., 1.]) tensor([0.7552, 0.2448], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 11 - 194: dog - cat || Loss: 1.0686416625976562\n",
      "tensor([0., 1.]) tensor([0.7554, 0.2446], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 11 - 195: dog - cat || Loss: 1.0687646865844727\n",
      "tensor([0., 1.]) tensor([0.7555, 0.2445], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 11 - 196: dog - cat || Loss: 1.0688090324401855\n",
      "tensor([0., 1.]) tensor([0.7555, 0.2445], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 11 - 197: dog - cat || Loss: 1.0687824487686157\n",
      "tensor([0., 1.]) tensor([0.7555, 0.2445], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 11 - 198: dog - cat || Loss: 1.0686922073364258\n",
      "tensor([0., 1.]) tensor([0.7554, 0.2446], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 11 - 199: dog - cat || Loss: 1.0685447454452515\n",
      "tensor([0., 1.]) tensor([0.7553, 0.2447], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 11 - 200: dog - cat || Loss: 1.0683454275131226\n",
      "tensor([0., 1.]) tensor([0.7551, 0.2449], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 11 - 201: dog - cat || Loss: 1.0680996179580688\n",
      "tensor([0., 1.]) tensor([0.7548, 0.2452], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 11 - 202: dog - cat || Loss: 1.0678118467330933\n",
      "tensor([0., 1.]) tensor([0.7546, 0.2454], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 11 - 203: dog - cat || Loss: 1.06748628616333\n",
      "tensor([0., 1.]) tensor([0.7542, 0.2458], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 11 - 204: dog - cat || Loss: 1.0671265125274658\n",
      "tensor([0., 1.]) tensor([0.7539, 0.2461], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 11 - 205: dog - cat || Loss: 1.066735863685608\n",
      "tensor([0., 1.]) tensor([0.7535, 0.2465], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 11 - 206: dog - cat || Loss: 1.0663177967071533\n",
      "tensor([0., 1.]) tensor([0.7531, 0.2469], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 11 - 207: dog - cat || Loss: 1.065874695777893\n",
      "tensor([0., 1.]) tensor([0.7526, 0.2474], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 11 - 208: dog - cat || Loss: 1.0654085874557495\n",
      "tensor([0., 1.]) tensor([0.7521, 0.2479], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 11 - 209: dog - cat || Loss: 1.0649223327636719\n",
      "tensor([0., 1.]) tensor([0.7517, 0.2483], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 11 - 210: dog - cat || Loss: 1.0644176006317139\n",
      "tensor([0., 1.]) tensor([0.7512, 0.2488], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 11 - 211: dog - cat || Loss: 1.0638962984085083\n",
      "tensor([0., 1.]) tensor([0.7506, 0.2494], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 11 - 212: dog - cat || Loss: 1.0633594989776611\n",
      "tensor([0., 1.]) tensor([0.7501, 0.2499], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 11 - 213: dog - cat || Loss: 1.0628092288970947\n",
      "tensor([0., 1.]) tensor([0.7495, 0.2505], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 11 - 214: dog - cat || Loss: 1.0622464418411255\n",
      "tensor([0., 1.]) tensor([0.7490, 0.2510], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 11 - 215: dog - cat || Loss: 1.061672568321228\n",
      "tensor([0., 1.]) tensor([0.7484, 0.2516], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 11 - 216: dog - cat || Loss: 1.0610884428024292\n",
      "tensor([0., 1.]) tensor([0.7478, 0.2522], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 11 - 217: dog - cat || Loss: 1.0604948997497559\n",
      "tensor([0., 1.]) tensor([0.7472, 0.2528], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 11 - 218: dog - cat || Loss: 1.059893012046814\n",
      "tensor([0., 1.]) tensor([0.7466, 0.2534], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 11 - 219: dog - cat || Loss: 1.0592833757400513\n",
      "tensor([0., 1.]) tensor([0.7460, 0.2540], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 11 - 220: dog - cat || Loss: 1.0586669445037842\n",
      "tensor([0., 1.]) tensor([0.7454, 0.2546], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 11 - 221: dog - cat || Loss: 1.0580440759658813\n",
      "tensor([0., 1.]) tensor([0.7448, 0.2552], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 11 - 222: dog - cat || Loss: 1.057415246963501\n",
      "tensor([0., 1.]) tensor([0.7442, 0.2558], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 11 - 223: dog - cat || Loss: 1.0567811727523804\n",
      "tensor([0., 1.]) tensor([0.7435, 0.2565], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 11 - 224: dog - cat || Loss: 1.0561423301696777\n",
      "tensor([0., 1.]) tensor([0.7429, 0.2571], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 11 - 225: dog - cat || Loss: 1.0554989576339722\n",
      "tensor([0., 1.]) tensor([0.7422, 0.2578], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 11 - 226: dog - cat || Loss: 1.0548514127731323\n",
      "tensor([0., 1.]) tensor([0.7416, 0.2584], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 11 - 227: dog - cat || Loss: 1.054200291633606\n",
      "tensor([0., 1.]) tensor([0.7409, 0.2591], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 11 - 228: dog - cat || Loss: 1.0535454750061035\n",
      "tensor([0., 1.]) tensor([0.7403, 0.2597], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 11 - 229: dog - cat || Loss: 1.0528876781463623\n",
      "tensor([0., 1.]) tensor([0.7396, 0.2604], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 11 - 230: dog - cat || Loss: 1.0522265434265137\n",
      "tensor([0., 1.]) tensor([0.7390, 0.2610], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 11 - 231: dog - cat || Loss: 1.051563024520874\n",
      "tensor([0., 1.]) tensor([0.7383, 0.2617], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 11 - 232: dog - cat || Loss: 1.0508968830108643\n",
      "tensor([0., 1.]) tensor([0.7376, 0.2624], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 11 - 233: dog - cat || Loss: 1.0502283573150635\n",
      "tensor([0., 1.]) tensor([0.7370, 0.2630], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 11 - 234: dog - cat || Loss: 1.0495574474334717\n",
      "tensor([0., 1.]) tensor([0.7363, 0.2637], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 11 - 235: dog - cat || Loss: 1.048884630203247\n",
      "tensor([0., 1.]) tensor([0.7356, 0.2644], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 11 - 236: dog - cat || Loss: 1.0482097864151\n",
      "tensor([0., 1.]) tensor([0.7349, 0.2651], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 11 - 237: dog - cat || Loss: 1.0475330352783203\n",
      "tensor([0., 1.]) tensor([0.7343, 0.2657], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 11 - 238: dog - cat || Loss: 1.0468546152114868\n",
      "tensor([0., 1.]) tensor([0.7336, 0.2664], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 11 - 239: dog - cat || Loss: 1.0461746454238892\n",
      "tensor([0., 1.]) tensor([0.7329, 0.2671], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 11 - 240: dog - cat || Loss: 1.0454928874969482\n",
      "tensor([0., 1.]) tensor([0.7322, 0.2678], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 11 - 241: dog - cat || Loss: 1.0448099374771118\n",
      "tensor([0., 1.]) tensor([0.7315, 0.2685], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 11 - 242: dog - cat || Loss: 1.0441254377365112\n",
      "tensor([0., 1.]) tensor([0.7309, 0.2691], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 11 - 243: dog - cat || Loss: 1.043439507484436\n",
      "tensor([0., 1.]) tensor([0.7302, 0.2698], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 11 - 244: dog - cat || Loss: 1.0427525043487549\n",
      "tensor([0., 1.]) tensor([0.7295, 0.2705], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 11 - 245: dog - cat || Loss: 1.0420641899108887\n",
      "tensor([0., 1.]) tensor([0.7288, 0.2712], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 11 - 246: dog - cat || Loss: 1.041374683380127\n",
      "tensor([0., 1.]) tensor([0.7281, 0.2719], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 11 - 247: dog - cat || Loss: 1.0406839847564697\n",
      "tensor([0., 1.]) tensor([0.7274, 0.2726], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 11 - 248: dog - cat || Loss: 1.039992332458496\n",
      "tensor([0., 1.]) tensor([0.7267, 0.2733], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 11 - 249: dog - cat || Loss: 1.0392992496490479\n",
      "tensor([0., 1.]) tensor([0.7260, 0.2740], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 11 - 250: dog - cat || Loss: 1.0386053323745728\n",
      "tensor([0., 1.]) tensor([0.7253, 0.2747], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 11 - 251: dog - cat || Loss: 1.0379104614257812\n",
      "tensor([0., 1.]) tensor([0.7246, 0.2754], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 11 - 252: dog - cat || Loss: 1.0372143983840942\n",
      "tensor([0., 1.]) tensor([0.7240, 0.2760], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 11 - 253: dog - cat || Loss: 1.0365173816680908\n",
      "tensor([0., 1.]) tensor([0.7233, 0.2767], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 11 - 254: dog - cat || Loss: 1.035819411277771\n",
      "tensor([0., 1.]) tensor([0.7226, 0.2774], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 11 - 255: dog - cat || Loss: 1.0351204872131348\n",
      "tensor([0., 1.]) tensor([0.7219, 0.2781], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 11 - 256: dog - cat || Loss: 1.0344208478927612\n",
      "tensor([0., 1.]) tensor([0.7212, 0.2788], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 11 - 257: dog - cat || Loss: 1.0337201356887817\n",
      "tensor([0., 1.]) tensor([0.7205, 0.2795], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 11 - 258: dog - cat || Loss: 1.0330185890197754\n",
      "tensor([0., 1.]) tensor([0.7198, 0.2802], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 11 - 259: dog - cat || Loss: 1.0323162078857422\n",
      "tensor([0., 1.]) tensor([0.7191, 0.2809], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 11 - 260: dog - cat || Loss: 1.0316128730773926\n",
      "tensor([0., 1.]) tensor([0.7184, 0.2816], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 11 - 261: dog - cat || Loss: 1.0309087038040161\n",
      "tensor([0., 1.]) tensor([0.7176, 0.2824], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 11 - 262: dog - cat || Loss: 1.0302037000656128\n",
      "tensor([0., 1.]) tensor([0.7169, 0.2831], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 11 - 263: dog - cat || Loss: 1.0294978618621826\n",
      "tensor([0., 1.]) tensor([0.7162, 0.2838], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 11 - 264: dog - cat || Loss: 1.0287913084030151\n",
      "tensor([0., 1.]) tensor([0.7155, 0.2845], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 11 - 265: dog - cat || Loss: 1.0280835628509521\n",
      "tensor([0., 1.]) tensor([0.7148, 0.2852], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 11 - 266: dog - cat || Loss: 1.0273754596710205\n",
      "tensor([0., 1.]) tensor([0.7141, 0.2859], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 11 - 267: dog - cat || Loss: 1.026666522026062\n",
      "tensor([0., 1.]) tensor([0.7134, 0.2866], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 11 - 268: dog - cat || Loss: 1.025956630706787\n",
      "tensor([0., 1.]) tensor([0.7127, 0.2873], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 11 - 269: dog - cat || Loss: 1.025246024131775\n",
      "tensor([0., 1.]) tensor([0.7120, 0.2880], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 11 - 270: dog - cat || Loss: 1.0245344638824463\n",
      "tensor([0., 1.]) tensor([0.7113, 0.2887], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 11 - 271: dog - cat || Loss: 1.02382230758667\n",
      "tensor([0., 1.]) tensor([0.7106, 0.2894], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 11 - 272: dog - cat || Loss: 1.0231094360351562\n",
      "tensor([0., 1.]) tensor([0.7098, 0.2902], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 11 - 273: dog - cat || Loss: 1.0223956108093262\n",
      "tensor([0., 1.]) tensor([0.7091, 0.2909], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 11 - 274: dog - cat || Loss: 1.0216810703277588\n",
      "tensor([0., 1.]) tensor([0.7084, 0.2916], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 11 - 275: dog - cat || Loss: 1.020965814590454\n",
      "tensor([0., 1.]) tensor([0.7077, 0.2923], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 11 - 276: dog - cat || Loss: 1.020249843597412\n",
      "tensor([0., 1.]) tensor([0.7070, 0.2930], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 11 - 277: dog - cat || Loss: 1.0195330381393433\n",
      "tensor([0., 1.]) tensor([0.7063, 0.2937], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 11 - 278: dog - cat || Loss: 1.0188157558441162\n",
      "tensor([0., 1.]) tensor([0.7056, 0.2944], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 11 - 279: dog - cat || Loss: 1.0180974006652832\n",
      "tensor([0., 1.]) tensor([0.7048, 0.2952], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 11 - 280: dog - cat || Loss: 1.017378568649292\n",
      "tensor([0., 1.]) tensor([0.7041, 0.2959], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 11 - 281: dog - cat || Loss: 1.0166587829589844\n",
      "tensor([0., 1.]) tensor([0.7034, 0.2966], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 11 - 282: dog - cat || Loss: 1.0159385204315186\n",
      "tensor([0., 1.]) tensor([0.7027, 0.2973], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 11 - 283: dog - cat || Loss: 1.0152173042297363\n",
      "tensor([0., 1.]) tensor([0.7020, 0.2980], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 11 - 284: dog - cat || Loss: 1.0144954919815063\n",
      "tensor([0., 1.]) tensor([0.7012, 0.2988], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 11 - 285: dog - cat || Loss: 1.013772964477539\n",
      "tensor([0., 1.]) tensor([0.7005, 0.2995], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 11 - 286: dog - cat || Loss: 1.013049840927124\n",
      "tensor([0., 1.]) tensor([0.6998, 0.3002], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 11 - 287: dog - cat || Loss: 1.0123258829116821\n",
      "tensor([0., 1.]) tensor([0.6991, 0.3009], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 11 - 288: dog - cat || Loss: 1.011601209640503\n",
      "tensor([0., 1.]) tensor([0.6983, 0.3017], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 11 - 289: dog - cat || Loss: 1.0108757019042969\n",
      "tensor([0., 1.]) tensor([0.6976, 0.3024], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 11 - 290: dog - cat || Loss: 1.0101497173309326\n",
      "tensor([0., 1.]) tensor([0.6969, 0.3031], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 11 - 291: dog - cat || Loss: 1.009423017501831\n",
      "tensor([0., 1.]) tensor([0.6962, 0.3038], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 11 - 292: dog - cat || Loss: 1.008695363998413\n",
      "tensor([0., 1.]) tensor([0.6954, 0.3046], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 11 - 293: dog - cat || Loss: 1.0079671144485474\n",
      "tensor([0., 1.]) tensor([0.6947, 0.3053], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 11 - 294: dog - cat || Loss: 1.0072382688522339\n",
      "tensor([0., 1.]) tensor([0.6940, 0.3060], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 11 - 295: dog - cat || Loss: 1.006508708000183\n",
      "tensor([0., 1.]) tensor([0.6932, 0.3068], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 11 - 296: dog - cat || Loss: 1.0057783126831055\n",
      "tensor([0., 1.]) tensor([0.6925, 0.3075], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 11 - 297: dog - cat || Loss: 1.0050475597381592\n",
      "tensor([0., 1.]) tensor([0.6918, 0.3082], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 11 - 298: dog - cat || Loss: 1.004315733909607\n",
      "tensor([0., 1.]) tensor([0.6911, 0.3089], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 11 - 299: dog - cat || Loss: 1.003583550453186\n",
      "tensor([0., 1.]) tensor([0.6903, 0.3097], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 11 - 300: dog - cat || Loss: 1.0028505325317383\n",
      "tensor([0., 1.]) tensor([0.6896, 0.3104], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 11 - 301: dog - cat || Loss: 1.0021166801452637\n",
      "tensor([0., 1.]) tensor([0.6889, 0.3111], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 11 - 302: dog - cat || Loss: 1.0013823509216309\n",
      "tensor([0., 1.]) tensor([0.6881, 0.3119], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 11 - 303: dog - cat || Loss: 1.0006473064422607\n",
      "tensor([0., 1.]) tensor([0.6874, 0.3126], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 11 - 304: dog - cat || Loss: 0.9999116063117981\n",
      "tensor([0., 1.]) tensor([0.6866, 0.3134], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 11 - 305: dog - cat || Loss: 0.9991750121116638\n",
      "tensor([0., 1.]) tensor([0.6859, 0.3141], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 11 - 306: dog - cat || Loss: 0.9984379410743713\n",
      "tensor([0., 1.]) tensor([0.6852, 0.3148], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 11 - 307: dog - cat || Loss: 0.9977002739906311\n",
      "tensor([0., 1.]) tensor([0.6844, 0.3156], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 11 - 308: dog - cat || Loss: 0.996961772441864\n",
      "tensor([0., 1.]) tensor([0.6837, 0.3163], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 11 - 309: dog - cat || Loss: 0.9962227940559387\n",
      "tensor([0., 1.]) tensor([0.6830, 0.3170], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 11 - 310: dog - cat || Loss: 0.9954829812049866\n",
      "tensor([0., 1.]) tensor([0.6822, 0.3178], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 11 - 311: dog - cat || Loss: 0.9947425127029419\n",
      "tensor([0., 1.]) tensor([0.6815, 0.3185], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 11 - 312: dog - cat || Loss: 0.9940015077590942\n",
      "tensor([0., 1.]) tensor([0.6807, 0.3193], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 11 - 313: dog - cat || Loss: 0.9932597875595093\n",
      "tensor([0., 1.]) tensor([0.6800, 0.3200], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 11 - 314: dog - cat || Loss: 0.9925174117088318\n",
      "tensor([0., 1.]) tensor([0.6793, 0.3207], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 11 - 315: dog - cat || Loss: 0.9917743802070618\n",
      "tensor([0., 1.]) tensor([0.6785, 0.3215], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 11 - 316: dog - cat || Loss: 0.9910308122634888\n",
      "tensor([0., 1.]) tensor([0.6778, 0.3222], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 11 - 317: dog - cat || Loss: 0.9902865290641785\n",
      "tensor([0., 1.]) tensor([0.6770, 0.3230], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 11 - 318: dog - cat || Loss: 0.9895415902137756\n",
      "tensor([0., 1.]) tensor([0.6763, 0.3237], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 11 - 319: dog - cat || Loss: 0.9887962341308594\n",
      "tensor([0., 1.]) tensor([0.6755, 0.3245], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 11 - 320: dog - cat || Loss: 0.9880500435829163\n",
      "tensor([0., 1.]) tensor([0.6748, 0.3252], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 11 - 321: dog - cat || Loss: 0.9873031973838806\n",
      "tensor([0., 1.]) tensor([0.6740, 0.3260], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 11 - 322: dog - cat || Loss: 0.9865558743476868\n",
      "tensor([0., 1.]) tensor([0.6733, 0.3267], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 11 - 323: dog - cat || Loss: 0.9858078956604004\n",
      "tensor([0., 1.]) tensor([0.6725, 0.3275], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 11 - 324: dog - cat || Loss: 0.9850592017173767\n",
      "tensor([0., 1.]) tensor([0.6718, 0.3282], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 11 - 325: dog - cat || Loss: 0.9843100309371948\n",
      "tensor([0., 1.]) tensor([0.6710, 0.3290], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 11 - 326: dog - cat || Loss: 0.9835601449012756\n",
      "tensor([0., 1.]) tensor([0.6703, 0.3297], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 11 - 327: dog - cat || Loss: 0.9828097820281982\n",
      "tensor([0., 1.]) tensor([0.6695, 0.3305], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 11 - 328: dog - cat || Loss: 0.9820587635040283\n",
      "tensor([0., 1.]) tensor([0.6688, 0.3312], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 11 - 329: dog - cat || Loss: 0.9813071489334106\n",
      "tensor([0., 1.]) tensor([0.6680, 0.3320], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 11 - 330: dog - cat || Loss: 0.9805549383163452\n",
      "tensor([0., 1.]) tensor([0.6673, 0.3327], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 11 - 331: dog - cat || Loss: 0.979802131652832\n",
      "tensor([0., 1.]) tensor([0.6665, 0.3335], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 11 - 332: dog - cat || Loss: 0.9790486693382263\n",
      "tensor([0., 1.]) tensor([0.6658, 0.3342], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 11 - 333: dog - cat || Loss: 0.9782946109771729\n",
      "tensor([0., 1.]) tensor([0.6650, 0.3350], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 11 - 334: dog - cat || Loss: 0.9775400161743164\n",
      "tensor([0., 1.]) tensor([0.6643, 0.3357], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 11 - 335: dog - cat || Loss: 0.9767848253250122\n",
      "tensor([0., 1.]) tensor([0.6635, 0.3365], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 11 - 336: dog - cat || Loss: 0.9760292172431946\n",
      "tensor([0., 1.]) tensor([0.6628, 0.3372], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 11 - 337: dog - cat || Loss: 0.9752728939056396\n",
      "tensor([0., 1.]) tensor([0.6620, 0.3380], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 11 - 338: dog - cat || Loss: 0.974515974521637\n",
      "tensor([0., 1.]) tensor([0.6613, 0.3387], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 11 - 339: dog - cat || Loss: 0.9737585783004761\n",
      "tensor([0., 1.]) tensor([0.6605, 0.3395], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 11 - 340: dog - cat || Loss: 0.9730005264282227\n",
      "tensor([0., 1.]) tensor([0.6597, 0.3403], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 11 - 341: dog - cat || Loss: 0.972241997718811\n",
      "tensor([0., 1.]) tensor([0.6590, 0.3410], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 11 - 342: dog - cat || Loss: 0.9714828133583069\n",
      "tensor([0., 1.]) tensor([0.6582, 0.3418], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 11 - 343: dog - cat || Loss: 0.9707231521606445\n",
      "tensor([0., 1.]) tensor([0.6575, 0.3425], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 11 - 344: dog - cat || Loss: 0.9699628949165344\n",
      "tensor([0., 1.]) tensor([0.6567, 0.3433], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 11 - 345: dog - cat || Loss: 0.9692020416259766\n",
      "tensor([0., 1.]) tensor([0.6559, 0.3441], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 11 - 346: dog - cat || Loss: 0.9684407114982605\n",
      "tensor([0., 1.]) tensor([0.6552, 0.3448], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 11 - 347: dog - cat || Loss: 0.9676787257194519\n",
      "tensor([0., 1.]) tensor([0.6544, 0.3456], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 11 - 348: dog - cat || Loss: 0.9669160842895508\n",
      "tensor([0., 1.]) tensor([0.6537, 0.3463], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 11 - 349: dog - cat || Loss: 0.9661530256271362\n",
      "tensor([0., 1.]) tensor([0.6529, 0.3471], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 11 - 350: dog - cat || Loss: 0.9653893113136292\n",
      "tensor([0., 1.]) tensor([0.6521, 0.3479], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 11 - 351: dog - cat || Loss: 0.9646250605583191\n",
      "tensor([0., 1.]) tensor([0.6514, 0.3486], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 11 - 352: dog - cat || Loss: 0.963860273361206\n",
      "tensor([0., 1.]) tensor([0.6506, 0.3494], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 11 - 353: dog - cat || Loss: 0.9630948305130005\n",
      "tensor([0., 1.]) tensor([0.6498, 0.3502], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 11 - 354: dog - cat || Loss: 0.9623288512229919\n",
      "tensor([0., 1.]) tensor([0.6491, 0.3509], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 11 - 355: dog - cat || Loss: 0.9615623950958252\n",
      "tensor([0., 1.]) tensor([0.6483, 0.3517], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 11 - 356: dog - cat || Loss: 0.9607951641082764\n",
      "tensor([0., 1.]) tensor([0.6475, 0.3525], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 11 - 357: dog - cat || Loss: 0.9600274562835693\n",
      "tensor([0., 1.]) tensor([0.6468, 0.3532], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 11 - 358: dog - cat || Loss: 0.959259033203125\n",
      "tensor([0., 1.]) tensor([0.6460, 0.3540], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 11 - 359: dog - cat || Loss: 0.9584901332855225\n",
      "tensor([0., 1.]) tensor([0.6452, 0.3548], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 11 - 360: dog - cat || Loss: 0.9577206373214722\n",
      "tensor([0., 1.]) tensor([0.6445, 0.3555], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 11 - 361: dog - cat || Loss: 0.9569504261016846\n",
      "tensor([0., 1.]) tensor([0.6437, 0.3563], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 11 - 362: dog - cat || Loss: 0.956179678440094\n",
      "tensor([0., 1.]) tensor([0.6429, 0.3571], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 11 - 363: dog - cat || Loss: 0.9554084539413452\n",
      "tensor([0., 1.]) tensor([0.6421, 0.3579], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 11 - 364: dog - cat || Loss: 0.9546366930007935\n",
      "tensor([0., 1.]) tensor([0.6414, 0.3586], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 11 - 365: dog - cat || Loss: 0.953864336013794\n",
      "tensor([0., 1.]) tensor([0.6406, 0.3594], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 11 - 366: dog - cat || Loss: 0.9530915021896362\n",
      "tensor([0., 1.]) tensor([0.6398, 0.3602], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 11 - 367: dog - cat || Loss: 0.9523180723190308\n",
      "tensor([0., 1.]) tensor([0.6391, 0.3609], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 11 - 368: dog - cat || Loss: 0.9515442252159119\n",
      "tensor([0., 1.]) tensor([0.6383, 0.3617], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 11 - 369: dog - cat || Loss: 0.9507696628570557\n",
      "tensor([0., 1.]) tensor([0.6375, 0.3625], grad_fn=<SoftmaxBackward0>)\n",
      "=====epoch:12=====\n",
      "Epoch 12 - 0: cat - cat || Loss: 0.6765285730361938\n",
      "tensor([1., 0.]) tensor([0.6367, 0.3633], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 12 - 1: cat - cat || Loss: 0.6771484017372131\n",
      "tensor([1., 0.]) tensor([0.6361, 0.3639], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 12 - 2: cat - cat || Loss: 0.6776284575462341\n",
      "tensor([1., 0.]) tensor([0.6356, 0.3644], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 12 - 3: cat - cat || Loss: 0.6779828071594238\n",
      "tensor([1., 0.]) tensor([0.6353, 0.3647], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 12 - 4: cat - cat || Loss: 0.6782236099243164\n",
      "tensor([1., 0.]) tensor([0.6350, 0.3650], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 12 - 5: cat - cat || Loss: 0.6783626079559326\n",
      "tensor([1., 0.]) tensor([0.6349, 0.3651], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 12 - 6: cat - cat || Loss: 0.6784096956253052\n",
      "tensor([1., 0.]) tensor([0.6349, 0.3651], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 12 - 7: cat - cat || Loss: 0.678374171257019\n",
      "tensor([1., 0.]) tensor([0.6349, 0.3651], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 12 - 8: cat - cat || Loss: 0.6782642602920532\n",
      "tensor([1., 0.]) tensor([0.6350, 0.3650], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 12 - 9: cat - cat || Loss: 0.678087592124939\n",
      "tensor([1., 0.]) tensor([0.6352, 0.3648], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 12 - 10: cat - cat || Loss: 0.6778506636619568\n",
      "tensor([1., 0.]) tensor([0.6354, 0.3646], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 12 - 11: cat - cat || Loss: 0.677559494972229\n",
      "tensor([1., 0.]) tensor([0.6357, 0.3643], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 12 - 12: cat - cat || Loss: 0.677219808101654\n",
      "tensor([1., 0.]) tensor([0.6360, 0.3640], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 12 - 13: cat - cat || Loss: 0.6768362522125244\n",
      "tensor([1., 0.]) tensor([0.6364, 0.3636], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 12 - 14: cat - cat || Loss: 0.676413357257843\n",
      "tensor([1., 0.]) tensor([0.6368, 0.3632], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 12 - 15: cat - cat || Loss: 0.6759549379348755\n",
      "tensor([1., 0.]) tensor([0.6373, 0.3627], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 12 - 16: cat - cat || Loss: 0.675464928150177\n",
      "tensor([1., 0.]) tensor([0.6378, 0.3622], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 12 - 17: cat - cat || Loss: 0.6749461889266968\n",
      "tensor([1., 0.]) tensor([0.6383, 0.3617], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 12 - 18: cat - cat || Loss: 0.6744018793106079\n",
      "tensor([1., 0.]) tensor([0.6389, 0.3611], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 12 - 19: cat - cat || Loss: 0.673834502696991\n",
      "tensor([1., 0.]) tensor([0.6394, 0.3606], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 12 - 20: cat - cat || Loss: 0.673246443271637\n",
      "tensor([1., 0.]) tensor([0.6400, 0.3600], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 12 - 21: cat - cat || Loss: 0.6726398468017578\n",
      "tensor([1., 0.]) tensor([0.6406, 0.3594], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 12 - 22: cat - cat || Loss: 0.6720167994499207\n",
      "tensor([1., 0.]) tensor([0.6412, 0.3588], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 12 - 23: cat - cat || Loss: 0.6713787317276001\n",
      "tensor([1., 0.]) tensor([0.6419, 0.3581], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 12 - 24: cat - cat || Loss: 0.6707273125648499\n",
      "tensor([1., 0.]) tensor([0.6425, 0.3575], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 12 - 25: cat - cat || Loss: 0.6700640320777893\n",
      "tensor([1., 0.]) tensor([0.6432, 0.3568], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 12 - 26: cat - cat || Loss: 0.6693901419639587\n",
      "tensor([1., 0.]) tensor([0.6439, 0.3561], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 12 - 27: cat - cat || Loss: 0.6687065958976746\n",
      "tensor([1., 0.]) tensor([0.6446, 0.3554], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 12 - 28: cat - cat || Loss: 0.6680145263671875\n",
      "tensor([1., 0.]) tensor([0.6452, 0.3548], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 12 - 29: cat - cat || Loss: 0.667314887046814\n",
      "tensor([1., 0.]) tensor([0.6459, 0.3541], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 12 - 30: cat - cat || Loss: 0.6666085720062256\n",
      "tensor([1., 0.]) tensor([0.6467, 0.3533], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 12 - 31: cat - cat || Loss: 0.6658961772918701\n",
      "tensor([1., 0.]) tensor([0.6474, 0.3526], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 12 - 32: cat - cat || Loss: 0.6651782393455505\n",
      "tensor([1., 0.]) tensor([0.6481, 0.3519], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 12 - 33: cat - cat || Loss: 0.6644557118415833\n",
      "tensor([1., 0.]) tensor([0.6488, 0.3512], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 12 - 34: cat - cat || Loss: 0.6637287139892578\n",
      "tensor([1., 0.]) tensor([0.6495, 0.3505], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 12 - 35: cat - cat || Loss: 0.6629979014396667\n",
      "tensor([1., 0.]) tensor([0.6503, 0.3497], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 12 - 36: cat - cat || Loss: 0.6622638702392578\n",
      "tensor([1., 0.]) tensor([0.6510, 0.3490], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 12 - 37: cat - cat || Loss: 0.6615268588066101\n",
      "tensor([1., 0.]) tensor([0.6517, 0.3483], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 12 - 38: cat - cat || Loss: 0.6607872843742371\n",
      "tensor([1., 0.]) tensor([0.6525, 0.3475], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 12 - 39: cat - cat || Loss: 0.6600453853607178\n",
      "tensor([1., 0.]) tensor([0.6532, 0.3468], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 12 - 40: cat - cat || Loss: 0.6593016386032104\n",
      "tensor([1., 0.]) tensor([0.6540, 0.3460], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 12 - 41: cat - cat || Loss: 0.6585558652877808\n",
      "tensor([1., 0.]) tensor([0.6547, 0.3453], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 12 - 42: cat - cat || Loss: 0.6578089594841003\n",
      "tensor([1., 0.]) tensor([0.6555, 0.3445], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 12 - 43: cat - cat || Loss: 0.6570605039596558\n",
      "tensor([1., 0.]) tensor([0.6562, 0.3438], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 12 - 44: cat - cat || Loss: 0.6563111543655396\n",
      "tensor([1., 0.]) tensor([0.6570, 0.3430], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 12 - 45: cat - cat || Loss: 0.6555606722831726\n",
      "tensor([1., 0.]) tensor([0.6577, 0.3423], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 12 - 46: cat - cat || Loss: 0.6548095345497131\n",
      "tensor([1., 0.]) tensor([0.6585, 0.3415], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 12 - 47: cat - cat || Loss: 0.6540577411651611\n",
      "tensor([1., 0.]) tensor([0.6592, 0.3408], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 12 - 48: cat - cat || Loss: 0.6533053517341614\n",
      "tensor([1., 0.]) tensor([0.6600, 0.3400], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 12 - 49: cat - cat || Loss: 0.652552604675293\n",
      "tensor([1., 0.]) tensor([0.6607, 0.3393], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 12 - 50: cat - cat || Loss: 0.6517994999885559\n",
      "tensor([1., 0.]) tensor([0.6615, 0.3385], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 12 - 51: cat - cat || Loss: 0.6510462760925293\n",
      "tensor([1., 0.]) tensor([0.6622, 0.3378], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 12 - 52: cat - cat || Loss: 0.6502928137779236\n",
      "tensor([1., 0.]) tensor([0.6630, 0.3370], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 12 - 53: cat - cat || Loss: 0.6495394110679626\n",
      "tensor([1., 0.]) tensor([0.6637, 0.3363], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 12 - 54: cat - cat || Loss: 0.6487859487533569\n",
      "tensor([1., 0.]) tensor([0.6645, 0.3355], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 12 - 55: cat - cat || Loss: 0.6480326056480408\n",
      "tensor([1., 0.]) tensor([0.6652, 0.3348], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 12 - 56: cat - cat || Loss: 0.6472793817520142\n",
      "tensor([1., 0.]) tensor([0.6660, 0.3340], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 12 - 57: cat - cat || Loss: 0.6465263366699219\n",
      "tensor([1., 0.]) tensor([0.6667, 0.3333], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 12 - 58: cat - cat || Loss: 0.6457735300064087\n",
      "tensor([1., 0.]) tensor([0.6675, 0.3325], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 12 - 59: cat - cat || Loss: 0.6450210809707642\n",
      "tensor([1., 0.]) tensor([0.6682, 0.3318], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 12 - 60: cat - cat || Loss: 0.6442688703536987\n",
      "tensor([1., 0.]) tensor([0.6690, 0.3310], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 12 - 61: cat - cat || Loss: 0.6435170769691467\n",
      "tensor([1., 0.]) tensor([0.6697, 0.3303], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 12 - 62: cat - cat || Loss: 0.6427655816078186\n",
      "tensor([1., 0.]) tensor([0.6705, 0.3295], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 12 - 63: cat - cat || Loss: 0.6420146226882935\n",
      "tensor([1., 0.]) tensor([0.6712, 0.3288], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 12 - 64: cat - cat || Loss: 0.6412639617919922\n",
      "tensor([1., 0.]) tensor([0.6720, 0.3280], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 12 - 65: cat - cat || Loss: 0.6405138969421387\n",
      "tensor([1., 0.]) tensor([0.6727, 0.3273], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 12 - 66: cat - cat || Loss: 0.6397642493247986\n",
      "tensor([1., 0.]) tensor([0.6735, 0.3265], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 12 - 67: cat - cat || Loss: 0.6390151381492615\n",
      "tensor([1., 0.]) tensor([0.6742, 0.3258], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 12 - 68: cat - cat || Loss: 0.6382665038108826\n",
      "tensor([1., 0.]) tensor([0.6750, 0.3250], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 12 - 69: cat - cat || Loss: 0.6375184059143066\n",
      "tensor([1., 0.]) tensor([0.6757, 0.3243], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 12 - 70: cat - cat || Loss: 0.6367709040641785\n",
      "tensor([1., 0.]) tensor([0.6765, 0.3235], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 12 - 71: cat - cat || Loss: 0.6360238790512085\n",
      "tensor([1., 0.]) tensor([0.6772, 0.3228], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 12 - 72: cat - cat || Loss: 0.6352773904800415\n",
      "tensor([1., 0.]) tensor([0.6780, 0.3220], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 12 - 73: cat - cat || Loss: 0.634531557559967\n",
      "tensor([1., 0.]) tensor([0.6787, 0.3213], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 12 - 74: cat - cat || Loss: 0.6337863206863403\n",
      "tensor([1., 0.]) tensor([0.6795, 0.3205], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 12 - 75: cat - cat || Loss: 0.6330417990684509\n",
      "tensor([1., 0.]) tensor([0.6802, 0.3198], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 12 - 76: cat - cat || Loss: 0.632297933101654\n",
      "tensor([1., 0.]) tensor([0.6810, 0.3190], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 12 - 77: cat - cat || Loss: 0.6315546035766602\n",
      "tensor([1., 0.]) tensor([0.6817, 0.3183], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 12 - 78: cat - cat || Loss: 0.6308119893074036\n",
      "tensor([1., 0.]) tensor([0.6824, 0.3176], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 12 - 79: cat - cat || Loss: 0.63006991147995\n",
      "tensor([1., 0.]) tensor([0.6832, 0.3168], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 12 - 80: cat - cat || Loss: 0.629328727722168\n",
      "tensor([1., 0.]) tensor([0.6839, 0.3161], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 12 - 81: cat - cat || Loss: 0.628588080406189\n",
      "tensor([1., 0.]) tensor([0.6847, 0.3153], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 12 - 82: cat - cat || Loss: 0.6278480291366577\n",
      "tensor([1., 0.]) tensor([0.6854, 0.3146], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 12 - 83: cat - cat || Loss: 0.6271088123321533\n",
      "tensor([1., 0.]) tensor([0.6862, 0.3138], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 12 - 84: cat - cat || Loss: 0.6263701915740967\n",
      "tensor([1., 0.]) tensor([0.6869, 0.3131], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 12 - 85: cat - cat || Loss: 0.6256323456764221\n",
      "tensor([1., 0.]) tensor([0.6876, 0.3124], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 12 - 86: cat - cat || Loss: 0.6248950958251953\n",
      "tensor([1., 0.]) tensor([0.6884, 0.3116], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 12 - 87: cat - cat || Loss: 0.6241586208343506\n",
      "tensor([1., 0.]) tensor([0.6891, 0.3109], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 12 - 88: cat - cat || Loss: 0.6234227418899536\n",
      "tensor([1., 0.]) tensor([0.6898, 0.3102], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 12 - 89: cat - cat || Loss: 0.6226876378059387\n",
      "tensor([1., 0.]) tensor([0.6906, 0.3094], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 12 - 90: cat - cat || Loss: 0.6219532489776611\n",
      "tensor([1., 0.]) tensor([0.6913, 0.3087], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 12 - 91: cat - cat || Loss: 0.6212193965911865\n",
      "tensor([1., 0.]) tensor([0.6920, 0.3080], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 12 - 92: cat - cat || Loss: 0.6204864382743835\n",
      "tensor([1., 0.]) tensor([0.6928, 0.3072], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 12 - 93: cat - cat || Loss: 0.6197540760040283\n",
      "tensor([1., 0.]) tensor([0.6935, 0.3065], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 12 - 94: cat - cat || Loss: 0.6190225481987\n",
      "tensor([1., 0.]) tensor([0.6942, 0.3058], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 12 - 95: cat - cat || Loss: 0.6182916164398193\n",
      "tensor([1., 0.]) tensor([0.6950, 0.3050], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 12 - 96: cat - cat || Loss: 0.6175615191459656\n",
      "tensor([1., 0.]) tensor([0.6957, 0.3043], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 12 - 97: cat - cat || Loss: 0.6168321371078491\n",
      "tensor([1., 0.]) tensor([0.6964, 0.3036], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 12 - 98: cat - cat || Loss: 0.6161035299301147\n",
      "tensor([1., 0.]) tensor([0.6972, 0.3028], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 12 - 99: cat - cat || Loss: 0.6153756380081177\n",
      "tensor([1., 0.]) tensor([0.6979, 0.3021], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 12 - 100: cat - cat || Loss: 0.6146485805511475\n",
      "tensor([1., 0.]) tensor([0.6986, 0.3014], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 12 - 101: cat - cat || Loss: 0.6139221787452698\n",
      "tensor([1., 0.]) tensor([0.6993, 0.3007], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 12 - 102: cat - cat || Loss: 0.613196611404419\n",
      "tensor([1., 0.]) tensor([0.7001, 0.2999], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 12 - 103: cat - cat || Loss: 0.6124715805053711\n",
      "tensor([1., 0.]) tensor([0.7008, 0.2992], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 12 - 104: cat - cat || Loss: 0.6117473840713501\n",
      "tensor([1., 0.]) tensor([0.7015, 0.2985], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 12 - 105: cat - cat || Loss: 0.6110240817070007\n",
      "tensor([1., 0.]) tensor([0.7022, 0.2978], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 12 - 106: cat - cat || Loss: 0.6103013753890991\n",
      "tensor([1., 0.]) tensor([0.7030, 0.2970], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 12 - 107: cat - cat || Loss: 0.6095794439315796\n",
      "tensor([1., 0.]) tensor([0.7037, 0.2963], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 12 - 108: cat - cat || Loss: 0.6088582277297974\n",
      "tensor([1., 0.]) tensor([0.7044, 0.2956], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 12 - 109: cat - cat || Loss: 0.608137845993042\n",
      "tensor([1., 0.]) tensor([0.7051, 0.2949], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 12 - 110: cat - cat || Loss: 0.6074181199073792\n",
      "tensor([1., 0.]) tensor([0.7058, 0.2942], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 12 - 111: cat - cat || Loss: 0.6066992878913879\n",
      "tensor([1., 0.]) tensor([0.7066, 0.2934], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 12 - 112: cat - cat || Loss: 0.6059812307357788\n",
      "tensor([1., 0.]) tensor([0.7073, 0.2927], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 12 - 113: cat - cat || Loss: 0.6052638292312622\n",
      "tensor([1., 0.]) tensor([0.7080, 0.2920], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 12 - 114: cat - cat || Loss: 0.6045472621917725\n",
      "tensor([1., 0.]) tensor([0.7087, 0.2913], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 12 - 115: cat - cat || Loss: 0.6038314700126648\n",
      "tensor([1., 0.]) tensor([0.7094, 0.2906], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 12 - 116: cat - cat || Loss: 0.6031164526939392\n",
      "tensor([1., 0.]) tensor([0.7101, 0.2899], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 12 - 117: cat - cat || Loss: 0.6024022698402405\n",
      "tensor([1., 0.]) tensor([0.7109, 0.2891], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 12 - 118: cat - cat || Loss: 0.6016887426376343\n",
      "tensor([1., 0.]) tensor([0.7116, 0.2884], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 12 - 119: cat - cat || Loss: 0.6009760499000549\n",
      "tensor([1., 0.]) tensor([0.7123, 0.2877], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 12 - 120: cat - cat || Loss: 0.6002641320228577\n",
      "tensor([1., 0.]) tensor([0.7130, 0.2870], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 12 - 121: cat - cat || Loss: 0.5995530486106873\n",
      "tensor([1., 0.]) tensor([0.7137, 0.2863], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 12 - 122: cat - cat || Loss: 0.5988428592681885\n",
      "tensor([1., 0.]) tensor([0.7144, 0.2856], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 12 - 123: cat - cat || Loss: 0.598133385181427\n",
      "tensor([1., 0.]) tensor([0.7151, 0.2849], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 12 - 124: cat - cat || Loss: 0.5974247455596924\n",
      "tensor([1., 0.]) tensor([0.7158, 0.2842], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 12 - 125: cat - cat || Loss: 0.5967169404029846\n",
      "tensor([1., 0.]) tensor([0.7165, 0.2835], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 12 - 126: cat - cat || Loss: 0.5960098505020142\n",
      "tensor([1., 0.]) tensor([0.7173, 0.2827], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 12 - 127: cat - cat || Loss: 0.5953035950660706\n",
      "tensor([1., 0.]) tensor([0.7180, 0.2820], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 12 - 128: cat - cat || Loss: 0.594598114490509\n",
      "tensor([1., 0.]) tensor([0.7187, 0.2813], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 12 - 129: cat - cat || Loss: 0.5938935279846191\n",
      "tensor([1., 0.]) tensor([0.7194, 0.2806], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 12 - 130: cat - cat || Loss: 0.5931898951530457\n",
      "tensor([1., 0.]) tensor([0.7201, 0.2799], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 12 - 131: cat - cat || Loss: 0.5924867987632751\n",
      "tensor([1., 0.]) tensor([0.7208, 0.2792], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 12 - 132: cat - cat || Loss: 0.5917845964431763\n",
      "tensor([1., 0.]) tensor([0.7215, 0.2785], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 12 - 133: cat - cat || Loss: 0.5910833477973938\n",
      "tensor([1., 0.]) tensor([0.7222, 0.2778], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 12 - 134: cat - cat || Loss: 0.5903828144073486\n",
      "tensor([1., 0.]) tensor([0.7229, 0.2771], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 12 - 135: cat - cat || Loss: 0.5896831750869751\n",
      "tensor([1., 0.]) tensor([0.7236, 0.2764], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 12 - 136: cat - cat || Loss: 0.5889842510223389\n",
      "tensor([1., 0.]) tensor([0.7243, 0.2757], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 12 - 137: cat - cat || Loss: 0.5882861614227295\n",
      "tensor([1., 0.]) tensor([0.7250, 0.2750], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 12 - 138: cat - cat || Loss: 0.5875890254974365\n",
      "tensor([1., 0.]) tensor([0.7257, 0.2743], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 12 - 139: cat - cat || Loss: 0.5868926644325256\n",
      "tensor([1., 0.]) tensor([0.7264, 0.2736], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 12 - 140: cat - cat || Loss: 0.5861971378326416\n",
      "tensor([1., 0.]) tensor([0.7271, 0.2729], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 12 - 141: cat - cat || Loss: 0.5855024456977844\n",
      "tensor([1., 0.]) tensor([0.7278, 0.2722], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 12 - 142: cat - cat || Loss: 0.5848087072372437\n",
      "tensor([1., 0.]) tensor([0.7285, 0.2715], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 12 - 143: cat - cat || Loss: 0.584115743637085\n",
      "tensor([1., 0.]) tensor([0.7291, 0.2709], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 12 - 144: cat - cat || Loss: 0.5834235548973083\n",
      "tensor([1., 0.]) tensor([0.7298, 0.2702], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 12 - 145: cat - cat || Loss: 0.5827323198318481\n",
      "tensor([1., 0.]) tensor([0.7305, 0.2695], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 12 - 146: cat - cat || Loss: 0.5820419788360596\n",
      "tensor([1., 0.]) tensor([0.7312, 0.2688], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 12 - 147: cat - cat || Loss: 0.5813524127006531\n",
      "tensor([1., 0.]) tensor([0.7319, 0.2681], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 12 - 148: cat - cat || Loss: 0.5806636810302734\n",
      "tensor([1., 0.]) tensor([0.7326, 0.2674], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 12 - 149: cat - cat || Loss: 0.5799758434295654\n",
      "tensor([1., 0.]) tensor([0.7333, 0.2667], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 12 - 150: cat - cat || Loss: 0.5792888402938843\n",
      "tensor([1., 0.]) tensor([0.7340, 0.2660], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 12 - 151: cat - cat || Loss: 0.5786027908325195\n",
      "tensor([1., 0.]) tensor([0.7347, 0.2653], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 12 - 152: cat - cat || Loss: 0.5779175758361816\n",
      "tensor([1., 0.]) tensor([0.7353, 0.2647], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 12 - 153: cat - cat || Loss: 0.5772331953048706\n",
      "tensor([1., 0.]) tensor([0.7360, 0.2640], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 12 - 154: cat - cat || Loss: 0.5765495896339417\n",
      "tensor([1., 0.]) tensor([0.7367, 0.2633], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 12 - 155: cat - cat || Loss: 0.5758669972419739\n",
      "tensor([1., 0.]) tensor([0.7374, 0.2626], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 12 - 156: cat - cat || Loss: 0.5751852989196777\n",
      "tensor([1., 0.]) tensor([0.7381, 0.2619], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 12 - 157: cat - cat || Loss: 0.5745043754577637\n",
      "tensor([1., 0.]) tensor([0.7388, 0.2612], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 12 - 158: cat - cat || Loss: 0.5738242864608765\n",
      "tensor([1., 0.]) tensor([0.7394, 0.2606], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 12 - 159: cat - cat || Loss: 0.5731451511383057\n",
      "tensor([1., 0.]) tensor([0.7401, 0.2599], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 12 - 160: cat - cat || Loss: 0.5724668502807617\n",
      "tensor([1., 0.]) tensor([0.7408, 0.2592], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 12 - 161: cat - cat || Loss: 0.5717896223068237\n",
      "tensor([1., 0.]) tensor([0.7415, 0.2585], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 12 - 162: cat - cat || Loss: 0.571113109588623\n",
      "tensor([1., 0.]) tensor([0.7421, 0.2579], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 12 - 163: cat - cat || Loss: 0.5704375505447388\n",
      "tensor([1., 0.]) tensor([0.7428, 0.2572], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 12 - 164: cat - cat || Loss: 0.5697627663612366\n",
      "tensor([1., 0.]) tensor([0.7435, 0.2565], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 12 - 165: cat - cat || Loss: 0.5690890550613403\n",
      "tensor([1., 0.]) tensor([0.7442, 0.2558], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 12 - 166: cat - cat || Loss: 0.5684160590171814\n",
      "tensor([1., 0.]) tensor([0.7448, 0.2552], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 12 - 167: cat - cat || Loss: 0.5677440762519836\n",
      "tensor([1., 0.]) tensor([0.7455, 0.2545], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 12 - 168: cat - cat || Loss: 0.567072868347168\n",
      "tensor([1., 0.]) tensor([0.7462, 0.2538], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 12 - 169: cat - cat || Loss: 0.5664026141166687\n",
      "tensor([1., 0.]) tensor([0.7469, 0.2531], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 12 - 170: cat - cat || Loss: 0.5657333135604858\n",
      "tensor([1., 0.]) tensor([0.7475, 0.2525], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 12 - 171: cat - cat || Loss: 0.5650650262832642\n",
      "tensor([1., 0.]) tensor([0.7482, 0.2518], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 12 - 172: cat - cat || Loss: 0.5643976330757141\n",
      "tensor([1., 0.]) tensor([0.7489, 0.2511], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 12 - 173: cat - cat || Loss: 0.5637311935424805\n",
      "tensor([1., 0.]) tensor([0.7495, 0.2505], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 12 - 174: cat - cat || Loss: 0.5630654692649841\n",
      "tensor([1., 0.]) tensor([0.7502, 0.2498], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 12 - 175: cat - cat || Loss: 0.562400758266449\n",
      "tensor([1., 0.]) tensor([0.7509, 0.2491], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 12 - 176: cat - cat || Loss: 0.5617369413375854\n",
      "tensor([1., 0.]) tensor([0.7515, 0.2485], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 12 - 177: cat - cat || Loss: 0.5610740780830383\n",
      "tensor([1., 0.]) tensor([0.7522, 0.2478], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 12 - 178: cat - cat || Loss: 0.5604120492935181\n",
      "tensor([1., 0.]) tensor([0.7528, 0.2472], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 12 - 179: cat - cat || Loss: 0.559751033782959\n",
      "tensor([1., 0.]) tensor([0.7535, 0.2465], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 12 - 180: cat - cat || Loss: 0.5590908527374268\n",
      "tensor([1., 0.]) tensor([0.7542, 0.2458], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 12 - 181: cat - cat || Loss: 0.5584316253662109\n",
      "tensor([1., 0.]) tensor([0.7548, 0.2452], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 12 - 182: cat - cat || Loss: 0.5577732920646667\n",
      "tensor([1., 0.]) tensor([0.7555, 0.2445], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 12 - 183: cat - cat || Loss: 0.5571159720420837\n",
      "tensor([1., 0.]) tensor([0.7561, 0.2439], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 12 - 184: cat - cat || Loss: 0.5564594268798828\n",
      "tensor([1., 0.]) tensor([0.7568, 0.2432], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 12 - 185: cat - cat || Loss: 0.5558040142059326\n",
      "tensor([1., 0.]) tensor([0.7575, 0.2425], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 12 - 186: cat - cat || Loss: 0.5551493167877197\n",
      "tensor([1., 0.]) tensor([0.7581, 0.2419], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 12 - 187: cat - cat || Loss: 0.5544958114624023\n",
      "tensor([1., 0.]) tensor([0.7588, 0.2412], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 12 - 188: cat - cat || Loss: 0.5538430213928223\n",
      "tensor([1., 0.]) tensor([0.7594, 0.2406], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 12 - 189: cat - cat || Loss: 0.5531913042068481\n",
      "tensor([1., 0.]) tensor([0.7601, 0.2399], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 12 - 190: dog - cat || Loss: 1.073982834815979\n",
      "tensor([0., 1.]) tensor([0.7607, 0.2393], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 12 - 191: dog - cat || Loss: 1.0745035409927368\n",
      "tensor([0., 1.]) tensor([0.7612, 0.2388], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 12 - 192: dog - cat || Loss: 1.0749073028564453\n",
      "tensor([0., 1.]) tensor([0.7616, 0.2384], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 12 - 193: dog - cat || Loss: 1.0752060413360596\n",
      "tensor([0., 1.]) tensor([0.7619, 0.2381], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 12 - 194: dog - cat || Loss: 1.0754104852676392\n",
      "tensor([0., 1.]) tensor([0.7621, 0.2379], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 12 - 195: dog - cat || Loss: 1.075529932975769\n",
      "tensor([0., 1.]) tensor([0.7623, 0.2377], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 12 - 196: dog - cat || Loss: 1.0755730867385864\n",
      "tensor([0., 1.]) tensor([0.7623, 0.2377], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 12 - 197: dog - cat || Loss: 1.075547456741333\n",
      "tensor([0., 1.]) tensor([0.7623, 0.2377], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 12 - 198: dog - cat || Loss: 1.0754601955413818\n",
      "tensor([0., 1.]) tensor([0.7622, 0.2378], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 12 - 199: dog - cat || Loss: 1.075317144393921\n",
      "tensor([0., 1.]) tensor([0.7621, 0.2379], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 12 - 200: dog - cat || Loss: 1.0751237869262695\n",
      "tensor([0., 1.]) tensor([0.7619, 0.2381], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 12 - 201: dog - cat || Loss: 1.0748854875564575\n",
      "tensor([0., 1.]) tensor([0.7616, 0.2384], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 12 - 202: dog - cat || Loss: 1.0746062994003296\n",
      "tensor([0., 1.]) tensor([0.7613, 0.2387], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 12 - 203: dog - cat || Loss: 1.0742906332015991\n",
      "tensor([0., 1.]) tensor([0.7610, 0.2390], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 12 - 204: dog - cat || Loss: 1.073941707611084\n",
      "tensor([0., 1.]) tensor([0.7607, 0.2393], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 12 - 205: dog - cat || Loss: 1.0735628604888916\n",
      "tensor([0., 1.]) tensor([0.7603, 0.2397], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 12 - 206: dog - cat || Loss: 1.0731571912765503\n",
      "tensor([0., 1.]) tensor([0.7599, 0.2401], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 12 - 207: dog - cat || Loss: 1.0727273225784302\n",
      "tensor([0., 1.]) tensor([0.7595, 0.2405], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 12 - 208: dog - cat || Loss: 1.0722752809524536\n",
      "tensor([0., 1.]) tensor([0.7590, 0.2410], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 12 - 209: dog - cat || Loss: 1.0718034505844116\n",
      "tensor([0., 1.]) tensor([0.7585, 0.2415], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 12 - 210: dog - cat || Loss: 1.071313738822937\n",
      "tensor([0., 1.]) tensor([0.7581, 0.2419], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 12 - 211: dog - cat || Loss: 1.070807933807373\n",
      "tensor([0., 1.]) tensor([0.7575, 0.2425], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 12 - 212: dog - cat || Loss: 1.0702869892120361\n",
      "tensor([0., 1.]) tensor([0.7570, 0.2430], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 12 - 213: dog - cat || Loss: 1.0697531700134277\n",
      "tensor([0., 1.]) tensor([0.7565, 0.2435], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 12 - 214: dog - cat || Loss: 1.0692070722579956\n",
      "tensor([0., 1.]) tensor([0.7559, 0.2441], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 12 - 215: dog - cat || Loss: 1.0686503648757935\n",
      "tensor([0., 1.]) tensor([0.7554, 0.2446], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 12 - 216: dog - cat || Loss: 1.0680835247039795\n",
      "tensor([0., 1.]) tensor([0.7548, 0.2452], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 12 - 217: dog - cat || Loss: 1.0675076246261597\n",
      "tensor([0., 1.]) tensor([0.7542, 0.2458], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 12 - 218: dog - cat || Loss: 1.0669234991073608\n",
      "tensor([0., 1.]) tensor([0.7537, 0.2463], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 12 - 219: dog - cat || Loss: 1.0663321018218994\n",
      "tensor([0., 1.]) tensor([0.7531, 0.2469], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 12 - 220: dog - cat || Loss: 1.0657336711883545\n",
      "tensor([0., 1.]) tensor([0.7525, 0.2475], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 12 - 221: dog - cat || Loss: 1.065129041671753\n",
      "tensor([0., 1.]) tensor([0.7519, 0.2481], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 12 - 222: dog - cat || Loss: 1.064518928527832\n",
      "tensor([0., 1.]) tensor([0.7513, 0.2487], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 12 - 223: dog - cat || Loss: 1.0639033317565918\n",
      "tensor([0., 1.]) tensor([0.7506, 0.2494], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 12 - 224: dog - cat || Loss: 1.0632832050323486\n",
      "tensor([0., 1.]) tensor([0.7500, 0.2500], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 12 - 225: dog - cat || Loss: 1.0626587867736816\n",
      "tensor([0., 1.]) tensor([0.7494, 0.2506], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 12 - 226: dog - cat || Loss: 1.0620300769805908\n",
      "tensor([0., 1.]) tensor([0.7488, 0.2512], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 12 - 227: dog - cat || Loss: 1.061397910118103\n",
      "tensor([0., 1.]) tensor([0.7481, 0.2519], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 12 - 228: dog - cat || Loss: 1.0607621669769287\n",
      "tensor([0., 1.]) tensor([0.7475, 0.2525], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 12 - 229: dog - cat || Loss: 1.0601234436035156\n",
      "tensor([0., 1.]) tensor([0.7469, 0.2531], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 12 - 230: dog - cat || Loss: 1.0594813823699951\n",
      "tensor([0., 1.]) tensor([0.7462, 0.2538], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 12 - 231: dog - cat || Loss: 1.0588369369506836\n",
      "tensor([0., 1.]) tensor([0.7456, 0.2544], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 12 - 232: dog - cat || Loss: 1.058189868927002\n",
      "tensor([0., 1.]) tensor([0.7449, 0.2551], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 12 - 233: dog - cat || Loss: 1.0575405359268188\n",
      "tensor([0., 1.]) tensor([0.7443, 0.2557], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 12 - 234: dog - cat || Loss: 1.0568889379501343\n",
      "tensor([0., 1.]) tensor([0.7436, 0.2564], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 12 - 235: dog - cat || Loss: 1.0562351942062378\n",
      "tensor([0., 1.]) tensor([0.7430, 0.2570], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 12 - 236: dog - cat || Loss: 1.0555795431137085\n",
      "tensor([0., 1.]) tensor([0.7423, 0.2577], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 12 - 237: dog - cat || Loss: 1.054922103881836\n",
      "tensor([0., 1.]) tensor([0.7417, 0.2583], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 12 - 238: dog - cat || Loss: 1.0542631149291992\n",
      "tensor([0., 1.]) tensor([0.7410, 0.2590], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 12 - 239: dog - cat || Loss: 1.0536022186279297\n",
      "tensor([0., 1.]) tensor([0.7403, 0.2597], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 12 - 240: dog - cat || Loss: 1.0529398918151855\n",
      "tensor([0., 1.]) tensor([0.7397, 0.2603], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 12 - 241: dog - cat || Loss: 1.0522760152816772\n",
      "tensor([0., 1.]) tensor([0.7390, 0.2610], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 12 - 242: dog - cat || Loss: 1.0516105890274048\n",
      "tensor([0., 1.]) tensor([0.7383, 0.2617], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 12 - 243: dog - cat || Loss: 1.0509440898895264\n",
      "tensor([0., 1.]) tensor([0.7377, 0.2623], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 12 - 244: dog - cat || Loss: 1.050276279449463\n",
      "tensor([0., 1.]) tensor([0.7370, 0.2630], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 12 - 245: dog - cat || Loss: 1.0496071577072144\n",
      "tensor([0., 1.]) tensor([0.7363, 0.2637], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 12 - 246: dog - cat || Loss: 1.0489368438720703\n",
      "tensor([0., 1.]) tensor([0.7357, 0.2643], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 12 - 247: dog - cat || Loss: 1.0482650995254517\n",
      "tensor([0., 1.]) tensor([0.7350, 0.2650], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 12 - 248: dog - cat || Loss: 1.0475926399230957\n",
      "tensor([0., 1.]) tensor([0.7343, 0.2657], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 12 - 249: dog - cat || Loss: 1.0469186305999756\n",
      "tensor([0., 1.]) tensor([0.7337, 0.2663], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 12 - 250: dog - cat || Loss: 1.0462437868118286\n",
      "tensor([0., 1.]) tensor([0.7330, 0.2670], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 12 - 251: dog - cat || Loss: 1.0455679893493652\n",
      "tensor([0., 1.]) tensor([0.7323, 0.2677], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 12 - 252: dog - cat || Loss: 1.0448908805847168\n",
      "tensor([0., 1.]) tensor([0.7316, 0.2684], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 12 - 253: dog - cat || Loss: 1.044212818145752\n",
      "tensor([0., 1.]) tensor([0.7310, 0.2690], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 12 - 254: dog - cat || Loss: 1.0435338020324707\n",
      "tensor([0., 1.]) tensor([0.7303, 0.2697], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 12 - 255: dog - cat || Loss: 1.0428540706634521\n",
      "tensor([0., 1.]) tensor([0.7296, 0.2704], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 12 - 256: dog - cat || Loss: 1.042173147201538\n",
      "tensor([0., 1.]) tensor([0.7289, 0.2711], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 12 - 257: dog - cat || Loss: 1.0414913892745972\n",
      "tensor([0., 1.]) tensor([0.7282, 0.2718], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 12 - 258: dog - cat || Loss: 1.0408085584640503\n",
      "tensor([0., 1.]) tensor([0.7275, 0.2725], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 12 - 259: dog - cat || Loss: 1.0401251316070557\n",
      "tensor([0., 1.]) tensor([0.7269, 0.2731], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 12 - 260: dog - cat || Loss: 1.0394405126571655\n",
      "tensor([0., 1.]) tensor([0.7262, 0.2738], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 12 - 261: dog - cat || Loss: 1.038755178451538\n",
      "tensor([0., 1.]) tensor([0.7255, 0.2745], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 12 - 262: dog - cat || Loss: 1.0380688905715942\n",
      "tensor([0., 1.]) tensor([0.7248, 0.2752], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 12 - 263: dog - cat || Loss: 1.037381649017334\n",
      "tensor([0., 1.]) tensor([0.7241, 0.2759], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 12 - 264: dog - cat || Loss: 1.036693811416626\n",
      "tensor([0., 1.]) tensor([0.7234, 0.2766], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 12 - 265: dog - cat || Loss: 1.0360047817230225\n",
      "tensor([0., 1.]) tensor([0.7227, 0.2773], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 12 - 266: dog - cat || Loss: 1.0353152751922607\n",
      "tensor([0., 1.]) tensor([0.7221, 0.2779], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 12 - 267: dog - cat || Loss: 1.034624695777893\n",
      "tensor([0., 1.]) tensor([0.7214, 0.2786], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 12 - 268: dog - cat || Loss: 1.033933401107788\n",
      "tensor([0., 1.]) tensor([0.7207, 0.2793], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 12 - 269: dog - cat || Loss: 1.0332412719726562\n",
      "tensor([0., 1.]) tensor([0.7200, 0.2800], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 12 - 270: dog - cat || Loss: 1.0325483083724976\n",
      "tensor([0., 1.]) tensor([0.7193, 0.2807], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 12 - 271: dog - cat || Loss: 1.0318546295166016\n",
      "tensor([0., 1.]) tensor([0.7186, 0.2814], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 12 - 272: dog - cat || Loss: 1.0311599969863892\n",
      "tensor([0., 1.]) tensor([0.7179, 0.2821], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 12 - 273: dog - cat || Loss: 1.030464768409729\n",
      "tensor([0., 1.]) tensor([0.7172, 0.2828], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 12 - 274: dog - cat || Loss: 1.029768466949463\n",
      "tensor([0., 1.]) tensor([0.7165, 0.2835], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 12 - 275: dog - cat || Loss: 1.029071569442749\n",
      "tensor([0., 1.]) tensor([0.7158, 0.2842], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 12 - 276: dog - cat || Loss: 1.0283738374710083\n",
      "tensor([0., 1.]) tensor([0.7151, 0.2849], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 12 - 277: dog - cat || Loss: 1.0276752710342407\n",
      "tensor([0., 1.]) tensor([0.7144, 0.2856], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 12 - 278: dog - cat || Loss: 1.0269759893417358\n",
      "tensor([0., 1.]) tensor([0.7137, 0.2863], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 12 - 279: dog - cat || Loss: 1.026275873184204\n",
      "tensor([0., 1.]) tensor([0.7130, 0.2870], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 12 - 280: dog - cat || Loss: 1.0255749225616455\n",
      "tensor([0., 1.]) tensor([0.7123, 0.2877], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 12 - 281: dog - cat || Loss: 1.0248733758926392\n",
      "tensor([0., 1.]) tensor([0.7116, 0.2884], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 12 - 282: dog - cat || Loss: 1.0241711139678955\n",
      "tensor([0., 1.]) tensor([0.7109, 0.2891], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 12 - 283: dog - cat || Loss: 1.023467779159546\n",
      "tensor([0., 1.]) tensor([0.7102, 0.2898], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 12 - 284: dog - cat || Loss: 1.0227638483047485\n",
      "tensor([0., 1.]) tensor([0.7095, 0.2905], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 12 - 285: dog - cat || Loss: 1.0220592021942139\n",
      "tensor([0., 1.]) tensor([0.7088, 0.2912], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 12 - 286: dog - cat || Loss: 1.0213537216186523\n",
      "tensor([0., 1.]) tensor([0.7081, 0.2919], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 12 - 287: dog - cat || Loss: 1.0206475257873535\n",
      "tensor([0., 1.]) tensor([0.7074, 0.2926], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 12 - 288: dog - cat || Loss: 1.0199406147003174\n",
      "tensor([0., 1.]) tensor([0.7067, 0.2933], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 12 - 289: dog - cat || Loss: 1.0192327499389648\n",
      "tensor([0., 1.]) tensor([0.7060, 0.2940], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 12 - 290: dog - cat || Loss: 1.018524408340454\n",
      "tensor([0., 1.]) tensor([0.7053, 0.2947], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 12 - 291: dog - cat || Loss: 1.017815351486206\n",
      "tensor([0., 1.]) tensor([0.7046, 0.2954], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 12 - 292: dog - cat || Loss: 1.0171053409576416\n",
      "tensor([0., 1.]) tensor([0.7038, 0.2962], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 12 - 293: dog - cat || Loss: 1.0163947343826294\n",
      "tensor([0., 1.]) tensor([0.7031, 0.2969], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 12 - 294: dog - cat || Loss: 1.0156834125518799\n",
      "tensor([0., 1.]) tensor([0.7024, 0.2976], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 12 - 295: dog - cat || Loss: 1.014971375465393\n",
      "tensor([0., 1.]) tensor([0.7017, 0.2983], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 12 - 296: dog - cat || Loss: 1.0142585039138794\n",
      "tensor([0., 1.]) tensor([0.7010, 0.2990], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 12 - 297: dog - cat || Loss: 1.013545036315918\n",
      "tensor([0., 1.]) tensor([0.7003, 0.2997], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 12 - 298: dog - cat || Loss: 1.0128307342529297\n",
      "tensor([0., 1.]) tensor([0.6996, 0.3004], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 12 - 299: dog - cat || Loss: 1.0121158361434937\n",
      "tensor([0., 1.]) tensor([0.6989, 0.3011], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 12 - 300: dog - cat || Loss: 1.0114001035690308\n",
      "tensor([0., 1.]) tensor([0.6981, 0.3019], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 12 - 301: dog - cat || Loss: 1.0106837749481201\n",
      "tensor([0., 1.]) tensor([0.6974, 0.3026], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 12 - 302: dog - cat || Loss: 1.0099668502807617\n",
      "tensor([0., 1.]) tensor([0.6967, 0.3033], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 12 - 303: dog - cat || Loss: 1.0092490911483765\n",
      "tensor([0., 1.]) tensor([0.6960, 0.3040], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 12 - 304: dog - cat || Loss: 1.008530616760254\n",
      "tensor([0., 1.]) tensor([0.6953, 0.3047], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 12 - 305: dog - cat || Loss: 1.007811188697815\n",
      "tensor([0., 1.]) tensor([0.6945, 0.3055], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 12 - 306: dog - cat || Loss: 1.0070914030075073\n",
      "tensor([0., 1.]) tensor([0.6938, 0.3062], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 12 - 307: dog - cat || Loss: 1.0063707828521729\n",
      "tensor([0., 1.]) tensor([0.6931, 0.3069], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 12 - 308: dog - cat || Loss: 1.005649447441101\n",
      "tensor([0., 1.]) tensor([0.6924, 0.3076], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 12 - 309: dog - cat || Loss: 1.0049275159835815\n",
      "tensor([0., 1.]) tensor([0.6917, 0.3083], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 12 - 310: dog - cat || Loss: 1.0042047500610352\n",
      "tensor([0., 1.]) tensor([0.6909, 0.3091], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 12 - 311: dog - cat || Loss: 1.003481388092041\n",
      "tensor([0., 1.]) tensor([0.6902, 0.3098], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 12 - 312: dog - cat || Loss: 1.0027573108673096\n",
      "tensor([0., 1.]) tensor([0.6895, 0.3105], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 12 - 313: dog - cat || Loss: 1.0020326375961304\n",
      "tensor([0., 1.]) tensor([0.6888, 0.3112], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 12 - 314: dog - cat || Loss: 1.0013072490692139\n",
      "tensor([0., 1.]) tensor([0.6880, 0.3120], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 12 - 315: dog - cat || Loss: 1.00058114528656\n",
      "tensor([0., 1.]) tensor([0.6873, 0.3127], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 12 - 316: dog - cat || Loss: 0.9998543858528137\n",
      "tensor([0., 1.]) tensor([0.6866, 0.3134], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 12 - 317: dog - cat || Loss: 0.9991269707679749\n",
      "tensor([0., 1.]) tensor([0.6859, 0.3141], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 12 - 318: dog - cat || Loss: 0.9983989000320435\n",
      "tensor([0., 1.]) tensor([0.6851, 0.3149], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 12 - 319: dog - cat || Loss: 0.9976701140403748\n",
      "tensor([0., 1.]) tensor([0.6844, 0.3156], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 12 - 320: dog - cat || Loss: 0.9969407320022583\n",
      "tensor([0., 1.]) tensor([0.6837, 0.3163], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 12 - 321: dog - cat || Loss: 0.9962106347084045\n",
      "tensor([0., 1.]) tensor([0.6829, 0.3171], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 12 - 322: dog - cat || Loss: 0.995479941368103\n",
      "tensor([0., 1.]) tensor([0.6822, 0.3178], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 12 - 323: dog - cat || Loss: 0.9947484135627747\n",
      "tensor([0., 1.]) tensor([0.6815, 0.3185], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 12 - 324: dog - cat || Loss: 0.9940163493156433\n",
      "tensor([0., 1.]) tensor([0.6808, 0.3192], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 12 - 325: dog - cat || Loss: 0.9932836294174194\n",
      "tensor([0., 1.]) tensor([0.6800, 0.3200], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 12 - 326: dog - cat || Loss: 0.9925501346588135\n",
      "tensor([0., 1.]) tensor([0.6793, 0.3207], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 12 - 327: dog - cat || Loss: 0.9918162822723389\n",
      "tensor([0., 1.]) tensor([0.6786, 0.3214], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 12 - 328: dog - cat || Loss: 0.9910815954208374\n",
      "tensor([0., 1.]) tensor([0.6778, 0.3222], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 12 - 329: dog - cat || Loss: 0.9903461933135986\n",
      "tensor([0., 1.]) tensor([0.6771, 0.3229], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 12 - 330: dog - cat || Loss: 0.9896102547645569\n",
      "tensor([0., 1.]) tensor([0.6763, 0.3237], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 12 - 331: dog - cat || Loss: 0.9888736009597778\n",
      "tensor([0., 1.]) tensor([0.6756, 0.3244], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 12 - 332: dog - cat || Loss: 0.9881364703178406\n",
      "tensor([0., 1.]) tensor([0.6749, 0.3251], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 12 - 333: dog - cat || Loss: 0.9873985052108765\n",
      "tensor([0., 1.]) tensor([0.6741, 0.3259], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 12 - 334: dog - cat || Loss: 0.9866600632667542\n",
      "tensor([0., 1.]) tensor([0.6734, 0.3266], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 12 - 335: dog - cat || Loss: 0.9859209060668945\n",
      "tensor([0., 1.]) tensor([0.6727, 0.3273], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 12 - 336: dog - cat || Loss: 0.9851811528205872\n",
      "tensor([0., 1.]) tensor([0.6719, 0.3281], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 12 - 337: dog - cat || Loss: 0.9844407439231873\n",
      "tensor([0., 1.]) tensor([0.6712, 0.3288], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 12 - 338: dog - cat || Loss: 0.9836995005607605\n",
      "tensor([0., 1.]) tensor([0.6704, 0.3296], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 12 - 339: dog - cat || Loss: 0.9829579591751099\n",
      "tensor([0., 1.]) tensor([0.6697, 0.3303], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 12 - 340: dog - cat || Loss: 0.9822156429290771\n",
      "tensor([0., 1.]) tensor([0.6690, 0.3310], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 12 - 341: dog - cat || Loss: 0.9814727902412415\n",
      "tensor([0., 1.]) tensor([0.6682, 0.3318], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 12 - 342: dog - cat || Loss: 0.9807292222976685\n",
      "tensor([0., 1.]) tensor([0.6675, 0.3325], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 12 - 343: dog - cat || Loss: 0.979985237121582\n",
      "tensor([0., 1.]) tensor([0.6667, 0.3333], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 12 - 344: dog - cat || Loss: 0.9792405366897583\n",
      "tensor([0., 1.]) tensor([0.6660, 0.3340], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 12 - 345: dog - cat || Loss: 0.9784950613975525\n",
      "tensor([0., 1.]) tensor([0.6652, 0.3348], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 12 - 346: dog - cat || Loss: 0.9777491092681885\n",
      "tensor([0., 1.]) tensor([0.6645, 0.3355], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 12 - 347: dog - cat || Loss: 0.9770026803016663\n",
      "tensor([0., 1.]) tensor([0.6637, 0.3363], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 12 - 348: dog - cat || Loss: 0.976255476474762\n",
      "tensor([0., 1.]) tensor([0.6630, 0.3370], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 12 - 349: dog - cat || Loss: 0.9755077362060547\n",
      "tensor([0., 1.]) tensor([0.6622, 0.3378], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 12 - 350: dog - cat || Loss: 0.974759578704834\n",
      "tensor([0., 1.]) tensor([0.6615, 0.3385], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 12 - 351: dog - cat || Loss: 0.9740104675292969\n",
      "tensor([0., 1.]) tensor([0.6607, 0.3393], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 12 - 352: dog - cat || Loss: 0.9732611775398254\n",
      "tensor([0., 1.]) tensor([0.6600, 0.3400], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 12 - 353: dog - cat || Loss: 0.9725109934806824\n",
      "tensor([0., 1.]) tensor([0.6592, 0.3408], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 12 - 354: dog - cat || Loss: 0.9717602729797363\n",
      "tensor([0., 1.]) tensor([0.6585, 0.3415], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 12 - 355: dog - cat || Loss: 0.9710091352462769\n",
      "tensor([0., 1.]) tensor([0.6577, 0.3423], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 12 - 356: dog - cat || Loss: 0.9702573418617249\n",
      "tensor([0., 1.]) tensor([0.6570, 0.3430], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 12 - 357: dog - cat || Loss: 0.9695050716400146\n",
      "tensor([0., 1.]) tensor([0.6562, 0.3438], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 12 - 358: dog - cat || Loss: 0.9687521457672119\n",
      "tensor([0., 1.]) tensor([0.6555, 0.3445], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 12 - 359: dog - cat || Loss: 0.9679986238479614\n",
      "tensor([0., 1.]) tensor([0.6547, 0.3453], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 12 - 360: dog - cat || Loss: 0.9672445058822632\n",
      "tensor([0., 1.]) tensor([0.6540, 0.3460], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 12 - 361: dog - cat || Loss: 0.966489851474762\n",
      "tensor([0., 1.]) tensor([0.6532, 0.3468], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 12 - 362: dog - cat || Loss: 0.9657346606254578\n",
      "tensor([0., 1.]) tensor([0.6525, 0.3475], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 12 - 363: dog - cat || Loss: 0.9649788737297058\n",
      "tensor([0., 1.]) tensor([0.6517, 0.3483], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 12 - 364: dog - cat || Loss: 0.9642224311828613\n",
      "tensor([0., 1.]) tensor([0.6510, 0.3490], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 12 - 365: dog - cat || Loss: 0.9634655117988586\n",
      "tensor([0., 1.]) tensor([0.6502, 0.3498], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 12 - 366: dog - cat || Loss: 0.9627079963684082\n",
      "tensor([0., 1.]) tensor([0.6494, 0.3506], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 12 - 367: dog - cat || Loss: 0.9619497656822205\n",
      "tensor([0., 1.]) tensor([0.6487, 0.3513], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 12 - 368: dog - cat || Loss: 0.9611909985542297\n",
      "tensor([0., 1.]) tensor([0.6479, 0.3521], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 12 - 369: dog - cat || Loss: 0.9604315757751465\n",
      "tensor([0., 1.]) tensor([0.6472, 0.3528], grad_fn=<SoftmaxBackward0>)\n",
      "=====epoch:13=====\n",
      "Epoch 13 - 0: cat - cat || Loss: 0.6668516993522644\n",
      "tensor([1., 0.]) tensor([0.6464, 0.3536], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 13 - 1: cat - cat || Loss: 0.6674595475196838\n",
      "tensor([1., 0.]) tensor([0.6458, 0.3542], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 13 - 2: cat - cat || Loss: 0.6679303646087646\n",
      "tensor([1., 0.]) tensor([0.6453, 0.3547], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 13 - 3: cat - cat || Loss: 0.6682775616645813\n",
      "tensor([1., 0.]) tensor([0.6450, 0.3550], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 13 - 4: cat - cat || Loss: 0.6685137748718262\n",
      "tensor([1., 0.]) tensor([0.6447, 0.3553], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 13 - 5: cat - cat || Loss: 0.6686497926712036\n",
      "tensor([1., 0.]) tensor([0.6446, 0.3554], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 13 - 6: cat - cat || Loss: 0.6686957478523254\n",
      "tensor([1., 0.]) tensor([0.6446, 0.3554], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 13 - 7: cat - cat || Loss: 0.6686606407165527\n",
      "tensor([1., 0.]) tensor([0.6446, 0.3554], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 13 - 8: cat - cat || Loss: 0.6685526371002197\n",
      "tensor([1., 0.]) tensor([0.6447, 0.3553], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 13 - 9: cat - cat || Loss: 0.6683791279792786\n",
      "tensor([1., 0.]) tensor([0.6449, 0.3551], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 13 - 10: cat - cat || Loss: 0.6681464314460754\n",
      "tensor([1., 0.]) tensor([0.6451, 0.3549], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 13 - 11: cat - cat || Loss: 0.6678608655929565\n",
      "tensor([1., 0.]) tensor([0.6454, 0.3546], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 13 - 12: cat - cat || Loss: 0.6675274968147278\n",
      "tensor([1., 0.]) tensor([0.6457, 0.3543], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 13 - 13: cat - cat || Loss: 0.667151153087616\n",
      "tensor([1., 0.]) tensor([0.6461, 0.3539], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 13 - 14: cat - cat || Loss: 0.6667363047599792\n",
      "tensor([1., 0.]) tensor([0.6465, 0.3535], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 13 - 15: cat - cat || Loss: 0.6662869453430176\n",
      "tensor([1., 0.]) tensor([0.6470, 0.3530], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 13 - 16: cat - cat || Loss: 0.6658063530921936\n",
      "tensor([1., 0.]) tensor([0.6475, 0.3525], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 13 - 17: cat - cat || Loss: 0.6652977466583252\n",
      "tensor([1., 0.]) tensor([0.6480, 0.3520], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 13 - 18: cat - cat || Loss: 0.6647641062736511\n",
      "tensor([1., 0.]) tensor([0.6485, 0.3515], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 13 - 19: cat - cat || Loss: 0.6642078757286072\n",
      "tensor([1., 0.]) tensor([0.6491, 0.3509], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 13 - 20: cat - cat || Loss: 0.6636315584182739\n",
      "tensor([1., 0.]) tensor([0.6496, 0.3504], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 13 - 21: cat - cat || Loss: 0.6630368828773499\n",
      "tensor([1., 0.]) tensor([0.6502, 0.3498], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 13 - 22: cat - cat || Loss: 0.6624261140823364\n",
      "tensor([1., 0.]) tensor([0.6508, 0.3492], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 13 - 23: cat - cat || Loss: 0.6618006229400635\n",
      "tensor([1., 0.]) tensor([0.6515, 0.3485], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 13 - 24: cat - cat || Loss: 0.6611620187759399\n",
      "tensor([1., 0.]) tensor([0.6521, 0.3479], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 13 - 25: cat - cat || Loss: 0.6605116724967957\n",
      "tensor([1., 0.]) tensor([0.6527, 0.3473], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 13 - 26: cat - cat || Loss: 0.6598508954048157\n",
      "tensor([1., 0.]) tensor([0.6534, 0.3466], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 13 - 27: cat - cat || Loss: 0.659180760383606\n",
      "tensor([1., 0.]) tensor([0.6541, 0.3459], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 13 - 28: cat - cat || Loss: 0.6585021615028381\n",
      "tensor([1., 0.]) tensor([0.6548, 0.3452], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 13 - 29: cat - cat || Loss: 0.6578159928321838\n",
      "tensor([1., 0.]) tensor([0.6554, 0.3446], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 13 - 30: cat - cat || Loss: 0.6571232080459595\n",
      "tensor([1., 0.]) tensor([0.6561, 0.3439], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 13 - 31: cat - cat || Loss: 0.6564244627952576\n",
      "tensor([1., 0.]) tensor([0.6568, 0.3432], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 13 - 32: cat - cat || Loss: 0.6557204723358154\n",
      "tensor([1., 0.]) tensor([0.6575, 0.3425], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 13 - 33: cat - cat || Loss: 0.655011773109436\n",
      "tensor([1., 0.]) tensor([0.6582, 0.3418], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 13 - 34: cat - cat || Loss: 0.6542988419532776\n",
      "tensor([1., 0.]) tensor([0.6590, 0.3410], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 13 - 35: cat - cat || Loss: 0.6535822153091431\n",
      "tensor([1., 0.]) tensor([0.6597, 0.3403], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 13 - 36: cat - cat || Loss: 0.6528624296188354\n",
      "tensor([1., 0.]) tensor([0.6604, 0.3396], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 13 - 37: cat - cat || Loss: 0.6521397233009338\n",
      "tensor([1., 0.]) tensor([0.6611, 0.3389], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 13 - 38: cat - cat || Loss: 0.6514145135879517\n",
      "tensor([1., 0.]) tensor([0.6618, 0.3382], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 13 - 39: cat - cat || Loss: 0.650687038898468\n",
      "tensor([1., 0.]) tensor([0.6626, 0.3374], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 13 - 40: cat - cat || Loss: 0.6499578952789307\n",
      "tensor([1., 0.]) tensor([0.6633, 0.3367], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 13 - 41: cat - cat || Loss: 0.6492269039154053\n",
      "tensor([1., 0.]) tensor([0.6640, 0.3360], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 13 - 42: cat - cat || Loss: 0.64849454164505\n",
      "tensor([1., 0.]) tensor([0.6648, 0.3352], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 13 - 43: cat - cat || Loss: 0.6477608680725098\n",
      "tensor([1., 0.]) tensor([0.6655, 0.3345], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 13 - 44: cat - cat || Loss: 0.6470263004302979\n",
      "tensor([1., 0.]) tensor([0.6662, 0.3338], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 13 - 45: cat - cat || Loss: 0.6462908387184143\n",
      "tensor([1., 0.]) tensor([0.6670, 0.3330], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 13 - 46: cat - cat || Loss: 0.6455546617507935\n",
      "tensor([1., 0.]) tensor([0.6677, 0.3323], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 13 - 47: cat - cat || Loss: 0.6448179483413696\n",
      "tensor([1., 0.]) tensor([0.6684, 0.3316], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 13 - 48: cat - cat || Loss: 0.6440807580947876\n",
      "tensor([1., 0.]) tensor([0.6692, 0.3308], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 13 - 49: cat - cat || Loss: 0.6433431506156921\n",
      "tensor([1., 0.]) tensor([0.6699, 0.3301], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 13 - 50: cat - cat || Loss: 0.6426054239273071\n",
      "tensor([1., 0.]) tensor([0.6707, 0.3293], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 13 - 51: cat - cat || Loss: 0.6418675184249878\n",
      "tensor([1., 0.]) tensor([0.6714, 0.3286], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 13 - 52: cat - cat || Loss: 0.6411296129226685\n",
      "tensor([1., 0.]) tensor([0.6721, 0.3279], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 13 - 53: cat - cat || Loss: 0.6403916478157043\n",
      "tensor([1., 0.]) tensor([0.6729, 0.3271], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 13 - 54: cat - cat || Loss: 0.6396538019180298\n",
      "tensor([1., 0.]) tensor([0.6736, 0.3264], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 13 - 55: cat - cat || Loss: 0.6389160752296448\n",
      "tensor([1., 0.]) tensor([0.6743, 0.3257], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 13 - 56: cat - cat || Loss: 0.6381785869598389\n",
      "tensor([1., 0.]) tensor([0.6751, 0.3249], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 13 - 57: cat - cat || Loss: 0.6374412178993225\n",
      "tensor([1., 0.]) tensor([0.6758, 0.3242], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 13 - 58: cat - cat || Loss: 0.6367042064666748\n",
      "tensor([1., 0.]) tensor([0.6766, 0.3234], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 13 - 59: cat - cat || Loss: 0.6359676122665405\n",
      "tensor([1., 0.]) tensor([0.6773, 0.3227], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 13 - 60: cat - cat || Loss: 0.6352312564849854\n",
      "tensor([1., 0.]) tensor([0.6780, 0.3220], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 13 - 61: cat - cat || Loss: 0.6344953775405884\n",
      "tensor([1., 0.]) tensor([0.6788, 0.3212], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 13 - 62: cat - cat || Loss: 0.6337598562240601\n",
      "tensor([1., 0.]) tensor([0.6795, 0.3205], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 13 - 63: cat - cat || Loss: 0.6330249309539795\n",
      "tensor([1., 0.]) tensor([0.6802, 0.3198], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 13 - 64: cat - cat || Loss: 0.6322903633117676\n",
      "tensor([1., 0.]) tensor([0.6810, 0.3190], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 13 - 65: cat - cat || Loss: 0.6315563321113586\n",
      "tensor([1., 0.]) tensor([0.6817, 0.3183], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 13 - 66: cat - cat || Loss: 0.6308228373527527\n",
      "tensor([1., 0.]) tensor([0.6824, 0.3176], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 13 - 67: cat - cat || Loss: 0.6300899982452393\n",
      "tensor([1., 0.]) tensor([0.6832, 0.3168], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 13 - 68: cat - cat || Loss: 0.6293575763702393\n",
      "tensor([1., 0.]) tensor([0.6839, 0.3161], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 13 - 69: cat - cat || Loss: 0.6286256909370422\n",
      "tensor([1., 0.]) tensor([0.6846, 0.3154], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 13 - 70: cat - cat || Loss: 0.6278945803642273\n",
      "tensor([1., 0.]) tensor([0.6854, 0.3146], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 13 - 71: cat - cat || Loss: 0.6271640062332153\n",
      "tensor([1., 0.]) tensor([0.6861, 0.3139], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 13 - 72: cat - cat || Loss: 0.6264339685440063\n",
      "tensor([1., 0.]) tensor([0.6868, 0.3132], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 13 - 73: cat - cat || Loss: 0.6257046461105347\n",
      "tensor([1., 0.]) tensor([0.6876, 0.3124], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 13 - 74: cat - cat || Loss: 0.6249759197235107\n",
      "tensor([1., 0.]) tensor([0.6883, 0.3117], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 13 - 75: cat - cat || Loss: 0.6242478489875793\n",
      "tensor([1., 0.]) tensor([0.6890, 0.3110], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 13 - 76: cat - cat || Loss: 0.6235204339027405\n",
      "tensor([1., 0.]) tensor([0.6897, 0.3103], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 13 - 77: cat - cat || Loss: 0.6227936148643494\n",
      "tensor([1., 0.]) tensor([0.6905, 0.3095], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 13 - 78: cat - cat || Loss: 0.6220675110816956\n",
      "tensor([1., 0.]) tensor([0.6912, 0.3088], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 13 - 79: cat - cat || Loss: 0.6213420629501343\n",
      "tensor([1., 0.]) tensor([0.6919, 0.3081], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 13 - 80: cat - cat || Loss: 0.6206173300743103\n",
      "tensor([1., 0.]) tensor([0.6926, 0.3074], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 13 - 81: cat - cat || Loss: 0.6198931932449341\n",
      "tensor([1., 0.]) tensor([0.6934, 0.3066], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 13 - 82: cat - cat || Loss: 0.6191698908805847\n",
      "tensor([1., 0.]) tensor([0.6941, 0.3059], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 13 - 83: cat - cat || Loss: 0.6184471845626831\n",
      "tensor([1., 0.]) tensor([0.6948, 0.3052], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 13 - 84: cat - cat || Loss: 0.6177254319190979\n",
      "tensor([1., 0.]) tensor([0.6955, 0.3045], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 13 - 85: cat - cat || Loss: 0.6170042157173157\n",
      "tensor([1., 0.]) tensor([0.6963, 0.3037], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 13 - 86: cat - cat || Loss: 0.6162838339805603\n",
      "tensor([1., 0.]) tensor([0.6970, 0.3030], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 13 - 87: cat - cat || Loss: 0.6155641674995422\n",
      "tensor([1., 0.]) tensor([0.6977, 0.3023], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 13 - 88: cat - cat || Loss: 0.6148452162742615\n",
      "tensor([1., 0.]) tensor([0.6984, 0.3016], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 13 - 89: cat - cat || Loss: 0.6141269207000732\n",
      "tensor([1., 0.]) tensor([0.6991, 0.3009], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 13 - 90: cat - cat || Loss: 0.6134094595909119\n",
      "tensor([1., 0.]) tensor([0.6999, 0.3001], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 13 - 91: cat - cat || Loss: 0.6126927137374878\n",
      "tensor([1., 0.]) tensor([0.7006, 0.2994], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 13 - 92: cat - cat || Loss: 0.6119767427444458\n",
      "tensor([1., 0.]) tensor([0.7013, 0.2987], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 13 - 93: cat - cat || Loss: 0.6112614870071411\n",
      "tensor([1., 0.]) tensor([0.7020, 0.2980], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 13 - 94: cat - cat || Loss: 0.610546886920929\n",
      "tensor([1., 0.]) tensor([0.7027, 0.2973], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 13 - 95: cat - cat || Loss: 0.6098330020904541\n",
      "tensor([1., 0.]) tensor([0.7034, 0.2966], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 13 - 96: cat - cat || Loss: 0.6091201305389404\n",
      "tensor([1., 0.]) tensor([0.7041, 0.2959], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 13 - 97: cat - cat || Loss: 0.608407735824585\n",
      "tensor([1., 0.]) tensor([0.7049, 0.2951], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 13 - 98: cat - cat || Loss: 0.6076961755752563\n",
      "tensor([1., 0.]) tensor([0.7056, 0.2944], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 13 - 99: cat - cat || Loss: 0.6069855093955994\n",
      "tensor([1., 0.]) tensor([0.7063, 0.2937], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 13 - 100: cat - cat || Loss: 0.6062754392623901\n",
      "tensor([1., 0.]) tensor([0.7070, 0.2930], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 13 - 101: cat - cat || Loss: 0.6055662631988525\n",
      "tensor([1., 0.]) tensor([0.7077, 0.2923], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 13 - 102: cat - cat || Loss: 0.6048578023910522\n",
      "tensor([1., 0.]) tensor([0.7084, 0.2916], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 13 - 103: cat - cat || Loss: 0.6041500568389893\n",
      "tensor([1., 0.]) tensor([0.7091, 0.2909], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 13 - 104: cat - cat || Loss: 0.6034430861473083\n",
      "tensor([1., 0.]) tensor([0.7098, 0.2902], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 13 - 105: cat - cat || Loss: 0.6027371287345886\n",
      "tensor([1., 0.]) tensor([0.7105, 0.2895], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 13 - 106: cat - cat || Loss: 0.6020318865776062\n",
      "tensor([1., 0.]) tensor([0.7112, 0.2888], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 13 - 107: cat - cat || Loss: 0.6013273000717163\n",
      "tensor([1., 0.]) tensor([0.7119, 0.2881], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 13 - 108: cat - cat || Loss: 0.6006237268447876\n",
      "tensor([1., 0.]) tensor([0.7126, 0.2874], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 13 - 109: cat - cat || Loss: 0.5999207496643066\n",
      "tensor([1., 0.]) tensor([0.7133, 0.2867], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 13 - 110: cat - cat || Loss: 0.5992186069488525\n",
      "tensor([1., 0.]) tensor([0.7140, 0.2860], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 13 - 111: cat - cat || Loss: 0.5985172986984253\n",
      "tensor([1., 0.]) tensor([0.7147, 0.2853], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 13 - 112: cat - cat || Loss: 0.5978168249130249\n",
      "tensor([1., 0.]) tensor([0.7154, 0.2846], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 13 - 113: cat - cat || Loss: 0.5971171259880066\n",
      "tensor([1., 0.]) tensor([0.7161, 0.2839], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 13 - 114: cat - cat || Loss: 0.5964181423187256\n",
      "tensor([1., 0.]) tensor([0.7168, 0.2832], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 13 - 115: cat - cat || Loss: 0.595720112323761\n",
      "tensor([1., 0.]) tensor([0.7175, 0.2825], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 13 - 116: cat - cat || Loss: 0.5950227379798889\n",
      "tensor([1., 0.]) tensor([0.7182, 0.2818], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 13 - 117: cat - cat || Loss: 0.594326376914978\n",
      "tensor([1., 0.]) tensor([0.7189, 0.2811], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 13 - 118: cat - cat || Loss: 0.5936306715011597\n",
      "tensor([1., 0.]) tensor([0.7196, 0.2804], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 13 - 119: cat - cat || Loss: 0.5929359197616577\n",
      "tensor([1., 0.]) tensor([0.7203, 0.2797], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 13 - 120: cat - cat || Loss: 0.5922419428825378\n",
      "tensor([1., 0.]) tensor([0.7210, 0.2790], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 13 - 121: cat - cat || Loss: 0.5915486812591553\n",
      "tensor([1., 0.]) tensor([0.7217, 0.2783], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 13 - 122: cat - cat || Loss: 0.5908564925193787\n",
      "tensor([1., 0.]) tensor([0.7224, 0.2776], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 13 - 123: cat - cat || Loss: 0.5901650786399841\n",
      "tensor([1., 0.]) tensor([0.7231, 0.2769], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 13 - 124: cat - cat || Loss: 0.5894744396209717\n",
      "tensor([1., 0.]) tensor([0.7238, 0.2762], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 13 - 125: cat - cat || Loss: 0.5887846946716309\n",
      "tensor([1., 0.]) tensor([0.7245, 0.2755], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 13 - 126: cat - cat || Loss: 0.5880956649780273\n",
      "tensor([1., 0.]) tensor([0.7252, 0.2748], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 13 - 127: cat - cat || Loss: 0.5874074697494507\n",
      "tensor([1., 0.]) tensor([0.7259, 0.2741], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 13 - 128: cat - cat || Loss: 0.5867201685905457\n",
      "tensor([1., 0.]) tensor([0.7265, 0.2735], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 13 - 129: cat - cat || Loss: 0.5860337615013123\n",
      "tensor([1., 0.]) tensor([0.7272, 0.2728], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 13 - 130: cat - cat || Loss: 0.5853481888771057\n",
      "tensor([1., 0.]) tensor([0.7279, 0.2721], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 13 - 131: cat - cat || Loss: 0.5846633911132812\n",
      "tensor([1., 0.]) tensor([0.7286, 0.2714], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 13 - 132: cat - cat || Loss: 0.5839794874191284\n",
      "tensor([1., 0.]) tensor([0.7293, 0.2707], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 13 - 133: cat - cat || Loss: 0.5832964181900024\n",
      "tensor([1., 0.]) tensor([0.7300, 0.2700], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 13 - 134: cat - cat || Loss: 0.5826142430305481\n",
      "tensor([1., 0.]) tensor([0.7306, 0.2694], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 13 - 135: cat - cat || Loss: 0.5819330215454102\n",
      "tensor([1., 0.]) tensor([0.7313, 0.2687], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 13 - 136: cat - cat || Loss: 0.5812525749206543\n",
      "tensor([1., 0.]) tensor([0.7320, 0.2680], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 13 - 137: cat - cat || Loss: 0.5805729031562805\n",
      "tensor([1., 0.]) tensor([0.7327, 0.2673], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 13 - 138: cat - cat || Loss: 0.5798942446708679\n",
      "tensor([1., 0.]) tensor([0.7334, 0.2666], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 13 - 139: cat - cat || Loss: 0.5792163014411926\n",
      "tensor([1., 0.]) tensor([0.7340, 0.2660], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 13 - 140: cat - cat || Loss: 0.5785393118858337\n",
      "tensor([1., 0.]) tensor([0.7347, 0.2653], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 13 - 141: cat - cat || Loss: 0.5778632164001465\n",
      "tensor([1., 0.]) tensor([0.7354, 0.2646], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 13 - 142: cat - cat || Loss: 0.5771881341934204\n",
      "tensor([1., 0.]) tensor([0.7361, 0.2639], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 13 - 143: cat - cat || Loss: 0.5765138864517212\n",
      "tensor([1., 0.]) tensor([0.7367, 0.2633], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 13 - 144: cat - cat || Loss: 0.5758404731750488\n",
      "tensor([1., 0.]) tensor([0.7374, 0.2626], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 13 - 145: cat - cat || Loss: 0.5751679539680481\n",
      "tensor([1., 0.]) tensor([0.7381, 0.2619], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 13 - 146: cat - cat || Loss: 0.5744963884353638\n",
      "tensor([1., 0.]) tensor([0.7388, 0.2612], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 13 - 147: cat - cat || Loss: 0.5738257169723511\n",
      "tensor([1., 0.]) tensor([0.7394, 0.2606], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 13 - 148: cat - cat || Loss: 0.5731558799743652\n",
      "tensor([1., 0.]) tensor([0.7401, 0.2599], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 13 - 149: cat - cat || Loss: 0.5724869966506958\n",
      "tensor([1., 0.]) tensor([0.7408, 0.2592], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 13 - 150: cat - cat || Loss: 0.5718189477920532\n",
      "tensor([1., 0.]) tensor([0.7414, 0.2586], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 13 - 151: cat - cat || Loss: 0.5711517930030823\n",
      "tensor([1., 0.]) tensor([0.7421, 0.2579], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 13 - 152: cat - cat || Loss: 0.5704855918884277\n",
      "tensor([1., 0.]) tensor([0.7428, 0.2572], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 13 - 153: cat - cat || Loss: 0.5698202252388\n",
      "tensor([1., 0.]) tensor([0.7434, 0.2566], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 13 - 154: cat - cat || Loss: 0.5691558122634888\n",
      "tensor([1., 0.]) tensor([0.7441, 0.2559], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 13 - 155: cat - cat || Loss: 0.5684921741485596\n",
      "tensor([1., 0.]) tensor([0.7448, 0.2552], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 13 - 156: cat - cat || Loss: 0.5678296089172363\n",
      "tensor([1., 0.]) tensor([0.7454, 0.2546], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 13 - 157: cat - cat || Loss: 0.5671678781509399\n",
      "tensor([1., 0.]) tensor([0.7461, 0.2539], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 13 - 158: cat - cat || Loss: 0.5665069818496704\n",
      "tensor([1., 0.]) tensor([0.7468, 0.2532], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 13 - 159: cat - cat || Loss: 0.5658469796180725\n",
      "tensor([1., 0.]) tensor([0.7474, 0.2526], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 13 - 160: cat - cat || Loss: 0.565187931060791\n",
      "tensor([1., 0.]) tensor([0.7481, 0.2519], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 13 - 161: cat - cat || Loss: 0.5645297765731812\n",
      "tensor([1., 0.]) tensor([0.7487, 0.2513], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 13 - 162: cat - cat || Loss: 0.5638725757598877\n",
      "tensor([1., 0.]) tensor([0.7494, 0.2506], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 13 - 163: cat - cat || Loss: 0.5632161498069763\n",
      "tensor([1., 0.]) tensor([0.7500, 0.2500], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 13 - 164: cat - cat || Loss: 0.5625607371330261\n",
      "tensor([1., 0.]) tensor([0.7507, 0.2493], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 13 - 165: cat - cat || Loss: 0.5619062185287476\n",
      "tensor([1., 0.]) tensor([0.7514, 0.2486], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 13 - 166: cat - cat || Loss: 0.5612525343894958\n",
      "tensor([1., 0.]) tensor([0.7520, 0.2480], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 13 - 167: cat - cat || Loss: 0.5605998039245605\n",
      "tensor([1., 0.]) tensor([0.7527, 0.2473], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 13 - 168: cat - cat || Loss: 0.5599480867385864\n",
      "tensor([1., 0.]) tensor([0.7533, 0.2467], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 13 - 169: cat - cat || Loss: 0.5592970252037048\n",
      "tensor([1., 0.]) tensor([0.7540, 0.2460], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 13 - 170: cat - cat || Loss: 0.5586470365524292\n",
      "tensor([1., 0.]) tensor([0.7546, 0.2454], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 13 - 171: cat - cat || Loss: 0.5579981207847595\n",
      "tensor([1., 0.]) tensor([0.7553, 0.2447], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 13 - 172: cat - cat || Loss: 0.5573499798774719\n",
      "tensor([1., 0.]) tensor([0.7559, 0.2441], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 13 - 173: cat - cat || Loss: 0.5567028522491455\n",
      "tensor([1., 0.]) tensor([0.7566, 0.2434], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 13 - 174: cat - cat || Loss: 0.5560566782951355\n",
      "tensor([1., 0.]) tensor([0.7572, 0.2428], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 13 - 175: cat - cat || Loss: 0.5554112792015076\n",
      "tensor([1., 0.]) tensor([0.7579, 0.2421], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 13 - 176: cat - cat || Loss: 0.5547669529914856\n",
      "tensor([1., 0.]) tensor([0.7585, 0.2415], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 13 - 177: cat - cat || Loss: 0.5541236996650696\n",
      "tensor([1., 0.]) tensor([0.7591, 0.2409], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 13 - 178: cat - cat || Loss: 0.5534811615943909\n",
      "tensor([1., 0.]) tensor([0.7598, 0.2402], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 13 - 179: cat - cat || Loss: 0.5528397560119629\n",
      "tensor([1., 0.]) tensor([0.7604, 0.2396], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 13 - 180: cat - cat || Loss: 0.552199125289917\n",
      "tensor([1., 0.]) tensor([0.7611, 0.2389], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 13 - 181: cat - cat || Loss: 0.5515595078468323\n",
      "tensor([1., 0.]) tensor([0.7617, 0.2383], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 13 - 182: cat - cat || Loss: 0.550920844078064\n",
      "tensor([1., 0.]) tensor([0.7623, 0.2377], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 13 - 183: cat - cat || Loss: 0.5502831935882568\n",
      "tensor([1., 0.]) tensor([0.7630, 0.2370], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 13 - 184: cat - cat || Loss: 0.5496463775634766\n",
      "tensor([1., 0.]) tensor([0.7636, 0.2364], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 13 - 185: cat - cat || Loss: 0.5490105152130127\n",
      "tensor([1., 0.]) tensor([0.7643, 0.2357], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 13 - 186: cat - cat || Loss: 0.5483756065368652\n",
      "tensor([1., 0.]) tensor([0.7649, 0.2351], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 13 - 187: cat - cat || Loss: 0.547741711139679\n",
      "tensor([1., 0.]) tensor([0.7655, 0.2345], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 13 - 188: cat - cat || Loss: 0.5471088290214539\n",
      "tensor([1., 0.]) tensor([0.7662, 0.2338], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 13 - 189: cat - cat || Loss: 0.5464768409729004\n",
      "tensor([1., 0.]) tensor([0.7668, 0.2332], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 13 - 190: dog - cat || Loss: 1.0806775093078613\n",
      "tensor([0., 1.]) tensor([0.7674, 0.2326], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 13 - 191: dog - cat || Loss: 1.0811823606491089\n",
      "tensor([0., 1.]) tensor([0.7679, 0.2321], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 13 - 192: dog - cat || Loss: 1.0815739631652832\n",
      "tensor([0., 1.]) tensor([0.7683, 0.2317], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 13 - 193: dog - cat || Loss: 1.0818637609481812\n",
      "tensor([0., 1.]) tensor([0.7686, 0.2314], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 13 - 194: dog - cat || Loss: 1.0820618867874146\n",
      "tensor([0., 1.]) tensor([0.7688, 0.2312], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 13 - 195: dog - cat || Loss: 1.0821778774261475\n",
      "tensor([0., 1.]) tensor([0.7689, 0.2311], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 13 - 196: dog - cat || Loss: 1.0822199583053589\n",
      "tensor([0., 1.]) tensor([0.7690, 0.2310], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 13 - 197: dog - cat || Loss: 1.0821952819824219\n",
      "tensor([0., 1.]) tensor([0.7689, 0.2311], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 13 - 198: dog - cat || Loss: 1.0821106433868408\n",
      "tensor([0., 1.]) tensor([0.7688, 0.2312], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 13 - 199: dog - cat || Loss: 1.081972360610962\n",
      "tensor([0., 1.]) tensor([0.7687, 0.2313], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 13 - 200: dog - cat || Loss: 1.0817850828170776\n",
      "tensor([0., 1.]) tensor([0.7685, 0.2315], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 13 - 201: dog - cat || Loss: 1.0815541744232178\n",
      "tensor([0., 1.]) tensor([0.7683, 0.2317], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 13 - 202: dog - cat || Loss: 1.0812838077545166\n",
      "tensor([0., 1.]) tensor([0.7680, 0.2320], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 13 - 203: dog - cat || Loss: 1.0809777975082397\n",
      "tensor([0., 1.]) tensor([0.7677, 0.2323], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 13 - 204: dog - cat || Loss: 1.0806398391723633\n",
      "tensor([0., 1.]) tensor([0.7674, 0.2326], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 13 - 205: dog - cat || Loss: 1.0802727937698364\n",
      "tensor([0., 1.]) tensor([0.7670, 0.2330], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 13 - 206: dog - cat || Loss: 1.0798795223236084\n",
      "tensor([0., 1.]) tensor([0.7666, 0.2334], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 13 - 207: dog - cat || Loss: 1.079463005065918\n",
      "tensor([0., 1.]) tensor([0.7662, 0.2338], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 13 - 208: dog - cat || Loss: 1.0790247917175293\n",
      "tensor([0., 1.]) tensor([0.7658, 0.2342], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 13 - 209: dog - cat || Loss: 1.0785675048828125\n",
      "tensor([0., 1.]) tensor([0.7653, 0.2347], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 13 - 210: dog - cat || Loss: 1.0780928134918213\n",
      "tensor([0., 1.]) tensor([0.7648, 0.2352], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 13 - 211: dog - cat || Loss: 1.0776026248931885\n",
      "tensor([0., 1.]) tensor([0.7643, 0.2357], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 13 - 212: dog - cat || Loss: 1.0770976543426514\n",
      "tensor([0., 1.]) tensor([0.7638, 0.2362], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 13 - 213: dog - cat || Loss: 1.0765800476074219\n",
      "tensor([0., 1.]) tensor([0.7633, 0.2367], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 13 - 214: dog - cat || Loss: 1.0760506391525269\n",
      "tensor([0., 1.]) tensor([0.7628, 0.2372], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 13 - 215: dog - cat || Loss: 1.0755106210708618\n",
      "tensor([0., 1.]) tensor([0.7622, 0.2378], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 13 - 216: dog - cat || Loss: 1.0749610662460327\n",
      "tensor([0., 1.]) tensor([0.7617, 0.2383], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 13 - 217: dog - cat || Loss: 1.0744023323059082\n",
      "tensor([0., 1.]) tensor([0.7611, 0.2389], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 13 - 218: dog - cat || Loss: 1.073835849761963\n",
      "tensor([0., 1.]) tensor([0.7606, 0.2394], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 13 - 219: dog - cat || Loss: 1.0732619762420654\n",
      "tensor([0., 1.]) tensor([0.7600, 0.2400], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 13 - 220: dog - cat || Loss: 1.0726815462112427\n",
      "tensor([0., 1.]) tensor([0.7594, 0.2406], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 13 - 221: dog - cat || Loss: 1.0720950365066528\n",
      "tensor([0., 1.]) tensor([0.7588, 0.2412], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 13 - 222: dog - cat || Loss: 1.0715031623840332\n",
      "tensor([0., 1.]) tensor([0.7582, 0.2418], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 13 - 223: dog - cat || Loss: 1.0709059238433838\n",
      "tensor([0., 1.]) tensor([0.7576, 0.2424], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 13 - 224: dog - cat || Loss: 1.0703041553497314\n",
      "tensor([0., 1.]) tensor([0.7570, 0.2430], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 13 - 225: dog - cat || Loss: 1.0696980953216553\n",
      "tensor([0., 1.]) tensor([0.7564, 0.2436], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 13 - 226: dog - cat || Loss: 1.069088101387024\n",
      "tensor([0., 1.]) tensor([0.7558, 0.2442], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 13 - 227: dog - cat || Loss: 1.068474531173706\n",
      "tensor([0., 1.]) tensor([0.7552, 0.2448], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 13 - 228: dog - cat || Loss: 1.067857265472412\n",
      "tensor([0., 1.]) tensor([0.7546, 0.2454], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 13 - 229: dog - cat || Loss: 1.067237377166748\n",
      "tensor([0., 1.]) tensor([0.7540, 0.2460], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 13 - 230: dog - cat || Loss: 1.0666142702102661\n",
      "tensor([0., 1.]) tensor([0.7534, 0.2466], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 13 - 231: dog - cat || Loss: 1.065988540649414\n",
      "tensor([0., 1.]) tensor([0.7527, 0.2473], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 13 - 232: dog - cat || Loss: 1.0653603076934814\n",
      "tensor([0., 1.]) tensor([0.7521, 0.2479], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 13 - 233: dog - cat || Loss: 1.0647300481796265\n",
      "tensor([0., 1.]) tensor([0.7515, 0.2485], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 13 - 234: dog - cat || Loss: 1.064097285270691\n",
      "tensor([0., 1.]) tensor([0.7508, 0.2492], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 13 - 235: dog - cat || Loss: 1.0634626150131226\n",
      "tensor([0., 1.]) tensor([0.7502, 0.2498], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 13 - 236: dog - cat || Loss: 1.0628257989883423\n",
      "tensor([0., 1.]) tensor([0.7496, 0.2504], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 13 - 237: dog - cat || Loss: 1.0621874332427979\n",
      "tensor([0., 1.]) tensor([0.7489, 0.2511], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 13 - 238: dog - cat || Loss: 1.0615471601486206\n",
      "tensor([0., 1.]) tensor([0.7483, 0.2517], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 13 - 239: dog - cat || Loss: 1.0609052181243896\n",
      "tensor([0., 1.]) tensor([0.7476, 0.2524], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 13 - 240: dog - cat || Loss: 1.060261845588684\n",
      "tensor([0., 1.]) tensor([0.7470, 0.2530], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 13 - 241: dog - cat || Loss: 1.0596169233322144\n",
      "tensor([0., 1.]) tensor([0.7464, 0.2536], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 13 - 242: dog - cat || Loss: 1.05897057056427\n",
      "tensor([0., 1.]) tensor([0.7457, 0.2543], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 13 - 243: dog - cat || Loss: 1.058322787284851\n",
      "tensor([0., 1.]) tensor([0.7451, 0.2549], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 13 - 244: dog - cat || Loss: 1.0576738119125366\n",
      "tensor([0., 1.]) tensor([0.7444, 0.2556], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 13 - 245: dog - cat || Loss: 1.057023525238037\n",
      "tensor([0., 1.]) tensor([0.7438, 0.2562], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 13 - 246: dog - cat || Loss: 1.056372046470642\n",
      "tensor([0., 1.]) tensor([0.7431, 0.2569], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 13 - 247: dog - cat || Loss: 1.055719256401062\n",
      "tensor([0., 1.]) tensor([0.7425, 0.2575], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 13 - 248: dog - cat || Loss: 1.055065631866455\n",
      "tensor([0., 1.]) tensor([0.7418, 0.2582], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 13 - 249: dog - cat || Loss: 1.0544103384017944\n",
      "tensor([0., 1.]) tensor([0.7411, 0.2589], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 13 - 250: dog - cat || Loss: 1.053754448890686\n",
      "tensor([0., 1.]) tensor([0.7405, 0.2595], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 13 - 251: dog - cat || Loss: 1.0530972480773926\n",
      "tensor([0., 1.]) tensor([0.7398, 0.2602], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 13 - 252: dog - cat || Loss: 1.0524392127990723\n",
      "tensor([0., 1.]) tensor([0.7392, 0.2608], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 13 - 253: dog - cat || Loss: 1.0517797470092773\n",
      "tensor([0., 1.]) tensor([0.7385, 0.2615], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 13 - 254: dog - cat || Loss: 1.0511195659637451\n",
      "tensor([0., 1.]) tensor([0.7379, 0.2621], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 13 - 255: dog - cat || Loss: 1.0504584312438965\n",
      "tensor([0., 1.]) tensor([0.7372, 0.2628], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 13 - 256: dog - cat || Loss: 1.049796223640442\n",
      "tensor([0., 1.]) tensor([0.7365, 0.2635], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 13 - 257: dog - cat || Loss: 1.0491331815719604\n",
      "tensor([0., 1.]) tensor([0.7359, 0.2641], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 13 - 258: dog - cat || Loss: 1.0484691858291626\n",
      "tensor([0., 1.]) tensor([0.7352, 0.2648], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 13 - 259: dog - cat || Loss: 1.0478041172027588\n",
      "tensor([0., 1.]) tensor([0.7345, 0.2655], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 13 - 260: dog - cat || Loss: 1.0471382141113281\n",
      "tensor([0., 1.]) tensor([0.7339, 0.2661], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 13 - 261: dog - cat || Loss: 1.0464712381362915\n",
      "tensor([0., 1.]) tensor([0.7332, 0.2668], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 13 - 262: dog - cat || Loss: 1.0458036661148071\n",
      "tensor([0., 1.]) tensor([0.7325, 0.2675], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 13 - 263: dog - cat || Loss: 1.0451347827911377\n",
      "tensor([0., 1.]) tensor([0.7319, 0.2681], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 13 - 264: dog - cat || Loss: 1.04446542263031\n",
      "tensor([0., 1.]) tensor([0.7312, 0.2688], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 13 - 265: dog - cat || Loss: 1.043794870376587\n",
      "tensor([0., 1.]) tensor([0.7305, 0.2695], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 13 - 266: dog - cat || Loss: 1.0431236028671265\n",
      "tensor([0., 1.]) tensor([0.7299, 0.2701], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 13 - 267: dog - cat || Loss: 1.0424516201019287\n",
      "tensor([0., 1.]) tensor([0.7292, 0.2708], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 13 - 268: dog - cat || Loss: 1.041778564453125\n",
      "tensor([0., 1.]) tensor([0.7285, 0.2715], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 13 - 269: dog - cat || Loss: 1.0411046743392944\n",
      "tensor([0., 1.]) tensor([0.7278, 0.2722], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 13 - 270: dog - cat || Loss: 1.040429949760437\n",
      "tensor([0., 1.]) tensor([0.7272, 0.2728], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 13 - 271: dog - cat || Loss: 1.0397545099258423\n",
      "tensor([0., 1.]) tensor([0.7265, 0.2735], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 13 - 272: dog - cat || Loss: 1.0390781164169312\n",
      "tensor([0., 1.]) tensor([0.7258, 0.2742], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 13 - 273: dog - cat || Loss: 1.0384008884429932\n",
      "tensor([0., 1.]) tensor([0.7251, 0.2749], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 13 - 274: dog - cat || Loss: 1.0377228260040283\n",
      "tensor([0., 1.]) tensor([0.7245, 0.2755], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 13 - 275: dog - cat || Loss: 1.037043809890747\n",
      "tensor([0., 1.]) tensor([0.7238, 0.2762], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 13 - 276: dog - cat || Loss: 1.036364197731018\n",
      "tensor([0., 1.]) tensor([0.7231, 0.2769], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 13 - 277: dog - cat || Loss: 1.0356836318969727\n",
      "tensor([0., 1.]) tensor([0.7224, 0.2776], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 13 - 278: dog - cat || Loss: 1.03500235080719\n",
      "tensor([0., 1.]) tensor([0.7217, 0.2783], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 13 - 279: dog - cat || Loss: 1.0343201160430908\n",
      "tensor([0., 1.]) tensor([0.7211, 0.2789], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 13 - 280: dog - cat || Loss: 1.033637285232544\n",
      "tensor([0., 1.]) tensor([0.7204, 0.2796], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 13 - 281: dog - cat || Loss: 1.0329535007476807\n",
      "tensor([0., 1.]) tensor([0.7197, 0.2803], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 13 - 282: dog - cat || Loss: 1.03226900100708\n",
      "tensor([0., 1.]) tensor([0.7190, 0.2810], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 13 - 283: dog - cat || Loss: 1.0315836668014526\n",
      "tensor([0., 1.]) tensor([0.7183, 0.2817], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 13 - 284: dog - cat || Loss: 1.0308973789215088\n",
      "tensor([0., 1.]) tensor([0.7176, 0.2824], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 13 - 285: dog - cat || Loss: 1.0302104949951172\n",
      "tensor([0., 1.]) tensor([0.7169, 0.2831], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 13 - 286: dog - cat || Loss: 1.0295228958129883\n",
      "tensor([0., 1.]) tensor([0.7163, 0.2837], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 13 - 287: dog - cat || Loss: 1.0288344621658325\n",
      "tensor([0., 1.]) tensor([0.7156, 0.2844], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 13 - 288: dog - cat || Loss: 1.0281453132629395\n",
      "tensor([0., 1.]) tensor([0.7149, 0.2851], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 13 - 289: dog - cat || Loss: 1.0274550914764404\n",
      "tensor([0., 1.]) tensor([0.7142, 0.2858], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 13 - 290: dog - cat || Loss: 1.0267643928527832\n",
      "tensor([0., 1.]) tensor([0.7135, 0.2865], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 13 - 291: dog - cat || Loss: 1.0260728597640991\n",
      "tensor([0., 1.]) tensor([0.7128, 0.2872], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 13 - 292: dog - cat || Loss: 1.025380253791809\n",
      "tensor([0., 1.]) tensor([0.7121, 0.2879], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 13 - 293: dog - cat || Loss: 1.0246872901916504\n",
      "tensor([0., 1.]) tensor([0.7114, 0.2886], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 13 - 294: dog - cat || Loss: 1.0239933729171753\n",
      "tensor([0., 1.]) tensor([0.7107, 0.2893], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 13 - 295: dog - cat || Loss: 1.023298740386963\n",
      "tensor([0., 1.]) tensor([0.7100, 0.2900], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 13 - 296: dog - cat || Loss: 1.0226032733917236\n",
      "tensor([0., 1.]) tensor([0.7093, 0.2907], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 13 - 297: dog - cat || Loss: 1.021907091140747\n",
      "tensor([0., 1.]) tensor([0.7086, 0.2914], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 13 - 298: dog - cat || Loss: 1.0212100744247437\n",
      "tensor([0., 1.]) tensor([0.7079, 0.2921], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 13 - 299: dog - cat || Loss: 1.020512342453003\n",
      "tensor([0., 1.]) tensor([0.7073, 0.2927], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 13 - 300: dog - cat || Loss: 1.019813895225525\n",
      "tensor([0., 1.]) tensor([0.7066, 0.2934], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 13 - 301: dog - cat || Loss: 1.01911461353302\n",
      "tensor([0., 1.]) tensor([0.7059, 0.2941], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 13 - 302: dog - cat || Loss: 1.0184147357940674\n",
      "tensor([0., 1.]) tensor([0.7052, 0.2948], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 13 - 303: dog - cat || Loss: 1.0177139043807983\n",
      "tensor([0., 1.]) tensor([0.7045, 0.2955], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 13 - 304: dog - cat || Loss: 1.017012596130371\n",
      "tensor([0., 1.]) tensor([0.7038, 0.2962], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 13 - 305: dog - cat || Loss: 1.016310214996338\n",
      "tensor([0., 1.]) tensor([0.7030, 0.2970], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 13 - 306: dog - cat || Loss: 1.015607237815857\n",
      "tensor([0., 1.]) tensor([0.7023, 0.2977], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 13 - 307: dog - cat || Loss: 1.0149035453796387\n",
      "tensor([0., 1.]) tensor([0.7016, 0.2984], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 13 - 308: dog - cat || Loss: 1.014199137687683\n",
      "tensor([0., 1.]) tensor([0.7009, 0.2991], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 13 - 309: dog - cat || Loss: 1.0134941339492798\n",
      "tensor([0., 1.]) tensor([0.7002, 0.2998], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 13 - 310: dog - cat || Loss: 1.01278817653656\n",
      "tensor([0., 1.]) tensor([0.6995, 0.3005], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 13 - 311: dog - cat || Loss: 1.0120813846588135\n",
      "tensor([0., 1.]) tensor([0.6988, 0.3012], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 13 - 312: dog - cat || Loss: 1.0113742351531982\n",
      "tensor([0., 1.]) tensor([0.6981, 0.3019], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 13 - 313: dog - cat || Loss: 1.0106662511825562\n",
      "tensor([0., 1.]) tensor([0.6974, 0.3026], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 13 - 314: dog - cat || Loss: 1.0099574327468872\n",
      "tensor([0., 1.]) tensor([0.6967, 0.3033], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 13 - 315: dog - cat || Loss: 1.0092477798461914\n",
      "tensor([0., 1.]) tensor([0.6960, 0.3040], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 13 - 316: dog - cat || Loss: 1.008537769317627\n",
      "tensor([0., 1.]) tensor([0.6953, 0.3047], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 13 - 317: dog - cat || Loss: 1.0078266859054565\n",
      "tensor([0., 1.]) tensor([0.6946, 0.3054], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 13 - 318: dog - cat || Loss: 1.0071150064468384\n",
      "tensor([0., 1.]) tensor([0.6939, 0.3061], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 13 - 319: dog - cat || Loss: 1.006402611732483\n",
      "tensor([0., 1.]) tensor([0.6931, 0.3069], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 13 - 320: dog - cat || Loss: 1.0056895017623901\n",
      "tensor([0., 1.]) tensor([0.6924, 0.3076], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 13 - 321: dog - cat || Loss: 1.00497567653656\n",
      "tensor([0., 1.]) tensor([0.6917, 0.3083], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 13 - 322: dog - cat || Loss: 1.0042612552642822\n",
      "tensor([0., 1.]) tensor([0.6910, 0.3090], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 13 - 323: dog - cat || Loss: 1.003545880317688\n",
      "tensor([0., 1.]) tensor([0.6903, 0.3097], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 13 - 324: dog - cat || Loss: 1.002829909324646\n",
      "tensor([0., 1.]) tensor([0.6896, 0.3104], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 13 - 325: dog - cat || Loss: 1.0021133422851562\n",
      "tensor([0., 1.]) tensor([0.6889, 0.3111], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 13 - 326: dog - cat || Loss: 1.00139582157135\n",
      "tensor([0., 1.]) tensor([0.6881, 0.3119], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 13 - 327: dog - cat || Loss: 1.0006779432296753\n",
      "tensor([0., 1.]) tensor([0.6874, 0.3126], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 13 - 328: dog - cat || Loss: 0.9999591708183289\n",
      "tensor([0., 1.]) tensor([0.6867, 0.3133], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 13 - 329: dog - cat || Loss: 0.9992397427558899\n",
      "tensor([0., 1.]) tensor([0.6860, 0.3140], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 13 - 330: dog - cat || Loss: 0.9985196590423584\n",
      "tensor([0., 1.]) tensor([0.6853, 0.3147], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 13 - 331: dog - cat || Loss: 0.9977987408638\n",
      "tensor([0., 1.]) tensor([0.6845, 0.3155], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 13 - 332: dog - cat || Loss: 0.9970774054527283\n",
      "tensor([0., 1.]) tensor([0.6838, 0.3162], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 13 - 333: dog - cat || Loss: 0.9963550567626953\n",
      "tensor([0., 1.]) tensor([0.6831, 0.3169], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 13 - 334: dog - cat || Loss: 0.9956322312355042\n",
      "tensor([0., 1.]) tensor([0.6824, 0.3176], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 13 - 335: dog - cat || Loss: 0.9949087500572205\n",
      "tensor([0., 1.]) tensor([0.6816, 0.3184], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 13 - 336: dog - cat || Loss: 0.9941847324371338\n",
      "tensor([0., 1.]) tensor([0.6809, 0.3191], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 13 - 337: dog - cat || Loss: 0.9934598207473755\n",
      "tensor([0., 1.]) tensor([0.6802, 0.3198], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 13 - 338: dog - cat || Loss: 0.9927343130111694\n",
      "tensor([0., 1.]) tensor([0.6795, 0.3205], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 13 - 339: dog - cat || Loss: 0.9920082092285156\n",
      "tensor([0., 1.]) tensor([0.6787, 0.3213], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 13 - 340: dog - cat || Loss: 0.9912813901901245\n",
      "tensor([0., 1.]) tensor([0.6780, 0.3220], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 13 - 341: dog - cat || Loss: 0.9905539155006409\n",
      "tensor([0., 1.]) tensor([0.6773, 0.3227], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 13 - 342: dog - cat || Loss: 0.9898259043693542\n",
      "tensor([0., 1.]) tensor([0.6766, 0.3234], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 13 - 343: dog - cat || Loss: 0.9890971183776855\n",
      "tensor([0., 1.]) tensor([0.6758, 0.3242], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 13 - 344: dog - cat || Loss: 0.9883676767349243\n",
      "tensor([0., 1.]) tensor([0.6751, 0.3249], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 13 - 345: dog - cat || Loss: 0.9876375198364258\n",
      "tensor([0., 1.]) tensor([0.6744, 0.3256], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 13 - 346: dog - cat || Loss: 0.9869068264961243\n",
      "tensor([0., 1.]) tensor([0.6736, 0.3264], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 13 - 347: dog - cat || Loss: 0.9861754179000854\n",
      "tensor([0., 1.]) tensor([0.6729, 0.3271], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 13 - 348: dog - cat || Loss: 0.9854433536529541\n",
      "tensor([0., 1.]) tensor([0.6722, 0.3278], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 13 - 349: dog - cat || Loss: 0.984710693359375\n",
      "tensor([0., 1.]) tensor([0.6714, 0.3286], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 13 - 350: dog - cat || Loss: 0.9839773774147034\n",
      "tensor([0., 1.]) tensor([0.6707, 0.3293], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 13 - 351: dog - cat || Loss: 0.983243465423584\n",
      "tensor([0., 1.]) tensor([0.6700, 0.3300], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 13 - 352: dog - cat || Loss: 0.9825089573860168\n",
      "tensor([0., 1.]) tensor([0.6692, 0.3308], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 13 - 353: dog - cat || Loss: 0.9817737340927124\n",
      "tensor([0., 1.]) tensor([0.6685, 0.3315], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 13 - 354: dog - cat || Loss: 0.9810378551483154\n",
      "tensor([0., 1.]) tensor([0.6678, 0.3322], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 13 - 355: dog - cat || Loss: 0.9803013801574707\n",
      "tensor([0., 1.]) tensor([0.6670, 0.3330], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 13 - 356: dog - cat || Loss: 0.9795644283294678\n",
      "tensor([0., 1.]) tensor([0.6663, 0.3337], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 13 - 357: dog - cat || Loss: 0.9788267016410828\n",
      "tensor([0., 1.]) tensor([0.6656, 0.3344], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 13 - 358: dog - cat || Loss: 0.9780884981155396\n",
      "tensor([0., 1.]) tensor([0.6648, 0.3352], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 13 - 359: dog - cat || Loss: 0.977349579334259\n",
      "tensor([0., 1.]) tensor([0.6641, 0.3359], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 13 - 360: dog - cat || Loss: 0.976610004901886\n",
      "tensor([0., 1.]) tensor([0.6633, 0.3367], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 13 - 361: dog - cat || Loss: 0.97586989402771\n",
      "tensor([0., 1.]) tensor([0.6626, 0.3374], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 13 - 362: dog - cat || Loss: 0.9751290678977966\n",
      "tensor([0., 1.]) tensor([0.6619, 0.3381], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 13 - 363: dog - cat || Loss: 0.9743877649307251\n",
      "tensor([0., 1.]) tensor([0.6611, 0.3389], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 13 - 364: dog - cat || Loss: 0.9736457467079163\n",
      "tensor([0., 1.]) tensor([0.6604, 0.3396], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 13 - 365: dog - cat || Loss: 0.9729031324386597\n",
      "tensor([0., 1.]) tensor([0.6596, 0.3404], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 13 - 366: dog - cat || Loss: 0.9721601009368896\n",
      "tensor([0., 1.]) tensor([0.6589, 0.3411], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 13 - 367: dog - cat || Loss: 0.9714162945747375\n",
      "tensor([0., 1.]) tensor([0.6582, 0.3418], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 13 - 368: dog - cat || Loss: 0.9706720113754272\n",
      "tensor([0., 1.]) tensor([0.6574, 0.3426], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 13 - 369: dog - cat || Loss: 0.9699268937110901\n",
      "tensor([0., 1.]) tensor([0.6567, 0.3433], grad_fn=<SoftmaxBackward0>)\n",
      "=====epoch:14=====\n",
      "Epoch 14 - 0: cat - cat || Loss: 0.6573418378829956\n",
      "tensor([1., 0.]) tensor([0.6559, 0.3441], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 14 - 1: cat - cat || Loss: 0.6579381823539734\n",
      "tensor([1., 0.]) tensor([0.6553, 0.3447], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 14 - 2: cat - cat || Loss: 0.6583999395370483\n",
      "tensor([1., 0.]) tensor([0.6549, 0.3451], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 14 - 3: cat - cat || Loss: 0.6587408185005188\n",
      "tensor([1., 0.]) tensor([0.6545, 0.3455], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 14 - 4: cat - cat || Loss: 0.6589725017547607\n",
      "tensor([1., 0.]) tensor([0.6543, 0.3457], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 14 - 5: cat - cat || Loss: 0.6591060161590576\n",
      "tensor([1., 0.]) tensor([0.6542, 0.3458], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 14 - 6: cat - cat || Loss: 0.6591512560844421\n",
      "tensor([1., 0.]) tensor([0.6541, 0.3459], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 14 - 7: cat - cat || Loss: 0.6591168642044067\n",
      "tensor([1., 0.]) tensor([0.6541, 0.3459], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 14 - 8: cat - cat || Loss: 0.6590109467506409\n",
      "tensor([1., 0.]) tensor([0.6543, 0.3457], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 14 - 9: cat - cat || Loss: 0.6588406562805176\n",
      "tensor([1., 0.]) tensor([0.6544, 0.3456], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 14 - 10: cat - cat || Loss: 0.6586123704910278\n",
      "tensor([1., 0.]) tensor([0.6546, 0.3454], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 14 - 11: cat - cat || Loss: 0.6583319902420044\n",
      "tensor([1., 0.]) tensor([0.6549, 0.3451], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 14 - 12: cat - cat || Loss: 0.658004879951477\n",
      "tensor([1., 0.]) tensor([0.6553, 0.3447], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 14 - 13: cat - cat || Loss: 0.6576355695724487\n",
      "tensor([1., 0.]) tensor([0.6556, 0.3444], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 14 - 14: cat - cat || Loss: 0.6572282910346985\n",
      "tensor([1., 0.]) tensor([0.6560, 0.3440], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 14 - 15: cat - cat || Loss: 0.6567871570587158\n",
      "tensor([1., 0.]) tensor([0.6565, 0.3435], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 14 - 16: cat - cat || Loss: 0.6563153266906738\n",
      "tensor([1., 0.]) tensor([0.6569, 0.3431], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 14 - 17: cat - cat || Loss: 0.6558161973953247\n",
      "tensor([1., 0.]) tensor([0.6574, 0.3426], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 14 - 18: cat - cat || Loss: 0.655292272567749\n",
      "tensor([1., 0.]) tensor([0.6580, 0.3420], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 14 - 19: cat - cat || Loss: 0.6547462940216064\n",
      "tensor([1., 0.]) tensor([0.6585, 0.3415], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 14 - 20: cat - cat || Loss: 0.6541803479194641\n",
      "tensor([1., 0.]) tensor([0.6591, 0.3409], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 14 - 21: cat - cat || Loss: 0.6535966396331787\n",
      "tensor([1., 0.]) tensor([0.6597, 0.3403], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 14 - 22: cat - cat || Loss: 0.6529971361160278\n",
      "tensor([1., 0.]) tensor([0.6603, 0.3397], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 14 - 23: cat - cat || Loss: 0.6523832082748413\n",
      "tensor([1., 0.]) tensor([0.6609, 0.3391], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 14 - 24: cat - cat || Loss: 0.6517565250396729\n",
      "tensor([1., 0.]) tensor([0.6615, 0.3385], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 14 - 25: cat - cat || Loss: 0.6511183977127075\n",
      "tensor([1., 0.]) tensor([0.6621, 0.3379], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 14 - 26: cat - cat || Loss: 0.6504700183868408\n",
      "tensor([1., 0.]) tensor([0.6628, 0.3372], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 14 - 27: cat - cat || Loss: 0.6498123407363892\n",
      "tensor([1., 0.]) tensor([0.6634, 0.3366], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 14 - 28: cat - cat || Loss: 0.6491464972496033\n",
      "tensor([1., 0.]) tensor([0.6641, 0.3359], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 14 - 29: cat - cat || Loss: 0.6484732627868652\n",
      "tensor([1., 0.]) tensor([0.6648, 0.3352], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 14 - 30: cat - cat || Loss: 0.6477936506271362\n",
      "tensor([1., 0.]) tensor([0.6655, 0.3345], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 14 - 31: cat - cat || Loss: 0.6471080780029297\n",
      "tensor([1., 0.]) tensor([0.6662, 0.3338], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 14 - 32: cat - cat || Loss: 0.6464174389839172\n",
      "tensor([1., 0.]) tensor([0.6668, 0.3332], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 14 - 33: cat - cat || Loss: 0.6457222700119019\n",
      "tensor([1., 0.]) tensor([0.6675, 0.3325], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 14 - 34: cat - cat || Loss: 0.6450231075286865\n",
      "tensor([1., 0.]) tensor([0.6682, 0.3318], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 14 - 35: cat - cat || Loss: 0.6443201899528503\n",
      "tensor([1., 0.]) tensor([0.6689, 0.3311], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 14 - 36: cat - cat || Loss: 0.6436141729354858\n",
      "tensor([1., 0.]) tensor([0.6696, 0.3304], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 14 - 37: cat - cat || Loss: 0.6429054141044617\n",
      "tensor([1., 0.]) tensor([0.6704, 0.3296], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 14 - 38: cat - cat || Loss: 0.6421942710876465\n",
      "tensor([1., 0.]) tensor([0.6711, 0.3289], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 14 - 39: cat - cat || Loss: 0.6414811611175537\n",
      "tensor([1., 0.]) tensor([0.6718, 0.3282], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 14 - 40: cat - cat || Loss: 0.6407662034034729\n",
      "tensor([1., 0.]) tensor([0.6725, 0.3275], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 14 - 41: cat - cat || Loss: 0.6400495767593384\n",
      "tensor([1., 0.]) tensor([0.6732, 0.3268], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 14 - 42: cat - cat || Loss: 0.6393317580223083\n",
      "tensor([1., 0.]) tensor([0.6739, 0.3261], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 14 - 43: cat - cat || Loss: 0.6386125087738037\n",
      "tensor([1., 0.]) tensor([0.6746, 0.3254], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 14 - 44: cat - cat || Loss: 0.6378925442695618\n",
      "tensor([1., 0.]) tensor([0.6754, 0.3246], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 14 - 45: cat - cat || Loss: 0.6371716856956482\n",
      "tensor([1., 0.]) tensor([0.6761, 0.3239], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 14 - 46: cat - cat || Loss: 0.6364502310752869\n",
      "tensor([1., 0.]) tensor([0.6768, 0.3232], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 14 - 47: cat - cat || Loss: 0.635728120803833\n",
      "tensor([1., 0.]) tensor([0.6775, 0.3225], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 14 - 48: cat - cat || Loss: 0.6350058317184448\n",
      "tensor([1., 0.]) tensor([0.6783, 0.3217], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 14 - 49: cat - cat || Loss: 0.6342830657958984\n",
      "tensor([1., 0.]) tensor([0.6790, 0.3210], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 14 - 50: cat - cat || Loss: 0.633560299873352\n",
      "tensor([1., 0.]) tensor([0.6797, 0.3203], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 14 - 51: cat - cat || Loss: 0.6328373551368713\n",
      "tensor([1., 0.]) tensor([0.6804, 0.3196], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 14 - 52: cat - cat || Loss: 0.6321142911911011\n",
      "tensor([1., 0.]) tensor([0.6811, 0.3189], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 14 - 53: cat - cat || Loss: 0.6313914060592651\n",
      "tensor([1., 0.]) tensor([0.6819, 0.3181], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 14 - 54: cat - cat || Loss: 0.6306686401367188\n",
      "tensor([1., 0.]) tensor([0.6826, 0.3174], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 14 - 55: cat - cat || Loss: 0.6299461126327515\n",
      "tensor([1., 0.]) tensor([0.6833, 0.3167], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 14 - 56: cat - cat || Loss: 0.6292237043380737\n",
      "tensor([1., 0.]) tensor([0.6840, 0.3160], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 14 - 57: cat - cat || Loss: 0.6285016536712646\n",
      "tensor([1., 0.]) tensor([0.6848, 0.3152], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 14 - 58: cat - cat || Loss: 0.6277799010276794\n",
      "tensor([1., 0.]) tensor([0.6855, 0.3145], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 14 - 59: cat - cat || Loss: 0.6270585060119629\n",
      "tensor([1., 0.]) tensor([0.6862, 0.3138], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 14 - 60: cat - cat || Loss: 0.6263375878334045\n",
      "tensor([1., 0.]) tensor([0.6869, 0.3131], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 14 - 61: cat - cat || Loss: 0.6256172060966492\n",
      "tensor([1., 0.]) tensor([0.6876, 0.3124], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 14 - 62: cat - cat || Loss: 0.6248972415924072\n",
      "tensor([1., 0.]) tensor([0.6884, 0.3116], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 14 - 63: cat - cat || Loss: 0.6241778135299683\n",
      "tensor([1., 0.]) tensor([0.6891, 0.3109], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 14 - 64: cat - cat || Loss: 0.6234588623046875\n",
      "tensor([1., 0.]) tensor([0.6898, 0.3102], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 14 - 65: cat - cat || Loss: 0.6227403879165649\n",
      "tensor([1., 0.]) tensor([0.6905, 0.3095], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 14 - 66: cat - cat || Loss: 0.6220225691795349\n",
      "tensor([1., 0.]) tensor([0.6912, 0.3088], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 14 - 67: cat - cat || Loss: 0.6213054060935974\n",
      "tensor([1., 0.]) tensor([0.6920, 0.3080], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 14 - 68: cat - cat || Loss: 0.6205888986587524\n",
      "tensor([1., 0.]) tensor([0.6927, 0.3073], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 14 - 69: cat - cat || Loss: 0.6198729276657104\n",
      "tensor([1., 0.]) tensor([0.6934, 0.3066], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 14 - 70: cat - cat || Loss: 0.6191576719284058\n",
      "tensor([1., 0.]) tensor([0.6941, 0.3059], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 14 - 71: cat - cat || Loss: 0.6184432506561279\n",
      "tensor([1., 0.]) tensor([0.6948, 0.3052], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 14 - 72: cat - cat || Loss: 0.6177292466163635\n",
      "tensor([1., 0.]) tensor([0.6955, 0.3045], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 14 - 73: cat - cat || Loss: 0.6170160174369812\n",
      "tensor([1., 0.]) tensor([0.6962, 0.3038], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 14 - 74: cat - cat || Loss: 0.6163034439086914\n",
      "tensor([1., 0.]) tensor([0.6970, 0.3030], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 14 - 75: cat - cat || Loss: 0.6155915260314941\n",
      "tensor([1., 0.]) tensor([0.6977, 0.3023], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 14 - 76: cat - cat || Loss: 0.614880383014679\n",
      "tensor([1., 0.]) tensor([0.6984, 0.3016], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 14 - 77: cat - cat || Loss: 0.6141699552536011\n",
      "tensor([1., 0.]) tensor([0.6991, 0.3009], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 14 - 78: cat - cat || Loss: 0.613460123538971\n",
      "tensor([1., 0.]) tensor([0.6998, 0.3002], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 14 - 79: cat - cat || Loss: 0.6127510070800781\n",
      "tensor([1., 0.]) tensor([0.7005, 0.2995], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 14 - 80: cat - cat || Loss: 0.6120427846908569\n",
      "tensor([1., 0.]) tensor([0.7012, 0.2988], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 14 - 81: cat - cat || Loss: 0.6113349795341492\n",
      "tensor([1., 0.]) tensor([0.7019, 0.2981], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 14 - 82: cat - cat || Loss: 0.610628068447113\n",
      "tensor([1., 0.]) tensor([0.7026, 0.2974], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 14 - 83: cat - cat || Loss: 0.6099220514297485\n",
      "tensor([1., 0.]) tensor([0.7033, 0.2967], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 14 - 84: cat - cat || Loss: 0.6092166900634766\n",
      "tensor([1., 0.]) tensor([0.7040, 0.2960], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 14 - 85: cat - cat || Loss: 0.6085120439529419\n",
      "tensor([1., 0.]) tensor([0.7047, 0.2953], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 14 - 86: cat - cat || Loss: 0.6078081130981445\n",
      "tensor([1., 0.]) tensor([0.7055, 0.2945], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 14 - 87: cat - cat || Loss: 0.6071050763130188\n",
      "tensor([1., 0.]) tensor([0.7062, 0.2938], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 14 - 88: cat - cat || Loss: 0.6064027547836304\n",
      "tensor([1., 0.]) tensor([0.7069, 0.2931], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 14 - 89: cat - cat || Loss: 0.605701208114624\n",
      "tensor([1., 0.]) tensor([0.7076, 0.2924], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 14 - 90: cat - cat || Loss: 0.6050005555152893\n",
      "tensor([1., 0.]) tensor([0.7083, 0.2917], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 14 - 91: cat - cat || Loss: 0.6043004989624023\n",
      "tensor([1., 0.]) tensor([0.7090, 0.2910], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 14 - 92: cat - cat || Loss: 0.6036013960838318\n",
      "tensor([1., 0.]) tensor([0.7097, 0.2903], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 14 - 93: cat - cat || Loss: 0.6029031276702881\n",
      "tensor([1., 0.]) tensor([0.7104, 0.2896], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 14 - 94: cat - cat || Loss: 0.6022055149078369\n",
      "tensor([1., 0.]) tensor([0.7111, 0.2889], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 14 - 95: cat - cat || Loss: 0.6015087366104126\n",
      "tensor([1., 0.]) tensor([0.7118, 0.2882], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 14 - 96: cat - cat || Loss: 0.6008129119873047\n",
      "tensor([1., 0.]) tensor([0.7124, 0.2876], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 14 - 97: cat - cat || Loss: 0.6001176834106445\n",
      "tensor([1., 0.]) tensor([0.7131, 0.2869], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 14 - 98: cat - cat || Loss: 0.5994232296943665\n",
      "tensor([1., 0.]) tensor([0.7138, 0.2862], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 14 - 99: cat - cat || Loss: 0.5987299084663391\n",
      "tensor([1., 0.]) tensor([0.7145, 0.2855], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 14 - 100: cat - cat || Loss: 0.5980370044708252\n",
      "tensor([1., 0.]) tensor([0.7152, 0.2848], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 14 - 101: cat - cat || Loss: 0.5973451137542725\n",
      "tensor([1., 0.]) tensor([0.7159, 0.2841], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 14 - 102: cat - cat || Loss: 0.5966540575027466\n",
      "tensor([1., 0.]) tensor([0.7166, 0.2834], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 14 - 103: cat - cat || Loss: 0.595963716506958\n",
      "tensor([1., 0.]) tensor([0.7173, 0.2827], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 14 - 104: cat - cat || Loss: 0.5952740907669067\n",
      "tensor([1., 0.]) tensor([0.7180, 0.2820], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 14 - 105: cat - cat || Loss: 0.5945854187011719\n",
      "tensor([1., 0.]) tensor([0.7187, 0.2813], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 14 - 106: cat - cat || Loss: 0.5938974618911743\n",
      "tensor([1., 0.]) tensor([0.7194, 0.2806], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 14 - 107: cat - cat || Loss: 0.5932103991508484\n",
      "tensor([1., 0.]) tensor([0.7201, 0.2799], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 14 - 108: cat - cat || Loss: 0.5925241112709045\n",
      "tensor([1., 0.]) tensor([0.7207, 0.2793], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 14 - 109: cat - cat || Loss: 0.5918386578559875\n",
      "tensor([1., 0.]) tensor([0.7214, 0.2786], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 14 - 110: cat - cat || Loss: 0.5911540985107422\n",
      "tensor([1., 0.]) tensor([0.7221, 0.2779], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 14 - 111: cat - cat || Loss: 0.5904702544212341\n",
      "tensor([1., 0.]) tensor([0.7228, 0.2772], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 14 - 112: cat - cat || Loss: 0.5897872447967529\n",
      "tensor([1., 0.]) tensor([0.7235, 0.2765], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 14 - 113: cat - cat || Loss: 0.5891050100326538\n",
      "tensor([1., 0.]) tensor([0.7242, 0.2758], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 14 - 114: cat - cat || Loss: 0.5884237885475159\n",
      "tensor([1., 0.]) tensor([0.7248, 0.2752], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 14 - 115: cat - cat || Loss: 0.58774334192276\n",
      "tensor([1., 0.]) tensor([0.7255, 0.2745], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 14 - 116: cat - cat || Loss: 0.5870637893676758\n",
      "tensor([1., 0.]) tensor([0.7262, 0.2738], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 14 - 117: cat - cat || Loss: 0.5863850116729736\n",
      "tensor([1., 0.]) tensor([0.7269, 0.2731], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 14 - 118: cat - cat || Loss: 0.5857070684432983\n",
      "tensor([1., 0.]) tensor([0.7276, 0.2724], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 14 - 119: cat - cat || Loss: 0.5850300788879395\n",
      "tensor([1., 0.]) tensor([0.7282, 0.2718], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 14 - 120: cat - cat || Loss: 0.5843538641929626\n",
      "tensor([1., 0.]) tensor([0.7289, 0.2711], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 14 - 121: cat - cat || Loss: 0.5836784839630127\n",
      "tensor([1., 0.]) tensor([0.7296, 0.2704], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 14 - 122: cat - cat || Loss: 0.5830039978027344\n",
      "tensor([1., 0.]) tensor([0.7303, 0.2697], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 14 - 123: cat - cat || Loss: 0.5823304057121277\n",
      "tensor([1., 0.]) tensor([0.7309, 0.2691], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 14 - 124: cat - cat || Loss: 0.5816576480865479\n",
      "tensor([1., 0.]) tensor([0.7316, 0.2684], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 14 - 125: cat - cat || Loss: 0.5809858441352844\n",
      "tensor([1., 0.]) tensor([0.7323, 0.2677], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 14 - 126: cat - cat || Loss: 0.5803148150444031\n",
      "tensor([1., 0.]) tensor([0.7329, 0.2671], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 14 - 127: cat - cat || Loss: 0.5796447396278381\n",
      "tensor([1., 0.]) tensor([0.7336, 0.2664], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 14 - 128: cat - cat || Loss: 0.5789754986763\n",
      "tensor([1., 0.]) tensor([0.7343, 0.2657], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 14 - 129: cat - cat || Loss: 0.5783071517944336\n",
      "tensor([1., 0.]) tensor([0.7350, 0.2650], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 14 - 130: cat - cat || Loss: 0.5776397585868835\n",
      "tensor([1., 0.]) tensor([0.7356, 0.2644], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 14 - 131: cat - cat || Loss: 0.5769731998443604\n",
      "tensor([1., 0.]) tensor([0.7363, 0.2637], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 14 - 132: cat - cat || Loss: 0.5763073563575745\n",
      "tensor([1., 0.]) tensor([0.7370, 0.2630], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 14 - 133: cat - cat || Loss: 0.5756425857543945\n",
      "tensor([1., 0.]) tensor([0.7376, 0.2624], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 14 - 134: cat - cat || Loss: 0.5749785900115967\n",
      "tensor([1., 0.]) tensor([0.7383, 0.2617], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 14 - 135: cat - cat || Loss: 0.5743156671524048\n",
      "tensor([1., 0.]) tensor([0.7389, 0.2611], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 14 - 136: cat - cat || Loss: 0.5736534595489502\n",
      "tensor([1., 0.]) tensor([0.7396, 0.2604], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 14 - 137: cat - cat || Loss: 0.572992205619812\n",
      "tensor([1., 0.]) tensor([0.7403, 0.2597], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 14 - 138: cat - cat || Loss: 0.5723318457603455\n",
      "tensor([1., 0.]) tensor([0.7409, 0.2591], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 14 - 139: cat - cat || Loss: 0.5716724395751953\n",
      "tensor([1., 0.]) tensor([0.7416, 0.2584], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 14 - 140: cat - cat || Loss: 0.5710136890411377\n",
      "tensor([1., 0.]) tensor([0.7422, 0.2578], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 14 - 141: cat - cat || Loss: 0.5703560709953308\n",
      "tensor([1., 0.]) tensor([0.7429, 0.2571], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 14 - 142: cat - cat || Loss: 0.5696992874145508\n",
      "tensor([1., 0.]) tensor([0.7436, 0.2564], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 14 - 143: cat - cat || Loss: 0.5690433382987976\n",
      "tensor([1., 0.]) tensor([0.7442, 0.2558], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 14 - 144: cat - cat || Loss: 0.5683884024620056\n",
      "tensor([1., 0.]) tensor([0.7449, 0.2551], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 14 - 145: cat - cat || Loss: 0.5677342414855957\n",
      "tensor([1., 0.]) tensor([0.7455, 0.2545], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 14 - 146: cat - cat || Loss: 0.5670811533927917\n",
      "tensor([1., 0.]) tensor([0.7462, 0.2538], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 14 - 147: cat - cat || Loss: 0.5664288997650146\n",
      "tensor([1., 0.]) tensor([0.7468, 0.2532], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 14 - 148: cat - cat || Loss: 0.5657774806022644\n",
      "tensor([1., 0.]) tensor([0.7475, 0.2525], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 14 - 149: cat - cat || Loss: 0.5651270747184753\n",
      "tensor([1., 0.]) tensor([0.7481, 0.2519], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 14 - 150: cat - cat || Loss: 0.5644775629043579\n",
      "tensor([1., 0.]) tensor([0.7488, 0.2512], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 14 - 151: cat - cat || Loss: 0.5638289451599121\n",
      "tensor([1., 0.]) tensor([0.7494, 0.2506], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 14 - 152: cat - cat || Loss: 0.5631813406944275\n",
      "tensor([1., 0.]) tensor([0.7501, 0.2499], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 14 - 153: cat - cat || Loss: 0.5625345706939697\n",
      "tensor([1., 0.]) tensor([0.7507, 0.2493], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 14 - 154: cat - cat || Loss: 0.5618886947631836\n",
      "tensor([1., 0.]) tensor([0.7514, 0.2486], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 14 - 155: cat - cat || Loss: 0.5612437129020691\n",
      "tensor([1., 0.]) tensor([0.7520, 0.2480], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 14 - 156: cat - cat || Loss: 0.5605997443199158\n",
      "tensor([1., 0.]) tensor([0.7527, 0.2473], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 14 - 157: cat - cat || Loss: 0.5599566698074341\n",
      "tensor([1., 0.]) tensor([0.7533, 0.2467], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 14 - 158: cat - cat || Loss: 0.559314489364624\n",
      "tensor([1., 0.]) tensor([0.7539, 0.2461], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 14 - 159: cat - cat || Loss: 0.5586732625961304\n",
      "tensor([1., 0.]) tensor([0.7546, 0.2454], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 14 - 160: cat - cat || Loss: 0.5580329298973083\n",
      "tensor([1., 0.]) tensor([0.7552, 0.2448], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 14 - 161: cat - cat || Loss: 0.557393491268158\n",
      "tensor([1., 0.]) tensor([0.7559, 0.2441], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 14 - 162: cat - cat || Loss: 0.5567550659179688\n",
      "tensor([1., 0.]) tensor([0.7565, 0.2435], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 14 - 163: cat - cat || Loss: 0.5561175346374512\n",
      "tensor([1., 0.]) tensor([0.7571, 0.2429], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 14 - 164: cat - cat || Loss: 0.5554808974266052\n",
      "tensor([1., 0.]) tensor([0.7578, 0.2422], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 14 - 165: cat - cat || Loss: 0.5548452734947205\n",
      "tensor([1., 0.]) tensor([0.7584, 0.2416], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 14 - 166: cat - cat || Loss: 0.5542104840278625\n",
      "tensor([1., 0.]) tensor([0.7591, 0.2409], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 14 - 167: cat - cat || Loss: 0.553576648235321\n",
      "tensor([1., 0.]) tensor([0.7597, 0.2403], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 14 - 168: cat - cat || Loss: 0.5529438257217407\n",
      "tensor([1., 0.]) tensor([0.7603, 0.2397], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 14 - 169: cat - cat || Loss: 0.5523118376731873\n",
      "tensor([1., 0.]) tensor([0.7609, 0.2391], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 14 - 170: cat - cat || Loss: 0.5516808032989502\n",
      "tensor([1., 0.]) tensor([0.7616, 0.2384], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 14 - 171: cat - cat || Loss: 0.5510507822036743\n",
      "tensor([1., 0.]) tensor([0.7622, 0.2378], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 14 - 172: cat - cat || Loss: 0.5504217147827148\n",
      "tensor([1., 0.]) tensor([0.7628, 0.2372], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 14 - 173: cat - cat || Loss: 0.5497934818267822\n",
      "tensor([1., 0.]) tensor([0.7635, 0.2365], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 14 - 174: cat - cat || Loss: 0.5491662621498108\n",
      "tensor([1., 0.]) tensor([0.7641, 0.2359], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 14 - 175: cat - cat || Loss: 0.548539936542511\n",
      "tensor([1., 0.]) tensor([0.7647, 0.2353], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 14 - 176: cat - cat || Loss: 0.5479146242141724\n",
      "tensor([1., 0.]) tensor([0.7653, 0.2347], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 14 - 177: cat - cat || Loss: 0.5472903251647949\n",
      "tensor([1., 0.]) tensor([0.7660, 0.2340], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 14 - 178: cat - cat || Loss: 0.5466668605804443\n",
      "tensor([1., 0.]) tensor([0.7666, 0.2334], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 14 - 179: cat - cat || Loss: 0.5460444688796997\n",
      "tensor([1., 0.]) tensor([0.7672, 0.2328], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 14 - 180: cat - cat || Loss: 0.5454229116439819\n",
      "tensor([1., 0.]) tensor([0.7678, 0.2322], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 14 - 181: cat - cat || Loss: 0.5448024272918701\n",
      "tensor([1., 0.]) tensor([0.7685, 0.2315], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 14 - 182: cat - cat || Loss: 0.5441828966140747\n",
      "tensor([1., 0.]) tensor([0.7691, 0.2309], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 14 - 183: cat - cat || Loss: 0.5435643792152405\n",
      "tensor([1., 0.]) tensor([0.7697, 0.2303], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 14 - 184: cat - cat || Loss: 0.5429466962814331\n",
      "tensor([1., 0.]) tensor([0.7703, 0.2297], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 14 - 185: cat - cat || Loss: 0.5423300266265869\n",
      "tensor([1., 0.]) tensor([0.7709, 0.2291], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 14 - 186: cat - cat || Loss: 0.5417144298553467\n",
      "tensor([1., 0.]) tensor([0.7715, 0.2285], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 14 - 187: cat - cat || Loss: 0.5410996675491333\n",
      "tensor([1., 0.]) tensor([0.7722, 0.2278], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 14 - 188: cat - cat || Loss: 0.5404859781265259\n",
      "tensor([1., 0.]) tensor([0.7728, 0.2272], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 14 - 189: cat - cat || Loss: 0.5398731827735901\n",
      "tensor([1., 0.]) tensor([0.7734, 0.2266], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 14 - 190: dog - cat || Loss: 1.0872619152069092\n",
      "tensor([0., 1.]) tensor([0.7740, 0.2260], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 14 - 191: dog - cat || Loss: 1.0877515077590942\n",
      "tensor([0., 1.]) tensor([0.7745, 0.2255], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 14 - 192: dog - cat || Loss: 1.0881311893463135\n",
      "tensor([0., 1.]) tensor([0.7749, 0.2251], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 14 - 193: dog - cat || Loss: 1.0884120464324951\n",
      "tensor([0., 1.]) tensor([0.7752, 0.2248], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 14 - 194: dog - cat || Loss: 1.0886043310165405\n",
      "tensor([0., 1.]) tensor([0.7753, 0.2247], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 14 - 195: dog - cat || Loss: 1.0887168645858765\n",
      "tensor([0., 1.]) tensor([0.7755, 0.2245], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 14 - 196: dog - cat || Loss: 1.0887577533721924\n",
      "tensor([0., 1.]) tensor([0.7755, 0.2245], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 14 - 197: dog - cat || Loss: 1.0887339115142822\n",
      "tensor([0., 1.]) tensor([0.7755, 0.2245], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 14 - 198: dog - cat || Loss: 1.0886521339416504\n",
      "tensor([0., 1.]) tensor([0.7754, 0.2246], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 14 - 199: dog - cat || Loss: 1.0885181427001953\n",
      "tensor([0., 1.]) tensor([0.7753, 0.2247], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 14 - 200: dog - cat || Loss: 1.088336706161499\n",
      "tensor([0., 1.]) tensor([0.7751, 0.2249], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 14 - 201: dog - cat || Loss: 1.0881129503250122\n",
      "tensor([0., 1.]) tensor([0.7749, 0.2251], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 14 - 202: dog - cat || Loss: 1.0878511667251587\n",
      "tensor([0., 1.]) tensor([0.7746, 0.2254], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 14 - 203: dog - cat || Loss: 1.087554693222046\n",
      "tensor([0., 1.]) tensor([0.7743, 0.2257], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 14 - 204: dog - cat || Loss: 1.0872273445129395\n",
      "tensor([0., 1.]) tensor([0.7740, 0.2260], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 14 - 205: dog - cat || Loss: 1.0868713855743408\n",
      "tensor([0., 1.]) tensor([0.7736, 0.2264], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 14 - 206: dog - cat || Loss: 1.086490511894226\n",
      "tensor([0., 1.]) tensor([0.7732, 0.2268], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 14 - 207: dog - cat || Loss: 1.0860868692398071\n",
      "tensor([0., 1.]) tensor([0.7728, 0.2272], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 14 - 208: dog - cat || Loss: 1.0856622457504272\n",
      "tensor([0., 1.]) tensor([0.7724, 0.2276], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 14 - 209: dog - cat || Loss: 1.0852192640304565\n",
      "tensor([0., 1.]) tensor([0.7720, 0.2280], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 14 - 210: dog - cat || Loss: 1.0847591161727905\n",
      "tensor([0., 1.]) tensor([0.7715, 0.2285], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 14 - 211: dog - cat || Loss: 1.084283709526062\n",
      "tensor([0., 1.]) tensor([0.7710, 0.2290], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 14 - 212: dog - cat || Loss: 1.0837944746017456\n",
      "tensor([0., 1.]) tensor([0.7705, 0.2295], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 14 - 213: dog - cat || Loss: 1.0832926034927368\n",
      "tensor([0., 1.]) tensor([0.7700, 0.2300], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 14 - 214: dog - cat || Loss: 1.0827794075012207\n",
      "tensor([0., 1.]) tensor([0.7695, 0.2305], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 14 - 215: dog - cat || Loss: 1.0822558403015137\n",
      "tensor([0., 1.]) tensor([0.7690, 0.2310], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 14 - 216: dog - cat || Loss: 1.0817228555679321\n",
      "tensor([0., 1.]) tensor([0.7685, 0.2315], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 14 - 217: dog - cat || Loss: 1.0811814069747925\n",
      "tensor([0., 1.]) tensor([0.7679, 0.2321], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 14 - 218: dog - cat || Loss: 1.0806320905685425\n",
      "tensor([0., 1.]) tensor([0.7674, 0.2326], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 14 - 219: dog - cat || Loss: 1.080075740814209\n",
      "tensor([0., 1.]) tensor([0.7668, 0.2332], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 14 - 220: dog - cat || Loss: 1.0795127153396606\n",
      "tensor([0., 1.]) tensor([0.7663, 0.2337], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 14 - 221: dog - cat || Loss: 1.078944206237793\n",
      "tensor([0., 1.]) tensor([0.7657, 0.2343], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 14 - 222: dog - cat || Loss: 1.0783698558807373\n",
      "tensor([0., 1.]) tensor([0.7651, 0.2349], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 14 - 223: dog - cat || Loss: 1.07779061794281\n",
      "tensor([0., 1.]) tensor([0.7645, 0.2355], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 14 - 224: dog - cat || Loss: 1.0772069692611694\n",
      "tensor([0., 1.]) tensor([0.7639, 0.2361], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 14 - 225: dog - cat || Loss: 1.076619267463684\n",
      "tensor([0., 1.]) tensor([0.7634, 0.2366], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 14 - 226: dog - cat || Loss: 1.0760273933410645\n",
      "tensor([0., 1.]) tensor([0.7628, 0.2372], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 14 - 227: dog - cat || Loss: 1.0754320621490479\n",
      "tensor([0., 1.]) tensor([0.7622, 0.2378], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 14 - 228: dog - cat || Loss: 1.0748333930969238\n",
      "tensor([0., 1.]) tensor([0.7616, 0.2384], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 14 - 229: dog - cat || Loss: 1.0742319822311401\n",
      "tensor([0., 1.]) tensor([0.7610, 0.2390], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 14 - 230: dog - cat || Loss: 1.0736273527145386\n",
      "tensor([0., 1.]) tensor([0.7604, 0.2396], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 14 - 231: dog - cat || Loss: 1.073020100593567\n",
      "tensor([0., 1.]) tensor([0.7598, 0.2402], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 14 - 232: dog - cat || Loss: 1.0724105834960938\n",
      "tensor([0., 1.]) tensor([0.7591, 0.2409], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 14 - 233: dog - cat || Loss: 1.0717986822128296\n",
      "tensor([0., 1.]) tensor([0.7585, 0.2415], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 14 - 234: dog - cat || Loss: 1.071184515953064\n",
      "tensor([0., 1.]) tensor([0.7579, 0.2421], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 14 - 235: dog - cat || Loss: 1.070568561553955\n",
      "tensor([0., 1.]) tensor([0.7573, 0.2427], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 14 - 236: dog - cat || Loss: 1.0699504613876343\n",
      "tensor([0., 1.]) tensor([0.7567, 0.2433], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 14 - 237: dog - cat || Loss: 1.0693306922912598\n",
      "tensor([0., 1.]) tensor([0.7561, 0.2439], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 14 - 238: dog - cat || Loss: 1.0687090158462524\n",
      "tensor([0., 1.]) tensor([0.7554, 0.2446], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 14 - 239: dog - cat || Loss: 1.0680859088897705\n",
      "tensor([0., 1.]) tensor([0.7548, 0.2452], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 14 - 240: dog - cat || Loss: 1.0674611330032349\n",
      "tensor([0., 1.]) tensor([0.7542, 0.2458], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 14 - 241: dog - cat || Loss: 1.066834807395935\n",
      "tensor([0., 1.]) tensor([0.7536, 0.2464], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 14 - 242: dog - cat || Loss: 1.0662070512771606\n",
      "tensor([0., 1.]) tensor([0.7529, 0.2471], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 14 - 243: dog - cat || Loss: 1.0655779838562012\n",
      "tensor([0., 1.]) tensor([0.7523, 0.2477], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 14 - 244: dog - cat || Loss: 1.0649477243423462\n",
      "tensor([0., 1.]) tensor([0.7517, 0.2483], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 14 - 245: dog - cat || Loss: 1.0643162727355957\n",
      "tensor([0., 1.]) tensor([0.7511, 0.2489], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 14 - 246: dog - cat || Loss: 1.0636831521987915\n",
      "tensor([0., 1.]) tensor([0.7504, 0.2496], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 14 - 247: dog - cat || Loss: 1.063049077987671\n",
      "tensor([0., 1.]) tensor([0.7498, 0.2502], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 14 - 248: dog - cat || Loss: 1.0624140501022339\n",
      "tensor([0., 1.]) tensor([0.7492, 0.2508], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 14 - 249: dog - cat || Loss: 1.0617774724960327\n",
      "tensor([0., 1.]) tensor([0.7485, 0.2515], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 14 - 250: dog - cat || Loss: 1.0611400604248047\n",
      "tensor([0., 1.]) tensor([0.7479, 0.2521], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 14 - 251: dog - cat || Loss: 1.0605014562606812\n",
      "tensor([0., 1.]) tensor([0.7472, 0.2528], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 14 - 252: dog - cat || Loss: 1.0598618984222412\n",
      "tensor([0., 1.]) tensor([0.7466, 0.2534], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 14 - 253: dog - cat || Loss: 1.0592211484909058\n",
      "tensor([0., 1.]) tensor([0.7460, 0.2540], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 14 - 254: dog - cat || Loss: 1.0585795640945435\n",
      "tensor([0., 1.]) tensor([0.7453, 0.2547], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 14 - 255: dog - cat || Loss: 1.0579367876052856\n",
      "tensor([0., 1.]) tensor([0.7447, 0.2553], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 14 - 256: dog - cat || Loss: 1.057293176651001\n",
      "tensor([0., 1.]) tensor([0.7440, 0.2560], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 14 - 257: dog - cat || Loss: 1.0566484928131104\n",
      "tensor([0., 1.]) tensor([0.7434, 0.2566], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 14 - 258: dog - cat || Loss: 1.0560029745101929\n",
      "tensor([0., 1.]) tensor([0.7427, 0.2573], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 14 - 259: dog - cat || Loss: 1.055356502532959\n",
      "tensor([0., 1.]) tensor([0.7421, 0.2579], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 14 - 260: dog - cat || Loss: 1.0547088384628296\n",
      "tensor([0., 1.]) tensor([0.7414, 0.2586], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 14 - 261: dog - cat || Loss: 1.0540605783462524\n",
      "tensor([0., 1.]) tensor([0.7408, 0.2592], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 14 - 262: dog - cat || Loss: 1.0534111261367798\n",
      "tensor([0., 1.]) tensor([0.7401, 0.2599], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 14 - 263: dog - cat || Loss: 1.0527607202529907\n",
      "tensor([0., 1.]) tensor([0.7395, 0.2605], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 14 - 264: dog - cat || Loss: 1.052109718322754\n",
      "tensor([0., 1.]) tensor([0.7388, 0.2612], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 14 - 265: dog - cat || Loss: 1.0514575242996216\n",
      "tensor([0., 1.]) tensor([0.7382, 0.2618], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 14 - 266: dog - cat || Loss: 1.050804615020752\n",
      "tensor([0., 1.]) tensor([0.7375, 0.2625], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 14 - 267: dog - cat || Loss: 1.0501508712768555\n",
      "tensor([0., 1.]) tensor([0.7369, 0.2631], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 14 - 268: dog - cat || Loss: 1.049496054649353\n",
      "tensor([0., 1.]) tensor([0.7362, 0.2638], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 14 - 269: dog - cat || Loss: 1.0488404035568237\n",
      "tensor([0., 1.]) tensor([0.7356, 0.2644], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 14 - 270: dog - cat || Loss: 1.0481839179992676\n",
      "tensor([0., 1.]) tensor([0.7349, 0.2651], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 14 - 271: dog - cat || Loss: 1.0475265979766846\n",
      "tensor([0., 1.]) tensor([0.7343, 0.2657], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 14 - 272: dog - cat || Loss: 1.0468683242797852\n",
      "tensor([0., 1.]) tensor([0.7336, 0.2664], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 14 - 273: dog - cat || Loss: 1.0462092161178589\n",
      "tensor([0., 1.]) tensor([0.7329, 0.2671], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 14 - 274: dog - cat || Loss: 1.0455493927001953\n",
      "tensor([0., 1.]) tensor([0.7323, 0.2677], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 14 - 275: dog - cat || Loss: 1.0448886156082153\n",
      "tensor([0., 1.]) tensor([0.7316, 0.2684], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 14 - 276: dog - cat || Loss: 1.044227123260498\n",
      "tensor([0., 1.]) tensor([0.7310, 0.2690], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 14 - 277: dog - cat || Loss: 1.0435645580291748\n",
      "tensor([0., 1.]) tensor([0.7303, 0.2697], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 14 - 278: dog - cat || Loss: 1.0429012775421143\n",
      "tensor([0., 1.]) tensor([0.7296, 0.2704], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 14 - 279: dog - cat || Loss: 1.0422371625900269\n",
      "tensor([0., 1.]) tensor([0.7290, 0.2710], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 14 - 280: dog - cat || Loss: 1.041572093963623\n",
      "tensor([0., 1.]) tensor([0.7283, 0.2717], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 14 - 281: dog - cat || Loss: 1.040906310081482\n",
      "tensor([0., 1.]) tensor([0.7276, 0.2724], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 14 - 282: dog - cat || Loss: 1.040239691734314\n",
      "tensor([0., 1.]) tensor([0.7270, 0.2730], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 14 - 283: dog - cat || Loss: 1.0395722389221191\n",
      "tensor([0., 1.]) tensor([0.7263, 0.2737], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 14 - 284: dog - cat || Loss: 1.0389039516448975\n",
      "tensor([0., 1.]) tensor([0.7256, 0.2744], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 14 - 285: dog - cat || Loss: 1.0382349491119385\n",
      "tensor([0., 1.]) tensor([0.7250, 0.2750], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 14 - 286: dog - cat || Loss: 1.037564992904663\n",
      "tensor([0., 1.]) tensor([0.7243, 0.2757], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 14 - 287: dog - cat || Loss: 1.0368943214416504\n",
      "tensor([0., 1.]) tensor([0.7236, 0.2764], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 14 - 288: dog - cat || Loss: 1.0362228155136108\n",
      "tensor([0., 1.]) tensor([0.7230, 0.2770], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 14 - 289: dog - cat || Loss: 1.0355504751205444\n",
      "tensor([0., 1.]) tensor([0.7223, 0.2777], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 14 - 290: dog - cat || Loss: 1.0348773002624512\n",
      "tensor([0., 1.]) tensor([0.7216, 0.2784], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 14 - 291: dog - cat || Loss: 1.0342034101486206\n",
      "tensor([0., 1.]) tensor([0.7209, 0.2791], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 14 - 292: dog - cat || Loss: 1.033528447151184\n",
      "tensor([0., 1.]) tensor([0.7203, 0.2797], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 14 - 293: dog - cat || Loss: 1.0328528881072998\n",
      "tensor([0., 1.]) tensor([0.7196, 0.2804], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 14 - 294: dog - cat || Loss: 1.0321764945983887\n",
      "tensor([0., 1.]) tensor([0.7189, 0.2811], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 14 - 295: dog - cat || Loss: 1.0314993858337402\n",
      "tensor([0., 1.]) tensor([0.7182, 0.2818], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 14 - 296: dog - cat || Loss: 1.030821442604065\n",
      "tensor([0., 1.]) tensor([0.7176, 0.2824], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 14 - 297: dog - cat || Loss: 1.0301426649093628\n",
      "tensor([0., 1.]) tensor([0.7169, 0.2831], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 14 - 298: dog - cat || Loss: 1.0294631719589233\n",
      "tensor([0., 1.]) tensor([0.7162, 0.2838], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 14 - 299: dog - cat || Loss: 1.028782844543457\n",
      "tensor([0., 1.]) tensor([0.7155, 0.2845], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 14 - 300: dog - cat || Loss: 1.0281016826629639\n",
      "tensor([0., 1.]) tensor([0.7148, 0.2852], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 14 - 301: dog - cat || Loss: 1.027419924736023\n",
      "tensor([0., 1.]) tensor([0.7142, 0.2858], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 14 - 302: dog - cat || Loss: 1.0267372131347656\n",
      "tensor([0., 1.]) tensor([0.7135, 0.2865], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 14 - 303: dog - cat || Loss: 1.026053786277771\n",
      "tensor([0., 1.]) tensor([0.7128, 0.2872], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 14 - 304: dog - cat || Loss: 1.0253697633743286\n",
      "tensor([0., 1.]) tensor([0.7121, 0.2879], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 14 - 305: dog - cat || Loss: 1.0246846675872803\n",
      "tensor([0., 1.]) tensor([0.7114, 0.2886], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 14 - 306: dog - cat || Loss: 1.0239989757537842\n",
      "tensor([0., 1.]) tensor([0.7107, 0.2893], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 14 - 307: dog - cat || Loss: 1.0233125686645508\n",
      "tensor([0., 1.]) tensor([0.7101, 0.2899], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 14 - 308: dog - cat || Loss: 1.0226253271102905\n",
      "tensor([0., 1.]) tensor([0.7094, 0.2906], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 14 - 309: dog - cat || Loss: 1.021937370300293\n",
      "tensor([0., 1.]) tensor([0.7087, 0.2913], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 14 - 310: dog - cat || Loss: 1.021248698234558\n",
      "tensor([0., 1.]) tensor([0.7080, 0.2920], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 14 - 311: dog - cat || Loss: 1.0205590724945068\n",
      "tensor([0., 1.]) tensor([0.7073, 0.2927], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 14 - 312: dog - cat || Loss: 1.0198688507080078\n",
      "tensor([0., 1.]) tensor([0.7066, 0.2934], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 14 - 313: dog - cat || Loss: 1.0191779136657715\n",
      "tensor([0., 1.]) tensor([0.7059, 0.2941], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 14 - 314: dog - cat || Loss: 1.0184862613677979\n",
      "tensor([0., 1.]) tensor([0.7052, 0.2948], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 14 - 315: dog - cat || Loss: 1.0177937746047974\n",
      "tensor([0., 1.]) tensor([0.7045, 0.2955], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 14 - 316: dog - cat || Loss: 1.01710045337677\n",
      "tensor([0., 1.]) tensor([0.7038, 0.2962], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 14 - 317: dog - cat || Loss: 1.016406536102295\n",
      "tensor([0., 1.]) tensor([0.7031, 0.2969], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 14 - 318: dog - cat || Loss: 1.015711784362793\n",
      "tensor([0., 1.]) tensor([0.7025, 0.2975], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 14 - 319: dog - cat || Loss: 1.0150165557861328\n",
      "tensor([0., 1.]) tensor([0.7018, 0.2982], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 14 - 320: dog - cat || Loss: 1.0143203735351562\n",
      "tensor([0., 1.]) tensor([0.7011, 0.2989], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 14 - 321: dog - cat || Loss: 1.0136234760284424\n",
      "tensor([0., 1.]) tensor([0.7004, 0.2996], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 14 - 322: dog - cat || Loss: 1.0129261016845703\n",
      "tensor([0., 1.]) tensor([0.6997, 0.3003], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 14 - 323: dog - cat || Loss: 1.0122276544570923\n",
      "tensor([0., 1.]) tensor([0.6990, 0.3010], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 14 - 324: dog - cat || Loss: 1.0115286111831665\n",
      "tensor([0., 1.]) tensor([0.6983, 0.3017], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 14 - 325: dog - cat || Loss: 1.0108288526535034\n",
      "tensor([0., 1.]) tensor([0.6976, 0.3024], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 14 - 326: dog - cat || Loss: 1.0101284980773926\n",
      "tensor([0., 1.]) tensor([0.6969, 0.3031], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 14 - 327: dog - cat || Loss: 1.0094271898269653\n",
      "tensor([0., 1.]) tensor([0.6962, 0.3038], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 14 - 328: dog - cat || Loss: 1.0087252855300903\n",
      "tensor([0., 1.]) tensor([0.6955, 0.3045], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 14 - 329: dog - cat || Loss: 1.0080227851867676\n",
      "tensor([0., 1.]) tensor([0.6948, 0.3052], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 14 - 330: dog - cat || Loss: 1.007319450378418\n",
      "tensor([0., 1.]) tensor([0.6941, 0.3059], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 14 - 331: dog - cat || Loss: 1.006615400314331\n",
      "tensor([0., 1.]) tensor([0.6934, 0.3066], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 14 - 332: dog - cat || Loss: 1.0059107542037964\n",
      "tensor([0., 1.]) tensor([0.6926, 0.3074], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 14 - 333: dog - cat || Loss: 1.0052052736282349\n",
      "tensor([0., 1.]) tensor([0.6919, 0.3081], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 14 - 334: dog - cat || Loss: 1.004499077796936\n",
      "tensor([0., 1.]) tensor([0.6912, 0.3088], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 14 - 335: dog - cat || Loss: 1.0037922859191895\n",
      "tensor([0., 1.]) tensor([0.6905, 0.3095], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 14 - 336: dog - cat || Loss: 1.0030847787857056\n",
      "tensor([0., 1.]) tensor([0.6898, 0.3102], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 14 - 337: dog - cat || Loss: 1.0023764371871948\n",
      "tensor([0., 1.]) tensor([0.6891, 0.3109], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 14 - 338: dog - cat || Loss: 1.0016674995422363\n",
      "tensor([0., 1.]) tensor([0.6884, 0.3116], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 14 - 339: dog - cat || Loss: 1.0009580850601196\n",
      "tensor([0., 1.]) tensor([0.6877, 0.3123], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 14 - 340: dog - cat || Loss: 1.0002477169036865\n",
      "tensor([0., 1.]) tensor([0.6870, 0.3130], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 14 - 341: dog - cat || Loss: 0.9995366930961609\n",
      "tensor([0., 1.]) tensor([0.6863, 0.3137], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 14 - 342: dog - cat || Loss: 0.998824954032898\n",
      "tensor([0., 1.]) tensor([0.6856, 0.3144], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 14 - 343: dog - cat || Loss: 0.9981127381324768\n",
      "tensor([0., 1.]) tensor([0.6849, 0.3151], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 14 - 344: dog - cat || Loss: 0.997399628162384\n",
      "tensor([0., 1.]) tensor([0.6841, 0.3159], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 14 - 345: dog - cat || Loss: 0.9966858625411987\n",
      "tensor([0., 1.]) tensor([0.6834, 0.3166], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 14 - 346: dog - cat || Loss: 0.9959715604782104\n",
      "tensor([0., 1.]) tensor([0.6827, 0.3173], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 14 - 347: dog - cat || Loss: 0.9952565431594849\n",
      "tensor([0., 1.]) tensor([0.6820, 0.3180], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 14 - 348: dog - cat || Loss: 0.9945407509803772\n",
      "tensor([0., 1.]) tensor([0.6813, 0.3187], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 14 - 349: dog - cat || Loss: 0.9938243627548218\n",
      "tensor([0., 1.]) tensor([0.6806, 0.3194], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 14 - 350: dog - cat || Loss: 0.993107259273529\n",
      "tensor([0., 1.]) tensor([0.6798, 0.3202], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 14 - 351: dog - cat || Loss: 0.9923895001411438\n",
      "tensor([0., 1.]) tensor([0.6791, 0.3209], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 14 - 352: dog - cat || Loss: 0.9916712641716003\n",
      "tensor([0., 1.]) tensor([0.6784, 0.3216], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 14 - 353: dog - cat || Loss: 0.99095219373703\n",
      "tensor([0., 1.]) tensor([0.6777, 0.3223], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 14 - 354: dog - cat || Loss: 0.9902324080467224\n",
      "tensor([0., 1.]) tensor([0.6770, 0.3230], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 14 - 355: dog - cat || Loss: 0.9895119667053223\n",
      "tensor([0., 1.]) tensor([0.6763, 0.3237], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 14 - 356: dog - cat || Loss: 0.9887909293174744\n",
      "tensor([0., 1.]) tensor([0.6755, 0.3245], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 14 - 357: dog - cat || Loss: 0.9880691766738892\n",
      "tensor([0., 1.]) tensor([0.6748, 0.3252], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 14 - 358: dog - cat || Loss: 0.9873468279838562\n",
      "tensor([0., 1.]) tensor([0.6741, 0.3259], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 14 - 359: dog - cat || Loss: 0.9866237640380859\n",
      "tensor([0., 1.]) tensor([0.6734, 0.3266], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 14 - 360: dog - cat || Loss: 0.9858999848365784\n",
      "tensor([0., 1.]) tensor([0.6726, 0.3274], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 14 - 361: dog - cat || Loss: 0.985175609588623\n",
      "tensor([0., 1.]) tensor([0.6719, 0.3281], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 14 - 362: dog - cat || Loss: 0.9844504594802856\n",
      "tensor([0., 1.]) tensor([0.6712, 0.3288], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 14 - 363: dog - cat || Loss: 0.98372483253479\n",
      "tensor([0., 1.]) tensor([0.6705, 0.3295], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 14 - 364: dog - cat || Loss: 0.982998251914978\n",
      "tensor([0., 1.]) tensor([0.6697, 0.3303], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 14 - 365: dog - cat || Loss: 0.9822713136672974\n",
      "tensor([0., 1.]) tensor([0.6690, 0.3310], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 14 - 366: dog - cat || Loss: 0.9815434813499451\n",
      "tensor([0., 1.]) tensor([0.6683, 0.3317], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 14 - 367: dog - cat || Loss: 0.9808151721954346\n",
      "tensor([0., 1.]) tensor([0.6676, 0.3324], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 14 - 368: dog - cat || Loss: 0.9800860285758972\n",
      "tensor([0., 1.]) tensor([0.6668, 0.3332], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 14 - 369: dog - cat || Loss: 0.9793565273284912\n",
      "tensor([0., 1.]) tensor([0.6661, 0.3339], grad_fn=<SoftmaxBackward0>)\n",
      "=====epoch:15=====\n",
      "Epoch 15 - 0: cat - cat || Loss: 0.6478972434997559\n",
      "tensor([1., 0.]) tensor([0.6654, 0.3346], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 15 - 1: cat - cat || Loss: 0.6484813094139099\n",
      "tensor([1., 0.]) tensor([0.6648, 0.3352], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 15 - 2: cat - cat || Loss: 0.6489337086677551\n",
      "tensor([1., 0.]) tensor([0.6643, 0.3357], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 15 - 3: cat - cat || Loss: 0.6492674350738525\n",
      "tensor([1., 0.]) tensor([0.6640, 0.3360], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 15 - 4: cat - cat || Loss: 0.6494942307472229\n",
      "tensor([1., 0.]) tensor([0.6638, 0.3362], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 15 - 5: cat - cat || Loss: 0.6496249437332153\n",
      "tensor([1., 0.]) tensor([0.6636, 0.3364], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 15 - 6: cat - cat || Loss: 0.6496689319610596\n",
      "tensor([1., 0.]) tensor([0.6636, 0.3364], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 15 - 7: cat - cat || Loss: 0.6496350169181824\n",
      "tensor([1., 0.]) tensor([0.6636, 0.3364], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 15 - 8: cat - cat || Loss: 0.6495310068130493\n",
      "tensor([1., 0.]) tensor([0.6637, 0.3363], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 15 - 9: cat - cat || Loss: 0.6493639945983887\n",
      "tensor([1., 0.]) tensor([0.6639, 0.3361], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 15 - 10: cat - cat || Loss: 0.6491400599479675\n",
      "tensor([1., 0.]) tensor([0.6641, 0.3359], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 15 - 11: cat - cat || Loss: 0.6488652229309082\n",
      "tensor([1., 0.]) tensor([0.6644, 0.3356], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 15 - 12: cat - cat || Loss: 0.6485444903373718\n",
      "tensor([1., 0.]) tensor([0.6647, 0.3353], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 15 - 13: cat - cat || Loss: 0.6481825113296509\n",
      "tensor([1., 0.]) tensor([0.6651, 0.3349], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 15 - 14: cat - cat || Loss: 0.6477833390235901\n",
      "tensor([1., 0.]) tensor([0.6655, 0.3345], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 15 - 15: cat - cat || Loss: 0.6473508477210999\n",
      "tensor([1., 0.]) tensor([0.6659, 0.3341], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 15 - 16: cat - cat || Loss: 0.6468884944915771\n",
      "tensor([1., 0.]) tensor([0.6664, 0.3336], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 15 - 17: cat - cat || Loss: 0.646399199962616\n",
      "tensor([1., 0.]) tensor([0.6669, 0.3331], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 15 - 18: cat - cat || Loss: 0.6458858251571655\n",
      "tensor([1., 0.]) tensor([0.6674, 0.3326], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 15 - 19: cat - cat || Loss: 0.6453508138656616\n",
      "tensor([1., 0.]) tensor([0.6679, 0.3321], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 15 - 20: cat - cat || Loss: 0.6447963714599609\n",
      "tensor([1., 0.]) tensor([0.6685, 0.3315], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 15 - 21: cat - cat || Loss: 0.6442245841026306\n",
      "tensor([1., 0.]) tensor([0.6690, 0.3310], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 15 - 22: cat - cat || Loss: 0.6436371803283691\n",
      "tensor([1., 0.]) tensor([0.6696, 0.3304], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 15 - 23: cat - cat || Loss: 0.6430357694625854\n",
      "tensor([1., 0.]) tensor([0.6702, 0.3298], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 15 - 24: cat - cat || Loss: 0.6424218416213989\n",
      "tensor([1., 0.]) tensor([0.6708, 0.3292], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 15 - 25: cat - cat || Loss: 0.6417967081069946\n",
      "tensor([1., 0.]) tensor([0.6715, 0.3285], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 15 - 26: cat - cat || Loss: 0.6411616206169128\n",
      "tensor([1., 0.]) tensor([0.6721, 0.3279], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 15 - 27: cat - cat || Loss: 0.6405175924301147\n",
      "tensor([1., 0.]) tensor([0.6727, 0.3273], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 15 - 28: cat - cat || Loss: 0.6398655772209167\n",
      "tensor([1., 0.]) tensor([0.6734, 0.3266], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 15 - 29: cat - cat || Loss: 0.6392064690589905\n",
      "tensor([1., 0.]) tensor([0.6741, 0.3259], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 15 - 30: cat - cat || Loss: 0.6385411024093628\n",
      "tensor([1., 0.]) tensor([0.6747, 0.3253], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 15 - 31: cat - cat || Loss: 0.6378701329231262\n",
      "tensor([1., 0.]) tensor([0.6754, 0.3246], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 15 - 32: cat - cat || Loss: 0.637194037437439\n",
      "tensor([1., 0.]) tensor([0.6761, 0.3239], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 15 - 33: cat - cat || Loss: 0.6365136504173279\n",
      "tensor([1., 0.]) tensor([0.6767, 0.3233], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 15 - 34: cat - cat || Loss: 0.6358292698860168\n",
      "tensor([1., 0.]) tensor([0.6774, 0.3226], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 15 - 35: cat - cat || Loss: 0.6351414322853088\n",
      "tensor([1., 0.]) tensor([0.6781, 0.3219], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 15 - 36: cat - cat || Loss: 0.6344506144523621\n",
      "tensor([1., 0.]) tensor([0.6788, 0.3212], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 15 - 37: cat - cat || Loss: 0.6337571144104004\n",
      "tensor([1., 0.]) tensor([0.6795, 0.3205], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 15 - 38: cat - cat || Loss: 0.6330612897872925\n",
      "tensor([1., 0.]) tensor([0.6802, 0.3198], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 15 - 39: cat - cat || Loss: 0.6323633790016174\n",
      "tensor([1., 0.]) tensor([0.6809, 0.3191], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 15 - 40: cat - cat || Loss: 0.6316638588905334\n",
      "tensor([1., 0.]) tensor([0.6816, 0.3184], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 15 - 41: cat - cat || Loss: 0.630962610244751\n",
      "tensor([1., 0.]) tensor([0.6823, 0.3177], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 15 - 42: cat - cat || Loss: 0.6302602887153625\n",
      "tensor([1., 0.]) tensor([0.6830, 0.3170], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 15 - 43: cat - cat || Loss: 0.6295567750930786\n",
      "tensor([1., 0.]) tensor([0.6837, 0.3163], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 15 - 44: cat - cat || Loss: 0.6288525462150574\n",
      "tensor([1., 0.]) tensor([0.6844, 0.3156], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 15 - 45: cat - cat || Loss: 0.6281474232673645\n",
      "tensor([1., 0.]) tensor([0.6851, 0.3149], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 15 - 46: cat - cat || Loss: 0.6274417042732239\n",
      "tensor([1., 0.]) tensor([0.6858, 0.3142], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 15 - 47: cat - cat || Loss: 0.6267357468605042\n",
      "tensor([1., 0.]) tensor([0.6865, 0.3135], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 15 - 48: cat - cat || Loss: 0.6260292530059814\n",
      "tensor([1., 0.]) tensor([0.6872, 0.3128], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 15 - 49: cat - cat || Loss: 0.6253226399421692\n",
      "tensor([1., 0.]) tensor([0.6879, 0.3121], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 15 - 50: cat - cat || Loss: 0.6246157884597778\n",
      "tensor([1., 0.]) tensor([0.6886, 0.3114], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 15 - 51: cat - cat || Loss: 0.6239089965820312\n",
      "tensor([1., 0.]) tensor([0.6894, 0.3106], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 15 - 52: cat - cat || Loss: 0.6232021450996399\n",
      "tensor([1., 0.]) tensor([0.6901, 0.3099], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 15 - 53: cat - cat || Loss: 0.6224954128265381\n",
      "tensor([1., 0.]) tensor([0.6908, 0.3092], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 15 - 54: cat - cat || Loss: 0.6217888593673706\n",
      "tensor([1., 0.]) tensor([0.6915, 0.3085], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 15 - 55: cat - cat || Loss: 0.6210824847221375\n",
      "tensor([1., 0.]) tensor([0.6922, 0.3078], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 15 - 56: cat - cat || Loss: 0.6203763484954834\n",
      "tensor([1., 0.]) tensor([0.6929, 0.3071], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 15 - 57: cat - cat || Loss: 0.619670569896698\n",
      "tensor([1., 0.]) tensor([0.6936, 0.3064], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 15 - 58: cat - cat || Loss: 0.6189652681350708\n",
      "tensor([1., 0.]) tensor([0.6943, 0.3057], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 15 - 59: cat - cat || Loss: 0.6182603240013123\n",
      "tensor([1., 0.]) tensor([0.6950, 0.3050], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 15 - 60: cat - cat || Loss: 0.6175557374954224\n",
      "tensor([1., 0.]) tensor([0.6957, 0.3043], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 15 - 61: cat - cat || Loss: 0.6168516874313354\n",
      "tensor([1., 0.]) tensor([0.6964, 0.3036], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 15 - 62: cat - cat || Loss: 0.6161481142044067\n",
      "tensor([1., 0.]) tensor([0.6971, 0.3029], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 15 - 63: cat - cat || Loss: 0.6154451370239258\n",
      "tensor([1., 0.]) tensor([0.6978, 0.3022], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 15 - 64: cat - cat || Loss: 0.6147426962852478\n",
      "tensor([1., 0.]) tensor([0.6985, 0.3015], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 15 - 65: cat - cat || Loss: 0.6140408515930176\n",
      "tensor([1., 0.]) tensor([0.6992, 0.3008], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 15 - 66: cat - cat || Loss: 0.6133395433425903\n",
      "tensor([1., 0.]) tensor([0.6999, 0.3001], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 15 - 67: cat - cat || Loss: 0.6126388907432556\n",
      "tensor([1., 0.]) tensor([0.7006, 0.2994], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 15 - 68: cat - cat || Loss: 0.6119387745857239\n",
      "tensor([1., 0.]) tensor([0.7013, 0.2987], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 15 - 69: cat - cat || Loss: 0.6112393736839294\n",
      "tensor([1., 0.]) tensor([0.7020, 0.2980], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 15 - 70: cat - cat || Loss: 0.6105406880378723\n",
      "tensor([1., 0.]) tensor([0.7027, 0.2973], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 15 - 71: cat - cat || Loss: 0.6098426580429077\n",
      "tensor([1., 0.]) tensor([0.7034, 0.2966], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 15 - 72: cat - cat || Loss: 0.6091451644897461\n",
      "tensor([1., 0.]) tensor([0.7041, 0.2959], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 15 - 73: cat - cat || Loss: 0.6084485054016113\n",
      "tensor([1., 0.]) tensor([0.7048, 0.2952], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 15 - 74: cat - cat || Loss: 0.6077524423599243\n",
      "tensor([1., 0.]) tensor([0.7055, 0.2945], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 15 - 75: cat - cat || Loss: 0.6070572137832642\n",
      "tensor([1., 0.]) tensor([0.7062, 0.2938], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 15 - 76: cat - cat || Loss: 0.6063627004623413\n",
      "tensor([1., 0.]) tensor([0.7069, 0.2931], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 15 - 77: cat - cat || Loss: 0.6056689023971558\n",
      "tensor([1., 0.]) tensor([0.7076, 0.2924], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 15 - 78: cat - cat || Loss: 0.6049758195877075\n",
      "tensor([1., 0.]) tensor([0.7083, 0.2917], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 15 - 79: cat - cat || Loss: 0.6042834520339966\n",
      "tensor([1., 0.]) tensor([0.7090, 0.2910], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 15 - 80: cat - cat || Loss: 0.6035919189453125\n",
      "tensor([1., 0.]) tensor([0.7097, 0.2903], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 15 - 81: cat - cat || Loss: 0.602901041507721\n",
      "tensor([1., 0.]) tensor([0.7104, 0.2896], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 15 - 82: cat - cat || Loss: 0.6022109389305115\n",
      "tensor([1., 0.]) tensor([0.7111, 0.2889], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 15 - 83: cat - cat || Loss: 0.6015217304229736\n",
      "tensor([1., 0.]) tensor([0.7117, 0.2883], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 15 - 84: cat - cat || Loss: 0.6008332967758179\n",
      "tensor([1., 0.]) tensor([0.7124, 0.2876], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 15 - 85: cat - cat || Loss: 0.6001455187797546\n",
      "tensor([1., 0.]) tensor([0.7131, 0.2869], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 15 - 86: cat - cat || Loss: 0.5994585752487183\n",
      "tensor([1., 0.]) tensor([0.7138, 0.2862], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 15 - 87: cat - cat || Loss: 0.5987724661827087\n",
      "tensor([1., 0.]) tensor([0.7145, 0.2855], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 15 - 88: cat - cat || Loss: 0.5980870127677917\n",
      "tensor([1., 0.]) tensor([0.7152, 0.2848], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 15 - 89: cat - cat || Loss: 0.5974025130271912\n",
      "tensor([1., 0.]) tensor([0.7159, 0.2841], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 15 - 90: cat - cat || Loss: 0.5967187285423279\n",
      "tensor([1., 0.]) tensor([0.7165, 0.2835], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 15 - 91: cat - cat || Loss: 0.5960356593132019\n",
      "tensor([1., 0.]) tensor([0.7172, 0.2828], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 15 - 92: cat - cat || Loss: 0.5953535437583923\n",
      "tensor([1., 0.]) tensor([0.7179, 0.2821], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 15 - 93: cat - cat || Loss: 0.5946721434593201\n",
      "tensor([1., 0.]) tensor([0.7186, 0.2814], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 15 - 94: cat - cat || Loss: 0.5939915180206299\n",
      "tensor([1., 0.]) tensor([0.7193, 0.2807], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 15 - 95: cat - cat || Loss: 0.5933117270469666\n",
      "tensor([1., 0.]) tensor([0.7199, 0.2801], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 15 - 96: cat - cat || Loss: 0.5926327705383301\n",
      "tensor([1., 0.]) tensor([0.7206, 0.2794], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 15 - 97: cat - cat || Loss: 0.5919546484947205\n",
      "tensor([1., 0.]) tensor([0.7213, 0.2787], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 15 - 98: cat - cat || Loss: 0.5912773609161377\n",
      "tensor([1., 0.]) tensor([0.7220, 0.2780], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 15 - 99: cat - cat || Loss: 0.5906009674072266\n",
      "tensor([1., 0.]) tensor([0.7227, 0.2773], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 15 - 100: cat - cat || Loss: 0.5899252891540527\n",
      "tensor([1., 0.]) tensor([0.7233, 0.2767], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 15 - 101: cat - cat || Loss: 0.5892505645751953\n",
      "tensor([1., 0.]) tensor([0.7240, 0.2760], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 15 - 102: cat - cat || Loss: 0.5885767340660095\n",
      "tensor([1., 0.]) tensor([0.7247, 0.2753], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 15 - 103: cat - cat || Loss: 0.5879036784172058\n",
      "tensor([1., 0.]) tensor([0.7254, 0.2746], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 15 - 104: cat - cat || Loss: 0.587231457233429\n",
      "tensor([1., 0.]) tensor([0.7260, 0.2740], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 15 - 105: cat - cat || Loss: 0.5865601897239685\n",
      "tensor([1., 0.]) tensor([0.7267, 0.2733], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 15 - 106: cat - cat || Loss: 0.5858896374702454\n",
      "tensor([1., 0.]) tensor([0.7274, 0.2726], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 15 - 107: cat - cat || Loss: 0.5852198600769043\n",
      "tensor([1., 0.]) tensor([0.7280, 0.2720], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 15 - 108: cat - cat || Loss: 0.5845510959625244\n",
      "tensor([1., 0.]) tensor([0.7287, 0.2713], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 15 - 109: cat - cat || Loss: 0.5838831067085266\n",
      "tensor([1., 0.]) tensor([0.7294, 0.2706], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 15 - 110: cat - cat || Loss: 0.5832158327102661\n",
      "tensor([1., 0.]) tensor([0.7300, 0.2700], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 15 - 111: cat - cat || Loss: 0.5825496912002563\n",
      "tensor([1., 0.]) tensor([0.7307, 0.2693], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 15 - 112: cat - cat || Loss: 0.5818842649459839\n",
      "tensor([1., 0.]) tensor([0.7314, 0.2686], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 15 - 113: cat - cat || Loss: 0.5812196731567383\n",
      "tensor([1., 0.]) tensor([0.7320, 0.2680], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 15 - 114: cat - cat || Loss: 0.5805560350418091\n",
      "tensor([1., 0.]) tensor([0.7327, 0.2673], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 15 - 115: cat - cat || Loss: 0.5798932313919067\n",
      "tensor([1., 0.]) tensor([0.7334, 0.2666], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 15 - 116: cat - cat || Loss: 0.579231321811676\n",
      "tensor([1., 0.]) tensor([0.7340, 0.2660], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 15 - 117: cat - cat || Loss: 0.5785702466964722\n",
      "tensor([1., 0.]) tensor([0.7347, 0.2653], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 15 - 118: cat - cat || Loss: 0.5779099464416504\n",
      "tensor([1., 0.]) tensor([0.7354, 0.2646], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 15 - 119: cat - cat || Loss: 0.5772506594657898\n",
      "tensor([1., 0.]) tensor([0.7360, 0.2640], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 15 - 120: cat - cat || Loss: 0.5765921473503113\n",
      "tensor([1., 0.]) tensor([0.7367, 0.2633], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 15 - 121: cat - cat || Loss: 0.5759345889091492\n",
      "tensor([1., 0.]) tensor([0.7373, 0.2627], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 15 - 122: cat - cat || Loss: 0.575278103351593\n",
      "tensor([1., 0.]) tensor([0.7380, 0.2620], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 15 - 123: cat - cat || Loss: 0.5746225118637085\n",
      "tensor([1., 0.]) tensor([0.7386, 0.2614], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 15 - 124: cat - cat || Loss: 0.5739675760269165\n",
      "tensor([1., 0.]) tensor([0.7393, 0.2607], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 15 - 125: cat - cat || Loss: 0.5733137726783752\n",
      "tensor([1., 0.]) tensor([0.7399, 0.2601], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 15 - 126: cat - cat || Loss: 0.5726606845855713\n",
      "tensor([1., 0.]) tensor([0.7406, 0.2594], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 15 - 127: cat - cat || Loss: 0.5720084309577942\n",
      "tensor([1., 0.]) tensor([0.7413, 0.2587], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 15 - 128: cat - cat || Loss: 0.5713571310043335\n",
      "tensor([1., 0.]) tensor([0.7419, 0.2581], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 15 - 129: cat - cat || Loss: 0.5707067847251892\n",
      "tensor([1., 0.]) tensor([0.7426, 0.2574], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 15 - 130: cat - cat || Loss: 0.5700573921203613\n",
      "tensor([1., 0.]) tensor([0.7432, 0.2568], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 15 - 131: cat - cat || Loss: 0.5694087743759155\n",
      "tensor([1., 0.]) tensor([0.7439, 0.2561], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 15 - 132: cat - cat || Loss: 0.5687611103057861\n",
      "tensor([1., 0.]) tensor([0.7445, 0.2555], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 15 - 133: cat - cat || Loss: 0.5681143999099731\n",
      "tensor([1., 0.]) tensor([0.7451, 0.2549], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 15 - 134: cat - cat || Loss: 0.567468523979187\n",
      "tensor([1., 0.]) tensor([0.7458, 0.2542], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 15 - 135: cat - cat || Loss: 0.5668234825134277\n",
      "tensor([1., 0.]) tensor([0.7464, 0.2536], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 15 - 136: cat - cat || Loss: 0.5661795139312744\n",
      "tensor([1., 0.]) tensor([0.7471, 0.2529], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 15 - 137: cat - cat || Loss: 0.5655362606048584\n",
      "tensor([1., 0.]) tensor([0.7477, 0.2523], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 15 - 138: cat - cat || Loss: 0.5648940801620483\n",
      "tensor([1., 0.]) tensor([0.7484, 0.2516], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 15 - 139: cat - cat || Loss: 0.5642527341842651\n",
      "tensor([1., 0.]) tensor([0.7490, 0.2510], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 15 - 140: cat - cat || Loss: 0.5636122226715088\n",
      "tensor([1., 0.]) tensor([0.7496, 0.2504], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 15 - 141: cat - cat || Loss: 0.5629727244377136\n",
      "tensor([1., 0.]) tensor([0.7503, 0.2497], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 15 - 142: cat - cat || Loss: 0.5623341798782349\n",
      "tensor([1., 0.]) tensor([0.7509, 0.2491], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 15 - 143: cat - cat || Loss: 0.5616964101791382\n",
      "tensor([1., 0.]) tensor([0.7516, 0.2484], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 15 - 144: cat - cat || Loss: 0.5610597133636475\n",
      "tensor([1., 0.]) tensor([0.7522, 0.2478], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 15 - 145: cat - cat || Loss: 0.560423731803894\n",
      "tensor([1., 0.]) tensor([0.7528, 0.2472], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 15 - 146: cat - cat || Loss: 0.5597888231277466\n",
      "tensor([1., 0.]) tensor([0.7535, 0.2465], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 15 - 147: cat - cat || Loss: 0.5591546893119812\n",
      "tensor([1., 0.]) tensor([0.7541, 0.2459], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 15 - 148: cat - cat || Loss: 0.558521568775177\n",
      "tensor([1., 0.]) tensor([0.7547, 0.2453], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 15 - 149: cat - cat || Loss: 0.5578893423080444\n",
      "tensor([1., 0.]) tensor([0.7554, 0.2446], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 15 - 150: cat - cat || Loss: 0.5572580099105835\n",
      "tensor([1., 0.]) tensor([0.7560, 0.2440], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 15 - 151: cat - cat || Loss: 0.5566276907920837\n",
      "tensor([1., 0.]) tensor([0.7566, 0.2434], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 15 - 152: cat - cat || Loss: 0.5559982061386108\n",
      "tensor([1., 0.]) tensor([0.7573, 0.2427], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 15 - 153: cat - cat || Loss: 0.5553697347640991\n",
      "tensor([1., 0.]) tensor([0.7579, 0.2421], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 15 - 154: cat - cat || Loss: 0.5547420978546143\n",
      "tensor([1., 0.]) tensor([0.7585, 0.2415], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 15 - 155: cat - cat || Loss: 0.5541154146194458\n",
      "tensor([1., 0.]) tensor([0.7591, 0.2409], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 15 - 156: cat - cat || Loss: 0.5534896850585938\n",
      "tensor([1., 0.]) tensor([0.7598, 0.2402], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 15 - 157: cat - cat || Loss: 0.5528649091720581\n",
      "tensor([1., 0.]) tensor([0.7604, 0.2396], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 15 - 158: cat - cat || Loss: 0.5522410869598389\n",
      "tensor([1., 0.]) tensor([0.7610, 0.2390], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 15 - 159: cat - cat || Loss: 0.5516181588172913\n",
      "tensor([1., 0.]) tensor([0.7616, 0.2384], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 15 - 160: cat - cat || Loss: 0.5509961247444153\n",
      "tensor([1., 0.]) tensor([0.7623, 0.2377], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 15 - 161: cat - cat || Loss: 0.5503751039505005\n",
      "tensor([1., 0.]) tensor([0.7629, 0.2371], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 15 - 162: cat - cat || Loss: 0.5497550964355469\n",
      "tensor([1., 0.]) tensor([0.7635, 0.2365], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 15 - 163: cat - cat || Loss: 0.5491358041763306\n",
      "tensor([1., 0.]) tensor([0.7641, 0.2359], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 15 - 164: cat - cat || Loss: 0.5485177040100098\n",
      "tensor([1., 0.]) tensor([0.7647, 0.2353], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 15 - 165: cat - cat || Loss: 0.5479004383087158\n",
      "tensor([1., 0.]) tensor([0.7654, 0.2346], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 15 - 166: cat - cat || Loss: 0.5472840070724487\n",
      "tensor([1., 0.]) tensor([0.7660, 0.2340], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 15 - 167: cat - cat || Loss: 0.5466686487197876\n",
      "tensor([1., 0.]) tensor([0.7666, 0.2334], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 15 - 168: cat - cat || Loss: 0.5460543632507324\n",
      "tensor([1., 0.]) tensor([0.7672, 0.2328], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 15 - 169: cat - cat || Loss: 0.5454407930374146\n",
      "tensor([1., 0.]) tensor([0.7678, 0.2322], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 15 - 170: cat - cat || Loss: 0.5448282957077026\n",
      "tensor([1., 0.]) tensor([0.7684, 0.2316], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 15 - 171: cat - cat || Loss: 0.5442168712615967\n",
      "tensor([1., 0.]) tensor([0.7690, 0.2310], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 15 - 172: cat - cat || Loss: 0.5436062812805176\n",
      "tensor([1., 0.]) tensor([0.7697, 0.2303], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 15 - 173: cat - cat || Loss: 0.5429966449737549\n",
      "tensor([1., 0.]) tensor([0.7703, 0.2297], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 15 - 174: cat - cat || Loss: 0.5423879623413086\n",
      "tensor([1., 0.]) tensor([0.7709, 0.2291], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 15 - 175: cat - cat || Loss: 0.5417801737785339\n",
      "tensor([1., 0.]) tensor([0.7715, 0.2285], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 15 - 176: cat - cat || Loss: 0.5411734580993652\n",
      "tensor([1., 0.]) tensor([0.7721, 0.2279], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 15 - 177: cat - cat || Loss: 0.5405677556991577\n",
      "tensor([1., 0.]) tensor([0.7727, 0.2273], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 15 - 178: cat - cat || Loss: 0.539962887763977\n",
      "tensor([1., 0.]) tensor([0.7733, 0.2267], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 15 - 179: cat - cat || Loss: 0.5393590927124023\n",
      "tensor([1., 0.]) tensor([0.7739, 0.2261], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 15 - 180: cat - cat || Loss: 0.5387561321258545\n",
      "tensor([1., 0.]) tensor([0.7745, 0.2255], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 15 - 181: cat - cat || Loss: 0.5381542444229126\n",
      "tensor([1., 0.]) tensor([0.7751, 0.2249], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 15 - 182: cat - cat || Loss: 0.5375533699989319\n",
      "tensor([1., 0.]) tensor([0.7757, 0.2243], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 15 - 183: cat - cat || Loss: 0.5369535684585571\n",
      "tensor([1., 0.]) tensor([0.7763, 0.2237], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 15 - 184: cat - cat || Loss: 0.5363545417785645\n",
      "tensor([1., 0.]) tensor([0.7769, 0.2231], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 15 - 185: cat - cat || Loss: 0.5357566475868225\n",
      "tensor([1., 0.]) tensor([0.7775, 0.2225], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 15 - 186: cat - cat || Loss: 0.5351596474647522\n",
      "tensor([1., 0.]) tensor([0.7781, 0.2219], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 15 - 187: cat - cat || Loss: 0.5345635414123535\n",
      "tensor([1., 0.]) tensor([0.7787, 0.2213], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 15 - 188: cat - cat || Loss: 0.5339685678482056\n",
      "tensor([1., 0.]) tensor([0.7793, 0.2207], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 15 - 189: cat - cat || Loss: 0.5333744883537292\n",
      "tensor([1., 0.]) tensor([0.7799, 0.2201], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 15 - 190: dog - cat || Loss: 1.0937418937683105\n",
      "tensor([0., 1.]) tensor([0.7805, 0.2195], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 15 - 191: dog - cat || Loss: 1.0942164659500122\n",
      "tensor([0., 1.]) tensor([0.7810, 0.2190], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 15 - 192: dog - cat || Loss: 1.094584584236145\n",
      "tensor([0., 1.]) tensor([0.7813, 0.2187], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 15 - 193: dog - cat || Loss: 1.0948569774627686\n",
      "tensor([0., 1.]) tensor([0.7816, 0.2184], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 15 - 194: dog - cat || Loss: 1.095043420791626\n",
      "tensor([0., 1.]) tensor([0.7818, 0.2182], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 15 - 195: dog - cat || Loss: 1.095152735710144\n",
      "tensor([0., 1.]) tensor([0.7819, 0.2181], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 15 - 196: dog - cat || Loss: 1.095192551612854\n",
      "tensor([0., 1.]) tensor([0.7819, 0.2181], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 15 - 197: dog - cat || Loss: 1.0951695442199707\n",
      "tensor([0., 1.]) tensor([0.7819, 0.2181], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 15 - 198: dog - cat || Loss: 1.095090627670288\n",
      "tensor([0., 1.]) tensor([0.7818, 0.2182], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 15 - 199: dog - cat || Loss: 1.0949606895446777\n",
      "tensor([0., 1.]) tensor([0.7817, 0.2183], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 15 - 200: dog - cat || Loss: 1.094785213470459\n",
      "tensor([0., 1.]) tensor([0.7815, 0.2185], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 15 - 201: dog - cat || Loss: 1.0945686101913452\n",
      "tensor([0., 1.]) tensor([0.7813, 0.2187], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 15 - 202: dog - cat || Loss: 1.0943149328231812\n",
      "tensor([0., 1.]) tensor([0.7811, 0.2189], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 15 - 203: dog - cat || Loss: 1.0940278768539429\n",
      "tensor([0., 1.]) tensor([0.7808, 0.2192], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 15 - 204: dog - cat || Loss: 1.0937107801437378\n",
      "tensor([0., 1.]) tensor([0.7804, 0.2196], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 15 - 205: dog - cat || Loss: 1.093366026878357\n",
      "tensor([0., 1.]) tensor([0.7801, 0.2199], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 15 - 206: dog - cat || Loss: 1.0929969549179077\n",
      "tensor([0., 1.]) tensor([0.7797, 0.2203], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 15 - 207: dog - cat || Loss: 1.0926058292388916\n",
      "tensor([0., 1.]) tensor([0.7793, 0.2207], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 15 - 208: dog - cat || Loss: 1.0921944379806519\n",
      "tensor([0., 1.]) tensor([0.7789, 0.2211], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 15 - 209: dog - cat || Loss: 1.09176504611969\n",
      "tensor([0., 1.]) tensor([0.7785, 0.2215], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 15 - 210: dog - cat || Loss: 1.0913193225860596\n",
      "tensor([0., 1.]) tensor([0.7781, 0.2219], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 15 - 211: dog - cat || Loss: 1.0908585786819458\n",
      "tensor([0., 1.]) tensor([0.7776, 0.2224], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 15 - 212: dog - cat || Loss: 1.0903843641281128\n",
      "tensor([0., 1.]) tensor([0.7771, 0.2229], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 15 - 213: dog - cat || Loss: 1.0898979902267456\n",
      "tensor([0., 1.]) tensor([0.7766, 0.2234], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 15 - 214: dog - cat || Loss: 1.0894004106521606\n",
      "tensor([0., 1.]) tensor([0.7761, 0.2239], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 15 - 215: dog - cat || Loss: 1.088892936706543\n",
      "tensor([0., 1.]) tensor([0.7756, 0.2244], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 15 - 216: dog - cat || Loss: 1.0883761644363403\n",
      "tensor([0., 1.]) tensor([0.7751, 0.2249], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 15 - 217: dog - cat || Loss: 1.0878511667251587\n",
      "tensor([0., 1.]) tensor([0.7746, 0.2254], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 15 - 218: dog - cat || Loss: 1.0873185396194458\n",
      "tensor([0., 1.]) tensor([0.7741, 0.2259], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 15 - 219: dog - cat || Loss: 1.086778998374939\n",
      "tensor([0., 1.]) tensor([0.7735, 0.2265], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 15 - 220: dog - cat || Loss: 1.0862332582473755\n",
      "tensor([0., 1.]) tensor([0.7730, 0.2270], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 15 - 221: dog - cat || Loss: 1.0856815576553345\n",
      "tensor([0., 1.]) tensor([0.7724, 0.2276], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 15 - 222: dog - cat || Loss: 1.0851247310638428\n",
      "tensor([0., 1.]) tensor([0.7719, 0.2281], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 15 - 223: dog - cat || Loss: 1.08456289768219\n",
      "tensor([0., 1.]) tensor([0.7713, 0.2287], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 15 - 224: dog - cat || Loss: 1.0839967727661133\n",
      "tensor([0., 1.]) tensor([0.7707, 0.2293], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 15 - 225: dog - cat || Loss: 1.0834264755249023\n",
      "tensor([0., 1.]) tensor([0.7702, 0.2298], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 15 - 226: dog - cat || Loss: 1.0828524827957153\n",
      "tensor([0., 1.]) tensor([0.7696, 0.2304], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 15 - 227: dog - cat || Loss: 1.0822749137878418\n",
      "tensor([0., 1.]) tensor([0.7690, 0.2310], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 15 - 228: dog - cat || Loss: 1.0816940069198608\n",
      "tensor([0., 1.]) tensor([0.7684, 0.2316], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 15 - 229: dog - cat || Loss: 1.0811103582382202\n",
      "tensor([0., 1.]) tensor([0.7678, 0.2322], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 15 - 230: dog - cat || Loss: 1.0805236101150513\n",
      "tensor([0., 1.]) tensor([0.7673, 0.2327], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 15 - 231: dog - cat || Loss: 1.0799343585968018\n",
      "tensor([0., 1.]) tensor([0.7667, 0.2333], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 15 - 232: dog - cat || Loss: 1.0793428421020508\n",
      "tensor([0., 1.]) tensor([0.7661, 0.2339], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 15 - 233: dog - cat || Loss: 1.0787489414215088\n",
      "tensor([0., 1.]) tensor([0.7655, 0.2345], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 15 - 234: dog - cat || Loss: 1.0781530141830444\n",
      "tensor([0., 1.]) tensor([0.7649, 0.2351], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 15 - 235: dog - cat || Loss: 1.0775550603866577\n",
      "tensor([0., 1.]) tensor([0.7643, 0.2357], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 15 - 236: dog - cat || Loss: 1.0769550800323486\n",
      "tensor([0., 1.]) tensor([0.7637, 0.2363], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 15 - 237: dog - cat || Loss: 1.0763533115386963\n",
      "tensor([0., 1.]) tensor([0.7631, 0.2369], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 15 - 238: dog - cat || Loss: 1.0757496356964111\n",
      "tensor([0., 1.]) tensor([0.7625, 0.2375], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 15 - 239: dog - cat || Loss: 1.075144648551941\n",
      "tensor([0., 1.]) tensor([0.7619, 0.2381], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 15 - 240: dog - cat || Loss: 1.074537992477417\n",
      "tensor([0., 1.]) tensor([0.7613, 0.2387], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 15 - 241: dog - cat || Loss: 1.0739299058914185\n",
      "tensor([0., 1.]) tensor([0.7607, 0.2393], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 15 - 242: dog - cat || Loss: 1.0733203887939453\n",
      "tensor([0., 1.]) tensor([0.7601, 0.2399], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 15 - 243: dog - cat || Loss: 1.0727092027664185\n",
      "tensor([0., 1.]) tensor([0.7594, 0.2406], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 15 - 244: dog - cat || Loss: 1.0720971822738647\n",
      "tensor([0., 1.]) tensor([0.7588, 0.2412], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 15 - 245: dog - cat || Loss: 1.0714837312698364\n",
      "tensor([0., 1.]) tensor([0.7582, 0.2418], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 15 - 246: dog - cat || Loss: 1.070868968963623\n",
      "tensor([0., 1.]) tensor([0.7576, 0.2424], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 15 - 247: dog - cat || Loss: 1.0702530145645142\n",
      "tensor([0., 1.]) tensor([0.7570, 0.2430], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 15 - 248: dog - cat || Loss: 1.0696359872817993\n",
      "tensor([0., 1.]) tensor([0.7564, 0.2436], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 15 - 249: dog - cat || Loss: 1.0690176486968994\n",
      "tensor([0., 1.]) tensor([0.7558, 0.2442], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 15 - 250: dog - cat || Loss: 1.0683982372283936\n",
      "tensor([0., 1.]) tensor([0.7551, 0.2449], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 15 - 251: dog - cat || Loss: 1.0677778720855713\n",
      "tensor([0., 1.]) tensor([0.7545, 0.2455], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 15 - 252: dog - cat || Loss: 1.067156434059143\n",
      "tensor([0., 1.]) tensor([0.7539, 0.2461], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 15 - 253: dog - cat || Loss: 1.0665336847305298\n",
      "tensor([0., 1.]) tensor([0.7533, 0.2467], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 15 - 254: dog - cat || Loss: 1.0659102201461792\n",
      "tensor([0., 1.]) tensor([0.7526, 0.2474], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 15 - 255: dog - cat || Loss: 1.0652854442596436\n",
      "tensor([0., 1.]) tensor([0.7520, 0.2480], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 15 - 256: dog - cat || Loss: 1.064659833908081\n",
      "tensor([0., 1.]) tensor([0.7514, 0.2486], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 15 - 257: dog - cat || Loss: 1.0640332698822021\n",
      "tensor([0., 1.]) tensor([0.7508, 0.2492], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 15 - 258: dog - cat || Loss: 1.0634057521820068\n",
      "tensor([0., 1.]) tensor([0.7501, 0.2499], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 15 - 259: dog - cat || Loss: 1.0627771615982056\n",
      "tensor([0., 1.]) tensor([0.7495, 0.2505], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 15 - 260: dog - cat || Loss: 1.062147617340088\n",
      "tensor([0., 1.]) tensor([0.7489, 0.2511], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 15 - 261: dog - cat || Loss: 1.061517357826233\n",
      "tensor([0., 1.]) tensor([0.7483, 0.2517], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 15 - 262: dog - cat || Loss: 1.0608859062194824\n",
      "tensor([0., 1.]) tensor([0.7476, 0.2524], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 15 - 263: dog - cat || Loss: 1.0602535009384155\n",
      "tensor([0., 1.]) tensor([0.7470, 0.2530], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 15 - 264: dog - cat || Loss: 1.0596203804016113\n",
      "tensor([0., 1.]) tensor([0.7464, 0.2536], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 15 - 265: dog - cat || Loss: 1.0589861869812012\n",
      "tensor([0., 1.]) tensor([0.7457, 0.2543], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 15 - 266: dog - cat || Loss: 1.0583512783050537\n",
      "tensor([0., 1.]) tensor([0.7451, 0.2549], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 15 - 267: dog - cat || Loss: 1.0577152967453003\n",
      "tensor([0., 1.]) tensor([0.7445, 0.2555], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 15 - 268: dog - cat || Loss: 1.05707848072052\n",
      "tensor([0., 1.]) tensor([0.7438, 0.2562], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 15 - 269: dog - cat || Loss: 1.0564407110214233\n",
      "tensor([0., 1.]) tensor([0.7432, 0.2568], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 15 - 270: dog - cat || Loss: 1.0558021068572998\n",
      "tensor([0., 1.]) tensor([0.7425, 0.2575], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 15 - 271: dog - cat || Loss: 1.0551624298095703\n",
      "tensor([0., 1.]) tensor([0.7419, 0.2581], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 15 - 272: dog - cat || Loss: 1.054522156715393\n",
      "tensor([0., 1.]) tensor([0.7413, 0.2587], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 15 - 273: dog - cat || Loss: 1.0538808107376099\n",
      "tensor([0., 1.]) tensor([0.7406, 0.2594], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 15 - 274: dog - cat || Loss: 1.0532386302947998\n",
      "tensor([0., 1.]) tensor([0.7400, 0.2600], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 15 - 275: dog - cat || Loss: 1.0525957345962524\n",
      "tensor([0., 1.]) tensor([0.7393, 0.2607], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 15 - 276: dog - cat || Loss: 1.0519518852233887\n",
      "tensor([0., 1.]) tensor([0.7387, 0.2613], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 15 - 277: dog - cat || Loss: 1.051307201385498\n",
      "tensor([0., 1.]) tensor([0.7380, 0.2620], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 15 - 278: dog - cat || Loss: 1.0506616830825806\n",
      "tensor([0., 1.]) tensor([0.7374, 0.2626], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 15 - 279: dog - cat || Loss: 1.0500152111053467\n",
      "tensor([0., 1.]) tensor([0.7368, 0.2632], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 15 - 280: dog - cat || Loss: 1.049367904663086\n",
      "tensor([0., 1.]) tensor([0.7361, 0.2639], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 15 - 281: dog - cat || Loss: 1.048719882965088\n",
      "tensor([0., 1.]) tensor([0.7355, 0.2645], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 15 - 282: dog - cat || Loss: 1.0480709075927734\n",
      "tensor([0., 1.]) tensor([0.7348, 0.2652], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 15 - 283: dog - cat || Loss: 1.0474210977554321\n",
      "tensor([0., 1.]) tensor([0.7342, 0.2658], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 15 - 284: dog - cat || Loss: 1.046770453453064\n",
      "tensor([0., 1.]) tensor([0.7335, 0.2665], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 15 - 285: dog - cat || Loss: 1.0461190938949585\n",
      "tensor([0., 1.]) tensor([0.7329, 0.2671], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 15 - 286: dog - cat || Loss: 1.045466661453247\n",
      "tensor([0., 1.]) tensor([0.7322, 0.2678], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 15 - 287: dog - cat || Loss: 1.044813632965088\n",
      "tensor([0., 1.]) tensor([0.7316, 0.2684], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 15 - 288: dog - cat || Loss: 1.0441596508026123\n",
      "tensor([0., 1.]) tensor([0.7309, 0.2691], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 15 - 289: dog - cat || Loss: 1.0435047149658203\n",
      "tensor([0., 1.]) tensor([0.7302, 0.2698], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 15 - 290: dog - cat || Loss: 1.0428493022918701\n",
      "tensor([0., 1.]) tensor([0.7296, 0.2704], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 15 - 291: dog - cat || Loss: 1.042192816734314\n",
      "tensor([0., 1.]) tensor([0.7289, 0.2711], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 15 - 292: dog - cat || Loss: 1.0415353775024414\n",
      "tensor([0., 1.]) tensor([0.7283, 0.2717], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 15 - 293: dog - cat || Loss: 1.040877342224121\n",
      "tensor([0., 1.]) tensor([0.7276, 0.2724], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 15 - 294: dog - cat || Loss: 1.0402183532714844\n",
      "tensor([0., 1.]) tensor([0.7270, 0.2730], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 15 - 295: dog - cat || Loss: 1.0395585298538208\n",
      "tensor([0., 1.]) tensor([0.7263, 0.2737], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 15 - 296: dog - cat || Loss: 1.03889799118042\n",
      "tensor([0., 1.]) tensor([0.7256, 0.2744], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 15 - 297: dog - cat || Loss: 1.0382366180419922\n",
      "tensor([0., 1.]) tensor([0.7250, 0.2750], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 15 - 298: dog - cat || Loss: 1.037574291229248\n",
      "tensor([0., 1.]) tensor([0.7243, 0.2757], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 15 - 299: dog - cat || Loss: 1.0369112491607666\n",
      "tensor([0., 1.]) tensor([0.7236, 0.2764], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 15 - 300: dog - cat || Loss: 1.0362472534179688\n",
      "tensor([0., 1.]) tensor([0.7230, 0.2770], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 15 - 301: dog - cat || Loss: 1.0355826616287231\n",
      "tensor([0., 1.]) tensor([0.7223, 0.2777], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 15 - 302: dog - cat || Loss: 1.0349172353744507\n",
      "tensor([0., 1.]) tensor([0.7217, 0.2783], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 15 - 303: dog - cat || Loss: 1.0342509746551514\n",
      "tensor([0., 1.]) tensor([0.7210, 0.2790], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 15 - 304: dog - cat || Loss: 1.0335837602615356\n",
      "tensor([0., 1.]) tensor([0.7203, 0.2797], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 15 - 305: dog - cat || Loss: 1.0329158306121826\n",
      "tensor([0., 1.]) tensor([0.7197, 0.2803], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 15 - 306: dog - cat || Loss: 1.0322469472885132\n",
      "tensor([0., 1.]) tensor([0.7190, 0.2810], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 15 - 307: dog - cat || Loss: 1.031577467918396\n",
      "tensor([0., 1.]) tensor([0.7183, 0.2817], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 15 - 308: dog - cat || Loss: 1.030907154083252\n",
      "tensor([0., 1.]) tensor([0.7176, 0.2824], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 15 - 309: dog - cat || Loss: 1.030236005783081\n",
      "tensor([0., 1.]) tensor([0.7170, 0.2830], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 15 - 310: dog - cat || Loss: 1.0295639038085938\n",
      "tensor([0., 1.]) tensor([0.7163, 0.2837], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 15 - 311: dog - cat || Loss: 1.0288912057876587\n",
      "tensor([0., 1.]) tensor([0.7156, 0.2844], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 15 - 312: dog - cat || Loss: 1.0282177925109863\n",
      "tensor([0., 1.]) tensor([0.7150, 0.2850], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 15 - 313: dog - cat || Loss: 1.0275434255599976\n",
      "tensor([0., 1.]) tensor([0.7143, 0.2857], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 15 - 314: dog - cat || Loss: 1.0268683433532715\n",
      "tensor([0., 1.]) tensor([0.7136, 0.2864], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 15 - 315: dog - cat || Loss: 1.026192545890808\n",
      "tensor([0., 1.]) tensor([0.7129, 0.2871], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 15 - 316: dog - cat || Loss: 1.0255159139633179\n",
      "tensor([0., 1.]) tensor([0.7123, 0.2877], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 15 - 317: dog - cat || Loss: 1.0248383283615112\n",
      "tensor([0., 1.]) tensor([0.7116, 0.2884], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 15 - 318: dog - cat || Loss: 1.0241601467132568\n",
      "tensor([0., 1.]) tensor([0.7109, 0.2891], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 15 - 319: dog - cat || Loss: 1.0234811305999756\n",
      "tensor([0., 1.]) tensor([0.7102, 0.2898], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 15 - 320: dog - cat || Loss: 1.0228015184402466\n",
      "tensor([0., 1.]) tensor([0.7095, 0.2905], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 15 - 321: dog - cat || Loss: 1.0221209526062012\n",
      "tensor([0., 1.]) tensor([0.7089, 0.2911], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 15 - 322: dog - cat || Loss: 1.021439790725708\n",
      "tensor([0., 1.]) tensor([0.7082, 0.2918], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 15 - 323: dog - cat || Loss: 1.0207575559616089\n",
      "tensor([0., 1.]) tensor([0.7075, 0.2925], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 15 - 324: dog - cat || Loss: 1.020074725151062\n",
      "tensor([0., 1.]) tensor([0.7068, 0.2932], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 15 - 325: dog - cat || Loss: 1.0193910598754883\n",
      "tensor([0., 1.]) tensor([0.7061, 0.2939], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 15 - 326: dog - cat || Loss: 1.0187066793441772\n",
      "tensor([0., 1.]) tensor([0.7054, 0.2946], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 15 - 327: dog - cat || Loss: 1.0180217027664185\n",
      "tensor([0., 1.]) tensor([0.7048, 0.2952], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 15 - 328: dog - cat || Loss: 1.0173357725143433\n",
      "tensor([0., 1.]) tensor([0.7041, 0.2959], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 15 - 329: dog - cat || Loss: 1.0166490077972412\n",
      "tensor([0., 1.]) tensor([0.7034, 0.2966], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 15 - 330: dog - cat || Loss: 1.0159616470336914\n",
      "tensor([0., 1.]) tensor([0.7027, 0.2973], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 15 - 331: dog - cat || Loss: 1.0152734518051147\n",
      "tensor([0., 1.]) tensor([0.7020, 0.2980], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 15 - 332: dog - cat || Loss: 1.0145844221115112\n",
      "tensor([0., 1.]) tensor([0.7013, 0.2987], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 15 - 333: dog - cat || Loss: 1.01389479637146\n",
      "tensor([0., 1.]) tensor([0.7006, 0.2994], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 15 - 334: dog - cat || Loss: 1.0132044553756714\n",
      "tensor([0., 1.]) tensor([0.6999, 0.3001], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 15 - 335: dog - cat || Loss: 1.0125133991241455\n",
      "tensor([0., 1.]) tensor([0.6993, 0.3007], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 15 - 336: dog - cat || Loss: 1.0118215084075928\n",
      "tensor([0., 1.]) tensor([0.6986, 0.3014], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 15 - 337: dog - cat || Loss: 1.0111287832260132\n",
      "tensor([0., 1.]) tensor([0.6979, 0.3021], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 15 - 338: dog - cat || Loss: 1.0104355812072754\n",
      "tensor([0., 1.]) tensor([0.6972, 0.3028], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 15 - 339: dog - cat || Loss: 1.0097415447235107\n",
      "tensor([0., 1.]) tensor([0.6965, 0.3035], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 15 - 340: dog - cat || Loss: 1.0090465545654297\n",
      "tensor([0., 1.]) tensor([0.6958, 0.3042], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 15 - 341: dog - cat || Loss: 1.0083510875701904\n",
      "tensor([0., 1.]) tensor([0.6951, 0.3049], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 15 - 342: dog - cat || Loss: 1.0076547861099243\n",
      "tensor([0., 1.]) tensor([0.6944, 0.3056], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 15 - 343: dog - cat || Loss: 1.006957769393921\n",
      "tensor([0., 1.]) tensor([0.6937, 0.3063], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 15 - 344: dog - cat || Loss: 1.0062601566314697\n",
      "tensor([0., 1.]) tensor([0.6930, 0.3070], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 15 - 345: dog - cat || Loss: 1.0055615901947021\n",
      "tensor([0., 1.]) tensor([0.6923, 0.3077], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 15 - 346: dog - cat || Loss: 1.0048625469207764\n",
      "tensor([0., 1.]) tensor([0.6916, 0.3084], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 15 - 347: dog - cat || Loss: 1.0041625499725342\n",
      "tensor([0., 1.]) tensor([0.6909, 0.3091], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 15 - 348: dog - cat || Loss: 1.0034618377685547\n",
      "tensor([0., 1.]) tensor([0.6902, 0.3098], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 15 - 349: dog - cat || Loss: 1.002760410308838\n",
      "tensor([0., 1.]) tensor([0.6895, 0.3105], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 15 - 350: dog - cat || Loss: 1.0020582675933838\n",
      "tensor([0., 1.]) tensor([0.6888, 0.3112], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 15 - 351: dog - cat || Loss: 1.001355528831482\n",
      "tensor([0., 1.]) tensor([0.6881, 0.3119], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 15 - 352: dog - cat || Loss: 1.0006519556045532\n",
      "tensor([0., 1.]) tensor([0.6874, 0.3126], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 15 - 353: dog - cat || Loss: 0.9999479055404663\n",
      "tensor([0., 1.]) tensor([0.6867, 0.3133], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 15 - 354: dog - cat || Loss: 0.9992427825927734\n",
      "tensor([0., 1.]) tensor([0.6860, 0.3140], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 15 - 355: dog - cat || Loss: 0.9985371828079224\n",
      "tensor([0., 1.]) tensor([0.6853, 0.3147], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 15 - 356: dog - cat || Loss: 0.9978306889533997\n",
      "tensor([0., 1.]) tensor([0.6846, 0.3154], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 15 - 357: dog - cat || Loss: 0.9971235394477844\n",
      "tensor([0., 1.]) tensor([0.6839, 0.3161], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 15 - 358: dog - cat || Loss: 0.9964157342910767\n",
      "tensor([0., 1.]) tensor([0.6832, 0.3168], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 15 - 359: dog - cat || Loss: 0.9957072734832764\n",
      "tensor([0., 1.]) tensor([0.6824, 0.3176], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 15 - 360: dog - cat || Loss: 0.9949979782104492\n",
      "tensor([0., 1.]) tensor([0.6817, 0.3183], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 15 - 361: dog - cat || Loss: 0.9942880868911743\n",
      "tensor([0., 1.]) tensor([0.6810, 0.3190], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 15 - 362: dog - cat || Loss: 0.9935774803161621\n",
      "tensor([0., 1.]) tensor([0.6803, 0.3197], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 15 - 363: dog - cat || Loss: 0.9928662180900574\n",
      "tensor([0., 1.]) tensor([0.6796, 0.3204], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 15 - 364: dog - cat || Loss: 0.9921542406082153\n",
      "tensor([0., 1.]) tensor([0.6789, 0.3211], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 15 - 365: dog - cat || Loss: 0.9914416074752808\n",
      "tensor([0., 1.]) tensor([0.6782, 0.3218], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 15 - 366: dog - cat || Loss: 0.9907280206680298\n",
      "tensor([0., 1.]) tensor([0.6775, 0.3225], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 15 - 367: dog - cat || Loss: 0.9900138974189758\n",
      "tensor([0., 1.]) tensor([0.6768, 0.3232], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 15 - 368: dog - cat || Loss: 0.9892989993095398\n",
      "tensor([0., 1.]) tensor([0.6760, 0.3240], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 15 - 369: dog - cat || Loss: 0.988583505153656\n",
      "tensor([0., 1.]) tensor([0.6753, 0.3247], grad_fn=<SoftmaxBackward0>)\n",
      "=====epoch:16=====\n",
      "Epoch 16 - 0: cat - cat || Loss: 0.6386560797691345\n",
      "tensor([1., 0.]) tensor([0.6746, 0.3254], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 16 - 1: cat - cat || Loss: 0.6392289400100708\n",
      "tensor([1., 0.]) tensor([0.6740, 0.3260], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 16 - 2: cat - cat || Loss: 0.6396725177764893\n",
      "tensor([1., 0.]) tensor([0.6736, 0.3264], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 16 - 3: cat - cat || Loss: 0.6399997472763062\n",
      "tensor([1., 0.]) tensor([0.6733, 0.3267], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 16 - 4: cat - cat || Loss: 0.6402222514152527\n",
      "tensor([1., 0.]) tensor([0.6730, 0.3270], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 16 - 5: cat - cat || Loss: 0.6403501629829407\n",
      "tensor([1., 0.]) tensor([0.6729, 0.3271], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 16 - 6: cat - cat || Loss: 0.6403933167457581\n",
      "tensor([1., 0.]) tensor([0.6729, 0.3271], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 16 - 7: cat - cat || Loss: 0.6403597593307495\n",
      "tensor([1., 0.]) tensor([0.6729, 0.3271], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 16 - 8: cat - cat || Loss: 0.6402575373649597\n",
      "tensor([1., 0.]) tensor([0.6730, 0.3270], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 16 - 9: cat - cat || Loss: 0.6400934457778931\n",
      "tensor([1., 0.]) tensor([0.6732, 0.3268], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 16 - 10: cat - cat || Loss: 0.6398735046386719\n",
      "tensor([1., 0.]) tensor([0.6734, 0.3266], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 16 - 11: cat - cat || Loss: 0.6396036148071289\n",
      "tensor([1., 0.]) tensor([0.6737, 0.3263], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 16 - 12: cat - cat || Loss: 0.6392887234687805\n",
      "tensor([1., 0.]) tensor([0.6740, 0.3260], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 16 - 13: cat - cat || Loss: 0.6389333605766296\n",
      "tensor([1., 0.]) tensor([0.6743, 0.3257], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 16 - 14: cat - cat || Loss: 0.6385416984558105\n",
      "tensor([1., 0.]) tensor([0.6747, 0.3253], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 16 - 15: cat - cat || Loss: 0.638117253780365\n",
      "tensor([1., 0.]) tensor([0.6751, 0.3249], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 16 - 16: cat - cat || Loss: 0.6376636624336243\n",
      "tensor([1., 0.]) tensor([0.6756, 0.3244], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 16 - 17: cat - cat || Loss: 0.6371836066246033\n",
      "tensor([1., 0.]) tensor([0.6761, 0.3239], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 16 - 18: cat - cat || Loss: 0.6366801261901855\n",
      "tensor([1., 0.]) tensor([0.6766, 0.3234], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 16 - 19: cat - cat || Loss: 0.6361552476882935\n",
      "tensor([1., 0.]) tensor([0.6771, 0.3229], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 16 - 20: cat - cat || Loss: 0.635611355304718\n",
      "tensor([1., 0.]) tensor([0.6777, 0.3223], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 16 - 21: cat - cat || Loss: 0.6350504755973816\n",
      "tensor([1., 0.]) tensor([0.6782, 0.3218], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 16 - 22: cat - cat || Loss: 0.6344743371009827\n",
      "tensor([1., 0.]) tensor([0.6788, 0.3212], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 16 - 23: cat - cat || Loss: 0.6338844895362854\n",
      "tensor([1., 0.]) tensor([0.6794, 0.3206], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 16 - 24: cat - cat || Loss: 0.6332823038101196\n",
      "tensor([1., 0.]) tensor([0.6800, 0.3200], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 16 - 25: cat - cat || Loss: 0.63266921043396\n",
      "tensor([1., 0.]) tensor([0.6806, 0.3194], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 16 - 26: cat - cat || Loss: 0.6320464611053467\n",
      "tensor([1., 0.]) tensor([0.6812, 0.3188], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 16 - 27: cat - cat || Loss: 0.6314148306846619\n",
      "tensor([1., 0.]) tensor([0.6818, 0.3182], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 16 - 28: cat - cat || Loss: 0.6307756304740906\n",
      "tensor([1., 0.]) tensor([0.6825, 0.3175], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 16 - 29: cat - cat || Loss: 0.6301292181015015\n",
      "tensor([1., 0.]) tensor([0.6831, 0.3169], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 16 - 30: cat - cat || Loss: 0.6294769048690796\n",
      "tensor([1., 0.]) tensor([0.6838, 0.3162], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 16 - 31: cat - cat || Loss: 0.6288189888000488\n",
      "tensor([1., 0.]) tensor([0.6844, 0.3156], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 16 - 32: cat - cat || Loss: 0.6281561851501465\n",
      "tensor([1., 0.]) tensor([0.6851, 0.3149], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 16 - 33: cat - cat || Loss: 0.6274892091751099\n",
      "tensor([1., 0.]) tensor([0.6858, 0.3142], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 16 - 34: cat - cat || Loss: 0.6268182992935181\n",
      "tensor([1., 0.]) tensor([0.6864, 0.3136], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 16 - 35: cat - cat || Loss: 0.6261441707611084\n",
      "tensor([1., 0.]) tensor([0.6871, 0.3129], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 16 - 36: cat - cat || Loss: 0.6254671812057495\n",
      "tensor([1., 0.]) tensor([0.6878, 0.3122], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 16 - 37: cat - cat || Loss: 0.6247876286506653\n",
      "tensor([1., 0.]) tensor([0.6885, 0.3115], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 16 - 38: cat - cat || Loss: 0.6241058707237244\n",
      "tensor([1., 0.]) tensor([0.6892, 0.3108], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 16 - 39: cat - cat || Loss: 0.6234221458435059\n",
      "tensor([1., 0.]) tensor([0.6898, 0.3102], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 16 - 40: cat - cat || Loss: 0.6227368116378784\n",
      "tensor([1., 0.]) tensor([0.6905, 0.3095], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 16 - 41: cat - cat || Loss: 0.6220499277114868\n",
      "tensor([1., 0.]) tensor([0.6912, 0.3088], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 16 - 42: cat - cat || Loss: 0.6213618516921997\n",
      "tensor([1., 0.]) tensor([0.6919, 0.3081], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 16 - 43: cat - cat || Loss: 0.6206727027893066\n",
      "tensor([1., 0.]) tensor([0.6926, 0.3074], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 16 - 44: cat - cat || Loss: 0.6199830174446106\n",
      "tensor([1., 0.]) tensor([0.6933, 0.3067], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 16 - 45: cat - cat || Loss: 0.6192923784255981\n",
      "tensor([1., 0.]) tensor([0.6940, 0.3060], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 16 - 46: cat - cat || Loss: 0.6186014413833618\n",
      "tensor([1., 0.]) tensor([0.6947, 0.3053], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 16 - 47: cat - cat || Loss: 0.6179099678993225\n",
      "tensor([1., 0.]) tensor([0.6954, 0.3046], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 16 - 48: cat - cat || Loss: 0.6172183752059937\n",
      "tensor([1., 0.]) tensor([0.6960, 0.3040], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 16 - 49: cat - cat || Loss: 0.6165265440940857\n",
      "tensor([1., 0.]) tensor([0.6967, 0.3033], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 16 - 50: cat - cat || Loss: 0.6158345341682434\n",
      "tensor([1., 0.]) tensor([0.6974, 0.3026], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 16 - 51: cat - cat || Loss: 0.6151427030563354\n",
      "tensor([1., 0.]) tensor([0.6981, 0.3019], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 16 - 52: cat - cat || Loss: 0.6144508719444275\n",
      "tensor([1., 0.]) tensor([0.6988, 0.3012], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 16 - 53: cat - cat || Loss: 0.6137590408325195\n",
      "tensor([1., 0.]) tensor([0.6995, 0.3005], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 16 - 54: cat - cat || Loss: 0.6130675673484802\n",
      "tensor([1., 0.]) tensor([0.7002, 0.2998], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 16 - 55: cat - cat || Loss: 0.61237633228302\n",
      "tensor([1., 0.]) tensor([0.7009, 0.2991], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 16 - 56: cat - cat || Loss: 0.6116855144500732\n",
      "tensor([1., 0.]) tensor([0.7016, 0.2984], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 16 - 57: cat - cat || Loss: 0.6109949350357056\n",
      "tensor([1., 0.]) tensor([0.7023, 0.2977], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 16 - 58: cat - cat || Loss: 0.6103050708770752\n",
      "tensor([1., 0.]) tensor([0.7030, 0.2970], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 16 - 59: cat - cat || Loss: 0.6096156239509583\n",
      "tensor([1., 0.]) tensor([0.7036, 0.2964], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 16 - 60: cat - cat || Loss: 0.6089266538619995\n",
      "tensor([1., 0.]) tensor([0.7043, 0.2957], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 16 - 61: cat - cat || Loss: 0.6082382202148438\n",
      "tensor([1., 0.]) tensor([0.7050, 0.2950], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 16 - 62: cat - cat || Loss: 0.6075502038002014\n",
      "tensor([1., 0.]) tensor([0.7057, 0.2943], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 16 - 63: cat - cat || Loss: 0.6068629026412964\n",
      "tensor([1., 0.]) tensor([0.7064, 0.2936], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 16 - 64: cat - cat || Loss: 0.6061761379241943\n",
      "tensor([1., 0.]) tensor([0.7071, 0.2929], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 16 - 65: cat - cat || Loss: 0.60548996925354\n",
      "tensor([1., 0.]) tensor([0.7078, 0.2922], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 16 - 66: cat - cat || Loss: 0.6048043966293335\n",
      "tensor([1., 0.]) tensor([0.7085, 0.2915], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 16 - 67: cat - cat || Loss: 0.604119598865509\n",
      "tensor([1., 0.]) tensor([0.7091, 0.2909], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 16 - 68: cat - cat || Loss: 0.6034352779388428\n",
      "tensor([1., 0.]) tensor([0.7098, 0.2902], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 16 - 69: cat - cat || Loss: 0.6027518510818481\n",
      "tensor([1., 0.]) tensor([0.7105, 0.2895], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 16 - 70: cat - cat || Loss: 0.602069079875946\n",
      "tensor([1., 0.]) tensor([0.7112, 0.2888], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 16 - 71: cat - cat || Loss: 0.601387083530426\n",
      "tensor([1., 0.]) tensor([0.7119, 0.2881], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 16 - 72: cat - cat || Loss: 0.6007056832313538\n",
      "tensor([1., 0.]) tensor([0.7126, 0.2874], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 16 - 73: cat - cat || Loss: 0.6000250577926636\n",
      "tensor([1., 0.]) tensor([0.7132, 0.2868], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 16 - 74: cat - cat || Loss: 0.5993452072143555\n",
      "tensor([1., 0.]) tensor([0.7139, 0.2861], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 16 - 75: cat - cat || Loss: 0.5986660718917847\n",
      "tensor([1., 0.]) tensor([0.7146, 0.2854], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 16 - 76: cat - cat || Loss: 0.5979877710342407\n",
      "tensor([1., 0.]) tensor([0.7153, 0.2847], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 16 - 77: cat - cat || Loss: 0.5973103046417236\n",
      "tensor([1., 0.]) tensor([0.7160, 0.2840], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 16 - 78: cat - cat || Loss: 0.5966333746910095\n",
      "tensor([1., 0.]) tensor([0.7166, 0.2834], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 16 - 79: cat - cat || Loss: 0.5959572792053223\n",
      "tensor([1., 0.]) tensor([0.7173, 0.2827], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 16 - 80: cat - cat || Loss: 0.5952820181846619\n",
      "tensor([1., 0.]) tensor([0.7180, 0.2820], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 16 - 81: cat - cat || Loss: 0.5946075916290283\n",
      "tensor([1., 0.]) tensor([0.7187, 0.2813], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 16 - 82: cat - cat || Loss: 0.5939339399337769\n",
      "tensor([1., 0.]) tensor([0.7193, 0.2807], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 16 - 83: cat - cat || Loss: 0.5932610034942627\n",
      "tensor([1., 0.]) tensor([0.7200, 0.2800], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 16 - 84: cat - cat || Loss: 0.5925890207290649\n",
      "tensor([1., 0.]) tensor([0.7207, 0.2793], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 16 - 85: cat - cat || Loss: 0.5919177532196045\n",
      "tensor([1., 0.]) tensor([0.7213, 0.2787], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 16 - 86: cat - cat || Loss: 0.5912473797798157\n",
      "tensor([1., 0.]) tensor([0.7220, 0.2780], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 16 - 87: cat - cat || Loss: 0.5905778408050537\n",
      "tensor([1., 0.]) tensor([0.7227, 0.2773], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 16 - 88: cat - cat || Loss: 0.5899090766906738\n",
      "tensor([1., 0.]) tensor([0.7234, 0.2766], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 16 - 89: cat - cat || Loss: 0.5892411470413208\n",
      "tensor([1., 0.]) tensor([0.7240, 0.2760], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 16 - 90: cat - cat || Loss: 0.5885741114616394\n",
      "tensor([1., 0.]) tensor([0.7247, 0.2753], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 16 - 91: cat - cat || Loss: 0.5879077911376953\n",
      "tensor([1., 0.]) tensor([0.7254, 0.2746], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 16 - 92: cat - cat || Loss: 0.5872424840927124\n",
      "tensor([1., 0.]) tensor([0.7260, 0.2740], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 16 - 93: cat - cat || Loss: 0.5865779519081116\n",
      "tensor([1., 0.]) tensor([0.7267, 0.2733], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 16 - 94: cat - cat || Loss: 0.5859141945838928\n",
      "tensor([1., 0.]) tensor([0.7273, 0.2727], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 16 - 95: cat - cat || Loss: 0.5852513909339905\n",
      "tensor([1., 0.]) tensor([0.7280, 0.2720], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 16 - 96: cat - cat || Loss: 0.5845895409584045\n",
      "tensor([1., 0.]) tensor([0.7287, 0.2713], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 16 - 97: cat - cat || Loss: 0.5839284062385559\n",
      "tensor([1., 0.]) tensor([0.7293, 0.2707], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 16 - 98: cat - cat || Loss: 0.5832681655883789\n",
      "tensor([1., 0.]) tensor([0.7300, 0.2700], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 16 - 99: cat - cat || Loss: 0.5826089382171631\n",
      "tensor([1., 0.]) tensor([0.7307, 0.2693], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 16 - 100: cat - cat || Loss: 0.5819503664970398\n",
      "tensor([1., 0.]) tensor([0.7313, 0.2687], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 16 - 101: cat - cat || Loss: 0.5812927484512329\n",
      "tensor([1., 0.]) tensor([0.7320, 0.2680], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 16 - 102: cat - cat || Loss: 0.5806359052658081\n",
      "tensor([1., 0.]) tensor([0.7326, 0.2674], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 16 - 103: cat - cat || Loss: 0.5799800157546997\n",
      "tensor([1., 0.]) tensor([0.7333, 0.2667], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 16 - 104: cat - cat || Loss: 0.5793249011039734\n",
      "tensor([1., 0.]) tensor([0.7339, 0.2661], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 16 - 105: cat - cat || Loss: 0.5786707401275635\n",
      "tensor([1., 0.]) tensor([0.7346, 0.2654], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 16 - 106: cat - cat || Loss: 0.57801753282547\n",
      "tensor([1., 0.]) tensor([0.7352, 0.2648], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 16 - 107: cat - cat || Loss: 0.5773650407791138\n",
      "tensor([1., 0.]) tensor([0.7359, 0.2641], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 16 - 108: cat - cat || Loss: 0.576713502407074\n",
      "tensor([1., 0.]) tensor([0.7365, 0.2635], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 16 - 109: cat - cat || Loss: 0.5760628581047058\n",
      "tensor([1., 0.]) tensor([0.7372, 0.2628], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 16 - 110: cat - cat || Loss: 0.575412929058075\n",
      "tensor([1., 0.]) tensor([0.7378, 0.2622], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 16 - 111: cat - cat || Loss: 0.5747640132904053\n",
      "tensor([1., 0.]) tensor([0.7385, 0.2615], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 16 - 112: cat - cat || Loss: 0.5741158723831177\n",
      "tensor([1., 0.]) tensor([0.7391, 0.2609], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 16 - 113: cat - cat || Loss: 0.5734686851501465\n",
      "tensor([1., 0.]) tensor([0.7398, 0.2602], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 16 - 114: cat - cat || Loss: 0.5728223919868469\n",
      "tensor([1., 0.]) tensor([0.7404, 0.2596], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 16 - 115: cat - cat || Loss: 0.572176992893219\n",
      "tensor([1., 0.]) tensor([0.7411, 0.2589], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 16 - 116: cat - cat || Loss: 0.5715324282646179\n",
      "tensor([1., 0.]) tensor([0.7417, 0.2583], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 16 - 117: cat - cat || Loss: 0.5708887577056885\n",
      "tensor([1., 0.]) tensor([0.7424, 0.2576], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 16 - 118: cat - cat || Loss: 0.5702461004257202\n",
      "tensor([1., 0.]) tensor([0.7430, 0.2570], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 16 - 119: cat - cat || Loss: 0.5696042776107788\n",
      "tensor([1., 0.]) tensor([0.7437, 0.2563], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 16 - 120: cat - cat || Loss: 0.5689632296562195\n",
      "tensor([1., 0.]) tensor([0.7443, 0.2557], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 16 - 121: cat - cat || Loss: 0.5683230757713318\n",
      "tensor([1., 0.]) tensor([0.7449, 0.2551], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 16 - 122: cat - cat || Loss: 0.56768399477005\n",
      "tensor([1., 0.]) tensor([0.7456, 0.2544], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 16 - 123: cat - cat || Loss: 0.5670457482337952\n",
      "tensor([1., 0.]) tensor([0.7462, 0.2538], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 16 - 124: cat - cat || Loss: 0.5664083957672119\n",
      "tensor([1., 0.]) tensor([0.7469, 0.2531], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 16 - 125: cat - cat || Loss: 0.5657719373703003\n",
      "tensor([1., 0.]) tensor([0.7475, 0.2525], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 16 - 126: cat - cat || Loss: 0.5651363730430603\n",
      "tensor([1., 0.]) tensor([0.7481, 0.2519], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 16 - 127: cat - cat || Loss: 0.5645017027854919\n",
      "tensor([1., 0.]) tensor([0.7488, 0.2512], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 16 - 128: cat - cat || Loss: 0.5638680458068848\n",
      "tensor([1., 0.]) tensor([0.7494, 0.2506], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 16 - 129: cat - cat || Loss: 0.5632352828979492\n",
      "tensor([1., 0.]) tensor([0.7500, 0.2500], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 16 - 130: cat - cat || Loss: 0.5626034140586853\n",
      "tensor([1., 0.]) tensor([0.7507, 0.2493], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 16 - 131: cat - cat || Loss: 0.561972439289093\n",
      "tensor([1., 0.]) tensor([0.7513, 0.2487], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 16 - 132: cat - cat || Loss: 0.5613423585891724\n",
      "tensor([1., 0.]) tensor([0.7519, 0.2481], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 16 - 133: cat - cat || Loss: 0.5607132911682129\n",
      "tensor([1., 0.]) tensor([0.7525, 0.2475], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 16 - 134: cat - cat || Loss: 0.5600849986076355\n",
      "tensor([1., 0.]) tensor([0.7532, 0.2468], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 16 - 135: cat - cat || Loss: 0.5594577789306641\n",
      "tensor([1., 0.]) tensor([0.7538, 0.2462], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 16 - 136: cat - cat || Loss: 0.5588314533233643\n",
      "tensor([1., 0.]) tensor([0.7544, 0.2456], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 16 - 137: cat - cat || Loss: 0.5582059621810913\n",
      "tensor([1., 0.]) tensor([0.7551, 0.2449], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 16 - 138: cat - cat || Loss: 0.5575814843177795\n",
      "tensor([1., 0.]) tensor([0.7557, 0.2443], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 16 - 139: cat - cat || Loss: 0.5569578409194946\n",
      "tensor([1., 0.]) tensor([0.7563, 0.2437], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 16 - 140: cat - cat || Loss: 0.5563352108001709\n",
      "tensor([1., 0.]) tensor([0.7569, 0.2431], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 16 - 141: cat - cat || Loss: 0.555713415145874\n",
      "tensor([1., 0.]) tensor([0.7575, 0.2425], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 16 - 142: cat - cat || Loss: 0.5550925731658936\n",
      "tensor([1., 0.]) tensor([0.7582, 0.2418], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 16 - 143: cat - cat || Loss: 0.5544726848602295\n",
      "tensor([1., 0.]) tensor([0.7588, 0.2412], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 16 - 144: cat - cat || Loss: 0.5538538098335266\n",
      "tensor([1., 0.]) tensor([0.7594, 0.2406], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 16 - 145: cat - cat || Loss: 0.5532357692718506\n",
      "tensor([1., 0.]) tensor([0.7600, 0.2400], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 16 - 146: cat - cat || Loss: 0.5526187419891357\n",
      "tensor([1., 0.]) tensor([0.7606, 0.2394], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 16 - 147: cat - cat || Loss: 0.5520026087760925\n",
      "tensor([1., 0.]) tensor([0.7613, 0.2387], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 16 - 148: cat - cat || Loss: 0.5513874292373657\n",
      "tensor([1., 0.]) tensor([0.7619, 0.2381], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 16 - 149: cat - cat || Loss: 0.5507732033729553\n",
      "tensor([1., 0.]) tensor([0.7625, 0.2375], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 16 - 150: cat - cat || Loss: 0.5501598119735718\n",
      "tensor([1., 0.]) tensor([0.7631, 0.2369], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 16 - 151: cat - cat || Loss: 0.549547553062439\n",
      "tensor([1., 0.]) tensor([0.7637, 0.2363], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 16 - 152: cat - cat || Loss: 0.548936128616333\n",
      "tensor([1., 0.]) tensor([0.7643, 0.2357], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 16 - 153: cat - cat || Loss: 0.5483256578445435\n",
      "tensor([1., 0.]) tensor([0.7649, 0.2351], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 16 - 154: cat - cat || Loss: 0.5477161407470703\n",
      "tensor([1., 0.]) tensor([0.7655, 0.2345], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 16 - 155: cat - cat || Loss: 0.5471075773239136\n",
      "tensor([1., 0.]) tensor([0.7662, 0.2338], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 16 - 156: cat - cat || Loss: 0.546500027179718\n",
      "tensor([1., 0.]) tensor([0.7668, 0.2332], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 16 - 157: cat - cat || Loss: 0.5458933711051941\n",
      "tensor([1., 0.]) tensor([0.7674, 0.2326], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 16 - 158: cat - cat || Loss: 0.545287549495697\n",
      "tensor([1., 0.]) tensor([0.7680, 0.2320], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 16 - 159: cat - cat || Loss: 0.5446828603744507\n",
      "tensor([1., 0.]) tensor([0.7686, 0.2314], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 16 - 160: cat - cat || Loss: 0.5440789461135864\n",
      "tensor([1., 0.]) tensor([0.7692, 0.2308], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 16 - 161: cat - cat || Loss: 0.5434761047363281\n",
      "tensor([1., 0.]) tensor([0.7698, 0.2302], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 16 - 162: cat - cat || Loss: 0.5428743362426758\n",
      "tensor([1., 0.]) tensor([0.7704, 0.2296], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 16 - 163: cat - cat || Loss: 0.5422732830047607\n",
      "tensor([1., 0.]) tensor([0.7710, 0.2290], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 16 - 164: cat - cat || Loss: 0.5416733622550964\n",
      "tensor([1., 0.]) tensor([0.7716, 0.2284], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 16 - 165: cat - cat || Loss: 0.5410743951797485\n",
      "tensor([1., 0.]) tensor([0.7722, 0.2278], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 16 - 166: cat - cat || Loss: 0.5404762625694275\n",
      "tensor([1., 0.]) tensor([0.7728, 0.2272], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 16 - 167: cat - cat || Loss: 0.5398792028427124\n",
      "tensor([1., 0.]) tensor([0.7734, 0.2266], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 16 - 168: cat - cat || Loss: 0.5392831563949585\n",
      "tensor([1., 0.]) tensor([0.7740, 0.2260], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 16 - 169: cat - cat || Loss: 0.538688063621521\n",
      "tensor([1., 0.]) tensor([0.7746, 0.2254], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 16 - 170: cat - cat || Loss: 0.5380939245223999\n",
      "tensor([1., 0.]) tensor([0.7752, 0.2248], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 16 - 171: cat - cat || Loss: 0.5375007390975952\n",
      "tensor([1., 0.]) tensor([0.7758, 0.2242], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 16 - 172: cat - cat || Loss: 0.5369085073471069\n",
      "tensor([1., 0.]) tensor([0.7764, 0.2236], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 16 - 173: cat - cat || Loss: 0.5363173484802246\n",
      "tensor([1., 0.]) tensor([0.7769, 0.2231], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 16 - 174: cat - cat || Loss: 0.5357270836830139\n",
      "tensor([1., 0.]) tensor([0.7775, 0.2225], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 16 - 175: cat - cat || Loss: 0.5351377725601196\n",
      "tensor([1., 0.]) tensor([0.7781, 0.2219], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 16 - 176: cat - cat || Loss: 0.5345494747161865\n",
      "tensor([1., 0.]) tensor([0.7787, 0.2213], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 16 - 177: cat - cat || Loss: 0.5339622497558594\n",
      "tensor([1., 0.]) tensor([0.7793, 0.2207], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 16 - 178: cat - cat || Loss: 0.5333759188652039\n",
      "tensor([1., 0.]) tensor([0.7799, 0.2201], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 16 - 179: cat - cat || Loss: 0.5327906012535095\n",
      "tensor([1., 0.]) tensor([0.7805, 0.2195], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 16 - 180: cat - cat || Loss: 0.5322061777114868\n",
      "tensor([1., 0.]) tensor([0.7811, 0.2189], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 16 - 181: cat - cat || Loss: 0.5316228270530701\n",
      "tensor([1., 0.]) tensor([0.7816, 0.2184], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 16 - 182: cat - cat || Loss: 0.5310404300689697\n",
      "tensor([1., 0.]) tensor([0.7822, 0.2178], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 16 - 183: cat - cat || Loss: 0.5304590463638306\n",
      "tensor([1., 0.]) tensor([0.7828, 0.2172], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 16 - 184: cat - cat || Loss: 0.5298786163330078\n",
      "tensor([1., 0.]) tensor([0.7834, 0.2166], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 16 - 185: cat - cat || Loss: 0.5292991995811462\n",
      "tensor([1., 0.]) tensor([0.7840, 0.2160], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 16 - 186: cat - cat || Loss: 0.5287206172943115\n",
      "tensor([1., 0.]) tensor([0.7845, 0.2155], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 16 - 187: cat - cat || Loss: 0.5281431674957275\n",
      "tensor([1., 0.]) tensor([0.7851, 0.2149], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 16 - 188: cat - cat || Loss: 0.5275665521621704\n",
      "tensor([1., 0.]) tensor([0.7857, 0.2143], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 16 - 189: cat - cat || Loss: 0.5269911289215088\n",
      "tensor([1., 0.]) tensor([0.7863, 0.2137], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 16 - 190: dog - cat || Loss: 1.1001065969467163\n",
      "tensor([0., 1.]) tensor([0.7868, 0.2132], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 16 - 191: dog - cat || Loss: 1.1005662679672241\n",
      "tensor([0., 1.]) tensor([0.7873, 0.2127], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 16 - 192: dog - cat || Loss: 1.1009228229522705\n",
      "tensor([0., 1.]) tensor([0.7877, 0.2123], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 16 - 193: dog - cat || Loss: 1.101186752319336\n",
      "tensor([0., 1.]) tensor([0.7879, 0.2121], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 16 - 194: dog - cat || Loss: 1.1013672351837158\n",
      "tensor([0., 1.]) tensor([0.7881, 0.2119], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 16 - 195: dog - cat || Loss: 1.1014732122421265\n",
      "tensor([0., 1.]) tensor([0.7882, 0.2118], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 16 - 196: dog - cat || Loss: 1.1015115976333618\n",
      "tensor([0., 1.]) tensor([0.7883, 0.2117], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 16 - 197: dog - cat || Loss: 1.1014896631240845\n",
      "tensor([0., 1.]) tensor([0.7882, 0.2118], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 16 - 198: dog - cat || Loss: 1.101413369178772\n",
      "tensor([0., 1.]) tensor([0.7882, 0.2118], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 16 - 199: dog - cat || Loss: 1.1012877225875854\n",
      "tensor([0., 1.]) tensor([0.7880, 0.2120], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 16 - 200: dog - cat || Loss: 1.101117730140686\n",
      "tensor([0., 1.]) tensor([0.7879, 0.2121], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 16 - 201: dog - cat || Loss: 1.1009081602096558\n",
      "tensor([0., 1.]) tensor([0.7876, 0.2124], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 16 - 202: dog - cat || Loss: 1.1006624698638916\n",
      "tensor([0., 1.]) tensor([0.7874, 0.2126], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 16 - 203: dog - cat || Loss: 1.1003845930099487\n",
      "tensor([0., 1.]) tensor([0.7871, 0.2129], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 16 - 204: dog - cat || Loss: 1.1000773906707764\n",
      "tensor([0., 1.]) tensor([0.7868, 0.2132], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 16 - 205: dog - cat || Loss: 1.0997438430786133\n",
      "tensor([0., 1.]) tensor([0.7865, 0.2135], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 16 - 206: dog - cat || Loss: 1.0993866920471191\n",
      "tensor([0., 1.]) tensor([0.7861, 0.2139], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 16 - 207: dog - cat || Loss: 1.0990079641342163\n",
      "tensor([0., 1.]) tensor([0.7857, 0.2143], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 16 - 208: dog - cat || Loss: 1.0986096858978271\n",
      "tensor([0., 1.]) tensor([0.7853, 0.2147], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 16 - 209: dog - cat || Loss: 1.098193883895874\n",
      "tensor([0., 1.]) tensor([0.7849, 0.2151], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 16 - 210: dog - cat || Loss: 1.0977623462677002\n",
      "tensor([0., 1.]) tensor([0.7845, 0.2155], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 16 - 211: dog - cat || Loss: 1.0973162651062012\n",
      "tensor([0., 1.]) tensor([0.7841, 0.2159], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 16 - 212: dog - cat || Loss: 1.096856951713562\n",
      "tensor([0., 1.]) tensor([0.7836, 0.2164], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 16 - 213: dog - cat || Loss: 1.0963858366012573\n",
      "tensor([0., 1.]) tensor([0.7831, 0.2169], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 16 - 214: dog - cat || Loss: 1.0959041118621826\n",
      "tensor([0., 1.]) tensor([0.7826, 0.2174], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 16 - 215: dog - cat || Loss: 1.0954127311706543\n",
      "tensor([0., 1.]) tensor([0.7822, 0.2178], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 16 - 216: dog - cat || Loss: 1.0949122905731201\n",
      "tensor([0., 1.]) tensor([0.7817, 0.2183], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 16 - 217: dog - cat || Loss: 1.0944037437438965\n",
      "tensor([0., 1.]) tensor([0.7811, 0.2189], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 16 - 218: dog - cat || Loss: 1.0938879251480103\n",
      "tensor([0., 1.]) tensor([0.7806, 0.2194], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 16 - 219: dog - cat || Loss: 1.0933653116226196\n",
      "tensor([0., 1.]) tensor([0.7801, 0.2199], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 16 - 220: dog - cat || Loss: 1.092836618423462\n",
      "tensor([0., 1.]) tensor([0.7796, 0.2204], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 16 - 221: dog - cat || Loss: 1.0923023223876953\n",
      "tensor([0., 1.]) tensor([0.7790, 0.2210], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 16 - 222: dog - cat || Loss: 1.091762900352478\n",
      "tensor([0., 1.]) tensor([0.7785, 0.2215], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 16 - 223: dog - cat || Loss: 1.0912185907363892\n",
      "tensor([0., 1.]) tensor([0.7780, 0.2220], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 16 - 224: dog - cat || Loss: 1.090670108795166\n",
      "tensor([0., 1.]) tensor([0.7774, 0.2226], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 16 - 225: dog - cat || Loss: 1.0901175737380981\n",
      "tensor([0., 1.]) tensor([0.7769, 0.2231], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 16 - 226: dog - cat || Loss: 1.0895613431930542\n",
      "tensor([0., 1.]) tensor([0.7763, 0.2237], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 16 - 227: dog - cat || Loss: 1.0890017747879028\n",
      "tensor([0., 1.]) tensor([0.7757, 0.2243], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 16 - 228: dog - cat || Loss: 1.088438868522644\n",
      "tensor([0., 1.]) tensor([0.7752, 0.2248], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 16 - 229: dog - cat || Loss: 1.0878732204437256\n",
      "tensor([0., 1.]) tensor([0.7746, 0.2254], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 16 - 230: dog - cat || Loss: 1.0873045921325684\n",
      "tensor([0., 1.]) tensor([0.7740, 0.2260], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 16 - 231: dog - cat || Loss: 1.0867335796356201\n",
      "tensor([0., 1.]) tensor([0.7735, 0.2265], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 16 - 232: dog - cat || Loss: 1.0861601829528809\n",
      "tensor([0., 1.]) tensor([0.7729, 0.2271], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 16 - 233: dog - cat || Loss: 1.0855844020843506\n",
      "tensor([0., 1.]) tensor([0.7723, 0.2277], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 16 - 234: dog - cat || Loss: 1.0850067138671875\n",
      "tensor([0., 1.]) tensor([0.7717, 0.2283], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 16 - 235: dog - cat || Loss: 1.0844268798828125\n",
      "tensor([0., 1.]) tensor([0.7712, 0.2288], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 16 - 236: dog - cat || Loss: 1.0838451385498047\n",
      "tensor([0., 1.]) tensor([0.7706, 0.2294], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 16 - 237: dog - cat || Loss: 1.0832616090774536\n",
      "tensor([0., 1.]) tensor([0.7700, 0.2300], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 16 - 238: dog - cat || Loss: 1.0826764106750488\n",
      "tensor([0., 1.]) tensor([0.7694, 0.2306], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 16 - 239: dog - cat || Loss: 1.0820896625518799\n",
      "tensor([0., 1.]) tensor([0.7688, 0.2312], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 16 - 240: dog - cat || Loss: 1.0815012454986572\n",
      "tensor([0., 1.]) tensor([0.7682, 0.2318], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 16 - 241: dog - cat || Loss: 1.08091139793396\n",
      "tensor([0., 1.]) tensor([0.7676, 0.2324], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 16 - 242: dog - cat || Loss: 1.080320119857788\n",
      "tensor([0., 1.]) tensor([0.7671, 0.2329], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 16 - 243: dog - cat || Loss: 1.0797274112701416\n",
      "tensor([0., 1.]) tensor([0.7665, 0.2335], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 16 - 244: dog - cat || Loss: 1.0791335105895996\n",
      "tensor([0., 1.]) tensor([0.7659, 0.2341], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 16 - 245: dog - cat || Loss: 1.0785382986068726\n",
      "tensor([0., 1.]) tensor([0.7653, 0.2347], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 16 - 246: dog - cat || Loss: 1.0779417753219604\n",
      "tensor([0., 1.]) tensor([0.7647, 0.2353], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 16 - 247: dog - cat || Loss: 1.0773440599441528\n",
      "tensor([0., 1.]) tensor([0.7641, 0.2359], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 16 - 248: dog - cat || Loss: 1.0767452716827393\n",
      "tensor([0., 1.]) tensor([0.7635, 0.2365], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 16 - 249: dog - cat || Loss: 1.076145052909851\n",
      "tensor([0., 1.]) tensor([0.7629, 0.2371], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 16 - 250: dog - cat || Loss: 1.075543999671936\n",
      "tensor([0., 1.]) tensor([0.7623, 0.2377], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 16 - 251: dog - cat || Loss: 1.0749417543411255\n",
      "tensor([0., 1.]) tensor([0.7617, 0.2383], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 16 - 252: dog - cat || Loss: 1.0743385553359985\n",
      "tensor([0., 1.]) tensor([0.7611, 0.2389], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 16 - 253: dog - cat || Loss: 1.0737340450286865\n",
      "tensor([0., 1.]) tensor([0.7605, 0.2395], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 16 - 254: dog - cat || Loss: 1.073128581047058\n",
      "tensor([0., 1.]) tensor([0.7599, 0.2401], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 16 - 255: dog - cat || Loss: 1.0725221633911133\n",
      "tensor([0., 1.]) tensor([0.7593, 0.2407], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 16 - 256: dog - cat || Loss: 1.0719146728515625\n",
      "tensor([0., 1.]) tensor([0.7587, 0.2413], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 16 - 257: dog - cat || Loss: 1.0713062286376953\n",
      "tensor([0., 1.]) tensor([0.7580, 0.2420], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 16 - 258: dog - cat || Loss: 1.0706969499588013\n",
      "tensor([0., 1.]) tensor([0.7574, 0.2426], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 16 - 259: dog - cat || Loss: 1.0700864791870117\n",
      "tensor([0., 1.]) tensor([0.7568, 0.2432], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 16 - 260: dog - cat || Loss: 1.0694751739501953\n",
      "tensor([0., 1.]) tensor([0.7562, 0.2438], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 16 - 261: dog - cat || Loss: 1.0688629150390625\n",
      "tensor([0., 1.]) tensor([0.7556, 0.2444], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 16 - 262: dog - cat || Loss: 1.0682495832443237\n",
      "tensor([0., 1.]) tensor([0.7550, 0.2450], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 16 - 263: dog - cat || Loss: 1.0676352977752686\n",
      "tensor([0., 1.]) tensor([0.7544, 0.2456], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 16 - 264: dog - cat || Loss: 1.0670201778411865\n",
      "tensor([0., 1.]) tensor([0.7538, 0.2462], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 16 - 265: dog - cat || Loss: 1.0664039850234985\n",
      "tensor([0., 1.]) tensor([0.7531, 0.2469], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 16 - 266: dog - cat || Loss: 1.0657871961593628\n",
      "tensor([0., 1.]) tensor([0.7525, 0.2475], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 16 - 267: dog - cat || Loss: 1.0651692152023315\n",
      "tensor([0., 1.]) tensor([0.7519, 0.2481], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 16 - 268: dog - cat || Loss: 1.0645503997802734\n",
      "tensor([0., 1.]) tensor([0.7513, 0.2487], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 16 - 269: dog - cat || Loss: 1.063930630683899\n",
      "tensor([0., 1.]) tensor([0.7507, 0.2493], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 16 - 270: dog - cat || Loss: 1.0633100271224976\n",
      "tensor([0., 1.]) tensor([0.7500, 0.2500], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 16 - 271: dog - cat || Loss: 1.0626884698867798\n",
      "tensor([0., 1.]) tensor([0.7494, 0.2506], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 16 - 272: dog - cat || Loss: 1.0620659589767456\n",
      "tensor([0., 1.]) tensor([0.7488, 0.2512], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 16 - 273: dog - cat || Loss: 1.0614427328109741\n",
      "tensor([0., 1.]) tensor([0.7482, 0.2518], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 16 - 274: dog - cat || Loss: 1.0608184337615967\n",
      "tensor([0., 1.]) tensor([0.7476, 0.2524], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 16 - 275: dog - cat || Loss: 1.0601933002471924\n",
      "tensor([0., 1.]) tensor([0.7469, 0.2531], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 16 - 276: dog - cat || Loss: 1.0595672130584717\n",
      "tensor([0., 1.]) tensor([0.7463, 0.2537], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 16 - 277: dog - cat || Loss: 1.0589402914047241\n",
      "tensor([0., 1.]) tensor([0.7457, 0.2543], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 16 - 278: dog - cat || Loss: 1.0583126544952393\n",
      "tensor([0., 1.]) tensor([0.7451, 0.2549], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 16 - 279: dog - cat || Loss: 1.0576839447021484\n",
      "tensor([0., 1.]) tensor([0.7444, 0.2556], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 16 - 280: dog - cat || Loss: 1.0570544004440308\n",
      "tensor([0., 1.]) tensor([0.7438, 0.2562], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 16 - 281: dog - cat || Loss: 1.0564239025115967\n",
      "tensor([0., 1.]) tensor([0.7432, 0.2568], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 16 - 282: dog - cat || Loss: 1.0557928085327148\n",
      "tensor([0., 1.]) tensor([0.7425, 0.2575], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 16 - 283: dog - cat || Loss: 1.0551607608795166\n",
      "tensor([0., 1.]) tensor([0.7419, 0.2581], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 16 - 284: dog - cat || Loss: 1.0545275211334229\n",
      "tensor([0., 1.]) tensor([0.7413, 0.2587], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 16 - 285: dog - cat || Loss: 1.053893804550171\n",
      "tensor([0., 1.]) tensor([0.7406, 0.2594], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 16 - 286: dog - cat || Loss: 1.0532591342926025\n",
      "tensor([0., 1.]) tensor([0.7400, 0.2600], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 16 - 287: dog - cat || Loss: 1.0526235103607178\n",
      "tensor([0., 1.]) tensor([0.7394, 0.2606], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 16 - 288: dog - cat || Loss: 1.0519870519638062\n",
      "tensor([0., 1.]) tensor([0.7387, 0.2613], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 16 - 289: dog - cat || Loss: 1.0513496398925781\n",
      "tensor([0., 1.]) tensor([0.7381, 0.2619], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 16 - 290: dog - cat || Loss: 1.0507116317749023\n",
      "tensor([0., 1.]) tensor([0.7375, 0.2625], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 16 - 291: dog - cat || Loss: 1.0500726699829102\n",
      "tensor([0., 1.]) tensor([0.7368, 0.2632], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 16 - 292: dog - cat || Loss: 1.0494327545166016\n",
      "tensor([0., 1.]) tensor([0.7362, 0.2638], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 16 - 293: dog - cat || Loss: 1.0487920045852661\n",
      "tensor([0., 1.]) tensor([0.7355, 0.2645], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 16 - 294: dog - cat || Loss: 1.0481505393981934\n",
      "tensor([0., 1.]) tensor([0.7349, 0.2651], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 16 - 295: dog - cat || Loss: 1.0475082397460938\n",
      "tensor([0., 1.]) tensor([0.7342, 0.2658], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 16 - 296: dog - cat || Loss: 1.0468649864196777\n",
      "tensor([0., 1.]) tensor([0.7336, 0.2664], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 16 - 297: dog - cat || Loss: 1.0462210178375244\n",
      "tensor([0., 1.]) tensor([0.7330, 0.2670], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 16 - 298: dog - cat || Loss: 1.0455760955810547\n",
      "tensor([0., 1.]) tensor([0.7323, 0.2677], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 16 - 299: dog - cat || Loss: 1.0449304580688477\n",
      "tensor([0., 1.]) tensor([0.7317, 0.2683], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 16 - 300: dog - cat || Loss: 1.0442838668823242\n",
      "tensor([0., 1.]) tensor([0.7310, 0.2690], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 16 - 301: dog - cat || Loss: 1.043636441230774\n",
      "tensor([0., 1.]) tensor([0.7304, 0.2696], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 16 - 302: dog - cat || Loss: 1.0429883003234863\n",
      "tensor([0., 1.]) tensor([0.7297, 0.2703], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 16 - 303: dog - cat || Loss: 1.0423390865325928\n",
      "tensor([0., 1.]) tensor([0.7291, 0.2709], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 16 - 304: dog - cat || Loss: 1.041689157485962\n",
      "tensor([0., 1.]) tensor([0.7284, 0.2716], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 16 - 305: dog - cat || Loss: 1.0410383939743042\n",
      "tensor([0., 1.]) tensor([0.7278, 0.2722], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 16 - 306: dog - cat || Loss: 1.0403870344161987\n",
      "tensor([0., 1.]) tensor([0.7271, 0.2729], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 16 - 307: dog - cat || Loss: 1.0397346019744873\n",
      "tensor([0., 1.]) tensor([0.7265, 0.2735], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 16 - 308: dog - cat || Loss: 1.039081335067749\n",
      "tensor([0., 1.]) tensor([0.7258, 0.2742], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 16 - 309: dog - cat || Loss: 1.038427472114563\n",
      "tensor([0., 1.]) tensor([0.7252, 0.2748], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 16 - 310: dog - cat || Loss: 1.0377726554870605\n",
      "tensor([0., 1.]) tensor([0.7245, 0.2755], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 16 - 311: dog - cat || Loss: 1.0371170043945312\n",
      "tensor([0., 1.]) tensor([0.7239, 0.2761], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 16 - 312: dog - cat || Loss: 1.0364606380462646\n",
      "tensor([0., 1.]) tensor([0.7232, 0.2768], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 16 - 313: dog - cat || Loss: 1.0358033180236816\n",
      "tensor([0., 1.]) tensor([0.7225, 0.2775], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 16 - 314: dog - cat || Loss: 1.0351454019546509\n",
      "tensor([0., 1.]) tensor([0.7219, 0.2781], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 16 - 315: dog - cat || Loss: 1.0344866514205933\n",
      "tensor([0., 1.]) tensor([0.7212, 0.2788], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 16 - 316: dog - cat || Loss: 1.0338270664215088\n",
      "tensor([0., 1.]) tensor([0.7206, 0.2794], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 16 - 317: dog - cat || Loss: 1.0331666469573975\n",
      "tensor([0., 1.]) tensor([0.7199, 0.2801], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 16 - 318: dog - cat || Loss: 1.0325052738189697\n",
      "tensor([0., 1.]) tensor([0.7192, 0.2808], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 16 - 319: dog - cat || Loss: 1.0318434238433838\n",
      "tensor([0., 1.]) tensor([0.7186, 0.2814], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 16 - 320: dog - cat || Loss: 1.0311806201934814\n",
      "tensor([0., 1.]) tensor([0.7179, 0.2821], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 16 - 321: dog - cat || Loss: 1.0305171012878418\n",
      "tensor([0., 1.]) tensor([0.7173, 0.2827], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 16 - 322: dog - cat || Loss: 1.0298527479171753\n",
      "tensor([0., 1.]) tensor([0.7166, 0.2834], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 16 - 323: dog - cat || Loss: 1.029187560081482\n",
      "tensor([0., 1.]) tensor([0.7159, 0.2841], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 16 - 324: dog - cat || Loss: 1.0285216569900513\n",
      "tensor([0., 1.]) tensor([0.7153, 0.2847], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 16 - 325: dog - cat || Loss: 1.0278549194335938\n",
      "tensor([0., 1.]) tensor([0.7146, 0.2854], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 16 - 326: dog - cat || Loss: 1.027187466621399\n",
      "tensor([0., 1.]) tensor([0.7139, 0.2861], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 16 - 327: dog - cat || Loss: 1.0265192985534668\n",
      "tensor([0., 1.]) tensor([0.7133, 0.2867], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 16 - 328: dog - cat || Loss: 1.0258502960205078\n",
      "tensor([0., 1.]) tensor([0.7126, 0.2874], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 16 - 329: dog - cat || Loss: 1.025180459022522\n",
      "tensor([0., 1.]) tensor([0.7119, 0.2881], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 16 - 330: dog - cat || Loss: 1.0245100259780884\n",
      "tensor([0., 1.]) tensor([0.7112, 0.2888], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 16 - 331: dog - cat || Loss: 1.0238385200500488\n",
      "tensor([0., 1.]) tensor([0.7106, 0.2894], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 16 - 332: dog - cat || Loss: 1.0231664180755615\n",
      "tensor([0., 1.]) tensor([0.7099, 0.2901], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 16 - 333: dog - cat || Loss: 1.0224934816360474\n",
      "tensor([0., 1.]) tensor([0.7092, 0.2908], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 16 - 334: dog - cat || Loss: 1.0218199491500854\n",
      "tensor([0., 1.]) tensor([0.7086, 0.2914], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 16 - 335: dog - cat || Loss: 1.0211455821990967\n",
      "tensor([0., 1.]) tensor([0.7079, 0.2921], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 16 - 336: dog - cat || Loss: 1.0204704999923706\n",
      "tensor([0., 1.]) tensor([0.7072, 0.2928], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 16 - 337: dog - cat || Loss: 1.0197945833206177\n",
      "tensor([0., 1.]) tensor([0.7065, 0.2935], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 16 - 338: dog - cat || Loss: 1.019118070602417\n",
      "tensor([0., 1.]) tensor([0.7059, 0.2941], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 16 - 339: dog - cat || Loss: 1.0184407234191895\n",
      "tensor([0., 1.]) tensor([0.7052, 0.2948], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 16 - 340: dog - cat || Loss: 1.017762541770935\n",
      "tensor([0., 1.]) tensor([0.7045, 0.2955], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 16 - 341: dog - cat || Loss: 1.0170836448669434\n",
      "tensor([0., 1.]) tensor([0.7038, 0.2962], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 16 - 342: dog - cat || Loss: 1.0164037942886353\n",
      "tensor([0., 1.]) tensor([0.7031, 0.2969], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 16 - 343: dog - cat || Loss: 1.0157235860824585\n",
      "tensor([0., 1.]) tensor([0.7025, 0.2975], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 16 - 344: dog - cat || Loss: 1.0150425434112549\n",
      "tensor([0., 1.]) tensor([0.7018, 0.2982], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 16 - 345: dog - cat || Loss: 1.0143604278564453\n",
      "tensor([0., 1.]) tensor([0.7011, 0.2989], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 16 - 346: dog - cat || Loss: 1.013677954673767\n",
      "tensor([0., 1.]) tensor([0.7004, 0.2996], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 16 - 347: dog - cat || Loss: 1.012994408607483\n",
      "tensor([0., 1.]) tensor([0.6997, 0.3003], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 16 - 348: dog - cat || Loss: 1.0123103857040405\n",
      "tensor([0., 1.]) tensor([0.6990, 0.3010], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 16 - 349: dog - cat || Loss: 1.0116254091262817\n",
      "tensor([0., 1.]) tensor([0.6984, 0.3016], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 16 - 350: dog - cat || Loss: 1.0109397172927856\n",
      "tensor([0., 1.]) tensor([0.6977, 0.3023], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 16 - 351: dog - cat || Loss: 1.0102533102035522\n",
      "tensor([0., 1.]) tensor([0.6970, 0.3030], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 16 - 352: dog - cat || Loss: 1.009566307067871\n",
      "tensor([0., 1.]) tensor([0.6963, 0.3037], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 16 - 353: dog - cat || Loss: 1.008878469467163\n",
      "tensor([0., 1.]) tensor([0.6956, 0.3044], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 16 - 354: dog - cat || Loss: 1.0081896781921387\n",
      "tensor([0., 1.]) tensor([0.6949, 0.3051], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 16 - 355: dog - cat || Loss: 1.007500410079956\n",
      "tensor([0., 1.]) tensor([0.6942, 0.3058], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 16 - 356: dog - cat || Loss: 1.0068103075027466\n",
      "tensor([0., 1.]) tensor([0.6935, 0.3065], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 16 - 357: dog - cat || Loss: 1.0061194896697998\n",
      "tensor([0., 1.]) tensor([0.6929, 0.3071], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 16 - 358: dog - cat || Loss: 1.0054278373718262\n",
      "tensor([0., 1.]) tensor([0.6922, 0.3078], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 16 - 359: dog - cat || Loss: 1.0047357082366943\n",
      "tensor([0., 1.]) tensor([0.6915, 0.3085], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 16 - 360: dog - cat || Loss: 1.004042625427246\n",
      "tensor([0., 1.]) tensor([0.6908, 0.3092], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 16 - 361: dog - cat || Loss: 1.00334894657135\n",
      "tensor([0., 1.]) tensor([0.6901, 0.3099], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 16 - 362: dog - cat || Loss: 1.0026543140411377\n",
      "tensor([0., 1.]) tensor([0.6894, 0.3106], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 16 - 363: dog - cat || Loss: 1.0019590854644775\n",
      "tensor([0., 1.]) tensor([0.6887, 0.3113], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 16 - 364: dog - cat || Loss: 1.0012630224227905\n",
      "tensor([0., 1.]) tensor([0.6880, 0.3120], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 16 - 365: dog - cat || Loss: 1.0005666017532349\n",
      "tensor([0., 1.]) tensor([0.6873, 0.3127], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 16 - 366: dog - cat || Loss: 0.9998691082000732\n",
      "tensor([0., 1.]) tensor([0.6866, 0.3134], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 16 - 367: dog - cat || Loss: 0.9991711378097534\n",
      "tensor([0., 1.]) tensor([0.6859, 0.3141], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 16 - 368: dog - cat || Loss: 0.9984721541404724\n",
      "tensor([0., 1.]) tensor([0.6852, 0.3148], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 16 - 369: dog - cat || Loss: 0.9977726936340332\n",
      "tensor([0., 1.]) tensor([0.6845, 0.3155], grad_fn=<SoftmaxBackward0>)\n",
      "=====epoch:17=====\n",
      "Epoch 17 - 0: cat - cat || Loss: 0.629450798034668\n",
      "tensor([1., 0.]) tensor([0.6838, 0.3162], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 17 - 1: cat - cat || Loss: 0.6300108432769775\n",
      "tensor([1., 0.]) tensor([0.6833, 0.3167], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 17 - 2: cat - cat || Loss: 0.6304445862770081\n",
      "tensor([1., 0.]) tensor([0.6828, 0.3172], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 17 - 3: cat - cat || Loss: 0.6307645440101624\n",
      "tensor([1., 0.]) tensor([0.6825, 0.3175], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 17 - 4: cat - cat || Loss: 0.6309819221496582\n",
      "tensor([1., 0.]) tensor([0.6823, 0.3177], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 17 - 5: cat - cat || Loss: 0.6311070322990417\n",
      "tensor([1., 0.]) tensor([0.6822, 0.3178], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 17 - 6: cat - cat || Loss: 0.6311490535736084\n",
      "tensor([1., 0.]) tensor([0.6821, 0.3179], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 17 - 7: cat - cat || Loss: 0.6311162710189819\n",
      "tensor([1., 0.]) tensor([0.6821, 0.3179], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 17 - 8: cat - cat || Loss: 0.6310162544250488\n",
      "tensor([1., 0.]) tensor([0.6822, 0.3178], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 17 - 9: cat - cat || Loss: 0.6308556795120239\n",
      "tensor([1., 0.]) tensor([0.6824, 0.3176], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 17 - 10: cat - cat || Loss: 0.6306405663490295\n",
      "tensor([1., 0.]) tensor([0.6826, 0.3174], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 17 - 11: cat - cat || Loss: 0.6303766369819641\n",
      "tensor([1., 0.]) tensor([0.6829, 0.3171], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 17 - 12: cat - cat || Loss: 0.6300686597824097\n",
      "tensor([1., 0.]) tensor([0.6832, 0.3168], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 17 - 13: cat - cat || Loss: 0.6297211647033691\n",
      "tensor([1., 0.]) tensor([0.6835, 0.3165], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 17 - 14: cat - cat || Loss: 0.6293379664421082\n",
      "tensor([1., 0.]) tensor([0.6839, 0.3161], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 17 - 15: cat - cat || Loss: 0.6289229393005371\n",
      "tensor([1., 0.]) tensor([0.6843, 0.3157], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 17 - 16: cat - cat || Loss: 0.6284791231155396\n",
      "tensor([1., 0.]) tensor([0.6848, 0.3152], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 17 - 17: cat - cat || Loss: 0.6280096769332886\n",
      "tensor([1., 0.]) tensor([0.6853, 0.3147], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 17 - 18: cat - cat || Loss: 0.6275171041488647\n",
      "tensor([1., 0.]) tensor([0.6857, 0.3143], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 17 - 19: cat - cat || Loss: 0.6270037293434143\n",
      "tensor([1., 0.]) tensor([0.6863, 0.3137], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 17 - 20: cat - cat || Loss: 0.626471757888794\n",
      "tensor([1., 0.]) tensor([0.6868, 0.3132], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 17 - 21: cat - cat || Loss: 0.6259232759475708\n",
      "tensor([1., 0.]) tensor([0.6873, 0.3127], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 17 - 22: cat - cat || Loss: 0.6253598928451538\n",
      "tensor([1., 0.]) tensor([0.6879, 0.3121], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 17 - 23: cat - cat || Loss: 0.6247830390930176\n",
      "tensor([1., 0.]) tensor([0.6885, 0.3115], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 17 - 24: cat - cat || Loss: 0.6241942644119263\n",
      "tensor([1., 0.]) tensor([0.6891, 0.3109], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 17 - 25: cat - cat || Loss: 0.6235948204994202\n",
      "tensor([1., 0.]) tensor([0.6897, 0.3103], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 17 - 26: cat - cat || Loss: 0.6229860186576843\n",
      "tensor([1., 0.]) tensor([0.6903, 0.3097], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 17 - 27: cat - cat || Loss: 0.6223685145378113\n",
      "tensor([1., 0.]) tensor([0.6909, 0.3091], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 17 - 28: cat - cat || Loss: 0.6217435002326965\n",
      "tensor([1., 0.]) tensor([0.6915, 0.3085], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 17 - 29: cat - cat || Loss: 0.6211116313934326\n",
      "tensor([1., 0.]) tensor([0.6921, 0.3079], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 17 - 30: cat - cat || Loss: 0.6204738616943359\n",
      "tensor([1., 0.]) tensor([0.6928, 0.3072], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 17 - 31: cat - cat || Loss: 0.6198307275772095\n",
      "tensor([1., 0.]) tensor([0.6934, 0.3066], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 17 - 32: cat - cat || Loss: 0.6191829442977905\n",
      "tensor([1., 0.]) tensor([0.6941, 0.3059], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 17 - 33: cat - cat || Loss: 0.6185311079025269\n",
      "tensor([1., 0.]) tensor([0.6947, 0.3053], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 17 - 34: cat - cat || Loss: 0.6178754568099976\n",
      "tensor([1., 0.]) tensor([0.6954, 0.3046], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 17 - 35: cat - cat || Loss: 0.6172166466712952\n",
      "tensor([1., 0.]) tensor([0.6960, 0.3040], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 17 - 36: cat - cat || Loss: 0.6165550351142883\n",
      "tensor([1., 0.]) tensor([0.6967, 0.3033], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 17 - 37: cat - cat || Loss: 0.6158909201622009\n",
      "tensor([1., 0.]) tensor([0.6974, 0.3026], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 17 - 38: cat - cat || Loss: 0.6152247190475464\n",
      "tensor([1., 0.]) tensor([0.6980, 0.3020], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 17 - 39: cat - cat || Loss: 0.6145565509796143\n",
      "tensor([1., 0.]) tensor([0.6987, 0.3013], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 17 - 40: cat - cat || Loss: 0.6138870120048523\n",
      "tensor([1., 0.]) tensor([0.6994, 0.3006], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 17 - 41: cat - cat || Loss: 0.6132159233093262\n",
      "tensor([1., 0.]) tensor([0.7000, 0.3000], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 17 - 42: cat - cat || Loss: 0.6125437617301941\n",
      "tensor([1., 0.]) tensor([0.7007, 0.2993], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 17 - 43: cat - cat || Loss: 0.6118705868721008\n",
      "tensor([1., 0.]) tensor([0.7014, 0.2986], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 17 - 44: cat - cat || Loss: 0.6111968755722046\n",
      "tensor([1., 0.]) tensor([0.7021, 0.2979], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 17 - 45: cat - cat || Loss: 0.6105222702026367\n",
      "tensor([1., 0.]) tensor([0.7027, 0.2973], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 17 - 46: cat - cat || Loss: 0.6098473072052002\n",
      "tensor([1., 0.]) tensor([0.7034, 0.2966], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 17 - 47: cat - cat || Loss: 0.6091720461845398\n",
      "tensor([1., 0.]) tensor([0.7041, 0.2959], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 17 - 48: cat - cat || Loss: 0.6084965467453003\n",
      "tensor([1., 0.]) tensor([0.7048, 0.2952], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 17 - 49: cat - cat || Loss: 0.6078208684921265\n",
      "tensor([1., 0.]) tensor([0.7054, 0.2946], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 17 - 50: cat - cat || Loss: 0.6071452498435974\n",
      "tensor([1., 0.]) tensor([0.7061, 0.2939], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 17 - 51: cat - cat || Loss: 0.6064695119857788\n",
      "tensor([1., 0.]) tensor([0.7068, 0.2932], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 17 - 52: cat - cat || Loss: 0.6057938933372498\n",
      "tensor([1., 0.]) tensor([0.7075, 0.2925], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 17 - 53: cat - cat || Loss: 0.6051186323165894\n",
      "tensor([1., 0.]) tensor([0.7081, 0.2919], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 17 - 54: cat - cat || Loss: 0.6044435501098633\n",
      "tensor([1., 0.]) tensor([0.7088, 0.2912], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 17 - 55: cat - cat || Loss: 0.6037687063217163\n",
      "tensor([1., 0.]) tensor([0.7095, 0.2905], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 17 - 56: cat - cat || Loss: 0.6030943393707275\n",
      "tensor([1., 0.]) tensor([0.7102, 0.2898], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 17 - 57: cat - cat || Loss: 0.6024202704429626\n",
      "tensor([1., 0.]) tensor([0.7108, 0.2892], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 17 - 58: cat - cat || Loss: 0.6017467975616455\n",
      "tensor([1., 0.]) tensor([0.7115, 0.2885], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 17 - 59: cat - cat || Loss: 0.601073682308197\n",
      "tensor([1., 0.]) tensor([0.7122, 0.2878], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 17 - 60: cat - cat || Loss: 0.6004010438919067\n",
      "tensor([1., 0.]) tensor([0.7129, 0.2871], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 17 - 61: cat - cat || Loss: 0.5997289419174194\n",
      "tensor([1., 0.]) tensor([0.7135, 0.2865], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 17 - 62: cat - cat || Loss: 0.5990574359893799\n",
      "tensor([1., 0.]) tensor([0.7142, 0.2858], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 17 - 63: cat - cat || Loss: 0.5983865857124329\n",
      "tensor([1., 0.]) tensor([0.7149, 0.2851], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 17 - 64: cat - cat || Loss: 0.597716212272644\n",
      "tensor([1., 0.]) tensor([0.7155, 0.2845], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 17 - 65: cat - cat || Loss: 0.5970466732978821\n",
      "tensor([1., 0.]) tensor([0.7162, 0.2838], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 17 - 66: cat - cat || Loss: 0.5963777303695679\n",
      "tensor([1., 0.]) tensor([0.7169, 0.2831], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 17 - 67: cat - cat || Loss: 0.5957095623016357\n",
      "tensor([1., 0.]) tensor([0.7176, 0.2824], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 17 - 68: cat - cat || Loss: 0.5950418710708618\n",
      "tensor([1., 0.]) tensor([0.7182, 0.2818], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 17 - 69: cat - cat || Loss: 0.5943750739097595\n",
      "tensor([1., 0.]) tensor([0.7189, 0.2811], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 17 - 70: cat - cat || Loss: 0.5937089323997498\n",
      "tensor([1., 0.]) tensor([0.7196, 0.2804], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 17 - 71: cat - cat || Loss: 0.5930436253547668\n",
      "tensor([1., 0.]) tensor([0.7202, 0.2798], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 17 - 72: cat - cat || Loss: 0.5923788547515869\n",
      "tensor([1., 0.]) tensor([0.7209, 0.2791], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 17 - 73: cat - cat || Loss: 0.5917149782180786\n",
      "tensor([1., 0.]) tensor([0.7215, 0.2785], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 17 - 74: cat - cat || Loss: 0.5910518169403076\n",
      "tensor([1., 0.]) tensor([0.7222, 0.2778], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 17 - 75: cat - cat || Loss: 0.5903894901275635\n",
      "tensor([1., 0.]) tensor([0.7229, 0.2771], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 17 - 76: cat - cat || Loss: 0.5897279381752014\n",
      "tensor([1., 0.]) tensor([0.7235, 0.2765], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 17 - 77: cat - cat || Loss: 0.5890671610832214\n",
      "tensor([1., 0.]) tensor([0.7242, 0.2758], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 17 - 78: cat - cat || Loss: 0.5884070992469788\n",
      "tensor([1., 0.]) tensor([0.7249, 0.2751], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 17 - 79: cat - cat || Loss: 0.5877478718757629\n",
      "tensor([1., 0.]) tensor([0.7255, 0.2745], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 17 - 80: cat - cat || Loss: 0.5870895385742188\n",
      "tensor([1., 0.]) tensor([0.7262, 0.2738], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 17 - 81: cat - cat || Loss: 0.5864318609237671\n",
      "tensor([1., 0.]) tensor([0.7268, 0.2732], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 17 - 82: cat - cat || Loss: 0.5857751965522766\n",
      "tensor([1., 0.]) tensor([0.7275, 0.2725], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 17 - 83: cat - cat || Loss: 0.5851191878318787\n",
      "tensor([1., 0.]) tensor([0.7281, 0.2719], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 17 - 84: cat - cat || Loss: 0.5844641327857971\n",
      "tensor([1., 0.]) tensor([0.7288, 0.2712], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 17 - 85: cat - cat || Loss: 0.5838099718093872\n",
      "tensor([1., 0.]) tensor([0.7295, 0.2705], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 17 - 86: cat - cat || Loss: 0.5831565856933594\n",
      "tensor([1., 0.]) tensor([0.7301, 0.2699], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 17 - 87: cat - cat || Loss: 0.5825040340423584\n",
      "tensor([1., 0.]) tensor([0.7308, 0.2692], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 17 - 88: cat - cat || Loss: 0.5818523168563843\n",
      "tensor([1., 0.]) tensor([0.7314, 0.2686], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 17 - 89: cat - cat || Loss: 0.5812015533447266\n",
      "tensor([1., 0.]) tensor([0.7321, 0.2679], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 17 - 90: cat - cat || Loss: 0.5805515050888062\n",
      "tensor([1., 0.]) tensor([0.7327, 0.2673], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 17 - 91: cat - cat || Loss: 0.5799022912979126\n",
      "tensor([1., 0.]) tensor([0.7334, 0.2666], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 17 - 92: cat - cat || Loss: 0.579254150390625\n",
      "tensor([1., 0.]) tensor([0.7340, 0.2660], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 17 - 93: cat - cat || Loss: 0.5786067247390747\n",
      "tensor([1., 0.]) tensor([0.7347, 0.2653], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 17 - 94: cat - cat || Loss: 0.5779601335525513\n",
      "tensor([1., 0.]) tensor([0.7353, 0.2647], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 17 - 95: cat - cat || Loss: 0.5773144364356995\n",
      "tensor([1., 0.]) tensor([0.7359, 0.2641], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 17 - 96: cat - cat || Loss: 0.5766696333885193\n",
      "tensor([1., 0.]) tensor([0.7366, 0.2634], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 17 - 97: cat - cat || Loss: 0.5760257244110107\n",
      "tensor([1., 0.]) tensor([0.7372, 0.2628], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 17 - 98: cat - cat || Loss: 0.5753825902938843\n",
      "tensor([1., 0.]) tensor([0.7379, 0.2621], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 17 - 99: cat - cat || Loss: 0.5747403502464294\n",
      "tensor([1., 0.]) tensor([0.7385, 0.2615], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 17 - 100: cat - cat || Loss: 0.5740990042686462\n",
      "tensor([1., 0.]) tensor([0.7392, 0.2608], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 17 - 101: cat - cat || Loss: 0.5734586715698242\n",
      "tensor([1., 0.]) tensor([0.7398, 0.2602], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 17 - 102: cat - cat || Loss: 0.5728191137313843\n",
      "tensor([1., 0.]) tensor([0.7404, 0.2596], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 17 - 103: cat - cat || Loss: 0.5721803307533264\n",
      "tensor([1., 0.]) tensor([0.7411, 0.2589], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 17 - 104: cat - cat || Loss: 0.5715426206588745\n",
      "tensor([1., 0.]) tensor([0.7417, 0.2583], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 17 - 105: cat - cat || Loss: 0.5709058046340942\n",
      "tensor([1., 0.]) tensor([0.7424, 0.2576], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 17 - 106: cat - cat || Loss: 0.570269763469696\n",
      "tensor([1., 0.]) tensor([0.7430, 0.2570], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 17 - 107: cat - cat || Loss: 0.5696346163749695\n",
      "tensor([1., 0.]) tensor([0.7436, 0.2564], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 17 - 108: cat - cat || Loss: 0.5690005421638489\n",
      "tensor([1., 0.]) tensor([0.7443, 0.2557], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 17 - 109: cat - cat || Loss: 0.5683671832084656\n",
      "tensor([1., 0.]) tensor([0.7449, 0.2551], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 17 - 110: cat - cat || Loss: 0.5677347779273987\n",
      "tensor([1., 0.]) tensor([0.7455, 0.2545], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 17 - 111: cat - cat || Loss: 0.5671032071113586\n",
      "tensor([1., 0.]) tensor([0.7462, 0.2538], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 17 - 112: cat - cat || Loss: 0.566472589969635\n",
      "tensor([1., 0.]) tensor([0.7468, 0.2532], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 17 - 113: cat - cat || Loss: 0.5658429265022278\n",
      "tensor([1., 0.]) tensor([0.7474, 0.2526], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 17 - 114: cat - cat || Loss: 0.5652140974998474\n",
      "tensor([1., 0.]) tensor([0.7480, 0.2520], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 17 - 115: cat - cat || Loss: 0.5645862817764282\n",
      "tensor([1., 0.]) tensor([0.7487, 0.2513], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 17 - 116: cat - cat || Loss: 0.5639591813087463\n",
      "tensor([1., 0.]) tensor([0.7493, 0.2507], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 17 - 117: cat - cat || Loss: 0.5633331537246704\n",
      "tensor([1., 0.]) tensor([0.7499, 0.2501], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 17 - 118: cat - cat || Loss: 0.5627079010009766\n",
      "tensor([1., 0.]) tensor([0.7506, 0.2494], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 17 - 119: cat - cat || Loss: 0.5620837807655334\n",
      "tensor([1., 0.]) tensor([0.7512, 0.2488], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 17 - 120: cat - cat || Loss: 0.5614603757858276\n",
      "tensor([1., 0.]) tensor([0.7518, 0.2482], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 17 - 121: cat - cat || Loss: 0.5608378648757935\n",
      "tensor([1., 0.]) tensor([0.7524, 0.2476], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 17 - 122: cat - cat || Loss: 0.5602165460586548\n",
      "tensor([1., 0.]) tensor([0.7530, 0.2470], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 17 - 123: cat - cat || Loss: 0.5595959424972534\n",
      "tensor([1., 0.]) tensor([0.7537, 0.2463], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 17 - 124: cat - cat || Loss: 0.5589763522148132\n",
      "tensor([1., 0.]) tensor([0.7543, 0.2457], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 17 - 125: cat - cat || Loss: 0.5583577156066895\n",
      "tensor([1., 0.]) tensor([0.7549, 0.2451], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 17 - 126: cat - cat || Loss: 0.5577398538589478\n",
      "tensor([1., 0.]) tensor([0.7555, 0.2445], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 17 - 127: cat - cat || Loss: 0.5571229457855225\n",
      "tensor([1., 0.]) tensor([0.7561, 0.2439], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 17 - 128: cat - cat || Loss: 0.5565069913864136\n",
      "tensor([1., 0.]) tensor([0.7568, 0.2432], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 17 - 129: cat - cat || Loss: 0.5558920502662659\n",
      "tensor([1., 0.]) tensor([0.7574, 0.2426], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 17 - 130: cat - cat || Loss: 0.5552780628204346\n",
      "tensor([1., 0.]) tensor([0.7580, 0.2420], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 17 - 131: cat - cat || Loss: 0.5546648502349854\n",
      "tensor([1., 0.]) tensor([0.7586, 0.2414], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 17 - 132: cat - cat || Loss: 0.5540525913238525\n",
      "tensor([1., 0.]) tensor([0.7592, 0.2408], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 17 - 133: cat - cat || Loss: 0.5534414649009705\n",
      "tensor([1., 0.]) tensor([0.7598, 0.2402], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 17 - 134: cat - cat || Loss: 0.5528310537338257\n",
      "tensor([1., 0.]) tensor([0.7604, 0.2396], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 17 - 135: cat - cat || Loss: 0.5522217154502869\n",
      "tensor([1., 0.]) tensor([0.7610, 0.2390], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 17 - 136: cat - cat || Loss: 0.5516132116317749\n",
      "tensor([1., 0.]) tensor([0.7616, 0.2384], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 17 - 137: cat - cat || Loss: 0.5510056614875793\n",
      "tensor([1., 0.]) tensor([0.7623, 0.2377], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 17 - 138: cat - cat || Loss: 0.550399124622345\n",
      "tensor([1., 0.]) tensor([0.7629, 0.2371], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 17 - 139: cat - cat || Loss: 0.5497934222221375\n",
      "tensor([1., 0.]) tensor([0.7635, 0.2365], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 17 - 140: cat - cat || Loss: 0.5491887331008911\n",
      "tensor([1., 0.]) tensor([0.7641, 0.2359], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 17 - 141: cat - cat || Loss: 0.5485849976539612\n",
      "tensor([1., 0.]) tensor([0.7647, 0.2353], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 17 - 142: cat - cat || Loss: 0.5479822158813477\n",
      "tensor([1., 0.]) tensor([0.7653, 0.2347], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 17 - 143: cat - cat || Loss: 0.5473803281784058\n",
      "tensor([1., 0.]) tensor([0.7659, 0.2341], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 17 - 144: cat - cat || Loss: 0.5467793941497803\n",
      "tensor([1., 0.]) tensor([0.7665, 0.2335], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 17 - 145: cat - cat || Loss: 0.5461793541908264\n",
      "tensor([1., 0.]) tensor([0.7671, 0.2329], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 17 - 146: cat - cat || Loss: 0.5455803871154785\n",
      "tensor([1., 0.]) tensor([0.7677, 0.2323], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 17 - 147: cat - cat || Loss: 0.5449823141098022\n",
      "tensor([1., 0.]) tensor([0.7683, 0.2317], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 17 - 148: cat - cat || Loss: 0.5443851351737976\n",
      "tensor([1., 0.]) tensor([0.7689, 0.2311], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 17 - 149: cat - cat || Loss: 0.5437890291213989\n",
      "tensor([1., 0.]) tensor([0.7695, 0.2305], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 17 - 150: cat - cat || Loss: 0.5431938767433167\n",
      "tensor([1., 0.]) tensor([0.7701, 0.2299], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 17 - 151: cat - cat || Loss: 0.5425997376441956\n",
      "tensor([1., 0.]) tensor([0.7707, 0.2293], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 17 - 152: cat - cat || Loss: 0.5420064926147461\n",
      "tensor([1., 0.]) tensor([0.7713, 0.2287], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 17 - 153: cat - cat || Loss: 0.5414141416549683\n",
      "tensor([1., 0.]) tensor([0.7718, 0.2282], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 17 - 154: cat - cat || Loss: 0.5408227443695068\n",
      "tensor([1., 0.]) tensor([0.7724, 0.2276], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 17 - 155: cat - cat || Loss: 0.5402323007583618\n",
      "tensor([1., 0.]) tensor([0.7730, 0.2270], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 17 - 156: cat - cat || Loss: 0.539642870426178\n",
      "tensor([1., 0.]) tensor([0.7736, 0.2264], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 17 - 157: cat - cat || Loss: 0.5390545129776001\n",
      "tensor([1., 0.]) tensor([0.7742, 0.2258], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 17 - 158: cat - cat || Loss: 0.5384669303894043\n",
      "tensor([1., 0.]) tensor([0.7748, 0.2252], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 17 - 159: cat - cat || Loss: 0.5378803610801697\n",
      "tensor([1., 0.]) tensor([0.7754, 0.2246], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 17 - 160: cat - cat || Loss: 0.5372947454452515\n",
      "tensor([1., 0.]) tensor([0.7760, 0.2240], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 17 - 161: cat - cat || Loss: 0.5367101430892944\n",
      "tensor([1., 0.]) tensor([0.7766, 0.2234], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 17 - 162: cat - cat || Loss: 0.5361266136169434\n",
      "tensor([1., 0.]) tensor([0.7771, 0.2229], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 17 - 163: cat - cat || Loss: 0.5355438590049744\n",
      "tensor([1., 0.]) tensor([0.7777, 0.2223], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 17 - 164: cat - cat || Loss: 0.5349621176719666\n",
      "tensor([1., 0.]) tensor([0.7783, 0.2217], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 17 - 165: cat - cat || Loss: 0.5343813896179199\n",
      "tensor([1., 0.]) tensor([0.7789, 0.2211], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 17 - 166: cat - cat || Loss: 0.5338016152381897\n",
      "tensor([1., 0.]) tensor([0.7795, 0.2205], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 17 - 167: cat - cat || Loss: 0.5332227349281311\n",
      "tensor([1., 0.]) tensor([0.7800, 0.2200], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 17 - 168: cat - cat || Loss: 0.5326449275016785\n",
      "tensor([1., 0.]) tensor([0.7806, 0.2194], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 17 - 169: cat - cat || Loss: 0.5320679545402527\n",
      "tensor([1., 0.]) tensor([0.7812, 0.2188], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 17 - 170: cat - cat || Loss: 0.5314921140670776\n",
      "tensor([1., 0.]) tensor([0.7818, 0.2182], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 17 - 171: cat - cat || Loss: 0.530917227268219\n",
      "tensor([1., 0.]) tensor([0.7823, 0.2177], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 17 - 172: cat - cat || Loss: 0.5303432941436768\n",
      "tensor([1., 0.]) tensor([0.7829, 0.2171], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 17 - 173: cat - cat || Loss: 0.5297703742980957\n",
      "tensor([1., 0.]) tensor([0.7835, 0.2165], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 17 - 174: cat - cat || Loss: 0.5291982889175415\n",
      "tensor([1., 0.]) tensor([0.7841, 0.2159], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 17 - 175: cat - cat || Loss: 0.528627336025238\n",
      "tensor([1., 0.]) tensor([0.7846, 0.2154], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 17 - 176: cat - cat || Loss: 0.5280572175979614\n",
      "tensor([1., 0.]) tensor([0.7852, 0.2148], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 17 - 177: cat - cat || Loss: 0.5274882316589355\n",
      "tensor([1., 0.]) tensor([0.7858, 0.2142], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 17 - 178: cat - cat || Loss: 0.5269201397895813\n",
      "tensor([1., 0.]) tensor([0.7863, 0.2137], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 17 - 179: cat - cat || Loss: 0.5263530015945435\n",
      "tensor([1., 0.]) tensor([0.7869, 0.2131], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 17 - 180: cat - cat || Loss: 0.5257868766784668\n",
      "tensor([1., 0.]) tensor([0.7875, 0.2125], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 17 - 181: cat - cat || Loss: 0.5252217650413513\n",
      "tensor([1., 0.]) tensor([0.7880, 0.2120], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 17 - 182: cat - cat || Loss: 0.524657666683197\n",
      "tensor([1., 0.]) tensor([0.7886, 0.2114], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 17 - 183: cat - cat || Loss: 0.5240945219993591\n",
      "tensor([1., 0.]) tensor([0.7892, 0.2108], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 17 - 184: cat - cat || Loss: 0.5235323905944824\n",
      "tensor([1., 0.]) tensor([0.7897, 0.2103], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 17 - 185: cat - cat || Loss: 0.5229711532592773\n",
      "tensor([1., 0.]) tensor([0.7903, 0.2097], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 17 - 186: cat - cat || Loss: 0.5224108695983887\n",
      "tensor([1., 0.]) tensor([0.7909, 0.2091], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 17 - 187: cat - cat || Loss: 0.5218517780303955\n",
      "tensor([1., 0.]) tensor([0.7914, 0.2086], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 17 - 188: cat - cat || Loss: 0.5212935209274292\n",
      "tensor([1., 0.]) tensor([0.7920, 0.2080], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 17 - 189: cat - cat || Loss: 0.5207363963127136\n",
      "tensor([1., 0.]) tensor([0.7925, 0.2075], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 17 - 190: dog - cat || Loss: 1.106343150138855\n",
      "tensor([0., 1.]) tensor([0.7931, 0.2069], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 17 - 191: dog - cat || Loss: 1.106788158416748\n",
      "tensor([0., 1.]) tensor([0.7935, 0.2065], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 17 - 192: dog - cat || Loss: 1.1071335077285767\n",
      "tensor([0., 1.]) tensor([0.7939, 0.2061], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 17 - 193: dog - cat || Loss: 1.107388973236084\n",
      "tensor([0., 1.]) tensor([0.7941, 0.2059], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 17 - 194: dog - cat || Loss: 1.1075639724731445\n",
      "tensor([0., 1.]) tensor([0.7943, 0.2057], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 17 - 195: dog - cat || Loss: 1.1076666116714478\n",
      "tensor([0., 1.]) tensor([0.7944, 0.2056], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 17 - 196: dog - cat || Loss: 1.1077039241790771\n",
      "tensor([0., 1.]) tensor([0.7944, 0.2056], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 17 - 197: dog - cat || Loss: 1.107682466506958\n",
      "tensor([0., 1.]) tensor([0.7944, 0.2056], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 17 - 198: dog - cat || Loss: 1.107608675956726\n",
      "tensor([0., 1.]) tensor([0.7943, 0.2057], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 17 - 199: dog - cat || Loss: 1.1074870824813843\n",
      "tensor([0., 1.]) tensor([0.7942, 0.2058], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 17 - 200: dog - cat || Loss: 1.1073229312896729\n",
      "tensor([0., 1.]) tensor([0.7941, 0.2059], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 17 - 201: dog - cat || Loss: 1.1071199178695679\n",
      "tensor([0., 1.]) tensor([0.7939, 0.2061], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 17 - 202: dog - cat || Loss: 1.1068823337554932\n",
      "tensor([0., 1.]) tensor([0.7936, 0.2064], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 17 - 203: dog - cat || Loss: 1.1066133975982666\n",
      "tensor([0., 1.]) tensor([0.7934, 0.2066], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 17 - 204: dog - cat || Loss: 1.1063162088394165\n",
      "tensor([0., 1.]) tensor([0.7931, 0.2069], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 17 - 205: dog - cat || Loss: 1.1059932708740234\n",
      "tensor([0., 1.]) tensor([0.7927, 0.2073], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 17 - 206: dog - cat || Loss: 1.1056475639343262\n",
      "tensor([0., 1.]) tensor([0.7924, 0.2076], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 17 - 207: dog - cat || Loss: 1.105280876159668\n",
      "tensor([0., 1.]) tensor([0.7920, 0.2080], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 17 - 208: dog - cat || Loss: 1.1048953533172607\n",
      "tensor([0., 1.]) tensor([0.7916, 0.2084], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 17 - 209: dog - cat || Loss: 1.1044929027557373\n",
      "tensor([0., 1.]) tensor([0.7912, 0.2088], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 17 - 210: dog - cat || Loss: 1.1040749549865723\n",
      "tensor([0., 1.]) tensor([0.7908, 0.2092], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 17 - 211: dog - cat || Loss: 1.1036431789398193\n",
      "tensor([0., 1.]) tensor([0.7904, 0.2096], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 17 - 212: dog - cat || Loss: 1.1031984090805054\n",
      "tensor([0., 1.]) tensor([0.7899, 0.2101], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 17 - 213: dog - cat || Loss: 1.1027425527572632\n",
      "tensor([0., 1.]) tensor([0.7895, 0.2105], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 17 - 214: dog - cat || Loss: 1.1022759675979614\n",
      "tensor([0., 1.]) tensor([0.7890, 0.2110], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 17 - 215: dog - cat || Loss: 1.1017999649047852\n",
      "tensor([0., 1.]) tensor([0.7885, 0.2115], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 17 - 216: dog - cat || Loss: 1.1013154983520508\n",
      "tensor([0., 1.]) tensor([0.7881, 0.2119], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 17 - 217: dog - cat || Loss: 1.100823163986206\n",
      "tensor([0., 1.]) tensor([0.7876, 0.2124], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 17 - 218: dog - cat || Loss: 1.1003234386444092\n",
      "tensor([0., 1.]) tensor([0.7871, 0.2129], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 17 - 219: dog - cat || Loss: 1.0998173952102661\n",
      "tensor([0., 1.]) tensor([0.7866, 0.2134], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 17 - 220: dog - cat || Loss: 1.099305272102356\n",
      "tensor([0., 1.]) tensor([0.7860, 0.2140], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 17 - 221: dog - cat || Loss: 1.098787784576416\n",
      "tensor([0., 1.]) tensor([0.7855, 0.2145], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 17 - 222: dog - cat || Loss: 1.0982650518417358\n",
      "tensor([0., 1.]) tensor([0.7850, 0.2150], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 17 - 223: dog - cat || Loss: 1.0977380275726318\n",
      "tensor([0., 1.]) tensor([0.7845, 0.2155], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 17 - 224: dog - cat || Loss: 1.097206473350525\n",
      "tensor([0., 1.]) tensor([0.7839, 0.2161], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 17 - 225: dog - cat || Loss: 1.096671223640442\n",
      "tensor([0., 1.]) tensor([0.7834, 0.2166], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 17 - 226: dog - cat || Loss: 1.0961321592330933\n",
      "tensor([0., 1.]) tensor([0.7829, 0.2171], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 17 - 227: dog - cat || Loss: 1.0955898761749268\n",
      "tensor([0., 1.]) tensor([0.7823, 0.2177], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 17 - 228: dog - cat || Loss: 1.0950443744659424\n",
      "tensor([0., 1.]) tensor([0.7818, 0.2182], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 17 - 229: dog - cat || Loss: 1.0944963693618774\n",
      "tensor([0., 1.]) tensor([0.7812, 0.2188], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 17 - 230: dog - cat || Loss: 1.0939451456069946\n",
      "tensor([0., 1.]) tensor([0.7807, 0.2193], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 17 - 231: dog - cat || Loss: 1.0933917760849\n",
      "tensor([0., 1.]) tensor([0.7801, 0.2199], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 17 - 232: dog - cat || Loss: 1.0928360223770142\n",
      "tensor([0., 1.]) tensor([0.7796, 0.2204], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 17 - 233: dog - cat || Loss: 1.0922778844833374\n",
      "tensor([0., 1.]) tensor([0.7790, 0.2210], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 17 - 234: dog - cat || Loss: 1.0917179584503174\n",
      "tensor([0., 1.]) tensor([0.7785, 0.2215], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 17 - 235: dog - cat || Loss: 1.0911558866500854\n",
      "tensor([0., 1.]) tensor([0.7779, 0.2221], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 17 - 236: dog - cat || Loss: 1.0905917882919312\n",
      "tensor([0., 1.]) tensor([0.7773, 0.2227], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 17 - 237: dog - cat || Loss: 1.0900263786315918\n",
      "tensor([0., 1.]) tensor([0.7768, 0.2232], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 17 - 238: dog - cat || Loss: 1.08945894241333\n",
      "tensor([0., 1.]) tensor([0.7762, 0.2238], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 17 - 239: dog - cat || Loss: 1.0888899564743042\n",
      "tensor([0., 1.]) tensor([0.7756, 0.2244], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 17 - 240: dog - cat || Loss: 1.0883194208145142\n",
      "tensor([0., 1.]) tensor([0.7751, 0.2249], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 17 - 241: dog - cat || Loss: 1.0877474546432495\n",
      "tensor([0., 1.]) tensor([0.7745, 0.2255], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 17 - 242: dog - cat || Loss: 1.0871740579605103\n",
      "tensor([0., 1.]) tensor([0.7739, 0.2261], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 17 - 243: dog - cat || Loss: 1.0865992307662964\n",
      "tensor([0., 1.]) tensor([0.7733, 0.2267], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 17 - 244: dog - cat || Loss: 1.086023211479187\n",
      "tensor([0., 1.]) tensor([0.7728, 0.2272], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 17 - 245: dog - cat || Loss: 1.0854460000991821\n",
      "tensor([0., 1.]) tensor([0.7722, 0.2278], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 17 - 246: dog - cat || Loss: 1.084867238998413\n",
      "tensor([0., 1.]) tensor([0.7716, 0.2284], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 17 - 247: dog - cat || Loss: 1.084287405014038\n",
      "tensor([0., 1.]) tensor([0.7710, 0.2290], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 17 - 248: dog - cat || Loss: 1.0837066173553467\n",
      "tensor([0., 1.]) tensor([0.7704, 0.2296], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 17 - 249: dog - cat || Loss: 1.0831242799758911\n",
      "tensor([0., 1.]) tensor([0.7699, 0.2301], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 17 - 250: dog - cat || Loss: 1.0825412273406982\n",
      "tensor([0., 1.]) tensor([0.7693, 0.2307], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 17 - 251: dog - cat || Loss: 1.0819568634033203\n",
      "tensor([0., 1.]) tensor([0.7687, 0.2313], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 17 - 252: dog - cat || Loss: 1.0813713073730469\n",
      "tensor([0., 1.]) tensor([0.7681, 0.2319], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 17 - 253: dog - cat || Loss: 1.0807846784591675\n",
      "tensor([0., 1.]) tensor([0.7675, 0.2325], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 17 - 254: dog - cat || Loss: 1.0801973342895508\n",
      "tensor([0., 1.]) tensor([0.7669, 0.2331], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 17 - 255: dog - cat || Loss: 1.0796085596084595\n",
      "tensor([0., 1.]) tensor([0.7663, 0.2337], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 17 - 256: dog - cat || Loss: 1.0790189504623413\n",
      "tensor([0., 1.]) tensor([0.7658, 0.2342], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 17 - 257: dog - cat || Loss: 1.0784283876419067\n",
      "tensor([0., 1.]) tensor([0.7652, 0.2348], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 17 - 258: dog - cat || Loss: 1.0778366327285767\n",
      "tensor([0., 1.]) tensor([0.7646, 0.2354], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 17 - 259: dog - cat || Loss: 1.0772441625595093\n",
      "tensor([0., 1.]) tensor([0.7640, 0.2360], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 17 - 260: dog - cat || Loss: 1.0766505002975464\n",
      "tensor([0., 1.]) tensor([0.7634, 0.2366], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 17 - 261: dog - cat || Loss: 1.0760560035705566\n",
      "tensor([0., 1.]) tensor([0.7628, 0.2372], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 17 - 262: dog - cat || Loss: 1.0754605531692505\n",
      "tensor([0., 1.]) tensor([0.7622, 0.2378], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 17 - 263: dog - cat || Loss: 1.0748640298843384\n",
      "tensor([0., 1.]) tensor([0.7616, 0.2384], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 17 - 264: dog - cat || Loss: 1.0742666721343994\n",
      "tensor([0., 1.]) tensor([0.7610, 0.2390], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 17 - 265: dog - cat || Loss: 1.073668122291565\n",
      "tensor([0., 1.]) tensor([0.7604, 0.2396], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 17 - 266: dog - cat || Loss: 1.0730688571929932\n",
      "tensor([0., 1.]) tensor([0.7598, 0.2402], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 17 - 267: dog - cat || Loss: 1.0724687576293945\n",
      "tensor([0., 1.]) tensor([0.7592, 0.2408], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 17 - 268: dog - cat || Loss: 1.0718674659729004\n",
      "tensor([0., 1.]) tensor([0.7586, 0.2414], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 17 - 269: dog - cat || Loss: 1.071265459060669\n",
      "tensor([0., 1.]) tensor([0.7580, 0.2420], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 17 - 270: dog - cat || Loss: 1.0706623792648315\n",
      "tensor([0., 1.]) tensor([0.7574, 0.2426], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 17 - 271: dog - cat || Loss: 1.0700584650039673\n",
      "tensor([0., 1.]) tensor([0.7568, 0.2432], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 17 - 272: dog - cat || Loss: 1.069453477859497\n",
      "tensor([0., 1.]) tensor([0.7562, 0.2438], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 17 - 273: dog - cat || Loss: 1.068847894668579\n",
      "tensor([0., 1.]) tensor([0.7556, 0.2444], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 17 - 274: dog - cat || Loss: 1.0682412385940552\n",
      "tensor([0., 1.]) tensor([0.7550, 0.2450], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 17 - 275: dog - cat || Loss: 1.0676337480545044\n",
      "tensor([0., 1.]) tensor([0.7544, 0.2456], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 17 - 276: dog - cat || Loss: 1.0670253038406372\n",
      "tensor([0., 1.]) tensor([0.7538, 0.2462], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 17 - 277: dog - cat || Loss: 1.0664159059524536\n",
      "tensor([0., 1.]) tensor([0.7532, 0.2468], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 17 - 278: dog - cat || Loss: 1.0658056735992432\n",
      "tensor([0., 1.]) tensor([0.7525, 0.2475], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 17 - 279: dog - cat || Loss: 1.0651944875717163\n",
      "tensor([0., 1.]) tensor([0.7519, 0.2481], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 17 - 280: dog - cat || Loss: 1.064582347869873\n",
      "tensor([0., 1.]) tensor([0.7513, 0.2487], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 17 - 281: dog - cat || Loss: 1.0639694929122925\n",
      "tensor([0., 1.]) tensor([0.7507, 0.2493], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 17 - 282: dog - cat || Loss: 1.063355803489685\n",
      "tensor([0., 1.]) tensor([0.7501, 0.2499], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 17 - 283: dog - cat || Loss: 1.0627411603927612\n",
      "tensor([0., 1.]) tensor([0.7495, 0.2505], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 17 - 284: dog - cat || Loss: 1.0621256828308105\n",
      "tensor([0., 1.]) tensor([0.7489, 0.2511], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 17 - 285: dog - cat || Loss: 1.061509132385254\n",
      "tensor([0., 1.]) tensor([0.7482, 0.2518], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 17 - 286: dog - cat || Loss: 1.06089186668396\n",
      "tensor([0., 1.]) tensor([0.7476, 0.2524], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 17 - 287: dog - cat || Loss: 1.0602737665176392\n",
      "tensor([0., 1.]) tensor([0.7470, 0.2530], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 17 - 288: dog - cat || Loss: 1.059654712677002\n",
      "tensor([0., 1.]) tensor([0.7464, 0.2536], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 17 - 289: dog - cat || Loss: 1.059034824371338\n",
      "tensor([0., 1.]) tensor([0.7458, 0.2542], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 17 - 290: dog - cat || Loss: 1.0584139823913574\n",
      "tensor([0., 1.]) tensor([0.7452, 0.2548], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 17 - 291: dog - cat || Loss: 1.0577925443649292\n",
      "tensor([0., 1.]) tensor([0.7445, 0.2555], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 17 - 292: dog - cat || Loss: 1.057169795036316\n",
      "tensor([0., 1.]) tensor([0.7439, 0.2561], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 17 - 293: dog - cat || Loss: 1.0565464496612549\n",
      "tensor([0., 1.]) tensor([0.7433, 0.2567], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 17 - 294: dog - cat || Loss: 1.0559221506118774\n",
      "tensor([0., 1.]) tensor([0.7427, 0.2573], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 17 - 295: dog - cat || Loss: 1.0552970170974731\n",
      "tensor([0., 1.]) tensor([0.7420, 0.2580], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 17 - 296: dog - cat || Loss: 1.054671049118042\n",
      "tensor([0., 1.]) tensor([0.7414, 0.2586], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 17 - 297: dog - cat || Loss: 1.054044246673584\n",
      "tensor([0., 1.]) tensor([0.7408, 0.2592], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 17 - 298: dog - cat || Loss: 1.0534164905548096\n",
      "tensor([0., 1.]) tensor([0.7402, 0.2598], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 17 - 299: dog - cat || Loss: 1.0527877807617188\n",
      "tensor([0., 1.]) tensor([0.7395, 0.2605], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 17 - 300: dog - cat || Loss: 1.0521583557128906\n",
      "tensor([0., 1.]) tensor([0.7389, 0.2611], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 17 - 301: dog - cat || Loss: 1.051527976989746\n",
      "tensor([0., 1.]) tensor([0.7383, 0.2617], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 17 - 302: dog - cat || Loss: 1.0508968830108643\n",
      "tensor([0., 1.]) tensor([0.7376, 0.2624], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 17 - 303: dog - cat || Loss: 1.0502647161483765\n",
      "tensor([0., 1.]) tensor([0.7370, 0.2630], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 17 - 304: dog - cat || Loss: 1.049631953239441\n",
      "tensor([0., 1.]) tensor([0.7364, 0.2636], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 17 - 305: dog - cat || Loss: 1.048998236656189\n",
      "tensor([0., 1.]) tensor([0.7357, 0.2643], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 17 - 306: dog - cat || Loss: 1.0483636856079102\n",
      "tensor([0., 1.]) tensor([0.7351, 0.2649], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 17 - 307: dog - cat || Loss: 1.0477283000946045\n",
      "tensor([0., 1.]) tensor([0.7345, 0.2655], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 17 - 308: dog - cat || Loss: 1.047092080116272\n",
      "tensor([0., 1.]) tensor([0.7338, 0.2662], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 17 - 309: dog - cat || Loss: 1.046454906463623\n",
      "tensor([0., 1.]) tensor([0.7332, 0.2668], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 17 - 310: dog - cat || Loss: 1.0458170175552368\n",
      "tensor([0., 1.]) tensor([0.7326, 0.2674], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 17 - 311: dog - cat || Loss: 1.0451781749725342\n",
      "tensor([0., 1.]) tensor([0.7319, 0.2681], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 17 - 312: dog - cat || Loss: 1.0445386171340942\n",
      "tensor([0., 1.]) tensor([0.7313, 0.2687], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 17 - 313: dog - cat || Loss: 1.0438982248306274\n",
      "tensor([0., 1.]) tensor([0.7306, 0.2694], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 17 - 314: dog - cat || Loss: 1.0432569980621338\n",
      "tensor([0., 1.]) tensor([0.7300, 0.2700], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 17 - 315: dog - cat || Loss: 1.0426149368286133\n",
      "tensor([0., 1.]) tensor([0.7294, 0.2706], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 17 - 316: dog - cat || Loss: 1.0419719219207764\n",
      "tensor([0., 1.]) tensor([0.7287, 0.2713], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 17 - 317: dog - cat || Loss: 1.0413281917572021\n",
      "tensor([0., 1.]) tensor([0.7281, 0.2719], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 17 - 318: dog - cat || Loss: 1.040683627128601\n",
      "tensor([0., 1.]) tensor([0.7274, 0.2726], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 17 - 319: dog - cat || Loss: 1.0400382280349731\n",
      "tensor([0., 1.]) tensor([0.7268, 0.2732], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 17 - 320: dog - cat || Loss: 1.039392113685608\n",
      "tensor([0., 1.]) tensor([0.7261, 0.2739], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 17 - 321: dog - cat || Loss: 1.0387449264526367\n",
      "tensor([0., 1.]) tensor([0.7255, 0.2745], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 17 - 322: dog - cat || Loss: 1.0380972623825073\n",
      "tensor([0., 1.]) tensor([0.7248, 0.2752], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 17 - 323: dog - cat || Loss: 1.037448525428772\n",
      "tensor([0., 1.]) tensor([0.7242, 0.2758], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 17 - 324: dog - cat || Loss: 1.0367990732192993\n",
      "tensor([0., 1.]) tensor([0.7235, 0.2765], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 17 - 325: dog - cat || Loss: 1.0361489057540894\n",
      "tensor([0., 1.]) tensor([0.7229, 0.2771], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 17 - 326: dog - cat || Loss: 1.0354979038238525\n",
      "tensor([0., 1.]) tensor([0.7222, 0.2778], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 17 - 327: dog - cat || Loss: 1.0348460674285889\n",
      "tensor([0., 1.]) tensor([0.7216, 0.2784], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 17 - 328: dog - cat || Loss: 1.0341933965682983\n",
      "tensor([0., 1.]) tensor([0.7209, 0.2791], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 17 - 329: dog - cat || Loss: 1.033539891242981\n",
      "tensor([0., 1.]) tensor([0.7203, 0.2797], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 17 - 330: dog - cat || Loss: 1.0328857898712158\n",
      "tensor([0., 1.]) tensor([0.7196, 0.2804], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 17 - 331: dog - cat || Loss: 1.0322306156158447\n",
      "tensor([0., 1.]) tensor([0.7190, 0.2810], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 17 - 332: dog - cat || Loss: 1.0315748453140259\n",
      "tensor([0., 1.]) tensor([0.7183, 0.2817], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 17 - 333: dog - cat || Loss: 1.0309181213378906\n",
      "tensor([0., 1.]) tensor([0.7177, 0.2823], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 17 - 334: dog - cat || Loss: 1.030260682106018\n",
      "tensor([0., 1.]) tensor([0.7170, 0.2830], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 17 - 335: dog - cat || Loss: 1.0296026468276978\n",
      "tensor([0., 1.]) tensor([0.7163, 0.2837], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 17 - 336: dog - cat || Loss: 1.028943657875061\n",
      "tensor([0., 1.]) tensor([0.7157, 0.2843], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 17 - 337: dog - cat || Loss: 1.028283953666687\n",
      "tensor([0., 1.]) tensor([0.7150, 0.2850], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 17 - 338: dog - cat || Loss: 1.0276234149932861\n",
      "tensor([0., 1.]) tensor([0.7144, 0.2856], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 17 - 339: dog - cat || Loss: 1.0269620418548584\n",
      "tensor([0., 1.]) tensor([0.7137, 0.2863], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 17 - 340: dog - cat || Loss: 1.0262998342514038\n",
      "tensor([0., 1.]) tensor([0.7130, 0.2870], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 17 - 341: dog - cat || Loss: 1.025636911392212\n",
      "tensor([0., 1.]) tensor([0.7124, 0.2876], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 17 - 342: dog - cat || Loss: 1.0249732732772827\n",
      "tensor([0., 1.]) tensor([0.7117, 0.2883], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 17 - 343: dog - cat || Loss: 1.0243089199066162\n",
      "tensor([0., 1.]) tensor([0.7110, 0.2890], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 17 - 344: dog - cat || Loss: 1.0236436128616333\n",
      "tensor([0., 1.]) tensor([0.7104, 0.2896], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 17 - 345: dog - cat || Loss: 1.022977590560913\n",
      "tensor([0., 1.]) tensor([0.7097, 0.2903], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 17 - 346: dog - cat || Loss: 1.0223108530044556\n",
      "tensor([0., 1.]) tensor([0.7090, 0.2910], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 17 - 347: dog - cat || Loss: 1.0216432809829712\n",
      "tensor([0., 1.]) tensor([0.7084, 0.2916], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 17 - 348: dog - cat || Loss: 1.02097487449646\n",
      "tensor([0., 1.]) tensor([0.7077, 0.2923], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 17 - 349: dog - cat || Loss: 1.0203057527542114\n",
      "tensor([0., 1.]) tensor([0.7070, 0.2930], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 17 - 350: dog - cat || Loss: 1.0196360349655151\n",
      "tensor([0., 1.]) tensor([0.7064, 0.2936], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 17 - 351: dog - cat || Loss: 1.018965482711792\n",
      "tensor([0., 1.]) tensor([0.7057, 0.2943], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 17 - 352: dog - cat || Loss: 1.0182939767837524\n",
      "tensor([0., 1.]) tensor([0.7050, 0.2950], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 17 - 353: dog - cat || Loss: 1.0176218748092651\n",
      "tensor([0., 1.]) tensor([0.7044, 0.2956], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 17 - 354: dog - cat || Loss: 1.016948938369751\n",
      "tensor([0., 1.]) tensor([0.7037, 0.2963], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 17 - 355: dog - cat || Loss: 1.0162752866744995\n",
      "tensor([0., 1.]) tensor([0.7030, 0.2970], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 17 - 356: dog - cat || Loss: 1.0156009197235107\n",
      "tensor([0., 1.]) tensor([0.7023, 0.2977], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 17 - 357: dog - cat || Loss: 1.0149255990982056\n",
      "tensor([0., 1.]) tensor([0.7017, 0.2983], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 17 - 358: dog - cat || Loss: 1.014249563217163\n",
      "tensor([0., 1.]) tensor([0.7010, 0.2990], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 17 - 359: dog - cat || Loss: 1.0135729312896729\n",
      "tensor([0., 1.]) tensor([0.7003, 0.2997], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 17 - 360: dog - cat || Loss: 1.0128954648971558\n",
      "tensor([0., 1.]) tensor([0.6996, 0.3004], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 17 - 361: dog - cat || Loss: 1.0122171640396118\n",
      "tensor([0., 1.]) tensor([0.6990, 0.3010], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 17 - 362: dog - cat || Loss: 1.0115382671356201\n",
      "tensor([0., 1.]) tensor([0.6983, 0.3017], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 17 - 363: dog - cat || Loss: 1.010858416557312\n",
      "tensor([0., 1.]) tensor([0.6976, 0.3024], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 17 - 364: dog - cat || Loss: 1.0101779699325562\n",
      "tensor([0., 1.]) tensor([0.6969, 0.3031], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 17 - 365: dog - cat || Loss: 1.009496808052063\n",
      "tensor([0., 1.]) tensor([0.6962, 0.3038], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 17 - 366: dog - cat || Loss: 1.0088149309158325\n",
      "tensor([0., 1.]) tensor([0.6956, 0.3044], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 17 - 367: dog - cat || Loss: 1.0081322193145752\n",
      "tensor([0., 1.]) tensor([0.6949, 0.3051], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 17 - 368: dog - cat || Loss: 1.0074487924575806\n",
      "tensor([0., 1.]) tensor([0.6942, 0.3058], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 17 - 369: dog - cat || Loss: 1.006764531135559\n",
      "tensor([0., 1.]) tensor([0.6935, 0.3065], grad_fn=<SoftmaxBackward0>)\n",
      "=====epoch:18=====\n",
      "Epoch 18 - 0: cat - cat || Loss: 0.6204437017440796\n",
      "tensor([1., 0.]) tensor([0.6928, 0.3072], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 18 - 1: cat - cat || Loss: 0.6209914684295654\n",
      "tensor([1., 0.]) tensor([0.6923, 0.3077], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 18 - 2: cat - cat || Loss: 0.6214157938957214\n",
      "tensor([1., 0.]) tensor([0.6918, 0.3082], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 18 - 3: cat - cat || Loss: 0.6217285394668579\n",
      "tensor([1., 0.]) tensor([0.6915, 0.3085], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 18 - 4: cat - cat || Loss: 0.6219411492347717\n",
      "tensor([1., 0.]) tensor([0.6913, 0.3087], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 18 - 5: cat - cat || Loss: 0.6220634579658508\n",
      "tensor([1., 0.]) tensor([0.6912, 0.3088], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 18 - 6: cat - cat || Loss: 0.6221045255661011\n",
      "tensor([1., 0.]) tensor([0.6912, 0.3088], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 18 - 7: cat - cat || Loss: 0.6220722794532776\n",
      "tensor([1., 0.]) tensor([0.6912, 0.3088], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 18 - 8: cat - cat || Loss: 0.6219743490219116\n",
      "tensor([1., 0.]) tensor([0.6913, 0.3087], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 18 - 9: cat - cat || Loss: 0.6218171119689941\n",
      "tensor([1., 0.]) tensor([0.6914, 0.3086], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 18 - 10: cat - cat || Loss: 0.6216065883636475\n",
      "tensor([1., 0.]) tensor([0.6917, 0.3083], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 18 - 11: cat - cat || Loss: 0.6213482618331909\n",
      "tensor([1., 0.]) tensor([0.6919, 0.3081], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 18 - 12: cat - cat || Loss: 0.6210469007492065\n",
      "tensor([1., 0.]) tensor([0.6922, 0.3078], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 18 - 13: cat - cat || Loss: 0.6207067966461182\n",
      "tensor([1., 0.]) tensor([0.6926, 0.3074], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 18 - 14: cat - cat || Loss: 0.620331883430481\n",
      "tensor([1., 0.]) tensor([0.6929, 0.3071], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 18 - 15: cat - cat || Loss: 0.6199257373809814\n",
      "tensor([1., 0.]) tensor([0.6933, 0.3067], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 18 - 16: cat - cat || Loss: 0.6194916367530823\n",
      "tensor([1., 0.]) tensor([0.6938, 0.3062], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 18 - 17: cat - cat || Loss: 0.6190321445465088\n",
      "tensor([1., 0.]) tensor([0.6942, 0.3058], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 18 - 18: cat - cat || Loss: 0.6185502409934998\n",
      "tensor([1., 0.]) tensor([0.6947, 0.3053], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 18 - 19: cat - cat || Loss: 0.6180480718612671\n",
      "tensor([1., 0.]) tensor([0.6952, 0.3048], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 18 - 20: cat - cat || Loss: 0.6175274848937988\n",
      "tensor([1., 0.]) tensor([0.6957, 0.3043], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 18 - 21: cat - cat || Loss: 0.6169908046722412\n",
      "tensor([1., 0.]) tensor([0.6963, 0.3037], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 18 - 22: cat - cat || Loss: 0.6164394617080688\n",
      "tensor([1., 0.]) tensor([0.6968, 0.3032], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 18 - 23: cat - cat || Loss: 0.6158751249313354\n",
      "tensor([1., 0.]) tensor([0.6974, 0.3026], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 18 - 24: cat - cat || Loss: 0.6152991056442261\n",
      "tensor([1., 0.]) tensor([0.6980, 0.3020], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 18 - 25: cat - cat || Loss: 0.6147127747535706\n",
      "tensor([1., 0.]) tensor([0.6985, 0.3015], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 18 - 26: cat - cat || Loss: 0.6141172647476196\n",
      "tensor([1., 0.]) tensor([0.6991, 0.3009], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 18 - 27: cat - cat || Loss: 0.6135132908821106\n",
      "tensor([1., 0.]) tensor([0.6997, 0.3003], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 18 - 28: cat - cat || Loss: 0.6129019856452942\n",
      "tensor([1., 0.]) tensor([0.7004, 0.2996], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 18 - 29: cat - cat || Loss: 0.6122840642929077\n",
      "tensor([1., 0.]) tensor([0.7010, 0.2990], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 18 - 30: cat - cat || Loss: 0.6116602420806885\n",
      "tensor([1., 0.]) tensor([0.7016, 0.2984], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 18 - 31: cat - cat || Loss: 0.6110314130783081\n",
      "tensor([1., 0.]) tensor([0.7022, 0.2978], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 18 - 32: cat - cat || Loss: 0.6103978753089905\n",
      "tensor([1., 0.]) tensor([0.7029, 0.2971], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 18 - 33: cat - cat || Loss: 0.6097604036331177\n",
      "tensor([1., 0.]) tensor([0.7035, 0.2965], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 18 - 34: cat - cat || Loss: 0.6091193556785583\n",
      "tensor([1., 0.]) tensor([0.7041, 0.2959], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 18 - 35: cat - cat || Loss: 0.6084752082824707\n",
      "tensor([1., 0.]) tensor([0.7048, 0.2952], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 18 - 36: cat - cat || Loss: 0.6078283786773682\n",
      "tensor([1., 0.]) tensor([0.7054, 0.2946], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 18 - 37: cat - cat || Loss: 0.6071790456771851\n",
      "tensor([1., 0.]) tensor([0.7061, 0.2939], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 18 - 38: cat - cat || Loss: 0.6065278053283691\n",
      "tensor([1., 0.]) tensor([0.7067, 0.2933], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 18 - 39: cat - cat || Loss: 0.6058745980262756\n",
      "tensor([1., 0.]) tensor([0.7074, 0.2926], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 18 - 40: cat - cat || Loss: 0.6052200794219971\n",
      "tensor([1., 0.]) tensor([0.7080, 0.2920], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 18 - 41: cat - cat || Loss: 0.6045641899108887\n",
      "tensor([1., 0.]) tensor([0.7087, 0.2913], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 18 - 42: cat - cat || Loss: 0.6039072275161743\n",
      "tensor([1., 0.]) tensor([0.7094, 0.2906], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 18 - 43: cat - cat || Loss: 0.6032493114471436\n",
      "tensor([1., 0.]) tensor([0.7100, 0.2900], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 18 - 44: cat - cat || Loss: 0.602590799331665\n",
      "tensor([1., 0.]) tensor([0.7107, 0.2893], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 18 - 45: cat - cat || Loss: 0.6019315719604492\n",
      "tensor([1., 0.]) tensor([0.7113, 0.2887], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 18 - 46: cat - cat || Loss: 0.6012719869613647\n",
      "tensor([1., 0.]) tensor([0.7120, 0.2880], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 18 - 47: cat - cat || Loss: 0.6006121635437012\n",
      "tensor([1., 0.]) tensor([0.7126, 0.2874], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 18 - 48: cat - cat || Loss: 0.5999521017074585\n",
      "tensor([1., 0.]) tensor([0.7133, 0.2867], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 18 - 49: cat - cat || Loss: 0.599291980266571\n",
      "tensor([1., 0.]) tensor([0.7140, 0.2860], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 18 - 50: cat - cat || Loss: 0.5986318588256836\n",
      "tensor([1., 0.]) tensor([0.7146, 0.2854], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 18 - 51: cat - cat || Loss: 0.5979719161987305\n",
      "tensor([1., 0.]) tensor([0.7153, 0.2847], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 18 - 52: cat - cat || Loss: 0.5973120331764221\n",
      "tensor([1., 0.]) tensor([0.7159, 0.2841], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 18 - 53: cat - cat || Loss: 0.5966523885726929\n",
      "tensor([1., 0.]) tensor([0.7166, 0.2834], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 18 - 54: cat - cat || Loss: 0.5959931015968323\n",
      "tensor([1., 0.]) tensor([0.7173, 0.2827], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 18 - 55: cat - cat || Loss: 0.5953341722488403\n",
      "tensor([1., 0.]) tensor([0.7179, 0.2821], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 18 - 56: cat - cat || Loss: 0.5946755409240723\n",
      "tensor([1., 0.]) tensor([0.7186, 0.2814], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 18 - 57: cat - cat || Loss: 0.5940173864364624\n",
      "tensor([1., 0.]) tensor([0.7192, 0.2808], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 18 - 58: cat - cat || Loss: 0.5933597683906555\n",
      "tensor([1., 0.]) tensor([0.7199, 0.2801], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 18 - 59: cat - cat || Loss: 0.5927025675773621\n",
      "tensor([1., 0.]) tensor([0.7206, 0.2794], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 18 - 60: cat - cat || Loss: 0.5920460224151611\n",
      "tensor([1., 0.]) tensor([0.7212, 0.2788], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 18 - 61: cat - cat || Loss: 0.5913898944854736\n",
      "tensor([1., 0.]) tensor([0.7219, 0.2781], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 18 - 62: cat - cat || Loss: 0.5907344818115234\n",
      "tensor([1., 0.]) tensor([0.7225, 0.2775], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 18 - 63: cat - cat || Loss: 0.5900797843933105\n",
      "tensor([1., 0.]) tensor([0.7232, 0.2768], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 18 - 64: cat - cat || Loss: 0.5894255638122559\n",
      "tensor([1., 0.]) tensor([0.7238, 0.2762], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 18 - 65: cat - cat || Loss: 0.5887721180915833\n",
      "tensor([1., 0.]) tensor([0.7245, 0.2755], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 18 - 66: cat - cat || Loss: 0.5881193280220032\n",
      "tensor([1., 0.]) tensor([0.7251, 0.2749], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 18 - 67: cat - cat || Loss: 0.5874673128128052\n",
      "tensor([1., 0.]) tensor([0.7258, 0.2742], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 18 - 68: cat - cat || Loss: 0.5868158936500549\n",
      "tensor([1., 0.]) tensor([0.7264, 0.2736], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 18 - 69: cat - cat || Loss: 0.5861653089523315\n",
      "tensor([1., 0.]) tensor([0.7271, 0.2729], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 18 - 70: cat - cat || Loss: 0.5855153799057007\n",
      "tensor([1., 0.]) tensor([0.7277, 0.2723], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 18 - 71: cat - cat || Loss: 0.5848663449287415\n",
      "tensor([1., 0.]) tensor([0.7284, 0.2716], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 18 - 72: cat - cat || Loss: 0.5842180252075195\n",
      "tensor([1., 0.]) tensor([0.7290, 0.2710], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 18 - 73: cat - cat || Loss: 0.5835704803466797\n",
      "tensor([1., 0.]) tensor([0.7297, 0.2703], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 18 - 74: cat - cat || Loss: 0.5829237103462219\n",
      "tensor([1., 0.]) tensor([0.7303, 0.2697], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 18 - 75: cat - cat || Loss: 0.582277774810791\n",
      "tensor([1., 0.]) tensor([0.7310, 0.2690], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 18 - 76: cat - cat || Loss: 0.5816326141357422\n",
      "tensor([1., 0.]) tensor([0.7316, 0.2684], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 18 - 77: cat - cat || Loss: 0.5809882879257202\n",
      "tensor([1., 0.]) tensor([0.7323, 0.2677], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 18 - 78: cat - cat || Loss: 0.5803447365760803\n",
      "tensor([1., 0.]) tensor([0.7329, 0.2671], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 18 - 79: cat - cat || Loss: 0.5797020792961121\n",
      "tensor([1., 0.]) tensor([0.7336, 0.2664], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 18 - 80: cat - cat || Loss: 0.5790603160858154\n",
      "tensor([1., 0.]) tensor([0.7342, 0.2658], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 18 - 81: cat - cat || Loss: 0.5784193277359009\n",
      "tensor([1., 0.]) tensor([0.7348, 0.2652], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 18 - 82: cat - cat || Loss: 0.5777791738510132\n",
      "tensor([1., 0.]) tensor([0.7355, 0.2645], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 18 - 83: cat - cat || Loss: 0.5771399140357971\n",
      "tensor([1., 0.]) tensor([0.7361, 0.2639], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 18 - 84: cat - cat || Loss: 0.5765014886856079\n",
      "tensor([1., 0.]) tensor([0.7368, 0.2632], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 18 - 85: cat - cat || Loss: 0.5758638978004456\n",
      "tensor([1., 0.]) tensor([0.7374, 0.2626], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 18 - 86: cat - cat || Loss: 0.5752273201942444\n",
      "tensor([1., 0.]) tensor([0.7380, 0.2620], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 18 - 87: cat - cat || Loss: 0.5745915770530701\n",
      "tensor([1., 0.]) tensor([0.7387, 0.2613], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 18 - 88: cat - cat || Loss: 0.5739566087722778\n",
      "tensor([1., 0.]) tensor([0.7393, 0.2607], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 18 - 89: cat - cat || Loss: 0.5733226537704468\n",
      "tensor([1., 0.]) tensor([0.7399, 0.2601], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 18 - 90: cat - cat || Loss: 0.5726894736289978\n",
      "tensor([1., 0.]) tensor([0.7406, 0.2594], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 18 - 91: cat - cat || Loss: 0.5720571279525757\n",
      "tensor([1., 0.]) tensor([0.7412, 0.2588], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 18 - 92: cat - cat || Loss: 0.5714257955551147\n",
      "tensor([1., 0.]) tensor([0.7418, 0.2582], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 18 - 93: cat - cat || Loss: 0.5707952380180359\n",
      "tensor([1., 0.]) tensor([0.7425, 0.2575], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 18 - 94: cat - cat || Loss: 0.5701655149459839\n",
      "tensor([1., 0.]) tensor([0.7431, 0.2569], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 18 - 95: cat - cat || Loss: 0.5695368051528931\n",
      "tensor([1., 0.]) tensor([0.7437, 0.2563], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 18 - 96: cat - cat || Loss: 0.5689088702201843\n",
      "tensor([1., 0.]) tensor([0.7444, 0.2556], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 18 - 97: cat - cat || Loss: 0.5682819485664368\n",
      "tensor([1., 0.]) tensor([0.7450, 0.2550], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 18 - 98: cat - cat || Loss: 0.5676557421684265\n",
      "tensor([1., 0.]) tensor([0.7456, 0.2544], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 18 - 99: cat - cat || Loss: 0.567030668258667\n",
      "tensor([1., 0.]) tensor([0.7462, 0.2538], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 18 - 100: cat - cat || Loss: 0.56640625\n",
      "tensor([1., 0.]) tensor([0.7469, 0.2531], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 18 - 101: cat - cat || Loss: 0.5657830238342285\n",
      "tensor([1., 0.]) tensor([0.7475, 0.2525], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 18 - 102: cat - cat || Loss: 0.5651605725288391\n",
      "tensor([1., 0.]) tensor([0.7481, 0.2519], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 18 - 103: cat - cat || Loss: 0.5645390152931213\n",
      "tensor([1., 0.]) tensor([0.7487, 0.2513], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 18 - 104: cat - cat || Loss: 0.5639183521270752\n",
      "tensor([1., 0.]) tensor([0.7493, 0.2507], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 18 - 105: cat - cat || Loss: 0.563298761844635\n",
      "tensor([1., 0.]) tensor([0.7500, 0.2500], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 18 - 106: cat - cat || Loss: 0.5626798868179321\n",
      "tensor([1., 0.]) tensor([0.7506, 0.2494], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 18 - 107: cat - cat || Loss: 0.5620619654655457\n",
      "tensor([1., 0.]) tensor([0.7512, 0.2488], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 18 - 108: cat - cat || Loss: 0.5614450573921204\n",
      "tensor([1., 0.]) tensor([0.7518, 0.2482], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 18 - 109: cat - cat || Loss: 0.5608289241790771\n",
      "tensor([1., 0.]) tensor([0.7524, 0.2476], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 18 - 110: cat - cat || Loss: 0.5602136254310608\n",
      "tensor([1., 0.]) tensor([0.7530, 0.2470], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 18 - 111: cat - cat || Loss: 0.5595995187759399\n",
      "tensor([1., 0.]) tensor([0.7537, 0.2463], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 18 - 112: cat - cat || Loss: 0.5589860677719116\n",
      "tensor([1., 0.]) tensor([0.7543, 0.2457], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 18 - 113: cat - cat || Loss: 0.5583735704421997\n",
      "tensor([1., 0.]) tensor([0.7549, 0.2451], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 18 - 114: cat - cat || Loss: 0.5577621459960938\n",
      "tensor([1., 0.]) tensor([0.7555, 0.2445], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 18 - 115: cat - cat || Loss: 0.5571515560150146\n",
      "tensor([1., 0.]) tensor([0.7561, 0.2439], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 18 - 116: cat - cat || Loss: 0.556541919708252\n",
      "tensor([1., 0.]) tensor([0.7567, 0.2433], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 18 - 117: cat - cat || Loss: 0.5559331178665161\n",
      "tensor([1., 0.]) tensor([0.7573, 0.2427], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 18 - 118: cat - cat || Loss: 0.5553253293037415\n",
      "tensor([1., 0.]) tensor([0.7579, 0.2421], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 18 - 119: cat - cat || Loss: 0.5547184944152832\n",
      "tensor([1., 0.]) tensor([0.7585, 0.2415], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 18 - 120: cat - cat || Loss: 0.5541124939918518\n",
      "tensor([1., 0.]) tensor([0.7591, 0.2409], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 18 - 121: cat - cat || Loss: 0.553507387638092\n",
      "tensor([1., 0.]) tensor([0.7598, 0.2402], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 18 - 122: cat - cat || Loss: 0.5529032945632935\n",
      "tensor([1., 0.]) tensor([0.7604, 0.2396], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 18 - 123: cat - cat || Loss: 0.552300214767456\n",
      "tensor([1., 0.]) tensor([0.7610, 0.2390], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 18 - 124: cat - cat || Loss: 0.5516979694366455\n",
      "tensor([1., 0.]) tensor([0.7616, 0.2384], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 18 - 125: cat - cat || Loss: 0.5510966777801514\n",
      "tensor([1., 0.]) tensor([0.7622, 0.2378], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 18 - 126: cat - cat || Loss: 0.5504963397979736\n",
      "tensor([1., 0.]) tensor([0.7628, 0.2372], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 18 - 127: cat - cat || Loss: 0.5498969554901123\n",
      "tensor([1., 0.]) tensor([0.7634, 0.2366], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 18 - 128: cat - cat || Loss: 0.5492984652519226\n",
      "tensor([1., 0.]) tensor([0.7640, 0.2360], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 18 - 129: cat - cat || Loss: 0.5487009286880493\n",
      "tensor([1., 0.]) tensor([0.7646, 0.2354], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 18 - 130: cat - cat || Loss: 0.5481044054031372\n",
      "tensor([1., 0.]) tensor([0.7652, 0.2348], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 18 - 131: cat - cat || Loss: 0.547508716583252\n",
      "tensor([1., 0.]) tensor([0.7658, 0.2342], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 18 - 132: cat - cat || Loss: 0.5469139814376831\n",
      "tensor([1., 0.]) tensor([0.7663, 0.2337], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 18 - 133: cat - cat || Loss: 0.5463203191757202\n",
      "tensor([1., 0.]) tensor([0.7669, 0.2331], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 18 - 134: cat - cat || Loss: 0.5457274913787842\n",
      "tensor([1., 0.]) tensor([0.7675, 0.2325], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 18 - 135: cat - cat || Loss: 0.5451357364654541\n",
      "tensor([1., 0.]) tensor([0.7681, 0.2319], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 18 - 136: cat - cat || Loss: 0.5445448160171509\n",
      "tensor([1., 0.]) tensor([0.7687, 0.2313], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 18 - 137: cat - cat || Loss: 0.5439547896385193\n",
      "tensor([1., 0.]) tensor([0.7693, 0.2307], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 18 - 138: cat - cat || Loss: 0.5433658361434937\n",
      "tensor([1., 0.]) tensor([0.7699, 0.2301], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 18 - 139: cat - cat || Loss: 0.5427778363227844\n",
      "tensor([1., 0.]) tensor([0.7705, 0.2295], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 18 - 140: cat - cat || Loss: 0.5421907305717468\n",
      "tensor([1., 0.]) tensor([0.7711, 0.2289], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 18 - 141: cat - cat || Loss: 0.5416046380996704\n",
      "tensor([1., 0.]) tensor([0.7717, 0.2283], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 18 - 142: cat - cat || Loss: 0.5410195589065552\n",
      "tensor([1., 0.]) tensor([0.7722, 0.2278], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 18 - 143: cat - cat || Loss: 0.5404353141784668\n",
      "tensor([1., 0.]) tensor([0.7728, 0.2272], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 18 - 144: cat - cat || Loss: 0.5398521423339844\n",
      "tensor([1., 0.]) tensor([0.7734, 0.2266], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 18 - 145: cat - cat || Loss: 0.5392698049545288\n",
      "tensor([1., 0.]) tensor([0.7740, 0.2260], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 18 - 146: cat - cat || Loss: 0.5386885404586792\n",
      "tensor([1., 0.]) tensor([0.7746, 0.2254], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 18 - 147: cat - cat || Loss: 0.5381081700325012\n",
      "tensor([1., 0.]) tensor([0.7752, 0.2248], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 18 - 148: cat - cat || Loss: 0.5375287532806396\n",
      "tensor([1., 0.]) tensor([0.7757, 0.2243], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 18 - 149: cat - cat || Loss: 0.5369502902030945\n",
      "tensor([1., 0.]) tensor([0.7763, 0.2237], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 18 - 150: cat - cat || Loss: 0.5363727807998657\n",
      "tensor([1., 0.]) tensor([0.7769, 0.2231], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 18 - 151: cat - cat || Loss: 0.5357962846755981\n",
      "tensor([1., 0.]) tensor([0.7775, 0.2225], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 18 - 152: cat - cat || Loss: 0.5352208018302917\n",
      "tensor([1., 0.]) tensor([0.7780, 0.2220], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 18 - 153: cat - cat || Loss: 0.5346460938453674\n",
      "tensor([1., 0.]) tensor([0.7786, 0.2214], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 18 - 154: cat - cat || Loss: 0.5340724587440491\n",
      "tensor([1., 0.]) tensor([0.7792, 0.2208], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 18 - 155: cat - cat || Loss: 0.5334997773170471\n",
      "tensor([1., 0.]) tensor([0.7798, 0.2202], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 18 - 156: cat - cat || Loss: 0.5329281091690063\n",
      "tensor([1., 0.]) tensor([0.7803, 0.2197], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 18 - 157: cat - cat || Loss: 0.5323574542999268\n",
      "tensor([1., 0.]) tensor([0.7809, 0.2191], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 18 - 158: cat - cat || Loss: 0.531787633895874\n",
      "tensor([1., 0.]) tensor([0.7815, 0.2185], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 18 - 159: cat - cat || Loss: 0.5312188267707825\n",
      "tensor([1., 0.]) tensor([0.7820, 0.2180], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 18 - 160: cat - cat || Loss: 0.5306510329246521\n",
      "tensor([1., 0.]) tensor([0.7826, 0.2174], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 18 - 161: cat - cat || Loss: 0.5300841927528381\n",
      "tensor([1., 0.]) tensor([0.7832, 0.2168], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 18 - 162: cat - cat || Loss: 0.5295184254646301\n",
      "tensor([1., 0.]) tensor([0.7837, 0.2163], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 18 - 163: cat - cat || Loss: 0.5289535522460938\n",
      "tensor([1., 0.]) tensor([0.7843, 0.2157], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 18 - 164: cat - cat || Loss: 0.528389573097229\n",
      "tensor([1., 0.]) tensor([0.7849, 0.2151], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 18 - 165: cat - cat || Loss: 0.5278266072273254\n",
      "tensor([1., 0.]) tensor([0.7854, 0.2146], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 18 - 166: cat - cat || Loss: 0.5272645950317383\n",
      "tensor([1., 0.]) tensor([0.7860, 0.2140], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 18 - 167: cat - cat || Loss: 0.5267035961151123\n",
      "tensor([1., 0.]) tensor([0.7866, 0.2134], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 18 - 168: cat - cat || Loss: 0.526143491268158\n",
      "tensor([1., 0.]) tensor([0.7871, 0.2129], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 18 - 169: cat - cat || Loss: 0.52558434009552\n",
      "tensor([1., 0.]) tensor([0.7877, 0.2123], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 18 - 170: cat - cat || Loss: 0.5250263214111328\n",
      "tensor([1., 0.]) tensor([0.7882, 0.2118], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 18 - 171: cat - cat || Loss: 0.5244691967964172\n",
      "tensor([1., 0.]) tensor([0.7888, 0.2112], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 18 - 172: cat - cat || Loss: 0.5239131450653076\n",
      "tensor([1., 0.]) tensor([0.7893, 0.2107], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 18 - 173: cat - cat || Loss: 0.5233579277992249\n",
      "tensor([1., 0.]) tensor([0.7899, 0.2101], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 18 - 174: cat - cat || Loss: 0.522803783416748\n",
      "tensor([1., 0.]) tensor([0.7905, 0.2095], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 18 - 175: cat - cat || Loss: 0.5222505927085876\n",
      "tensor([1., 0.]) tensor([0.7910, 0.2090], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 18 - 176: cat - cat || Loss: 0.5216983556747437\n",
      "tensor([1., 0.]) tensor([0.7916, 0.2084], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 18 - 177: cat - cat || Loss: 0.5211472511291504\n",
      "tensor([1., 0.]) tensor([0.7921, 0.2079], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 18 - 178: cat - cat || Loss: 0.5205971002578735\n",
      "tensor([1., 0.]) tensor([0.7927, 0.2073], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 18 - 179: cat - cat || Loss: 0.5200478434562683\n",
      "tensor([1., 0.]) tensor([0.7932, 0.2068], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 18 - 180: cat - cat || Loss: 0.5194994807243347\n",
      "tensor([1., 0.]) tensor([0.7938, 0.2062], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 18 - 181: cat - cat || Loss: 0.5189522504806519\n",
      "tensor([1., 0.]) tensor([0.7943, 0.2057], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 18 - 182: cat - cat || Loss: 0.5184059739112854\n",
      "tensor([1., 0.]) tensor([0.7949, 0.2051], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 18 - 183: cat - cat || Loss: 0.5178607106208801\n",
      "tensor([1., 0.]) tensor([0.7954, 0.2046], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 18 - 184: cat - cat || Loss: 0.5173164010047913\n",
      "tensor([1., 0.]) tensor([0.7959, 0.2041], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 18 - 185: cat - cat || Loss: 0.5167731642723083\n",
      "tensor([1., 0.]) tensor([0.7965, 0.2035], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 18 - 186: cat - cat || Loss: 0.5162306427955627\n",
      "tensor([1., 0.]) tensor([0.7970, 0.2030], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 18 - 187: cat - cat || Loss: 0.5156894326210022\n",
      "tensor([1., 0.]) tensor([0.7976, 0.2024], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 18 - 188: cat - cat || Loss: 0.5151489973068237\n",
      "tensor([1., 0.]) tensor([0.7981, 0.2019], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 18 - 189: cat - cat || Loss: 0.514609694480896\n",
      "tensor([1., 0.]) tensor([0.7987, 0.2013], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 18 - 190: dog - cat || Loss: 1.1124520301818848\n",
      "tensor([0., 1.]) tensor([0.7992, 0.2008], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 18 - 191: dog - cat || Loss: 1.1128828525543213\n",
      "tensor([0., 1.]) tensor([0.7996, 0.2004], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 18 - 192: dog - cat || Loss: 1.1132171154022217\n",
      "tensor([0., 1.]) tensor([0.8000, 0.2000], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 18 - 193: dog - cat || Loss: 1.113464593887329\n",
      "tensor([0., 1.]) tensor([0.8002, 0.1998], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 18 - 194: dog - cat || Loss: 1.1136339902877808\n",
      "tensor([0., 1.]) tensor([0.8004, 0.1996], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 18 - 195: dog - cat || Loss: 1.1137334108352661\n",
      "tensor([0., 1.]) tensor([0.8005, 0.1995], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 18 - 196: dog - cat || Loss: 1.113769769668579\n",
      "tensor([0., 1.]) tensor([0.8005, 0.1995], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 18 - 197: dog - cat || Loss: 1.1137492656707764\n",
      "tensor([0., 1.]) tensor([0.8005, 0.1995], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 18 - 198: dog - cat || Loss: 1.113677740097046\n",
      "tensor([0., 1.]) tensor([0.8004, 0.1996], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 18 - 199: dog - cat || Loss: 1.113560438156128\n",
      "tensor([0., 1.]) tensor([0.8003, 0.1997], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 18 - 200: dog - cat || Loss: 1.1134014129638672\n",
      "tensor([0., 1.]) tensor([0.8001, 0.1999], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 18 - 201: dog - cat || Loss: 1.1132051944732666\n",
      "tensor([0., 1.]) tensor([0.7999, 0.2001], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 18 - 202: dog - cat || Loss: 1.1129754781723022\n",
      "tensor([0., 1.]) tensor([0.7997, 0.2003], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 18 - 203: dog - cat || Loss: 1.112715244293213\n",
      "tensor([0., 1.]) tensor([0.7995, 0.2005], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 18 - 204: dog - cat || Loss: 1.1124275922775269\n",
      "tensor([0., 1.]) tensor([0.7992, 0.2008], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 18 - 205: dog - cat || Loss: 1.1121151447296143\n",
      "tensor([0., 1.]) tensor([0.7989, 0.2011], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 18 - 206: dog - cat || Loss: 1.1117806434631348\n",
      "tensor([0., 1.]) tensor([0.7985, 0.2015], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 18 - 207: dog - cat || Loss: 1.1114259958267212\n",
      "tensor([0., 1.]) tensor([0.7982, 0.2018], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 18 - 208: dog - cat || Loss: 1.1110528707504272\n",
      "tensor([0., 1.]) tensor([0.7978, 0.2022], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 18 - 209: dog - cat || Loss: 1.1106634140014648\n",
      "tensor([0., 1.]) tensor([0.7974, 0.2026], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 18 - 210: dog - cat || Loss: 1.110258936882019\n",
      "tensor([0., 1.]) tensor([0.7970, 0.2030], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 18 - 211: dog - cat || Loss: 1.109840989112854\n",
      "tensor([0., 1.]) tensor([0.7966, 0.2034], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 18 - 212: dog - cat || Loss: 1.1094105243682861\n",
      "tensor([0., 1.]) tensor([0.7961, 0.2039], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 18 - 213: dog - cat || Loss: 1.1089692115783691\n",
      "tensor([0., 1.]) tensor([0.7957, 0.2043], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 18 - 214: dog - cat || Loss: 1.1085176467895508\n",
      "tensor([0., 1.]) tensor([0.7953, 0.2047], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 18 - 215: dog - cat || Loss: 1.108056902885437\n",
      "tensor([0., 1.]) tensor([0.7948, 0.2052], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 18 - 216: dog - cat || Loss: 1.1075878143310547\n",
      "tensor([0., 1.]) tensor([0.7943, 0.2057], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 18 - 217: dog - cat || Loss: 1.1071110963821411\n",
      "tensor([0., 1.]) tensor([0.7938, 0.2062], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 18 - 218: dog - cat || Loss: 1.106627345085144\n",
      "tensor([0., 1.]) tensor([0.7934, 0.2066], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 18 - 219: dog - cat || Loss: 1.1061375141143799\n",
      "tensor([0., 1.]) tensor([0.7929, 0.2071], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 18 - 220: dog - cat || Loss: 1.1056416034698486\n",
      "tensor([0., 1.]) tensor([0.7924, 0.2076], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 18 - 221: dog - cat || Loss: 1.1051404476165771\n",
      "tensor([0., 1.]) tensor([0.7919, 0.2081], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 18 - 222: dog - cat || Loss: 1.104634404182434\n",
      "tensor([0., 1.]) tensor([0.7914, 0.2086], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 18 - 223: dog - cat || Loss: 1.1041239500045776\n",
      "tensor([0., 1.]) tensor([0.7909, 0.2091], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 18 - 224: dog - cat || Loss: 1.1036092042922974\n",
      "tensor([0., 1.]) tensor([0.7903, 0.2097], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 18 - 225: dog - cat || Loss: 1.1030906438827515\n",
      "tensor([0., 1.]) tensor([0.7898, 0.2102], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 18 - 226: dog - cat || Loss: 1.1025686264038086\n",
      "tensor([0., 1.]) tensor([0.7893, 0.2107], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 18 - 227: dog - cat || Loss: 1.1020433902740479\n",
      "tensor([0., 1.]) tensor([0.7888, 0.2112], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 18 - 228: dog - cat || Loss: 1.1015150547027588\n",
      "tensor([0., 1.]) tensor([0.7883, 0.2117], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 18 - 229: dog - cat || Loss: 1.10098397731781\n",
      "tensor([0., 1.]) tensor([0.7877, 0.2123], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 18 - 230: dog - cat || Loss: 1.100450038909912\n",
      "tensor([0., 1.]) tensor([0.7872, 0.2128], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 18 - 231: dog - cat || Loss: 1.0999139547348022\n",
      "tensor([0., 1.]) tensor([0.7867, 0.2133], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 18 - 232: dog - cat || Loss: 1.0993753671646118\n",
      "tensor([0., 1.]) tensor([0.7861, 0.2139], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 18 - 233: dog - cat || Loss: 1.098834753036499\n",
      "tensor([0., 1.]) tensor([0.7856, 0.2144], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 18 - 234: dog - cat || Loss: 1.0982919931411743\n",
      "tensor([0., 1.]) tensor([0.7850, 0.2150], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 18 - 235: dog - cat || Loss: 1.0977474451065063\n",
      "tensor([0., 1.]) tensor([0.7845, 0.2155], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 18 - 236: dog - cat || Loss: 1.097200870513916\n",
      "tensor([0., 1.]) tensor([0.7839, 0.2161], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 18 - 237: dog - cat || Loss: 1.096652626991272\n",
      "tensor([0., 1.]) tensor([0.7834, 0.2166], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 18 - 238: dog - cat || Loss: 1.0961028337478638\n",
      "tensor([0., 1.]) tensor([0.7828, 0.2172], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 18 - 239: dog - cat || Loss: 1.0955511331558228\n",
      "tensor([0., 1.]) tensor([0.7823, 0.2177], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 18 - 240: dog - cat || Loss: 1.0949981212615967\n",
      "tensor([0., 1.]) tensor([0.7817, 0.2183], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 18 - 241: dog - cat || Loss: 1.0944435596466064\n",
      "tensor([0., 1.]) tensor([0.7812, 0.2188], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 18 - 242: dog - cat || Loss: 1.0938878059387207\n",
      "tensor([0., 1.]) tensor([0.7806, 0.2194], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 18 - 243: dog - cat || Loss: 1.0933305025100708\n",
      "tensor([0., 1.]) tensor([0.7801, 0.2199], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 18 - 244: dog - cat || Loss: 1.0927718877792358\n",
      "tensor([0., 1.]) tensor([0.7795, 0.2205], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 18 - 245: dog - cat || Loss: 1.0922123193740845\n",
      "tensor([0., 1.]) tensor([0.7790, 0.2210], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 18 - 246: dog - cat || Loss: 1.0916510820388794\n",
      "tensor([0., 1.]) tensor([0.7784, 0.2216], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 18 - 247: dog - cat || Loss: 1.0910887718200684\n",
      "tensor([0., 1.]) tensor([0.7778, 0.2222], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 18 - 248: dog - cat || Loss: 1.0905253887176514\n",
      "tensor([0., 1.]) tensor([0.7773, 0.2227], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 18 - 249: dog - cat || Loss: 1.0899606943130493\n",
      "tensor([0., 1.]) tensor([0.7767, 0.2233], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 18 - 250: dog - cat || Loss: 1.0893951654434204\n",
      "tensor([0., 1.]) tensor([0.7761, 0.2239], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 18 - 251: dog - cat || Loss: 1.088828206062317\n",
      "tensor([0., 1.]) tensor([0.7756, 0.2244], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 18 - 252: dog - cat || Loss: 1.0882604122161865\n",
      "tensor([0., 1.]) tensor([0.7750, 0.2250], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 18 - 253: dog - cat || Loss: 1.0876911878585815\n",
      "tensor([0., 1.]) tensor([0.7744, 0.2256], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 18 - 254: dog - cat || Loss: 1.0871212482452393\n",
      "tensor([0., 1.]) tensor([0.7739, 0.2261], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 18 - 255: dog - cat || Loss: 1.086550235748291\n",
      "tensor([0., 1.]) tensor([0.7733, 0.2267], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 18 - 256: dog - cat || Loss: 1.0859780311584473\n",
      "tensor([0., 1.]) tensor([0.7727, 0.2273], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 18 - 257: dog - cat || Loss: 1.0854049921035767\n",
      "tensor([0., 1.]) tensor([0.7721, 0.2279], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 18 - 258: dog - cat || Loss: 1.0848308801651\n",
      "tensor([0., 1.]) tensor([0.7716, 0.2284], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 18 - 259: dog - cat || Loss: 1.0842558145523071\n",
      "tensor([0., 1.]) tensor([0.7710, 0.2290], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 18 - 260: dog - cat || Loss: 1.0836796760559082\n",
      "tensor([0., 1.]) tensor([0.7704, 0.2296], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 18 - 261: dog - cat || Loss: 1.0831027030944824\n",
      "tensor([0., 1.]) tensor([0.7698, 0.2302], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 18 - 262: dog - cat || Loss: 1.0825245380401611\n",
      "tensor([0., 1.]) tensor([0.7693, 0.2307], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 18 - 263: dog - cat || Loss: 1.0819456577301025\n",
      "tensor([0., 1.]) tensor([0.7687, 0.2313], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 18 - 264: dog - cat || Loss: 1.081365704536438\n",
      "tensor([0., 1.]) tensor([0.7681, 0.2319], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 18 - 265: dog - cat || Loss: 1.0807846784591675\n",
      "tensor([0., 1.]) tensor([0.7675, 0.2325], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 18 - 266: dog - cat || Loss: 1.0802030563354492\n",
      "tensor([0., 1.]) tensor([0.7669, 0.2331], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 18 - 267: dog - cat || Loss: 1.0796202421188354\n",
      "tensor([0., 1.]) tensor([0.7664, 0.2336], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 18 - 268: dog - cat || Loss: 1.0790364742279053\n",
      "tensor([0., 1.]) tensor([0.7658, 0.2342], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 18 - 269: dog - cat || Loss: 1.0784517526626587\n",
      "tensor([0., 1.]) tensor([0.7652, 0.2348], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 18 - 270: dog - cat || Loss: 1.0778661966323853\n",
      "tensor([0., 1.]) tensor([0.7646, 0.2354], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 18 - 271: dog - cat || Loss: 1.0772796869277954\n",
      "tensor([0., 1.]) tensor([0.7640, 0.2360], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 18 - 272: dog - cat || Loss: 1.0766923427581787\n",
      "tensor([0., 1.]) tensor([0.7634, 0.2366], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 18 - 273: dog - cat || Loss: 1.0761040449142456\n",
      "tensor([0., 1.]) tensor([0.7628, 0.2372], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 18 - 274: dog - cat || Loss: 1.0755146741867065\n",
      "tensor([0., 1.]) tensor([0.7623, 0.2377], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 18 - 275: dog - cat || Loss: 1.0749244689941406\n",
      "tensor([0., 1.]) tensor([0.7617, 0.2383], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 18 - 276: dog - cat || Loss: 1.0743334293365479\n",
      "tensor([0., 1.]) tensor([0.7611, 0.2389], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 18 - 277: dog - cat || Loss: 1.0737414360046387\n",
      "tensor([0., 1.]) tensor([0.7605, 0.2395], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 18 - 278: dog - cat || Loss: 1.0731486082077026\n",
      "tensor([0., 1.]) tensor([0.7599, 0.2401], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 18 - 279: dog - cat || Loss: 1.0725548267364502\n",
      "tensor([0., 1.]) tensor([0.7593, 0.2407], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 18 - 280: dog - cat || Loss: 1.0719600915908813\n",
      "tensor([0., 1.]) tensor([0.7587, 0.2413], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 18 - 281: dog - cat || Loss: 1.071364402770996\n",
      "tensor([0., 1.]) tensor([0.7581, 0.2419], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 18 - 282: dog - cat || Loss: 1.0707679986953735\n",
      "tensor([0., 1.]) tensor([0.7575, 0.2425], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 18 - 283: dog - cat || Loss: 1.070170521736145\n",
      "tensor([0., 1.]) tensor([0.7569, 0.2431], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 18 - 284: dog - cat || Loss: 1.0695723295211792\n",
      "tensor([0., 1.]) tensor([0.7563, 0.2437], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 18 - 285: dog - cat || Loss: 1.0689730644226074\n",
      "tensor([0., 1.]) tensor([0.7557, 0.2443], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 18 - 286: dog - cat || Loss: 1.0683729648590088\n",
      "tensor([0., 1.]) tensor([0.7551, 0.2449], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 18 - 287: dog - cat || Loss: 1.0677719116210938\n",
      "tensor([0., 1.]) tensor([0.7545, 0.2455], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 18 - 288: dog - cat || Loss: 1.0671700239181519\n",
      "tensor([0., 1.]) tensor([0.7539, 0.2461], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 18 - 289: dog - cat || Loss: 1.066567063331604\n",
      "tensor([0., 1.]) tensor([0.7533, 0.2467], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 18 - 290: dog - cat || Loss: 1.065963625907898\n",
      "tensor([0., 1.]) tensor([0.7527, 0.2473], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 18 - 291: dog - cat || Loss: 1.0653589963912964\n",
      "tensor([0., 1.]) tensor([0.7521, 0.2479], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 18 - 292: dog - cat || Loss: 1.064753532409668\n",
      "tensor([0., 1.]) tensor([0.7515, 0.2485], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 18 - 293: dog - cat || Loss: 1.0641472339630127\n",
      "tensor([0., 1.]) tensor([0.7509, 0.2491], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 18 - 294: dog - cat || Loss: 1.063539981842041\n",
      "tensor([0., 1.]) tensor([0.7503, 0.2497], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 18 - 295: dog - cat || Loss: 1.062932014465332\n",
      "tensor([0., 1.]) tensor([0.7497, 0.2503], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 18 - 296: dog - cat || Loss: 1.062322974205017\n",
      "tensor([0., 1.]) tensor([0.7491, 0.2509], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 18 - 297: dog - cat || Loss: 1.0617133378982544\n",
      "tensor([0., 1.]) tensor([0.7485, 0.2515], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 18 - 298: dog - cat || Loss: 1.0611026287078857\n",
      "tensor([0., 1.]) tensor([0.7478, 0.2522], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 18 - 299: dog - cat || Loss: 1.0604910850524902\n",
      "tensor([0., 1.]) tensor([0.7472, 0.2528], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 18 - 300: dog - cat || Loss: 1.0598784685134888\n",
      "tensor([0., 1.]) tensor([0.7466, 0.2534], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 18 - 301: dog - cat || Loss: 1.0592652559280396\n",
      "tensor([0., 1.]) tensor([0.7460, 0.2540], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 18 - 302: dog - cat || Loss: 1.058651089668274\n",
      "tensor([0., 1.]) tensor([0.7454, 0.2546], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 18 - 303: dog - cat || Loss: 1.0580360889434814\n",
      "tensor([0., 1.]) tensor([0.7448, 0.2552], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 18 - 304: dog - cat || Loss: 1.057420253753662\n",
      "tensor([0., 1.]) tensor([0.7442, 0.2558], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 18 - 305: dog - cat || Loss: 1.0568033456802368\n",
      "tensor([0., 1.]) tensor([0.7435, 0.2565], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 18 - 306: dog - cat || Loss: 1.0561857223510742\n",
      "tensor([0., 1.]) tensor([0.7429, 0.2571], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 18 - 307: dog - cat || Loss: 1.0555673837661743\n",
      "tensor([0., 1.]) tensor([0.7423, 0.2577], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 18 - 308: dog - cat || Loss: 1.054948091506958\n",
      "tensor([0., 1.]) tensor([0.7417, 0.2583], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 18 - 309: dog - cat || Loss: 1.0543278455734253\n",
      "tensor([0., 1.]) tensor([0.7411, 0.2589], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 18 - 310: dog - cat || Loss: 1.0537067651748657\n",
      "tensor([0., 1.]) tensor([0.7404, 0.2596], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 18 - 311: dog - cat || Loss: 1.0530848503112793\n",
      "tensor([0., 1.]) tensor([0.7398, 0.2602], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 18 - 312: dog - cat || Loss: 1.052462100982666\n",
      "tensor([0., 1.]) tensor([0.7392, 0.2608], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 18 - 313: dog - cat || Loss: 1.0518385171890259\n",
      "tensor([0., 1.]) tensor([0.7386, 0.2614], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 18 - 314: dog - cat || Loss: 1.0512140989303589\n",
      "tensor([0., 1.]) tensor([0.7380, 0.2620], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 18 - 315: dog - cat || Loss: 1.0505887269973755\n",
      "tensor([0., 1.]) tensor([0.7373, 0.2627], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 18 - 316: dog - cat || Loss: 1.0499626398086548\n",
      "tensor([0., 1.]) tensor([0.7367, 0.2633], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 18 - 317: dog - cat || Loss: 1.0493355989456177\n",
      "tensor([0., 1.]) tensor([0.7361, 0.2639], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 18 - 318: dog - cat || Loss: 1.0487077236175537\n",
      "tensor([0., 1.]) tensor([0.7354, 0.2646], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 18 - 319: dog - cat || Loss: 1.048079013824463\n",
      "tensor([0., 1.]) tensor([0.7348, 0.2652], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 18 - 320: dog - cat || Loss: 1.0474495887756348\n",
      "tensor([0., 1.]) tensor([0.7342, 0.2658], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 18 - 321: dog - cat || Loss: 1.0468190908432007\n",
      "tensor([0., 1.]) tensor([0.7336, 0.2664], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 18 - 322: dog - cat || Loss: 1.0461878776550293\n",
      "tensor([0., 1.]) tensor([0.7329, 0.2671], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 18 - 323: dog - cat || Loss: 1.045555830001831\n",
      "tensor([0., 1.]) tensor([0.7323, 0.2677], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 18 - 324: dog - cat || Loss: 1.044922947883606\n",
      "tensor([0., 1.]) tensor([0.7317, 0.2683], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 18 - 325: dog - cat || Loss: 1.044289231300354\n",
      "tensor([0., 1.]) tensor([0.7310, 0.2690], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 18 - 326: dog - cat || Loss: 1.0436546802520752\n",
      "tensor([0., 1.]) tensor([0.7304, 0.2696], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 18 - 327: dog - cat || Loss: 1.0430192947387695\n",
      "tensor([0., 1.]) tensor([0.7298, 0.2702], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 18 - 328: dog - cat || Loss: 1.042383074760437\n",
      "tensor([0., 1.]) tensor([0.7291, 0.2709], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 18 - 329: dog - cat || Loss: 1.0417460203170776\n",
      "tensor([0., 1.]) tensor([0.7285, 0.2715], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 18 - 330: dog - cat || Loss: 1.041108250617981\n",
      "tensor([0., 1.]) tensor([0.7278, 0.2722], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 18 - 331: dog - cat || Loss: 1.0404695272445679\n",
      "tensor([0., 1.]) tensor([0.7272, 0.2728], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 18 - 332: dog - cat || Loss: 1.039830207824707\n",
      "tensor([0., 1.]) tensor([0.7266, 0.2734], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 18 - 333: dog - cat || Loss: 1.0391899347305298\n",
      "tensor([0., 1.]) tensor([0.7259, 0.2741], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 18 - 334: dog - cat || Loss: 1.0385487079620361\n",
      "tensor([0., 1.]) tensor([0.7253, 0.2747], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 18 - 335: dog - cat || Loss: 1.0379070043563843\n",
      "tensor([0., 1.]) tensor([0.7246, 0.2754], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 18 - 336: dog - cat || Loss: 1.037264347076416\n",
      "tensor([0., 1.]) tensor([0.7240, 0.2760], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 18 - 337: dog - cat || Loss: 1.0366207361221313\n",
      "tensor([0., 1.]) tensor([0.7234, 0.2766], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 18 - 338: dog - cat || Loss: 1.035976529121399\n",
      "tensor([0., 1.]) tensor([0.7227, 0.2773], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 18 - 339: dog - cat || Loss: 1.0353314876556396\n",
      "tensor([0., 1.]) tensor([0.7221, 0.2779], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 18 - 340: dog - cat || Loss: 1.034685492515564\n",
      "tensor([0., 1.]) tensor([0.7214, 0.2786], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 18 - 341: dog - cat || Loss: 1.0340389013290405\n",
      "tensor([0., 1.]) tensor([0.7208, 0.2792], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 18 - 342: dog - cat || Loss: 1.0333914756774902\n",
      "tensor([0., 1.]) tensor([0.7201, 0.2799], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 18 - 343: dog - cat || Loss: 1.032742977142334\n",
      "tensor([0., 1.]) tensor([0.7195, 0.2805], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 18 - 344: dog - cat || Loss: 1.0320940017700195\n",
      "tensor([0., 1.]) tensor([0.7188, 0.2812], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 18 - 345: dog - cat || Loss: 1.0314440727233887\n",
      "tensor([0., 1.]) tensor([0.7182, 0.2818], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 18 - 346: dog - cat || Loss: 1.030793309211731\n",
      "tensor([0., 1.]) tensor([0.7175, 0.2825], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 18 - 347: dog - cat || Loss: 1.030141830444336\n",
      "tensor([0., 1.]) tensor([0.7169, 0.2831], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 18 - 348: dog - cat || Loss: 1.0294896364212036\n",
      "tensor([0., 1.]) tensor([0.7162, 0.2838], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 18 - 349: dog - cat || Loss: 1.0288366079330444\n",
      "tensor([0., 1.]) tensor([0.7156, 0.2844], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 18 - 350: dog - cat || Loss: 1.0281827449798584\n",
      "tensor([0., 1.]) tensor([0.7149, 0.2851], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 18 - 351: dog - cat || Loss: 1.0275280475616455\n",
      "tensor([0., 1.]) tensor([0.7143, 0.2857], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 18 - 352: dog - cat || Loss: 1.0268727540969849\n",
      "tensor([0., 1.]) tensor([0.7136, 0.2864], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 18 - 353: dog - cat || Loss: 1.0262165069580078\n",
      "tensor([0., 1.]) tensor([0.7130, 0.2870], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 18 - 354: dog - cat || Loss: 1.0255593061447144\n",
      "tensor([0., 1.]) tensor([0.7123, 0.2877], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 18 - 355: dog - cat || Loss: 1.0249017477035522\n",
      "tensor([0., 1.]) tensor([0.7116, 0.2884], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 18 - 356: dog - cat || Loss: 1.0242431163787842\n",
      "tensor([0., 1.]) tensor([0.7110, 0.2890], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 18 - 357: dog - cat || Loss: 1.0235837697982788\n",
      "tensor([0., 1.]) tensor([0.7103, 0.2897], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 18 - 358: dog - cat || Loss: 1.0229237079620361\n",
      "tensor([0., 1.]) tensor([0.7097, 0.2903], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 18 - 359: dog - cat || Loss: 1.0222628116607666\n",
      "tensor([0., 1.]) tensor([0.7090, 0.2910], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 18 - 360: dog - cat || Loss: 1.0216010808944702\n",
      "tensor([0., 1.]) tensor([0.7083, 0.2917], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 18 - 361: dog - cat || Loss: 1.020938754081726\n",
      "tensor([0., 1.]) tensor([0.7077, 0.2923], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 18 - 362: dog - cat || Loss: 1.020275592803955\n",
      "tensor([0., 1.]) tensor([0.7070, 0.2930], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 18 - 363: dog - cat || Loss: 1.0196117162704468\n",
      "tensor([0., 1.]) tensor([0.7064, 0.2936], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 18 - 364: dog - cat || Loss: 1.0189470052719116\n",
      "tensor([0., 1.]) tensor([0.7057, 0.2943], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 18 - 365: dog - cat || Loss: 1.0182815790176392\n",
      "tensor([0., 1.]) tensor([0.7050, 0.2950], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 18 - 366: dog - cat || Loss: 1.0176153182983398\n",
      "tensor([0., 1.]) tensor([0.7044, 0.2956], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 18 - 367: dog - cat || Loss: 1.0169482231140137\n",
      "tensor([0., 1.]) tensor([0.7037, 0.2963], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 18 - 368: dog - cat || Loss: 1.0162805318832397\n",
      "tensor([0., 1.]) tensor([0.7030, 0.2970], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 18 - 369: dog - cat || Loss: 1.0156118869781494\n",
      "tensor([0., 1.]) tensor([0.7024, 0.2976], grad_fn=<SoftmaxBackward0>)\n",
      "=====epoch:19=====\n",
      "Epoch 19 - 0: cat - cat || Loss: 0.6115807294845581\n",
      "tensor([1., 0.]) tensor([0.7017, 0.2983], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 19 - 1: cat - cat || Loss: 0.6121160984039307\n",
      "tensor([1., 0.]) tensor([0.7011, 0.2989], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 19 - 2: cat - cat || Loss: 0.6125307083129883\n",
      "tensor([1., 0.]) tensor([0.7007, 0.2993], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 19 - 3: cat - cat || Loss: 0.6128364205360413\n",
      "tensor([1., 0.]) tensor([0.7004, 0.2996], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 19 - 4: cat - cat || Loss: 0.6130440831184387\n",
      "tensor([1., 0.]) tensor([0.7002, 0.2998], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 19 - 5: cat - cat || Loss: 0.6131634712219238\n",
      "tensor([1., 0.]) tensor([0.7001, 0.2999], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 19 - 6: cat - cat || Loss: 0.6132032871246338\n",
      "tensor([1., 0.]) tensor([0.7001, 0.2999], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 19 - 7: cat - cat || Loss: 0.6131716370582581\n",
      "tensor([1., 0.]) tensor([0.7001, 0.2999], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 19 - 8: cat - cat || Loss: 0.6130756735801697\n",
      "tensor([1., 0.]) tensor([0.7002, 0.2998], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 19 - 9: cat - cat || Loss: 0.6129217147827148\n",
      "tensor([1., 0.]) tensor([0.7003, 0.2997], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 19 - 10: cat - cat || Loss: 0.6127157807350159\n",
      "tensor([1., 0.]) tensor([0.7005, 0.2995], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 19 - 11: cat - cat || Loss: 0.612463116645813\n",
      "tensor([1., 0.]) tensor([0.7008, 0.2992], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 19 - 12: cat - cat || Loss: 0.6121683716773987\n",
      "tensor([1., 0.]) tensor([0.7011, 0.2989], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 19 - 13: cat - cat || Loss: 0.6118358373641968\n",
      "tensor([1., 0.]) tensor([0.7014, 0.2986], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 19 - 14: cat - cat || Loss: 0.6114692687988281\n",
      "tensor([1., 0.]) tensor([0.7018, 0.2982], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 19 - 15: cat - cat || Loss: 0.6110721826553345\n",
      "tensor([1., 0.]) tensor([0.7022, 0.2978], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 19 - 16: cat - cat || Loss: 0.6106476783752441\n",
      "tensor([1., 0.]) tensor([0.7026, 0.2974], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 19 - 17: cat - cat || Loss: 0.6101987361907959\n",
      "tensor([1., 0.]) tensor([0.7031, 0.2969], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 19 - 18: cat - cat || Loss: 0.6097275018692017\n",
      "tensor([1., 0.]) tensor([0.7035, 0.2965], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 19 - 19: cat - cat || Loss: 0.6092365980148315\n",
      "tensor([1., 0.]) tensor([0.7040, 0.2960], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 19 - 20: cat - cat || Loss: 0.6087279319763184\n",
      "tensor([1., 0.]) tensor([0.7045, 0.2955], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 19 - 21: cat - cat || Loss: 0.6082032918930054\n",
      "tensor([1., 0.]) tensor([0.7051, 0.2949], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 19 - 22: cat - cat || Loss: 0.6076646447181702\n",
      "tensor([1., 0.]) tensor([0.7056, 0.2944], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 19 - 23: cat - cat || Loss: 0.6071131825447083\n",
      "tensor([1., 0.]) tensor([0.7061, 0.2939], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 19 - 24: cat - cat || Loss: 0.6065502166748047\n",
      "tensor([1., 0.]) tensor([0.7067, 0.2933], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 19 - 25: cat - cat || Loss: 0.6059771776199341\n",
      "tensor([1., 0.]) tensor([0.7073, 0.2927], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 19 - 26: cat - cat || Loss: 0.6053951382637024\n",
      "tensor([1., 0.]) tensor([0.7079, 0.2921], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 19 - 27: cat - cat || Loss: 0.6048049330711365\n",
      "tensor([1., 0.]) tensor([0.7085, 0.2915], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 19 - 28: cat - cat || Loss: 0.6042075157165527\n",
      "tensor([1., 0.]) tensor([0.7091, 0.2909], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 19 - 29: cat - cat || Loss: 0.6036037802696228\n",
      "tensor([1., 0.]) tensor([0.7097, 0.2903], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 19 - 30: cat - cat || Loss: 0.6029943823814392\n",
      "tensor([1., 0.]) tensor([0.7103, 0.2897], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 19 - 31: cat - cat || Loss: 0.6023799180984497\n",
      "tensor([1., 0.]) tensor([0.7109, 0.2891], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 19 - 32: cat - cat || Loss: 0.601760983467102\n",
      "tensor([1., 0.]) tensor([0.7115, 0.2885], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 19 - 33: cat - cat || Loss: 0.6011382341384888\n",
      "tensor([1., 0.]) tensor([0.7121, 0.2879], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 19 - 34: cat - cat || Loss: 0.6005120277404785\n",
      "tensor([1., 0.]) tensor([0.7127, 0.2873], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 19 - 35: cat - cat || Loss: 0.5998827219009399\n",
      "tensor([1., 0.]) tensor([0.7134, 0.2866], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 19 - 36: cat - cat || Loss: 0.599250853061676\n",
      "tensor([1., 0.]) tensor([0.7140, 0.2860], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 19 - 37: cat - cat || Loss: 0.5986167192459106\n",
      "tensor([1., 0.]) tensor([0.7146, 0.2854], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 19 - 38: cat - cat || Loss: 0.5979804992675781\n",
      "tensor([1., 0.]) tensor([0.7153, 0.2847], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 19 - 39: cat - cat || Loss: 0.5973425507545471\n",
      "tensor([1., 0.]) tensor([0.7159, 0.2841], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 19 - 40: cat - cat || Loss: 0.5967034101486206\n",
      "tensor([1., 0.]) tensor([0.7166, 0.2834], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 19 - 41: cat - cat || Loss: 0.5960628390312195\n",
      "tensor([1., 0.]) tensor([0.7172, 0.2828], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 19 - 42: cat - cat || Loss: 0.5954213738441467\n",
      "tensor([1., 0.]) tensor([0.7178, 0.2822], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 19 - 43: cat - cat || Loss: 0.594778835773468\n",
      "tensor([1., 0.]) tensor([0.7185, 0.2815], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 19 - 44: cat - cat || Loss: 0.594136118888855\n",
      "tensor([1., 0.]) tensor([0.7191, 0.2809], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 19 - 45: cat - cat || Loss: 0.5934925079345703\n",
      "tensor([1., 0.]) tensor([0.7198, 0.2802], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 19 - 46: cat - cat || Loss: 0.5928485989570618\n",
      "tensor([1., 0.]) tensor([0.7204, 0.2796], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 19 - 47: cat - cat || Loss: 0.5922045111656189\n",
      "tensor([1., 0.]) tensor([0.7211, 0.2789], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 19 - 48: cat - cat || Loss: 0.5915601849555969\n",
      "tensor([1., 0.]) tensor([0.7217, 0.2783], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 19 - 49: cat - cat || Loss: 0.590915858745575\n",
      "tensor([1., 0.]) tensor([0.7223, 0.2777], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 19 - 50: cat - cat || Loss: 0.5902717113494873\n",
      "tensor([1., 0.]) tensor([0.7230, 0.2770], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 19 - 51: cat - cat || Loss: 0.5896275043487549\n",
      "tensor([1., 0.]) tensor([0.7236, 0.2764], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 19 - 52: cat - cat || Loss: 0.5889835357666016\n",
      "tensor([1., 0.]) tensor([0.7243, 0.2757], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 19 - 53: cat - cat || Loss: 0.5883399248123169\n",
      "tensor([1., 0.]) tensor([0.7249, 0.2751], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 19 - 54: cat - cat || Loss: 0.5876965522766113\n",
      "tensor([1., 0.]) tensor([0.7256, 0.2744], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 19 - 55: cat - cat || Loss: 0.5870535969734192\n",
      "tensor([1., 0.]) tensor([0.7262, 0.2738], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 19 - 56: cat - cat || Loss: 0.5864109992980957\n",
      "tensor([1., 0.]) tensor([0.7269, 0.2731], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 19 - 57: cat - cat || Loss: 0.5857689380645752\n",
      "tensor([1., 0.]) tensor([0.7275, 0.2725], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 19 - 58: cat - cat || Loss: 0.5851272940635681\n",
      "tensor([1., 0.]) tensor([0.7281, 0.2719], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 19 - 59: cat - cat || Loss: 0.5844862461090088\n",
      "tensor([1., 0.]) tensor([0.7288, 0.2712], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 19 - 60: cat - cat || Loss: 0.583845853805542\n",
      "tensor([1., 0.]) tensor([0.7294, 0.2706], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 19 - 61: cat - cat || Loss: 0.5832058787345886\n",
      "tensor([1., 0.]) tensor([0.7301, 0.2699], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 19 - 62: cat - cat || Loss: 0.5825666785240173\n",
      "tensor([1., 0.]) tensor([0.7307, 0.2693], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 19 - 63: cat - cat || Loss: 0.5819281339645386\n",
      "tensor([1., 0.]) tensor([0.7313, 0.2687], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 19 - 64: cat - cat || Loss: 0.5812901258468628\n",
      "tensor([1., 0.]) tensor([0.7320, 0.2680], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 19 - 65: cat - cat || Loss: 0.5806528925895691\n",
      "tensor([1., 0.]) tensor([0.7326, 0.2674], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 19 - 66: cat - cat || Loss: 0.5800163745880127\n",
      "tensor([1., 0.]) tensor([0.7332, 0.2668], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 19 - 67: cat - cat || Loss: 0.5793806314468384\n",
      "tensor([1., 0.]) tensor([0.7339, 0.2661], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 19 - 68: cat - cat || Loss: 0.5787455439567566\n",
      "tensor([1., 0.]) tensor([0.7345, 0.2655], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 19 - 69: cat - cat || Loss: 0.5781112909317017\n",
      "tensor([1., 0.]) tensor([0.7352, 0.2648], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 19 - 70: cat - cat || Loss: 0.577477753162384\n",
      "tensor([1., 0.]) tensor([0.7358, 0.2642], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 19 - 71: cat - cat || Loss: 0.5768451690673828\n",
      "tensor([1., 0.]) tensor([0.7364, 0.2636], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 19 - 72: cat - cat || Loss: 0.5762132406234741\n",
      "tensor([1., 0.]) tensor([0.7370, 0.2630], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 19 - 73: cat - cat || Loss: 0.5755821466445923\n",
      "tensor([1., 0.]) tensor([0.7377, 0.2623], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 19 - 74: cat - cat || Loss: 0.5749520063400269\n",
      "tensor([1., 0.]) tensor([0.7383, 0.2617], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 19 - 75: cat - cat || Loss: 0.5743224620819092\n",
      "tensor([1., 0.]) tensor([0.7389, 0.2611], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 19 - 76: cat - cat || Loss: 0.5736939907073975\n",
      "tensor([1., 0.]) tensor([0.7396, 0.2604], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 19 - 77: cat - cat || Loss: 0.5730663537979126\n",
      "tensor([1., 0.]) tensor([0.7402, 0.2598], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 19 - 78: cat - cat || Loss: 0.5724393725395203\n",
      "tensor([1., 0.]) tensor([0.7408, 0.2592], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 19 - 79: cat - cat || Loss: 0.5718132853507996\n",
      "tensor([1., 0.]) tensor([0.7414, 0.2586], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 19 - 80: cat - cat || Loss: 0.5711881518363953\n",
      "tensor([1., 0.]) tensor([0.7421, 0.2579], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 19 - 81: cat - cat || Loss: 0.570563793182373\n",
      "tensor([1., 0.]) tensor([0.7427, 0.2573], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 19 - 82: cat - cat || Loss: 0.5699402689933777\n",
      "tensor([1., 0.]) tensor([0.7433, 0.2567], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 19 - 83: cat - cat || Loss: 0.5693176984786987\n",
      "tensor([1., 0.]) tensor([0.7439, 0.2561], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 19 - 84: cat - cat || Loss: 0.5686960220336914\n",
      "tensor([1., 0.]) tensor([0.7446, 0.2554], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 19 - 85: cat - cat || Loss: 0.5680750012397766\n",
      "tensor([1., 0.]) tensor([0.7452, 0.2548], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 19 - 86: cat - cat || Loss: 0.5674551129341125\n",
      "tensor([1., 0.]) tensor([0.7458, 0.2542], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 19 - 87: cat - cat || Loss: 0.5668359994888306\n",
      "tensor([1., 0.]) tensor([0.7464, 0.2536], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 19 - 88: cat - cat || Loss: 0.5662177205085754\n",
      "tensor([1., 0.]) tensor([0.7470, 0.2530], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 19 - 89: cat - cat || Loss: 0.5656003952026367\n",
      "tensor([1., 0.]) tensor([0.7477, 0.2523], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 19 - 90: cat - cat || Loss: 0.5649839639663696\n",
      "tensor([1., 0.]) tensor([0.7483, 0.2517], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 19 - 91: cat - cat || Loss: 0.5643683671951294\n",
      "tensor([1., 0.]) tensor([0.7489, 0.2511], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 19 - 92: cat - cat || Loss: 0.5637536644935608\n",
      "tensor([1., 0.]) tensor([0.7495, 0.2505], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 19 - 93: cat - cat || Loss: 0.5631399154663086\n",
      "tensor([1., 0.]) tensor([0.7501, 0.2499], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 19 - 94: cat - cat || Loss: 0.5625271201133728\n",
      "tensor([1., 0.]) tensor([0.7507, 0.2493], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 19 - 95: cat - cat || Loss: 0.5619150400161743\n",
      "tensor([1., 0.]) tensor([0.7513, 0.2487], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 19 - 96: cat - cat || Loss: 0.5613040328025818\n",
      "tensor([1., 0.]) tensor([0.7520, 0.2480], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 19 - 97: cat - cat || Loss: 0.5606938600540161\n",
      "tensor([1., 0.]) tensor([0.7526, 0.2474], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 19 - 98: cat - cat || Loss: 0.5600846409797668\n",
      "tensor([1., 0.]) tensor([0.7532, 0.2468], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 19 - 99: cat - cat || Loss: 0.5594763159751892\n",
      "tensor([1., 0.]) tensor([0.7538, 0.2462], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 19 - 100: cat - cat || Loss: 0.5588688850402832\n",
      "tensor([1., 0.]) tensor([0.7544, 0.2456], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 19 - 101: cat - cat || Loss: 0.5582623481750488\n",
      "tensor([1., 0.]) tensor([0.7550, 0.2450], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 19 - 102: cat - cat || Loss: 0.5576568841934204\n",
      "tensor([1., 0.]) tensor([0.7556, 0.2444], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 19 - 103: cat - cat || Loss: 0.5570520758628845\n",
      "tensor([1., 0.]) tensor([0.7562, 0.2438], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 19 - 104: cat - cat || Loss: 0.5564484596252441\n",
      "tensor([1., 0.]) tensor([0.7568, 0.2432], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 19 - 105: cat - cat || Loss: 0.5558457374572754\n",
      "tensor([1., 0.]) tensor([0.7574, 0.2426], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 19 - 106: cat - cat || Loss: 0.5552437901496887\n",
      "tensor([1., 0.]) tensor([0.7580, 0.2420], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 19 - 107: cat - cat || Loss: 0.5546427965164185\n",
      "tensor([1., 0.]) tensor([0.7586, 0.2414], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 19 - 108: cat - cat || Loss: 0.5540428161621094\n",
      "tensor([1., 0.]) tensor([0.7592, 0.2408], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 19 - 109: cat - cat || Loss: 0.5534437298774719\n",
      "tensor([1., 0.]) tensor([0.7598, 0.2402], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 19 - 110: cat - cat || Loss: 0.5528454780578613\n",
      "tensor([1., 0.]) tensor([0.7604, 0.2396], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 19 - 111: cat - cat || Loss: 0.5522482395172119\n",
      "tensor([1., 0.]) tensor([0.7610, 0.2390], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 19 - 112: cat - cat || Loss: 0.5516518950462341\n",
      "tensor([1., 0.]) tensor([0.7616, 0.2384], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 19 - 113: cat - cat || Loss: 0.5510565638542175\n",
      "tensor([1., 0.]) tensor([0.7622, 0.2378], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 19 - 114: cat - cat || Loss: 0.5504621267318726\n",
      "tensor([1., 0.]) tensor([0.7628, 0.2372], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 19 - 115: cat - cat || Loss: 0.5498685836791992\n",
      "tensor([1., 0.]) tensor([0.7634, 0.2366], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 19 - 116: cat - cat || Loss: 0.5492759943008423\n",
      "tensor([1., 0.]) tensor([0.7640, 0.2360], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 19 - 117: cat - cat || Loss: 0.5486844778060913\n",
      "tensor([1., 0.]) tensor([0.7646, 0.2354], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 19 - 118: cat - cat || Loss: 0.5480937957763672\n",
      "tensor([1., 0.]) tensor([0.7652, 0.2348], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 19 - 119: cat - cat || Loss: 0.5475041270256042\n",
      "tensor([1., 0.]) tensor([0.7658, 0.2342], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 19 - 120: cat - cat || Loss: 0.5469152927398682\n",
      "tensor([1., 0.]) tensor([0.7663, 0.2337], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 19 - 121: cat - cat || Loss: 0.5463273525238037\n",
      "tensor([1., 0.]) tensor([0.7669, 0.2331], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 19 - 122: cat - cat || Loss: 0.5457406044006348\n",
      "tensor([1., 0.]) tensor([0.7675, 0.2325], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 19 - 123: cat - cat || Loss: 0.5451546311378479\n",
      "tensor([1., 0.]) tensor([0.7681, 0.2319], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 19 - 124: cat - cat || Loss: 0.5445696115493774\n",
      "tensor([1., 0.]) tensor([0.7687, 0.2313], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 19 - 125: cat - cat || Loss: 0.5439856052398682\n",
      "tensor([1., 0.]) tensor([0.7693, 0.2307], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 19 - 126: cat - cat || Loss: 0.5434024333953857\n",
      "tensor([1., 0.]) tensor([0.7699, 0.2301], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 19 - 127: cat - cat || Loss: 0.5428202152252197\n",
      "tensor([1., 0.]) tensor([0.7704, 0.2296], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 19 - 128: cat - cat || Loss: 0.5422390103340149\n",
      "tensor([1., 0.]) tensor([0.7710, 0.2290], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 19 - 129: cat - cat || Loss: 0.5416586399078369\n",
      "tensor([1., 0.]) tensor([0.7716, 0.2284], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 19 - 130: cat - cat || Loss: 0.5410794019699097\n",
      "tensor([1., 0.]) tensor([0.7722, 0.2278], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 19 - 131: cat - cat || Loss: 0.5405009984970093\n",
      "tensor([1., 0.]) tensor([0.7728, 0.2272], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 19 - 132: cat - cat || Loss: 0.5399235486984253\n",
      "tensor([1., 0.]) tensor([0.7733, 0.2267], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 19 - 133: cat - cat || Loss: 0.5393470525741577\n",
      "tensor([1., 0.]) tensor([0.7739, 0.2261], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 19 - 134: cat - cat || Loss: 0.5387715101242065\n",
      "tensor([1., 0.]) tensor([0.7745, 0.2255], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 19 - 135: cat - cat || Loss: 0.5381969809532166\n",
      "tensor([1., 0.]) tensor([0.7751, 0.2249], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 19 - 136: cat - cat || Loss: 0.537623405456543\n",
      "tensor([1., 0.]) tensor([0.7756, 0.2244], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 19 - 137: cat - cat || Loss: 0.5370506644248962\n",
      "tensor([1., 0.]) tensor([0.7762, 0.2238], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 19 - 138: cat - cat || Loss: 0.5364789962768555\n",
      "tensor([1., 0.]) tensor([0.7768, 0.2232], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 19 - 139: cat - cat || Loss: 0.5359082818031311\n",
      "tensor([1., 0.]) tensor([0.7774, 0.2226], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 19 - 140: cat - cat || Loss: 0.5353385210037231\n",
      "tensor([1., 0.]) tensor([0.7779, 0.2221], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 19 - 141: cat - cat || Loss: 0.534769594669342\n",
      "tensor([1., 0.]) tensor([0.7785, 0.2215], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 19 - 142: cat - cat || Loss: 0.5342017412185669\n",
      "tensor([1., 0.]) tensor([0.7791, 0.2209], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 19 - 143: cat - cat || Loss: 0.5336347818374634\n",
      "tensor([1., 0.]) tensor([0.7796, 0.2204], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 19 - 144: cat - cat || Loss: 0.5330688953399658\n",
      "tensor([1., 0.]) tensor([0.7802, 0.2198], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 19 - 145: cat - cat || Loss: 0.5325038433074951\n",
      "tensor([1., 0.]) tensor([0.7808, 0.2192], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 19 - 146: cat - cat || Loss: 0.5319398641586304\n",
      "tensor([1., 0.]) tensor([0.7813, 0.2187], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 19 - 147: cat - cat || Loss: 0.531376838684082\n",
      "tensor([1., 0.]) tensor([0.7819, 0.2181], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 19 - 148: cat - cat || Loss: 0.5308146476745605\n",
      "tensor([1., 0.]) tensor([0.7824, 0.2176], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 19 - 149: cat - cat || Loss: 0.530253529548645\n",
      "tensor([1., 0.]) tensor([0.7830, 0.2170], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 19 - 150: cat - cat || Loss: 0.5296933650970459\n",
      "tensor([1., 0.]) tensor([0.7836, 0.2164], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 19 - 151: cat - cat || Loss: 0.5291342735290527\n",
      "tensor([1., 0.]) tensor([0.7841, 0.2159], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 19 - 152: cat - cat || Loss: 0.5285760164260864\n",
      "tensor([1., 0.]) tensor([0.7847, 0.2153], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 19 - 153: cat - cat || Loss: 0.5280187129974365\n",
      "tensor([1., 0.]) tensor([0.7852, 0.2148], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 19 - 154: cat - cat || Loss: 0.5274624824523926\n",
      "tensor([1., 0.]) tensor([0.7858, 0.2142], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 19 - 155: cat - cat || Loss: 0.5269070863723755\n",
      "tensor([1., 0.]) tensor([0.7864, 0.2136], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 19 - 156: cat - cat || Loss: 0.5263528227806091\n",
      "tensor([1., 0.]) tensor([0.7869, 0.2131], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 19 - 157: cat - cat || Loss: 0.5257995128631592\n",
      "tensor([1., 0.]) tensor([0.7875, 0.2125], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 19 - 158: cat - cat || Loss: 0.5252470374107361\n",
      "tensor([1., 0.]) tensor([0.7880, 0.2120], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 19 - 159: cat - cat || Loss: 0.5246955752372742\n",
      "tensor([1., 0.]) tensor([0.7886, 0.2114], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 19 - 160: cat - cat || Loss: 0.5241451263427734\n",
      "tensor([1., 0.]) tensor([0.7891, 0.2109], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 19 - 161: cat - cat || Loss: 0.5235956907272339\n",
      "tensor([1., 0.]) tensor([0.7897, 0.2103], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 19 - 162: cat - cat || Loss: 0.5230472683906555\n",
      "tensor([1., 0.]) tensor([0.7902, 0.2098], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 19 - 163: cat - cat || Loss: 0.522499680519104\n",
      "tensor([1., 0.]) tensor([0.7908, 0.2092], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 19 - 164: cat - cat || Loss: 0.5219531059265137\n",
      "tensor([1., 0.]) tensor([0.7913, 0.2087], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 19 - 165: cat - cat || Loss: 0.5214076042175293\n",
      "tensor([1., 0.]) tensor([0.7919, 0.2081], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 19 - 166: cat - cat || Loss: 0.5208630561828613\n",
      "tensor([1., 0.]) tensor([0.7924, 0.2076], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 19 - 167: cat - cat || Loss: 0.5203194618225098\n",
      "tensor([1., 0.]) tensor([0.7929, 0.2071], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 19 - 168: cat - cat || Loss: 0.5197768807411194\n",
      "tensor([1., 0.]) tensor([0.7935, 0.2065], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 19 - 169: cat - cat || Loss: 0.5192351341247559\n",
      "tensor([1., 0.]) tensor([0.7940, 0.2060], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 19 - 170: cat - cat || Loss: 0.5186945199966431\n",
      "tensor([1., 0.]) tensor([0.7946, 0.2054], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 19 - 171: cat - cat || Loss: 0.5181548595428467\n",
      "tensor([1., 0.]) tensor([0.7951, 0.2049], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 19 - 172: cat - cat || Loss: 0.5176162123680115\n",
      "tensor([1., 0.]) tensor([0.7956, 0.2044], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 19 - 173: cat - cat || Loss: 0.5170784592628479\n",
      "tensor([1., 0.]) tensor([0.7962, 0.2038], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 19 - 174: cat - cat || Loss: 0.5165417194366455\n",
      "tensor([1., 0.]) tensor([0.7967, 0.2033], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 19 - 175: cat - cat || Loss: 0.5160059332847595\n",
      "tensor([1., 0.]) tensor([0.7973, 0.2027], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 19 - 176: cat - cat || Loss: 0.5154711008071899\n",
      "tensor([1., 0.]) tensor([0.7978, 0.2022], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 19 - 177: cat - cat || Loss: 0.5149374008178711\n",
      "tensor([1., 0.]) tensor([0.7983, 0.2017], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 19 - 178: cat - cat || Loss: 0.5144046545028687\n",
      "tensor([1., 0.]) tensor([0.7989, 0.2011], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 19 - 179: cat - cat || Loss: 0.5138728618621826\n",
      "tensor([1., 0.]) tensor([0.7994, 0.2006], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 19 - 180: cat - cat || Loss: 0.513342022895813\n",
      "tensor([1., 0.]) tensor([0.7999, 0.2001], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 19 - 181: cat - cat || Loss: 0.5128121972084045\n",
      "tensor([1., 0.]) tensor([0.8004, 0.1996], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 19 - 182: cat - cat || Loss: 0.5122833847999573\n",
      "tensor([1., 0.]) tensor([0.8010, 0.1990], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 19 - 183: cat - cat || Loss: 0.5117555260658264\n",
      "tensor([1., 0.]) tensor([0.8015, 0.1985], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 19 - 184: cat - cat || Loss: 0.5112286806106567\n",
      "tensor([1., 0.]) tensor([0.8020, 0.1980], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 19 - 185: cat - cat || Loss: 0.5107027888298035\n",
      "tensor([1., 0.]) tensor([0.8026, 0.1974], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 19 - 186: cat - cat || Loss: 0.5101778507232666\n",
      "tensor([1., 0.]) tensor([0.8031, 0.1969], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 19 - 187: cat - cat || Loss: 0.5096540451049805\n",
      "tensor([1., 0.]) tensor([0.8036, 0.1964], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 19 - 188: cat - cat || Loss: 0.5091310739517212\n",
      "tensor([1., 0.]) tensor([0.8041, 0.1959], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 19 - 189: cat - cat || Loss: 0.5086092352867126\n",
      "tensor([1., 0.]) tensor([0.8047, 0.1953], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 19 - 190: dog - cat || Loss: 1.1184349060058594\n",
      "tensor([0., 1.]) tensor([0.8052, 0.1948], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 19 - 191: dog - cat || Loss: 1.118851900100708\n",
      "tensor([0., 1.]) tensor([0.8056, 0.1944], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 19 - 192: dog - cat || Loss: 1.1191750764846802\n",
      "tensor([0., 1.]) tensor([0.8059, 0.1941], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 19 - 193: dog - cat || Loss: 1.1194146871566772\n",
      "tensor([0., 1.]) tensor([0.8062, 0.1938], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 19 - 194: dog - cat || Loss: 1.1195785999298096\n",
      "tensor([0., 1.]) tensor([0.8063, 0.1937], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 19 - 195: dog - cat || Loss: 1.1196749210357666\n",
      "tensor([0., 1.]) tensor([0.8064, 0.1936], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 19 - 196: dog - cat || Loss: 1.1197099685668945\n",
      "tensor([0., 1.]) tensor([0.8064, 0.1936], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 19 - 197: dog - cat || Loss: 1.1196902990341187\n",
      "tensor([0., 1.]) tensor([0.8064, 0.1936], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 19 - 198: dog - cat || Loss: 1.1196215152740479\n",
      "tensor([0., 1.]) tensor([0.8064, 0.1936], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 19 - 199: dog - cat || Loss: 1.119507908821106\n",
      "tensor([0., 1.]) tensor([0.8062, 0.1938], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 19 - 200: dog - cat || Loss: 1.119354248046875\n",
      "tensor([0., 1.]) tensor([0.8061, 0.1939], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 19 - 201: dog - cat || Loss: 1.1191647052764893\n",
      "tensor([0., 1.]) tensor([0.8059, 0.1941], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 19 - 202: dog - cat || Loss: 1.118942379951477\n",
      "tensor([0., 1.]) tensor([0.8057, 0.1943], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 19 - 203: dog - cat || Loss: 1.118690848350525\n",
      "tensor([0., 1.]) tensor([0.8054, 0.1946], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 19 - 204: dog - cat || Loss: 1.1184128522872925\n",
      "tensor([0., 1.]) tensor([0.8052, 0.1948], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 19 - 205: dog - cat || Loss: 1.1181106567382812\n",
      "tensor([0., 1.]) tensor([0.8048, 0.1952], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 19 - 206: dog - cat || Loss: 1.1177871227264404\n",
      "tensor([0., 1.]) tensor([0.8045, 0.1955], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 19 - 207: dog - cat || Loss: 1.1174442768096924\n",
      "tensor([0., 1.]) tensor([0.8042, 0.1958], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 19 - 208: dog - cat || Loss: 1.1170834302902222\n",
      "tensor([0., 1.]) tensor([0.8038, 0.1962], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 19 - 209: dog - cat || Loss: 1.1167067289352417\n",
      "tensor([0., 1.]) tensor([0.8034, 0.1966], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 19 - 210: dog - cat || Loss: 1.1163156032562256\n",
      "tensor([0., 1.]) tensor([0.8031, 0.1969], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 19 - 211: dog - cat || Loss: 1.1159113645553589\n",
      "tensor([0., 1.]) tensor([0.8026, 0.1974], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 19 - 212: dog - cat || Loss: 1.1154950857162476\n",
      "tensor([0., 1.]) tensor([0.8022, 0.1978], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 19 - 213: dog - cat || Loss: 1.1150681972503662\n",
      "tensor([0., 1.]) tensor([0.8018, 0.1982], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 19 - 214: dog - cat || Loss: 1.1146314144134521\n",
      "tensor([0., 1.]) tensor([0.8014, 0.1986], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 19 - 215: dog - cat || Loss: 1.1141856908798218\n",
      "tensor([0., 1.]) tensor([0.8009, 0.1991], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 19 - 216: dog - cat || Loss: 1.113732099533081\n",
      "tensor([0., 1.]) tensor([0.8005, 0.1995], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 19 - 217: dog - cat || Loss: 1.11327064037323\n",
      "tensor([0., 1.]) tensor([0.8000, 0.2000], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 19 - 218: dog - cat || Loss: 1.1128027439117432\n",
      "tensor([0., 1.]) tensor([0.7995, 0.2005], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 19 - 219: dog - cat || Loss: 1.1123286485671997\n",
      "tensor([0., 1.]) tensor([0.7991, 0.2009], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 19 - 220: dog - cat || Loss: 1.1118488311767578\n",
      "tensor([0., 1.]) tensor([0.7986, 0.2014], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 19 - 221: dog - cat || Loss: 1.1113641262054443\n",
      "tensor([0., 1.]) tensor([0.7981, 0.2019], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 19 - 222: dog - cat || Loss: 1.1108742952346802\n",
      "tensor([0., 1.]) tensor([0.7976, 0.2024], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 19 - 223: dog - cat || Loss: 1.1103804111480713\n",
      "tensor([0., 1.]) tensor([0.7971, 0.2029], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 19 - 224: dog - cat || Loss: 1.109882116317749\n",
      "tensor([0., 1.]) tensor([0.7966, 0.2034], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 19 - 225: dog - cat || Loss: 1.1093804836273193\n",
      "tensor([0., 1.]) tensor([0.7961, 0.2039], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 19 - 226: dog - cat || Loss: 1.1088751554489136\n",
      "tensor([0., 1.]) tensor([0.7956, 0.2044], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 19 - 227: dog - cat || Loss: 1.1083669662475586\n",
      "tensor([0., 1.]) tensor([0.7951, 0.2049], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 19 - 228: dog - cat || Loss: 1.1078555583953857\n",
      "tensor([0., 1.]) tensor([0.7946, 0.2054], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 19 - 229: dog - cat || Loss: 1.1073414087295532\n",
      "tensor([0., 1.]) tensor([0.7941, 0.2059], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 19 - 230: dog - cat || Loss: 1.106824517250061\n",
      "tensor([0., 1.]) tensor([0.7936, 0.2064], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 19 - 231: dog - cat || Loss: 1.106305480003357\n",
      "tensor([0., 1.]) tensor([0.7930, 0.2070], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 19 - 232: dog - cat || Loss: 1.1057841777801514\n",
      "tensor([0., 1.]) tensor([0.7925, 0.2075], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 19 - 233: dog - cat || Loss: 1.1052606105804443\n",
      "tensor([0., 1.]) tensor([0.7920, 0.2080], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 19 - 234: dog - cat || Loss: 1.104735255241394\n",
      "tensor([0., 1.]) tensor([0.7915, 0.2085], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 19 - 235: dog - cat || Loss: 1.1042078733444214\n",
      "tensor([0., 1.]) tensor([0.7909, 0.2091], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 19 - 236: dog - cat || Loss: 1.1036787033081055\n",
      "tensor([0., 1.]) tensor([0.7904, 0.2096], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 19 - 237: dog - cat || Loss: 1.1031477451324463\n",
      "tensor([0., 1.]) tensor([0.7899, 0.2101], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 19 - 238: dog - cat || Loss: 1.1026151180267334\n",
      "tensor([0., 1.]) tensor([0.7894, 0.2106], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 19 - 239: dog - cat || Loss: 1.1020809412002563\n",
      "tensor([0., 1.]) tensor([0.7888, 0.2112], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 19 - 240: dog - cat || Loss: 1.1015452146530151\n",
      "tensor([0., 1.]) tensor([0.7883, 0.2117], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 19 - 241: dog - cat || Loss: 1.1010080575942993\n",
      "tensor([0., 1.]) tensor([0.7877, 0.2123], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 19 - 242: dog - cat || Loss: 1.1004694700241089\n",
      "tensor([0., 1.]) tensor([0.7872, 0.2128], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 19 - 243: dog - cat || Loss: 1.0999295711517334\n",
      "tensor([0., 1.]) tensor([0.7867, 0.2133], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 19 - 244: dog - cat || Loss: 1.0993883609771729\n",
      "tensor([0., 1.]) tensor([0.7861, 0.2139], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 19 - 245: dog - cat || Loss: 1.0988460779190063\n",
      "tensor([0., 1.]) tensor([0.7856, 0.2144], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 19 - 246: dog - cat || Loss: 1.0983024835586548\n",
      "tensor([0., 1.]) tensor([0.7850, 0.2150], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 19 - 247: dog - cat || Loss: 1.0977575778961182\n",
      "tensor([0., 1.]) tensor([0.7845, 0.2155], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 19 - 248: dog - cat || Loss: 1.0972113609313965\n",
      "tensor([0., 1.]) tensor([0.7839, 0.2161], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 19 - 249: dog - cat || Loss: 1.0966641902923584\n",
      "tensor([0., 1.]) tensor([0.7834, 0.2166], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 19 - 250: dog - cat || Loss: 1.0961159467697144\n",
      "tensor([0., 1.]) tensor([0.7829, 0.2171], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 19 - 251: dog - cat || Loss: 1.0955665111541748\n",
      "tensor([0., 1.]) tensor([0.7823, 0.2177], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 19 - 252: dog - cat || Loss: 1.0950160026550293\n",
      "tensor([0., 1.]) tensor([0.7818, 0.2182], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 19 - 253: dog - cat || Loss: 1.0944641828536987\n",
      "tensor([0., 1.]) tensor([0.7812, 0.2188], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 19 - 254: dog - cat || Loss: 1.0939115285873413\n",
      "tensor([0., 1.]) tensor([0.7806, 0.2194], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 19 - 255: dog - cat || Loss: 1.093357801437378\n",
      "tensor([0., 1.]) tensor([0.7801, 0.2199], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 19 - 256: dog - cat || Loss: 1.0928030014038086\n",
      "tensor([0., 1.]) tensor([0.7795, 0.2205], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 19 - 257: dog - cat || Loss: 1.0922472476959229\n",
      "tensor([0., 1.]) tensor([0.7790, 0.2210], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 19 - 258: dog - cat || Loss: 1.0916904211044312\n",
      "tensor([0., 1.]) tensor([0.7784, 0.2216], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 19 - 259: dog - cat || Loss: 1.0911327600479126\n",
      "tensor([0., 1.]) tensor([0.7779, 0.2221], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 19 - 260: dog - cat || Loss: 1.0905739068984985\n",
      "tensor([0., 1.]) tensor([0.7773, 0.2227], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 19 - 261: dog - cat || Loss: 1.0900142192840576\n",
      "tensor([0., 1.]) tensor([0.7768, 0.2232], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 19 - 262: dog - cat || Loss: 1.0894534587860107\n",
      "tensor([0., 1.]) tensor([0.7762, 0.2238], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 19 - 263: dog - cat || Loss: 1.0888917446136475\n",
      "tensor([0., 1.]) tensor([0.7756, 0.2244], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 19 - 264: dog - cat || Loss: 1.0883290767669678\n",
      "tensor([0., 1.]) tensor([0.7751, 0.2249], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 19 - 265: dog - cat || Loss: 1.0877653360366821\n",
      "tensor([0., 1.]) tensor([0.7745, 0.2255], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 19 - 266: dog - cat || Loss: 1.0872007608413696\n",
      "tensor([0., 1.]) tensor([0.7739, 0.2261], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 19 - 267: dog - cat || Loss: 1.0866354703903198\n",
      "tensor([0., 1.]) tensor([0.7734, 0.2266], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 19 - 268: dog - cat || Loss: 1.086068868637085\n",
      "tensor([0., 1.]) tensor([0.7728, 0.2272], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 19 - 269: dog - cat || Loss: 1.0855015516281128\n",
      "tensor([0., 1.]) tensor([0.7722, 0.2278], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 19 - 270: dog - cat || Loss: 1.0849331617355347\n",
      "tensor([0., 1.]) tensor([0.7717, 0.2283], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 19 - 271: dog - cat || Loss: 1.0843638181686401\n",
      "tensor([0., 1.]) tensor([0.7711, 0.2289], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 19 - 272: dog - cat || Loss: 1.0837936401367188\n",
      "tensor([0., 1.]) tensor([0.7705, 0.2295], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 19 - 273: dog - cat || Loss: 1.083222508430481\n",
      "tensor([0., 1.]) tensor([0.7700, 0.2300], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 19 - 274: dog - cat || Loss: 1.0826505422592163\n",
      "tensor([0., 1.]) tensor([0.7694, 0.2306], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 19 - 275: dog - cat || Loss: 1.0820775032043457\n",
      "tensor([0., 1.]) tensor([0.7688, 0.2312], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 19 - 276: dog - cat || Loss: 1.0815036296844482\n",
      "tensor([0., 1.]) tensor([0.7682, 0.2318], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 19 - 277: dog - cat || Loss: 1.0809286832809448\n",
      "tensor([0., 1.]) tensor([0.7677, 0.2323], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 19 - 278: dog - cat || Loss: 1.0803529024124146\n",
      "tensor([0., 1.]) tensor([0.7671, 0.2329], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 19 - 279: dog - cat || Loss: 1.079776406288147\n",
      "tensor([0., 1.]) tensor([0.7665, 0.2335], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 19 - 280: dog - cat || Loss: 1.0791987180709839\n",
      "tensor([0., 1.]) tensor([0.7659, 0.2341], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 19 - 281: dog - cat || Loss: 1.078620195388794\n",
      "tensor([0., 1.]) tensor([0.7654, 0.2346], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 19 - 282: dog - cat || Loss: 1.0780408382415771\n",
      "tensor([0., 1.]) tensor([0.7648, 0.2352], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 19 - 283: dog - cat || Loss: 1.077460527420044\n",
      "tensor([0., 1.]) tensor([0.7642, 0.2358], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 19 - 284: dog - cat || Loss: 1.0768792629241943\n",
      "tensor([0., 1.]) tensor([0.7636, 0.2364], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 19 - 285: dog - cat || Loss: 1.0762971639633179\n",
      "tensor([0., 1.]) tensor([0.7630, 0.2370], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 19 - 286: dog - cat || Loss: 1.075714111328125\n",
      "tensor([0., 1.]) tensor([0.7625, 0.2375], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 19 - 287: dog - cat || Loss: 1.0751303434371948\n",
      "tensor([0., 1.]) tensor([0.7619, 0.2381], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 19 - 288: dog - cat || Loss: 1.0745453834533691\n",
      "tensor([0., 1.]) tensor([0.7613, 0.2387], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 19 - 289: dog - cat || Loss: 1.0739597082138062\n",
      "tensor([0., 1.]) tensor([0.7607, 0.2393], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 19 - 290: dog - cat || Loss: 1.0733730792999268\n",
      "tensor([0., 1.]) tensor([0.7601, 0.2399], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 19 - 291: dog - cat || Loss: 1.0727856159210205\n",
      "tensor([0., 1.]) tensor([0.7595, 0.2405], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 19 - 292: dog - cat || Loss: 1.0721970796585083\n",
      "tensor([0., 1.]) tensor([0.7589, 0.2411], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 19 - 293: dog - cat || Loss: 1.0716079473495483\n",
      "tensor([0., 1.]) tensor([0.7583, 0.2417], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 19 - 294: dog - cat || Loss: 1.0710177421569824\n",
      "tensor([0., 1.]) tensor([0.7578, 0.2422], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 19 - 295: dog - cat || Loss: 1.0704265832901\n",
      "tensor([0., 1.]) tensor([0.7572, 0.2428], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 19 - 296: dog - cat || Loss: 1.0698347091674805\n",
      "tensor([0., 1.]) tensor([0.7566, 0.2434], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 19 - 297: dog - cat || Loss: 1.0692418813705444\n",
      "tensor([0., 1.]) tensor([0.7560, 0.2440], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 19 - 298: dog - cat || Loss: 1.068648099899292\n",
      "tensor([0., 1.]) tensor([0.7554, 0.2446], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 19 - 299: dog - cat || Loss: 1.0680534839630127\n",
      "tensor([0., 1.]) tensor([0.7548, 0.2452], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 19 - 300: dog - cat || Loss: 1.067457914352417\n",
      "tensor([0., 1.]) tensor([0.7542, 0.2458], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 19 - 301: dog - cat || Loss: 1.066861629486084\n",
      "tensor([0., 1.]) tensor([0.7536, 0.2464], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 19 - 302: dog - cat || Loss: 1.0662645101547241\n",
      "tensor([0., 1.]) tensor([0.7530, 0.2470], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 19 - 303: dog - cat || Loss: 1.0656663179397583\n",
      "tensor([0., 1.]) tensor([0.7524, 0.2476], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 19 - 304: dog - cat || Loss: 1.0650672912597656\n",
      "tensor([0., 1.]) tensor([0.7518, 0.2482], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 19 - 305: dog - cat || Loss: 1.0644673109054565\n",
      "tensor([0., 1.]) tensor([0.7512, 0.2488], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 19 - 306: dog - cat || Loss: 1.0638666152954102\n",
      "tensor([0., 1.]) tensor([0.7506, 0.2494], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 19 - 307: dog - cat || Loss: 1.0632649660110474\n",
      "tensor([0., 1.]) tensor([0.7500, 0.2500], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 19 - 308: dog - cat || Loss: 1.0626623630523682\n",
      "tensor([0., 1.]) tensor([0.7494, 0.2506], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 19 - 309: dog - cat || Loss: 1.0620588064193726\n",
      "tensor([0., 1.]) tensor([0.7488, 0.2512], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 19 - 310: dog - cat || Loss: 1.06145441532135\n",
      "tensor([0., 1.]) tensor([0.7482, 0.2518], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 19 - 311: dog - cat || Loss: 1.0608491897583008\n",
      "tensor([0., 1.]) tensor([0.7476, 0.2524], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 19 - 312: dog - cat || Loss: 1.0602431297302246\n",
      "tensor([0., 1.]) tensor([0.7470, 0.2530], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 19 - 313: dog - cat || Loss: 1.059636116027832\n",
      "tensor([0., 1.]) tensor([0.7464, 0.2536], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 19 - 314: dog - cat || Loss: 1.059028148651123\n",
      "tensor([0., 1.]) tensor([0.7458, 0.2542], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 19 - 315: dog - cat || Loss: 1.0584195852279663\n",
      "tensor([0., 1.]) tensor([0.7452, 0.2548], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 19 - 316: dog - cat || Loss: 1.057809829711914\n",
      "tensor([0., 1.]) tensor([0.7445, 0.2555], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 19 - 317: dog - cat || Loss: 1.057199478149414\n",
      "tensor([0., 1.]) tensor([0.7439, 0.2561], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 19 - 318: dog - cat || Loss: 1.0565881729125977\n",
      "tensor([0., 1.]) tensor([0.7433, 0.2567], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 19 - 319: dog - cat || Loss: 1.0559760332107544\n",
      "tensor([0., 1.]) tensor([0.7427, 0.2573], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 19 - 320: dog - cat || Loss: 1.0553629398345947\n",
      "tensor([0., 1.]) tensor([0.7421, 0.2579], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 19 - 321: dog - cat || Loss: 1.0547490119934082\n",
      "tensor([0., 1.]) tensor([0.7415, 0.2585], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 19 - 322: dog - cat || Loss: 1.0541343688964844\n",
      "tensor([0., 1.]) tensor([0.7409, 0.2591], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 19 - 323: dog - cat || Loss: 1.0535187721252441\n",
      "tensor([0., 1.]) tensor([0.7403, 0.2597], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 19 - 324: dog - cat || Loss: 1.0529022216796875\n",
      "tensor([0., 1.]) tensor([0.7396, 0.2604], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 19 - 325: dog - cat || Loss: 1.0522849559783936\n",
      "tensor([0., 1.]) tensor([0.7390, 0.2610], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 19 - 326: dog - cat || Loss: 1.0516667366027832\n",
      "tensor([0., 1.]) tensor([0.7384, 0.2616], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 19 - 327: dog - cat || Loss: 1.051047682762146\n",
      "tensor([0., 1.]) tensor([0.7378, 0.2622], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 19 - 328: dog - cat || Loss: 1.0504279136657715\n",
      "tensor([0., 1.]) tensor([0.7372, 0.2628], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 19 - 329: dog - cat || Loss: 1.0498071908950806\n",
      "tensor([0., 1.]) tensor([0.7365, 0.2635], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 19 - 330: dog - cat || Loss: 1.0491856336593628\n",
      "tensor([0., 1.]) tensor([0.7359, 0.2641], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 19 - 331: dog - cat || Loss: 1.0485631227493286\n",
      "tensor([0., 1.]) tensor([0.7353, 0.2647], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 19 - 332: dog - cat || Loss: 1.0479398965835571\n",
      "tensor([0., 1.]) tensor([0.7347, 0.2653], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 19 - 333: dog - cat || Loss: 1.0473158359527588\n",
      "tensor([0., 1.]) tensor([0.7341, 0.2659], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 19 - 334: dog - cat || Loss: 1.046690821647644\n",
      "tensor([0., 1.]) tensor([0.7334, 0.2666], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 19 - 335: dog - cat || Loss: 1.046065092086792\n",
      "tensor([0., 1.]) tensor([0.7328, 0.2672], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 19 - 336: dog - cat || Loss: 1.045438528060913\n",
      "tensor([0., 1.]) tensor([0.7322, 0.2678], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 19 - 337: dog - cat || Loss: 1.0448110103607178\n",
      "tensor([0., 1.]) tensor([0.7315, 0.2685], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 19 - 338: dog - cat || Loss: 1.0441827774047852\n",
      "tensor([0., 1.]) tensor([0.7309, 0.2691], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 19 - 339: dog - cat || Loss: 1.0435537099838257\n",
      "tensor([0., 1.]) tensor([0.7303, 0.2697], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 19 - 340: dog - cat || Loss: 1.0429238080978394\n",
      "tensor([0., 1.]) tensor([0.7297, 0.2703], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 19 - 341: dog - cat || Loss: 1.0422930717468262\n",
      "tensor([0., 1.]) tensor([0.7290, 0.2710], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 19 - 342: dog - cat || Loss: 1.0416613817214966\n",
      "tensor([0., 1.]) tensor([0.7284, 0.2716], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 19 - 343: dog - cat || Loss: 1.0410290956497192\n",
      "tensor([0., 1.]) tensor([0.7278, 0.2722], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 19 - 344: dog - cat || Loss: 1.040395975112915\n",
      "tensor([0., 1.]) tensor([0.7271, 0.2729], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 19 - 345: dog - cat || Loss: 1.0397617816925049\n",
      "tensor([0., 1.]) tensor([0.7265, 0.2735], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 19 - 346: dog - cat || Loss: 1.039126992225647\n",
      "tensor([0., 1.]) tensor([0.7259, 0.2741], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 19 - 347: dog - cat || Loss: 1.0384912490844727\n",
      "tensor([0., 1.]) tensor([0.7252, 0.2748], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 19 - 348: dog - cat || Loss: 1.037854790687561\n",
      "tensor([0., 1.]) tensor([0.7246, 0.2754], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 19 - 349: dog - cat || Loss: 1.037217378616333\n",
      "tensor([0., 1.]) tensor([0.7240, 0.2760], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 19 - 350: dog - cat || Loss: 1.0365792512893677\n",
      "tensor([0., 1.]) tensor([0.7233, 0.2767], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 19 - 351: dog - cat || Loss: 1.0359402894973755\n",
      "tensor([0., 1.]) tensor([0.7227, 0.2773], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 19 - 352: dog - cat || Loss: 1.0353004932403564\n",
      "tensor([0., 1.]) tensor([0.7220, 0.2780], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 19 - 353: dog - cat || Loss: 1.0346599817276\n",
      "tensor([0., 1.]) tensor([0.7214, 0.2786], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 19 - 354: dog - cat || Loss: 1.0340185165405273\n",
      "tensor([0., 1.]) tensor([0.7208, 0.2792], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 19 - 355: dog - cat || Loss: 1.0333764553070068\n",
      "tensor([0., 1.]) tensor([0.7201, 0.2799], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 19 - 356: dog - cat || Loss: 1.0327333211898804\n",
      "tensor([0., 1.]) tensor([0.7195, 0.2805], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 19 - 357: dog - cat || Loss: 1.0320895910263062\n",
      "tensor([0., 1.]) tensor([0.7188, 0.2812], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 19 - 358: dog - cat || Loss: 1.031445026397705\n",
      "tensor([0., 1.]) tensor([0.7182, 0.2818], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 19 - 359: dog - cat || Loss: 1.0307996273040771\n",
      "tensor([0., 1.]) tensor([0.7175, 0.2825], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 19 - 360: dog - cat || Loss: 1.0301532745361328\n",
      "tensor([0., 1.]) tensor([0.7169, 0.2831], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 19 - 361: dog - cat || Loss: 1.0295062065124512\n",
      "tensor([0., 1.]) tensor([0.7162, 0.2838], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 19 - 362: dog - cat || Loss: 1.0288583040237427\n",
      "tensor([0., 1.]) tensor([0.7156, 0.2844], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 19 - 363: dog - cat || Loss: 1.0282096862792969\n",
      "tensor([0., 1.]) tensor([0.7149, 0.2851], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 19 - 364: dog - cat || Loss: 1.0275599956512451\n",
      "tensor([0., 1.]) tensor([0.7143, 0.2857], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 19 - 365: dog - cat || Loss: 1.0269098281860352\n",
      "tensor([0., 1.]) tensor([0.7136, 0.2864], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 19 - 366: dog - cat || Loss: 1.0262585878372192\n",
      "tensor([0., 1.]) tensor([0.7130, 0.2870], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 19 - 367: dog - cat || Loss: 1.025606632232666\n",
      "tensor([0., 1.]) tensor([0.7123, 0.2877], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 19 - 368: dog - cat || Loss: 1.024953842163086\n",
      "tensor([0., 1.]) tensor([0.7117, 0.2883], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 19 - 369: dog - cat || Loss: 1.0243000984191895\n",
      "tensor([0., 1.]) tensor([0.7110, 0.2890], grad_fn=<SoftmaxBackward0>)\n",
      "=====epoch:20=====\n",
      "Epoch 20 - 0: cat - cat || Loss: 0.6028775572776794\n",
      "tensor([1., 0.]) tensor([0.7104, 0.2896], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 20 - 1: cat - cat || Loss: 0.6034008264541626\n",
      "tensor([1., 0.]) tensor([0.7099, 0.2901], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 20 - 2: cat - cat || Loss: 0.6038061380386353\n",
      "tensor([1., 0.]) tensor([0.7095, 0.2905], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 20 - 3: cat - cat || Loss: 0.6041049957275391\n",
      "tensor([1., 0.]) tensor([0.7092, 0.2908], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 20 - 4: cat - cat || Loss: 0.6043078899383545\n",
      "tensor([1., 0.]) tensor([0.7090, 0.2910], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 20 - 5: cat - cat || Loss: 0.6044245958328247\n",
      "tensor([1., 0.]) tensor([0.7088, 0.2912], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 20 - 6: cat - cat || Loss: 0.604463517665863\n",
      "tensor([1., 0.]) tensor([0.7088, 0.2912], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 20 - 7: cat - cat || Loss: 0.6044324636459351\n",
      "tensor([1., 0.]) tensor([0.7088, 0.2912], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 20 - 8: cat - cat || Loss: 0.6043384075164795\n",
      "tensor([1., 0.]) tensor([0.7089, 0.2911], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 20 - 9: cat - cat || Loss: 0.6041878461837769\n",
      "tensor([1., 0.]) tensor([0.7091, 0.2909], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 20 - 10: cat - cat || Loss: 0.6039862632751465\n",
      "tensor([1., 0.]) tensor([0.7093, 0.2907], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 20 - 11: cat - cat || Loss: 0.6037390232086182\n",
      "tensor([1., 0.]) tensor([0.7095, 0.2905], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 20 - 12: cat - cat || Loss: 0.6034505367279053\n",
      "tensor([1., 0.]) tensor([0.7098, 0.2902], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 20 - 13: cat - cat || Loss: 0.6031250953674316\n",
      "tensor([1., 0.]) tensor([0.7101, 0.2899], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 20 - 14: cat - cat || Loss: 0.6027664542198181\n",
      "tensor([1., 0.]) tensor([0.7105, 0.2895], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 20 - 15: cat - cat || Loss: 0.6023779511451721\n",
      "tensor([1., 0.]) tensor([0.7109, 0.2891], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 20 - 16: cat - cat || Loss: 0.601962685585022\n",
      "tensor([1., 0.]) tensor([0.7113, 0.2887], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 20 - 17: cat - cat || Loss: 0.6015233993530273\n",
      "tensor([1., 0.]) tensor([0.7117, 0.2883], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 20 - 18: cat - cat || Loss: 0.6010625958442688\n",
      "tensor([1., 0.]) tensor([0.7122, 0.2878], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 20 - 19: cat - cat || Loss: 0.6005823612213135\n",
      "tensor([1., 0.]) tensor([0.7127, 0.2873], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 20 - 20: cat - cat || Loss: 0.6000848412513733\n",
      "tensor([1., 0.]) tensor([0.7132, 0.2868], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 20 - 21: cat - cat || Loss: 0.599571943283081\n",
      "tensor([1., 0.]) tensor([0.7137, 0.2863], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 20 - 22: cat - cat || Loss: 0.5990453958511353\n",
      "tensor([1., 0.]) tensor([0.7142, 0.2858], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 20 - 23: cat - cat || Loss: 0.5985063314437866\n",
      "tensor([1., 0.]) tensor([0.7148, 0.2852], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 20 - 24: cat - cat || Loss: 0.5979560613632202\n",
      "tensor([1., 0.]) tensor([0.7153, 0.2847], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 20 - 25: cat - cat || Loss: 0.5973960161209106\n",
      "tensor([1., 0.]) tensor([0.7159, 0.2841], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 20 - 26: cat - cat || Loss: 0.5968271493911743\n",
      "tensor([1., 0.]) tensor([0.7164, 0.2836], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 20 - 27: cat - cat || Loss: 0.5962504148483276\n",
      "tensor([1., 0.]) tensor([0.7170, 0.2830], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 20 - 28: cat - cat || Loss: 0.5956667065620422\n",
      "tensor([1., 0.]) tensor([0.7176, 0.2824], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 20 - 29: cat - cat || Loss: 0.5950766205787659\n",
      "tensor([1., 0.]) tensor([0.7182, 0.2818], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 20 - 30: cat - cat || Loss: 0.5944812297821045\n",
      "tensor([1., 0.]) tensor([0.7188, 0.2812], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 20 - 31: cat - cat || Loss: 0.5938807725906372\n",
      "tensor([1., 0.]) tensor([0.7194, 0.2806], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 20 - 32: cat - cat || Loss: 0.5932761430740356\n",
      "tensor([1., 0.]) tensor([0.7200, 0.2800], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 20 - 33: cat - cat || Loss: 0.5926677584648132\n",
      "tensor([1., 0.]) tensor([0.7206, 0.2794], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 20 - 34: cat - cat || Loss: 0.5920559763908386\n",
      "tensor([1., 0.]) tensor([0.7212, 0.2788], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 20 - 35: cat - cat || Loss: 0.5914412140846252\n",
      "tensor([1., 0.]) tensor([0.7218, 0.2782], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 20 - 36: cat - cat || Loss: 0.5908240675926208\n",
      "tensor([1., 0.]) tensor([0.7224, 0.2776], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 20 - 37: cat - cat || Loss: 0.5902045965194702\n",
      "tensor([1., 0.]) tensor([0.7231, 0.2769], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 20 - 38: cat - cat || Loss: 0.5895832777023315\n",
      "tensor([1., 0.]) tensor([0.7237, 0.2763], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 20 - 39: cat - cat || Loss: 0.5889602899551392\n",
      "tensor([1., 0.]) tensor([0.7243, 0.2757], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 20 - 40: cat - cat || Loss: 0.588336169719696\n",
      "tensor([1., 0.]) tensor([0.7249, 0.2751], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 20 - 41: cat - cat || Loss: 0.5877106189727783\n",
      "tensor([1., 0.]) tensor([0.7256, 0.2744], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 20 - 42: cat - cat || Loss: 0.5870843529701233\n",
      "tensor([1., 0.]) tensor([0.7262, 0.2738], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 20 - 43: cat - cat || Loss: 0.5864571928977966\n",
      "tensor([1., 0.]) tensor([0.7268, 0.2732], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 20 - 44: cat - cat || Loss: 0.5858295559883118\n",
      "tensor([1., 0.]) tensor([0.7274, 0.2726], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 20 - 45: cat - cat || Loss: 0.5852013826370239\n",
      "tensor([1., 0.]) tensor([0.7281, 0.2719], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 20 - 46: cat - cat || Loss: 0.5845728516578674\n",
      "tensor([1., 0.]) tensor([0.7287, 0.2713], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 20 - 47: cat - cat || Loss: 0.5839442610740662\n",
      "tensor([1., 0.]) tensor([0.7293, 0.2707], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 20 - 48: cat - cat || Loss: 0.5833154916763306\n",
      "tensor([1., 0.]) tensor([0.7299, 0.2701], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 20 - 49: cat - cat || Loss: 0.582686722278595\n",
      "tensor([1., 0.]) tensor([0.7306, 0.2694], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 20 - 50: cat - cat || Loss: 0.5820580720901489\n",
      "tensor([1., 0.]) tensor([0.7312, 0.2688], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 20 - 51: cat - cat || Loss: 0.5814296007156372\n",
      "tensor([1., 0.]) tensor([0.7318, 0.2682], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 20 - 52: cat - cat || Loss: 0.5808013081550598\n",
      "tensor([1., 0.]) tensor([0.7325, 0.2675], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 20 - 53: cat - cat || Loss: 0.5801733136177063\n",
      "tensor([1., 0.]) tensor([0.7331, 0.2669], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 20 - 54: cat - cat || Loss: 0.5795457363128662\n",
      "tensor([1., 0.]) tensor([0.7337, 0.2663], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 20 - 55: cat - cat || Loss: 0.57891845703125\n",
      "tensor([1., 0.]) tensor([0.7343, 0.2657], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 20 - 56: cat - cat || Loss: 0.5782917737960815\n",
      "tensor([1., 0.]) tensor([0.7350, 0.2650], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 20 - 57: cat - cat || Loss: 0.5776654481887817\n",
      "tensor([1., 0.]) tensor([0.7356, 0.2644], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 20 - 58: cat - cat || Loss: 0.5770398378372192\n",
      "tensor([1., 0.]) tensor([0.7362, 0.2638], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 20 - 59: cat - cat || Loss: 0.5764147043228149\n",
      "tensor([1., 0.]) tensor([0.7368, 0.2632], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 20 - 60: cat - cat || Loss: 0.5757901668548584\n",
      "tensor([1., 0.]) tensor([0.7375, 0.2625], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 20 - 61: cat - cat || Loss: 0.5751662254333496\n",
      "tensor([1., 0.]) tensor([0.7381, 0.2619], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 20 - 62: cat - cat || Loss: 0.5745431184768677\n",
      "tensor([1., 0.]) tensor([0.7387, 0.2613], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 20 - 63: cat - cat || Loss: 0.5739206671714783\n",
      "tensor([1., 0.]) tensor([0.7393, 0.2607], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 20 - 64: cat - cat || Loss: 0.5732986927032471\n",
      "tensor([1., 0.]) tensor([0.7400, 0.2600], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 20 - 65: cat - cat || Loss: 0.5726776719093323\n",
      "tensor([1., 0.]) tensor([0.7406, 0.2594], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 20 - 66: cat - cat || Loss: 0.5720573663711548\n",
      "tensor([1., 0.]) tensor([0.7412, 0.2588], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 20 - 67: cat - cat || Loss: 0.5714378356933594\n",
      "tensor([1., 0.]) tensor([0.7418, 0.2582], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 20 - 68: cat - cat || Loss: 0.5708190202713013\n",
      "tensor([1., 0.]) tensor([0.7424, 0.2576], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 20 - 69: cat - cat || Loss: 0.5702009201049805\n",
      "tensor([1., 0.]) tensor([0.7431, 0.2569], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 20 - 70: cat - cat || Loss: 0.5695837736129761\n",
      "tensor([1., 0.]) tensor([0.7437, 0.2563], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 20 - 71: cat - cat || Loss: 0.5689674019813538\n",
      "tensor([1., 0.]) tensor([0.7443, 0.2557], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 20 - 72: cat - cat || Loss: 0.568351686000824\n",
      "tensor([1., 0.]) tensor([0.7449, 0.2551], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 20 - 73: cat - cat || Loss: 0.5677369832992554\n",
      "tensor([1., 0.]) tensor([0.7455, 0.2545], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 20 - 74: cat - cat || Loss: 0.5671230554580688\n",
      "tensor([1., 0.]) tensor([0.7461, 0.2539], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 20 - 75: cat - cat || Loss: 0.566510021686554\n",
      "tensor([1., 0.]) tensor([0.7468, 0.2532], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 20 - 76: cat - cat || Loss: 0.5658978223800659\n",
      "tensor([1., 0.]) tensor([0.7474, 0.2526], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 20 - 77: cat - cat || Loss: 0.5652865171432495\n",
      "tensor([1., 0.]) tensor([0.7480, 0.2520], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 20 - 78: cat - cat || Loss: 0.5646759271621704\n",
      "tensor([1., 0.]) tensor([0.7486, 0.2514], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 20 - 79: cat - cat || Loss: 0.5640663504600525\n",
      "tensor([1., 0.]) tensor([0.7492, 0.2508], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 20 - 80: cat - cat || Loss: 0.5634575486183167\n",
      "tensor([1., 0.]) tensor([0.7498, 0.2502], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 20 - 81: cat - cat || Loss: 0.5628497004508972\n",
      "tensor([1., 0.]) tensor([0.7504, 0.2496], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 20 - 82: cat - cat || Loss: 0.5622428059577942\n",
      "tensor([1., 0.]) tensor([0.7510, 0.2490], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 20 - 83: cat - cat || Loss: 0.561636745929718\n",
      "tensor([1., 0.]) tensor([0.7516, 0.2484], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 20 - 84: cat - cat || Loss: 0.5610316395759583\n",
      "tensor([1., 0.]) tensor([0.7522, 0.2478], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 20 - 85: cat - cat || Loss: 0.5604274272918701\n",
      "tensor([1., 0.]) tensor([0.7528, 0.2472], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 20 - 86: cat - cat || Loss: 0.5598241090774536\n",
      "tensor([1., 0.]) tensor([0.7534, 0.2466], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 20 - 87: cat - cat || Loss: 0.559221625328064\n",
      "tensor([1., 0.]) tensor([0.7540, 0.2460], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 20 - 88: cat - cat || Loss: 0.5586201548576355\n",
      "tensor([1., 0.]) tensor([0.7546, 0.2454], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 20 - 89: cat - cat || Loss: 0.5580195188522339\n",
      "tensor([1., 0.]) tensor([0.7552, 0.2448], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 20 - 90: cat - cat || Loss: 0.5574197769165039\n",
      "tensor([1., 0.]) tensor([0.7558, 0.2442], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 20 - 91: cat - cat || Loss: 0.5568209886550903\n",
      "tensor([1., 0.]) tensor([0.7564, 0.2436], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 20 - 92: cat - cat || Loss: 0.5562230348587036\n",
      "tensor([1., 0.]) tensor([0.7570, 0.2430], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 20 - 93: cat - cat || Loss: 0.5556260347366333\n",
      "tensor([1., 0.]) tensor([0.7576, 0.2424], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 20 - 94: cat - cat || Loss: 0.5550298690795898\n",
      "tensor([1., 0.]) tensor([0.7582, 0.2418], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 20 - 95: cat - cat || Loss: 0.5544347167015076\n",
      "tensor([1., 0.]) tensor([0.7588, 0.2412], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 20 - 96: cat - cat || Loss: 0.5538403987884521\n",
      "tensor([1., 0.]) tensor([0.7594, 0.2406], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 20 - 97: cat - cat || Loss: 0.5532470941543579\n",
      "tensor([1., 0.]) tensor([0.7600, 0.2400], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 20 - 98: cat - cat || Loss: 0.5526546239852905\n",
      "tensor([1., 0.]) tensor([0.7606, 0.2394], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 20 - 99: cat - cat || Loss: 0.5520631074905396\n",
      "tensor([1., 0.]) tensor([0.7612, 0.2388], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 20 - 100: cat - cat || Loss: 0.551472544670105\n",
      "tensor([1., 0.]) tensor([0.7618, 0.2382], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 20 - 101: cat - cat || Loss: 0.550882875919342\n",
      "tensor([1., 0.]) tensor([0.7624, 0.2376], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 20 - 102: cat - cat || Loss: 0.5502941608428955\n",
      "tensor([1., 0.]) tensor([0.7630, 0.2370], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 20 - 103: cat - cat || Loss: 0.5497063398361206\n",
      "tensor([1., 0.]) tensor([0.7636, 0.2364], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 20 - 104: cat - cat || Loss: 0.5491194725036621\n",
      "tensor([1., 0.]) tensor([0.7641, 0.2359], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 20 - 105: cat - cat || Loss: 0.54853355884552\n",
      "tensor([1., 0.]) tensor([0.7647, 0.2353], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 20 - 106: cat - cat || Loss: 0.5479484796524048\n",
      "tensor([1., 0.]) tensor([0.7653, 0.2347], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 20 - 107: cat - cat || Loss: 0.547364354133606\n",
      "tensor([1., 0.]) tensor([0.7659, 0.2341], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 20 - 108: cat - cat || Loss: 0.5467812418937683\n",
      "tensor([1., 0.]) tensor([0.7665, 0.2335], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 20 - 109: cat - cat || Loss: 0.5461990833282471\n",
      "tensor([1., 0.]) tensor([0.7671, 0.2329], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 20 - 110: cat - cat || Loss: 0.5456177592277527\n",
      "tensor([1., 0.]) tensor([0.7676, 0.2324], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 20 - 111: cat - cat || Loss: 0.5450374484062195\n",
      "tensor([1., 0.]) tensor([0.7682, 0.2318], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 20 - 112: cat - cat || Loss: 0.5444579720497131\n",
      "tensor([1., 0.]) tensor([0.7688, 0.2312], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 20 - 113: cat - cat || Loss: 0.5438794493675232\n",
      "tensor([1., 0.]) tensor([0.7694, 0.2306], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 20 - 114: cat - cat || Loss: 0.5433019995689392\n",
      "tensor([1., 0.]) tensor([0.7700, 0.2300], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 20 - 115: cat - cat || Loss: 0.5427255034446716\n",
      "tensor([1., 0.]) tensor([0.7705, 0.2295], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 20 - 116: cat - cat || Loss: 0.5421499013900757\n",
      "tensor([1., 0.]) tensor([0.7711, 0.2289], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 20 - 117: cat - cat || Loss: 0.5415753126144409\n",
      "tensor([1., 0.]) tensor([0.7717, 0.2283], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 20 - 118: cat - cat || Loss: 0.541001558303833\n",
      "tensor([1., 0.]) tensor([0.7723, 0.2277], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 20 - 119: cat - cat || Loss: 0.540428876876831\n",
      "tensor([1., 0.]) tensor([0.7728, 0.2272], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 20 - 120: cat - cat || Loss: 0.539857029914856\n",
      "tensor([1., 0.]) tensor([0.7734, 0.2266], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 20 - 121: cat - cat || Loss: 0.5392860770225525\n",
      "tensor([1., 0.]) tensor([0.7740, 0.2260], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 20 - 122: cat - cat || Loss: 0.5387163162231445\n",
      "tensor([1., 0.]) tensor([0.7745, 0.2255], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 20 - 123: cat - cat || Loss: 0.5381473302841187\n",
      "tensor([1., 0.]) tensor([0.7751, 0.2249], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 20 - 124: cat - cat || Loss: 0.5375794172286987\n",
      "tensor([1., 0.]) tensor([0.7757, 0.2243], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 20 - 125: cat - cat || Loss: 0.5370123982429504\n",
      "tensor([1., 0.]) tensor([0.7762, 0.2238], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 20 - 126: cat - cat || Loss: 0.5364463329315186\n",
      "tensor([1., 0.]) tensor([0.7768, 0.2232], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 20 - 127: cat - cat || Loss: 0.5358811616897583\n",
      "tensor([1., 0.]) tensor([0.7774, 0.2226], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 20 - 128: cat - cat || Loss: 0.5353169441223145\n",
      "tensor([1., 0.]) tensor([0.7779, 0.2221], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 20 - 129: cat - cat || Loss: 0.534753680229187\n",
      "tensor([1., 0.]) tensor([0.7785, 0.2215], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 20 - 130: cat - cat || Loss: 0.5341914892196655\n",
      "tensor([1., 0.]) tensor([0.7791, 0.2209], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 20 - 131: cat - cat || Loss: 0.5336301326751709\n",
      "tensor([1., 0.]) tensor([0.7796, 0.2204], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 20 - 132: cat - cat || Loss: 0.5330697298049927\n",
      "tensor([1., 0.]) tensor([0.7802, 0.2198], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 20 - 133: cat - cat || Loss: 0.5325103998184204\n",
      "tensor([1., 0.]) tensor([0.7808, 0.2192], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 20 - 134: cat - cat || Loss: 0.531951904296875\n",
      "tensor([1., 0.]) tensor([0.7813, 0.2187], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 20 - 135: cat - cat || Loss: 0.5313945412635803\n",
      "tensor([1., 0.]) tensor([0.7819, 0.2181], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 20 - 136: cat - cat || Loss: 0.5308380126953125\n",
      "tensor([1., 0.]) tensor([0.7824, 0.2176], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 20 - 137: cat - cat || Loss: 0.5302824974060059\n",
      "tensor([1., 0.]) tensor([0.7830, 0.2170], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 20 - 138: cat - cat || Loss: 0.5297279357910156\n",
      "tensor([1., 0.]) tensor([0.7835, 0.2165], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 20 - 139: cat - cat || Loss: 0.5291743278503418\n",
      "tensor([1., 0.]) tensor([0.7841, 0.2159], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 20 - 140: cat - cat || Loss: 0.5286216139793396\n",
      "tensor([1., 0.]) tensor([0.7846, 0.2154], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 20 - 141: cat - cat || Loss: 0.5280699729919434\n",
      "tensor([1., 0.]) tensor([0.7852, 0.2148], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 20 - 142: cat - cat || Loss: 0.5275192856788635\n",
      "tensor([1., 0.]) tensor([0.7857, 0.2143], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 20 - 143: cat - cat || Loss: 0.5269696116447449\n",
      "tensor([1., 0.]) tensor([0.7863, 0.2137], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 20 - 144: cat - cat || Loss: 0.5264208912849426\n",
      "tensor([1., 0.]) tensor([0.7868, 0.2132], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 20 - 145: cat - cat || Loss: 0.525873064994812\n",
      "tensor([1., 0.]) tensor([0.7874, 0.2126], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 20 - 146: cat - cat || Loss: 0.5253263115882874\n",
      "tensor([1., 0.]) tensor([0.7879, 0.2121], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 20 - 147: cat - cat || Loss: 0.5247805118560791\n",
      "tensor([1., 0.]) tensor([0.7885, 0.2115], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 20 - 148: cat - cat || Loss: 0.524235725402832\n",
      "tensor([1., 0.]) tensor([0.7890, 0.2110], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 20 - 149: cat - cat || Loss: 0.5236918330192566\n",
      "tensor([1., 0.]) tensor([0.7896, 0.2104], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 20 - 150: cat - cat || Loss: 0.5231488943099976\n",
      "tensor([1., 0.]) tensor([0.7901, 0.2099], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 20 - 151: cat - cat || Loss: 0.5226070284843445\n",
      "tensor([1., 0.]) tensor([0.7907, 0.2093], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 20 - 152: cat - cat || Loss: 0.5220661163330078\n",
      "tensor([1., 0.]) tensor([0.7912, 0.2088], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 20 - 153: cat - cat || Loss: 0.5215260982513428\n",
      "tensor([1., 0.]) tensor([0.7917, 0.2083], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 20 - 154: cat - cat || Loss: 0.5209870934486389\n",
      "tensor([1., 0.]) tensor([0.7923, 0.2077], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 20 - 155: cat - cat || Loss: 0.5204490423202515\n",
      "tensor([1., 0.]) tensor([0.7928, 0.2072], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 20 - 156: cat - cat || Loss: 0.5199120044708252\n",
      "tensor([1., 0.]) tensor([0.7933, 0.2067], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 20 - 157: cat - cat || Loss: 0.5193759799003601\n",
      "tensor([1., 0.]) tensor([0.7939, 0.2061], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 20 - 158: cat - cat || Loss: 0.5188408493995667\n",
      "tensor([1., 0.]) tensor([0.7944, 0.2056], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 20 - 159: cat - cat || Loss: 0.5183066129684448\n",
      "tensor([1., 0.]) tensor([0.7950, 0.2050], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 20 - 160: cat - cat || Loss: 0.517773449420929\n",
      "tensor([1., 0.]) tensor([0.7955, 0.2045], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 20 - 161: cat - cat || Loss: 0.5172412395477295\n",
      "tensor([1., 0.]) tensor([0.7960, 0.2040], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 20 - 162: cat - cat || Loss: 0.5167101621627808\n",
      "tensor([1., 0.]) tensor([0.7966, 0.2034], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 20 - 163: cat - cat || Loss: 0.5161798000335693\n",
      "tensor([1., 0.]) tensor([0.7971, 0.2029], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 20 - 164: cat - cat || Loss: 0.5156505107879639\n",
      "tensor([1., 0.]) tensor([0.7976, 0.2024], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 20 - 165: cat - cat || Loss: 0.5151222944259644\n",
      "tensor([1., 0.]) tensor([0.7981, 0.2019], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 20 - 166: cat - cat || Loss: 0.5145949125289917\n",
      "tensor([1., 0.]) tensor([0.7987, 0.2013], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 20 - 167: cat - cat || Loss: 0.5140684843063354\n",
      "tensor([1., 0.]) tensor([0.7992, 0.2008], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 20 - 168: cat - cat || Loss: 0.5135431885719299\n",
      "tensor([1., 0.]) tensor([0.7997, 0.2003], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 20 - 169: cat - cat || Loss: 0.5130186080932617\n",
      "tensor([1., 0.]) tensor([0.8002, 0.1998], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 20 - 170: cat - cat || Loss: 0.512495219707489\n",
      "tensor([1., 0.]) tensor([0.8008, 0.1992], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 20 - 171: cat - cat || Loss: 0.5119727253913879\n",
      "tensor([1., 0.]) tensor([0.8013, 0.1987], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 20 - 172: cat - cat || Loss: 0.5114513039588928\n",
      "tensor([1., 0.]) tensor([0.8018, 0.1982], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 20 - 173: cat - cat || Loss: 0.5109307765960693\n",
      "tensor([1., 0.]) tensor([0.8023, 0.1977], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 20 - 174: cat - cat || Loss: 0.5104111433029175\n",
      "tensor([1., 0.]) tensor([0.8029, 0.1971], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 20 - 175: cat - cat || Loss: 0.5098925232887268\n",
      "tensor([1., 0.]) tensor([0.8034, 0.1966], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 20 - 176: cat - cat || Loss: 0.5093749165534973\n",
      "tensor([1., 0.]) tensor([0.8039, 0.1961], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 20 - 177: cat - cat || Loss: 0.5088582634925842\n",
      "tensor([1., 0.]) tensor([0.8044, 0.1956], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 20 - 178: cat - cat || Loss: 0.5083426237106323\n",
      "tensor([1., 0.]) tensor([0.8049, 0.1951], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 20 - 179: cat - cat || Loss: 0.5078279376029968\n",
      "tensor([1., 0.]) tensor([0.8054, 0.1946], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 20 - 180: cat - cat || Loss: 0.5073142647743225\n",
      "tensor([1., 0.]) tensor([0.8059, 0.1941], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 20 - 181: cat - cat || Loss: 0.5068016052246094\n",
      "tensor([1., 0.]) tensor([0.8065, 0.1935], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 20 - 182: cat - cat || Loss: 0.5062898397445679\n",
      "tensor([1., 0.]) tensor([0.8070, 0.1930], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 20 - 183: cat - cat || Loss: 0.5057792663574219\n",
      "tensor([1., 0.]) tensor([0.8075, 0.1925], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 20 - 184: cat - cat || Loss: 0.505269467830658\n",
      "tensor([1., 0.]) tensor([0.8080, 0.1920], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 20 - 185: cat - cat || Loss: 0.5047607421875\n",
      "tensor([1., 0.]) tensor([0.8085, 0.1915], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 20 - 186: cat - cat || Loss: 0.5042529106140137\n",
      "tensor([1., 0.]) tensor([0.8090, 0.1910], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 20 - 187: cat - cat || Loss: 0.5037461519241333\n",
      "tensor([1., 0.]) tensor([0.8095, 0.1905], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 20 - 188: cat - cat || Loss: 0.5032403469085693\n",
      "tensor([1., 0.]) tensor([0.8100, 0.1900], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 20 - 189: cat - cat || Loss: 0.5027355551719666\n",
      "tensor([1., 0.]) tensor([0.8105, 0.1895], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 20 - 190: dog - cat || Loss: 1.1242917776107788\n",
      "tensor([0., 1.]) tensor([0.8110, 0.1890], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 20 - 191: dog - cat || Loss: 1.12469482421875\n",
      "tensor([0., 1.]) tensor([0.8114, 0.1886], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 20 - 192: dog - cat || Loss: 1.1250075101852417\n",
      "tensor([0., 1.]) tensor([0.8117, 0.1883], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 20 - 193: dog - cat || Loss: 1.1252391338348389\n",
      "tensor([0., 1.]) tensor([0.8120, 0.1880], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 20 - 194: dog - cat || Loss: 1.125397801399231\n",
      "tensor([0., 1.]) tensor([0.8121, 0.1879], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 20 - 195: dog - cat || Loss: 1.1254909038543701\n",
      "tensor([0., 1.]) tensor([0.8122, 0.1878], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 20 - 196: dog - cat || Loss: 1.1255249977111816\n",
      "tensor([0., 1.]) tensor([0.8123, 0.1877], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 20 - 197: dog - cat || Loss: 1.125506043434143\n",
      "tensor([0., 1.]) tensor([0.8122, 0.1878], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 20 - 198: dog - cat || Loss: 1.1254394054412842\n",
      "tensor([0., 1.]) tensor([0.8122, 0.1878], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 20 - 199: dog - cat || Loss: 1.125329613685608\n",
      "tensor([0., 1.]) tensor([0.8121, 0.1879], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 20 - 200: dog - cat || Loss: 1.1251811981201172\n",
      "tensor([0., 1.]) tensor([0.8119, 0.1881], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 20 - 201: dog - cat || Loss: 1.1249977350234985\n",
      "tensor([0., 1.]) tensor([0.8117, 0.1883], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 20 - 202: dog - cat || Loss: 1.124782919883728\n",
      "tensor([0., 1.]) tensor([0.8115, 0.1885], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 20 - 203: dog - cat || Loss: 1.124539852142334\n",
      "tensor([0., 1.]) tensor([0.8113, 0.1887], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 20 - 204: dog - cat || Loss: 1.1242709159851074\n",
      "tensor([0., 1.]) tensor([0.8110, 0.1890], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 20 - 205: dog - cat || Loss: 1.123978853225708\n",
      "tensor([0., 1.]) tensor([0.8107, 0.1893], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 20 - 206: dog - cat || Loss: 1.1236658096313477\n",
      "tensor([0., 1.]) tensor([0.8104, 0.1896], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 20 - 207: dog - cat || Loss: 1.1233341693878174\n",
      "tensor([0., 1.]) tensor([0.8101, 0.1899], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 20 - 208: dog - cat || Loss: 1.1229852437973022\n",
      "tensor([0., 1.]) tensor([0.8097, 0.1903], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 20 - 209: dog - cat || Loss: 1.1226208209991455\n",
      "tensor([0., 1.]) tensor([0.8094, 0.1906], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 20 - 210: dog - cat || Loss: 1.1222426891326904\n",
      "tensor([0., 1.]) tensor([0.8090, 0.1910], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 20 - 211: dog - cat || Loss: 1.1218515634536743\n",
      "tensor([0., 1.]) tensor([0.8086, 0.1914], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 20 - 212: dog - cat || Loss: 1.1214488744735718\n",
      "tensor([0., 1.]) tensor([0.8082, 0.1918], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 20 - 213: dog - cat || Loss: 1.1210358142852783\n",
      "tensor([0., 1.]) tensor([0.8078, 0.1922], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 20 - 214: dog - cat || Loss: 1.1206134557724\n",
      "tensor([0., 1.]) tensor([0.8074, 0.1926], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 20 - 215: dog - cat || Loss: 1.1201822757720947\n",
      "tensor([0., 1.]) tensor([0.8069, 0.1931], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 20 - 216: dog - cat || Loss: 1.1197433471679688\n",
      "tensor([0., 1.]) tensor([0.8065, 0.1935], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 20 - 217: dog - cat || Loss: 1.1192970275878906\n",
      "tensor([0., 1.]) tensor([0.8060, 0.1940], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 20 - 218: dog - cat || Loss: 1.1188442707061768\n",
      "tensor([0., 1.]) tensor([0.8056, 0.1944], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 20 - 219: dog - cat || Loss: 1.118385672569275\n",
      "tensor([0., 1.]) tensor([0.8051, 0.1949], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 20 - 220: dog - cat || Loss: 1.1179213523864746\n",
      "tensor([0., 1.]) tensor([0.8047, 0.1953], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 20 - 221: dog - cat || Loss: 1.1174521446228027\n",
      "tensor([0., 1.]) tensor([0.8042, 0.1958], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 20 - 222: dog - cat || Loss: 1.1169782876968384\n",
      "tensor([0., 1.]) tensor([0.8037, 0.1963], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 20 - 223: dog - cat || Loss: 1.1165001392364502\n",
      "tensor([0., 1.]) tensor([0.8032, 0.1968], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 20 - 224: dog - cat || Loss: 1.1160180568695068\n",
      "tensor([0., 1.]) tensor([0.8028, 0.1972], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 20 - 225: dog - cat || Loss: 1.1155325174331665\n",
      "tensor([0., 1.]) tensor([0.8023, 0.1977], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 20 - 226: dog - cat || Loss: 1.1150435209274292\n",
      "tensor([0., 1.]) tensor([0.8018, 0.1982], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 20 - 227: dog - cat || Loss: 1.1145515441894531\n",
      "tensor([0., 1.]) tensor([0.8013, 0.1987], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 20 - 228: dog - cat || Loss: 1.1140565872192383\n",
      "tensor([0., 1.]) tensor([0.8008, 0.1992], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 20 - 229: dog - cat || Loss: 1.1135590076446533\n",
      "tensor([0., 1.]) tensor([0.8003, 0.1997], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 20 - 230: dog - cat || Loss: 1.1130588054656982\n",
      "tensor([0., 1.]) tensor([0.7998, 0.2002], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 20 - 231: dog - cat || Loss: 1.1125563383102417\n",
      "tensor([0., 1.]) tensor([0.7993, 0.2007], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 20 - 232: dog - cat || Loss: 1.1120513677597046\n",
      "tensor([0., 1.]) tensor([0.7988, 0.2012], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 20 - 233: dog - cat || Loss: 1.1115447282791138\n",
      "tensor([0., 1.]) tensor([0.7983, 0.2017], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 20 - 234: dog - cat || Loss: 1.111035943031311\n",
      "tensor([0., 1.]) tensor([0.7978, 0.2022], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 20 - 235: dog - cat || Loss: 1.110525369644165\n",
      "tensor([0., 1.]) tensor([0.7973, 0.2027], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 20 - 236: dog - cat || Loss: 1.1100130081176758\n",
      "tensor([0., 1.]) tensor([0.7968, 0.2032], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 20 - 237: dog - cat || Loss: 1.1094989776611328\n",
      "tensor([0., 1.]) tensor([0.7962, 0.2038], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 20 - 238: dog - cat || Loss: 1.1089832782745361\n",
      "tensor([0., 1.]) tensor([0.7957, 0.2043], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 20 - 239: dog - cat || Loss: 1.1084661483764648\n",
      "tensor([0., 1.]) tensor([0.7952, 0.2048], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 20 - 240: dog - cat || Loss: 1.1079473495483398\n",
      "tensor([0., 1.]) tensor([0.7947, 0.2053], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 20 - 241: dog - cat || Loss: 1.1074272394180298\n",
      "tensor([0., 1.]) tensor([0.7942, 0.2058], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 20 - 242: dog - cat || Loss: 1.1069056987762451\n",
      "tensor([0., 1.]) tensor([0.7936, 0.2064], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 20 - 243: dog - cat || Loss: 1.1063827276229858\n",
      "tensor([0., 1.]) tensor([0.7931, 0.2069], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 20 - 244: dog - cat || Loss: 1.1058586835861206\n",
      "tensor([0., 1.]) tensor([0.7926, 0.2074], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 20 - 245: dog - cat || Loss: 1.1053334474563599\n",
      "tensor([0., 1.]) tensor([0.7921, 0.2079], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 20 - 246: dog - cat || Loss: 1.1048067808151245\n",
      "tensor([0., 1.]) tensor([0.7915, 0.2085], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 20 - 247: dog - cat || Loss: 1.1042789220809937\n",
      "tensor([0., 1.]) tensor([0.7910, 0.2090], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 20 - 248: dog - cat || Loss: 1.1037499904632568\n",
      "tensor([0., 1.]) tensor([0.7905, 0.2095], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 20 - 249: dog - cat || Loss: 1.1032196283340454\n",
      "tensor([0., 1.]) tensor([0.7900, 0.2100], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 20 - 250: dog - cat || Loss: 1.1026884317398071\n",
      "tensor([0., 1.]) tensor([0.7894, 0.2106], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 20 - 251: dog - cat || Loss: 1.102156162261963\n",
      "tensor([0., 1.]) tensor([0.7889, 0.2111], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 20 - 252: dog - cat || Loss: 1.1016227006912231\n",
      "tensor([0., 1.]) tensor([0.7884, 0.2116], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 20 - 253: dog - cat || Loss: 1.101088047027588\n",
      "tensor([0., 1.]) tensor([0.7878, 0.2122], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 20 - 254: dog - cat || Loss: 1.1005524396896362\n",
      "tensor([0., 1.]) tensor([0.7873, 0.2127], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 20 - 255: dog - cat || Loss: 1.1000158786773682\n",
      "tensor([0., 1.]) tensor([0.7868, 0.2132], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 20 - 256: dog - cat || Loss: 1.0994782447814941\n",
      "tensor([0., 1.]) tensor([0.7862, 0.2138], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 20 - 257: dog - cat || Loss: 1.0989395380020142\n",
      "tensor([0., 1.]) tensor([0.7857, 0.2143], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 20 - 258: dog - cat || Loss: 1.0983998775482178\n",
      "tensor([0., 1.]) tensor([0.7851, 0.2149], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 20 - 259: dog - cat || Loss: 1.097859263420105\n",
      "tensor([0., 1.]) tensor([0.7846, 0.2154], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 20 - 260: dog - cat || Loss: 1.0973174571990967\n",
      "tensor([0., 1.]) tensor([0.7841, 0.2159], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 20 - 261: dog - cat || Loss: 1.0967748165130615\n",
      "tensor([0., 1.]) tensor([0.7835, 0.2165], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 20 - 262: dog - cat || Loss: 1.0962311029434204\n",
      "tensor([0., 1.]) tensor([0.7830, 0.2170], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 20 - 263: dog - cat || Loss: 1.095686435699463\n",
      "tensor([0., 1.]) tensor([0.7824, 0.2176], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 20 - 264: dog - cat || Loss: 1.0951409339904785\n",
      "tensor([0., 1.]) tensor([0.7819, 0.2181], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 20 - 265: dog - cat || Loss: 1.0945942401885986\n",
      "tensor([0., 1.]) tensor([0.7813, 0.2187], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 20 - 266: dog - cat || Loss: 1.0940468311309814\n",
      "tensor([0., 1.]) tensor([0.7808, 0.2192], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 20 - 267: dog - cat || Loss: 1.0934983491897583\n",
      "tensor([0., 1.]) tensor([0.7802, 0.2198], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 20 - 268: dog - cat || Loss: 1.0929487943649292\n",
      "tensor([0., 1.]) tensor([0.7797, 0.2203], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 20 - 269: dog - cat || Loss: 1.0923986434936523\n",
      "tensor([0., 1.]) tensor([0.7791, 0.2209], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 20 - 270: dog - cat || Loss: 1.0918470621109009\n",
      "tensor([0., 1.]) tensor([0.7786, 0.2214], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 20 - 271: dog - cat || Loss: 1.0912950038909912\n",
      "tensor([0., 1.]) tensor([0.7780, 0.2220], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 20 - 272: dog - cat || Loss: 1.090741753578186\n",
      "tensor([0., 1.]) tensor([0.7775, 0.2225], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 20 - 273: dog - cat || Loss: 1.0901875495910645\n",
      "tensor([0., 1.]) tensor([0.7769, 0.2231], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 20 - 274: dog - cat || Loss: 1.0896326303482056\n",
      "tensor([0., 1.]) tensor([0.7764, 0.2236], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 20 - 275: dog - cat || Loss: 1.0890766382217407\n",
      "tensor([0., 1.]) tensor([0.7758, 0.2242], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 20 - 276: dog - cat || Loss: 1.08851957321167\n",
      "tensor([0., 1.]) tensor([0.7753, 0.2247], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 20 - 277: dog - cat || Loss: 1.0879616737365723\n",
      "tensor([0., 1.]) tensor([0.7747, 0.2253], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 20 - 278: dog - cat || Loss: 1.0874031782150269\n",
      "tensor([0., 1.]) tensor([0.7741, 0.2259], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 20 - 279: dog - cat || Loss: 1.086843490600586\n",
      "tensor([0., 1.]) tensor([0.7736, 0.2264], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 20 - 280: dog - cat || Loss: 1.0862829685211182\n",
      "tensor([0., 1.]) tensor([0.7730, 0.2270], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 20 - 281: dog - cat || Loss: 1.0857211351394653\n",
      "tensor([0., 1.]) tensor([0.7725, 0.2275], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 20 - 282: dog - cat || Loss: 1.0851588249206543\n",
      "tensor([0., 1.]) tensor([0.7719, 0.2281], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 20 - 283: dog - cat || Loss: 1.0845954418182373\n",
      "tensor([0., 1.]) tensor([0.7713, 0.2287], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 20 - 284: dog - cat || Loss: 1.084031105041504\n",
      "tensor([0., 1.]) tensor([0.7708, 0.2292], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 20 - 285: dog - cat || Loss: 1.0834659337997437\n",
      "tensor([0., 1.]) tensor([0.7702, 0.2298], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 20 - 286: dog - cat || Loss: 1.0828999280929565\n",
      "tensor([0., 1.]) tensor([0.7696, 0.2304], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 20 - 287: dog - cat || Loss: 1.0823328495025635\n",
      "tensor([0., 1.]) tensor([0.7691, 0.2309], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 20 - 288: dog - cat || Loss: 1.081765055656433\n",
      "tensor([0., 1.]) tensor([0.7685, 0.2315], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 20 - 289: dog - cat || Loss: 1.0811961889266968\n",
      "tensor([0., 1.]) tensor([0.7679, 0.2321], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 20 - 290: dog - cat || Loss: 1.0806264877319336\n",
      "tensor([0., 1.]) tensor([0.7674, 0.2326], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 20 - 291: dog - cat || Loss: 1.0800559520721436\n",
      "tensor([0., 1.]) tensor([0.7668, 0.2332], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 20 - 292: dog - cat || Loss: 1.079484224319458\n",
      "tensor([0., 1.]) tensor([0.7662, 0.2338], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 20 - 293: dog - cat || Loss: 1.0789117813110352\n",
      "tensor([0., 1.]) tensor([0.7657, 0.2343], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 20 - 294: dog - cat || Loss: 1.0783385038375854\n",
      "tensor([0., 1.]) tensor([0.7651, 0.2349], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 20 - 295: dog - cat || Loss: 1.0777642726898193\n",
      "tensor([0., 1.]) tensor([0.7645, 0.2355], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 20 - 296: dog - cat || Loss: 1.0771890878677368\n",
      "tensor([0., 1.]) tensor([0.7639, 0.2361], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 20 - 297: dog - cat || Loss: 1.076613187789917\n",
      "tensor([0., 1.]) tensor([0.7634, 0.2366], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 20 - 298: dog - cat || Loss: 1.0760363340377808\n",
      "tensor([0., 1.]) tensor([0.7628, 0.2372], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 20 - 299: dog - cat || Loss: 1.0754584074020386\n",
      "tensor([0., 1.]) tensor([0.7622, 0.2378], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 20 - 300: dog - cat || Loss: 1.074879765510559\n",
      "tensor([0., 1.]) tensor([0.7616, 0.2384], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 20 - 301: dog - cat || Loss: 1.0743001699447632\n",
      "tensor([0., 1.]) tensor([0.7610, 0.2390], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 20 - 302: dog - cat || Loss: 1.07371985912323\n",
      "tensor([0., 1.]) tensor([0.7605, 0.2395], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 20 - 303: dog - cat || Loss: 1.0731384754180908\n",
      "tensor([0., 1.]) tensor([0.7599, 0.2401], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 20 - 304: dog - cat || Loss: 1.0725561380386353\n",
      "tensor([0., 1.]) tensor([0.7593, 0.2407], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 20 - 305: dog - cat || Loss: 1.0719728469848633\n",
      "tensor([0., 1.]) tensor([0.7587, 0.2413], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 20 - 306: dog - cat || Loss: 1.071389079093933\n",
      "tensor([0., 1.]) tensor([0.7581, 0.2419], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 20 - 307: dog - cat || Loss: 1.0708041191101074\n",
      "tensor([0., 1.]) tensor([0.7575, 0.2425], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 20 - 308: dog - cat || Loss: 1.0702182054519653\n",
      "tensor([0., 1.]) tensor([0.7570, 0.2430], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 20 - 309: dog - cat || Loss: 1.069631576538086\n",
      "tensor([0., 1.]) tensor([0.7564, 0.2436], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 20 - 310: dog - cat || Loss: 1.0690441131591797\n",
      "tensor([0., 1.]) tensor([0.7558, 0.2442], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 20 - 311: dog - cat || Loss: 1.068455696105957\n",
      "tensor([0., 1.]) tensor([0.7552, 0.2448], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 20 - 312: dog - cat || Loss: 1.0678664445877075\n",
      "tensor([0., 1.]) tensor([0.7546, 0.2454], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 20 - 313: dog - cat || Loss: 1.0672762393951416\n",
      "tensor([0., 1.]) tensor([0.7540, 0.2460], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 20 - 314: dog - cat || Loss: 1.0666851997375488\n",
      "tensor([0., 1.]) tensor([0.7534, 0.2466], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 20 - 315: dog - cat || Loss: 1.0660932064056396\n",
      "tensor([0., 1.]) tensor([0.7528, 0.2472], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 20 - 316: dog - cat || Loss: 1.0655004978179932\n",
      "tensor([0., 1.]) tensor([0.7522, 0.2478], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 20 - 317: dog - cat || Loss: 1.0649068355560303\n",
      "tensor([0., 1.]) tensor([0.7516, 0.2484], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 20 - 318: dog - cat || Loss: 1.064312219619751\n",
      "tensor([0., 1.]) tensor([0.7511, 0.2489], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 20 - 319: dog - cat || Loss: 1.063717007637024\n",
      "tensor([0., 1.]) tensor([0.7505, 0.2495], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 20 - 320: dog - cat || Loss: 1.0631206035614014\n",
      "tensor([0., 1.]) tensor([0.7499, 0.2501], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 20 - 321: dog - cat || Loss: 1.0625234842300415\n",
      "tensor([0., 1.]) tensor([0.7493, 0.2507], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 20 - 322: dog - cat || Loss: 1.0619255304336548\n",
      "tensor([0., 1.]) tensor([0.7487, 0.2513], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 20 - 323: dog - cat || Loss: 1.061326503753662\n",
      "tensor([0., 1.]) tensor([0.7481, 0.2519], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 20 - 324: dog - cat || Loss: 1.0607267618179321\n",
      "tensor([0., 1.]) tensor([0.7475, 0.2525], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 20 - 325: dog - cat || Loss: 1.0601260662078857\n",
      "tensor([0., 1.]) tensor([0.7469, 0.2531], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 20 - 326: dog - cat || Loss: 1.059524655342102\n",
      "tensor([0., 1.]) tensor([0.7463, 0.2537], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 20 - 327: dog - cat || Loss: 1.058922290802002\n",
      "tensor([0., 1.]) tensor([0.7457, 0.2543], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 20 - 328: dog - cat || Loss: 1.058319091796875\n",
      "tensor([0., 1.]) tensor([0.7451, 0.2549], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 20 - 329: dog - cat || Loss: 1.0577149391174316\n",
      "tensor([0., 1.]) tensor([0.7445, 0.2555], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 20 - 330: dog - cat || Loss: 1.057110071182251\n",
      "tensor([0., 1.]) tensor([0.7438, 0.2562], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 20 - 331: dog - cat || Loss: 1.056504249572754\n",
      "tensor([0., 1.]) tensor([0.7432, 0.2568], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 20 - 332: dog - cat || Loss: 1.0558974742889404\n",
      "tensor([0., 1.]) tensor([0.7426, 0.2574], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 20 - 333: dog - cat || Loss: 1.0552899837493896\n",
      "tensor([0., 1.]) tensor([0.7420, 0.2580], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 20 - 334: dog - cat || Loss: 1.0546815395355225\n",
      "tensor([0., 1.]) tensor([0.7414, 0.2586], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 20 - 335: dog - cat || Loss: 1.0540722608566284\n",
      "tensor([0., 1.]) tensor([0.7408, 0.2592], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 20 - 336: dog - cat || Loss: 1.053462266921997\n",
      "tensor([0., 1.]) tensor([0.7402, 0.2598], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 20 - 337: dog - cat || Loss: 1.0528512001037598\n",
      "tensor([0., 1.]) tensor([0.7396, 0.2604], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 20 - 338: dog - cat || Loss: 1.0522392988204956\n",
      "tensor([0., 1.]) tensor([0.7390, 0.2610], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 20 - 339: dog - cat || Loss: 1.0516268014907837\n",
      "tensor([0., 1.]) tensor([0.7384, 0.2616], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 20 - 340: dog - cat || Loss: 1.0510131120681763\n",
      "tensor([0., 1.]) tensor([0.7378, 0.2622], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 20 - 341: dog - cat || Loss: 1.050398826599121\n",
      "tensor([0., 1.]) tensor([0.7371, 0.2629], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 20 - 342: dog - cat || Loss: 1.04978346824646\n",
      "tensor([0., 1.]) tensor([0.7365, 0.2635], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 20 - 343: dog - cat || Loss: 1.0491673946380615\n",
      "tensor([0., 1.]) tensor([0.7359, 0.2641], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 20 - 344: dog - cat || Loss: 1.0485506057739258\n",
      "tensor([0., 1.]) tensor([0.7353, 0.2647], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 20 - 345: dog - cat || Loss: 1.0479326248168945\n",
      "tensor([0., 1.]) tensor([0.7347, 0.2653], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 20 - 346: dog - cat || Loss: 1.0473140478134155\n",
      "tensor([0., 1.]) tensor([0.7341, 0.2659], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 20 - 347: dog - cat || Loss: 1.0466946363449097\n",
      "tensor([0., 1.]) tensor([0.7334, 0.2666], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 20 - 348: dog - cat || Loss: 1.046074390411377\n",
      "tensor([0., 1.]) tensor([0.7328, 0.2672], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 20 - 349: dog - cat || Loss: 1.0454530715942383\n",
      "tensor([0., 1.]) tensor([0.7322, 0.2678], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 20 - 350: dog - cat || Loss: 1.0448311567306519\n",
      "tensor([0., 1.]) tensor([0.7316, 0.2684], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 20 - 351: dog - cat || Loss: 1.0442081689834595\n",
      "tensor([0., 1.]) tensor([0.7309, 0.2691], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 20 - 352: dog - cat || Loss: 1.0435845851898193\n",
      "tensor([0., 1.]) tensor([0.7303, 0.2697], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 20 - 353: dog - cat || Loss: 1.0429601669311523\n",
      "tensor([0., 1.]) tensor([0.7297, 0.2703], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 20 - 354: dog - cat || Loss: 1.0423346757888794\n",
      "tensor([0., 1.]) tensor([0.7291, 0.2709], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 20 - 355: dog - cat || Loss: 1.0417085886001587\n",
      "tensor([0., 1.]) tensor([0.7284, 0.2716], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 20 - 356: dog - cat || Loss: 1.0410816669464111\n",
      "tensor([0., 1.]) tensor([0.7278, 0.2722], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 20 - 357: dog - cat || Loss: 1.0404537916183472\n",
      "tensor([0., 1.]) tensor([0.7272, 0.2728], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 20 - 358: dog - cat || Loss: 1.0398250818252563\n",
      "tensor([0., 1.]) tensor([0.7266, 0.2734], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 20 - 359: dog - cat || Loss: 1.0391954183578491\n",
      "tensor([0., 1.]) tensor([0.7259, 0.2741], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 20 - 360: dog - cat || Loss: 1.0385651588439941\n",
      "tensor([0., 1.]) tensor([0.7253, 0.2747], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 20 - 361: dog - cat || Loss: 1.0379340648651123\n",
      "tensor([0., 1.]) tensor([0.7247, 0.2753], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 20 - 362: dog - cat || Loss: 1.0373018980026245\n",
      "tensor([0., 1.]) tensor([0.7240, 0.2760], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 20 - 363: dog - cat || Loss: 1.0366692543029785\n",
      "tensor([0., 1.]) tensor([0.7234, 0.2766], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 20 - 364: dog - cat || Loss: 1.0360355377197266\n",
      "tensor([0., 1.]) tensor([0.7228, 0.2772], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 20 - 365: dog - cat || Loss: 1.0354011058807373\n",
      "tensor([0., 1.]) tensor([0.7221, 0.2779], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 20 - 366: dog - cat || Loss: 1.0347658395767212\n",
      "tensor([0., 1.]) tensor([0.7215, 0.2785], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 20 - 367: dog - cat || Loss: 1.0341298580169678\n",
      "tensor([0., 1.]) tensor([0.7209, 0.2791], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 20 - 368: dog - cat || Loss: 1.033492922782898\n",
      "tensor([0., 1.]) tensor([0.7202, 0.2798], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 20 - 369: dog - cat || Loss: 1.0328551530838013\n",
      "tensor([0., 1.]) tensor([0.7196, 0.2804], grad_fn=<SoftmaxBackward0>)\n",
      "=====epoch:21=====\n",
      "Epoch 21 - 0: cat - cat || Loss: 0.5943067669868469\n",
      "tensor([1., 0.]) tensor([0.7190, 0.2810], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 21 - 1: cat - cat || Loss: 0.5948174595832825\n",
      "tensor([1., 0.]) tensor([0.7184, 0.2816], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 21 - 2: cat - cat || Loss: 0.595212996006012\n",
      "tensor([1., 0.]) tensor([0.7180, 0.2820], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 21 - 3: cat - cat || Loss: 0.5955045223236084\n",
      "tensor([1., 0.]) tensor([0.7178, 0.2822], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 21 - 4: cat - cat || Loss: 0.595702588558197\n",
      "tensor([1., 0.]) tensor([0.7176, 0.2824], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 21 - 5: cat - cat || Loss: 0.5958163738250732\n",
      "tensor([1., 0.]) tensor([0.7174, 0.2826], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 21 - 6: cat - cat || Loss: 0.5958542227745056\n",
      "tensor([1., 0.]) tensor([0.7174, 0.2826], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 21 - 7: cat - cat || Loss: 0.5958237051963806\n",
      "tensor([1., 0.]) tensor([0.7174, 0.2826], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 21 - 8: cat - cat || Loss: 0.5957319140434265\n",
      "tensor([1., 0.]) tensor([0.7175, 0.2825], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 21 - 9: cat - cat || Loss: 0.5955848693847656\n",
      "tensor([1., 0.]) tensor([0.7177, 0.2823], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 21 - 10: cat - cat || Loss: 0.5953880548477173\n",
      "tensor([1., 0.]) tensor([0.7179, 0.2821], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 21 - 11: cat - cat || Loss: 0.595146656036377\n",
      "tensor([1., 0.]) tensor([0.7181, 0.2819], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 21 - 12: cat - cat || Loss: 0.5948649644851685\n",
      "tensor([1., 0.]) tensor([0.7184, 0.2816], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 21 - 13: cat - cat || Loss: 0.5945472717285156\n",
      "tensor([1., 0.]) tensor([0.7187, 0.2813], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 21 - 14: cat - cat || Loss: 0.594197154045105\n",
      "tensor([1., 0.]) tensor([0.7191, 0.2809], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 21 - 15: cat - cat || Loss: 0.5938178896903992\n",
      "tensor([1., 0.]) tensor([0.7194, 0.2806], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 21 - 16: cat - cat || Loss: 0.5934125185012817\n",
      "tensor([1., 0.]) tensor([0.7198, 0.2802], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 21 - 17: cat - cat || Loss: 0.592983603477478\n",
      "tensor([1., 0.]) tensor([0.7203, 0.2797], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 21 - 18: cat - cat || Loss: 0.5925338268280029\n",
      "tensor([1., 0.]) tensor([0.7207, 0.2793], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 21 - 19: cat - cat || Loss: 0.5920650959014893\n",
      "tensor([1., 0.]) tensor([0.7212, 0.2788], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 21 - 20: cat - cat || Loss: 0.5915794372558594\n",
      "tensor([1., 0.]) tensor([0.7217, 0.2783], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 21 - 21: cat - cat || Loss: 0.5910787582397461\n",
      "tensor([1., 0.]) tensor([0.7222, 0.2778], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 21 - 22: cat - cat || Loss: 0.5905646085739136\n",
      "tensor([1., 0.]) tensor([0.7227, 0.2773], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 21 - 23: cat - cat || Loss: 0.5900382995605469\n",
      "tensor([1., 0.]) tensor([0.7232, 0.2768], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 21 - 24: cat - cat || Loss: 0.589501142501831\n",
      "tensor([1., 0.]) tensor([0.7238, 0.2762], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 21 - 25: cat - cat || Loss: 0.588954508304596\n",
      "tensor([1., 0.]) tensor([0.7243, 0.2757], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 21 - 26: cat - cat || Loss: 0.5883992910385132\n",
      "tensor([1., 0.]) tensor([0.7249, 0.2751], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 21 - 27: cat - cat || Loss: 0.5878363847732544\n",
      "tensor([1., 0.]) tensor([0.7254, 0.2746], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 21 - 28: cat - cat || Loss: 0.587266743183136\n",
      "tensor([1., 0.]) tensor([0.7260, 0.2740], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 21 - 29: cat - cat || Loss: 0.5866909027099609\n",
      "tensor([1., 0.]) tensor([0.7266, 0.2734], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 21 - 30: cat - cat || Loss: 0.5861098766326904\n",
      "tensor([1., 0.]) tensor([0.7272, 0.2728], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 21 - 31: cat - cat || Loss: 0.5855239629745483\n",
      "tensor([1., 0.]) tensor([0.7277, 0.2723], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 21 - 32: cat - cat || Loss: 0.5849339962005615\n",
      "tensor([1., 0.]) tensor([0.7283, 0.2717], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 21 - 33: cat - cat || Loss: 0.5843403339385986\n",
      "tensor([1., 0.]) tensor([0.7289, 0.2711], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 21 - 34: cat - cat || Loss: 0.5837434530258179\n",
      "tensor([1., 0.]) tensor([0.7295, 0.2705], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 21 - 35: cat - cat || Loss: 0.5831438302993774\n",
      "tensor([1., 0.]) tensor([0.7301, 0.2699], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 21 - 36: cat - cat || Loss: 0.582541823387146\n",
      "tensor([1., 0.]) tensor([0.7307, 0.2693], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 21 - 37: cat - cat || Loss: 0.5819376111030579\n",
      "tensor([1., 0.]) tensor([0.7313, 0.2687], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 21 - 38: cat - cat || Loss: 0.5813316106796265\n",
      "tensor([1., 0.]) tensor([0.7319, 0.2681], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 21 - 39: cat - cat || Loss: 0.5807240605354309\n",
      "tensor([1., 0.]) tensor([0.7325, 0.2675], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 21 - 40: cat - cat || Loss: 0.5801153779029846\n",
      "tensor([1., 0.]) tensor([0.7331, 0.2669], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 21 - 41: cat - cat || Loss: 0.5795055031776428\n",
      "tensor([1., 0.]) tensor([0.7338, 0.2662], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 21 - 42: cat - cat || Loss: 0.5788947343826294\n",
      "tensor([1., 0.]) tensor([0.7344, 0.2656], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 21 - 43: cat - cat || Loss: 0.5782830715179443\n",
      "tensor([1., 0.]) tensor([0.7350, 0.2650], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 21 - 44: cat - cat || Loss: 0.577671229839325\n",
      "tensor([1., 0.]) tensor([0.7356, 0.2644], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 21 - 45: cat - cat || Loss: 0.5770587921142578\n",
      "tensor([1., 0.]) tensor([0.7362, 0.2638], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 21 - 46: cat - cat || Loss: 0.5764461159706116\n",
      "tensor([1., 0.]) tensor([0.7368, 0.2632], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 21 - 47: cat - cat || Loss: 0.5758333206176758\n",
      "tensor([1., 0.]) tensor([0.7374, 0.2626], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 21 - 48: cat - cat || Loss: 0.5752204656600952\n",
      "tensor([1., 0.]) tensor([0.7380, 0.2620], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 21 - 49: cat - cat || Loss: 0.5746076107025146\n",
      "tensor([1., 0.]) tensor([0.7387, 0.2613], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 21 - 50: cat - cat || Loss: 0.5739949345588684\n",
      "tensor([1., 0.]) tensor([0.7393, 0.2607], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 21 - 51: cat - cat || Loss: 0.573382556438446\n",
      "tensor([1., 0.]) tensor([0.7399, 0.2601], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 21 - 52: cat - cat || Loss: 0.572770357131958\n",
      "tensor([1., 0.]) tensor([0.7405, 0.2595], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 21 - 53: cat - cat || Loss: 0.5721584558486938\n",
      "tensor([1., 0.]) tensor([0.7411, 0.2589], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 21 - 54: cat - cat || Loss: 0.5715470314025879\n",
      "tensor([1., 0.]) tensor([0.7417, 0.2583], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 21 - 55: cat - cat || Loss: 0.5709360837936401\n",
      "tensor([1., 0.]) tensor([0.7423, 0.2577], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 21 - 56: cat - cat || Loss: 0.5703255534172058\n",
      "tensor([1., 0.]) tensor([0.7429, 0.2571], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 21 - 57: cat - cat || Loss: 0.5697154998779297\n",
      "tensor([1., 0.]) tensor([0.7435, 0.2565], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 21 - 58: cat - cat || Loss: 0.5691061019897461\n",
      "tensor([1., 0.]) tensor([0.7442, 0.2558], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 21 - 59: cat - cat || Loss: 0.568497359752655\n",
      "tensor([1., 0.]) tensor([0.7448, 0.2552], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 21 - 60: cat - cat || Loss: 0.5678890347480774\n",
      "tensor([1., 0.]) tensor([0.7454, 0.2546], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 21 - 61: cat - cat || Loss: 0.5672815442085266\n",
      "tensor([1., 0.]) tensor([0.7460, 0.2540], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 21 - 62: cat - cat || Loss: 0.5666746497154236\n",
      "tensor([1., 0.]) tensor([0.7466, 0.2534], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 21 - 63: cat - cat || Loss: 0.5660685300827026\n",
      "tensor([1., 0.]) tensor([0.7472, 0.2528], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 21 - 64: cat - cat || Loss: 0.565463125705719\n",
      "tensor([1., 0.]) tensor([0.7478, 0.2522], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 21 - 65: cat - cat || Loss: 0.5648583769798279\n",
      "tensor([1., 0.]) tensor([0.7484, 0.2516], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 21 - 66: cat - cat || Loss: 0.5642545223236084\n",
      "tensor([1., 0.]) tensor([0.7490, 0.2510], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 21 - 67: cat - cat || Loss: 0.563651442527771\n",
      "tensor([1., 0.]) tensor([0.7496, 0.2504], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 21 - 68: cat - cat || Loss: 0.5630490183830261\n",
      "tensor([1., 0.]) tensor([0.7502, 0.2498], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 21 - 69: cat - cat || Loss: 0.5624475479125977\n",
      "tensor([1., 0.]) tensor([0.7508, 0.2492], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 21 - 70: cat - cat || Loss: 0.5618468523025513\n",
      "tensor([1., 0.]) tensor([0.7514, 0.2486], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 21 - 71: cat - cat || Loss: 0.5612469911575317\n",
      "tensor([1., 0.]) tensor([0.7520, 0.2480], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 21 - 72: cat - cat || Loss: 0.5606479048728943\n",
      "tensor([1., 0.]) tensor([0.7526, 0.2474], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 21 - 73: cat - cat || Loss: 0.5600497126579285\n",
      "tensor([1., 0.]) tensor([0.7532, 0.2468], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 21 - 74: cat - cat || Loss: 0.5594522356987\n",
      "tensor([1., 0.]) tensor([0.7538, 0.2462], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 21 - 75: cat - cat || Loss: 0.5588557720184326\n",
      "tensor([1., 0.]) tensor([0.7544, 0.2456], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 21 - 76: cat - cat || Loss: 0.5582601428031921\n",
      "tensor([1., 0.]) tensor([0.7550, 0.2450], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 21 - 77: cat - cat || Loss: 0.5576654672622681\n",
      "tensor([1., 0.]) tensor([0.7556, 0.2444], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 21 - 78: cat - cat || Loss: 0.5570715665817261\n",
      "tensor([1., 0.]) tensor([0.7562, 0.2438], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 21 - 79: cat - cat || Loss: 0.5564786195755005\n",
      "tensor([1., 0.]) tensor([0.7568, 0.2432], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 21 - 80: cat - cat || Loss: 0.5558865070343018\n",
      "tensor([1., 0.]) tensor([0.7574, 0.2426], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 21 - 81: cat - cat || Loss: 0.5552951693534851\n",
      "tensor([1., 0.]) tensor([0.7580, 0.2420], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 21 - 82: cat - cat || Loss: 0.5547048449516296\n",
      "tensor([1., 0.]) tensor([0.7586, 0.2414], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 21 - 83: cat - cat || Loss: 0.5541154742240906\n",
      "tensor([1., 0.]) tensor([0.7591, 0.2409], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 21 - 84: cat - cat || Loss: 0.5535268783569336\n",
      "tensor([1., 0.]) tensor([0.7597, 0.2403], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 21 - 85: cat - cat || Loss: 0.5529392957687378\n",
      "tensor([1., 0.]) tensor([0.7603, 0.2397], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 21 - 86: cat - cat || Loss: 0.5523525476455688\n",
      "tensor([1., 0.]) tensor([0.7609, 0.2391], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 21 - 87: cat - cat || Loss: 0.5517667531967163\n",
      "tensor([1., 0.]) tensor([0.7615, 0.2385], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 21 - 88: cat - cat || Loss: 0.5511818528175354\n",
      "tensor([1., 0.]) tensor([0.7621, 0.2379], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 21 - 89: cat - cat || Loss: 0.5505977869033813\n",
      "tensor([1., 0.]) tensor([0.7627, 0.2373], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 21 - 90: cat - cat || Loss: 0.5500146746635437\n",
      "tensor([1., 0.]) tensor([0.7632, 0.2368], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 21 - 91: cat - cat || Loss: 0.5494324564933777\n",
      "tensor([1., 0.]) tensor([0.7638, 0.2362], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 21 - 92: cat - cat || Loss: 0.5488512516021729\n",
      "tensor([1., 0.]) tensor([0.7644, 0.2356], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 21 - 93: cat - cat || Loss: 0.5482708215713501\n",
      "tensor([1., 0.]) tensor([0.7650, 0.2350], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 21 - 94: cat - cat || Loss: 0.5476913452148438\n",
      "tensor([1., 0.]) tensor([0.7656, 0.2344], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 21 - 95: cat - cat || Loss: 0.5471128225326538\n",
      "tensor([1., 0.]) tensor([0.7661, 0.2339], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 21 - 96: cat - cat || Loss: 0.546535313129425\n",
      "tensor([1., 0.]) tensor([0.7667, 0.2333], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 21 - 97: cat - cat || Loss: 0.5459586977958679\n",
      "tensor([1., 0.]) tensor([0.7673, 0.2327], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 21 - 98: cat - cat || Loss: 0.5453829169273376\n",
      "tensor([1., 0.]) tensor([0.7679, 0.2321], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 21 - 99: cat - cat || Loss: 0.5448082089424133\n",
      "tensor([1., 0.]) tensor([0.7685, 0.2315], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 21 - 100: cat - cat || Loss: 0.5442342758178711\n",
      "tensor([1., 0.]) tensor([0.7690, 0.2310], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 21 - 101: cat - cat || Loss: 0.54366135597229\n",
      "tensor([1., 0.]) tensor([0.7696, 0.2304], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 21 - 102: cat - cat || Loss: 0.5430894494056702\n",
      "tensor([1., 0.]) tensor([0.7702, 0.2298], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 21 - 103: cat - cat || Loss: 0.5425183773040771\n",
      "tensor([1., 0.]) tensor([0.7707, 0.2293], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 21 - 104: cat - cat || Loss: 0.5419481992721558\n",
      "tensor([1., 0.]) tensor([0.7713, 0.2287], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 21 - 105: cat - cat || Loss: 0.5413790345191956\n",
      "tensor([1., 0.]) tensor([0.7719, 0.2281], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 21 - 106: cat - cat || Loss: 0.5408108830451965\n",
      "tensor([1., 0.]) tensor([0.7725, 0.2275], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 21 - 107: cat - cat || Loss: 0.5402435064315796\n",
      "tensor([1., 0.]) tensor([0.7730, 0.2270], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 21 - 108: cat - cat || Loss: 0.5396772623062134\n",
      "tensor([1., 0.]) tensor([0.7736, 0.2264], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 21 - 109: cat - cat || Loss: 0.5391117930412292\n",
      "tensor([1., 0.]) tensor([0.7741, 0.2259], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 21 - 110: cat - cat || Loss: 0.5385473966598511\n",
      "tensor([1., 0.]) tensor([0.7747, 0.2253], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 21 - 111: cat - cat || Loss: 0.5379838943481445\n",
      "tensor([1., 0.]) tensor([0.7753, 0.2247], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 21 - 112: cat - cat || Loss: 0.5374212861061096\n",
      "tensor([1., 0.]) tensor([0.7758, 0.2242], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 21 - 113: cat - cat || Loss: 0.5368596911430359\n",
      "tensor([1., 0.]) tensor([0.7764, 0.2236], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 21 - 114: cat - cat || Loss: 0.5362990498542786\n",
      "tensor([1., 0.]) tensor([0.7770, 0.2230], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 21 - 115: cat - cat || Loss: 0.5357393026351929\n",
      "tensor([1., 0.]) tensor([0.7775, 0.2225], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 21 - 116: cat - cat || Loss: 0.5351805090904236\n",
      "tensor([1., 0.]) tensor([0.7781, 0.2219], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 21 - 117: cat - cat || Loss: 0.5346227288246155\n",
      "tensor([1., 0.]) tensor([0.7786, 0.2214], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 21 - 118: cat - cat || Loss: 0.5340657830238342\n",
      "tensor([1., 0.]) tensor([0.7792, 0.2208], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 21 - 119: cat - cat || Loss: 0.5335099697113037\n",
      "tensor([1., 0.]) tensor([0.7798, 0.2202], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 21 - 120: cat - cat || Loss: 0.5329549908638\n",
      "tensor([1., 0.]) tensor([0.7803, 0.2197], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 21 - 121: cat - cat || Loss: 0.5324008464813232\n",
      "tensor([1., 0.]) tensor([0.7809, 0.2191], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 21 - 122: cat - cat || Loss: 0.5318478345870972\n",
      "tensor([1., 0.]) tensor([0.7814, 0.2186], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 21 - 123: cat - cat || Loss: 0.5312958359718323\n",
      "tensor([1., 0.]) tensor([0.7820, 0.2180], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 21 - 124: cat - cat || Loss: 0.5307446718215942\n",
      "tensor([1., 0.]) tensor([0.7825, 0.2175], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 21 - 125: cat - cat || Loss: 0.5301945805549622\n",
      "tensor([1., 0.]) tensor([0.7831, 0.2169], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 21 - 126: cat - cat || Loss: 0.5296453237533569\n",
      "tensor([1., 0.]) tensor([0.7836, 0.2164], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 21 - 127: cat - cat || Loss: 0.5290970206260681\n",
      "tensor([1., 0.]) tensor([0.7842, 0.2158], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 21 - 128: cat - cat || Loss: 0.5285497307777405\n",
      "tensor([1., 0.]) tensor([0.7847, 0.2153], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 21 - 129: cat - cat || Loss: 0.528003454208374\n",
      "tensor([1., 0.]) tensor([0.7853, 0.2147], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 21 - 130: cat - cat || Loss: 0.5274580717086792\n",
      "tensor([1., 0.]) tensor([0.7858, 0.2142], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 21 - 131: cat - cat || Loss: 0.526913583278656\n",
      "tensor([1., 0.]) tensor([0.7863, 0.2137], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 21 - 132: cat - cat || Loss: 0.5263701677322388\n",
      "tensor([1., 0.]) tensor([0.7869, 0.2131], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 21 - 133: cat - cat || Loss: 0.5258277058601379\n",
      "tensor([1., 0.]) tensor([0.7874, 0.2126], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 21 - 134: cat - cat || Loss: 0.5252861380577087\n",
      "tensor([1., 0.]) tensor([0.7880, 0.2120], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 21 - 135: cat - cat || Loss: 0.5247456431388855\n",
      "tensor([1., 0.]) tensor([0.7885, 0.2115], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 21 - 136: cat - cat || Loss: 0.5242060422897339\n",
      "tensor([1., 0.]) tensor([0.7891, 0.2109], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 21 - 137: cat - cat || Loss: 0.5236673951148987\n",
      "tensor([1., 0.]) tensor([0.7896, 0.2104], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 21 - 138: cat - cat || Loss: 0.5231297612190247\n",
      "tensor([1., 0.]) tensor([0.7901, 0.2099], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 21 - 139: cat - cat || Loss: 0.5225931406021118\n",
      "tensor([1., 0.]) tensor([0.7907, 0.2093], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 21 - 140: cat - cat || Loss: 0.5220574140548706\n",
      "tensor([1., 0.]) tensor([0.7912, 0.2088], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 21 - 141: cat - cat || Loss: 0.5215227007865906\n",
      "tensor([1., 0.]) tensor([0.7917, 0.2083], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 21 - 142: cat - cat || Loss: 0.520988941192627\n",
      "tensor([1., 0.]) tensor([0.7923, 0.2077], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 21 - 143: cat - cat || Loss: 0.5204561352729797\n",
      "tensor([1., 0.]) tensor([0.7928, 0.2072], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 21 - 144: cat - cat || Loss: 0.5199244022369385\n",
      "tensor([1., 0.]) tensor([0.7933, 0.2067], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 21 - 145: cat - cat || Loss: 0.5193935632705688\n",
      "tensor([1., 0.]) tensor([0.7939, 0.2061], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 21 - 146: cat - cat || Loss: 0.5188636779785156\n",
      "tensor([1., 0.]) tensor([0.7944, 0.2056], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 21 - 147: cat - cat || Loss: 0.5183348059654236\n",
      "tensor([1., 0.]) tensor([0.7949, 0.2051], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 21 - 148: cat - cat || Loss: 0.5178069472312927\n",
      "tensor([1., 0.]) tensor([0.7955, 0.2045], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 21 - 149: cat - cat || Loss: 0.517280101776123\n",
      "tensor([1., 0.]) tensor([0.7960, 0.2040], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 21 - 150: cat - cat || Loss: 0.5167540311813354\n",
      "tensor([1., 0.]) tensor([0.7965, 0.2035], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 21 - 151: cat - cat || Loss: 0.5162290930747986\n",
      "tensor([1., 0.]) tensor([0.7970, 0.2030], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 21 - 152: cat - cat || Loss: 0.5157051086425781\n",
      "tensor([1., 0.]) tensor([0.7976, 0.2024], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 21 - 153: cat - cat || Loss: 0.5151820182800293\n",
      "tensor([1., 0.]) tensor([0.7981, 0.2019], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 21 - 154: cat - cat || Loss: 0.5146600008010864\n",
      "tensor([1., 0.]) tensor([0.7986, 0.2014], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 21 - 155: cat - cat || Loss: 0.51413893699646\n",
      "tensor([1., 0.]) tensor([0.7991, 0.2009], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 21 - 156: cat - cat || Loss: 0.5136188268661499\n",
      "tensor([1., 0.]) tensor([0.7996, 0.2004], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 21 - 157: cat - cat || Loss: 0.5130997896194458\n",
      "tensor([1., 0.]) tensor([0.8002, 0.1998], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 21 - 158: cat - cat || Loss: 0.512581467628479\n",
      "tensor([1., 0.]) tensor([0.8007, 0.1993], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 21 - 159: cat - cat || Loss: 0.5120643377304077\n",
      "tensor([1., 0.]) tensor([0.8012, 0.1988], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 21 - 160: cat - cat || Loss: 0.5115480422973633\n",
      "tensor([1., 0.]) tensor([0.8017, 0.1983], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 21 - 161: cat - cat || Loss: 0.5110328197479248\n",
      "tensor([1., 0.]) tensor([0.8022, 0.1978], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 21 - 162: cat - cat || Loss: 0.5105185508728027\n",
      "tensor([1., 0.]) tensor([0.8027, 0.1973], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 21 - 163: cat - cat || Loss: 0.5100052356719971\n",
      "tensor([1., 0.]) tensor([0.8033, 0.1967], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 21 - 164: cat - cat || Loss: 0.5094928741455078\n",
      "tensor([1., 0.]) tensor([0.8038, 0.1962], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 21 - 165: cat - cat || Loss: 0.5089815258979797\n",
      "tensor([1., 0.]) tensor([0.8043, 0.1957], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 21 - 166: cat - cat || Loss: 0.5084710717201233\n",
      "tensor([1., 0.]) tensor([0.8048, 0.1952], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 21 - 167: cat - cat || Loss: 0.507961630821228\n",
      "tensor([1., 0.]) tensor([0.8053, 0.1947], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 21 - 168: cat - cat || Loss: 0.507453203201294\n",
      "tensor([1., 0.]) tensor([0.8058, 0.1942], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 21 - 169: cat - cat || Loss: 0.5069457292556763\n",
      "tensor([1., 0.]) tensor([0.8063, 0.1937], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 21 - 170: cat - cat || Loss: 0.5064393281936646\n",
      "tensor([1., 0.]) tensor([0.8068, 0.1932], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 21 - 171: cat - cat || Loss: 0.5059337615966797\n",
      "tensor([1., 0.]) tensor([0.8073, 0.1927], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 21 - 172: cat - cat || Loss: 0.505429208278656\n",
      "tensor([1., 0.]) tensor([0.8078, 0.1922], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 21 - 173: cat - cat || Loss: 0.5049256086349487\n",
      "tensor([1., 0.]) tensor([0.8083, 0.1917], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 21 - 174: cat - cat || Loss: 0.5044230222702026\n",
      "tensor([1., 0.]) tensor([0.8088, 0.1912], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 21 - 175: cat - cat || Loss: 0.503921389579773\n",
      "tensor([1., 0.]) tensor([0.8093, 0.1907], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 21 - 176: cat - cat || Loss: 0.5034207105636597\n",
      "tensor([1., 0.]) tensor([0.8098, 0.1902], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 21 - 177: cat - cat || Loss: 0.5029210448265076\n",
      "tensor([1., 0.]) tensor([0.8103, 0.1897], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 21 - 178: cat - cat || Loss: 0.5024223327636719\n",
      "tensor([1., 0.]) tensor([0.8108, 0.1892], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 21 - 179: cat - cat || Loss: 0.5019245147705078\n",
      "tensor([1., 0.]) tensor([0.8113, 0.1887], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 21 - 180: cat - cat || Loss: 0.5014278292655945\n",
      "tensor([1., 0.]) tensor([0.8118, 0.1882], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 21 - 181: cat - cat || Loss: 0.500931978225708\n",
      "tensor([1., 0.]) tensor([0.8123, 0.1877], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 21 - 182: cat - cat || Loss: 0.5004372000694275\n",
      "tensor([1., 0.]) tensor([0.8128, 0.1872], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 21 - 183: cat - cat || Loss: 0.49994343519210815\n",
      "tensor([1., 0.]) tensor([0.8133, 0.1867], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 21 - 184: cat - cat || Loss: 0.49945056438446045\n",
      "tensor([1., 0.]) tensor([0.8138, 0.1862], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 21 - 185: cat - cat || Loss: 0.4989587068557739\n",
      "tensor([1., 0.]) tensor([0.8143, 0.1857], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 21 - 186: cat - cat || Loss: 0.49846774339675903\n",
      "tensor([1., 0.]) tensor([0.8148, 0.1852], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 21 - 187: cat - cat || Loss: 0.4979777932167053\n",
      "tensor([1., 0.]) tensor([0.8153, 0.1847], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 21 - 188: cat - cat || Loss: 0.497488796710968\n",
      "tensor([1., 0.]) tensor([0.8158, 0.1842], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 21 - 189: cat - cat || Loss: 0.4970007538795471\n",
      "tensor([1., 0.]) tensor([0.8163, 0.1837], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 21 - 190: dog - cat || Loss: 1.1300095319747925\n",
      "tensor([0., 1.]) tensor([0.8167, 0.1833], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 21 - 191: dog - cat || Loss: 1.130399227142334\n",
      "tensor([0., 1.]) tensor([0.8171, 0.1829], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 21 - 192: dog - cat || Loss: 1.1307015419006348\n",
      "tensor([0., 1.]) tensor([0.8174, 0.1826], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 21 - 193: dog - cat || Loss: 1.1309254169464111\n",
      "tensor([0., 1.]) tensor([0.8177, 0.1823], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 21 - 194: dog - cat || Loss: 1.1310787200927734\n",
      "tensor([0., 1.]) tensor([0.8178, 0.1822], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 21 - 195: dog - cat || Loss: 1.1311688423156738\n",
      "tensor([0., 1.]) tensor([0.8179, 0.1821], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 21 - 196: dog - cat || Loss: 1.1312017440795898\n",
      "tensor([0., 1.]) tensor([0.8179, 0.1821], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 21 - 197: dog - cat || Loss: 1.131183385848999\n",
      "tensor([0., 1.]) tensor([0.8179, 0.1821], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 21 - 198: dog - cat || Loss: 1.1311190128326416\n",
      "tensor([0., 1.]) tensor([0.8179, 0.1821], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 21 - 199: dog - cat || Loss: 1.1310131549835205\n",
      "tensor([0., 1.]) tensor([0.8178, 0.1822], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 21 - 200: dog - cat || Loss: 1.130869746208191\n",
      "tensor([0., 1.]) tensor([0.8176, 0.1824], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 21 - 201: dog - cat || Loss: 1.130692481994629\n",
      "tensor([0., 1.]) tensor([0.8174, 0.1826], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 21 - 202: dog - cat || Loss: 1.1304848194122314\n",
      "tensor([0., 1.]) tensor([0.8172, 0.1828], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 21 - 203: dog - cat || Loss: 1.1302498579025269\n",
      "tensor([0., 1.]) tensor([0.8170, 0.1830], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 21 - 204: dog - cat || Loss: 1.1299899816513062\n",
      "tensor([0., 1.]) tensor([0.8167, 0.1833], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 21 - 205: dog - cat || Loss: 1.1297078132629395\n",
      "tensor([0., 1.]) tensor([0.8164, 0.1836], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 21 - 206: dog - cat || Loss: 1.1294056177139282\n",
      "tensor([0., 1.]) tensor([0.8161, 0.1839], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 21 - 207: dog - cat || Loss: 1.1290849447250366\n",
      "tensor([0., 1.]) tensor([0.8158, 0.1842], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 21 - 208: dog - cat || Loss: 1.128747582435608\n",
      "tensor([0., 1.]) tensor([0.8155, 0.1845], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 21 - 209: dog - cat || Loss: 1.128395676612854\n",
      "tensor([0., 1.]) tensor([0.8151, 0.1849], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 21 - 210: dog - cat || Loss: 1.1280300617218018\n",
      "tensor([0., 1.]) tensor([0.8148, 0.1852], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 21 - 211: dog - cat || Loss: 1.1276521682739258\n",
      "tensor([0., 1.]) tensor([0.8144, 0.1856], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 21 - 212: dog - cat || Loss: 1.127263069152832\n",
      "tensor([0., 1.]) tensor([0.8140, 0.1860], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 21 - 213: dog - cat || Loss: 1.1268638372421265\n",
      "tensor([0., 1.]) tensor([0.8136, 0.1864], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 21 - 214: dog - cat || Loss: 1.1264554262161255\n",
      "tensor([0., 1.]) tensor([0.8132, 0.1868], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 21 - 215: dog - cat || Loss: 1.1260385513305664\n",
      "tensor([0., 1.]) tensor([0.8128, 0.1872], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 21 - 216: dog - cat || Loss: 1.1256142854690552\n",
      "tensor([0., 1.]) tensor([0.8124, 0.1876], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 21 - 217: dog - cat || Loss: 1.125182867050171\n",
      "tensor([0., 1.]) tensor([0.8119, 0.1881], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 21 - 218: dog - cat || Loss: 1.1247450113296509\n",
      "tensor([0., 1.]) tensor([0.8115, 0.1885], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 21 - 219: dog - cat || Loss: 1.124301791191101\n",
      "tensor([0., 1.]) tensor([0.8110, 0.1890], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 21 - 220: dog - cat || Loss: 1.1238527297973633\n",
      "tensor([0., 1.]) tensor([0.8106, 0.1894], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 21 - 221: dog - cat || Loss: 1.123399019241333\n",
      "tensor([0., 1.]) tensor([0.8101, 0.1899], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 21 - 222: dog - cat || Loss: 1.1229408979415894\n",
      "tensor([0., 1.]) tensor([0.8097, 0.1903], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 21 - 223: dog - cat || Loss: 1.1224784851074219\n",
      "tensor([0., 1.]) tensor([0.8092, 0.1908], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 21 - 224: dog - cat || Loss: 1.1220123767852783\n",
      "tensor([0., 1.]) tensor([0.8088, 0.1912], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 21 - 225: dog - cat || Loss: 1.1215428113937378\n",
      "tensor([0., 1.]) tensor([0.8083, 0.1917], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 21 - 226: dog - cat || Loss: 1.1210697889328003\n",
      "tensor([0., 1.]) tensor([0.8078, 0.1922], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 21 - 227: dog - cat || Loss: 1.1205940246582031\n",
      "tensor([0., 1.]) tensor([0.8073, 0.1927], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 21 - 228: dog - cat || Loss: 1.1201152801513672\n",
      "tensor([0., 1.]) tensor([0.8069, 0.1931], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 21 - 229: dog - cat || Loss: 1.1196340322494507\n",
      "tensor([0., 1.]) tensor([0.8064, 0.1936], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 21 - 230: dog - cat || Loss: 1.119149923324585\n",
      "tensor([0., 1.]) tensor([0.8059, 0.1941], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 21 - 231: dog - cat || Loss: 1.1186639070510864\n",
      "tensor([0., 1.]) tensor([0.8054, 0.1946], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 21 - 232: dog - cat || Loss: 1.1181756258010864\n",
      "tensor([0., 1.]) tensor([0.8049, 0.1951], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 21 - 233: dog - cat || Loss: 1.117685317993164\n",
      "tensor([0., 1.]) tensor([0.8044, 0.1956], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 21 - 234: dog - cat || Loss: 1.1171931028366089\n",
      "tensor([0., 1.]) tensor([0.8039, 0.1961], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 21 - 235: dog - cat || Loss: 1.116698980331421\n",
      "tensor([0., 1.]) tensor([0.8034, 0.1966], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 21 - 236: dog - cat || Loss: 1.1162030696868896\n",
      "tensor([0., 1.]) tensor([0.8029, 0.1971], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 21 - 237: dog - cat || Loss: 1.1157057285308838\n",
      "tensor([0., 1.]) tensor([0.8024, 0.1976], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 21 - 238: dog - cat || Loss: 1.1152064800262451\n",
      "tensor([0., 1.]) tensor([0.8019, 0.1981], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 21 - 239: dog - cat || Loss: 1.1147059202194214\n",
      "tensor([0., 1.]) tensor([0.8014, 0.1986], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 21 - 240: dog - cat || Loss: 1.1142038106918335\n",
      "tensor([0., 1.]) tensor([0.8009, 0.1991], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 21 - 241: dog - cat || Loss: 1.1137003898620605\n",
      "tensor([0., 1.]) tensor([0.8004, 0.1996], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 21 - 242: dog - cat || Loss: 1.113195538520813\n",
      "tensor([0., 1.]) tensor([0.7999, 0.2001], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 21 - 243: dog - cat || Loss: 1.1126893758773804\n",
      "tensor([0., 1.]) tensor([0.7994, 0.2006], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 21 - 244: dog - cat || Loss: 1.1121817827224731\n",
      "tensor([0., 1.]) tensor([0.7989, 0.2011], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 21 - 245: dog - cat || Loss: 1.111673355102539\n",
      "tensor([0., 1.]) tensor([0.7984, 0.2016], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 21 - 246: dog - cat || Loss: 1.1111634969711304\n",
      "tensor([0., 1.]) tensor([0.7979, 0.2021], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 21 - 247: dog - cat || Loss: 1.1106523275375366\n",
      "tensor([0., 1.]) tensor([0.7974, 0.2026], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 21 - 248: dog - cat || Loss: 1.110140085220337\n",
      "tensor([0., 1.]) tensor([0.7969, 0.2031], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 21 - 249: dog - cat || Loss: 1.1096266508102417\n",
      "tensor([0., 1.]) tensor([0.7964, 0.2036], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 21 - 250: dog - cat || Loss: 1.10911226272583\n",
      "tensor([0., 1.]) tensor([0.7959, 0.2041], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 21 - 251: dog - cat || Loss: 1.108596682548523\n",
      "tensor([0., 1.]) tensor([0.7953, 0.2047], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 21 - 252: dog - cat || Loss: 1.1080801486968994\n",
      "tensor([0., 1.]) tensor([0.7948, 0.2052], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 21 - 253: dog - cat || Loss: 1.1075623035430908\n",
      "tensor([0., 1.]) tensor([0.7943, 0.2057], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 21 - 254: dog - cat || Loss: 1.1070436239242554\n",
      "tensor([0., 1.]) tensor([0.7938, 0.2062], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 21 - 255: dog - cat || Loss: 1.1065237522125244\n",
      "tensor([0., 1.]) tensor([0.7933, 0.2067], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 21 - 256: dog - cat || Loss: 1.106002926826477\n",
      "tensor([0., 1.]) tensor([0.7927, 0.2073], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 21 - 257: dog - cat || Loss: 1.1054811477661133\n",
      "tensor([0., 1.]) tensor([0.7922, 0.2078], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 21 - 258: dog - cat || Loss: 1.1049582958221436\n",
      "tensor([0., 1.]) tensor([0.7917, 0.2083], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 21 - 259: dog - cat || Loss: 1.1044344902038574\n",
      "tensor([0., 1.]) tensor([0.7912, 0.2088], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 21 - 260: dog - cat || Loss: 1.1039094924926758\n",
      "tensor([0., 1.]) tensor([0.7906, 0.2094], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 21 - 261: dog - cat || Loss: 1.1033836603164673\n",
      "tensor([0., 1.]) tensor([0.7901, 0.2099], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 21 - 262: dog - cat || Loss: 1.102856993675232\n",
      "tensor([0., 1.]) tensor([0.7896, 0.2104], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 21 - 263: dog - cat || Loss: 1.102329134941101\n",
      "tensor([0., 1.]) tensor([0.7891, 0.2109], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 21 - 264: dog - cat || Loss: 1.101800560951233\n",
      "tensor([0., 1.]) tensor([0.7885, 0.2115], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 21 - 265: dog - cat || Loss: 1.1012706756591797\n",
      "tensor([0., 1.]) tensor([0.7880, 0.2120], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 21 - 266: dog - cat || Loss: 1.1007400751113892\n",
      "tensor([0., 1.]) tensor([0.7875, 0.2125], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 21 - 267: dog - cat || Loss: 1.1002086400985718\n",
      "tensor([0., 1.]) tensor([0.7869, 0.2131], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 21 - 268: dog - cat || Loss: 1.0996758937835693\n",
      "tensor([0., 1.]) tensor([0.7864, 0.2136], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 21 - 269: dog - cat || Loss: 1.0991424322128296\n",
      "tensor([0., 1.]) tensor([0.7859, 0.2141], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 21 - 270: dog - cat || Loss: 1.0986078977584839\n",
      "tensor([0., 1.]) tensor([0.7853, 0.2147], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 21 - 271: dog - cat || Loss: 1.0980726480484009\n",
      "tensor([0., 1.]) tensor([0.7848, 0.2152], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 21 - 272: dog - cat || Loss: 1.097536325454712\n",
      "tensor([0., 1.]) tensor([0.7843, 0.2157], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 21 - 273: dog - cat || Loss: 1.096998929977417\n",
      "tensor([0., 1.]) tensor([0.7837, 0.2163], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 21 - 274: dog - cat || Loss: 1.0964608192443848\n",
      "tensor([0., 1.]) tensor([0.7832, 0.2168], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 21 - 275: dog - cat || Loss: 1.095921516418457\n",
      "tensor([0., 1.]) tensor([0.7827, 0.2173], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 21 - 276: dog - cat || Loss: 1.095381498336792\n",
      "tensor([0., 1.]) tensor([0.7821, 0.2179], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 21 - 277: dog - cat || Loss: 1.0948405265808105\n",
      "tensor([0., 1.]) tensor([0.7816, 0.2184], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 21 - 278: dog - cat || Loss: 1.0942986011505127\n",
      "tensor([0., 1.]) tensor([0.7810, 0.2190], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 21 - 279: dog - cat || Loss: 1.0937556028366089\n",
      "tensor([0., 1.]) tensor([0.7805, 0.2195], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 21 - 280: dog - cat || Loss: 1.0932117700576782\n",
      "tensor([0., 1.]) tensor([0.7800, 0.2200], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 21 - 281: dog - cat || Loss: 1.0926671028137207\n",
      "tensor([0., 1.]) tensor([0.7794, 0.2206], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 21 - 282: dog - cat || Loss: 1.0921216011047363\n",
      "tensor([0., 1.]) tensor([0.7789, 0.2211], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 21 - 283: dog - cat || Loss: 1.0915749073028564\n",
      "tensor([0., 1.]) tensor([0.7783, 0.2217], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 21 - 284: dog - cat || Loss: 1.0910273790359497\n",
      "tensor([0., 1.]) tensor([0.7778, 0.2222], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 21 - 285: dog - cat || Loss: 1.0904790163040161\n",
      "tensor([0., 1.]) tensor([0.7772, 0.2228], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 21 - 286: dog - cat || Loss: 1.0899295806884766\n",
      "tensor([0., 1.]) tensor([0.7767, 0.2233], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 21 - 287: dog - cat || Loss: 1.0893793106079102\n",
      "tensor([0., 1.]) tensor([0.7761, 0.2239], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 21 - 288: dog - cat || Loss: 1.0888283252716064\n",
      "tensor([0., 1.]) tensor([0.7756, 0.2244], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 21 - 289: dog - cat || Loss: 1.0882760286331177\n",
      "tensor([0., 1.]) tensor([0.7750, 0.2250], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 21 - 290: dog - cat || Loss: 1.0877231359481812\n",
      "tensor([0., 1.]) tensor([0.7745, 0.2255], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 21 - 291: dog - cat || Loss: 1.0871692895889282\n",
      "tensor([0., 1.]) tensor([0.7739, 0.2261], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 21 - 292: dog - cat || Loss: 1.0866143703460693\n",
      "tensor([0., 1.]) tensor([0.7734, 0.2266], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 21 - 293: dog - cat || Loss: 1.0860588550567627\n",
      "tensor([0., 1.]) tensor([0.7728, 0.2272], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 21 - 294: dog - cat || Loss: 1.085502028465271\n",
      "tensor([0., 1.]) tensor([0.7722, 0.2278], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 21 - 295: dog - cat || Loss: 1.084944486618042\n",
      "tensor([0., 1.]) tensor([0.7717, 0.2283], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 21 - 296: dog - cat || Loss: 1.0843859910964966\n",
      "tensor([0., 1.]) tensor([0.7711, 0.2289], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 21 - 297: dog - cat || Loss: 1.0838267803192139\n",
      "tensor([0., 1.]) tensor([0.7706, 0.2294], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 21 - 298: dog - cat || Loss: 1.0832663774490356\n",
      "tensor([0., 1.]) tensor([0.7700, 0.2300], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 21 - 299: dog - cat || Loss: 1.0827054977416992\n",
      "tensor([0., 1.]) tensor([0.7694, 0.2306], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 21 - 300: dog - cat || Loss: 1.0821434259414673\n",
      "tensor([0., 1.]) tensor([0.7689, 0.2311], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 21 - 301: dog - cat || Loss: 1.0815801620483398\n",
      "tensor([0., 1.]) tensor([0.7683, 0.2317], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 21 - 302: dog - cat || Loss: 1.0810165405273438\n",
      "tensor([0., 1.]) tensor([0.7678, 0.2322], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 21 - 303: dog - cat || Loss: 1.0804517269134521\n",
      "tensor([0., 1.]) tensor([0.7672, 0.2328], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 21 - 304: dog - cat || Loss: 1.0798859596252441\n",
      "tensor([0., 1.]) tensor([0.7666, 0.2334], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 21 - 305: dog - cat || Loss: 1.0793193578720093\n",
      "tensor([0., 1.]) tensor([0.7661, 0.2339], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 21 - 306: dog - cat || Loss: 1.0787521600723267\n",
      "tensor([0., 1.]) tensor([0.7655, 0.2345], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 21 - 307: dog - cat || Loss: 1.0781837701797485\n",
      "tensor([0., 1.]) tensor([0.7649, 0.2351], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 21 - 308: dog - cat || Loss: 1.0776145458221436\n",
      "tensor([0., 1.]) tensor([0.7644, 0.2356], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 21 - 309: dog - cat || Loss: 1.0770444869995117\n",
      "tensor([0., 1.]) tensor([0.7638, 0.2362], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 21 - 310: dog - cat || Loss: 1.076473355293274\n",
      "tensor([0., 1.]) tensor([0.7632, 0.2368], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 21 - 311: dog - cat || Loss: 1.0759013891220093\n",
      "tensor([0., 1.]) tensor([0.7626, 0.2374], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 21 - 312: dog - cat || Loss: 1.0753285884857178\n",
      "tensor([0., 1.]) tensor([0.7621, 0.2379], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 21 - 313: dog - cat || Loss: 1.0747549533843994\n",
      "tensor([0., 1.]) tensor([0.7615, 0.2385], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 21 - 314: dog - cat || Loss: 1.074180245399475\n",
      "tensor([0., 1.]) tensor([0.7609, 0.2391], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 21 - 315: dog - cat || Loss: 1.0736048221588135\n",
      "tensor([0., 1.]) tensor([0.7603, 0.2397], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 21 - 316: dog - cat || Loss: 1.073028564453125\n",
      "tensor([0., 1.]) tensor([0.7598, 0.2402], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 21 - 317: dog - cat || Loss: 1.0724512338638306\n",
      "tensor([0., 1.]) tensor([0.7592, 0.2408], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 21 - 318: dog - cat || Loss: 1.0718729496002197\n",
      "tensor([0., 1.]) tensor([0.7586, 0.2414], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 21 - 319: dog - cat || Loss: 1.0712941884994507\n",
      "tensor([0., 1.]) tensor([0.7580, 0.2420], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 21 - 320: dog - cat || Loss: 1.0707143545150757\n",
      "tensor([0., 1.]) tensor([0.7575, 0.2425], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 21 - 321: dog - cat || Loss: 1.0701334476470947\n",
      "tensor([0., 1.]) tensor([0.7569, 0.2431], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 21 - 322: dog - cat || Loss: 1.069551944732666\n",
      "tensor([0., 1.]) tensor([0.7563, 0.2437], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 21 - 323: dog - cat || Loss: 1.0689693689346313\n",
      "tensor([0., 1.]) tensor([0.7557, 0.2443], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 21 - 324: dog - cat || Loss: 1.0683859586715698\n",
      "tensor([0., 1.]) tensor([0.7551, 0.2449], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 21 - 325: dog - cat || Loss: 1.067801594734192\n",
      "tensor([0., 1.]) tensor([0.7545, 0.2455], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 21 - 326: dog - cat || Loss: 1.0672166347503662\n",
      "tensor([0., 1.]) tensor([0.7540, 0.2460], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 21 - 327: dog - cat || Loss: 1.066630482673645\n",
      "tensor([0., 1.]) tensor([0.7534, 0.2466], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 21 - 328: dog - cat || Loss: 1.066043496131897\n",
      "tensor([0., 1.]) tensor([0.7528, 0.2472], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 21 - 329: dog - cat || Loss: 1.0654557943344116\n",
      "tensor([0., 1.]) tensor([0.7522, 0.2478], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 21 - 330: dog - cat || Loss: 1.0648672580718994\n",
      "tensor([0., 1.]) tensor([0.7516, 0.2484], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 21 - 331: dog - cat || Loss: 1.0642775297164917\n",
      "tensor([0., 1.]) tensor([0.7510, 0.2490], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 21 - 332: dog - cat || Loss: 1.0636873245239258\n",
      "tensor([0., 1.]) tensor([0.7504, 0.2496], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 21 - 333: dog - cat || Loss: 1.0630959272384644\n",
      "tensor([0., 1.]) tensor([0.7498, 0.2502], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 21 - 334: dog - cat || Loss: 1.062503695487976\n",
      "tensor([0., 1.]) tensor([0.7492, 0.2508], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 21 - 335: dog - cat || Loss: 1.0619107484817505\n",
      "tensor([0., 1.]) tensor([0.7486, 0.2514], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 21 - 336: dog - cat || Loss: 1.061316967010498\n",
      "tensor([0., 1.]) tensor([0.7481, 0.2519], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 21 - 337: dog - cat || Loss: 1.0607221126556396\n",
      "tensor([0., 1.]) tensor([0.7475, 0.2525], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 21 - 338: dog - cat || Loss: 1.0601266622543335\n",
      "tensor([0., 1.]) tensor([0.7469, 0.2531], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 21 - 339: dog - cat || Loss: 1.0595301389694214\n",
      "tensor([0., 1.]) tensor([0.7463, 0.2537], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 21 - 340: dog - cat || Loss: 1.0589326620101929\n",
      "tensor([0., 1.]) tensor([0.7457, 0.2543], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 21 - 341: dog - cat || Loss: 1.058334469795227\n",
      "tensor([0., 1.]) tensor([0.7451, 0.2549], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 21 - 342: dog - cat || Loss: 1.0577353239059448\n",
      "tensor([0., 1.]) tensor([0.7445, 0.2555], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 21 - 343: dog - cat || Loss: 1.0571353435516357\n",
      "tensor([0., 1.]) tensor([0.7439, 0.2561], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 21 - 344: dog - cat || Loss: 1.0565346479415894\n",
      "tensor([0., 1.]) tensor([0.7433, 0.2567], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 21 - 345: dog - cat || Loss: 1.055932879447937\n",
      "tensor([0., 1.]) tensor([0.7427, 0.2573], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 21 - 346: dog - cat || Loss: 1.0553302764892578\n",
      "tensor([0., 1.]) tensor([0.7421, 0.2579], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 21 - 347: dog - cat || Loss: 1.0547269582748413\n",
      "tensor([0., 1.]) tensor([0.7415, 0.2585], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 21 - 348: dog - cat || Loss: 1.0541226863861084\n",
      "tensor([0., 1.]) tensor([0.7409, 0.2591], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 21 - 349: dog - cat || Loss: 1.0535175800323486\n",
      "tensor([0., 1.]) tensor([0.7403, 0.2597], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 21 - 350: dog - cat || Loss: 1.052911639213562\n",
      "tensor([0., 1.]) tensor([0.7397, 0.2604], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 21 - 351: dog - cat || Loss: 1.052304744720459\n",
      "tensor([0., 1.]) tensor([0.7390, 0.2610], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 21 - 352: dog - cat || Loss: 1.0516971349716187\n",
      "tensor([0., 1.]) tensor([0.7384, 0.2616], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 21 - 353: dog - cat || Loss: 1.0510884523391724\n",
      "tensor([0., 1.]) tensor([0.7378, 0.2622], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 21 - 354: dog - cat || Loss: 1.0504789352416992\n",
      "tensor([0., 1.]) tensor([0.7372, 0.2628], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 21 - 355: dog - cat || Loss: 1.0498687028884888\n",
      "tensor([0., 1.]) tensor([0.7366, 0.2634], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 21 - 356: dog - cat || Loss: 1.049257755279541\n",
      "tensor([0., 1.]) tensor([0.7360, 0.2640], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 21 - 357: dog - cat || Loss: 1.0486456155776978\n",
      "tensor([0., 1.]) tensor([0.7354, 0.2646], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 21 - 358: dog - cat || Loss: 1.0480329990386963\n",
      "tensor([0., 1.]) tensor([0.7348, 0.2652], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 21 - 359: dog - cat || Loss: 1.0474193096160889\n",
      "tensor([0., 1.]) tensor([0.7342, 0.2658], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 21 - 360: dog - cat || Loss: 1.0468049049377441\n",
      "tensor([0., 1.]) tensor([0.7335, 0.2665], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 21 - 361: dog - cat || Loss: 1.046189546585083\n",
      "tensor([0., 1.]) tensor([0.7329, 0.2671], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 21 - 362: dog - cat || Loss: 1.0455734729766846\n",
      "tensor([0., 1.]) tensor([0.7323, 0.2677], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 21 - 363: dog - cat || Loss: 1.0449565649032593\n",
      "tensor([0., 1.]) tensor([0.7317, 0.2683], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 21 - 364: dog - cat || Loss: 1.0443387031555176\n",
      "tensor([0., 1.]) tensor([0.7311, 0.2689], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 21 - 365: dog - cat || Loss: 1.0437203645706177\n",
      "tensor([0., 1.]) tensor([0.7305, 0.2695], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 21 - 366: dog - cat || Loss: 1.0431007146835327\n",
      "tensor([0., 1.]) tensor([0.7298, 0.2702], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 21 - 367: dog - cat || Loss: 1.0424805879592896\n",
      "tensor([0., 1.]) tensor([0.7292, 0.2708], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 21 - 368: dog - cat || Loss: 1.04185950756073\n",
      "tensor([0., 1.]) tensor([0.7286, 0.2714], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 21 - 369: dog - cat || Loss: 1.0412375926971436\n",
      "tensor([0., 1.]) tensor([0.7280, 0.2720], grad_fn=<SoftmaxBackward0>)\n",
      "=====epoch:22=====\n",
      "Epoch 22 - 0: cat - cat || Loss: 0.5859085321426392\n",
      "tensor([1., 0.]) tensor([0.7274, 0.2726], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 22 - 1: cat - cat || Loss: 0.5864065289497375\n",
      "tensor([1., 0.]) tensor([0.7269, 0.2731], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 22 - 2: cat - cat || Loss: 0.5867922902107239\n",
      "tensor([1., 0.]) tensor([0.7265, 0.2735], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 22 - 3: cat - cat || Loss: 0.5870764851570129\n",
      "tensor([1., 0.]) tensor([0.7262, 0.2738], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 22 - 4: cat - cat || Loss: 0.5872695446014404\n",
      "tensor([1., 0.]) tensor([0.7260, 0.2740], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 22 - 5: cat - cat || Loss: 0.5873804092407227\n",
      "tensor([1., 0.]) tensor([0.7259, 0.2741], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 22 - 6: cat - cat || Loss: 0.5874172449111938\n",
      "tensor([1., 0.]) tensor([0.7258, 0.2742], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 22 - 7: cat - cat || Loss: 0.5873874425888062\n",
      "tensor([1., 0.]) tensor([0.7259, 0.2741], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 22 - 8: cat - cat || Loss: 0.5872977375984192\n",
      "tensor([1., 0.]) tensor([0.7260, 0.2740], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 22 - 9: cat - cat || Loss: 0.5871540904045105\n",
      "tensor([1., 0.]) tensor([0.7261, 0.2739], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 22 - 10: cat - cat || Loss: 0.5869618654251099\n",
      "tensor([1., 0.]) tensor([0.7263, 0.2737], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 22 - 11: cat - cat || Loss: 0.586726188659668\n",
      "tensor([1., 0.]) tensor([0.7265, 0.2735], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 22 - 12: cat - cat || Loss: 0.5864512920379639\n",
      "tensor([1., 0.]) tensor([0.7268, 0.2732], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 22 - 13: cat - cat || Loss: 0.5861412882804871\n",
      "tensor([1., 0.]) tensor([0.7271, 0.2729], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 22 - 14: cat - cat || Loss: 0.5857996344566345\n",
      "tensor([1., 0.]) tensor([0.7275, 0.2725], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 22 - 15: cat - cat || Loss: 0.5854296088218689\n",
      "tensor([1., 0.]) tensor([0.7278, 0.2722], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 22 - 16: cat - cat || Loss: 0.5850341320037842\n",
      "tensor([1., 0.]) tensor([0.7282, 0.2718], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 22 - 17: cat - cat || Loss: 0.5846157073974609\n",
      "tensor([1., 0.]) tensor([0.7286, 0.2714], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 22 - 18: cat - cat || Loss: 0.584176778793335\n",
      "tensor([1., 0.]) tensor([0.7291, 0.2709], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 22 - 19: cat - cat || Loss: 0.5837196111679077\n",
      "tensor([1., 0.]) tensor([0.7295, 0.2705], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 22 - 20: cat - cat || Loss: 0.5832457542419434\n",
      "tensor([1., 0.]) tensor([0.7300, 0.2700], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 22 - 21: cat - cat || Loss: 0.5827573537826538\n",
      "tensor([1., 0.]) tensor([0.7305, 0.2695], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 22 - 22: cat - cat || Loss: 0.5822557210922241\n",
      "tensor([1., 0.]) tensor([0.7310, 0.2690], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 22 - 23: cat - cat || Loss: 0.5817424654960632\n",
      "tensor([1., 0.]) tensor([0.7315, 0.2685], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 22 - 24: cat - cat || Loss: 0.5812185406684875\n",
      "tensor([1., 0.]) tensor([0.7320, 0.2680], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 22 - 25: cat - cat || Loss: 0.5806852579116821\n",
      "tensor([1., 0.]) tensor([0.7326, 0.2674], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 22 - 26: cat - cat || Loss: 0.5801436305046082\n",
      "tensor([1., 0.]) tensor([0.7331, 0.2669], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 22 - 27: cat - cat || Loss: 0.579594612121582\n",
      "tensor([1., 0.]) tensor([0.7337, 0.2663], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 22 - 28: cat - cat || Loss: 0.5790390372276306\n",
      "tensor([1., 0.]) tensor([0.7342, 0.2658], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 22 - 29: cat - cat || Loss: 0.5784774422645569\n",
      "tensor([1., 0.]) tensor([0.7348, 0.2652], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 22 - 30: cat - cat || Loss: 0.5779107213020325\n",
      "tensor([1., 0.]) tensor([0.7354, 0.2646], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 22 - 31: cat - cat || Loss: 0.5773394107818604\n",
      "tensor([1., 0.]) tensor([0.7359, 0.2641], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 22 - 32: cat - cat || Loss: 0.5767641067504883\n",
      "tensor([1., 0.]) tensor([0.7365, 0.2635], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 22 - 33: cat - cat || Loss: 0.5761853456497192\n",
      "tensor([1., 0.]) tensor([0.7371, 0.2629], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 22 - 34: cat - cat || Loss: 0.5756033658981323\n",
      "tensor([1., 0.]) tensor([0.7377, 0.2623], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 22 - 35: cat - cat || Loss: 0.5750187039375305\n",
      "tensor([1., 0.]) tensor([0.7382, 0.2618], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 22 - 36: cat - cat || Loss: 0.5744317770004272\n",
      "tensor([1., 0.]) tensor([0.7388, 0.2612], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 22 - 37: cat - cat || Loss: 0.5738428235054016\n",
      "tensor([1., 0.]) tensor([0.7394, 0.2606], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 22 - 38: cat - cat || Loss: 0.5732521414756775\n",
      "tensor([1., 0.]) tensor([0.7400, 0.2600], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 22 - 39: cat - cat || Loss: 0.572659969329834\n",
      "tensor([1., 0.]) tensor([0.7406, 0.2594], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 22 - 40: cat - cat || Loss: 0.5720667243003845\n",
      "tensor([1., 0.]) tensor([0.7412, 0.2588], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 22 - 41: cat - cat || Loss: 0.57147216796875\n",
      "tensor([1., 0.]) tensor([0.7418, 0.2582], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 22 - 42: cat - cat || Loss: 0.5708770155906677\n",
      "tensor([1., 0.]) tensor([0.7424, 0.2576], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 22 - 43: cat - cat || Loss: 0.5702810287475586\n",
      "tensor([1., 0.]) tensor([0.7430, 0.2570], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 22 - 44: cat - cat || Loss: 0.5696847438812256\n",
      "tensor([1., 0.]) tensor([0.7436, 0.2564], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 22 - 45: cat - cat || Loss: 0.5690879821777344\n",
      "tensor([1., 0.]) tensor([0.7442, 0.2558], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 22 - 46: cat - cat || Loss: 0.5684909820556641\n",
      "tensor([1., 0.]) tensor([0.7448, 0.2552], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 22 - 47: cat - cat || Loss: 0.5678939819335938\n",
      "tensor([1., 0.]) tensor([0.7454, 0.2546], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 22 - 48: cat - cat || Loss: 0.5672969222068787\n",
      "tensor([1., 0.]) tensor([0.7460, 0.2540], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 22 - 49: cat - cat || Loss: 0.5666999816894531\n",
      "tensor([1., 0.]) tensor([0.7466, 0.2534], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 22 - 50: cat - cat || Loss: 0.5661031007766724\n",
      "tensor([1., 0.]) tensor([0.7472, 0.2528], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 22 - 51: cat - cat || Loss: 0.5655065774917603\n",
      "tensor([1., 0.]) tensor([0.7478, 0.2522], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 22 - 52: cat - cat || Loss: 0.5649102330207825\n",
      "tensor([1., 0.]) tensor([0.7484, 0.2516], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 22 - 53: cat - cat || Loss: 0.5643142461776733\n",
      "tensor([1., 0.]) tensor([0.7489, 0.2511], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 22 - 54: cat - cat || Loss: 0.5637187361717224\n",
      "tensor([1., 0.]) tensor([0.7495, 0.2505], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 22 - 55: cat - cat || Loss: 0.5631235837936401\n",
      "tensor([1., 0.]) tensor([0.7501, 0.2499], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 22 - 56: cat - cat || Loss: 0.5625290274620056\n",
      "tensor([1., 0.]) tensor([0.7507, 0.2493], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 22 - 57: cat - cat || Loss: 0.5619350075721741\n",
      "tensor([1., 0.]) tensor([0.7513, 0.2487], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 22 - 58: cat - cat || Loss: 0.5613415241241455\n",
      "tensor([1., 0.]) tensor([0.7519, 0.2481], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 22 - 59: cat - cat || Loss: 0.5607487559318542\n",
      "tensor([1., 0.]) tensor([0.7525, 0.2475], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 22 - 60: cat - cat || Loss: 0.5601565837860107\n",
      "tensor([1., 0.]) tensor([0.7531, 0.2469], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 22 - 61: cat - cat || Loss: 0.5595650672912598\n",
      "tensor([1., 0.]) tensor([0.7537, 0.2463], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 22 - 62: cat - cat || Loss: 0.5589742064476013\n",
      "tensor([1., 0.]) tensor([0.7543, 0.2457], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 22 - 63: cat - cat || Loss: 0.5583840608596802\n",
      "tensor([1., 0.]) tensor([0.7549, 0.2451], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 22 - 64: cat - cat || Loss: 0.5577948093414307\n",
      "tensor([1., 0.]) tensor([0.7555, 0.2445], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 22 - 65: cat - cat || Loss: 0.5572061538696289\n",
      "tensor([1., 0.]) tensor([0.7561, 0.2439], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 22 - 66: cat - cat || Loss: 0.556618332862854\n",
      "tensor([1., 0.]) tensor([0.7566, 0.2434], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 22 - 67: cat - cat || Loss: 0.5560314059257507\n",
      "tensor([1., 0.]) tensor([0.7572, 0.2428], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 22 - 68: cat - cat || Loss: 0.5554451942443848\n",
      "tensor([1., 0.]) tensor([0.7578, 0.2422], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 22 - 69: cat - cat || Loss: 0.5548597574234009\n",
      "tensor([1., 0.]) tensor([0.7584, 0.2416], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 22 - 70: cat - cat || Loss: 0.5542752742767334\n",
      "tensor([1., 0.]) tensor([0.7590, 0.2410], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 22 - 71: cat - cat || Loss: 0.5536916255950928\n",
      "tensor([1., 0.]) tensor([0.7596, 0.2404], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 22 - 72: cat - cat || Loss: 0.5531086325645447\n",
      "tensor([1., 0.]) tensor([0.7602, 0.2398], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 22 - 73: cat - cat || Loss: 0.5525267124176025\n",
      "tensor([1., 0.]) tensor([0.7607, 0.2393], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 22 - 74: cat - cat || Loss: 0.5519455671310425\n",
      "tensor([1., 0.]) tensor([0.7613, 0.2387], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 22 - 75: cat - cat || Loss: 0.5513652563095093\n",
      "tensor([1., 0.]) tensor([0.7619, 0.2381], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 22 - 76: cat - cat || Loss: 0.5507858991622925\n",
      "tensor([1., 0.]) tensor([0.7625, 0.2375], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 22 - 77: cat - cat || Loss: 0.5502074956893921\n",
      "tensor([1., 0.]) tensor([0.7631, 0.2369], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 22 - 78: cat - cat || Loss: 0.549629807472229\n",
      "tensor([1., 0.]) tensor([0.7636, 0.2364], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 22 - 79: cat - cat || Loss: 0.5490531921386719\n",
      "tensor([1., 0.]) tensor([0.7642, 0.2358], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 22 - 80: cat - cat || Loss: 0.5484773516654968\n",
      "tensor([1., 0.]) tensor([0.7648, 0.2352], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 22 - 81: cat - cat || Loss: 0.5479023456573486\n",
      "tensor([1., 0.]) tensor([0.7654, 0.2346], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 22 - 82: cat - cat || Loss: 0.5473283529281616\n",
      "tensor([1., 0.]) tensor([0.7659, 0.2341], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 22 - 83: cat - cat || Loss: 0.5467551946640015\n",
      "tensor([1., 0.]) tensor([0.7665, 0.2335], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 22 - 84: cat - cat || Loss: 0.5461829900741577\n",
      "tensor([1., 0.]) tensor([0.7671, 0.2329], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 22 - 85: cat - cat || Loss: 0.5456116795539856\n",
      "tensor([1., 0.]) tensor([0.7676, 0.2324], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 22 - 86: cat - cat || Loss: 0.5450413227081299\n",
      "tensor([1., 0.]) tensor([0.7682, 0.2318], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 22 - 87: cat - cat || Loss: 0.5444719195365906\n",
      "tensor([1., 0.]) tensor([0.7688, 0.2312], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 22 - 88: cat - cat || Loss: 0.5439033508300781\n",
      "tensor([1., 0.]) tensor([0.7694, 0.2306], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 22 - 89: cat - cat || Loss: 0.5433357357978821\n",
      "tensor([1., 0.]) tensor([0.7699, 0.2301], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 22 - 90: cat - cat || Loss: 0.5427690148353577\n",
      "tensor([1., 0.]) tensor([0.7705, 0.2295], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 22 - 91: cat - cat || Loss: 0.5422031879425049\n",
      "tensor([1., 0.]) tensor([0.7711, 0.2289], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 22 - 92: cat - cat || Loss: 0.5416384935379028\n",
      "tensor([1., 0.]) tensor([0.7716, 0.2284], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 22 - 93: cat - cat || Loss: 0.5410745739936829\n",
      "tensor([1., 0.]) tensor([0.7722, 0.2278], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 22 - 94: cat - cat || Loss: 0.5405116081237793\n",
      "tensor([1., 0.]) tensor([0.7728, 0.2272], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 22 - 95: cat - cat || Loss: 0.5399495363235474\n",
      "tensor([1., 0.]) tensor([0.7733, 0.2267], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 22 - 96: cat - cat || Loss: 0.5393884181976318\n",
      "tensor([1., 0.]) tensor([0.7739, 0.2261], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 22 - 97: cat - cat || Loss: 0.5388283729553223\n",
      "tensor([1., 0.]) tensor([0.7744, 0.2256], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 22 - 98: cat - cat || Loss: 0.53826904296875\n",
      "tensor([1., 0.]) tensor([0.7750, 0.2250], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 22 - 99: cat - cat || Loss: 0.5377108454704285\n",
      "tensor([1., 0.]) tensor([0.7756, 0.2244], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 22 - 100: cat - cat || Loss: 0.5371534824371338\n",
      "tensor([1., 0.]) tensor([0.7761, 0.2239], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 22 - 101: cat - cat || Loss: 0.5365970134735107\n",
      "tensor([1., 0.]) tensor([0.7767, 0.2233], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 22 - 102: cat - cat || Loss: 0.5360416173934937\n",
      "tensor([1., 0.]) tensor([0.7772, 0.2228], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 22 - 103: cat - cat || Loss: 0.5354869961738586\n",
      "tensor([1., 0.]) tensor([0.7778, 0.2222], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 22 - 104: cat - cat || Loss: 0.5349333882331848\n",
      "tensor([1., 0.]) tensor([0.7783, 0.2217], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 22 - 105: cat - cat || Loss: 0.5343807935714722\n",
      "tensor([1., 0.]) tensor([0.7789, 0.2211], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 22 - 106: cat - cat || Loss: 0.5338290929794312\n",
      "tensor([1., 0.]) tensor([0.7794, 0.2206], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 22 - 107: cat - cat || Loss: 0.5332782864570618\n",
      "tensor([1., 0.]) tensor([0.7800, 0.2200], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 22 - 108: cat - cat || Loss: 0.5327285528182983\n",
      "tensor([1., 0.]) tensor([0.7805, 0.2195], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 22 - 109: cat - cat || Loss: 0.5321797132492065\n",
      "tensor([1., 0.]) tensor([0.7811, 0.2189], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 22 - 110: cat - cat || Loss: 0.5316317081451416\n",
      "tensor([1., 0.]) tensor([0.7816, 0.2184], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 22 - 111: cat - cat || Loss: 0.5310847163200378\n",
      "tensor([1., 0.]) tensor([0.7822, 0.2178], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 22 - 112: cat - cat || Loss: 0.5305386781692505\n",
      "tensor([1., 0.]) tensor([0.7827, 0.2173], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 22 - 113: cat - cat || Loss: 0.5299937129020691\n",
      "tensor([1., 0.]) tensor([0.7833, 0.2167], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 22 - 114: cat - cat || Loss: 0.5294495820999146\n",
      "tensor([1., 0.]) tensor([0.7838, 0.2162], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 22 - 115: cat - cat || Loss: 0.5289065837860107\n",
      "tensor([1., 0.]) tensor([0.7844, 0.2156], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 22 - 116: cat - cat || Loss: 0.528364360332489\n",
      "tensor([1., 0.]) tensor([0.7849, 0.2151], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 22 - 117: cat - cat || Loss: 0.5278232097625732\n",
      "tensor([1., 0.]) tensor([0.7854, 0.2146], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 22 - 118: cat - cat || Loss: 0.5272829532623291\n",
      "tensor([1., 0.]) tensor([0.7860, 0.2140], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 22 - 119: cat - cat || Loss: 0.5267437100410461\n",
      "tensor([1., 0.]) tensor([0.7865, 0.2135], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 22 - 120: cat - cat || Loss: 0.5262054204940796\n",
      "tensor([1., 0.]) tensor([0.7871, 0.2129], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 22 - 121: cat - cat || Loss: 0.5256680250167847\n",
      "tensor([1., 0.]) tensor([0.7876, 0.2124], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 22 - 122: cat - cat || Loss: 0.5251317024230957\n",
      "tensor([1., 0.]) tensor([0.7881, 0.2119], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 22 - 123: cat - cat || Loss: 0.5245963335037231\n",
      "tensor([1., 0.]) tensor([0.7887, 0.2113], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 22 - 124: cat - cat || Loss: 0.5240617990493774\n",
      "tensor([1., 0.]) tensor([0.7892, 0.2108], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 22 - 125: cat - cat || Loss: 0.5235283374786377\n",
      "tensor([1., 0.]) tensor([0.7897, 0.2103], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 22 - 126: cat - cat || Loss: 0.5229958295822144\n",
      "tensor([1., 0.]) tensor([0.7903, 0.2097], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 22 - 127: cat - cat || Loss: 0.5224642157554626\n",
      "tensor([1., 0.]) tensor([0.7908, 0.2092], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 22 - 128: cat - cat || Loss: 0.5219336748123169\n",
      "tensor([1., 0.]) tensor([0.7913, 0.2087], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 22 - 129: cat - cat || Loss: 0.5214040875434875\n",
      "tensor([1., 0.]) tensor([0.7919, 0.2081], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 22 - 130: cat - cat || Loss: 0.5208754539489746\n",
      "tensor([1., 0.]) tensor([0.7924, 0.2076], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 22 - 131: cat - cat || Loss: 0.5203477144241333\n",
      "tensor([1., 0.]) tensor([0.7929, 0.2071], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 22 - 132: cat - cat || Loss: 0.5198209285736084\n",
      "tensor([1., 0.]) tensor([0.7934, 0.2066], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 22 - 133: cat - cat || Loss: 0.5192952156066895\n",
      "tensor([1., 0.]) tensor([0.7940, 0.2060], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 22 - 134: cat - cat || Loss: 0.5187702775001526\n",
      "tensor([1., 0.]) tensor([0.7945, 0.2055], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 22 - 135: cat - cat || Loss: 0.5182465314865112\n",
      "tensor([1., 0.]) tensor([0.7950, 0.2050], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 22 - 136: cat - cat || Loss: 0.517723560333252\n",
      "tensor([1., 0.]) tensor([0.7955, 0.2045], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 22 - 137: cat - cat || Loss: 0.5172016620635986\n",
      "tensor([1., 0.]) tensor([0.7961, 0.2039], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 22 - 138: cat - cat || Loss: 0.5166805982589722\n",
      "tensor([1., 0.]) tensor([0.7966, 0.2034], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 22 - 139: cat - cat || Loss: 0.5161606669425964\n",
      "tensor([1., 0.]) tensor([0.7971, 0.2029], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 22 - 140: cat - cat || Loss: 0.5156416296958923\n",
      "tensor([1., 0.]) tensor([0.7976, 0.2024], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 22 - 141: cat - cat || Loss: 0.5151236057281494\n",
      "tensor([1., 0.]) tensor([0.7981, 0.2019], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 22 - 142: cat - cat || Loss: 0.5146064758300781\n",
      "tensor([1., 0.]) tensor([0.7987, 0.2013], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 22 - 143: cat - cat || Loss: 0.5140902996063232\n",
      "tensor([1., 0.]) tensor([0.7992, 0.2008], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 22 - 144: cat - cat || Loss: 0.5135751962661743\n",
      "tensor([1., 0.]) tensor([0.7997, 0.2003], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 22 - 145: cat - cat || Loss: 0.5130610466003418\n",
      "tensor([1., 0.]) tensor([0.8002, 0.1998], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 22 - 146: cat - cat || Loss: 0.5125477910041809\n",
      "tensor([1., 0.]) tensor([0.8007, 0.1993], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 22 - 147: cat - cat || Loss: 0.5120354890823364\n",
      "tensor([1., 0.]) tensor([0.8012, 0.1988], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 22 - 148: cat - cat || Loss: 0.5115241408348083\n",
      "tensor([1., 0.]) tensor([0.8017, 0.1983], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 22 - 149: cat - cat || Loss: 0.5110138654708862\n",
      "tensor([1., 0.]) tensor([0.8022, 0.1978], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 22 - 150: cat - cat || Loss: 0.510504424571991\n",
      "tensor([1., 0.]) tensor([0.8028, 0.1972], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 22 - 151: cat - cat || Loss: 0.5099960565567017\n",
      "tensor([1., 0.]) tensor([0.8033, 0.1967], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 22 - 152: cat - cat || Loss: 0.5094886422157288\n",
      "tensor([1., 0.]) tensor([0.8038, 0.1962], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 22 - 153: cat - cat || Loss: 0.5089820623397827\n",
      "tensor([1., 0.]) tensor([0.8043, 0.1957], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 22 - 154: cat - cat || Loss: 0.5084766149520874\n",
      "tensor([1., 0.]) tensor([0.8048, 0.1952], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 22 - 155: cat - cat || Loss: 0.507972002029419\n",
      "tensor([1., 0.]) tensor([0.8053, 0.1947], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 22 - 156: cat - cat || Loss: 0.5074684619903564\n",
      "tensor([1., 0.]) tensor([0.8058, 0.1942], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 22 - 157: cat - cat || Loss: 0.5069659948348999\n",
      "tensor([1., 0.]) tensor([0.8063, 0.1937], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 22 - 158: cat - cat || Loss: 0.5064643025398254\n",
      "tensor([1., 0.]) tensor([0.8068, 0.1932], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 22 - 159: cat - cat || Loss: 0.5059635639190674\n",
      "tensor([1., 0.]) tensor([0.8073, 0.1927], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 22 - 160: cat - cat || Loss: 0.5054638385772705\n",
      "tensor([1., 0.]) tensor([0.8078, 0.1922], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 22 - 161: cat - cat || Loss: 0.5049651861190796\n",
      "tensor([1., 0.]) tensor([0.8083, 0.1917], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 22 - 162: cat - cat || Loss: 0.5044676065444946\n",
      "tensor([1., 0.]) tensor([0.8088, 0.1912], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 22 - 163: cat - cat || Loss: 0.503970742225647\n",
      "tensor([1., 0.]) tensor([0.8093, 0.1907], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 22 - 164: cat - cat || Loss: 0.5034749507904053\n",
      "tensor([1., 0.]) tensor([0.8098, 0.1902], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 22 - 165: cat - cat || Loss: 0.50298011302948\n",
      "tensor([1., 0.]) tensor([0.8103, 0.1897], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 22 - 166: cat - cat || Loss: 0.5024862289428711\n",
      "tensor([1., 0.]) tensor([0.8108, 0.1892], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 22 - 167: cat - cat || Loss: 0.5019932985305786\n",
      "tensor([1., 0.]) tensor([0.8113, 0.1887], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 22 - 168: cat - cat || Loss: 0.5015014410018921\n",
      "tensor([1., 0.]) tensor([0.8118, 0.1882], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 22 - 169: cat - cat || Loss: 0.5010104179382324\n",
      "tensor([1., 0.]) tensor([0.8123, 0.1877], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 22 - 170: cat - cat || Loss: 0.5005203485488892\n",
      "tensor([1., 0.]) tensor([0.8127, 0.1873], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 22 - 171: cat - cat || Loss: 0.5000313520431519\n",
      "tensor([1., 0.]) tensor([0.8132, 0.1868], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 22 - 172: cat - cat || Loss: 0.49954333901405334\n",
      "tensor([1., 0.]) tensor([0.8137, 0.1863], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 22 - 173: cat - cat || Loss: 0.49905622005462646\n",
      "tensor([1., 0.]) tensor([0.8142, 0.1858], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 22 - 174: cat - cat || Loss: 0.4985700845718384\n",
      "tensor([1., 0.]) tensor([0.8147, 0.1853], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 22 - 175: cat - cat || Loss: 0.4980848729610443\n",
      "tensor([1., 0.]) tensor([0.8152, 0.1848], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 22 - 176: cat - cat || Loss: 0.49760061502456665\n",
      "tensor([1., 0.]) tensor([0.8157, 0.1843], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 22 - 177: cat - cat || Loss: 0.49711742997169495\n",
      "tensor([1., 0.]) tensor([0.8161, 0.1839], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 22 - 178: cat - cat || Loss: 0.4966351389884949\n",
      "tensor([1., 0.]) tensor([0.8166, 0.1834], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 22 - 179: cat - cat || Loss: 0.49615392088890076\n",
      "tensor([1., 0.]) tensor([0.8171, 0.1829], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 22 - 180: cat - cat || Loss: 0.49567359685897827\n",
      "tensor([1., 0.]) tensor([0.8176, 0.1824], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 22 - 181: cat - cat || Loss: 0.4951941967010498\n",
      "tensor([1., 0.]) tensor([0.8181, 0.1819], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 22 - 182: cat - cat || Loss: 0.4947158694267273\n",
      "tensor([1., 0.]) tensor([0.8185, 0.1815], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 22 - 183: cat - cat || Loss: 0.4942384958267212\n",
      "tensor([1., 0.]) tensor([0.8190, 0.1810], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 22 - 184: cat - cat || Loss: 0.4937620759010315\n",
      "tensor([1., 0.]) tensor([0.8195, 0.1805], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 22 - 185: cat - cat || Loss: 0.493286669254303\n",
      "tensor([1., 0.]) tensor([0.8200, 0.1800], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 22 - 186: cat - cat || Loss: 0.49281197786331177\n",
      "tensor([1., 0.]) tensor([0.8204, 0.1796], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 22 - 187: cat - cat || Loss: 0.49233847856521606\n",
      "tensor([1., 0.]) tensor([0.8209, 0.1791], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 22 - 188: cat - cat || Loss: 0.49186593294143677\n",
      "tensor([1., 0.]) tensor([0.8214, 0.1786], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 22 - 189: cat - cat || Loss: 0.4913942217826843\n",
      "tensor([1., 0.]) tensor([0.8219, 0.1781], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 22 - 190: dog - cat || Loss: 1.1355998516082764\n",
      "tensor([0., 1.]) tensor([0.8223, 0.1777], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 22 - 191: dog - cat || Loss: 1.1359763145446777\n",
      "tensor([0., 1.]) tensor([0.8227, 0.1773], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 22 - 192: dog - cat || Loss: 1.1362684965133667\n",
      "tensor([0., 1.]) tensor([0.8230, 0.1770], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 22 - 193: dog - cat || Loss: 1.1364847421646118\n",
      "tensor([0., 1.]) tensor([0.8232, 0.1768], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 22 - 194: dog - cat || Loss: 1.1366329193115234\n",
      "tensor([0., 1.]) tensor([0.8234, 0.1766], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 22 - 195: dog - cat || Loss: 1.1367199420928955\n",
      "tensor([0., 1.]) tensor([0.8235, 0.1765], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 22 - 196: dog - cat || Loss: 1.1367518901824951\n",
      "tensor([0., 1.]) tensor([0.8235, 0.1765], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 22 - 197: dog - cat || Loss: 1.136734127998352\n",
      "tensor([0., 1.]) tensor([0.8235, 0.1765], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 22 - 198: dog - cat || Loss: 1.136672019958496\n",
      "tensor([0., 1.]) tensor([0.8234, 0.1766], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 22 - 199: dog - cat || Loss: 1.1365694999694824\n",
      "tensor([0., 1.]) tensor([0.8233, 0.1767], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 22 - 200: dog - cat || Loss: 1.1364308595657349\n",
      "tensor([0., 1.]) tensor([0.8232, 0.1768], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 22 - 201: dog - cat || Loss: 1.1362595558166504\n",
      "tensor([0., 1.]) tensor([0.8230, 0.1770], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 22 - 202: dog - cat || Loss: 1.1360589265823364\n",
      "tensor([0., 1.]) tensor([0.8228, 0.1772], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 22 - 203: dog - cat || Loss: 1.1358318328857422\n",
      "tensor([0., 1.]) tensor([0.8226, 0.1774], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 22 - 204: dog - cat || Loss: 1.1355808973312378\n",
      "tensor([0., 1.]) tensor([0.8223, 0.1777], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 22 - 205: dog - cat || Loss: 1.135308027267456\n",
      "tensor([0., 1.]) tensor([0.8220, 0.1780], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 22 - 206: dog - cat || Loss: 1.1350157260894775\n",
      "tensor([0., 1.]) tensor([0.8218, 0.1782], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 22 - 207: dog - cat || Loss: 1.1347061395645142\n",
      "tensor([0., 1.]) tensor([0.8214, 0.1786], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 22 - 208: dog - cat || Loss: 1.1343802213668823\n",
      "tensor([0., 1.]) tensor([0.8211, 0.1789], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 22 - 209: dog - cat || Loss: 1.1340398788452148\n",
      "tensor([0., 1.]) tensor([0.8208, 0.1792], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 22 - 210: dog - cat || Loss: 1.1336865425109863\n",
      "tensor([0., 1.]) tensor([0.8204, 0.1796], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 22 - 211: dog - cat || Loss: 1.1333211660385132\n",
      "tensor([0., 1.]) tensor([0.8201, 0.1799], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 22 - 212: dog - cat || Loss: 1.13294517993927\n",
      "tensor([0., 1.]) tensor([0.8197, 0.1803], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 22 - 213: dog - cat || Loss: 1.1325592994689941\n",
      "tensor([0., 1.]) tensor([0.8193, 0.1807], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 22 - 214: dog - cat || Loss: 1.1321645975112915\n",
      "tensor([0., 1.]) tensor([0.8189, 0.1811], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 22 - 215: dog - cat || Loss: 1.1317617893218994\n",
      "tensor([0., 1.]) tensor([0.8185, 0.1815], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 22 - 216: dog - cat || Loss: 1.1313515901565552\n",
      "tensor([0., 1.]) tensor([0.8181, 0.1819], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 22 - 217: dog - cat || Loss: 1.130934476852417\n",
      "tensor([0., 1.]) tensor([0.8177, 0.1823], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 22 - 218: dog - cat || Loss: 1.1305114030838013\n",
      "tensor([0., 1.]) tensor([0.8172, 0.1828], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 22 - 219: dog - cat || Loss: 1.1300828456878662\n",
      "tensor([0., 1.]) tensor([0.8168, 0.1832], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 22 - 220: dog - cat || Loss: 1.1296489238739014\n",
      "tensor([0., 1.]) tensor([0.8164, 0.1836], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 22 - 221: dog - cat || Loss: 1.129210352897644\n",
      "tensor([0., 1.]) tensor([0.8159, 0.1841], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 22 - 222: dog - cat || Loss: 1.1287672519683838\n",
      "tensor([0., 1.]) tensor([0.8155, 0.1845], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 22 - 223: dog - cat || Loss: 1.1283202171325684\n",
      "tensor([0., 1.]) tensor([0.8151, 0.1849], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 22 - 224: dog - cat || Loss: 1.1278696060180664\n",
      "tensor([0., 1.]) tensor([0.8146, 0.1854], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 22 - 225: dog - cat || Loss: 1.1274155378341675\n",
      "tensor([0., 1.]) tensor([0.8142, 0.1858], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 22 - 226: dog - cat || Loss: 1.1269582509994507\n",
      "tensor([0., 1.]) tensor([0.8137, 0.1863], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 22 - 227: dog - cat || Loss: 1.1264979839324951\n",
      "tensor([0., 1.]) tensor([0.8132, 0.1868], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 22 - 228: dog - cat || Loss: 1.1260349750518799\n",
      "tensor([0., 1.]) tensor([0.8128, 0.1872], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 22 - 229: dog - cat || Loss: 1.1255695819854736\n",
      "tensor([0., 1.]) tensor([0.8123, 0.1877], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 22 - 230: dog - cat || Loss: 1.1251014471054077\n",
      "tensor([0., 1.]) tensor([0.8118, 0.1882], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 22 - 231: dog - cat || Loss: 1.1246312856674194\n",
      "tensor([0., 1.]) tensor([0.8114, 0.1886], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 22 - 232: dog - cat || Loss: 1.1241589784622192\n",
      "tensor([0., 1.]) tensor([0.8109, 0.1891], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 22 - 233: dog - cat || Loss: 1.1236847639083862\n",
      "tensor([0., 1.]) tensor([0.8104, 0.1896], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 22 - 234: dog - cat || Loss: 1.1232085227966309\n",
      "tensor([0., 1.]) tensor([0.8099, 0.1901], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 22 - 235: dog - cat || Loss: 1.1227304935455322\n",
      "tensor([0., 1.]) tensor([0.8095, 0.1905], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 22 - 236: dog - cat || Loss: 1.1222509145736694\n",
      "tensor([0., 1.]) tensor([0.8090, 0.1910], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 22 - 237: dog - cat || Loss: 1.1217694282531738\n",
      "tensor([0., 1.]) tensor([0.8085, 0.1915], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 22 - 238: dog - cat || Loss: 1.1212866306304932\n",
      "tensor([0., 1.]) tensor([0.8080, 0.1920], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 22 - 239: dog - cat || Loss: 1.1208021640777588\n",
      "tensor([0., 1.]) tensor([0.8075, 0.1925], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 22 - 240: dog - cat || Loss: 1.1203162670135498\n",
      "tensor([0., 1.]) tensor([0.8071, 0.1929], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 22 - 241: dog - cat || Loss: 1.1198290586471558\n",
      "tensor([0., 1.]) tensor([0.8066, 0.1934], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 22 - 242: dog - cat || Loss: 1.1193405389785767\n",
      "tensor([0., 1.]) tensor([0.8061, 0.1939], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 22 - 243: dog - cat || Loss: 1.1188507080078125\n",
      "tensor([0., 1.]) tensor([0.8056, 0.1944], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 22 - 244: dog - cat || Loss: 1.1183594465255737\n",
      "tensor([0., 1.]) tensor([0.8051, 0.1949], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 22 - 245: dog - cat || Loss: 1.117867112159729\n",
      "tensor([0., 1.]) tensor([0.8046, 0.1954], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 22 - 246: dog - cat || Loss: 1.1173735857009888\n",
      "tensor([0., 1.]) tensor([0.8041, 0.1959], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 22 - 247: dog - cat || Loss: 1.116878867149353\n",
      "tensor([0., 1.]) tensor([0.8036, 0.1964], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 22 - 248: dog - cat || Loss: 1.1163829565048218\n",
      "tensor([0., 1.]) tensor([0.8031, 0.1969], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 22 - 249: dog - cat || Loss: 1.115885853767395\n",
      "tensor([0., 1.]) tensor([0.8026, 0.1974], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 22 - 250: dog - cat || Loss: 1.1153877973556519\n",
      "tensor([0., 1.]) tensor([0.8021, 0.1979], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 22 - 251: dog - cat || Loss: 1.1148885488510132\n",
      "tensor([0., 1.]) tensor([0.8016, 0.1984], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 22 - 252: dog - cat || Loss: 1.114388346672058\n",
      "tensor([0., 1.]) tensor([0.8011, 0.1989], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 22 - 253: dog - cat || Loss: 1.113886833190918\n",
      "tensor([0., 1.]) tensor([0.8006, 0.1994], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 22 - 254: dog - cat || Loss: 1.1133846044540405\n",
      "tensor([0., 1.]) tensor([0.8001, 0.1999], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 22 - 255: dog - cat || Loss: 1.1128811836242676\n",
      "tensor([0., 1.]) tensor([0.7996, 0.2004], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 22 - 256: dog - cat || Loss: 1.1123768091201782\n",
      "tensor([0., 1.]) tensor([0.7991, 0.2009], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 22 - 257: dog - cat || Loss: 1.1118712425231934\n",
      "tensor([0., 1.]) tensor([0.7986, 0.2014], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 22 - 258: dog - cat || Loss: 1.1113649606704712\n",
      "tensor([0., 1.]) tensor([0.7981, 0.2019], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 22 - 259: dog - cat || Loss: 1.1108574867248535\n",
      "tensor([0., 1.]) tensor([0.7976, 0.2024], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 22 - 260: dog - cat || Loss: 1.1103490591049194\n",
      "tensor([0., 1.]) tensor([0.7971, 0.2029], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 22 - 261: dog - cat || Loss: 1.1098397970199585\n",
      "tensor([0., 1.]) tensor([0.7966, 0.2034], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 22 - 262: dog - cat || Loss: 1.109329342842102\n",
      "tensor([0., 1.]) tensor([0.7961, 0.2039], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 22 - 263: dog - cat || Loss: 1.1088179349899292\n",
      "tensor([0., 1.]) tensor([0.7956, 0.2044], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 22 - 264: dog - cat || Loss: 1.10830557346344\n",
      "tensor([0., 1.]) tensor([0.7950, 0.2050], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 22 - 265: dog - cat || Loss: 1.1077922582626343\n",
      "tensor([0., 1.]) tensor([0.7945, 0.2055], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 22 - 266: dog - cat || Loss: 1.1072781085968018\n",
      "tensor([0., 1.]) tensor([0.7940, 0.2060], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 22 - 267: dog - cat || Loss: 1.1067630052566528\n",
      "tensor([0., 1.]) tensor([0.7935, 0.2065], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 22 - 268: dog - cat || Loss: 1.1062469482421875\n",
      "tensor([0., 1.]) tensor([0.7930, 0.2070], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 22 - 269: dog - cat || Loss: 1.1057296991348267\n",
      "tensor([0., 1.]) tensor([0.7925, 0.2075], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 22 - 270: dog - cat || Loss: 1.105211615562439\n",
      "tensor([0., 1.]) tensor([0.7919, 0.2080], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 22 - 271: dog - cat || Loss: 1.104692816734314\n",
      "tensor([0., 1.]) tensor([0.7914, 0.2086], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 22 - 272: dog - cat || Loss: 1.104172706604004\n",
      "tensor([0., 1.]) tensor([0.7909, 0.2091], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 22 - 273: dog - cat || Loss: 1.1036518812179565\n",
      "tensor([0., 1.]) tensor([0.7904, 0.2096], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 22 - 274: dog - cat || Loss: 1.1031301021575928\n",
      "tensor([0., 1.]) tensor([0.7899, 0.2101], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 22 - 275: dog - cat || Loss: 1.1026073694229126\n",
      "tensor([0., 1.]) tensor([0.7893, 0.2107], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 22 - 276: dog - cat || Loss: 1.102083683013916\n",
      "tensor([0., 1.]) tensor([0.7888, 0.2112], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 22 - 277: dog - cat || Loss: 1.1015591621398926\n",
      "tensor([0., 1.]) tensor([0.7883, 0.2117], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 22 - 278: dog - cat || Loss: 1.1010336875915527\n",
      "tensor([0., 1.]) tensor([0.7878, 0.2122], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 22 - 279: dog - cat || Loss: 1.1005072593688965\n",
      "tensor([0., 1.]) tensor([0.7872, 0.2128], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 22 - 280: dog - cat || Loss: 1.0999797582626343\n",
      "tensor([0., 1.]) tensor([0.7867, 0.2133], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 22 - 281: dog - cat || Loss: 1.0994515419006348\n",
      "tensor([0., 1.]) tensor([0.7862, 0.2138], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 22 - 282: dog - cat || Loss: 1.0989221334457397\n",
      "tensor([0., 1.]) tensor([0.7857, 0.2143], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 22 - 283: dog - cat || Loss: 1.0983920097351074\n",
      "tensor([0., 1.]) tensor([0.7851, 0.2149], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 22 - 284: dog - cat || Loss: 1.0978608131408691\n",
      "tensor([0., 1.]) tensor([0.7846, 0.2154], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 22 - 285: dog - cat || Loss: 1.0973289012908936\n",
      "tensor([0., 1.]) tensor([0.7841, 0.2159], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 22 - 286: dog - cat || Loss: 1.0967960357666016\n",
      "tensor([0., 1.]) tensor([0.7835, 0.2165], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 22 - 287: dog - cat || Loss: 1.0962620973587036\n",
      "tensor([0., 1.]) tensor([0.7830, 0.2170], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 22 - 288: dog - cat || Loss: 1.0957273244857788\n",
      "tensor([0., 1.]) tensor([0.7825, 0.2175], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 22 - 289: dog - cat || Loss: 1.0951915979385376\n",
      "tensor([0., 1.]) tensor([0.7819, 0.2181], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 22 - 290: dog - cat || Loss: 1.0946550369262695\n",
      "tensor([0., 1.]) tensor([0.7814, 0.2186], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 22 - 291: dog - cat || Loss: 1.0941174030303955\n",
      "tensor([0., 1.]) tensor([0.7809, 0.2191], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 22 - 292: dog - cat || Loss: 1.093578815460205\n",
      "tensor([0., 1.]) tensor([0.7803, 0.2197], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 22 - 293: dog - cat || Loss: 1.093039631843567\n",
      "tensor([0., 1.]) tensor([0.7798, 0.2202], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 22 - 294: dog - cat || Loss: 1.0924994945526123\n",
      "tensor([0., 1.]) tensor([0.7792, 0.2208], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 22 - 295: dog - cat || Loss: 1.0919581651687622\n",
      "tensor([0., 1.]) tensor([0.7787, 0.2213], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 22 - 296: dog - cat || Loss: 1.0914161205291748\n",
      "tensor([0., 1.]) tensor([0.7782, 0.2218], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 22 - 297: dog - cat || Loss: 1.0908730030059814\n",
      "tensor([0., 1.]) tensor([0.7776, 0.2224], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 22 - 298: dog - cat || Loss: 1.0903291702270508\n",
      "tensor([0., 1.]) tensor([0.7771, 0.2229], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 22 - 299: dog - cat || Loss: 1.0897842645645142\n",
      "tensor([0., 1.]) tensor([0.7765, 0.2235], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 22 - 300: dog - cat || Loss: 1.0892384052276611\n",
      "tensor([0., 1.]) tensor([0.7760, 0.2240], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 22 - 301: dog - cat || Loss: 1.0886917114257812\n",
      "tensor([0., 1.]) tensor([0.7754, 0.2246], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 22 - 302: dog - cat || Loss: 1.088144302368164\n",
      "tensor([0., 1.]) tensor([0.7749, 0.2251], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 22 - 303: dog - cat || Loss: 1.0875957012176514\n",
      "tensor([0., 1.]) tensor([0.7743, 0.2257], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 22 - 304: dog - cat || Loss: 1.0870461463928223\n",
      "tensor([0., 1.]) tensor([0.7738, 0.2262], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 22 - 305: dog - cat || Loss: 1.0864958763122559\n",
      "tensor([0., 1.]) tensor([0.7732, 0.2268], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 22 - 306: dog - cat || Loss: 1.0859445333480835\n",
      "tensor([0., 1.]) tensor([0.7727, 0.2273], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 22 - 307: dog - cat || Loss: 1.0853924751281738\n",
      "tensor([0., 1.]) tensor([0.7721, 0.2279], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 22 - 308: dog - cat || Loss: 1.0848393440246582\n",
      "tensor([0., 1.]) tensor([0.7716, 0.2284], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 22 - 309: dog - cat || Loss: 1.0842853784561157\n",
      "tensor([0., 1.]) tensor([0.7710, 0.2290], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 22 - 310: dog - cat || Loss: 1.0837303400039673\n",
      "tensor([0., 1.]) tensor([0.7705, 0.2295], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 22 - 311: dog - cat || Loss: 1.083174467086792\n",
      "tensor([0., 1.]) tensor([0.7699, 0.2301], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 22 - 312: dog - cat || Loss: 1.0826177597045898\n",
      "tensor([0., 1.]) tensor([0.7694, 0.2306], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 22 - 313: dog - cat || Loss: 1.0820602178573608\n",
      "tensor([0., 1.]) tensor([0.7688, 0.2312], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 22 - 314: dog - cat || Loss: 1.0815016031265259\n",
      "tensor([0., 1.]) tensor([0.7682, 0.2318], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 22 - 315: dog - cat || Loss: 1.0809420347213745\n",
      "tensor([0., 1.]) tensor([0.7677, 0.2323], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 22 - 316: dog - cat || Loss: 1.0803818702697754\n",
      "tensor([0., 1.]) tensor([0.7671, 0.2329], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 22 - 317: dog - cat || Loss: 1.0798205137252808\n",
      "tensor([0., 1.]) tensor([0.7666, 0.2334], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 22 - 318: dog - cat || Loss: 1.0792582035064697\n",
      "tensor([0., 1.]) tensor([0.7660, 0.2340], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 22 - 319: dog - cat || Loss: 1.078695297241211\n",
      "tensor([0., 1.]) tensor([0.7654, 0.2346], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 22 - 320: dog - cat || Loss: 1.0781313180923462\n",
      "tensor([0., 1.]) tensor([0.7649, 0.2351], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 22 - 321: dog - cat || Loss: 1.077566385269165\n",
      "tensor([0., 1.]) tensor([0.7643, 0.2357], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 22 - 322: dog - cat || Loss: 1.0770007371902466\n",
      "tensor([0., 1.]) tensor([0.7637, 0.2363], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 22 - 323: dog - cat || Loss: 1.0764338970184326\n",
      "tensor([0., 1.]) tensor([0.7632, 0.2368], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 22 - 324: dog - cat || Loss: 1.075866460800171\n",
      "tensor([0., 1.]) tensor([0.7626, 0.2374], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 22 - 325: dog - cat || Loss: 1.0752980709075928\n",
      "tensor([0., 1.]) tensor([0.7620, 0.2380], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 22 - 326: dog - cat || Loss: 1.0747286081314087\n",
      "tensor([0., 1.]) tensor([0.7615, 0.2385], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 22 - 327: dog - cat || Loss: 1.0741584300994873\n",
      "tensor([0., 1.]) tensor([0.7609, 0.2391], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 22 - 328: dog - cat || Loss: 1.07358717918396\n",
      "tensor([0., 1.]) tensor([0.7603, 0.2397], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 22 - 329: dog - cat || Loss: 1.0730152130126953\n",
      "tensor([0., 1.]) tensor([0.7598, 0.2402], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 22 - 330: dog - cat || Loss: 1.0724422931671143\n",
      "tensor([0., 1.]) tensor([0.7592, 0.2408], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 22 - 331: dog - cat || Loss: 1.0718684196472168\n",
      "tensor([0., 1.]) tensor([0.7586, 0.2414], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 22 - 332: dog - cat || Loss: 1.071293830871582\n",
      "tensor([0., 1.]) tensor([0.7580, 0.2420], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 22 - 333: dog - cat || Loss: 1.0707182884216309\n",
      "tensor([0., 1.]) tensor([0.7575, 0.2425], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 22 - 334: dog - cat || Loss: 1.0701417922973633\n",
      "tensor([0., 1.]) tensor([0.7569, 0.2431], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 22 - 335: dog - cat || Loss: 1.0695644617080688\n",
      "tensor([0., 1.]) tensor([0.7563, 0.2437], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 22 - 336: dog - cat || Loss: 1.0689862966537476\n",
      "tensor([0., 1.]) tensor([0.7557, 0.2443], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 22 - 337: dog - cat || Loss: 1.0684070587158203\n",
      "tensor([0., 1.]) tensor([0.7551, 0.2449], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 22 - 338: dog - cat || Loss: 1.0678271055221558\n",
      "tensor([0., 1.]) tensor([0.7546, 0.2454], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 22 - 339: dog - cat || Loss: 1.0672460794448853\n",
      "tensor([0., 1.]) tensor([0.7540, 0.2460], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 22 - 340: dog - cat || Loss: 1.0666643381118774\n",
      "tensor([0., 1.]) tensor([0.7534, 0.2466], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 22 - 341: dog - cat || Loss: 1.0660817623138428\n",
      "tensor([0., 1.]) tensor([0.7528, 0.2472], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 22 - 342: dog - cat || Loss: 1.0654981136322021\n",
      "tensor([0., 1.]) tensor([0.7522, 0.2478], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 22 - 343: dog - cat || Loss: 1.0649137496948242\n",
      "tensor([0., 1.]) tensor([0.7517, 0.2483], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 22 - 344: dog - cat || Loss: 1.0643284320831299\n",
      "tensor([0., 1.]) tensor([0.7511, 0.2489], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 22 - 345: dog - cat || Loss: 1.0637421607971191\n",
      "tensor([0., 1.]) tensor([0.7505, 0.2495], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 22 - 346: dog - cat || Loss: 1.063155174255371\n",
      "tensor([0., 1.]) tensor([0.7499, 0.2501], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 22 - 347: dog - cat || Loss: 1.0625672340393066\n",
      "tensor([0., 1.]) tensor([0.7493, 0.2507], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 22 - 348: dog - cat || Loss: 1.0619783401489258\n",
      "tensor([0., 1.]) tensor([0.7487, 0.2513], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 22 - 349: dog - cat || Loss: 1.061388611793518\n",
      "tensor([0., 1.]) tensor([0.7481, 0.2519], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 22 - 350: dog - cat || Loss: 1.060797929763794\n",
      "tensor([0., 1.]) tensor([0.7475, 0.2525], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 22 - 351: dog - cat || Loss: 1.060206413269043\n",
      "tensor([0., 1.]) tensor([0.7469, 0.2531], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 22 - 352: dog - cat || Loss: 1.059613823890686\n",
      "tensor([0., 1.]) tensor([0.7464, 0.2536], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 22 - 353: dog - cat || Loss: 1.0590205192565918\n",
      "tensor([0., 1.]) tensor([0.7458, 0.2542], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 22 - 354: dog - cat || Loss: 1.0584261417388916\n",
      "tensor([0., 1.]) tensor([0.7452, 0.2548], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 22 - 355: dog - cat || Loss: 1.0578311681747437\n",
      "tensor([0., 1.]) tensor([0.7446, 0.2554], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 22 - 356: dog - cat || Loss: 1.0572351217269897\n",
      "tensor([0., 1.]) tensor([0.7440, 0.2560], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 22 - 357: dog - cat || Loss: 1.0566380023956299\n",
      "tensor([0., 1.]) tensor([0.7434, 0.2566], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 22 - 358: dog - cat || Loss: 1.0560401678085327\n",
      "tensor([0., 1.]) tensor([0.7428, 0.2572], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 22 - 359: dog - cat || Loss: 1.0554414987564087\n",
      "tensor([0., 1.]) tensor([0.7422, 0.2578], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 22 - 360: dog - cat || Loss: 1.0548418760299683\n",
      "tensor([0., 1.]) tensor([0.7416, 0.2584], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 22 - 361: dog - cat || Loss: 1.0542411804199219\n",
      "tensor([0., 1.]) tensor([0.7410, 0.2590], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 22 - 362: dog - cat || Loss: 1.0536398887634277\n",
      "tensor([0., 1.]) tensor([0.7404, 0.2596], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 22 - 363: dog - cat || Loss: 1.0530376434326172\n",
      "tensor([0., 1.]) tensor([0.7398, 0.2602], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 22 - 364: dog - cat || Loss: 1.0524343252182007\n",
      "tensor([0., 1.]) tensor([0.7392, 0.2608], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 22 - 365: dog - cat || Loss: 1.0518302917480469\n",
      "tensor([0., 1.]) tensor([0.7386, 0.2614], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 22 - 366: dog - cat || Loss: 1.051225185394287\n",
      "tensor([0., 1.]) tensor([0.7380, 0.2620], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 22 - 367: dog - cat || Loss: 1.0506192445755005\n",
      "tensor([0., 1.]) tensor([0.7374, 0.2626], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 22 - 368: dog - cat || Loss: 1.050012469291687\n",
      "tensor([0., 1.]) tensor([0.7368, 0.2632], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 22 - 369: dog - cat || Loss: 1.0494046211242676\n",
      "tensor([0., 1.]) tensor([0.7361, 0.2639], grad_fn=<SoftmaxBackward0>)\n",
      "=====epoch:23=====\n",
      "Epoch 23 - 0: cat - cat || Loss: 0.577727198600769\n",
      "tensor([1., 0.]) tensor([0.7355, 0.2645], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 23 - 1: cat - cat || Loss: 0.5782138705253601\n",
      "tensor([1., 0.]) tensor([0.7350, 0.2650], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 23 - 2: cat - cat || Loss: 0.5785906314849854\n",
      "tensor([1., 0.]) tensor([0.7347, 0.2653], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 23 - 3: cat - cat || Loss: 0.5788684487342834\n",
      "tensor([1., 0.]) tensor([0.7344, 0.2656], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 23 - 4: cat - cat || Loss: 0.579056978225708\n",
      "tensor([1., 0.]) tensor([0.7342, 0.2658], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 23 - 5: cat - cat || Loss: 0.5791651606559753\n",
      "tensor([1., 0.]) tensor([0.7341, 0.2659], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 23 - 6: cat - cat || Loss: 0.5792009830474854\n",
      "tensor([1., 0.]) tensor([0.7341, 0.2659], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 23 - 7: cat - cat || Loss: 0.5791716575622559\n",
      "tensor([1., 0.]) tensor([0.7341, 0.2659], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 23 - 8: cat - cat || Loss: 0.5790837407112122\n",
      "tensor([1., 0.]) tensor([0.7342, 0.2658], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 23 - 9: cat - cat || Loss: 0.578943133354187\n",
      "tensor([1., 0.]) tensor([0.7343, 0.2657], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 23 - 10: cat - cat || Loss: 0.5787550210952759\n",
      "tensor([1., 0.]) tensor([0.7345, 0.2655], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 23 - 11: cat - cat || Loss: 0.5785244703292847\n",
      "tensor([1., 0.]) tensor([0.7347, 0.2653], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 23 - 12: cat - cat || Loss: 0.5782555341720581\n",
      "tensor([1., 0.]) tensor([0.7350, 0.2650], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 23 - 13: cat - cat || Loss: 0.5779522657394409\n",
      "tensor([1., 0.]) tensor([0.7353, 0.2647], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 23 - 14: cat - cat || Loss: 0.5776180028915405\n",
      "tensor([1., 0.]) tensor([0.7356, 0.2644], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 23 - 15: cat - cat || Loss: 0.5772560834884644\n",
      "tensor([1., 0.]) tensor([0.7360, 0.2640], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 23 - 16: cat - cat || Loss: 0.5768693685531616\n",
      "tensor([1., 0.]) tensor([0.7364, 0.2636], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 23 - 17: cat - cat || Loss: 0.5764602422714233\n",
      "tensor([1., 0.]) tensor([0.7368, 0.2632], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 23 - 18: cat - cat || Loss: 0.5760312080383301\n",
      "tensor([1., 0.]) tensor([0.7372, 0.2628], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 23 - 19: cat - cat || Loss: 0.5755841732025146\n",
      "tensor([1., 0.]) tensor([0.7377, 0.2623], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 23 - 20: cat - cat || Loss: 0.5751211047172546\n",
      "tensor([1., 0.]) tensor([0.7381, 0.2619], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 23 - 21: cat - cat || Loss: 0.5746437311172485\n",
      "tensor([1., 0.]) tensor([0.7386, 0.2614], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 23 - 22: cat - cat || Loss: 0.57415372133255\n",
      "tensor([1., 0.]) tensor([0.7391, 0.2609], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 23 - 23: cat - cat || Loss: 0.5736520886421204\n",
      "tensor([1., 0.]) tensor([0.7396, 0.2604], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 23 - 24: cat - cat || Loss: 0.5731402635574341\n",
      "tensor([1., 0.]) tensor([0.7401, 0.2599], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 23 - 25: cat - cat || Loss: 0.5726194381713867\n",
      "tensor([1., 0.]) tensor([0.7406, 0.2594], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 23 - 26: cat - cat || Loss: 0.5720903873443604\n",
      "tensor([1., 0.]) tensor([0.7412, 0.2588], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 23 - 27: cat - cat || Loss: 0.5715542435646057\n",
      "tensor([1., 0.]) tensor([0.7417, 0.2583], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 23 - 28: cat - cat || Loss: 0.5710116624832153\n",
      "tensor([1., 0.]) tensor([0.7422, 0.2578], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 23 - 29: cat - cat || Loss: 0.5704632997512817\n",
      "tensor([1., 0.]) tensor([0.7428, 0.2572], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 23 - 30: cat - cat || Loss: 0.5699102878570557\n",
      "tensor([1., 0.]) tensor([0.7434, 0.2566], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 23 - 31: cat - cat || Loss: 0.5693526864051819\n",
      "tensor([1., 0.]) tensor([0.7439, 0.2561], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 23 - 32: cat - cat || Loss: 0.5687912702560425\n",
      "tensor([1., 0.]) tensor([0.7445, 0.2555], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 23 - 33: cat - cat || Loss: 0.56822669506073\n",
      "tensor([1., 0.]) tensor([0.7450, 0.2550], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 23 - 34: cat - cat || Loss: 0.5676589012145996\n",
      "tensor([1., 0.]) tensor([0.7456, 0.2544], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 23 - 35: cat - cat || Loss: 0.5670886039733887\n",
      "tensor([1., 0.]) tensor([0.7462, 0.2538], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 23 - 36: cat - cat || Loss: 0.5665160417556763\n",
      "tensor([1., 0.]) tensor([0.7467, 0.2533], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 23 - 37: cat - cat || Loss: 0.5659416317939758\n",
      "tensor([1., 0.]) tensor([0.7473, 0.2527], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 23 - 38: cat - cat || Loss: 0.5653655529022217\n",
      "tensor([1., 0.]) tensor([0.7479, 0.2521], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 23 - 39: cat - cat || Loss: 0.5647879838943481\n",
      "tensor([1., 0.]) tensor([0.7485, 0.2515], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 23 - 40: cat - cat || Loss: 0.5642095804214478\n",
      "tensor([1., 0.]) tensor([0.7491, 0.2509], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 23 - 41: cat - cat || Loss: 0.5636299848556519\n",
      "tensor([1., 0.]) tensor([0.7496, 0.2504], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 23 - 42: cat - cat || Loss: 0.5630497932434082\n",
      "tensor([1., 0.]) tensor([0.7502, 0.2498], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 23 - 43: cat - cat || Loss: 0.5624688267707825\n",
      "tensor([1., 0.]) tensor([0.7508, 0.2492], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 23 - 44: cat - cat || Loss: 0.5618875622749329\n",
      "tensor([1., 0.]) tensor([0.7514, 0.2486], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 23 - 45: cat - cat || Loss: 0.5613058805465698\n",
      "tensor([1., 0.]) tensor([0.7520, 0.2480], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 23 - 46: cat - cat || Loss: 0.5607240200042725\n",
      "tensor([1., 0.]) tensor([0.7525, 0.2475], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 23 - 47: cat - cat || Loss: 0.5601421594619751\n",
      "tensor([1., 0.]) tensor([0.7531, 0.2469], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 23 - 48: cat - cat || Loss: 0.5595602989196777\n",
      "tensor([1., 0.]) tensor([0.7537, 0.2463], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 23 - 49: cat - cat || Loss: 0.5589785575866699\n",
      "tensor([1., 0.]) tensor([0.7543, 0.2457], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 23 - 50: cat - cat || Loss: 0.5583970546722412\n",
      "tensor([1., 0.]) tensor([0.7549, 0.2451], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 23 - 51: cat - cat || Loss: 0.5578158497810364\n",
      "tensor([1., 0.]) tensor([0.7554, 0.2446], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 23 - 52: cat - cat || Loss: 0.5572349429130554\n",
      "tensor([1., 0.]) tensor([0.7560, 0.2440], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 23 - 53: cat - cat || Loss: 0.5566544532775879\n",
      "tensor([1., 0.]) tensor([0.7566, 0.2434], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 23 - 54: cat - cat || Loss: 0.5560742616653442\n",
      "tensor([1., 0.]) tensor([0.7572, 0.2428], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 23 - 55: cat - cat || Loss: 0.5554946660995483\n",
      "tensor([1., 0.]) tensor([0.7578, 0.2422], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 23 - 56: cat - cat || Loss: 0.554915726184845\n",
      "tensor([1., 0.]) tensor([0.7583, 0.2417], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 23 - 57: cat - cat || Loss: 0.5543371438980103\n",
      "tensor([1., 0.]) tensor([0.7589, 0.2411], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 23 - 58: cat - cat || Loss: 0.5537593364715576\n",
      "tensor([1., 0.]) tensor([0.7595, 0.2405], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 23 - 59: cat - cat || Loss: 0.5531821250915527\n",
      "tensor([1., 0.]) tensor([0.7601, 0.2399], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 23 - 60: cat - cat || Loss: 0.5526056289672852\n",
      "tensor([1., 0.]) tensor([0.7607, 0.2393], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 23 - 61: cat - cat || Loss: 0.5520297288894653\n",
      "tensor([1., 0.]) tensor([0.7612, 0.2388], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 23 - 62: cat - cat || Loss: 0.5514546632766724\n",
      "tensor([1., 0.]) tensor([0.7618, 0.2382], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 23 - 63: cat - cat || Loss: 0.5508803129196167\n",
      "tensor([1., 0.]) tensor([0.7624, 0.2376], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 23 - 64: cat - cat || Loss: 0.5503065586090088\n",
      "tensor([1., 0.]) tensor([0.7630, 0.2370], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 23 - 65: cat - cat || Loss: 0.5497337579727173\n",
      "tensor([1., 0.]) tensor([0.7635, 0.2365], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 23 - 66: cat - cat || Loss: 0.5491616725921631\n",
      "tensor([1., 0.]) tensor([0.7641, 0.2359], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 23 - 67: cat - cat || Loss: 0.5485905408859253\n",
      "tensor([1., 0.]) tensor([0.7647, 0.2353], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 23 - 68: cat - cat || Loss: 0.5480200052261353\n",
      "tensor([1., 0.]) tensor([0.7652, 0.2348], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 23 - 69: cat - cat || Loss: 0.5474504232406616\n",
      "tensor([1., 0.]) tensor([0.7658, 0.2342], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 23 - 70: cat - cat || Loss: 0.5468817353248596\n",
      "tensor([1., 0.]) tensor([0.7664, 0.2336], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 23 - 71: cat - cat || Loss: 0.5463138222694397\n",
      "tensor([1., 0.]) tensor([0.7669, 0.2331], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 23 - 72: cat - cat || Loss: 0.5457467436790466\n",
      "tensor([1., 0.]) tensor([0.7675, 0.2325], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 23 - 73: cat - cat || Loss: 0.5451805591583252\n",
      "tensor([1., 0.]) tensor([0.7681, 0.2319], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 23 - 74: cat - cat || Loss: 0.5446152687072754\n",
      "tensor([1., 0.]) tensor([0.7686, 0.2314], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 23 - 75: cat - cat || Loss: 0.544050931930542\n",
      "tensor([1., 0.]) tensor([0.7692, 0.2308], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 23 - 76: cat - cat || Loss: 0.543487548828125\n",
      "tensor([1., 0.]) tensor([0.7698, 0.2302], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 23 - 77: cat - cat || Loss: 0.5429250001907349\n",
      "tensor([1., 0.]) tensor([0.7703, 0.2297], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 23 - 78: cat - cat || Loss: 0.5423632860183716\n",
      "tensor([1., 0.]) tensor([0.7709, 0.2291], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 23 - 79: cat - cat || Loss: 0.5418025255203247\n",
      "tensor([1., 0.]) tensor([0.7715, 0.2285], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 23 - 80: cat - cat || Loss: 0.541242778301239\n",
      "tensor([1., 0.]) tensor([0.7720, 0.2280], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 23 - 81: cat - cat || Loss: 0.5406836867332458\n",
      "tensor([1., 0.]) tensor([0.7726, 0.2274], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 23 - 82: cat - cat || Loss: 0.5401256680488586\n",
      "tensor([1., 0.]) tensor([0.7731, 0.2269], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 23 - 83: cat - cat || Loss: 0.5395686030387878\n",
      "tensor([1., 0.]) tensor([0.7737, 0.2263], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 23 - 84: cat - cat || Loss: 0.5390124917030334\n",
      "tensor([1., 0.]) tensor([0.7742, 0.2258], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 23 - 85: cat - cat || Loss: 0.5384573340415955\n",
      "tensor([1., 0.]) tensor([0.7748, 0.2252], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 23 - 86: cat - cat || Loss: 0.5379030704498291\n",
      "tensor([1., 0.]) tensor([0.7754, 0.2246], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 23 - 87: cat - cat || Loss: 0.5373497009277344\n",
      "tensor([1., 0.]) tensor([0.7759, 0.2241], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 23 - 88: cat - cat || Loss: 0.536797285079956\n",
      "tensor([1., 0.]) tensor([0.7765, 0.2235], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 23 - 89: cat - cat || Loss: 0.5362458825111389\n",
      "tensor([1., 0.]) tensor([0.7770, 0.2230], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 23 - 90: cat - cat || Loss: 0.5356953144073486\n",
      "tensor([1., 0.]) tensor([0.7776, 0.2224], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 23 - 91: cat - cat || Loss: 0.53514564037323\n",
      "tensor([1., 0.]) tensor([0.7781, 0.2219], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 23 - 92: cat - cat || Loss: 0.5345970988273621\n",
      "tensor([1., 0.]) tensor([0.7787, 0.2213], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 23 - 93: cat - cat || Loss: 0.534049391746521\n",
      "tensor([1., 0.]) tensor([0.7792, 0.2208], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 23 - 94: cat - cat || Loss: 0.5335025787353516\n",
      "tensor([1., 0.]) tensor([0.7798, 0.2202], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 23 - 95: cat - cat || Loss: 0.5329567193984985\n",
      "tensor([1., 0.]) tensor([0.7803, 0.2197], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 23 - 96: cat - cat || Loss: 0.5324119329452515\n",
      "tensor([1., 0.]) tensor([0.7808, 0.2192], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 23 - 97: cat - cat || Loss: 0.531868040561676\n",
      "tensor([1., 0.]) tensor([0.7814, 0.2186], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 23 - 98: cat - cat || Loss: 0.5313249826431274\n",
      "tensor([1., 0.]) tensor([0.7819, 0.2181], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 23 - 99: cat - cat || Loss: 0.5307830572128296\n",
      "tensor([1., 0.]) tensor([0.7825, 0.2175], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 23 - 100: cat - cat || Loss: 0.5302419662475586\n",
      "tensor([1., 0.]) tensor([0.7830, 0.2170], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 23 - 101: cat - cat || Loss: 0.5297017693519592\n",
      "tensor([1., 0.]) tensor([0.7836, 0.2164], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 23 - 102: cat - cat || Loss: 0.5291626453399658\n",
      "tensor([1., 0.]) tensor([0.7841, 0.2159], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 23 - 103: cat - cat || Loss: 0.528624415397644\n",
      "tensor([1., 0.]) tensor([0.7846, 0.2154], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 23 - 104: cat - cat || Loss: 0.5280870795249939\n",
      "tensor([1., 0.]) tensor([0.7852, 0.2148], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 23 - 105: cat - cat || Loss: 0.5275508165359497\n",
      "tensor([1., 0.]) tensor([0.7857, 0.2143], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 23 - 106: cat - cat || Loss: 0.5270154476165771\n",
      "tensor([1., 0.]) tensor([0.7862, 0.2138], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 23 - 107: cat - cat || Loss: 0.526481032371521\n",
      "tensor([1., 0.]) tensor([0.7868, 0.2132], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 23 - 108: cat - cat || Loss: 0.5259475111961365\n",
      "tensor([1., 0.]) tensor([0.7873, 0.2127], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 23 - 109: cat - cat || Loss: 0.5254150032997131\n",
      "tensor([1., 0.]) tensor([0.7878, 0.2122], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 23 - 110: cat - cat || Loss: 0.5248834490776062\n",
      "tensor([1., 0.]) tensor([0.7884, 0.2116], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 23 - 111: cat - cat || Loss: 0.5243529081344604\n",
      "tensor([1., 0.]) tensor([0.7889, 0.2111], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 23 - 112: cat - cat || Loss: 0.5238232612609863\n",
      "tensor([1., 0.]) tensor([0.7894, 0.2106], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 23 - 113: cat - cat || Loss: 0.5232945680618286\n",
      "tensor([1., 0.]) tensor([0.7900, 0.2100], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 23 - 114: cat - cat || Loss: 0.5227668285369873\n",
      "tensor([1., 0.]) tensor([0.7905, 0.2095], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 23 - 115: cat - cat || Loss: 0.5222400426864624\n",
      "tensor([1., 0.]) tensor([0.7910, 0.2090], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 23 - 116: cat - cat || Loss: 0.5217142105102539\n",
      "tensor([1., 0.]) tensor([0.7915, 0.2085], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 23 - 117: cat - cat || Loss: 0.5211893320083618\n",
      "tensor([1., 0.]) tensor([0.7921, 0.2079], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 23 - 118: cat - cat || Loss: 0.5206654071807861\n",
      "tensor([1., 0.]) tensor([0.7926, 0.2074], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 23 - 119: cat - cat || Loss: 0.5201424956321716\n",
      "tensor([1., 0.]) tensor([0.7931, 0.2069], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 23 - 120: cat - cat || Loss: 0.5196204781532288\n",
      "tensor([1., 0.]) tensor([0.7936, 0.2064], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 23 - 121: cat - cat || Loss: 0.5190994739532471\n",
      "tensor([1., 0.]) tensor([0.7942, 0.2058], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 23 - 122: cat - cat || Loss: 0.5185795426368713\n",
      "tensor([1., 0.]) tensor([0.7947, 0.2053], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 23 - 123: cat - cat || Loss: 0.5180603861808777\n",
      "tensor([1., 0.]) tensor([0.7952, 0.2048], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 23 - 124: cat - cat || Loss: 0.51754230260849\n",
      "tensor([1., 0.]) tensor([0.7957, 0.2043], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 23 - 125: cat - cat || Loss: 0.5170251727104187\n",
      "tensor([1., 0.]) tensor([0.7962, 0.2038], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 23 - 126: cat - cat || Loss: 0.516508936882019\n",
      "tensor([1., 0.]) tensor([0.7968, 0.2032], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 23 - 127: cat - cat || Loss: 0.5159936547279358\n",
      "tensor([1., 0.]) tensor([0.7973, 0.2027], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 23 - 128: cat - cat || Loss: 0.5154794454574585\n",
      "tensor([1., 0.]) tensor([0.7978, 0.2022], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 23 - 129: cat - cat || Loss: 0.5149661302566528\n",
      "tensor([1., 0.]) tensor([0.7983, 0.2017], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 23 - 130: cat - cat || Loss: 0.5144538283348083\n",
      "tensor([1., 0.]) tensor([0.7988, 0.2012], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 23 - 131: cat - cat || Loss: 0.5139423608779907\n",
      "tensor([1., 0.]) tensor([0.7993, 0.2007], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 23 - 132: cat - cat || Loss: 0.513431966304779\n",
      "tensor([1., 0.]) tensor([0.7998, 0.2002], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 23 - 133: cat - cat || Loss: 0.5129225850105286\n",
      "tensor([1., 0.]) tensor([0.8003, 0.1997], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 23 - 134: cat - cat || Loss: 0.5124140977859497\n",
      "tensor([1., 0.]) tensor([0.8008, 0.1992], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 23 - 135: cat - cat || Loss: 0.511906623840332\n",
      "tensor([1., 0.]) tensor([0.8014, 0.1986], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 23 - 136: cat - cat || Loss: 0.5113999843597412\n",
      "tensor([1., 0.]) tensor([0.8019, 0.1981], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 23 - 137: cat - cat || Loss: 0.5108944177627563\n",
      "tensor([1., 0.]) tensor([0.8024, 0.1976], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 23 - 138: cat - cat || Loss: 0.5103898048400879\n",
      "tensor([1., 0.]) tensor([0.8029, 0.1971], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 23 - 139: cat - cat || Loss: 0.5098860859870911\n",
      "tensor([1., 0.]) tensor([0.8034, 0.1966], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 23 - 140: cat - cat || Loss: 0.5093833208084106\n",
      "tensor([1., 0.]) tensor([0.8039, 0.1961], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 23 - 141: cat - cat || Loss: 0.5088815689086914\n",
      "tensor([1., 0.]) tensor([0.8044, 0.1956], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 23 - 142: cat - cat || Loss: 0.5083807706832886\n",
      "tensor([1., 0.]) tensor([0.8049, 0.1951], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 23 - 143: cat - cat || Loss: 0.5078809261322021\n",
      "tensor([1., 0.]) tensor([0.8054, 0.1946], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 23 - 144: cat - cat || Loss: 0.5073821544647217\n",
      "tensor([1., 0.]) tensor([0.8059, 0.1941], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 23 - 145: cat - cat || Loss: 0.5068842172622681\n",
      "tensor([1., 0.]) tensor([0.8064, 0.1936], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 23 - 146: cat - cat || Loss: 0.5063872337341309\n",
      "tensor([1., 0.]) tensor([0.8069, 0.1931], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 23 - 147: cat - cat || Loss: 0.5058913230895996\n",
      "tensor([1., 0.]) tensor([0.8074, 0.1926], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 23 - 148: cat - cat || Loss: 0.50539630651474\n",
      "tensor([1., 0.]) tensor([0.8079, 0.1921], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 23 - 149: cat - cat || Loss: 0.5049023032188416\n",
      "tensor([1., 0.]) tensor([0.8084, 0.1916], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 23 - 150: cat - cat || Loss: 0.5044091939926147\n",
      "tensor([1., 0.]) tensor([0.8089, 0.1911], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 23 - 151: cat - cat || Loss: 0.5039170980453491\n",
      "tensor([1., 0.]) tensor([0.8093, 0.1907], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 23 - 152: cat - cat || Loss: 0.5034259557723999\n",
      "tensor([1., 0.]) tensor([0.8098, 0.1902], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 23 - 153: cat - cat || Loss: 0.5029357075691223\n",
      "tensor([1., 0.]) tensor([0.8103, 0.1897], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 23 - 154: cat - cat || Loss: 0.5024465322494507\n",
      "tensor([1., 0.]) tensor([0.8108, 0.1892], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 23 - 155: cat - cat || Loss: 0.5019582509994507\n",
      "tensor([1., 0.]) tensor([0.8113, 0.1887], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 23 - 156: cat - cat || Loss: 0.5014709234237671\n",
      "tensor([1., 0.]) tensor([0.8118, 0.1882], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 23 - 157: cat - cat || Loss: 0.5009847283363342\n",
      "tensor([1., 0.]) tensor([0.8123, 0.1877], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 23 - 158: cat - cat || Loss: 0.5004993677139282\n",
      "tensor([1., 0.]) tensor([0.8128, 0.1872], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 23 - 159: cat - cat || Loss: 0.5000149607658386\n",
      "tensor([1., 0.]) tensor([0.8132, 0.1868], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 23 - 160: cat - cat || Loss: 0.49953150749206543\n",
      "tensor([1., 0.]) tensor([0.8137, 0.1863], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 23 - 161: cat - cat || Loss: 0.4990490674972534\n",
      "tensor([1., 0.]) tensor([0.8142, 0.1858], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 23 - 162: cat - cat || Loss: 0.4985675811767578\n",
      "tensor([1., 0.]) tensor([0.8147, 0.1853], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 23 - 163: cat - cat || Loss: 0.49808698892593384\n",
      "tensor([1., 0.]) tensor([0.8152, 0.1848], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 23 - 164: cat - cat || Loss: 0.49760740995407104\n",
      "tensor([1., 0.]) tensor([0.8157, 0.1843], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 23 - 165: cat - cat || Loss: 0.49712878465652466\n",
      "tensor([1., 0.]) tensor([0.8161, 0.1839], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 23 - 166: cat - cat || Loss: 0.4966511130332947\n",
      "tensor([1., 0.]) tensor([0.8166, 0.1834], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 23 - 167: cat - cat || Loss: 0.4961744248867035\n",
      "tensor([1., 0.]) tensor([0.8171, 0.1829], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 23 - 168: cat - cat || Loss: 0.4956986904144287\n",
      "tensor([1., 0.]) tensor([0.8176, 0.1824], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 23 - 169: cat - cat || Loss: 0.49522387981414795\n",
      "tensor([1., 0.]) tensor([0.8180, 0.1820], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 23 - 170: cat - cat || Loss: 0.49475008249282837\n",
      "tensor([1., 0.]) tensor([0.8185, 0.1815], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 23 - 171: cat - cat || Loss: 0.4942772388458252\n",
      "tensor([1., 0.]) tensor([0.8190, 0.1810], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 23 - 172: cat - cat || Loss: 0.49380531907081604\n",
      "tensor([1., 0.]) tensor([0.8195, 0.1805], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 23 - 173: cat - cat || Loss: 0.4933343529701233\n",
      "tensor([1., 0.]) tensor([0.8199, 0.1801], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 23 - 174: cat - cat || Loss: 0.49286434054374695\n",
      "tensor([1., 0.]) tensor([0.8204, 0.1796], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 23 - 175: cat - cat || Loss: 0.4923953413963318\n",
      "tensor([1., 0.]) tensor([0.8209, 0.1791], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 23 - 176: cat - cat || Loss: 0.4919273257255554\n",
      "tensor([1., 0.]) tensor([0.8213, 0.1787], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 23 - 177: cat - cat || Loss: 0.49146032333374023\n",
      "tensor([1., 0.]) tensor([0.8218, 0.1782], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 23 - 178: cat - cat || Loss: 0.4909942150115967\n",
      "tensor([1., 0.]) tensor([0.8223, 0.1777], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 23 - 179: cat - cat || Loss: 0.4905291199684143\n",
      "tensor([1., 0.]) tensor([0.8227, 0.1773], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 23 - 180: cat - cat || Loss: 0.49006497859954834\n",
      "tensor([1., 0.]) tensor([0.8232, 0.1768], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 23 - 181: cat - cat || Loss: 0.4896017611026764\n",
      "tensor([1., 0.]) tensor([0.8237, 0.1763], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 23 - 182: cat - cat || Loss: 0.4891395568847656\n",
      "tensor([1., 0.]) tensor([0.8241, 0.1759], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 23 - 183: cat - cat || Loss: 0.4886784851551056\n",
      "tensor([1., 0.]) tensor([0.8246, 0.1754], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 23 - 184: cat - cat || Loss: 0.48821812868118286\n",
      "tensor([1., 0.]) tensor([0.8250, 0.1750], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 23 - 185: cat - cat || Loss: 0.4877588748931885\n",
      "tensor([1., 0.]) tensor([0.8255, 0.1745], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 23 - 186: cat - cat || Loss: 0.4873003661632538\n",
      "tensor([1., 0.]) tensor([0.8260, 0.1740], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 23 - 187: cat - cat || Loss: 0.4868429899215698\n",
      "tensor([1., 0.]) tensor([0.8264, 0.1736], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 23 - 188: cat - cat || Loss: 0.48638641834259033\n",
      "tensor([1., 0.]) tensor([0.8269, 0.1731], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 23 - 189: cat - cat || Loss: 0.485930860042572\n",
      "tensor([1., 0.]) tensor([0.8273, 0.1727], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 23 - 190: dog - cat || Loss: 1.1410470008850098\n",
      "tensor([0., 1.]) tensor([0.8278, 0.1722], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 23 - 191: dog - cat || Loss: 1.1414108276367188\n",
      "tensor([0., 1.]) tensor([0.8281, 0.1719], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 23 - 192: dog - cat || Loss: 1.141693115234375\n",
      "tensor([0., 1.]) tensor([0.8284, 0.1716], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 23 - 193: dog - cat || Loss: 1.141902208328247\n",
      "tensor([0., 1.]) tensor([0.8286, 0.1714], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 23 - 194: dog - cat || Loss: 1.142045259475708\n",
      "tensor([0., 1.]) tensor([0.8288, 0.1712], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 23 - 195: dog - cat || Loss: 1.1421295404434204\n",
      "tensor([0., 1.]) tensor([0.8289, 0.1711], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 23 - 196: dog - cat || Loss: 1.142160415649414\n",
      "tensor([0., 1.]) tensor([0.8289, 0.1711], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 23 - 197: dog - cat || Loss: 1.1421432495117188\n",
      "tensor([0., 1.]) tensor([0.8289, 0.1711], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 23 - 198: dog - cat || Loss: 1.1420835256576538\n",
      "tensor([0., 1.]) tensor([0.8288, 0.1712], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 23 - 199: dog - cat || Loss: 1.1419847011566162\n",
      "tensor([0., 1.]) tensor([0.8287, 0.1713], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 23 - 200: dog - cat || Loss: 1.1418510675430298\n",
      "tensor([0., 1.]) tensor([0.8286, 0.1714], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 23 - 201: dog - cat || Loss: 1.1416858434677124\n",
      "tensor([0., 1.]) tensor([0.8284, 0.1716], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 23 - 202: dog - cat || Loss: 1.141492247581482\n",
      "tensor([0., 1.]) tensor([0.8282, 0.1718], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 23 - 203: dog - cat || Loss: 1.141273021697998\n",
      "tensor([0., 1.]) tensor([0.8280, 0.1720], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 23 - 204: dog - cat || Loss: 1.1410307884216309\n",
      "tensor([0., 1.]) tensor([0.8278, 0.1722], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 23 - 205: dog - cat || Loss: 1.1407675743103027\n",
      "tensor([0., 1.]) tensor([0.8275, 0.1725], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 23 - 206: dog - cat || Loss: 1.1404855251312256\n",
      "tensor([0., 1.]) tensor([0.8272, 0.1728], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 23 - 207: dog - cat || Loss: 1.1401864290237427\n",
      "tensor([0., 1.]) tensor([0.8269, 0.1731], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 23 - 208: dog - cat || Loss: 1.1398719549179077\n",
      "tensor([0., 1.]) tensor([0.8266, 0.1734], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 23 - 209: dog - cat || Loss: 1.1395434141159058\n",
      "tensor([0., 1.]) tensor([0.8263, 0.1737], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 23 - 210: dog - cat || Loss: 1.1392022371292114\n",
      "tensor([0., 1.]) tensor([0.8259, 0.1741], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 23 - 211: dog - cat || Loss: 1.1388497352600098\n",
      "tensor([0., 1.]) tensor([0.8256, 0.1744], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 23 - 212: dog - cat || Loss: 1.138486623764038\n",
      "tensor([0., 1.]) tensor([0.8252, 0.1748], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 23 - 213: dog - cat || Loss: 1.1381139755249023\n",
      "tensor([0., 1.]) tensor([0.8249, 0.1751], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 23 - 214: dog - cat || Loss: 1.1377328634262085\n",
      "tensor([0., 1.]) tensor([0.8245, 0.1755], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 23 - 215: dog - cat || Loss: 1.1373438835144043\n",
      "tensor([0., 1.]) tensor([0.8241, 0.1759], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 23 - 216: dog - cat || Loss: 1.1369478702545166\n",
      "tensor([0., 1.]) tensor([0.8237, 0.1763], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 23 - 217: dog - cat || Loss: 1.1365450620651245\n",
      "tensor([0., 1.]) tensor([0.8233, 0.1767], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 23 - 218: dog - cat || Loss: 1.1361366510391235\n",
      "tensor([0., 1.]) tensor([0.8229, 0.1771], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 23 - 219: dog - cat || Loss: 1.1357223987579346\n",
      "tensor([0., 1.]) tensor([0.8225, 0.1775], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 23 - 220: dog - cat || Loss: 1.135303258895874\n",
      "tensor([0., 1.]) tensor([0.8220, 0.1780], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 23 - 221: dog - cat || Loss: 1.1348797082901\n",
      "tensor([0., 1.]) tensor([0.8216, 0.1784], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 23 - 222: dog - cat || Loss: 1.1344518661499023\n",
      "tensor([0., 1.]) tensor([0.8212, 0.1788], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 23 - 223: dog - cat || Loss: 1.1340199708938599\n",
      "tensor([0., 1.]) tensor([0.8208, 0.1792], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 23 - 224: dog - cat || Loss: 1.1335846185684204\n",
      "tensor([0., 1.]) tensor([0.8203, 0.1797], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 23 - 225: dog - cat || Loss: 1.133146047592163\n",
      "tensor([0., 1.]) tensor([0.8199, 0.1801], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 23 - 226: dog - cat || Loss: 1.132704257965088\n",
      "tensor([0., 1.]) tensor([0.8194, 0.1806], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 23 - 227: dog - cat || Loss: 1.1322596073150635\n",
      "tensor([0., 1.]) tensor([0.8190, 0.1810], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 23 - 228: dog - cat || Loss: 1.1318124532699585\n",
      "tensor([0., 1.]) tensor([0.8186, 0.1814], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 23 - 229: dog - cat || Loss: 1.131362795829773\n",
      "tensor([0., 1.]) tensor([0.8181, 0.1819], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 23 - 230: dog - cat || Loss: 1.1309105157852173\n",
      "tensor([0., 1.]) tensor([0.8176, 0.1824], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 23 - 231: dog - cat || Loss: 1.1304562091827393\n",
      "tensor([0., 1.]) tensor([0.8172, 0.1828], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 23 - 232: dog - cat || Loss: 1.1299998760223389\n",
      "tensor([0., 1.]) tensor([0.8167, 0.1833], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 23 - 233: dog - cat || Loss: 1.1295415163040161\n",
      "tensor([0., 1.]) tensor([0.8163, 0.1837], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 23 - 234: dog - cat || Loss: 1.12908136844635\n",
      "tensor([0., 1.]) tensor([0.8158, 0.1842], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 23 - 235: dog - cat || Loss: 1.1286194324493408\n",
      "tensor([0., 1.]) tensor([0.8154, 0.1846], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 23 - 236: dog - cat || Loss: 1.1281559467315674\n",
      "tensor([0., 1.]) tensor([0.8149, 0.1851], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 23 - 237: dog - cat || Loss: 1.1276906728744507\n",
      "tensor([0., 1.]) tensor([0.8144, 0.1856], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 23 - 238: dog - cat || Loss: 1.1272238492965698\n",
      "tensor([0., 1.]) tensor([0.8140, 0.1860], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 23 - 239: dog - cat || Loss: 1.126755714416504\n",
      "tensor([0., 1.]) tensor([0.8135, 0.1865], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 23 - 240: dog - cat || Loss: 1.1262860298156738\n",
      "tensor([0., 1.]) tensor([0.8130, 0.1870], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 23 - 241: dog - cat || Loss: 1.1258150339126587\n",
      "tensor([0., 1.]) tensor([0.8126, 0.1874], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 23 - 242: dog - cat || Loss: 1.1253427267074585\n",
      "tensor([0., 1.]) tensor([0.8121, 0.1879], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 23 - 243: dog - cat || Loss: 1.1248692274093628\n",
      "tensor([0., 1.]) tensor([0.8116, 0.1884], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 23 - 244: dog - cat || Loss: 1.1243945360183716\n",
      "tensor([0., 1.]) tensor([0.8111, 0.1889], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 23 - 245: dog - cat || Loss: 1.1239185333251953\n",
      "tensor([0., 1.]) tensor([0.8107, 0.1893], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 23 - 246: dog - cat || Loss: 1.123441219329834\n",
      "tensor([0., 1.]) tensor([0.8102, 0.1898], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 23 - 247: dog - cat || Loss: 1.1229629516601562\n",
      "tensor([0., 1.]) tensor([0.8097, 0.1903], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 23 - 248: dog - cat || Loss: 1.122483491897583\n",
      "tensor([0., 1.]) tensor([0.8092, 0.1908], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 23 - 249: dog - cat || Loss: 1.1220027208328247\n",
      "tensor([0., 1.]) tensor([0.8087, 0.1913], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 23 - 250: dog - cat || Loss: 1.121521234512329\n",
      "tensor([0., 1.]) tensor([0.8083, 0.1917], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 23 - 251: dog - cat || Loss: 1.1210384368896484\n",
      "tensor([0., 1.]) tensor([0.8078, 0.1922], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 23 - 252: dog - cat || Loss: 1.1205546855926514\n",
      "tensor([0., 1.]) tensor([0.8073, 0.1927], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 23 - 253: dog - cat || Loss: 1.1200697422027588\n",
      "tensor([0., 1.]) tensor([0.8068, 0.1932], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 23 - 254: dog - cat || Loss: 1.1195838451385498\n",
      "tensor([0., 1.]) tensor([0.8063, 0.1937], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 23 - 255: dog - cat || Loss: 1.1190969944000244\n",
      "tensor([0., 1.]) tensor([0.8058, 0.1942], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 23 - 256: dog - cat || Loss: 1.118609070777893\n",
      "tensor([0., 1.]) tensor([0.8053, 0.1947], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 23 - 257: dog - cat || Loss: 1.1181200742721558\n",
      "tensor([0., 1.]) tensor([0.8049, 0.1951], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 23 - 258: dog - cat || Loss: 1.1176302433013916\n",
      "tensor([0., 1.]) tensor([0.8044, 0.1956], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 23 - 259: dog - cat || Loss: 1.1171393394470215\n",
      "tensor([0., 1.]) tensor([0.8039, 0.1961], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 23 - 260: dog - cat || Loss: 1.1166473627090454\n",
      "tensor([0., 1.]) tensor([0.8034, 0.1966], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 23 - 261: dog - cat || Loss: 1.116154670715332\n",
      "tensor([0., 1.]) tensor([0.8029, 0.1971], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 23 - 262: dog - cat || Loss: 1.1156607866287231\n",
      "tensor([0., 1.]) tensor([0.8024, 0.1976], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 23 - 263: dog - cat || Loss: 1.1151659488677979\n",
      "tensor([0., 1.]) tensor([0.8019, 0.1981], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 23 - 264: dog - cat || Loss: 1.1146701574325562\n",
      "tensor([0., 1.]) tensor([0.8014, 0.1986], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 23 - 265: dog - cat || Loss: 1.1141735315322876\n",
      "tensor([0., 1.]) tensor([0.8009, 0.1991], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 23 - 266: dog - cat || Loss: 1.113675832748413\n",
      "tensor([0., 1.]) tensor([0.8004, 0.1996], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 23 - 267: dog - cat || Loss: 1.1131772994995117\n",
      "tensor([0., 1.]) tensor([0.7999, 0.2001], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 23 - 268: dog - cat || Loss: 1.1126776933670044\n",
      "tensor([0., 1.]) tensor([0.7994, 0.2006], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 23 - 269: dog - cat || Loss: 1.1121772527694702\n",
      "tensor([0., 1.]) tensor([0.7989, 0.2011], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 23 - 270: dog - cat || Loss: 1.11167573928833\n",
      "tensor([0., 1.]) tensor([0.7984, 0.2016], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 23 - 271: dog - cat || Loss: 1.111173391342163\n",
      "tensor([0., 1.]) tensor([0.7979, 0.2021], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 23 - 272: dog - cat || Loss: 1.1106702089309692\n",
      "tensor([0., 1.]) tensor([0.7974, 0.2026], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 23 - 273: dog - cat || Loss: 1.1101659536361694\n",
      "tensor([0., 1.]) tensor([0.7969, 0.2031], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 23 - 274: dog - cat || Loss: 1.1096607446670532\n",
      "tensor([0., 1.]) tensor([0.7964, 0.2036], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 23 - 275: dog - cat || Loss: 1.1091545820236206\n",
      "tensor([0., 1.]) tensor([0.7959, 0.2041], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 23 - 276: dog - cat || Loss: 1.1086477041244507\n",
      "tensor([0., 1.]) tensor([0.7954, 0.2046], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 23 - 277: dog - cat || Loss: 1.1081397533416748\n",
      "tensor([0., 1.]) tensor([0.7949, 0.2051], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 23 - 278: dog - cat || Loss: 1.1076308488845825\n",
      "tensor([0., 1.]) tensor([0.7944, 0.2056], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 23 - 279: dog - cat || Loss: 1.1071209907531738\n",
      "tensor([0., 1.]) tensor([0.7939, 0.2061], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 23 - 280: dog - cat || Loss: 1.1066104173660278\n",
      "tensor([0., 1.]) tensor([0.7933, 0.2067], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 23 - 281: dog - cat || Loss: 1.1060986518859863\n",
      "tensor([0., 1.]) tensor([0.7928, 0.2072], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 23 - 282: dog - cat || Loss: 1.1055861711502075\n",
      "tensor([0., 1.]) tensor([0.7923, 0.2077], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 23 - 283: dog - cat || Loss: 1.1050726175308228\n",
      "tensor([0., 1.]) tensor([0.7918, 0.2082], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 23 - 284: dog - cat || Loss: 1.1045581102371216\n",
      "tensor([0., 1.]) tensor([0.7913, 0.2087], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 23 - 285: dog - cat || Loss: 1.1040427684783936\n",
      "tensor([0., 1.]) tensor([0.7908, 0.2092], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 23 - 286: dog - cat || Loss: 1.1035265922546387\n",
      "tensor([0., 1.]) tensor([0.7903, 0.2097], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 23 - 287: dog - cat || Loss: 1.1030093431472778\n",
      "tensor([0., 1.]) tensor([0.7897, 0.2103], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 23 - 288: dog - cat || Loss: 1.1024913787841797\n",
      "tensor([0., 1.]) tensor([0.7892, 0.2108], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 23 - 289: dog - cat || Loss: 1.1019721031188965\n",
      "tensor([0., 1.]) tensor([0.7887, 0.2113], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 23 - 290: dog - cat || Loss: 1.1014522314071655\n",
      "tensor([0., 1.]) tensor([0.7882, 0.2118], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 23 - 291: dog - cat || Loss: 1.1009314060211182\n",
      "tensor([0., 1.]) tensor([0.7877, 0.2123], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 23 - 292: dog - cat || Loss: 1.1004095077514648\n",
      "tensor([0., 1.]) tensor([0.7871, 0.2129], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 23 - 293: dog - cat || Loss: 1.0998868942260742\n",
      "tensor([0., 1.]) tensor([0.7866, 0.2134], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 23 - 294: dog - cat || Loss: 1.0993633270263672\n",
      "tensor([0., 1.]) tensor([0.7861, 0.2139], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 23 - 295: dog - cat || Loss: 1.0988386869430542\n",
      "tensor([0., 1.]) tensor([0.7856, 0.2144], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 23 - 296: dog - cat || Loss: 1.0983130931854248\n",
      "tensor([0., 1.]) tensor([0.7851, 0.2149], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 23 - 297: dog - cat || Loss: 1.0977869033813477\n",
      "tensor([0., 1.]) tensor([0.7845, 0.2155], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 23 - 298: dog - cat || Loss: 1.097259521484375\n",
      "tensor([0., 1.]) tensor([0.7840, 0.2160], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 23 - 299: dog - cat || Loss: 1.0967313051223755\n",
      "tensor([0., 1.]) tensor([0.7835, 0.2165], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 23 - 300: dog - cat || Loss: 1.0962021350860596\n",
      "tensor([0., 1.]) tensor([0.7829, 0.2171], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 23 - 301: dog - cat || Loss: 1.0956720113754272\n",
      "tensor([0., 1.]) tensor([0.7824, 0.2176], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 23 - 302: dog - cat || Loss: 1.0951411724090576\n",
      "tensor([0., 1.]) tensor([0.7819, 0.2181], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 23 - 303: dog - cat || Loss: 1.0946091413497925\n",
      "tensor([0., 1.]) tensor([0.7813, 0.2187], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 23 - 304: dog - cat || Loss: 1.0940765142440796\n",
      "tensor([0., 1.]) tensor([0.7808, 0.2192], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 23 - 305: dog - cat || Loss: 1.0935426950454712\n",
      "tensor([0., 1.]) tensor([0.7803, 0.2197], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 23 - 306: dog - cat || Loss: 1.093008041381836\n",
      "tensor([0., 1.]) tensor([0.7797, 0.2203], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 23 - 307: dog - cat || Loss: 1.0924726724624634\n",
      "tensor([0., 1.]) tensor([0.7792, 0.2208], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 23 - 308: dog - cat || Loss: 1.0919361114501953\n",
      "tensor([0., 1.]) tensor([0.7787, 0.2213], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 23 - 309: dog - cat || Loss: 1.0913989543914795\n",
      "tensor([0., 1.]) tensor([0.7781, 0.2219], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 23 - 310: dog - cat || Loss: 1.0908607244491577\n",
      "tensor([0., 1.]) tensor([0.7776, 0.2224], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 23 - 311: dog - cat || Loss: 1.0903215408325195\n",
      "tensor([0., 1.]) tensor([0.7771, 0.2229], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 23 - 312: dog - cat || Loss: 1.0897815227508545\n",
      "tensor([0., 1.]) tensor([0.7765, 0.2235], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 23 - 313: dog - cat || Loss: 1.0892404317855835\n",
      "tensor([0., 1.]) tensor([0.7760, 0.2240], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 23 - 314: dog - cat || Loss: 1.0886986255645752\n",
      "tensor([0., 1.]) tensor([0.7754, 0.2246], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 23 - 315: dog - cat || Loss: 1.0881558656692505\n",
      "tensor([0., 1.]) tensor([0.7749, 0.2251], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 23 - 316: dog - cat || Loss: 1.0876121520996094\n",
      "tensor([0., 1.]) tensor([0.7744, 0.2256], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 23 - 317: dog - cat || Loss: 1.0870674848556519\n",
      "tensor([0., 1.]) tensor([0.7738, 0.2262], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 23 - 318: dog - cat || Loss: 1.086522102355957\n",
      "tensor([0., 1.]) tensor([0.7733, 0.2267], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 23 - 319: dog - cat || Loss: 1.0859756469726562\n",
      "tensor([0., 1.]) tensor([0.7727, 0.2273], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 23 - 320: dog - cat || Loss: 1.0854284763336182\n",
      "tensor([0., 1.]) tensor([0.7722, 0.2278], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 23 - 321: dog - cat || Loss: 1.0848801136016846\n",
      "tensor([0., 1.]) tensor([0.7716, 0.2284], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 23 - 322: dog - cat || Loss: 1.0843312740325928\n",
      "tensor([0., 1.]) tensor([0.7711, 0.2289], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 23 - 323: dog - cat || Loss: 1.083781123161316\n",
      "tensor([0., 1.]) tensor([0.7705, 0.2295], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 23 - 324: dog - cat || Loss: 1.0832302570343018\n",
      "tensor([0., 1.]) tensor([0.7700, 0.2300], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 23 - 325: dog - cat || Loss: 1.0826784372329712\n",
      "tensor([0., 1.]) tensor([0.7694, 0.2306], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 23 - 326: dog - cat || Loss: 1.0821259021759033\n",
      "tensor([0., 1.]) tensor([0.7689, 0.2311], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 23 - 327: dog - cat || Loss: 1.08157217502594\n",
      "tensor([0., 1.]) tensor([0.7683, 0.2317], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 23 - 328: dog - cat || Loss: 1.0810177326202393\n",
      "tensor([0., 1.]) tensor([0.7678, 0.2322], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 23 - 329: dog - cat || Loss: 1.0804623365402222\n",
      "tensor([0., 1.]) tensor([0.7672, 0.2328], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 23 - 330: dog - cat || Loss: 1.0799059867858887\n",
      "tensor([0., 1.]) tensor([0.7666, 0.2334], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 23 - 331: dog - cat || Loss: 1.0793489217758179\n",
      "tensor([0., 1.]) tensor([0.7661, 0.2339], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 23 - 332: dog - cat || Loss: 1.0787907838821411\n",
      "tensor([0., 1.]) tensor([0.7655, 0.2345], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 23 - 333: dog - cat || Loss: 1.0782318115234375\n",
      "tensor([0., 1.]) tensor([0.7650, 0.2350], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 23 - 334: dog - cat || Loss: 1.0776718854904175\n",
      "tensor([0., 1.]) tensor([0.7644, 0.2356], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 23 - 335: dog - cat || Loss: 1.0771111249923706\n",
      "tensor([0., 1.]) tensor([0.7638, 0.2362], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 23 - 336: dog - cat || Loss: 1.0765495300292969\n",
      "tensor([0., 1.]) tensor([0.7633, 0.2367], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 23 - 337: dog - cat || Loss: 1.0759869813919067\n",
      "tensor([0., 1.]) tensor([0.7627, 0.2373], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 23 - 338: dog - cat || Loss: 1.0754234790802002\n",
      "tensor([0., 1.]) tensor([0.7622, 0.2378], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 23 - 339: dog - cat || Loss: 1.0748590230941772\n",
      "tensor([0., 1.]) tensor([0.7616, 0.2384], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 23 - 340: dog - cat || Loss: 1.074293851852417\n",
      "tensor([0., 1.]) tensor([0.7610, 0.2390], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 23 - 341: dog - cat || Loss: 1.0737276077270508\n",
      "tensor([0., 1.]) tensor([0.7605, 0.2395], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 23 - 342: dog - cat || Loss: 1.0731606483459473\n",
      "tensor([0., 1.]) tensor([0.7599, 0.2401], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 23 - 343: dog - cat || Loss: 1.0725927352905273\n",
      "tensor([0., 1.]) tensor([0.7593, 0.2407], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 23 - 344: dog - cat || Loss: 1.0720239877700806\n",
      "tensor([0., 1.]) tensor([0.7588, 0.2412], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 23 - 345: dog - cat || Loss: 1.0714540481567383\n",
      "tensor([0., 1.]) tensor([0.7582, 0.2418], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 23 - 346: dog - cat || Loss: 1.0708836317062378\n",
      "tensor([0., 1.]) tensor([0.7576, 0.2424], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 23 - 347: dog - cat || Loss: 1.0703121423721313\n",
      "tensor([0., 1.]) tensor([0.7571, 0.2429], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 23 - 348: dog - cat || Loss: 1.0697396993637085\n",
      "tensor([0., 1.]) tensor([0.7565, 0.2435], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 23 - 349: dog - cat || Loss: 1.0691665410995483\n",
      "tensor([0., 1.]) tensor([0.7559, 0.2441], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 23 - 350: dog - cat || Loss: 1.0685924291610718\n",
      "tensor([0., 1.]) tensor([0.7553, 0.2447], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 23 - 351: dog - cat || Loss: 1.0680173635482788\n",
      "tensor([0., 1.]) tensor([0.7548, 0.2452], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 23 - 352: dog - cat || Loss: 1.0674415826797485\n",
      "tensor([0., 1.]) tensor([0.7542, 0.2458], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 23 - 353: dog - cat || Loss: 1.0668647289276123\n",
      "tensor([0., 1.]) tensor([0.7536, 0.2464], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 23 - 354: dog - cat || Loss: 1.0662870407104492\n",
      "tensor([0., 1.]) tensor([0.7530, 0.2470], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 23 - 355: dog - cat || Loss: 1.0657086372375488\n",
      "tensor([0., 1.]) tensor([0.7524, 0.2476], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 23 - 356: dog - cat || Loss: 1.065129041671753\n",
      "tensor([0., 1.]) tensor([0.7519, 0.2481], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 23 - 357: dog - cat || Loss: 1.0645487308502197\n",
      "tensor([0., 1.]) tensor([0.7513, 0.2487], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 23 - 358: dog - cat || Loss: 1.0639677047729492\n",
      "tensor([0., 1.]) tensor([0.7507, 0.2493], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 23 - 359: dog - cat || Loss: 1.0633856058120728\n",
      "tensor([0., 1.]) tensor([0.7501, 0.2499], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 23 - 360: dog - cat || Loss: 1.0628025531768799\n",
      "tensor([0., 1.]) tensor([0.7495, 0.2505], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 23 - 361: dog - cat || Loss: 1.0622187852859497\n",
      "tensor([0., 1.]) tensor([0.7490, 0.2510], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 23 - 362: dog - cat || Loss: 1.0616341829299927\n",
      "tensor([0., 1.]) tensor([0.7484, 0.2516], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 23 - 363: dog - cat || Loss: 1.0610486268997192\n",
      "tensor([0., 1.]) tensor([0.7478, 0.2522], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 23 - 364: dog - cat || Loss: 1.060462236404419\n",
      "tensor([0., 1.]) tensor([0.7472, 0.2528], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 23 - 365: dog - cat || Loss: 1.0598751306533813\n",
      "tensor([0., 1.]) tensor([0.7466, 0.2534], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 23 - 366: dog - cat || Loss: 1.0592868328094482\n",
      "tensor([0., 1.]) tensor([0.7460, 0.2540], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 23 - 367: dog - cat || Loss: 1.0586979389190674\n",
      "tensor([0., 1.]) tensor([0.7454, 0.2546], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 23 - 368: dog - cat || Loss: 1.0581080913543701\n",
      "tensor([0., 1.]) tensor([0.7448, 0.2552], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 23 - 369: dog - cat || Loss: 1.0575172901153564\n",
      "tensor([0., 1.]) tensor([0.7443, 0.2557], grad_fn=<SoftmaxBackward0>)\n",
      "=====epoch:24=====\n",
      "Epoch 24 - 0: cat - cat || Loss: 0.569597601890564\n",
      "tensor([1., 0.]) tensor([0.7437, 0.2563], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 24 - 1: cat - cat || Loss: 0.5700706839561462\n",
      "tensor([1., 0.]) tensor([0.7432, 0.2568], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 24 - 2: cat - cat || Loss: 0.570436954498291\n",
      "tensor([1., 0.]) tensor([0.7428, 0.2572], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 24 - 3: cat - cat || Loss: 0.5707070827484131\n",
      "tensor([1., 0.]) tensor([0.7426, 0.2574], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 24 - 4: cat - cat || Loss: 0.5708903670310974\n",
      "tensor([1., 0.]) tensor([0.7424, 0.2576], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 24 - 5: cat - cat || Loss: 0.5709955096244812\n",
      "tensor([1., 0.]) tensor([0.7423, 0.2577], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 24 - 6: cat - cat || Loss: 0.5710303783416748\n",
      "tensor([1., 0.]) tensor([0.7422, 0.2578], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 24 - 7: cat - cat || Loss: 0.5710018873214722\n",
      "tensor([1., 0.]) tensor([0.7423, 0.2577], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 24 - 8: cat - cat || Loss: 0.5709164142608643\n",
      "tensor([1., 0.]) tensor([0.7423, 0.2577], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 24 - 9: cat - cat || Loss: 0.5707798004150391\n",
      "tensor([1., 0.]) tensor([0.7425, 0.2575], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 24 - 10: cat - cat || Loss: 0.5705969333648682\n",
      "tensor([1., 0.]) tensor([0.7427, 0.2573], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 24 - 11: cat - cat || Loss: 0.5703728199005127\n",
      "tensor([1., 0.]) tensor([0.7429, 0.2571], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 24 - 12: cat - cat || Loss: 0.5701113939285278\n",
      "tensor([1., 0.]) tensor([0.7432, 0.2568], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 24 - 13: cat - cat || Loss: 0.5698165893554688\n",
      "tensor([1., 0.]) tensor([0.7434, 0.2566], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 24 - 14: cat - cat || Loss: 0.5694916844367981\n",
      "tensor([1., 0.]) tensor([0.7438, 0.2562], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 24 - 15: cat - cat || Loss: 0.569139838218689\n",
      "tensor([1., 0.]) tensor([0.7441, 0.2559], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 24 - 16: cat - cat || Loss: 0.5687638521194458\n",
      "tensor([1., 0.]) tensor([0.7445, 0.2555], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 24 - 17: cat - cat || Loss: 0.5683660507202148\n",
      "tensor([1., 0.]) tensor([0.7449, 0.2551], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 24 - 18: cat - cat || Loss: 0.5679488778114319\n",
      "tensor([1., 0.]) tensor([0.7453, 0.2547], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 24 - 19: cat - cat || Loss: 0.5675143003463745\n",
      "tensor([1., 0.]) tensor([0.7457, 0.2543], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 24 - 20: cat - cat || Loss: 0.5670640468597412\n",
      "tensor([1., 0.]) tensor([0.7462, 0.2538], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 24 - 21: cat - cat || Loss: 0.5665998458862305\n",
      "tensor([1., 0.]) tensor([0.7467, 0.2533], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 24 - 22: cat - cat || Loss: 0.5661232471466064\n",
      "tensor([1., 0.]) tensor([0.7471, 0.2529], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 24 - 23: cat - cat || Loss: 0.5656355023384094\n",
      "tensor([1., 0.]) tensor([0.7476, 0.2524], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 24 - 24: cat - cat || Loss: 0.5651377439498901\n",
      "tensor([1., 0.]) tensor([0.7481, 0.2519], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 24 - 25: cat - cat || Loss: 0.5646311044692993\n",
      "tensor([1., 0.]) tensor([0.7486, 0.2514], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 24 - 26: cat - cat || Loss: 0.5641167163848877\n",
      "tensor([1., 0.]) tensor([0.7491, 0.2509], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 24 - 27: cat - cat || Loss: 0.563595175743103\n",
      "tensor([1., 0.]) tensor([0.7497, 0.2503], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 24 - 28: cat - cat || Loss: 0.5630676746368408\n",
      "tensor([1., 0.]) tensor([0.7502, 0.2498], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 24 - 29: cat - cat || Loss: 0.5625343322753906\n",
      "tensor([1., 0.]) tensor([0.7507, 0.2493], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 24 - 30: cat - cat || Loss: 0.561996340751648\n",
      "tensor([1., 0.]) tensor([0.7513, 0.2487], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 24 - 31: cat - cat || Loss: 0.5614540576934814\n",
      "tensor([1., 0.]) tensor([0.7518, 0.2482], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 24 - 32: cat - cat || Loss: 0.5609079599380493\n",
      "tensor([1., 0.]) tensor([0.7524, 0.2476], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 24 - 33: cat - cat || Loss: 0.5603586435317993\n",
      "tensor([1., 0.]) tensor([0.7529, 0.2471], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 24 - 34: cat - cat || Loss: 0.5598065853118896\n",
      "tensor([1., 0.]) tensor([0.7535, 0.2465], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 24 - 35: cat - cat || Loss: 0.5592517852783203\n",
      "tensor([1., 0.]) tensor([0.7540, 0.2460], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 24 - 36: cat - cat || Loss: 0.5586949586868286\n",
      "tensor([1., 0.]) tensor([0.7546, 0.2454], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 24 - 37: cat - cat || Loss: 0.5581363439559937\n",
      "tensor([1., 0.]) tensor([0.7551, 0.2449], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 24 - 38: cat - cat || Loss: 0.5575760006904602\n",
      "tensor([1., 0.]) tensor([0.7557, 0.2443], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 24 - 39: cat - cat || Loss: 0.5570142269134521\n",
      "tensor([1., 0.]) tensor([0.7562, 0.2438], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 24 - 40: cat - cat || Loss: 0.5564517378807068\n",
      "tensor([1., 0.]) tensor([0.7568, 0.2432], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 24 - 41: cat - cat || Loss: 0.5558880567550659\n",
      "tensor([1., 0.]) tensor([0.7574, 0.2426], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 24 - 42: cat - cat || Loss: 0.5553237795829773\n",
      "tensor([1., 0.]) tensor([0.7579, 0.2421], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 24 - 43: cat - cat || Loss: 0.5547589063644409\n",
      "tensor([1., 0.]) tensor([0.7585, 0.2415], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 24 - 44: cat - cat || Loss: 0.5541936755180359\n",
      "tensor([1., 0.]) tensor([0.7591, 0.2409], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 24 - 45: cat - cat || Loss: 0.5536280870437622\n",
      "tensor([1., 0.]) tensor([0.7596, 0.2404], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 24 - 46: cat - cat || Loss: 0.5530624389648438\n",
      "tensor([1., 0.]) tensor([0.7602, 0.2398], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 24 - 47: cat - cat || Loss: 0.5524967312812805\n",
      "tensor([1., 0.]) tensor([0.7608, 0.2392], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 24 - 48: cat - cat || Loss: 0.5519311428070068\n",
      "tensor([1., 0.]) tensor([0.7613, 0.2387], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 24 - 49: cat - cat || Loss: 0.5513656139373779\n",
      "tensor([1., 0.]) tensor([0.7619, 0.2381], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 24 - 50: cat - cat || Loss: 0.5508003234863281\n",
      "tensor([1., 0.]) tensor([0.7625, 0.2375], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 24 - 51: cat - cat || Loss: 0.550235390663147\n",
      "tensor([1., 0.]) tensor([0.7630, 0.2370], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 24 - 52: cat - cat || Loss: 0.5496708154678345\n",
      "tensor([1., 0.]) tensor([0.7636, 0.2364], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 24 - 53: cat - cat || Loss: 0.5491065979003906\n",
      "tensor([1., 0.]) tensor([0.7642, 0.2358], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 24 - 54: cat - cat || Loss: 0.5485429167747498\n",
      "tensor([1., 0.]) tensor([0.7647, 0.2353], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 24 - 55: cat - cat || Loss: 0.5479797124862671\n",
      "tensor([1., 0.]) tensor([0.7653, 0.2347], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 24 - 56: cat - cat || Loss: 0.547417163848877\n",
      "tensor([1., 0.]) tensor([0.7658, 0.2342], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 24 - 57: cat - cat || Loss: 0.5468549728393555\n",
      "tensor([1., 0.]) tensor([0.7664, 0.2336], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 24 - 58: cat - cat || Loss: 0.5462935566902161\n",
      "tensor([1., 0.]) tensor([0.7670, 0.2330], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 24 - 59: cat - cat || Loss: 0.5457329154014587\n",
      "tensor([1., 0.]) tensor([0.7675, 0.2325], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 24 - 60: cat - cat || Loss: 0.5451727509498596\n",
      "tensor([1., 0.]) tensor([0.7681, 0.2319], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 24 - 61: cat - cat || Loss: 0.5446133613586426\n",
      "tensor([1., 0.]) tensor([0.7686, 0.2314], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 24 - 62: cat - cat || Loss: 0.5440547466278076\n",
      "tensor([1., 0.]) tensor([0.7692, 0.2308], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 24 - 63: cat - cat || Loss: 0.5434969067573547\n",
      "tensor([1., 0.]) tensor([0.7698, 0.2302], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 24 - 64: cat - cat || Loss: 0.5429397821426392\n",
      "tensor([1., 0.]) tensor([0.7703, 0.2297], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 24 - 65: cat - cat || Loss: 0.5423834323883057\n",
      "tensor([1., 0.]) tensor([0.7709, 0.2291], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 24 - 66: cat - cat || Loss: 0.541827917098999\n",
      "tensor([1., 0.]) tensor([0.7714, 0.2286], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 24 - 67: cat - cat || Loss: 0.5412732362747192\n",
      "tensor([1., 0.]) tensor([0.7720, 0.2280], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 24 - 68: cat - cat || Loss: 0.5407193899154663\n",
      "tensor([1., 0.]) tensor([0.7725, 0.2275], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 24 - 69: cat - cat || Loss: 0.5401662588119507\n",
      "tensor([1., 0.]) tensor([0.7731, 0.2269], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 24 - 70: cat - cat || Loss: 0.5396140813827515\n",
      "tensor([1., 0.]) tensor([0.7736, 0.2264], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 24 - 71: cat - cat || Loss: 0.5390627384185791\n",
      "tensor([1., 0.]) tensor([0.7742, 0.2258], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 24 - 72: cat - cat || Loss: 0.5385122299194336\n",
      "tensor([1., 0.]) tensor([0.7747, 0.2253], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 24 - 73: cat - cat || Loss: 0.5379626154899597\n",
      "tensor([1., 0.]) tensor([0.7753, 0.2247], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 24 - 74: cat - cat || Loss: 0.5374138951301575\n",
      "tensor([1., 0.]) tensor([0.7758, 0.2242], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 24 - 75: cat - cat || Loss: 0.5368661880493164\n",
      "tensor([1., 0.]) tensor([0.7764, 0.2236], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 24 - 76: cat - cat || Loss: 0.5363193154335022\n",
      "tensor([1., 0.]) tensor([0.7769, 0.2231], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 24 - 77: cat - cat || Loss: 0.5357732772827148\n",
      "tensor([1., 0.]) tensor([0.7775, 0.2225], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 24 - 78: cat - cat || Loss: 0.5352281332015991\n",
      "tensor([1., 0.]) tensor([0.7780, 0.2220], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 24 - 79: cat - cat || Loss: 0.5346839427947998\n",
      "tensor([1., 0.]) tensor([0.7786, 0.2214], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 24 - 80: cat - cat || Loss: 0.5341407060623169\n",
      "tensor([1., 0.]) tensor([0.7791, 0.2209], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 24 - 81: cat - cat || Loss: 0.5335982441902161\n",
      "tensor([1., 0.]) tensor([0.7797, 0.2203], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 24 - 82: cat - cat || Loss: 0.5330567359924316\n",
      "tensor([1., 0.]) tensor([0.7802, 0.2198], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 24 - 83: cat - cat || Loss: 0.5325163006782532\n",
      "tensor([1., 0.]) tensor([0.7807, 0.2193], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 24 - 84: cat - cat || Loss: 0.5319767594337463\n",
      "tensor([1., 0.]) tensor([0.7813, 0.2187], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 24 - 85: cat - cat || Loss: 0.5314380526542664\n",
      "tensor([1., 0.]) tensor([0.7818, 0.2182], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 24 - 86: cat - cat || Loss: 0.5309002995491028\n",
      "tensor([1., 0.]) tensor([0.7824, 0.2176], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 24 - 87: cat - cat || Loss: 0.5303635001182556\n",
      "tensor([1., 0.]) tensor([0.7829, 0.2171], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 24 - 88: cat - cat || Loss: 0.5298276543617249\n",
      "tensor([1., 0.]) tensor([0.7834, 0.2166], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 24 - 89: cat - cat || Loss: 0.5292927026748657\n",
      "tensor([1., 0.]) tensor([0.7840, 0.2160], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 24 - 90: cat - cat || Loss: 0.5287587642669678\n",
      "tensor([1., 0.]) tensor([0.7845, 0.2155], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 24 - 91: cat - cat || Loss: 0.5282256603240967\n",
      "tensor([1., 0.]) tensor([0.7850, 0.2150], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 24 - 92: cat - cat || Loss: 0.5276935696601868\n",
      "tensor([1., 0.]) tensor([0.7856, 0.2144], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 24 - 93: cat - cat || Loss: 0.5271623730659485\n",
      "tensor([1., 0.]) tensor([0.7861, 0.2139], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 24 - 94: cat - cat || Loss: 0.5266320705413818\n",
      "tensor([1., 0.]) tensor([0.7866, 0.2134], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 24 - 95: cat - cat || Loss: 0.5261027216911316\n",
      "tensor([1., 0.]) tensor([0.7872, 0.2128], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 24 - 96: cat - cat || Loss: 0.5255743861198425\n",
      "tensor([1., 0.]) tensor([0.7877, 0.2123], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 24 - 97: cat - cat || Loss: 0.5250470638275146\n",
      "tensor([1., 0.]) tensor([0.7882, 0.2118], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 24 - 98: cat - cat || Loss: 0.5245205163955688\n",
      "tensor([1., 0.]) tensor([0.7887, 0.2113], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 24 - 99: cat - cat || Loss: 0.5239951014518738\n",
      "tensor([1., 0.]) tensor([0.7893, 0.2107], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 24 - 100: cat - cat || Loss: 0.5234705209732056\n",
      "tensor([1., 0.]) tensor([0.7898, 0.2102], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 24 - 101: cat - cat || Loss: 0.5229468941688538\n",
      "tensor([1., 0.]) tensor([0.7903, 0.2097], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 24 - 102: cat - cat || Loss: 0.5224243402481079\n",
      "tensor([1., 0.]) tensor([0.7908, 0.2092], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 24 - 103: cat - cat || Loss: 0.5219024419784546\n",
      "tensor([1., 0.]) tensor([0.7914, 0.2086], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 24 - 104: cat - cat || Loss: 0.5213817358016968\n",
      "tensor([1., 0.]) tensor([0.7919, 0.2081], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 24 - 105: cat - cat || Loss: 0.5208619832992554\n",
      "tensor([1., 0.]) tensor([0.7924, 0.2076], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 24 - 106: cat - cat || Loss: 0.5203430652618408\n",
      "tensor([1., 0.]) tensor([0.7929, 0.2071], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 24 - 107: cat - cat || Loss: 0.5198251605033875\n",
      "tensor([1., 0.]) tensor([0.7934, 0.2066], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 24 - 108: cat - cat || Loss: 0.51930832862854\n",
      "tensor([1., 0.]) tensor([0.7940, 0.2060], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 24 - 109: cat - cat || Loss: 0.5187922716140747\n",
      "tensor([1., 0.]) tensor([0.7945, 0.2055], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 24 - 110: cat - cat || Loss: 0.5182771682739258\n",
      "tensor([1., 0.]) tensor([0.7950, 0.2050], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 24 - 111: cat - cat || Loss: 0.5177632570266724\n",
      "tensor([1., 0.]) tensor([0.7955, 0.2045], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 24 - 112: cat - cat || Loss: 0.5172499418258667\n",
      "tensor([1., 0.]) tensor([0.7960, 0.2040], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 24 - 113: cat - cat || Loss: 0.5167379379272461\n",
      "tensor([1., 0.]) tensor([0.7965, 0.2035], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 24 - 114: cat - cat || Loss: 0.516226589679718\n",
      "tensor([1., 0.]) tensor([0.7970, 0.2030], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 24 - 115: cat - cat || Loss: 0.5157163739204407\n",
      "tensor([1., 0.]) tensor([0.7975, 0.2025], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 24 - 116: cat - cat || Loss: 0.515207052230835\n",
      "tensor([1., 0.]) tensor([0.7981, 0.2019], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 24 - 117: cat - cat || Loss: 0.5146987438201904\n",
      "tensor([1., 0.]) tensor([0.7986, 0.2014], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 24 - 118: cat - cat || Loss: 0.5141912698745728\n",
      "tensor([1., 0.]) tensor([0.7991, 0.2009], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 24 - 119: cat - cat || Loss: 0.5136849284172058\n",
      "tensor([1., 0.]) tensor([0.7996, 0.2004], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 24 - 120: cat - cat || Loss: 0.513179361820221\n",
      "tensor([1., 0.]) tensor([0.8001, 0.1999], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 24 - 121: cat - cat || Loss: 0.5126748085021973\n",
      "tensor([1., 0.]) tensor([0.8006, 0.1994], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 24 - 122: cat - cat || Loss: 0.51217120885849\n",
      "tensor([1., 0.]) tensor([0.8011, 0.1989], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 24 - 123: cat - cat || Loss: 0.5116686820983887\n",
      "tensor([1., 0.]) tensor([0.8016, 0.1984], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 24 - 124: cat - cat || Loss: 0.511167049407959\n",
      "tensor([1., 0.]) tensor([0.8021, 0.1979], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 24 - 125: cat - cat || Loss: 0.5106663703918457\n",
      "tensor([1., 0.]) tensor([0.8026, 0.1974], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 24 - 126: cat - cat || Loss: 0.510166585445404\n",
      "tensor([1., 0.]) tensor([0.8031, 0.1969], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 24 - 127: cat - cat || Loss: 0.5096678137779236\n",
      "tensor([1., 0.]) tensor([0.8036, 0.1964], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 24 - 128: cat - cat || Loss: 0.5091699361801147\n",
      "tensor([1., 0.]) tensor([0.8041, 0.1959], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 24 - 129: cat - cat || Loss: 0.5086730718612671\n",
      "tensor([1., 0.]) tensor([0.8046, 0.1954], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 24 - 130: cat - cat || Loss: 0.5081772208213806\n",
      "tensor([1., 0.]) tensor([0.8051, 0.1949], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 24 - 131: cat - cat || Loss: 0.507682204246521\n",
      "tensor([1., 0.]) tensor([0.8056, 0.1944], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 24 - 132: cat - cat || Loss: 0.5071882009506226\n",
      "tensor([1., 0.]) tensor([0.8061, 0.1939], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 24 - 133: cat - cat || Loss: 0.5066952109336853\n",
      "tensor([1., 0.]) tensor([0.8066, 0.1934], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 24 - 134: cat - cat || Loss: 0.5062030553817749\n",
      "tensor([1., 0.]) tensor([0.8071, 0.1929], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 24 - 135: cat - cat || Loss: 0.5057120323181152\n",
      "tensor([1., 0.]) tensor([0.8075, 0.1925], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 24 - 136: cat - cat || Loss: 0.5052218437194824\n",
      "tensor([1., 0.]) tensor([0.8080, 0.1920], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 24 - 137: cat - cat || Loss: 0.5047324895858765\n",
      "tensor([1., 0.]) tensor([0.8085, 0.1915], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 24 - 138: cat - cat || Loss: 0.504244327545166\n",
      "tensor([1., 0.]) tensor([0.8090, 0.1910], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 24 - 139: cat - cat || Loss: 0.5037569403648376\n",
      "tensor([1., 0.]) tensor([0.8095, 0.1905], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 24 - 140: cat - cat || Loss: 0.5032706260681152\n",
      "tensor([1., 0.]) tensor([0.8100, 0.1900], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 24 - 141: cat - cat || Loss: 0.5027850866317749\n",
      "tensor([1., 0.]) tensor([0.8105, 0.1895], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 24 - 142: cat - cat || Loss: 0.5023007392883301\n",
      "tensor([1., 0.]) tensor([0.8110, 0.1890], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 24 - 143: cat - cat || Loss: 0.5018172264099121\n",
      "tensor([1., 0.]) tensor([0.8114, 0.1886], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 24 - 144: cat - cat || Loss: 0.5013347268104553\n",
      "tensor([1., 0.]) tensor([0.8119, 0.1881], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 24 - 145: cat - cat || Loss: 0.5008531212806702\n",
      "tensor([1., 0.]) tensor([0.8124, 0.1876], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 24 - 146: cat - cat || Loss: 0.500372588634491\n",
      "tensor([1., 0.]) tensor([0.8129, 0.1871], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 24 - 147: cat - cat || Loss: 0.499892920255661\n",
      "tensor([1., 0.]) tensor([0.8134, 0.1866], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 24 - 148: cat - cat || Loss: 0.4994141459465027\n",
      "tensor([1., 0.]) tensor([0.8138, 0.1862], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 24 - 149: cat - cat || Loss: 0.49893638491630554\n",
      "tensor([1., 0.]) tensor([0.8143, 0.1857], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 24 - 150: cat - cat || Loss: 0.4984595477581024\n",
      "tensor([1., 0.]) tensor([0.8148, 0.1852], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 24 - 151: cat - cat || Loss: 0.49798378348350525\n",
      "tensor([1., 0.]) tensor([0.8153, 0.1847], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 24 - 152: cat - cat || Loss: 0.4975088834762573\n",
      "tensor([1., 0.]) tensor([0.8158, 0.1842], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 24 - 153: cat - cat || Loss: 0.4970349073410034\n",
      "tensor([1., 0.]) tensor([0.8162, 0.1838], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 24 - 154: cat - cat || Loss: 0.4965618848800659\n",
      "tensor([1., 0.]) tensor([0.8167, 0.1833], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 24 - 155: cat - cat || Loss: 0.49608975648880005\n",
      "tensor([1., 0.]) tensor([0.8172, 0.1828], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 24 - 156: cat - cat || Loss: 0.4956187605857849\n",
      "tensor([1., 0.]) tensor([0.8176, 0.1824], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 24 - 157: cat - cat || Loss: 0.4951486587524414\n",
      "tensor([1., 0.]) tensor([0.8181, 0.1819], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 24 - 158: cat - cat || Loss: 0.49467939138412476\n",
      "tensor([1., 0.]) tensor([0.8186, 0.1814], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 24 - 159: cat - cat || Loss: 0.4942111372947693\n",
      "tensor([1., 0.]) tensor([0.8191, 0.1809], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 24 - 160: cat - cat || Loss: 0.49374380707740784\n",
      "tensor([1., 0.]) tensor([0.8195, 0.1805], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 24 - 161: cat - cat || Loss: 0.49327754974365234\n",
      "tensor([1., 0.]) tensor([0.8200, 0.1800], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 24 - 162: cat - cat || Loss: 0.4928121566772461\n",
      "tensor([1., 0.]) tensor([0.8204, 0.1796], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 24 - 163: cat - cat || Loss: 0.4923475980758667\n",
      "tensor([1., 0.]) tensor([0.8209, 0.1791], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 24 - 164: cat - cat || Loss: 0.49188417196273804\n",
      "tensor([1., 0.]) tensor([0.8214, 0.1786], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 24 - 165: cat - cat || Loss: 0.4914216101169586\n",
      "tensor([1., 0.]) tensor([0.8218, 0.1782], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 24 - 166: cat - cat || Loss: 0.490960031747818\n",
      "tensor([1., 0.]) tensor([0.8223, 0.1777], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 24 - 167: cat - cat || Loss: 0.4904993772506714\n",
      "tensor([1., 0.]) tensor([0.8228, 0.1772], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 24 - 168: cat - cat || Loss: 0.4900397062301636\n",
      "tensor([1., 0.]) tensor([0.8232, 0.1768], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 24 - 169: cat - cat || Loss: 0.4895808696746826\n",
      "tensor([1., 0.]) tensor([0.8237, 0.1763], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 24 - 170: cat - cat || Loss: 0.4891231656074524\n",
      "tensor([1., 0.]) tensor([0.8241, 0.1759], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 24 - 171: cat - cat || Loss: 0.488666296005249\n",
      "tensor([1., 0.]) tensor([0.8246, 0.1754], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 24 - 172: cat - cat || Loss: 0.4882103204727173\n",
      "tensor([1., 0.]) tensor([0.8251, 0.1749], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 24 - 173: cat - cat || Loss: 0.4877554178237915\n",
      "tensor([1., 0.]) tensor([0.8255, 0.1745], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 24 - 174: cat - cat || Loss: 0.48730137944221497\n",
      "tensor([1., 0.]) tensor([0.8260, 0.1740], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 24 - 175: cat - cat || Loss: 0.48684823513031006\n",
      "tensor([1., 0.]) tensor([0.8264, 0.1736], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 24 - 176: cat - cat || Loss: 0.4863961338996887\n",
      "tensor([1., 0.]) tensor([0.8269, 0.1731], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 24 - 177: cat - cat || Loss: 0.4859450161457062\n",
      "tensor([1., 0.]) tensor([0.8273, 0.1727], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 24 - 178: cat - cat || Loss: 0.4854947328567505\n",
      "tensor([1., 0.]) tensor([0.8278, 0.1722], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 24 - 179: cat - cat || Loss: 0.48504549264907837\n",
      "tensor([1., 0.]) tensor([0.8282, 0.1718], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 24 - 180: cat - cat || Loss: 0.4845971465110779\n",
      "tensor([1., 0.]) tensor([0.8287, 0.1713], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 24 - 181: cat - cat || Loss: 0.484149694442749\n",
      "tensor([1., 0.]) tensor([0.8291, 0.1709], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 24 - 182: cat - cat || Loss: 0.48370325565338135\n",
      "tensor([1., 0.]) tensor([0.8296, 0.1704], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 24 - 183: cat - cat || Loss: 0.48325788974761963\n",
      "tensor([1., 0.]) tensor([0.8300, 0.1700], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 24 - 184: cat - cat || Loss: 0.4828132688999176\n",
      "tensor([1., 0.]) tensor([0.8304, 0.1696], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 24 - 185: cat - cat || Loss: 0.48236969113349915\n",
      "tensor([1., 0.]) tensor([0.8309, 0.1691], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 24 - 186: cat - cat || Loss: 0.48192694783210754\n",
      "tensor([1., 0.]) tensor([0.8313, 0.1687], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 24 - 187: cat - cat || Loss: 0.4814853072166443\n",
      "tensor([1., 0.]) tensor([0.8318, 0.1682], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 24 - 188: cat - cat || Loss: 0.48104456067085266\n",
      "tensor([1., 0.]) tensor([0.8322, 0.1678], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 24 - 189: cat - cat || Loss: 0.4806046485900879\n",
      "tensor([1., 0.]) tensor([0.8327, 0.1673], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 24 - 190: dog - cat || Loss: 1.146357536315918\n",
      "tensor([0., 1.]) tensor([0.8331, 0.1669], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 24 - 191: dog - cat || Loss: 1.1467087268829346\n",
      "tensor([0., 1.]) tensor([0.8334, 0.1666], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 24 - 192: dog - cat || Loss: 1.146981120109558\n",
      "tensor([0., 1.]) tensor([0.8337, 0.1663], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 24 - 193: dog - cat || Loss: 1.1471829414367676\n",
      "tensor([0., 1.]) tensor([0.8339, 0.1661], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 24 - 194: dog - cat || Loss: 1.1473212242126465\n",
      "tensor([0., 1.]) tensor([0.8341, 0.1659], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 24 - 195: dog - cat || Loss: 1.1474025249481201\n",
      "tensor([0., 1.]) tensor([0.8341, 0.1659], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 24 - 196: dog - cat || Loss: 1.1474324464797974\n",
      "tensor([0., 1.]) tensor([0.8342, 0.1658], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 24 - 197: dog - cat || Loss: 1.147416114807129\n",
      "tensor([0., 1.]) tensor([0.8342, 0.1658], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 24 - 198: dog - cat || Loss: 1.1473581790924072\n",
      "tensor([0., 1.]) tensor([0.8341, 0.1659], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 24 - 199: dog - cat || Loss: 1.1472628116607666\n",
      "tensor([0., 1.]) tensor([0.8340, 0.1660], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 24 - 200: dog - cat || Loss: 1.1471338272094727\n",
      "tensor([0., 1.]) tensor([0.8339, 0.1661], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 24 - 201: dog - cat || Loss: 1.1469743251800537\n",
      "tensor([0., 1.]) tensor([0.8337, 0.1663], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 24 - 202: dog - cat || Loss: 1.1467876434326172\n",
      "tensor([0., 1.]) tensor([0.8335, 0.1665], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 24 - 203: dog - cat || Loss: 1.146575927734375\n",
      "tensor([0., 1.]) tensor([0.8333, 0.1667], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 24 - 204: dog - cat || Loss: 1.1463420391082764\n",
      "tensor([0., 1.]) tensor([0.8331, 0.1669], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 24 - 205: dog - cat || Loss: 1.1460877656936646\n",
      "tensor([0., 1.]) tensor([0.8328, 0.1672], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 24 - 206: dog - cat || Loss: 1.1458157300949097\n",
      "tensor([0., 1.]) tensor([0.8326, 0.1674], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 24 - 207: dog - cat || Loss: 1.1455268859863281\n",
      "tensor([0., 1.]) tensor([0.8323, 0.1677], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 24 - 208: dog - cat || Loss: 1.1452231407165527\n",
      "tensor([0., 1.]) tensor([0.8320, 0.1680], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 24 - 209: dog - cat || Loss: 1.1449060440063477\n",
      "tensor([0., 1.]) tensor([0.8316, 0.1684], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 24 - 210: dog - cat || Loss: 1.1445766687393188\n",
      "tensor([0., 1.]) tensor([0.8313, 0.1687], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 24 - 211: dog - cat || Loss: 1.1442362070083618\n",
      "tensor([0., 1.]) tensor([0.8310, 0.1690], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 24 - 212: dog - cat || Loss: 1.1438854932785034\n",
      "tensor([0., 1.]) tensor([0.8306, 0.1694], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 24 - 213: dog - cat || Loss: 1.1435258388519287\n",
      "tensor([0., 1.]) tensor([0.8303, 0.1697], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 24 - 214: dog - cat || Loss: 1.1431578397750854\n",
      "tensor([0., 1.]) tensor([0.8299, 0.1701], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 24 - 215: dog - cat || Loss: 1.1427820920944214\n",
      "tensor([0., 1.]) tensor([0.8295, 0.1705], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 24 - 216: dog - cat || Loss: 1.142399549484253\n",
      "tensor([0., 1.]) tensor([0.8291, 0.1709], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 24 - 217: dog - cat || Loss: 1.1420106887817383\n",
      "tensor([0., 1.]) tensor([0.8287, 0.1713], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 24 - 218: dog - cat || Loss: 1.1416161060333252\n",
      "tensor([0., 1.]) tensor([0.8284, 0.1716], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 24 - 219: dog - cat || Loss: 1.1412162780761719\n",
      "tensor([0., 1.]) tensor([0.8280, 0.1720], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 24 - 220: dog - cat || Loss: 1.140811562538147\n",
      "tensor([0., 1.]) tensor([0.8275, 0.1725], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 24 - 221: dog - cat || Loss: 1.1404023170471191\n",
      "tensor([0., 1.]) tensor([0.8271, 0.1729], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 24 - 222: dog - cat || Loss: 1.1399890184402466\n",
      "tensor([0., 1.]) tensor([0.8267, 0.1733], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 24 - 223: dog - cat || Loss: 1.1395719051361084\n",
      "tensor([0., 1.]) tensor([0.8263, 0.1737], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 24 - 224: dog - cat || Loss: 1.1391513347625732\n",
      "tensor([0., 1.]) tensor([0.8259, 0.1741], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 24 - 225: dog - cat || Loss: 1.1387276649475098\n",
      "tensor([0., 1.]) tensor([0.8255, 0.1745], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 24 - 226: dog - cat || Loss: 1.138300895690918\n",
      "tensor([0., 1.]) tensor([0.8250, 0.1750], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 24 - 227: dog - cat || Loss: 1.1378713846206665\n",
      "tensor([0., 1.]) tensor([0.8246, 0.1754], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 24 - 228: dog - cat || Loss: 1.1374391317367554\n",
      "tensor([0., 1.]) tensor([0.8242, 0.1758], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 24 - 229: dog - cat || Loss: 1.1370046138763428\n",
      "tensor([0., 1.]) tensor([0.8237, 0.1763], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 24 - 230: dog - cat || Loss: 1.1365677118301392\n",
      "tensor([0., 1.]) tensor([0.8233, 0.1767], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 24 - 231: dog - cat || Loss: 1.1361286640167236\n",
      "tensor([0., 1.]) tensor([0.8229, 0.1771], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 24 - 232: dog - cat || Loss: 1.1356877088546753\n",
      "tensor([0., 1.]) tensor([0.8224, 0.1776], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 24 - 233: dog - cat || Loss: 1.1352448463439941\n",
      "tensor([0., 1.]) tensor([0.8220, 0.1780], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 24 - 234: dog - cat || Loss: 1.1348001956939697\n",
      "tensor([0., 1.]) tensor([0.8215, 0.1785], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 24 - 235: dog - cat || Loss: 1.134353756904602\n",
      "tensor([0., 1.]) tensor([0.8211, 0.1789], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 24 - 236: dog - cat || Loss: 1.1339056491851807\n",
      "tensor([0., 1.]) tensor([0.8206, 0.1794], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 24 - 237: dog - cat || Loss: 1.1334559917449951\n",
      "tensor([0., 1.]) tensor([0.8202, 0.1798], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 24 - 238: dog - cat || Loss: 1.1330050230026245\n",
      "tensor([0., 1.]) tensor([0.8197, 0.1803], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 24 - 239: dog - cat || Loss: 1.1325522661209106\n",
      "tensor([0., 1.]) tensor([0.8193, 0.1807], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 24 - 240: dog - cat || Loss: 1.1320981979370117\n",
      "tensor([0., 1.]) tensor([0.8188, 0.1812], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 24 - 241: dog - cat || Loss: 1.1316430568695068\n",
      "tensor([0., 1.]) tensor([0.8184, 0.1816], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 24 - 242: dog - cat || Loss: 1.1311864852905273\n",
      "tensor([0., 1.]) tensor([0.8179, 0.1821], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 24 - 243: dog - cat || Loss: 1.1307286024093628\n",
      "tensor([0., 1.]) tensor([0.8175, 0.1825], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 24 - 244: dog - cat || Loss: 1.1302695274353027\n",
      "tensor([0., 1.]) tensor([0.8170, 0.1830], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 24 - 245: dog - cat || Loss: 1.1298093795776367\n",
      "tensor([0., 1.]) tensor([0.8165, 0.1835], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 24 - 246: dog - cat || Loss: 1.1293479204177856\n",
      "tensor([0., 1.]) tensor([0.8161, 0.1839], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 24 - 247: dog - cat || Loss: 1.128885269165039\n",
      "tensor([0., 1.]) tensor([0.8156, 0.1844], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 24 - 248: dog - cat || Loss: 1.128421664237976\n",
      "tensor([0., 1.]) tensor([0.8152, 0.1848], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 24 - 249: dog - cat || Loss: 1.127956748008728\n",
      "tensor([0., 1.]) tensor([0.8147, 0.1853], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 24 - 250: dog - cat || Loss: 1.1274909973144531\n",
      "tensor([0., 1.]) tensor([0.8142, 0.1858], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 24 - 251: dog - cat || Loss: 1.1270241737365723\n",
      "tensor([0., 1.]) tensor([0.8138, 0.1862], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 24 - 252: dog - cat || Loss: 1.1265560388565063\n",
      "tensor([0., 1.]) tensor([0.8133, 0.1867], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 24 - 253: dog - cat || Loss: 1.1260870695114136\n",
      "tensor([0., 1.]) tensor([0.8128, 0.1872], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 24 - 254: dog - cat || Loss: 1.1256169080734253\n",
      "tensor([0., 1.]) tensor([0.8124, 0.1876], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 24 - 255: dog - cat || Loss: 1.1251460313796997\n",
      "tensor([0., 1.]) tensor([0.8119, 0.1881], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 24 - 256: dog - cat || Loss: 1.124673843383789\n",
      "tensor([0., 1.]) tensor([0.8114, 0.1886], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 24 - 257: dog - cat || Loss: 1.1242008209228516\n",
      "tensor([0., 1.]) tensor([0.8109, 0.1891], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 24 - 258: dog - cat || Loss: 1.1237269639968872\n",
      "tensor([0., 1.]) tensor([0.8105, 0.1895], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 24 - 259: dog - cat || Loss: 1.1232519149780273\n",
      "tensor([0., 1.]) tensor([0.8100, 0.1900], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 24 - 260: dog - cat || Loss: 1.122775912284851\n",
      "tensor([0., 1.]) tensor([0.8095, 0.1905], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 24 - 261: dog - cat || Loss: 1.1222989559173584\n",
      "tensor([0., 1.]) tensor([0.8090, 0.1910], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 24 - 262: dog - cat || Loss: 1.1218211650848389\n",
      "tensor([0., 1.]) tensor([0.8086, 0.1914], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 24 - 263: dog - cat || Loss: 1.1213421821594238\n",
      "tensor([0., 1.]) tensor([0.8081, 0.1919], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 24 - 264: dog - cat || Loss: 1.1208624839782715\n",
      "tensor([0., 1.]) tensor([0.8076, 0.1924], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 24 - 265: dog - cat || Loss: 1.1203817129135132\n",
      "tensor([0., 1.]) tensor([0.8071, 0.1929], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 24 - 266: dog - cat || Loss: 1.1198999881744385\n",
      "tensor([0., 1.]) tensor([0.8066, 0.1934], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 24 - 267: dog - cat || Loss: 1.119417428970337\n",
      "tensor([0., 1.]) tensor([0.8062, 0.1938], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 24 - 268: dog - cat || Loss: 1.1189337968826294\n",
      "tensor([0., 1.]) tensor([0.8057, 0.1943], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 24 - 269: dog - cat || Loss: 1.1184494495391846\n",
      "tensor([0., 1.]) tensor([0.8052, 0.1948], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 24 - 270: dog - cat || Loss: 1.1179637908935547\n",
      "tensor([0., 1.]) tensor([0.8047, 0.1953], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 24 - 271: dog - cat || Loss: 1.1174774169921875\n",
      "tensor([0., 1.]) tensor([0.8042, 0.1958], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 24 - 272: dog - cat || Loss: 1.1169902086257935\n",
      "tensor([0., 1.]) tensor([0.8037, 0.1963], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 24 - 273: dog - cat || Loss: 1.1165019273757935\n",
      "tensor([0., 1.]) tensor([0.8032, 0.1968], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 24 - 274: dog - cat || Loss: 1.116012692451477\n",
      "tensor([0., 1.]) tensor([0.8028, 0.1972], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 24 - 275: dog - cat || Loss: 1.1155226230621338\n",
      "tensor([0., 1.]) tensor([0.8023, 0.1977], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 24 - 276: dog - cat || Loss: 1.1150315999984741\n",
      "tensor([0., 1.]) tensor([0.8018, 0.1982], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 24 - 277: dog - cat || Loss: 1.114539623260498\n",
      "tensor([0., 1.]) tensor([0.8013, 0.1987], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 24 - 278: dog - cat || Loss: 1.1140468120574951\n",
      "tensor([0., 1.]) tensor([0.8008, 0.1992], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 24 - 279: dog - cat || Loss: 1.1135529279708862\n",
      "tensor([0., 1.]) tensor([0.8003, 0.1997], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 24 - 280: dog - cat || Loss: 1.1130582094192505\n",
      "tensor([0., 1.]) tensor([0.7998, 0.2002], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 24 - 281: dog - cat || Loss: 1.1125625371932983\n",
      "tensor([0., 1.]) tensor([0.7993, 0.2007], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 24 - 282: dog - cat || Loss: 1.1120661497116089\n",
      "tensor([0., 1.]) tensor([0.7988, 0.2012], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 24 - 283: dog - cat || Loss: 1.111568570137024\n",
      "tensor([0., 1.]) tensor([0.7983, 0.2017], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 24 - 284: dog - cat || Loss: 1.111070156097412\n",
      "tensor([0., 1.]) tensor([0.7978, 0.2022], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 24 - 285: dog - cat || Loss: 1.1105709075927734\n",
      "tensor([0., 1.]) tensor([0.7973, 0.2027], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 24 - 286: dog - cat || Loss: 1.1100705862045288\n",
      "tensor([0., 1.]) tensor([0.7968, 0.2032], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 24 - 287: dog - cat || Loss: 1.1095693111419678\n",
      "tensor([0., 1.]) tensor([0.7963, 0.2037], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 24 - 288: dog - cat || Loss: 1.1090672016143799\n",
      "tensor([0., 1.]) tensor([0.7958, 0.2042], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 24 - 289: dog - cat || Loss: 1.1085641384124756\n",
      "tensor([0., 1.]) tensor([0.7953, 0.2047], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 24 - 290: dog - cat || Loss: 1.1080602407455444\n",
      "tensor([0., 1.]) tensor([0.7948, 0.2052], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 24 - 291: dog - cat || Loss: 1.1075553894042969\n",
      "tensor([0., 1.]) tensor([0.7943, 0.2057], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 24 - 292: dog - cat || Loss: 1.107049584388733\n",
      "tensor([0., 1.]) tensor([0.7938, 0.2062], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 24 - 293: dog - cat || Loss: 1.106542944908142\n",
      "tensor([0., 1.]) tensor([0.7933, 0.2067], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 24 - 294: dog - cat || Loss: 1.1060351133346558\n",
      "tensor([0., 1.]) tensor([0.7928, 0.2072], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 24 - 295: dog - cat || Loss: 1.1055268049240112\n",
      "tensor([0., 1.]) tensor([0.7923, 0.2077], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 24 - 296: dog - cat || Loss: 1.1050174236297607\n",
      "tensor([0., 1.]) tensor([0.7918, 0.2082], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 24 - 297: dog - cat || Loss: 1.1045069694519043\n",
      "tensor([0., 1.]) tensor([0.7912, 0.2088], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 24 - 298: dog - cat || Loss: 1.103995680809021\n",
      "tensor([0., 1.]) tensor([0.7907, 0.2093], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 24 - 299: dog - cat || Loss: 1.1034834384918213\n",
      "tensor([0., 1.]) tensor([0.7902, 0.2098], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 24 - 300: dog - cat || Loss: 1.1029703617095947\n",
      "tensor([0., 1.]) tensor([0.7897, 0.2103], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 24 - 301: dog - cat || Loss: 1.1024562120437622\n",
      "tensor([0., 1.]) tensor([0.7892, 0.2108], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 24 - 302: dog - cat || Loss: 1.1019413471221924\n",
      "tensor([0., 1.]) tensor([0.7887, 0.2113], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 24 - 303: dog - cat || Loss: 1.1014255285263062\n",
      "tensor([0., 1.]) tensor([0.7882, 0.2118], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 24 - 304: dog - cat || Loss: 1.100908875465393\n",
      "tensor([0., 1.]) tensor([0.7876, 0.2124], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 24 - 305: dog - cat || Loss: 1.1003910303115845\n",
      "tensor([0., 1.]) tensor([0.7871, 0.2129], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 24 - 306: dog - cat || Loss: 1.0998724699020386\n",
      "tensor([0., 1.]) tensor([0.7866, 0.2134], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 24 - 307: dog - cat || Loss: 1.0993529558181763\n",
      "tensor([0., 1.]) tensor([0.7861, 0.2139], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 24 - 308: dog - cat || Loss: 1.098832607269287\n",
      "tensor([0., 1.]) tensor([0.7856, 0.2144], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 24 - 309: dog - cat || Loss: 1.098311185836792\n",
      "tensor([0., 1.]) tensor([0.7850, 0.2150], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 24 - 310: dog - cat || Loss: 1.09778892993927\n",
      "tensor([0., 1.]) tensor([0.7845, 0.2155], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 24 - 311: dog - cat || Loss: 1.0972657203674316\n",
      "tensor([0., 1.]) tensor([0.7840, 0.2160], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 24 - 312: dog - cat || Loss: 1.096741795539856\n",
      "tensor([0., 1.]) tensor([0.7835, 0.2165], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 24 - 313: dog - cat || Loss: 1.0962165594100952\n",
      "tensor([0., 1.]) tensor([0.7830, 0.2170], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 24 - 314: dog - cat || Loss: 1.0956907272338867\n",
      "tensor([0., 1.]) tensor([0.7824, 0.2176], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 24 - 315: dog - cat || Loss: 1.0951638221740723\n",
      "tensor([0., 1.]) tensor([0.7819, 0.2181], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 24 - 316: dog - cat || Loss: 1.094636082649231\n",
      "tensor([0., 1.]) tensor([0.7814, 0.2186], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 24 - 317: dog - cat || Loss: 1.0941075086593628\n",
      "tensor([0., 1.]) tensor([0.7808, 0.2192], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 24 - 318: dog - cat || Loss: 1.0935778617858887\n",
      "tensor([0., 1.]) tensor([0.7803, 0.2197], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 24 - 319: dog - cat || Loss: 1.0930476188659668\n",
      "tensor([0., 1.]) tensor([0.7798, 0.2202], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 24 - 320: dog - cat || Loss: 1.0925161838531494\n",
      "tensor([0., 1.]) tensor([0.7793, 0.2207], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 24 - 321: dog - cat || Loss: 1.0919839143753052\n",
      "tensor([0., 1.]) tensor([0.7787, 0.2213], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 24 - 322: dog - cat || Loss: 1.091450810432434\n",
      "tensor([0., 1.]) tensor([0.7782, 0.2218], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 24 - 323: dog - cat || Loss: 1.090916633605957\n",
      "tensor([0., 1.]) tensor([0.7777, 0.2223], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 24 - 324: dog - cat || Loss: 1.0903817415237427\n",
      "tensor([0., 1.]) tensor([0.7771, 0.2229], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 24 - 325: dog - cat || Loss: 1.089845895767212\n",
      "tensor([0., 1.]) tensor([0.7766, 0.2234], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 24 - 326: dog - cat || Loss: 1.0893090963363647\n",
      "tensor([0., 1.]) tensor([0.7760, 0.2240], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 24 - 327: dog - cat || Loss: 1.0887714624404907\n",
      "tensor([0., 1.]) tensor([0.7755, 0.2245], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 24 - 328: dog - cat || Loss: 1.0882327556610107\n",
      "tensor([0., 1.]) tensor([0.7750, 0.2250], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 24 - 329: dog - cat || Loss: 1.087693214416504\n",
      "tensor([0., 1.]) tensor([0.7744, 0.2256], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 24 - 330: dog - cat || Loss: 1.0871528387069702\n",
      "tensor([0., 1.]) tensor([0.7739, 0.2261], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 24 - 331: dog - cat || Loss: 1.0866117477416992\n",
      "tensor([0., 1.]) tensor([0.7734, 0.2267], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 24 - 332: dog - cat || Loss: 1.0860694646835327\n",
      "tensor([0., 1.]) tensor([0.7728, 0.2272], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 24 - 333: dog - cat || Loss: 1.0855263471603394\n",
      "tensor([0., 1.]) tensor([0.7723, 0.2277], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 24 - 334: dog - cat || Loss: 1.0849823951721191\n",
      "tensor([0., 1.]) tensor([0.7717, 0.2283], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 24 - 335: dog - cat || Loss: 1.084437608718872\n",
      "tensor([0., 1.]) tensor([0.7712, 0.2288], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 24 - 336: dog - cat || Loss: 1.083891749382019\n",
      "tensor([0., 1.]) tensor([0.7706, 0.2294], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 24 - 337: dog - cat || Loss: 1.0833450555801392\n",
      "tensor([0., 1.]) tensor([0.7701, 0.2299], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 24 - 338: dog - cat || Loss: 1.0827975273132324\n",
      "tensor([0., 1.]) tensor([0.7695, 0.2305], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 24 - 339: dog - cat || Loss: 1.0822491645812988\n",
      "tensor([0., 1.]) tensor([0.7690, 0.2310], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 24 - 340: dog - cat || Loss: 1.0816996097564697\n",
      "tensor([0., 1.]) tensor([0.7684, 0.2316], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 24 - 341: dog - cat || Loss: 1.0811495780944824\n",
      "tensor([0., 1.]) tensor([0.7679, 0.2321], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 24 - 342: dog - cat || Loss: 1.0805983543395996\n",
      "tensor([0., 1.]) tensor([0.7673, 0.2327], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 24 - 343: dog - cat || Loss: 1.0800464153289795\n",
      "tensor([0., 1.]) tensor([0.7668, 0.2332], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 24 - 344: dog - cat || Loss: 1.079493522644043\n",
      "tensor([0., 1.]) tensor([0.7662, 0.2338], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 24 - 345: dog - cat || Loss: 1.0789395570755005\n",
      "tensor([0., 1.]) tensor([0.7657, 0.2343], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 24 - 346: dog - cat || Loss: 1.0783847570419312\n",
      "tensor([0., 1.]) tensor([0.7651, 0.2349], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 24 - 347: dog - cat || Loss: 1.077829122543335\n",
      "tensor([0., 1.]) tensor([0.7646, 0.2354], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 24 - 348: dog - cat || Loss: 1.077272653579712\n",
      "tensor([0., 1.]) tensor([0.7640, 0.2360], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 24 - 349: dog - cat || Loss: 1.076715111732483\n",
      "tensor([0., 1.]) tensor([0.7635, 0.2365], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 24 - 350: dog - cat || Loss: 1.0761568546295166\n",
      "tensor([0., 1.]) tensor([0.7629, 0.2371], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 24 - 351: dog - cat || Loss: 1.0755976438522339\n",
      "tensor([0., 1.]) tensor([0.7623, 0.2377], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 24 - 352: dog - cat || Loss: 1.0750374794006348\n",
      "tensor([0., 1.]) tensor([0.7618, 0.2382], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 24 - 353: dog - cat || Loss: 1.0744764804840088\n",
      "tensor([0., 1.]) tensor([0.7612, 0.2388], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 24 - 354: dog - cat || Loss: 1.0739144086837769\n",
      "tensor([0., 1.]) tensor([0.7607, 0.2393], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 24 - 355: dog - cat || Loss: 1.0733516216278076\n",
      "tensor([0., 1.]) tensor([0.7601, 0.2399], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 24 - 356: dog - cat || Loss: 1.0727880001068115\n",
      "tensor([0., 1.]) tensor([0.7595, 0.2405], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 24 - 357: dog - cat || Loss: 1.07222318649292\n",
      "tensor([0., 1.]) tensor([0.7590, 0.2410], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 24 - 358: dog - cat || Loss: 1.071657657623291\n",
      "tensor([0., 1.]) tensor([0.7584, 0.2416], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 24 - 359: dog - cat || Loss: 1.0710911750793457\n",
      "tensor([0., 1.]) tensor([0.7578, 0.2422], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 24 - 360: dog - cat || Loss: 1.0705238580703735\n",
      "tensor([0., 1.]) tensor([0.7573, 0.2427], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 24 - 361: dog - cat || Loss: 1.069955587387085\n",
      "tensor([0., 1.]) tensor([0.7567, 0.2433], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 24 - 362: dog - cat || Loss: 1.0693864822387695\n",
      "tensor([0., 1.]) tensor([0.7561, 0.2439], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 24 - 363: dog - cat || Loss: 1.0688165426254272\n",
      "tensor([0., 1.]) tensor([0.7556, 0.2444], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 24 - 364: dog - cat || Loss: 1.068245530128479\n",
      "tensor([0., 1.]) tensor([0.7550, 0.2450], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 24 - 365: dog - cat || Loss: 1.0676738023757935\n",
      "tensor([0., 1.]) tensor([0.7544, 0.2456], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 24 - 366: dog - cat || Loss: 1.0671011209487915\n",
      "tensor([0., 1.]) tensor([0.7538, 0.2462], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 24 - 367: dog - cat || Loss: 1.0665276050567627\n",
      "tensor([0., 1.]) tensor([0.7533, 0.2467], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 24 - 368: dog - cat || Loss: 1.065953016281128\n",
      "tensor([0., 1.]) tensor([0.7527, 0.2473], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 24 - 369: dog - cat || Loss: 1.0653775930404663\n",
      "tensor([0., 1.]) tensor([0.7521, 0.2479], grad_fn=<SoftmaxBackward0>)\n",
      "=====epoch:25=====\n",
      "Epoch 25 - 0: cat - cat || Loss: 0.561721920967102\n",
      "tensor([1., 0.]) tensor([0.7515, 0.2485], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 25 - 1: cat - cat || Loss: 0.5621828436851501\n",
      "tensor([1., 0.]) tensor([0.7511, 0.2489], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 25 - 2: cat - cat || Loss: 0.5625396966934204\n",
      "tensor([1., 0.]) tensor([0.7507, 0.2493], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 25 - 3: cat - cat || Loss: 0.5628026723861694\n",
      "tensor([1., 0.]) tensor([0.7505, 0.2495], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 25 - 4: cat - cat || Loss: 0.5629810094833374\n",
      "tensor([1., 0.]) tensor([0.7503, 0.2497], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 25 - 5: cat - cat || Loss: 0.5630834102630615\n",
      "tensor([1., 0.]) tensor([0.7502, 0.2498], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 25 - 6: cat - cat || Loss: 0.5631170868873596\n",
      "tensor([1., 0.]) tensor([0.7501, 0.2499], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 25 - 7: cat - cat || Loss: 0.5630890727043152\n",
      "tensor([1., 0.]) tensor([0.7502, 0.2498], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 25 - 8: cat - cat || Loss: 0.5630056262016296\n",
      "tensor([1., 0.]) tensor([0.7503, 0.2497], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 25 - 9: cat - cat || Loss: 0.5628722310066223\n",
      "tensor([1., 0.]) tensor([0.7504, 0.2496], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 25 - 10: cat - cat || Loss: 0.5626938343048096\n",
      "tensor([1., 0.]) tensor([0.7506, 0.2494], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 25 - 11: cat - cat || Loss: 0.5624753832817078\n",
      "tensor([1., 0.]) tensor([0.7508, 0.2492], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 25 - 12: cat - cat || Loss: 0.562220573425293\n",
      "tensor([1., 0.]) tensor([0.7510, 0.2490], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 25 - 13: cat - cat || Loss: 0.561933159828186\n",
      "tensor([1., 0.]) tensor([0.7513, 0.2487], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 25 - 14: cat - cat || Loss: 0.5616165399551392\n",
      "tensor([1., 0.]) tensor([0.7516, 0.2484], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 25 - 15: cat - cat || Loss: 0.5612735748291016\n",
      "tensor([1., 0.]) tensor([0.7520, 0.2480], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 25 - 16: cat - cat || Loss: 0.5609071254730225\n",
      "tensor([1., 0.]) tensor([0.7524, 0.2476], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 25 - 17: cat - cat || Loss: 0.5605195760726929\n",
      "tensor([1., 0.]) tensor([0.7527, 0.2473], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 25 - 18: cat - cat || Loss: 0.5601130723953247\n",
      "tensor([1., 0.]) tensor([0.7531, 0.2469], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 25 - 19: cat - cat || Loss: 0.5596895813941956\n",
      "tensor([1., 0.]) tensor([0.7536, 0.2464], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 25 - 20: cat - cat || Loss: 0.5592508912086487\n",
      "tensor([1., 0.]) tensor([0.7540, 0.2460], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 25 - 21: cat - cat || Loss: 0.5587986707687378\n",
      "tensor([1., 0.]) tensor([0.7545, 0.2455], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 25 - 22: cat - cat || Loss: 0.5583343505859375\n",
      "tensor([1., 0.]) tensor([0.7549, 0.2451], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 25 - 23: cat - cat || Loss: 0.5578593015670776\n",
      "tensor([1., 0.]) tensor([0.7554, 0.2446], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 25 - 24: cat - cat || Loss: 0.5573743581771851\n",
      "tensor([1., 0.]) tensor([0.7559, 0.2441], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 25 - 25: cat - cat || Loss: 0.5568809509277344\n",
      "tensor([1., 0.]) tensor([0.7564, 0.2436], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 25 - 26: cat - cat || Loss: 0.5563798546791077\n",
      "tensor([1., 0.]) tensor([0.7569, 0.2431], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 25 - 27: cat - cat || Loss: 0.5558722019195557\n",
      "tensor([1., 0.]) tensor([0.7574, 0.2426], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 25 - 28: cat - cat || Loss: 0.5553584098815918\n",
      "tensor([1., 0.]) tensor([0.7579, 0.2421], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 25 - 29: cat - cat || Loss: 0.5548392534255981\n",
      "tensor([1., 0.]) tensor([0.7584, 0.2416], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 25 - 30: cat - cat || Loss: 0.554315447807312\n",
      "tensor([1., 0.]) tensor([0.7589, 0.2411], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 25 - 31: cat - cat || Loss: 0.5537874698638916\n",
      "tensor([1., 0.]) tensor([0.7595, 0.2405], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 25 - 32: cat - cat || Loss: 0.5532559156417847\n",
      "tensor([1., 0.]) tensor([0.7600, 0.2400], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 25 - 33: cat - cat || Loss: 0.552721381187439\n",
      "tensor([1., 0.]) tensor([0.7605, 0.2395], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 25 - 34: cat - cat || Loss: 0.5521838665008545\n",
      "tensor([1., 0.]) tensor([0.7611, 0.2389], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 25 - 35: cat - cat || Loss: 0.551643967628479\n",
      "tensor([1., 0.]) tensor([0.7616, 0.2384], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 25 - 36: cat - cat || Loss: 0.5511020421981812\n",
      "tensor([1., 0.]) tensor([0.7622, 0.2378], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 25 - 37: cat - cat || Loss: 0.5505584478378296\n",
      "tensor([1., 0.]) tensor([0.7627, 0.2373], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 25 - 38: cat - cat || Loss: 0.5500130653381348\n",
      "tensor([1., 0.]) tensor([0.7632, 0.2368], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 25 - 39: cat - cat || Loss: 0.5494666695594788\n",
      "tensor([1., 0.]) tensor([0.7638, 0.2362], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 25 - 40: cat - cat || Loss: 0.5489193797111511\n",
      "tensor([1., 0.]) tensor([0.7643, 0.2357], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 25 - 41: cat - cat || Loss: 0.5483710169792175\n",
      "tensor([1., 0.]) tensor([0.7649, 0.2351], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 25 - 42: cat - cat || Loss: 0.547822117805481\n",
      "tensor([1., 0.]) tensor([0.7654, 0.2346], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 25 - 43: cat - cat || Loss: 0.5472726821899414\n",
      "tensor([1., 0.]) tensor([0.7660, 0.2340], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 25 - 44: cat - cat || Loss: 0.546722948551178\n",
      "tensor([1., 0.]) tensor([0.7665, 0.2335], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 25 - 45: cat - cat || Loss: 0.5461728572845459\n",
      "tensor([1., 0.]) tensor([0.7671, 0.2329], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 25 - 46: cat - cat || Loss: 0.545622706413269\n",
      "tensor([1., 0.]) tensor([0.7676, 0.2324], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 25 - 47: cat - cat || Loss: 0.5450724959373474\n",
      "tensor([1., 0.]) tensor([0.7682, 0.2318], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 25 - 48: cat - cat || Loss: 0.5445224642753601\n",
      "tensor([1., 0.]) tensor([0.7687, 0.2313], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 25 - 49: cat - cat || Loss: 0.5439724922180176\n",
      "tensor([1., 0.]) tensor([0.7693, 0.2307], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 25 - 50: cat - cat || Loss: 0.5434228777885437\n",
      "tensor([1., 0.]) tensor([0.7698, 0.2302], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 25 - 51: cat - cat || Loss: 0.5428735017776489\n",
      "tensor([1., 0.]) tensor([0.7704, 0.2296], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 25 - 52: cat - cat || Loss: 0.5423244833946228\n",
      "tensor([1., 0.]) tensor([0.7709, 0.2291], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 25 - 53: cat - cat || Loss: 0.5417760014533997\n",
      "tensor([1., 0.]) tensor([0.7715, 0.2285], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 25 - 54: cat - cat || Loss: 0.5412279367446899\n",
      "tensor([1., 0.]) tensor([0.7720, 0.2280], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 25 - 55: cat - cat || Loss: 0.5406804084777832\n",
      "tensor([1., 0.]) tensor([0.7726, 0.2274], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 25 - 56: cat - cat || Loss: 0.5401334762573242\n",
      "tensor([1., 0.]) tensor([0.7731, 0.2269], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 25 - 57: cat - cat || Loss: 0.5395870208740234\n",
      "tensor([1., 0.]) tensor([0.7737, 0.2263], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 25 - 58: cat - cat || Loss: 0.5390413999557495\n",
      "tensor([1., 0.]) tensor([0.7742, 0.2258], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 25 - 59: cat - cat || Loss: 0.5384963750839233\n",
      "tensor([1., 0.]) tensor([0.7748, 0.2252], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 25 - 60: cat - cat || Loss: 0.5379520654678345\n",
      "tensor([1., 0.]) tensor([0.7753, 0.2247], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 25 - 61: cat - cat || Loss: 0.5374083518981934\n",
      "tensor([1., 0.]) tensor([0.7759, 0.2241], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 25 - 62: cat - cat || Loss: 0.5368654727935791\n",
      "tensor([1., 0.]) tensor([0.7764, 0.2236], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 25 - 63: cat - cat || Loss: 0.5363234281539917\n",
      "tensor([1., 0.]) tensor([0.7769, 0.2231], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 25 - 64: cat - cat || Loss: 0.5357820987701416\n",
      "tensor([1., 0.]) tensor([0.7775, 0.2225], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 25 - 65: cat - cat || Loss: 0.5352415442466736\n",
      "tensor([1., 0.]) tensor([0.7780, 0.2220], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 25 - 66: cat - cat || Loss: 0.5347018241882324\n",
      "tensor([1., 0.]) tensor([0.7786, 0.2214], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 25 - 67: cat - cat || Loss: 0.5341629385948181\n",
      "tensor([1., 0.]) tensor([0.7791, 0.2209], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 25 - 68: cat - cat || Loss: 0.5336248874664307\n",
      "tensor([1., 0.]) tensor([0.7796, 0.2204], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 25 - 69: cat - cat || Loss: 0.5330876111984253\n",
      "tensor([1., 0.]) tensor([0.7802, 0.2198], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 25 - 70: cat - cat || Loss: 0.5325511693954468\n",
      "tensor([1., 0.]) tensor([0.7807, 0.2193], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 25 - 71: cat - cat || Loss: 0.5320158004760742\n",
      "tensor([1., 0.]) tensor([0.7812, 0.2188], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 25 - 72: cat - cat || Loss: 0.5314810872077942\n",
      "tensor([1., 0.]) tensor([0.7818, 0.2182], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 25 - 73: cat - cat || Loss: 0.5309472680091858\n",
      "tensor([1., 0.]) tensor([0.7823, 0.2177], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 25 - 74: cat - cat || Loss: 0.530414342880249\n",
      "tensor([1., 0.]) tensor([0.7828, 0.2172], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 25 - 75: cat - cat || Loss: 0.5298824310302734\n",
      "tensor([1., 0.]) tensor([0.7834, 0.2166], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 25 - 76: cat - cat || Loss: 0.5293513536453247\n",
      "tensor([1., 0.]) tensor([0.7839, 0.2161], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 25 - 77: cat - cat || Loss: 0.5288212299346924\n",
      "tensor([1., 0.]) tensor([0.7844, 0.2156], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 25 - 78: cat - cat || Loss: 0.5282919406890869\n",
      "tensor([1., 0.]) tensor([0.7850, 0.2150], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 25 - 79: cat - cat || Loss: 0.5277636647224426\n",
      "tensor([1., 0.]) tensor([0.7855, 0.2145], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 25 - 80: cat - cat || Loss: 0.5272362232208252\n",
      "tensor([1., 0.]) tensor([0.7860, 0.2140], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 25 - 81: cat - cat || Loss: 0.526709794998169\n",
      "tensor([1., 0.]) tensor([0.7866, 0.2134], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 25 - 82: cat - cat || Loss: 0.5261842012405396\n",
      "tensor([1., 0.]) tensor([0.7871, 0.2129], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 25 - 83: cat - cat || Loss: 0.5256595611572266\n",
      "tensor([1., 0.]) tensor([0.7876, 0.2124], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 25 - 84: cat - cat || Loss: 0.52513587474823\n",
      "tensor([1., 0.]) tensor([0.7881, 0.2119], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 25 - 85: cat - cat || Loss: 0.5246131420135498\n",
      "tensor([1., 0.]) tensor([0.7886, 0.2114], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 25 - 86: cat - cat || Loss: 0.524091362953186\n",
      "tensor([1., 0.]) tensor([0.7892, 0.2108], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 25 - 87: cat - cat || Loss: 0.5235704183578491\n",
      "tensor([1., 0.]) tensor([0.7897, 0.2103], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 25 - 88: cat - cat || Loss: 0.5230503082275391\n",
      "tensor([1., 0.]) tensor([0.7902, 0.2098], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 25 - 89: cat - cat || Loss: 0.5225313901901245\n",
      "tensor([1., 0.]) tensor([0.7907, 0.2093], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 25 - 90: cat - cat || Loss: 0.5220133066177368\n",
      "tensor([1., 0.]) tensor([0.7912, 0.2088], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 25 - 91: cat - cat || Loss: 0.521496057510376\n",
      "tensor([1., 0.]) tensor([0.7918, 0.2082], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 25 - 92: cat - cat || Loss: 0.5209799408912659\n",
      "tensor([1., 0.]) tensor([0.7923, 0.2077], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 25 - 93: cat - cat || Loss: 0.5204645991325378\n",
      "tensor([1., 0.]) tensor([0.7928, 0.2072], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 25 - 94: cat - cat || Loss: 0.519950270652771\n",
      "tensor([1., 0.]) tensor([0.7933, 0.2067], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 25 - 95: cat - cat || Loss: 0.5194368362426758\n",
      "tensor([1., 0.]) tensor([0.7938, 0.2062], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 25 - 96: cat - cat || Loss: 0.5189244151115417\n",
      "tensor([1., 0.]) tensor([0.7943, 0.2057], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 25 - 97: cat - cat || Loss: 0.5184130072593689\n",
      "tensor([1., 0.]) tensor([0.7948, 0.2052], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 25 - 98: cat - cat || Loss: 0.5179024934768677\n",
      "tensor([1., 0.]) tensor([0.7954, 0.2046], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 25 - 99: cat - cat || Loss: 0.5173929333686829\n",
      "tensor([1., 0.]) tensor([0.7959, 0.2041], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 25 - 100: cat - cat || Loss: 0.5168842673301697\n",
      "tensor([1., 0.]) tensor([0.7964, 0.2036], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 25 - 101: cat - cat || Loss: 0.5163766145706177\n",
      "tensor([1., 0.]) tensor([0.7969, 0.2031], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 25 - 102: cat - cat || Loss: 0.5158699750900269\n",
      "tensor([1., 0.]) tensor([0.7974, 0.2026], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 25 - 103: cat - cat || Loss: 0.5153641104698181\n",
      "tensor([1., 0.]) tensor([0.7979, 0.2021], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 25 - 104: cat - cat || Loss: 0.5148593187332153\n",
      "tensor([1., 0.]) tensor([0.7984, 0.2016], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 25 - 105: cat - cat || Loss: 0.5143555402755737\n",
      "tensor([1., 0.]) tensor([0.7989, 0.2011], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 25 - 106: cat - cat || Loss: 0.5138526558876038\n",
      "tensor([1., 0.]) tensor([0.7994, 0.2006], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 25 - 107: cat - cat || Loss: 0.5133506059646606\n",
      "tensor([1., 0.]) tensor([0.7999, 0.2001], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 25 - 108: cat - cat || Loss: 0.5128496885299683\n",
      "tensor([1., 0.]) tensor([0.8004, 0.1996], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 25 - 109: cat - cat || Loss: 0.5123496055603027\n",
      "tensor([1., 0.]) tensor([0.8009, 0.1991], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 25 - 110: cat - cat || Loss: 0.5118504762649536\n",
      "tensor([1., 0.]) tensor([0.8014, 0.1986], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 25 - 111: cat - cat || Loss: 0.5113523006439209\n",
      "tensor([1., 0.]) tensor([0.8019, 0.1981], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 25 - 112: cat - cat || Loss: 0.5108550786972046\n",
      "tensor([1., 0.]) tensor([0.8024, 0.1976], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 25 - 113: cat - cat || Loss: 0.5103589296340942\n",
      "tensor([1., 0.]) tensor([0.8029, 0.1971], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 25 - 114: cat - cat || Loss: 0.5098634958267212\n",
      "tensor([1., 0.]) tensor([0.8034, 0.1966], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 25 - 115: cat - cat || Loss: 0.5093691349029541\n",
      "tensor([1., 0.]) tensor([0.8039, 0.1961], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 25 - 116: cat - cat || Loss: 0.5088757872581482\n",
      "tensor([1., 0.]) tensor([0.8044, 0.1956], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 25 - 117: cat - cat || Loss: 0.5083833932876587\n",
      "tensor([1., 0.]) tensor([0.8049, 0.1951], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 25 - 118: cat - cat || Loss: 0.5078918933868408\n",
      "tensor([1., 0.]) tensor([0.8054, 0.1946], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 25 - 119: cat - cat || Loss: 0.5074014067649841\n",
      "tensor([1., 0.]) tensor([0.8059, 0.1941], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 25 - 120: cat - cat || Loss: 0.5069118738174438\n",
      "tensor([1., 0.]) tensor([0.8063, 0.1937], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 25 - 121: cat - cat || Loss: 0.5064231753349304\n",
      "tensor([1., 0.]) tensor([0.8068, 0.1932], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 25 - 122: cat - cat || Loss: 0.5059356093406677\n",
      "tensor([1., 0.]) tensor([0.8073, 0.1927], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 25 - 123: cat - cat || Loss: 0.5054489374160767\n",
      "tensor([1., 0.]) tensor([0.8078, 0.1922], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 25 - 124: cat - cat || Loss: 0.5049631595611572\n",
      "tensor([1., 0.]) tensor([0.8083, 0.1917], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 25 - 125: cat - cat || Loss: 0.5044784545898438\n",
      "tensor([1., 0.]) tensor([0.8088, 0.1912], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 25 - 126: cat - cat || Loss: 0.5039944648742676\n",
      "tensor([1., 0.]) tensor([0.8093, 0.1907], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 25 - 127: cat - cat || Loss: 0.5035115480422974\n",
      "tensor([1., 0.]) tensor([0.8098, 0.1902], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 25 - 128: cat - cat || Loss: 0.5030296444892883\n",
      "tensor([1., 0.]) tensor([0.8102, 0.1898], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 25 - 129: cat - cat || Loss: 0.5025486946105957\n",
      "tensor([1., 0.]) tensor([0.8107, 0.1893], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 25 - 130: cat - cat || Loss: 0.5020686388015747\n",
      "tensor([1., 0.]) tensor([0.8112, 0.1888], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 25 - 131: cat - cat || Loss: 0.5015895366668701\n",
      "tensor([1., 0.]) tensor([0.8117, 0.1883], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 25 - 132: cat - cat || Loss: 0.5011112689971924\n",
      "tensor([1., 0.]) tensor([0.8122, 0.1878], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 25 - 133: cat - cat || Loss: 0.5006341934204102\n",
      "tensor([1., 0.]) tensor([0.8126, 0.1874], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 25 - 134: cat - cat || Loss: 0.5001579523086548\n",
      "tensor([1., 0.]) tensor([0.8131, 0.1869], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 25 - 135: cat - cat || Loss: 0.4996827244758606\n",
      "tensor([1., 0.]) tensor([0.8136, 0.1864], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 25 - 136: cat - cat || Loss: 0.49920839071273804\n",
      "tensor([1., 0.]) tensor([0.8141, 0.1859], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 25 - 137: cat - cat || Loss: 0.49873489141464233\n",
      "tensor([1., 0.]) tensor([0.8145, 0.1855], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 25 - 138: cat - cat || Loss: 0.4982624650001526\n",
      "tensor([1., 0.]) tensor([0.8150, 0.1850], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 25 - 139: cat - cat || Loss: 0.49779096245765686\n",
      "tensor([1., 0.]) tensor([0.8155, 0.1845], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 25 - 140: cat - cat || Loss: 0.4973204731941223\n",
      "tensor([1., 0.]) tensor([0.8159, 0.1841], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 25 - 141: cat - cat || Loss: 0.4968509078025818\n",
      "tensor([1., 0.]) tensor([0.8164, 0.1836], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 25 - 142: cat - cat || Loss: 0.4963822364807129\n",
      "tensor([1., 0.]) tensor([0.8169, 0.1831], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 25 - 143: cat - cat || Loss: 0.4959144592285156\n",
      "tensor([1., 0.]) tensor([0.8173, 0.1827], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 25 - 144: cat - cat || Loss: 0.4954477846622467\n",
      "tensor([1., 0.]) tensor([0.8178, 0.1822], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 25 - 145: cat - cat || Loss: 0.49498194456100464\n",
      "tensor([1., 0.]) tensor([0.8183, 0.1817], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 25 - 146: cat - cat || Loss: 0.49451711773872375\n",
      "tensor([1., 0.]) tensor([0.8187, 0.1813], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 25 - 147: cat - cat || Loss: 0.4940532147884369\n",
      "tensor([1., 0.]) tensor([0.8192, 0.1808], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 25 - 148: cat - cat || Loss: 0.4935901463031769\n",
      "tensor([1., 0.]) tensor([0.8197, 0.1803], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 25 - 149: cat - cat || Loss: 0.4931281805038452\n",
      "tensor([1., 0.]) tensor([0.8201, 0.1799], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 25 - 150: cat - cat || Loss: 0.49266698956489563\n",
      "tensor([1., 0.]) tensor([0.8206, 0.1794], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 25 - 151: cat - cat || Loss: 0.4922069013118744\n",
      "tensor([1., 0.]) tensor([0.8211, 0.1789], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 25 - 152: cat - cat || Loss: 0.4917476773262024\n",
      "tensor([1., 0.]) tensor([0.8215, 0.1785], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 25 - 153: cat - cat || Loss: 0.4912893772125244\n",
      "tensor([1., 0.]) tensor([0.8220, 0.1780], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 25 - 154: cat - cat || Loss: 0.49083206057548523\n",
      "tensor([1., 0.]) tensor([0.8224, 0.1776], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 25 - 155: cat - cat || Loss: 0.4903756380081177\n",
      "tensor([1., 0.]) tensor([0.8229, 0.1771], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 25 - 156: cat - cat || Loss: 0.4899201989173889\n",
      "tensor([1., 0.]) tensor([0.8233, 0.1767], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 25 - 157: cat - cat || Loss: 0.48946577310562134\n",
      "tensor([1., 0.]) tensor([0.8238, 0.1762], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 25 - 158: cat - cat || Loss: 0.4890121817588806\n",
      "tensor([1., 0.]) tensor([0.8242, 0.1758], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 25 - 159: cat - cat || Loss: 0.4885594844818115\n",
      "tensor([1., 0.]) tensor([0.8247, 0.1753], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 25 - 160: cat - cat || Loss: 0.4881078004837036\n",
      "tensor([1., 0.]) tensor([0.8252, 0.1748], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 25 - 161: cat - cat || Loss: 0.48765701055526733\n",
      "tensor([1., 0.]) tensor([0.8256, 0.1744], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 25 - 162: cat - cat || Loss: 0.4872073531150818\n",
      "tensor([1., 0.]) tensor([0.8261, 0.1739], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 25 - 163: cat - cat || Loss: 0.48675841093063354\n",
      "tensor([1., 0.]) tensor([0.8265, 0.1735], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 25 - 164: cat - cat || Loss: 0.48631051182746887\n",
      "tensor([1., 0.]) tensor([0.8270, 0.1730], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 25 - 165: cat - cat || Loss: 0.48586350679397583\n",
      "tensor([1., 0.]) tensor([0.8274, 0.1726], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 25 - 166: cat - cat || Loss: 0.4854174256324768\n",
      "tensor([1., 0.]) tensor([0.8278, 0.1722], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 25 - 167: cat - cat || Loss: 0.4849722981452942\n",
      "tensor([1., 0.]) tensor([0.8283, 0.1717], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 25 - 168: cat - cat || Loss: 0.484528124332428\n",
      "tensor([1., 0.]) tensor([0.8287, 0.1713], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 25 - 169: cat - cat || Loss: 0.4840848743915558\n",
      "tensor([1., 0.]) tensor([0.8292, 0.1708], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 25 - 170: cat - cat || Loss: 0.4836425483226776\n",
      "tensor([1., 0.]) tensor([0.8296, 0.1704], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 25 - 171: cat - cat || Loss: 0.48320120573043823\n",
      "tensor([1., 0.]) tensor([0.8301, 0.1699], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 25 - 172: cat - cat || Loss: 0.48276078701019287\n",
      "tensor([1., 0.]) tensor([0.8305, 0.1695], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 25 - 173: cat - cat || Loss: 0.48232126235961914\n",
      "tensor([1., 0.]) tensor([0.8309, 0.1691], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 25 - 174: cat - cat || Loss: 0.4818826913833618\n",
      "tensor([1., 0.]) tensor([0.8314, 0.1686], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 25 - 175: cat - cat || Loss: 0.4814450144767761\n",
      "tensor([1., 0.]) tensor([0.8318, 0.1682], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 25 - 176: cat - cat || Loss: 0.481008380651474\n",
      "tensor([1., 0.]) tensor([0.8323, 0.1677], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 25 - 177: cat - cat || Loss: 0.4805726706981659\n",
      "tensor([1., 0.]) tensor([0.8327, 0.1673], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 25 - 178: cat - cat || Loss: 0.48013776540756226\n",
      "tensor([1., 0.]) tensor([0.8331, 0.1669], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 25 - 179: cat - cat || Loss: 0.4797038733959198\n",
      "tensor([1., 0.]) tensor([0.8336, 0.1664], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 25 - 180: cat - cat || Loss: 0.47927096486091614\n",
      "tensor([1., 0.]) tensor([0.8340, 0.1660], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 25 - 181: cat - cat || Loss: 0.4788389205932617\n",
      "tensor([1., 0.]) tensor([0.8344, 0.1656], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 25 - 182: cat - cat || Loss: 0.4784078598022461\n",
      "tensor([1., 0.]) tensor([0.8349, 0.1651], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 25 - 183: cat - cat || Loss: 0.4779777526855469\n",
      "tensor([1., 0.]) tensor([0.8353, 0.1647], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 25 - 184: cat - cat || Loss: 0.4775484800338745\n",
      "tensor([1., 0.]) tensor([0.8357, 0.1643], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 25 - 185: cat - cat || Loss: 0.4771202802658081\n",
      "tensor([1., 0.]) tensor([0.8361, 0.1639], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 25 - 186: cat - cat || Loss: 0.4766928553581238\n",
      "tensor([1., 0.]) tensor([0.8366, 0.1634], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 25 - 187: cat - cat || Loss: 0.47626644372940063\n",
      "tensor([1., 0.]) tensor([0.8370, 0.1630], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 25 - 188: cat - cat || Loss: 0.47584104537963867\n",
      "tensor([1., 0.]) tensor([0.8374, 0.1626], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 25 - 189: cat - cat || Loss: 0.47541648149490356\n",
      "tensor([1., 0.]) tensor([0.8378, 0.1622], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 25 - 190: dog - cat || Loss: 1.1515305042266846\n",
      "tensor([0., 1.]) tensor([0.8383, 0.1617], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 25 - 191: dog - cat || Loss: 1.1518694162368774\n",
      "tensor([0., 1.]) tensor([0.8386, 0.1614], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 25 - 192: dog - cat || Loss: 1.1521323919296265\n",
      "tensor([0., 1.]) tensor([0.8389, 0.1611], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 25 - 193: dog - cat || Loss: 1.1523271799087524\n",
      "tensor([0., 1.]) tensor([0.8391, 0.1609], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 25 - 194: dog - cat || Loss: 1.1524606943130493\n",
      "tensor([0., 1.]) tensor([0.8392, 0.1608], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 25 - 195: dog - cat || Loss: 1.1525391340255737\n",
      "tensor([0., 1.]) tensor([0.8393, 0.1607], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 25 - 196: dog - cat || Loss: 1.1525681018829346\n",
      "tensor([0., 1.]) tensor([0.8393, 0.1607], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 25 - 197: dog - cat || Loss: 1.1525523662567139\n",
      "tensor([0., 1.]) tensor([0.8393, 0.1607], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 25 - 198: dog - cat || Loss: 1.1524966955184937\n",
      "tensor([0., 1.]) tensor([0.8392, 0.1608], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 25 - 199: dog - cat || Loss: 1.15240478515625\n",
      "tensor([0., 1.]) tensor([0.8391, 0.1609], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 25 - 200: dog - cat || Loss: 1.152280330657959\n",
      "tensor([0., 1.]) tensor([0.8390, 0.1610], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 25 - 201: dog - cat || Loss: 1.152126431465149\n",
      "tensor([0., 1.]) tensor([0.8389, 0.1611], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 25 - 202: dog - cat || Loss: 1.1519461870193481\n",
      "tensor([0., 1.]) tensor([0.8387, 0.1613], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 25 - 203: dog - cat || Loss: 1.1517421007156372\n",
      "tensor([0., 1.]) tensor([0.8385, 0.1615], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 25 - 204: dog - cat || Loss: 1.1515164375305176\n",
      "tensor([0., 1.]) tensor([0.8383, 0.1617], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 25 - 205: dog - cat || Loss: 1.1512713432312012\n",
      "tensor([0., 1.]) tensor([0.8380, 0.1620], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 25 - 206: dog - cat || Loss: 1.1510084867477417\n",
      "tensor([0., 1.]) tensor([0.8377, 0.1623], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 25 - 207: dog - cat || Loss: 1.150730013847351\n",
      "tensor([0., 1.]) tensor([0.8375, 0.1625], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 25 - 208: dog - cat || Loss: 1.1504371166229248\n",
      "tensor([0., 1.]) tensor([0.8372, 0.1628], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 25 - 209: dog - cat || Loss: 1.150131106376648\n",
      "tensor([0., 1.]) tensor([0.8369, 0.1631], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 25 - 210: dog - cat || Loss: 1.1498132944107056\n",
      "tensor([0., 1.]) tensor([0.8366, 0.1634], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 25 - 211: dog - cat || Loss: 1.1494848728179932\n",
      "tensor([0., 1.]) tensor([0.8362, 0.1638], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 25 - 212: dog - cat || Loss: 1.149146556854248\n",
      "tensor([0., 1.]) tensor([0.8359, 0.1641], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 25 - 213: dog - cat || Loss: 1.1487994194030762\n",
      "tensor([0., 1.]) tensor([0.8355, 0.1645], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 25 - 214: dog - cat || Loss: 1.148444414138794\n",
      "tensor([0., 1.]) tensor([0.8352, 0.1648], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 25 - 215: dog - cat || Loss: 1.1480820178985596\n",
      "tensor([0., 1.]) tensor([0.8348, 0.1652], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 25 - 216: dog - cat || Loss: 1.1477128267288208\n",
      "tensor([0., 1.]) tensor([0.8345, 0.1655], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 25 - 217: dog - cat || Loss: 1.147337555885315\n",
      "tensor([0., 1.]) tensor([0.8341, 0.1659], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 25 - 218: dog - cat || Loss: 1.1469569206237793\n",
      "tensor([0., 1.]) tensor([0.8337, 0.1663], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 25 - 219: dog - cat || Loss: 1.1465709209442139\n",
      "tensor([0., 1.]) tensor([0.8333, 0.1667], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 25 - 220: dog - cat || Loss: 1.1461803913116455\n",
      "tensor([0., 1.]) tensor([0.8329, 0.1671], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 25 - 221: dog - cat || Loss: 1.1457855701446533\n",
      "tensor([0., 1.]) tensor([0.8325, 0.1675], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 25 - 222: dog - cat || Loss: 1.1453866958618164\n",
      "tensor([0., 1.]) tensor([0.8321, 0.1679], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 25 - 223: dog - cat || Loss: 1.144984245300293\n",
      "tensor([0., 1.]) tensor([0.8317, 0.1683], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 25 - 224: dog - cat || Loss: 1.144578218460083\n",
      "tensor([0., 1.]) tensor([0.8313, 0.1687], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 25 - 225: dog - cat || Loss: 1.1441693305969238\n",
      "tensor([0., 1.]) tensor([0.8309, 0.1691], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 25 - 226: dog - cat || Loss: 1.1437573432922363\n",
      "tensor([0., 1.]) tensor([0.8305, 0.1695], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 25 - 227: dog - cat || Loss: 1.1433427333831787\n",
      "tensor([0., 1.]) tensor([0.8301, 0.1699], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 25 - 228: dog - cat || Loss: 1.1429256200790405\n",
      "tensor([0., 1.]) tensor([0.8297, 0.1703], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 25 - 229: dog - cat || Loss: 1.1425061225891113\n",
      "tensor([0., 1.]) tensor([0.8292, 0.1708], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 25 - 230: dog - cat || Loss: 1.1420843601226807\n",
      "tensor([0., 1.]) tensor([0.8288, 0.1712], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 25 - 231: dog - cat || Loss: 1.141660451889038\n",
      "tensor([0., 1.]) tensor([0.8284, 0.1716], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 25 - 232: dog - cat || Loss: 1.1412345170974731\n",
      "tensor([0., 1.]) tensor([0.8280, 0.1720], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 25 - 233: dog - cat || Loss: 1.140807032585144\n",
      "tensor([0., 1.]) tensor([0.8275, 0.1725], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 25 - 234: dog - cat || Loss: 1.1403777599334717\n",
      "tensor([0., 1.]) tensor([0.8271, 0.1729], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 25 - 235: dog - cat || Loss: 1.139946699142456\n",
      "tensor([0., 1.]) tensor([0.8267, 0.1733], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 25 - 236: dog - cat || Loss: 1.1395139694213867\n",
      "tensor([0., 1.]) tensor([0.8263, 0.1737], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 25 - 237: dog - cat || Loss: 1.1390798091888428\n",
      "tensor([0., 1.]) tensor([0.8258, 0.1742], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 25 - 238: dog - cat || Loss: 1.1386442184448242\n",
      "tensor([0., 1.]) tensor([0.8254, 0.1746], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 25 - 239: dog - cat || Loss: 1.1382070779800415\n",
      "tensor([0., 1.]) tensor([0.8249, 0.1751], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 25 - 240: dog - cat || Loss: 1.1377686262130737\n",
      "tensor([0., 1.]) tensor([0.8245, 0.1755], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 25 - 241: dog - cat || Loss: 1.1373287439346313\n",
      "tensor([0., 1.]) tensor([0.8241, 0.1759], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 25 - 242: dog - cat || Loss: 1.136887788772583\n",
      "tensor([0., 1.]) tensor([0.8236, 0.1764], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 25 - 243: dog - cat || Loss: 1.1364456415176392\n",
      "tensor([0., 1.]) tensor([0.8232, 0.1768], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 25 - 244: dog - cat || Loss: 1.1360020637512207\n",
      "tensor([0., 1.]) tensor([0.8227, 0.1773], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 25 - 245: dog - cat || Loss: 1.1355576515197754\n",
      "tensor([0., 1.]) tensor([0.8223, 0.1777], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 25 - 246: dog - cat || Loss: 1.135111689567566\n",
      "tensor([0., 1.]) tensor([0.8219, 0.1781], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 25 - 247: dog - cat || Loss: 1.1346648931503296\n",
      "tensor([0., 1.]) tensor([0.8214, 0.1786], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 25 - 248: dog - cat || Loss: 1.1342169046401978\n",
      "tensor([0., 1.]) tensor([0.8210, 0.1790], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 25 - 249: dog - cat || Loss: 1.1337677240371704\n",
      "tensor([0., 1.]) tensor([0.8205, 0.1795], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 25 - 250: dog - cat || Loss: 1.1333175897598267\n",
      "tensor([0., 1.]) tensor([0.8201, 0.1799], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 25 - 251: dog - cat || Loss: 1.1328665018081665\n",
      "tensor([0., 1.]) tensor([0.8196, 0.1804], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 25 - 252: dog - cat || Loss: 1.1324143409729004\n",
      "tensor([0., 1.]) tensor([0.8192, 0.1808], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 25 - 253: dog - cat || Loss: 1.1319609880447388\n",
      "tensor([0., 1.]) tensor([0.8187, 0.1813], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 25 - 254: dog - cat || Loss: 1.1315068006515503\n",
      "tensor([0., 1.]) tensor([0.8182, 0.1818], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 25 - 255: dog - cat || Loss: 1.1310514211654663\n",
      "tensor([0., 1.]) tensor([0.8178, 0.1822], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 25 - 256: dog - cat || Loss: 1.130595088005066\n",
      "tensor([0., 1.]) tensor([0.8173, 0.1827], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 25 - 257: dog - cat || Loss: 1.1301380395889282\n",
      "tensor([0., 1.]) tensor([0.8169, 0.1831], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 25 - 258: dog - cat || Loss: 1.1296799182891846\n",
      "tensor([0., 1.]) tensor([0.8164, 0.1836], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 25 - 259: dog - cat || Loss: 1.1292206048965454\n",
      "tensor([0., 1.]) tensor([0.8160, 0.1840], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 25 - 260: dog - cat || Loss: 1.1287604570388794\n",
      "tensor([0., 1.]) tensor([0.8155, 0.1845], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 25 - 261: dog - cat || Loss: 1.128299593925476\n",
      "tensor([0., 1.]) tensor([0.8150, 0.1850], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 25 - 262: dog - cat || Loss: 1.1278375387191772\n",
      "tensor([0., 1.]) tensor([0.8146, 0.1854], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 25 - 263: dog - cat || Loss: 1.127374529838562\n",
      "tensor([0., 1.]) tensor([0.8141, 0.1859], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 25 - 264: dog - cat || Loss: 1.12691068649292\n",
      "tensor([0., 1.]) tensor([0.8136, 0.1864], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 25 - 265: dog - cat || Loss: 1.1264456510543823\n",
      "tensor([0., 1.]) tensor([0.8132, 0.1868], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 25 - 266: dog - cat || Loss: 1.1259799003601074\n",
      "tensor([0., 1.]) tensor([0.8127, 0.1873], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 25 - 267: dog - cat || Loss: 1.1255134344100952\n",
      "tensor([0., 1.]) tensor([0.8123, 0.1877], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 25 - 268: dog - cat || Loss: 1.125045657157898\n",
      "tensor([0., 1.]) tensor([0.8118, 0.1882], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 25 - 269: dog - cat || Loss: 1.1245770454406738\n",
      "tensor([0., 1.]) tensor([0.8113, 0.1887], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 25 - 270: dog - cat || Loss: 1.1241074800491333\n",
      "tensor([0., 1.]) tensor([0.8108, 0.1892], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 25 - 271: dog - cat || Loss: 1.1236371994018555\n",
      "tensor([0., 1.]) tensor([0.8104, 0.1896], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 25 - 272: dog - cat || Loss: 1.1231658458709717\n",
      "tensor([0., 1.]) tensor([0.8099, 0.1901], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 25 - 273: dog - cat || Loss: 1.122693419456482\n",
      "tensor([0., 1.]) tensor([0.8094, 0.1906], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 25 - 274: dog - cat || Loss: 1.1222203969955444\n",
      "tensor([0., 1.]) tensor([0.8090, 0.1910], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 25 - 275: dog - cat || Loss: 1.1217461824417114\n",
      "tensor([0., 1.]) tensor([0.8085, 0.1915], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 25 - 276: dog - cat || Loss: 1.1212711334228516\n",
      "tensor([0., 1.]) tensor([0.8080, 0.1920], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 25 - 277: dog - cat || Loss: 1.1207952499389648\n",
      "tensor([0., 1.]) tensor([0.8075, 0.1925], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 25 - 278: dog - cat || Loss: 1.1203184127807617\n",
      "tensor([0., 1.]) tensor([0.8071, 0.1929], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 25 - 279: dog - cat || Loss: 1.1198406219482422\n",
      "tensor([0., 1.]) tensor([0.8066, 0.1934], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 25 - 280: dog - cat || Loss: 1.1193618774414062\n",
      "tensor([0., 1.]) tensor([0.8061, 0.1939], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 25 - 281: dog - cat || Loss: 1.118882417678833\n",
      "tensor([0., 1.]) tensor([0.8056, 0.1944], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 25 - 282: dog - cat || Loss: 1.1184018850326538\n",
      "tensor([0., 1.]) tensor([0.8051, 0.1949], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 25 - 283: dog - cat || Loss: 1.1179203987121582\n",
      "tensor([0., 1.]) tensor([0.8047, 0.1953], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 25 - 284: dog - cat || Loss: 1.1174379587173462\n",
      "tensor([0., 1.]) tensor([0.8042, 0.1958], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 25 - 285: dog - cat || Loss: 1.1169548034667969\n",
      "tensor([0., 1.]) tensor([0.8037, 0.1963], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 25 - 286: dog - cat || Loss: 1.1164705753326416\n",
      "tensor([0., 1.]) tensor([0.8032, 0.1968], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 25 - 287: dog - cat || Loss: 1.11598539352417\n",
      "tensor([0., 1.]) tensor([0.8027, 0.1973], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 25 - 288: dog - cat || Loss: 1.115499496459961\n",
      "tensor([0., 1.]) tensor([0.8022, 0.1978], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 25 - 289: dog - cat || Loss: 1.115012526512146\n",
      "tensor([0., 1.]) tensor([0.8018, 0.1982], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 25 - 290: dog - cat || Loss: 1.1145248413085938\n",
      "tensor([0., 1.]) tensor([0.8013, 0.1987], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 25 - 291: dog - cat || Loss: 1.1140360832214355\n",
      "tensor([0., 1.]) tensor([0.8008, 0.1992], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 25 - 292: dog - cat || Loss: 1.1135462522506714\n",
      "tensor([0., 1.]) tensor([0.8003, 0.1997], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 25 - 293: dog - cat || Loss: 1.11305570602417\n",
      "tensor([0., 1.]) tensor([0.7998, 0.2002], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 25 - 294: dog - cat || Loss: 1.112564206123352\n",
      "tensor([0., 1.]) tensor([0.7993, 0.2007], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 25 - 295: dog - cat || Loss: 1.1120717525482178\n",
      "tensor([0., 1.]) tensor([0.7988, 0.2012], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 25 - 296: dog - cat || Loss: 1.1115784645080566\n",
      "tensor([0., 1.]) tensor([0.7983, 0.2017], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 25 - 297: dog - cat || Loss: 1.1110843420028687\n",
      "tensor([0., 1.]) tensor([0.7978, 0.2022], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 25 - 298: dog - cat || Loss: 1.1105891466140747\n",
      "tensor([0., 1.]) tensor([0.7973, 0.2027], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 25 - 299: dog - cat || Loss: 1.1100932359695435\n",
      "tensor([0., 1.]) tensor([0.7968, 0.2032], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 25 - 300: dog - cat || Loss: 1.1095962524414062\n",
      "tensor([0., 1.]) tensor([0.7963, 0.2037], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 25 - 301: dog - cat || Loss: 1.1090983152389526\n",
      "tensor([0., 1.]) tensor([0.7958, 0.2042], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 25 - 302: dog - cat || Loss: 1.1085995435714722\n",
      "tensor([0., 1.]) tensor([0.7953, 0.2047], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 25 - 303: dog - cat || Loss: 1.1080998182296753\n",
      "tensor([0., 1.]) tensor([0.7948, 0.2052], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 25 - 304: dog - cat || Loss: 1.1075992584228516\n",
      "tensor([0., 1.]) tensor([0.7943, 0.2057], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 25 - 305: dog - cat || Loss: 1.1070976257324219\n",
      "tensor([0., 1.]) tensor([0.7938, 0.2062], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 25 - 306: dog - cat || Loss: 1.1065952777862549\n",
      "tensor([0., 1.]) tensor([0.7933, 0.2067], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 25 - 307: dog - cat || Loss: 1.1060919761657715\n",
      "tensor([0., 1.]) tensor([0.7928, 0.2072], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 25 - 308: dog - cat || Loss: 1.1055876016616821\n",
      "tensor([0., 1.]) tensor([0.7923, 0.2077], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 25 - 309: dog - cat || Loss: 1.105082392692566\n",
      "tensor([0., 1.]) tensor([0.7918, 0.2082], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 25 - 310: dog - cat || Loss: 1.1045762300491333\n",
      "tensor([0., 1.]) tensor([0.7913, 0.2087], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 25 - 311: dog - cat || Loss: 1.1040693521499634\n",
      "tensor([0., 1.]) tensor([0.7908, 0.2092], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 25 - 312: dog - cat || Loss: 1.103561282157898\n",
      "tensor([0., 1.]) tensor([0.7903, 0.2097], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 25 - 313: dog - cat || Loss: 1.1030526161193848\n",
      "tensor([0., 1.]) tensor([0.7898, 0.2102], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 25 - 314: dog - cat || Loss: 1.102542757987976\n",
      "tensor([0., 1.]) tensor([0.7893, 0.2107], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 25 - 315: dog - cat || Loss: 1.10203218460083\n",
      "tensor([0., 1.]) tensor([0.7888, 0.2112], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 25 - 316: dog - cat || Loss: 1.1015205383300781\n",
      "tensor([0., 1.]) tensor([0.7883, 0.2117], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 25 - 317: dog - cat || Loss: 1.1010082960128784\n",
      "tensor([0., 1.]) tensor([0.7877, 0.2123], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 25 - 318: dog - cat || Loss: 1.1004948616027832\n",
      "tensor([0., 1.]) tensor([0.7872, 0.2128], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 25 - 319: dog - cat || Loss: 1.0999805927276611\n",
      "tensor([0., 1.]) tensor([0.7867, 0.2133], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 25 - 320: dog - cat || Loss: 1.0994654893875122\n",
      "tensor([0., 1.]) tensor([0.7862, 0.2138], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 25 - 321: dog - cat || Loss: 1.0989493131637573\n",
      "tensor([0., 1.]) tensor([0.7857, 0.2143], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 25 - 322: dog - cat || Loss: 1.0984323024749756\n",
      "tensor([0., 1.]) tensor([0.7852, 0.2148], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 25 - 323: dog - cat || Loss: 1.097914218902588\n",
      "tensor([0., 1.]) tensor([0.7847, 0.2153], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 25 - 324: dog - cat || Loss: 1.097395420074463\n",
      "tensor([0., 1.]) tensor([0.7841, 0.2159], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 25 - 325: dog - cat || Loss: 1.096875548362732\n",
      "tensor([0., 1.]) tensor([0.7836, 0.2164], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 25 - 326: dog - cat || Loss: 1.0963549613952637\n",
      "tensor([0., 1.]) tensor([0.7831, 0.2169], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 25 - 327: dog - cat || Loss: 1.0958333015441895\n",
      "tensor([0., 1.]) tensor([0.7826, 0.2174], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 25 - 328: dog - cat || Loss: 1.0953108072280884\n",
      "tensor([0., 1.]) tensor([0.7820, 0.2180], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 25 - 329: dog - cat || Loss: 1.0947874784469604\n",
      "tensor([0., 1.]) tensor([0.7815, 0.2185], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 25 - 330: dog - cat || Loss: 1.0942631959915161\n",
      "tensor([0., 1.]) tensor([0.7810, 0.2190], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 25 - 331: dog - cat || Loss: 1.093738079071045\n",
      "tensor([0., 1.]) tensor([0.7805, 0.2195], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 25 - 332: dog - cat || Loss: 1.0932120084762573\n",
      "tensor([0., 1.]) tensor([0.7800, 0.2200], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 25 - 333: dog - cat || Loss: 1.0926849842071533\n",
      "tensor([0., 1.]) tensor([0.7794, 0.2206], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 25 - 334: dog - cat || Loss: 1.092157006263733\n",
      "tensor([0., 1.]) tensor([0.7789, 0.2211], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 25 - 335: dog - cat || Loss: 1.0916281938552856\n",
      "tensor([0., 1.]) tensor([0.7784, 0.2216], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 25 - 336: dog - cat || Loss: 1.0910985469818115\n",
      "tensor([0., 1.]) tensor([0.7778, 0.2222], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 25 - 337: dog - cat || Loss: 1.0905678272247314\n",
      "tensor([0., 1.]) tensor([0.7773, 0.2227], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 25 - 338: dog - cat || Loss: 1.090036392211914\n",
      "tensor([0., 1.]) tensor([0.7768, 0.2232], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 25 - 339: dog - cat || Loss: 1.0895038843154907\n",
      "tensor([0., 1.]) tensor([0.7762, 0.2238], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 25 - 340: dog - cat || Loss: 1.088970422744751\n",
      "tensor([0., 1.]) tensor([0.7757, 0.2243], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 25 - 341: dog - cat || Loss: 1.088436245918274\n",
      "tensor([0., 1.]) tensor([0.7752, 0.2248], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 25 - 342: dog - cat || Loss: 1.087900996208191\n",
      "tensor([0., 1.]) tensor([0.7746, 0.2254], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 25 - 343: dog - cat || Loss: 1.0873650312423706\n",
      "tensor([0., 1.]) tensor([0.7741, 0.2259], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 25 - 344: dog - cat || Loss: 1.0868281126022339\n",
      "tensor([0., 1.]) tensor([0.7736, 0.2264], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 25 - 345: dog - cat || Loss: 1.0862901210784912\n",
      "tensor([0., 1.]) tensor([0.7730, 0.2270], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 25 - 346: dog - cat || Loss: 1.0857512950897217\n",
      "tensor([0., 1.]) tensor([0.7725, 0.2275], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 25 - 347: dog - cat || Loss: 1.0852116346359253\n",
      "tensor([0., 1.]) tensor([0.7720, 0.2280], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 25 - 348: dog - cat || Loss: 1.084671139717102\n",
      "tensor([0., 1.]) tensor([0.7714, 0.2286], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 25 - 349: dog - cat || Loss: 1.0841295719146729\n",
      "tensor([0., 1.]) tensor([0.7709, 0.2291], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 25 - 350: dog - cat || Loss: 1.0835871696472168\n",
      "tensor([0., 1.]) tensor([0.7703, 0.2297], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 25 - 351: dog - cat || Loss: 1.0830439329147339\n",
      "tensor([0., 1.]) tensor([0.7698, 0.2302], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 25 - 352: dog - cat || Loss: 1.0824997425079346\n",
      "tensor([0., 1.]) tensor([0.7692, 0.2308], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 25 - 353: dog - cat || Loss: 1.0819547176361084\n",
      "tensor([0., 1.]) tensor([0.7687, 0.2313], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 25 - 354: dog - cat || Loss: 1.0814085006713867\n",
      "tensor([0., 1.]) tensor([0.7681, 0.2319], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 25 - 355: dog - cat || Loss: 1.0808616876602173\n",
      "tensor([0., 1.]) tensor([0.7676, 0.2324], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 25 - 356: dog - cat || Loss: 1.0803141593933105\n",
      "tensor([0., 1.]) tensor([0.7671, 0.2329], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 25 - 357: dog - cat || Loss: 1.0797653198242188\n",
      "tensor([0., 1.]) tensor([0.7665, 0.2335], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 25 - 358: dog - cat || Loss: 1.0792157649993896\n",
      "tensor([0., 1.]) tensor([0.7660, 0.2340], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 25 - 359: dog - cat || Loss: 1.0786651372909546\n",
      "tensor([0., 1.]) tensor([0.7654, 0.2346], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 25 - 360: dog - cat || Loss: 1.0781137943267822\n",
      "tensor([0., 1.]) tensor([0.7649, 0.2351], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 25 - 361: dog - cat || Loss: 1.077561616897583\n",
      "tensor([0., 1.]) tensor([0.7643, 0.2357], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 25 - 362: dog - cat || Loss: 1.0770082473754883\n",
      "tensor([0., 1.]) tensor([0.7637, 0.2363], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 25 - 363: dog - cat || Loss: 1.0764542818069458\n",
      "tensor([0., 1.]) tensor([0.7632, 0.2368], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 25 - 364: dog - cat || Loss: 1.0758992433547974\n",
      "tensor([0., 1.]) tensor([0.7626, 0.2374], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 25 - 365: dog - cat || Loss: 1.0753434896469116\n",
      "tensor([0., 1.]) tensor([0.7621, 0.2379], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 25 - 366: dog - cat || Loss: 1.07478666305542\n",
      "tensor([0., 1.]) tensor([0.7615, 0.2385], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 25 - 367: dog - cat || Loss: 1.074229121208191\n",
      "tensor([0., 1.]) tensor([0.7610, 0.2390], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 25 - 368: dog - cat || Loss: 1.073670506477356\n",
      "tensor([0., 1.]) tensor([0.7604, 0.2396], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 25 - 369: dog - cat || Loss: 1.0731109380722046\n",
      "tensor([0., 1.]) tensor([0.7598, 0.2402], grad_fn=<SoftmaxBackward0>)\n",
      "=====epoch:26=====\n",
      "Epoch 26 - 0: cat - cat || Loss: 0.553972601890564\n",
      "tensor([1., 0.]) tensor([0.7593, 0.2407], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 26 - 1: cat - cat || Loss: 0.5544207692146301\n",
      "tensor([1., 0.]) tensor([0.7588, 0.2412], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 26 - 2: cat - cat || Loss: 0.5547677278518677\n",
      "tensor([1., 0.]) tensor([0.7585, 0.2415], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 26 - 3: cat - cat || Loss: 0.5550233721733093\n",
      "tensor([1., 0.]) tensor([0.7582, 0.2418], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 26 - 4: cat - cat || Loss: 0.5551969408988953\n",
      "tensor([1., 0.]) tensor([0.7581, 0.2419], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 26 - 5: cat - cat || Loss: 0.5552963018417358\n",
      "tensor([1., 0.]) tensor([0.7580, 0.2420], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 26 - 6: cat - cat || Loss: 0.5553290843963623\n",
      "tensor([1., 0.]) tensor([0.7579, 0.2421], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 26 - 7: cat - cat || Loss: 0.5553018450737\n",
      "tensor([1., 0.]) tensor([0.7580, 0.2420], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 26 - 8: cat - cat || Loss: 0.5552206635475159\n",
      "tensor([1., 0.]) tensor([0.7580, 0.2420], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 26 - 9: cat - cat || Loss: 0.5550909042358398\n",
      "tensor([1., 0.]) tensor([0.7582, 0.2418], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 26 - 10: cat - cat || Loss: 0.5549173951148987\n",
      "tensor([1., 0.]) tensor([0.7583, 0.2417], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 26 - 11: cat - cat || Loss: 0.5547047853469849\n",
      "tensor([1., 0.]) tensor([0.7586, 0.2414], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 26 - 12: cat - cat || Loss: 0.5544568300247192\n",
      "tensor([1., 0.]) tensor([0.7588, 0.2412], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 26 - 13: cat - cat || Loss: 0.5541771650314331\n",
      "tensor([1., 0.]) tensor([0.7591, 0.2409], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 26 - 14: cat - cat || Loss: 0.5538690090179443\n",
      "tensor([1., 0.]) tensor([0.7594, 0.2406], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 26 - 15: cat - cat || Loss: 0.5535354614257812\n",
      "tensor([1., 0.]) tensor([0.7597, 0.2403], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 26 - 16: cat - cat || Loss: 0.5531789064407349\n",
      "tensor([1., 0.]) tensor([0.7601, 0.2399], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 26 - 17: cat - cat || Loss: 0.5528018474578857\n",
      "tensor([1., 0.]) tensor([0.7605, 0.2395], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 26 - 18: cat - cat || Loss: 0.5524064898490906\n",
      "tensor([1., 0.]) tensor([0.7609, 0.2391], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 26 - 19: cat - cat || Loss: 0.5519946217536926\n",
      "tensor([1., 0.]) tensor([0.7613, 0.2387], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 26 - 20: cat - cat || Loss: 0.5515679121017456\n",
      "tensor([1., 0.]) tensor([0.7617, 0.2383], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 26 - 21: cat - cat || Loss: 0.5511280298233032\n",
      "tensor([1., 0.]) tensor([0.7621, 0.2379], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 26 - 22: cat - cat || Loss: 0.5506765246391296\n",
      "tensor([1., 0.]) tensor([0.7626, 0.2374], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 26 - 23: cat - cat || Loss: 0.5502144694328308\n",
      "tensor([1., 0.]) tensor([0.7630, 0.2370], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 26 - 24: cat - cat || Loss: 0.5497429370880127\n",
      "tensor([1., 0.]) tensor([0.7635, 0.2365], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 26 - 25: cat - cat || Loss: 0.5492632389068604\n",
      "tensor([1., 0.]) tensor([0.7640, 0.2360], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 26 - 26: cat - cat || Loss: 0.5487760305404663\n",
      "tensor([1., 0.]) tensor([0.7645, 0.2355], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 26 - 27: cat - cat || Loss: 0.5482823252677917\n",
      "tensor([1., 0.]) tensor([0.7650, 0.2350], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 26 - 28: cat - cat || Loss: 0.5477827787399292\n",
      "tensor([1., 0.]) tensor([0.7655, 0.2345], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 26 - 29: cat - cat || Loss: 0.5472779273986816\n",
      "tensor([1., 0.]) tensor([0.7660, 0.2340], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 26 - 30: cat - cat || Loss: 0.5467686653137207\n",
      "tensor([1., 0.]) tensor([0.7665, 0.2335], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 26 - 31: cat - cat || Loss: 0.5462554097175598\n",
      "tensor([1., 0.]) tensor([0.7670, 0.2330], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 26 - 32: cat - cat || Loss: 0.5457385778427124\n",
      "tensor([1., 0.]) tensor([0.7675, 0.2325], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 26 - 33: cat - cat || Loss: 0.545218825340271\n",
      "tensor([1., 0.]) tensor([0.7680, 0.2320], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 26 - 34: cat - cat || Loss: 0.5446963310241699\n",
      "tensor([1., 0.]) tensor([0.7686, 0.2314], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 26 - 35: cat - cat || Loss: 0.5441714525222778\n",
      "tensor([1., 0.]) tensor([0.7691, 0.2309], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 26 - 36: cat - cat || Loss: 0.5436447858810425\n",
      "tensor([1., 0.]) tensor([0.7696, 0.2304], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 26 - 37: cat - cat || Loss: 0.5431162714958191\n",
      "tensor([1., 0.]) tensor([0.7701, 0.2299], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 26 - 38: cat - cat || Loss: 0.5425863862037659\n",
      "tensor([1., 0.]) tensor([0.7707, 0.2293], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 26 - 39: cat - cat || Loss: 0.5420551896095276\n",
      "tensor([1., 0.]) tensor([0.7712, 0.2288], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 26 - 40: cat - cat || Loss: 0.541523277759552\n",
      "tensor([1., 0.]) tensor([0.7717, 0.2283], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 26 - 41: cat - cat || Loss: 0.5409903526306152\n",
      "tensor([1., 0.]) tensor([0.7723, 0.2277], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 26 - 42: cat - cat || Loss: 0.5404568910598755\n",
      "tensor([1., 0.]) tensor([0.7728, 0.2272], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 26 - 43: cat - cat || Loss: 0.5399228930473328\n",
      "tensor([1., 0.]) tensor([0.7733, 0.2267], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 26 - 44: cat - cat || Loss: 0.5393887758255005\n",
      "tensor([1., 0.]) tensor([0.7739, 0.2261], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 26 - 45: cat - cat || Loss: 0.5388543605804443\n",
      "tensor([1., 0.]) tensor([0.7744, 0.2256], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 26 - 46: cat - cat || Loss: 0.5383198261260986\n",
      "tensor([1., 0.]) tensor([0.7749, 0.2251], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 26 - 47: cat - cat || Loss: 0.5377854108810425\n",
      "tensor([1., 0.]) tensor([0.7755, 0.2245], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 26 - 48: cat - cat || Loss: 0.5372509956359863\n",
      "tensor([1., 0.]) tensor([0.7760, 0.2240], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 26 - 49: cat - cat || Loss: 0.536716878414154\n",
      "tensor([1., 0.]) tensor([0.7765, 0.2235], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 26 - 50: cat - cat || Loss: 0.5361830592155457\n",
      "tensor([1., 0.]) tensor([0.7771, 0.2229], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 26 - 51: cat - cat || Loss: 0.5356495976448059\n",
      "tensor([1., 0.]) tensor([0.7776, 0.2224], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 26 - 52: cat - cat || Loss: 0.5351164937019348\n",
      "tensor([1., 0.]) tensor([0.7781, 0.2219], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 26 - 53: cat - cat || Loss: 0.5345838069915771\n",
      "tensor([1., 0.]) tensor([0.7787, 0.2213], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 26 - 54: cat - cat || Loss: 0.5340516567230225\n",
      "tensor([1., 0.]) tensor([0.7792, 0.2208], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 26 - 55: cat - cat || Loss: 0.533519983291626\n",
      "tensor([1., 0.]) tensor([0.7797, 0.2203], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 26 - 56: cat - cat || Loss: 0.532988965511322\n",
      "tensor([1., 0.]) tensor([0.7803, 0.2197], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 26 - 57: cat - cat || Loss: 0.532458484172821\n",
      "tensor([1., 0.]) tensor([0.7808, 0.2192], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 26 - 58: cat - cat || Loss: 0.5319287776947021\n",
      "tensor([1., 0.]) tensor([0.7813, 0.2187], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 26 - 59: cat - cat || Loss: 0.5313996076583862\n",
      "tensor([1., 0.]) tensor([0.7819, 0.2181], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 26 - 60: cat - cat || Loss: 0.5308712720870972\n",
      "tensor([1., 0.]) tensor([0.7824, 0.2176], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 26 - 61: cat - cat || Loss: 0.5303435325622559\n",
      "tensor([1., 0.]) tensor([0.7829, 0.2171], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 26 - 62: cat - cat || Loss: 0.5298165082931519\n",
      "tensor([1., 0.]) tensor([0.7834, 0.2166], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 26 - 63: cat - cat || Loss: 0.5292904376983643\n",
      "tensor([1., 0.]) tensor([0.7840, 0.2160], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 26 - 64: cat - cat || Loss: 0.5287651419639587\n",
      "tensor([1., 0.]) tensor([0.7845, 0.2155], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 26 - 65: cat - cat || Loss: 0.5282406210899353\n",
      "tensor([1., 0.]) tensor([0.7850, 0.2150], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 26 - 66: cat - cat || Loss: 0.5277169346809387\n",
      "tensor([1., 0.]) tensor([0.7855, 0.2145], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 26 - 67: cat - cat || Loss: 0.5271942615509033\n",
      "tensor([1., 0.]) tensor([0.7861, 0.2139], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 26 - 68: cat - cat || Loss: 0.5266721844673157\n",
      "tensor([1., 0.]) tensor([0.7866, 0.2134], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 26 - 69: cat - cat || Loss: 0.5261510014533997\n",
      "tensor([1., 0.]) tensor([0.7871, 0.2129], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 26 - 70: cat - cat || Loss: 0.5256308317184448\n",
      "tensor([1., 0.]) tensor([0.7876, 0.2124], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 26 - 71: cat - cat || Loss: 0.5251113772392273\n",
      "tensor([1., 0.]) tensor([0.7882, 0.2118], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 26 - 72: cat - cat || Loss: 0.5245927572250366\n",
      "tensor([1., 0.]) tensor([0.7887, 0.2113], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 26 - 73: cat - cat || Loss: 0.5240751504898071\n",
      "tensor([1., 0.]) tensor([0.7892, 0.2108], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 26 - 74: cat - cat || Loss: 0.5235583782196045\n",
      "tensor([1., 0.]) tensor([0.7897, 0.2103], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 26 - 75: cat - cat || Loss: 0.5230425596237183\n",
      "tensor([1., 0.]) tensor([0.7902, 0.2098], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 26 - 76: cat - cat || Loss: 0.5225276350975037\n",
      "tensor([1., 0.]) tensor([0.7907, 0.2093], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 26 - 77: cat - cat || Loss: 0.5220135450363159\n",
      "tensor([1., 0.]) tensor([0.7912, 0.2088], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 26 - 78: cat - cat || Loss: 0.5215003490447998\n",
      "tensor([1., 0.]) tensor([0.7918, 0.2082], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 26 - 79: cat - cat || Loss: 0.5209881067276001\n",
      "tensor([1., 0.]) tensor([0.7923, 0.2077], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 26 - 80: cat - cat || Loss: 0.5204769372940063\n",
      "tensor([1., 0.]) tensor([0.7928, 0.2072], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 26 - 81: cat - cat || Loss: 0.5199663639068604\n",
      "tensor([1., 0.]) tensor([0.7933, 0.2067], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 26 - 82: cat - cat || Loss: 0.5194568037986755\n",
      "tensor([1., 0.]) tensor([0.7938, 0.2062], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 26 - 83: cat - cat || Loss: 0.5189483165740967\n",
      "tensor([1., 0.]) tensor([0.7943, 0.2057], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 26 - 84: cat - cat || Loss: 0.5184407830238342\n",
      "tensor([1., 0.]) tensor([0.7948, 0.2052], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 26 - 85: cat - cat || Loss: 0.5179341435432434\n",
      "tensor([1., 0.]) tensor([0.7953, 0.2047], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 26 - 86: cat - cat || Loss: 0.5174282789230347\n",
      "tensor([1., 0.]) tensor([0.7958, 0.2042], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 26 - 87: cat - cat || Loss: 0.5169235467910767\n",
      "tensor([1., 0.]) tensor([0.7963, 0.2037], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 26 - 88: cat - cat || Loss: 0.5164196491241455\n",
      "tensor([1., 0.]) tensor([0.7968, 0.2032], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 26 - 89: cat - cat || Loss: 0.5159167051315308\n",
      "tensor([1., 0.]) tensor([0.7973, 0.2027], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 26 - 90: cat - cat || Loss: 0.5154147148132324\n",
      "tensor([1., 0.]) tensor([0.7978, 0.2022], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 26 - 91: cat - cat || Loss: 0.5149135589599609\n",
      "tensor([1., 0.]) tensor([0.7983, 0.2017], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 26 - 92: cat - cat || Loss: 0.5144134759902954\n",
      "tensor([1., 0.]) tensor([0.7988, 0.2012], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 26 - 93: cat - cat || Loss: 0.5139142274856567\n",
      "tensor([1., 0.]) tensor([0.7993, 0.2007], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 26 - 94: cat - cat || Loss: 0.5134159922599792\n",
      "tensor([1., 0.]) tensor([0.7998, 0.2002], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 26 - 95: cat - cat || Loss: 0.5129186511039734\n",
      "tensor([1., 0.]) tensor([0.8003, 0.1997], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 26 - 96: cat - cat || Loss: 0.5124223232269287\n",
      "tensor([1., 0.]) tensor([0.8008, 0.1992], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 26 - 97: cat - cat || Loss: 0.5119269490242004\n",
      "tensor([1., 0.]) tensor([0.8013, 0.1987], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 26 - 98: cat - cat || Loss: 0.511432409286499\n",
      "tensor([1., 0.]) tensor([0.8018, 0.1982], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 26 - 99: cat - cat || Loss: 0.5109388828277588\n",
      "tensor([1., 0.]) tensor([0.8023, 0.1977], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 26 - 100: cat - cat || Loss: 0.510446310043335\n",
      "tensor([1., 0.]) tensor([0.8028, 0.1972], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 26 - 101: cat - cat || Loss: 0.5099546313285828\n",
      "tensor([1., 0.]) tensor([0.8033, 0.1967], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 26 - 102: cat - cat || Loss: 0.5094640254974365\n",
      "tensor([1., 0.]) tensor([0.8038, 0.1962], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 26 - 103: cat - cat || Loss: 0.5089741945266724\n",
      "tensor([1., 0.]) tensor([0.8043, 0.1957], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 26 - 104: cat - cat || Loss: 0.5084853172302246\n",
      "tensor([1., 0.]) tensor([0.8048, 0.1952], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 26 - 105: cat - cat || Loss: 0.5079976320266724\n",
      "tensor([1., 0.]) tensor([0.8053, 0.1947], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 26 - 106: cat - cat || Loss: 0.5075106620788574\n",
      "tensor([1., 0.]) tensor([0.8058, 0.1942], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 26 - 107: cat - cat || Loss: 0.5070246458053589\n",
      "tensor([1., 0.]) tensor([0.8062, 0.1938], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 26 - 108: cat - cat || Loss: 0.5065396428108215\n",
      "tensor([1., 0.]) tensor([0.8067, 0.1933], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 26 - 109: cat - cat || Loss: 0.5060555934906006\n",
      "tensor([1., 0.]) tensor([0.8072, 0.1928], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 26 - 110: cat - cat || Loss: 0.5055724382400513\n",
      "tensor([1., 0.]) tensor([0.8077, 0.1923], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 26 - 111: cat - cat || Loss: 0.5050902962684631\n",
      "tensor([1., 0.]) tensor([0.8082, 0.1918], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 26 - 112: cat - cat || Loss: 0.5046089887619019\n",
      "tensor([1., 0.]) tensor([0.8087, 0.1913], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 26 - 113: cat - cat || Loss: 0.5041286945343018\n",
      "tensor([1., 0.]) tensor([0.8091, 0.1909], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 26 - 114: cat - cat || Loss: 0.5036493539810181\n",
      "tensor([1., 0.]) tensor([0.8096, 0.1904], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 26 - 115: cat - cat || Loss: 0.5031709671020508\n",
      "tensor([1., 0.]) tensor([0.8101, 0.1899], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 26 - 116: cat - cat || Loss: 0.5026934742927551\n",
      "tensor([1., 0.]) tensor([0.8106, 0.1894], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 26 - 117: cat - cat || Loss: 0.5022169351577759\n",
      "tensor([1., 0.]) tensor([0.8110, 0.1890], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 26 - 118: cat - cat || Loss: 0.501741349697113\n",
      "tensor([1., 0.]) tensor([0.8115, 0.1885], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 26 - 119: cat - cat || Loss: 0.5012668371200562\n",
      "tensor([1., 0.]) tensor([0.8120, 0.1880], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 26 - 120: cat - cat || Loss: 0.5007930397987366\n",
      "tensor([1., 0.]) tensor([0.8125, 0.1875], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 26 - 121: cat - cat || Loss: 0.5003202557563782\n",
      "tensor([1., 0.]) tensor([0.8129, 0.1871], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 26 - 122: cat - cat || Loss: 0.49984848499298096\n",
      "tensor([1., 0.]) tensor([0.8134, 0.1866], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 26 - 123: cat - cat || Loss: 0.49937766790390015\n",
      "tensor([1., 0.]) tensor([0.8139, 0.1861], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 26 - 124: cat - cat || Loss: 0.4989077150821686\n",
      "tensor([1., 0.]) tensor([0.8144, 0.1856], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 26 - 125: cat - cat || Loss: 0.4984387755393982\n",
      "tensor([1., 0.]) tensor([0.8148, 0.1852], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 26 - 126: cat - cat || Loss: 0.49797073006629944\n",
      "tensor([1., 0.]) tensor([0.8153, 0.1847], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 26 - 127: cat - cat || Loss: 0.49750351905822754\n",
      "tensor([1., 0.]) tensor([0.8158, 0.1842], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 26 - 128: cat - cat || Loss: 0.49703744053840637\n",
      "tensor([1., 0.]) tensor([0.8162, 0.1838], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 26 - 129: cat - cat || Loss: 0.49657219648361206\n",
      "tensor([1., 0.]) tensor([0.8167, 0.1833], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 26 - 130: cat - cat || Loss: 0.4961079955101013\n",
      "tensor([1., 0.]) tensor([0.8172, 0.1828], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 26 - 131: cat - cat || Loss: 0.49564462900161743\n",
      "tensor([1., 0.]) tensor([0.8176, 0.1824], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 26 - 132: cat - cat || Loss: 0.49518221616744995\n",
      "tensor([1., 0.]) tensor([0.8181, 0.1819], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 26 - 133: cat - cat || Loss: 0.49472081661224365\n",
      "tensor([1., 0.]) tensor([0.8185, 0.1815], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 26 - 134: cat - cat || Loss: 0.4942602515220642\n",
      "tensor([1., 0.]) tensor([0.8190, 0.1810], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 26 - 135: cat - cat || Loss: 0.4938008189201355\n",
      "tensor([1., 0.]) tensor([0.8195, 0.1805], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 26 - 136: cat - cat || Loss: 0.49334216117858887\n",
      "tensor([1., 0.]) tensor([0.8199, 0.1801], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 26 - 137: cat - cat || Loss: 0.49288445711135864\n",
      "tensor([1., 0.]) tensor([0.8204, 0.1796], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 26 - 138: cat - cat || Loss: 0.4924277663230896\n",
      "tensor([1., 0.]) tensor([0.8208, 0.1792], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 26 - 139: cat - cat || Loss: 0.4919719099998474\n",
      "tensor([1., 0.]) tensor([0.8213, 0.1787], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 26 - 140: cat - cat || Loss: 0.4915171265602112\n",
      "tensor([1., 0.]) tensor([0.8217, 0.1783], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 26 - 141: cat - cat || Loss: 0.49106311798095703\n",
      "tensor([1., 0.]) tensor([0.8222, 0.1778], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 26 - 142: cat - cat || Loss: 0.49061012268066406\n",
      "tensor([1., 0.]) tensor([0.8227, 0.1773], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 26 - 143: cat - cat || Loss: 0.4901580810546875\n",
      "tensor([1., 0.]) tensor([0.8231, 0.1769], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 26 - 144: cat - cat || Loss: 0.48970699310302734\n",
      "tensor([1., 0.]) tensor([0.8236, 0.1764], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 26 - 145: cat - cat || Loss: 0.4892567992210388\n",
      "tensor([1., 0.]) tensor([0.8240, 0.1760], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 26 - 146: cat - cat || Loss: 0.4888075888156891\n",
      "tensor([1., 0.]) tensor([0.8245, 0.1755], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 26 - 147: cat - cat || Loss: 0.488359272480011\n",
      "tensor([1., 0.]) tensor([0.8249, 0.1751], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 26 - 148: cat - cat || Loss: 0.4879118800163269\n",
      "tensor([1., 0.]) tensor([0.8253, 0.1747], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 26 - 149: cat - cat || Loss: 0.487465500831604\n",
      "tensor([1., 0.]) tensor([0.8258, 0.1742], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 26 - 150: cat - cat || Loss: 0.48702001571655273\n",
      "tensor([1., 0.]) tensor([0.8262, 0.1738], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 26 - 151: cat - cat || Loss: 0.4865754246711731\n",
      "tensor([1., 0.]) tensor([0.8267, 0.1733], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 26 - 152: cat - cat || Loss: 0.486131876707077\n",
      "tensor([1., 0.]) tensor([0.8271, 0.1729], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 26 - 153: cat - cat || Loss: 0.48568910360336304\n",
      "tensor([1., 0.]) tensor([0.8276, 0.1724], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 26 - 154: cat - cat || Loss: 0.4852473735809326\n",
      "tensor([1., 0.]) tensor([0.8280, 0.1720], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 26 - 155: cat - cat || Loss: 0.48480647802352905\n",
      "tensor([1., 0.]) tensor([0.8285, 0.1715], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 26 - 156: cat - cat || Loss: 0.48436659574508667\n",
      "tensor([1., 0.]) tensor([0.8289, 0.1711], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 26 - 157: cat - cat || Loss: 0.48392772674560547\n",
      "tensor([1., 0.]) tensor([0.8293, 0.1707], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 26 - 158: cat - cat || Loss: 0.4834895431995392\n",
      "tensor([1., 0.]) tensor([0.8298, 0.1702], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 26 - 159: cat - cat || Loss: 0.4830523729324341\n",
      "tensor([1., 0.]) tensor([0.8302, 0.1698], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 26 - 160: cat - cat || Loss: 0.482616126537323\n",
      "tensor([1., 0.]) tensor([0.8306, 0.1694], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 26 - 161: cat - cat || Loss: 0.48218095302581787\n",
      "tensor([1., 0.]) tensor([0.8311, 0.1689], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 26 - 162: cat - cat || Loss: 0.481746643781662\n",
      "tensor([1., 0.]) tensor([0.8315, 0.1685], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 26 - 163: cat - cat || Loss: 0.48131316900253296\n",
      "tensor([1., 0.]) tensor([0.8319, 0.1681], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 26 - 164: cat - cat || Loss: 0.4808807373046875\n",
      "tensor([1., 0.]) tensor([0.8324, 0.1676], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 26 - 165: cat - cat || Loss: 0.48044919967651367\n",
      "tensor([1., 0.]) tensor([0.8328, 0.1672], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 26 - 166: cat - cat || Loss: 0.4800185263156891\n",
      "tensor([1., 0.]) tensor([0.8332, 0.1668], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 26 - 167: cat - cat || Loss: 0.47958874702453613\n",
      "tensor([1., 0.]) tensor([0.8337, 0.1663], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 26 - 168: cat - cat || Loss: 0.47916001081466675\n",
      "tensor([1., 0.]) tensor([0.8341, 0.1659], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 26 - 169: cat - cat || Loss: 0.47873207926750183\n",
      "tensor([1., 0.]) tensor([0.8345, 0.1655], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 26 - 170: cat - cat || Loss: 0.4783051311969757\n",
      "tensor([1., 0.]) tensor([0.8350, 0.1650], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 26 - 171: cat - cat || Loss: 0.4778791069984436\n",
      "tensor([1., 0.]) tensor([0.8354, 0.1646], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 26 - 172: cat - cat || Loss: 0.4774540066719055\n",
      "tensor([1., 0.]) tensor([0.8358, 0.1642], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 26 - 173: cat - cat || Loss: 0.47702986001968384\n",
      "tensor([1., 0.]) tensor([0.8362, 0.1638], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 26 - 174: cat - cat || Loss: 0.476606547832489\n",
      "tensor([1., 0.]) tensor([0.8367, 0.1633], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 26 - 175: cat - cat || Loss: 0.47618424892425537\n",
      "tensor([1., 0.]) tensor([0.8371, 0.1629], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 26 - 176: cat - cat || Loss: 0.47576281428337097\n",
      "tensor([1., 0.]) tensor([0.8375, 0.1625], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 26 - 177: cat - cat || Loss: 0.4753423035144806\n",
      "tensor([1., 0.]) tensor([0.8379, 0.1621], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 26 - 178: cat - cat || Loss: 0.47492271661758423\n",
      "tensor([1., 0.]) tensor([0.8383, 0.1617], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 26 - 179: cat - cat || Loss: 0.4745040535926819\n",
      "tensor([1., 0.]) tensor([0.8388, 0.1612], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 26 - 180: cat - cat || Loss: 0.474086195230484\n",
      "tensor([1., 0.]) tensor([0.8392, 0.1608], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 26 - 181: cat - cat || Loss: 0.47366926074028015\n",
      "tensor([1., 0.]) tensor([0.8396, 0.1604], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 26 - 182: cat - cat || Loss: 0.4732533097267151\n",
      "tensor([1., 0.]) tensor([0.8400, 0.1600], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 26 - 183: cat - cat || Loss: 0.47283828258514404\n",
      "tensor([1., 0.]) tensor([0.8404, 0.1596], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 26 - 184: cat - cat || Loss: 0.4724240303039551\n",
      "tensor([1., 0.]) tensor([0.8408, 0.1592], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 26 - 185: cat - cat || Loss: 0.4720108211040497\n",
      "tensor([1., 0.]) tensor([0.8413, 0.1587], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 26 - 186: cat - cat || Loss: 0.47159838676452637\n",
      "tensor([1., 0.]) tensor([0.8417, 0.1583], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 26 - 187: cat - cat || Loss: 0.47118693590164185\n",
      "tensor([1., 0.]) tensor([0.8421, 0.1579], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 26 - 188: cat - cat || Loss: 0.47077643871307373\n",
      "tensor([1., 0.]) tensor([0.8425, 0.1575], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 26 - 189: cat - cat || Loss: 0.47036683559417725\n",
      "tensor([1., 0.]) tensor([0.8429, 0.1571], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 26 - 190: dog - cat || Loss: 1.1565653085708618\n",
      "tensor([0., 1.]) tensor([0.8433, 0.1567], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 26 - 191: dog - cat || Loss: 1.1568924188613892\n",
      "tensor([0., 1.]) tensor([0.8436, 0.1564], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 26 - 192: dog - cat || Loss: 1.1571462154388428\n",
      "tensor([0., 1.]) tensor([0.8439, 0.1561], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 26 - 193: dog - cat || Loss: 1.1573342084884644\n",
      "tensor([0., 1.]) tensor([0.8441, 0.1559], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 26 - 194: dog - cat || Loss: 1.1574629545211792\n",
      "tensor([0., 1.]) tensor([0.8442, 0.1558], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 26 - 195: dog - cat || Loss: 1.157538652420044\n",
      "tensor([0., 1.]) tensor([0.8443, 0.1557], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 26 - 196: dog - cat || Loss: 1.1575666666030884\n",
      "tensor([0., 1.]) tensor([0.8443, 0.1557], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 26 - 197: dog - cat || Loss: 1.1575515270233154\n",
      "tensor([0., 1.]) tensor([0.8443, 0.1557], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 26 - 198: dog - cat || Loss: 1.1574978828430176\n",
      "tensor([0., 1.]) tensor([0.8442, 0.1558], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 26 - 199: dog - cat || Loss: 1.1574091911315918\n",
      "tensor([0., 1.]) tensor([0.8441, 0.1559], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 26 - 200: dog - cat || Loss: 1.1572891473770142\n",
      "tensor([0., 1.]) tensor([0.8440, 0.1560], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 26 - 201: dog - cat || Loss: 1.157140851020813\n",
      "tensor([0., 1.]) tensor([0.8439, 0.1561], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 26 - 202: dog - cat || Loss: 1.156967043876648\n",
      "tensor([0., 1.]) tensor([0.8437, 0.1563], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 26 - 203: dog - cat || Loss: 1.1567702293395996\n",
      "tensor([0., 1.]) tensor([0.8435, 0.1565], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 26 - 204: dog - cat || Loss: 1.1565525531768799\n",
      "tensor([0., 1.]) tensor([0.8433, 0.1567], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 26 - 205: dog - cat || Loss: 1.1563159227371216\n",
      "tensor([0., 1.]) tensor([0.8431, 0.1569], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 26 - 206: dog - cat || Loss: 1.1560626029968262\n",
      "tensor([0., 1.]) tensor([0.8428, 0.1572], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 26 - 207: dog - cat || Loss: 1.1557939052581787\n",
      "tensor([0., 1.]) tensor([0.8425, 0.1575], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 26 - 208: dog - cat || Loss: 1.1555111408233643\n",
      "tensor([0., 1.]) tensor([0.8422, 0.1578], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 26 - 209: dog - cat || Loss: 1.155215859413147\n",
      "tensor([0., 1.]) tensor([0.8420, 0.1580], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 26 - 210: dog - cat || Loss: 1.154909372329712\n",
      "tensor([0., 1.]) tensor([0.8416, 0.1584], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 26 - 211: dog - cat || Loss: 1.154592514038086\n",
      "tensor([0., 1.]) tensor([0.8413, 0.1587], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 26 - 212: dog - cat || Loss: 1.1542659997940063\n",
      "tensor([0., 1.]) tensor([0.8410, 0.1590], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 26 - 213: dog - cat || Loss: 1.153930902481079\n",
      "tensor([0., 1.]) tensor([0.8407, 0.1593], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 26 - 214: dog - cat || Loss: 1.1535882949829102\n",
      "tensor([0., 1.]) tensor([0.8403, 0.1597], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 26 - 215: dog - cat || Loss: 1.1532385349273682\n",
      "tensor([0., 1.]) tensor([0.8400, 0.1600], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 26 - 216: dog - cat || Loss: 1.15288245677948\n",
      "tensor([0., 1.]) tensor([0.8396, 0.1604], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 26 - 217: dog - cat || Loss: 1.1525202989578247\n",
      "tensor([0., 1.]) tensor([0.8393, 0.1607], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 26 - 218: dog - cat || Loss: 1.1521527767181396\n",
      "tensor([0., 1.]) tensor([0.8389, 0.1611], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 26 - 219: dog - cat || Loss: 1.1517802476882935\n",
      "tensor([0., 1.]) tensor([0.8385, 0.1615], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 26 - 220: dog - cat || Loss: 1.1514033079147339\n",
      "tensor([0., 1.]) tensor([0.8381, 0.1619], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 26 - 221: dog - cat || Loss: 1.15102219581604\n",
      "tensor([0., 1.]) tensor([0.8378, 0.1622], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 26 - 222: dog - cat || Loss: 1.150637149810791\n",
      "tensor([0., 1.]) tensor([0.8374, 0.1626], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 26 - 223: dog - cat || Loss: 1.1502485275268555\n",
      "tensor([0., 1.]) tensor([0.8370, 0.1630], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 26 - 224: dog - cat || Loss: 1.149856686592102\n",
      "tensor([0., 1.]) tensor([0.8366, 0.1634], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 26 - 225: dog - cat || Loss: 1.1494618654251099\n",
      "tensor([0., 1.]) tensor([0.8362, 0.1638], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 26 - 226: dog - cat || Loss: 1.1490641832351685\n",
      "tensor([0., 1.]) tensor([0.8358, 0.1642], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 26 - 227: dog - cat || Loss: 1.148663878440857\n",
      "tensor([0., 1.]) tensor([0.8354, 0.1646], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 26 - 228: dog - cat || Loss: 1.1482610702514648\n",
      "tensor([0., 1.]) tensor([0.8350, 0.1650], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 26 - 229: dog - cat || Loss: 1.1478562355041504\n",
      "tensor([0., 1.]) tensor([0.8346, 0.1654], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 26 - 230: dog - cat || Loss: 1.1474487781524658\n",
      "tensor([0., 1.]) tensor([0.8342, 0.1658], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 26 - 231: dog - cat || Loss: 1.147039532661438\n",
      "tensor([0., 1.]) tensor([0.8338, 0.1662], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 26 - 232: dog - cat || Loss: 1.1466283798217773\n",
      "tensor([0., 1.]) tensor([0.8334, 0.1666], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 26 - 233: dog - cat || Loss: 1.1462154388427734\n",
      "tensor([0., 1.]) tensor([0.8330, 0.1670], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 26 - 234: dog - cat || Loss: 1.1458008289337158\n",
      "tensor([0., 1.]) tensor([0.8325, 0.1675], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 26 - 235: dog - cat || Loss: 1.1453845500946045\n",
      "tensor([0., 1.]) tensor([0.8321, 0.1679], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 26 - 236: dog - cat || Loss: 1.1449666023254395\n",
      "tensor([0., 1.]) tensor([0.8317, 0.1683], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 26 - 237: dog - cat || Loss: 1.1445473432540894\n",
      "tensor([0., 1.]) tensor([0.8313, 0.1687], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 26 - 238: dog - cat || Loss: 1.144126534461975\n",
      "tensor([0., 1.]) tensor([0.8309, 0.1691], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 26 - 239: dog - cat || Loss: 1.1437042951583862\n",
      "tensor([0., 1.]) tensor([0.8304, 0.1696], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 26 - 240: dog - cat || Loss: 1.1432808637619019\n",
      "tensor([0., 1.]) tensor([0.8300, 0.1700], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 26 - 241: dog - cat || Loss: 1.1428561210632324\n",
      "tensor([0., 1.]) tensor([0.8296, 0.1704], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 26 - 242: dog - cat || Loss: 1.1424299478530884\n",
      "tensor([0., 1.]) tensor([0.8292, 0.1708], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 26 - 243: dog - cat || Loss: 1.142002820968628\n",
      "tensor([0., 1.]) tensor([0.8287, 0.1713], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 26 - 244: dog - cat || Loss: 1.141574501991272\n",
      "tensor([0., 1.]) tensor([0.8283, 0.1717], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 26 - 245: dog - cat || Loss: 1.141144871711731\n",
      "tensor([0., 1.]) tensor([0.8279, 0.1721], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 26 - 246: dog - cat || Loss: 1.140714168548584\n",
      "tensor([0., 1.]) tensor([0.8275, 0.1725], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 26 - 247: dog - cat || Loss: 1.1402825117111206\n",
      "tensor([0., 1.]) tensor([0.8270, 0.1730], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 26 - 248: dog - cat || Loss: 1.1398495435714722\n",
      "tensor([0., 1.]) tensor([0.8266, 0.1734], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 26 - 249: dog - cat || Loss: 1.1394156217575073\n",
      "tensor([0., 1.]) tensor([0.8262, 0.1738], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 26 - 250: dog - cat || Loss: 1.138980746269226\n",
      "tensor([0., 1.]) tensor([0.8257, 0.1743], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 26 - 251: dog - cat || Loss: 1.1385446786880493\n",
      "tensor([0., 1.]) tensor([0.8253, 0.1747], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 26 - 252: dog - cat || Loss: 1.1381077766418457\n",
      "tensor([0., 1.]) tensor([0.8248, 0.1752], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 26 - 253: dog - cat || Loss: 1.1376696825027466\n",
      "tensor([0., 1.]) tensor([0.8244, 0.1756], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 26 - 254: dog - cat || Loss: 1.137230634689331\n",
      "tensor([0., 1.]) tensor([0.8240, 0.1760], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 26 - 255: dog - cat || Loss: 1.1367906332015991\n",
      "tensor([0., 1.]) tensor([0.8235, 0.1765], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 26 - 256: dog - cat || Loss: 1.1363496780395508\n",
      "tensor([0., 1.]) tensor([0.8231, 0.1769], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 26 - 257: dog - cat || Loss: 1.1359076499938965\n",
      "tensor([0., 1.]) tensor([0.8226, 0.1774], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 26 - 258: dog - cat || Loss: 1.1354649066925049\n",
      "tensor([0., 1.]) tensor([0.8222, 0.1778], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 26 - 259: dog - cat || Loss: 1.1350209712982178\n",
      "tensor([0., 1.]) tensor([0.8218, 0.1782], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 26 - 260: dog - cat || Loss: 1.1345760822296143\n",
      "tensor([0., 1.]) tensor([0.8213, 0.1787], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 26 - 261: dog - cat || Loss: 1.1341304779052734\n",
      "tensor([0., 1.]) tensor([0.8209, 0.1791], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 26 - 262: dog - cat || Loss: 1.1336838006973267\n",
      "tensor([0., 1.]) tensor([0.8204, 0.1796], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 26 - 263: dog - cat || Loss: 1.133236050605774\n",
      "tensor([0., 1.]) tensor([0.8200, 0.1800], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 26 - 264: dog - cat || Loss: 1.1327877044677734\n",
      "tensor([0., 1.]) tensor([0.8195, 0.1805], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 26 - 265: dog - cat || Loss: 1.132338047027588\n",
      "tensor([0., 1.]) tensor([0.8191, 0.1809], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 26 - 266: dog - cat || Loss: 1.1318877935409546\n",
      "tensor([0., 1.]) tensor([0.8186, 0.1814], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 26 - 267: dog - cat || Loss: 1.1314364671707153\n",
      "tensor([0., 1.]) tensor([0.8182, 0.1818], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 26 - 268: dog - cat || Loss: 1.1309840679168701\n",
      "tensor([0., 1.]) tensor([0.8177, 0.1823], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 26 - 269: dog - cat || Loss: 1.130530834197998\n",
      "tensor([0., 1.]) tensor([0.8173, 0.1827], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 26 - 270: dog - cat || Loss: 1.1300767660140991\n",
      "tensor([0., 1.]) tensor([0.8168, 0.1832], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 26 - 271: dog - cat || Loss: 1.1296217441558838\n",
      "tensor([0., 1.]) tensor([0.8164, 0.1836], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 26 - 272: dog - cat || Loss: 1.1291658878326416\n",
      "tensor([0., 1.]) tensor([0.8159, 0.1841], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 26 - 273: dog - cat || Loss: 1.128709077835083\n",
      "tensor([0., 1.]) tensor([0.8154, 0.1846], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 26 - 274: dog - cat || Loss: 1.128251314163208\n",
      "tensor([0., 1.]) tensor([0.8150, 0.1850], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 26 - 275: dog - cat || Loss: 1.127792477607727\n",
      "tensor([0., 1.]) tensor([0.8145, 0.1855], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 26 - 276: dog - cat || Loss: 1.1273330450057983\n",
      "tensor([0., 1.]) tensor([0.8141, 0.1859], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 26 - 277: dog - cat || Loss: 1.1268725395202637\n",
      "tensor([0., 1.]) tensor([0.8136, 0.1864], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 26 - 278: dog - cat || Loss: 1.1264110803604126\n",
      "tensor([0., 1.]) tensor([0.8131, 0.1869], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 26 - 279: dog - cat || Loss: 1.1259489059448242\n",
      "tensor([0., 1.]) tensor([0.8127, 0.1873], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 26 - 280: dog - cat || Loss: 1.1254855394363403\n",
      "tensor([0., 1.]) tensor([0.8122, 0.1878], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 26 - 281: dog - cat || Loss: 1.1250215768814087\n",
      "tensor([0., 1.]) tensor([0.8118, 0.1882], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 26 - 282: dog - cat || Loss: 1.124556541442871\n",
      "tensor([0., 1.]) tensor([0.8113, 0.1887], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 26 - 283: dog - cat || Loss: 1.124090552330017\n",
      "tensor([0., 1.]) tensor([0.8108, 0.1892], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 26 - 284: dog - cat || Loss: 1.1236236095428467\n",
      "tensor([0., 1.]) tensor([0.8104, 0.1896], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 26 - 285: dog - cat || Loss: 1.1231558322906494\n",
      "tensor([0., 1.]) tensor([0.8099, 0.1901], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 26 - 286: dog - cat || Loss: 1.1226873397827148\n",
      "tensor([0., 1.]) tensor([0.8094, 0.1906], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 26 - 287: dog - cat || Loss: 1.1222177743911743\n",
      "tensor([0., 1.]) tensor([0.8090, 0.1910], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 26 - 288: dog - cat || Loss: 1.121747374534607\n",
      "tensor([0., 1.]) tensor([0.8085, 0.1915], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 26 - 289: dog - cat || Loss: 1.1212759017944336\n",
      "tensor([0., 1.]) tensor([0.8080, 0.1920], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 26 - 290: dog - cat || Loss: 1.1208038330078125\n",
      "tensor([0., 1.]) tensor([0.8075, 0.1925], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 26 - 291: dog - cat || Loss: 1.1203304529190063\n",
      "tensor([0., 1.]) tensor([0.8071, 0.1929], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 26 - 292: dog - cat || Loss: 1.1198562383651733\n",
      "tensor([0., 1.]) tensor([0.8066, 0.1934], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 26 - 293: dog - cat || Loss: 1.119381308555603\n",
      "tensor([0., 1.]) tensor([0.8061, 0.1939], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 26 - 294: dog - cat || Loss: 1.1189054250717163\n",
      "tensor([0., 1.]) tensor([0.8056, 0.1944], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 26 - 295: dog - cat || Loss: 1.1184287071228027\n",
      "tensor([0., 1.]) tensor([0.8052, 0.1948], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 26 - 296: dog - cat || Loss: 1.1179510354995728\n",
      "tensor([0., 1.]) tensor([0.8047, 0.1953], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 26 - 297: dog - cat || Loss: 1.1174724102020264\n",
      "tensor([0., 1.]) tensor([0.8042, 0.1958], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 26 - 298: dog - cat || Loss: 1.1169928312301636\n",
      "tensor([0., 1.]) tensor([0.8037, 0.1963], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 26 - 299: dog - cat || Loss: 1.1165125370025635\n",
      "tensor([0., 1.]) tensor([0.8033, 0.1967], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 26 - 300: dog - cat || Loss: 1.1160309314727783\n",
      "tensor([0., 1.]) tensor([0.8028, 0.1972], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 26 - 301: dog - cat || Loss: 1.115548849105835\n",
      "tensor([0., 1.]) tensor([0.8023, 0.1977], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 26 - 302: dog - cat || Loss: 1.1150656938552856\n",
      "tensor([0., 1.]) tensor([0.8018, 0.1982], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 26 - 303: dog - cat || Loss: 1.11458158493042\n",
      "tensor([0., 1.]) tensor([0.8013, 0.1987], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 26 - 304: dog - cat || Loss: 1.1140966415405273\n",
      "tensor([0., 1.]) tensor([0.8008, 0.1992], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 26 - 305: dog - cat || Loss: 1.1136107444763184\n",
      "tensor([0., 1.]) tensor([0.8003, 0.1997], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 26 - 306: dog - cat || Loss: 1.113124132156372\n",
      "tensor([0., 1.]) tensor([0.7999, 0.2001], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 26 - 307: dog - cat || Loss: 1.1126362085342407\n",
      "tensor([0., 1.]) tensor([0.7994, 0.2006], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 26 - 308: dog - cat || Loss: 1.1121478080749512\n",
      "tensor([0., 1.]) tensor([0.7989, 0.2011], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 26 - 309: dog - cat || Loss: 1.1116582155227661\n",
      "tensor([0., 1.]) tensor([0.7984, 0.2016], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 26 - 310: dog - cat || Loss: 1.1111679077148438\n",
      "tensor([0., 1.]) tensor([0.7979, 0.2021], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 26 - 311: dog - cat || Loss: 1.1106765270233154\n",
      "tensor([0., 1.]) tensor([0.7974, 0.2026], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 26 - 312: dog - cat || Loss: 1.1101843118667603\n",
      "tensor([0., 1.]) tensor([0.7969, 0.2031], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 26 - 313: dog - cat || Loss: 1.1096912622451782\n",
      "tensor([0., 1.]) tensor([0.7964, 0.2036], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 26 - 314: dog - cat || Loss: 1.1091972589492798\n",
      "tensor([0., 1.]) tensor([0.7959, 0.2041], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 26 - 315: dog - cat || Loss: 1.1087024211883545\n",
      "tensor([0., 1.]) tensor([0.7954, 0.2046], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 26 - 316: dog - cat || Loss: 1.1082065105438232\n",
      "tensor([0., 1.]) tensor([0.7949, 0.2051], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 26 - 317: dog - cat || Loss: 1.1077097654342651\n",
      "tensor([0., 1.]) tensor([0.7944, 0.2056], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 26 - 318: dog - cat || Loss: 1.1072121858596802\n",
      "tensor([0., 1.]) tensor([0.7940, 0.2060], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 26 - 319: dog - cat || Loss: 1.1067136526107788\n",
      "tensor([0., 1.]) tensor([0.7935, 0.2065], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 26 - 320: dog - cat || Loss: 1.106214165687561\n",
      "tensor([0., 1.]) tensor([0.7930, 0.2070], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 26 - 321: dog - cat || Loss: 1.1057137250900269\n",
      "tensor([0., 1.]) tensor([0.7925, 0.2075], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 26 - 322: dog - cat || Loss: 1.1052125692367554\n",
      "tensor([0., 1.]) tensor([0.7920, 0.2080], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 26 - 323: dog - cat || Loss: 1.1047104597091675\n",
      "tensor([0., 1.]) tensor([0.7914, 0.2086], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 26 - 324: dog - cat || Loss: 1.1042073965072632\n",
      "tensor([0., 1.]) tensor([0.7909, 0.2091], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 26 - 325: dog - cat || Loss: 1.1037033796310425\n",
      "tensor([0., 1.]) tensor([0.7904, 0.2096], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 26 - 326: dog - cat || Loss: 1.1031984090805054\n",
      "tensor([0., 1.]) tensor([0.7899, 0.2101], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 26 - 327: dog - cat || Loss: 1.1026926040649414\n",
      "tensor([0., 1.]) tensor([0.7894, 0.2106], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 26 - 328: dog - cat || Loss: 1.1021859645843506\n",
      "tensor([0., 1.]) tensor([0.7889, 0.2111], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 26 - 329: dog - cat || Loss: 1.1016783714294434\n",
      "tensor([0., 1.]) tensor([0.7884, 0.2116], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 26 - 330: dog - cat || Loss: 1.1011698246002197\n",
      "tensor([0., 1.]) tensor([0.7879, 0.2121], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 26 - 331: dog - cat || Loss: 1.1006603240966797\n",
      "tensor([0., 1.]) tensor([0.7874, 0.2126], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 26 - 332: dog - cat || Loss: 1.1001501083374023\n",
      "tensor([0., 1.]) tensor([0.7869, 0.2131], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 26 - 333: dog - cat || Loss: 1.0996387004852295\n",
      "tensor([0., 1.]) tensor([0.7864, 0.2136], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 26 - 334: dog - cat || Loss: 1.0991264581680298\n",
      "tensor([0., 1.]) tensor([0.7859, 0.2141], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 26 - 335: dog - cat || Loss: 1.0986135005950928\n",
      "tensor([0., 1.]) tensor([0.7854, 0.2146], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 26 - 336: dog - cat || Loss: 1.0980995893478394\n",
      "tensor([0., 1.]) tensor([0.7848, 0.2152], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 26 - 337: dog - cat || Loss: 1.09758460521698\n",
      "tensor([0., 1.]) tensor([0.7843, 0.2157], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 26 - 338: dog - cat || Loss: 1.0970689058303833\n",
      "tensor([0., 1.]) tensor([0.7838, 0.2162], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 26 - 339: dog - cat || Loss: 1.0965521335601807\n",
      "tensor([0., 1.]) tensor([0.7833, 0.2167], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 26 - 340: dog - cat || Loss: 1.0960345268249512\n",
      "tensor([0., 1.]) tensor([0.7828, 0.2172], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 26 - 341: dog - cat || Loss: 1.0955160856246948\n",
      "tensor([0., 1.]) tensor([0.7823, 0.2177], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 26 - 342: dog - cat || Loss: 1.094996690750122\n",
      "tensor([0., 1.]) tensor([0.7817, 0.2183], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 26 - 343: dog - cat || Loss: 1.094476342201233\n",
      "tensor([0., 1.]) tensor([0.7812, 0.2188], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 26 - 344: dog - cat || Loss: 1.0939552783966064\n",
      "tensor([0., 1.]) tensor([0.7807, 0.2193], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 26 - 345: dog - cat || Loss: 1.0934330224990845\n",
      "tensor([0., 1.]) tensor([0.7802, 0.2198], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 26 - 346: dog - cat || Loss: 1.0929100513458252\n",
      "tensor([0., 1.]) tensor([0.7796, 0.2204], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 26 - 347: dog - cat || Loss: 1.092386245727539\n",
      "tensor([0., 1.]) tensor([0.7791, 0.2209], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 26 - 348: dog - cat || Loss: 1.0918612480163574\n",
      "tensor([0., 1.]) tensor([0.7786, 0.2214], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 26 - 349: dog - cat || Loss: 1.091335654258728\n",
      "tensor([0., 1.]) tensor([0.7781, 0.2219], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 26 - 350: dog - cat || Loss: 1.0908091068267822\n",
      "tensor([0., 1.]) tensor([0.7775, 0.2225], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 26 - 351: dog - cat || Loss: 1.0902817249298096\n",
      "tensor([0., 1.]) tensor([0.7770, 0.2230], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 26 - 352: dog - cat || Loss: 1.0897531509399414\n",
      "tensor([0., 1.]) tensor([0.7765, 0.2235], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 26 - 353: dog - cat || Loss: 1.089223861694336\n",
      "tensor([0., 1.]) tensor([0.7760, 0.2240], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 26 - 354: dog - cat || Loss: 1.088693618774414\n",
      "tensor([0., 1.]) tensor([0.7754, 0.2246], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 26 - 355: dog - cat || Loss: 1.0881625413894653\n",
      "tensor([0., 1.]) tensor([0.7749, 0.2251], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 26 - 356: dog - cat || Loss: 1.0876306295394897\n",
      "tensor([0., 1.]) tensor([0.7744, 0.2256], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 26 - 357: dog - cat || Loss: 1.0870975255966187\n",
      "tensor([0., 1.]) tensor([0.7738, 0.2262], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 26 - 358: dog - cat || Loss: 1.0865639448165894\n",
      "tensor([0., 1.]) tensor([0.7733, 0.2267], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 26 - 359: dog - cat || Loss: 1.0860291719436646\n",
      "tensor([0., 1.]) tensor([0.7728, 0.2272], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 26 - 360: dog - cat || Loss: 1.085493564605713\n",
      "tensor([0., 1.]) tensor([0.7722, 0.2278], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 26 - 361: dog - cat || Loss: 1.0849570035934448\n",
      "tensor([0., 1.]) tensor([0.7717, 0.2283], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 26 - 362: dog - cat || Loss: 1.0844197273254395\n",
      "tensor([0., 1.]) tensor([0.7712, 0.2288], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 26 - 363: dog - cat || Loss: 1.0838814973831177\n",
      "tensor([0., 1.]) tensor([0.7706, 0.2294], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 26 - 364: dog - cat || Loss: 1.0833420753479004\n",
      "tensor([0., 1.]) tensor([0.7701, 0.2299], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 26 - 365: dog - cat || Loss: 1.0828020572662354\n",
      "tensor([0., 1.]) tensor([0.7695, 0.2305], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 26 - 366: dog - cat || Loss: 1.0822609663009644\n",
      "tensor([0., 1.]) tensor([0.7690, 0.2310], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 26 - 367: dog - cat || Loss: 1.081719160079956\n",
      "tensor([0., 1.]) tensor([0.7685, 0.2315], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 26 - 368: dog - cat || Loss: 1.0811764001846313\n",
      "tensor([0., 1.]) tensor([0.7679, 0.2321], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 26 - 369: dog - cat || Loss: 1.0806324481964111\n",
      "tensor([0., 1.]) tensor([0.7674, 0.2326], grad_fn=<SoftmaxBackward0>)\n",
      "=====epoch:27=====\n",
      "Epoch 27 - 0: cat - cat || Loss: 0.5464353561401367\n",
      "tensor([1., 0.]) tensor([0.7668, 0.2332], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 27 - 1: cat - cat || Loss: 0.5468709468841553\n",
      "tensor([1., 0.]) tensor([0.7664, 0.2336], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 27 - 2: cat - cat || Loss: 0.5472081303596497\n",
      "tensor([1., 0.]) tensor([0.7661, 0.2339], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 27 - 3: cat - cat || Loss: 0.5474566221237183\n",
      "tensor([1., 0.]) tensor([0.7658, 0.2342], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 27 - 4: cat - cat || Loss: 0.5476251840591431\n",
      "tensor([1., 0.]) tensor([0.7656, 0.2344], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 27 - 5: cat - cat || Loss: 0.5477218627929688\n",
      "tensor([1., 0.]) tensor([0.7655, 0.2345], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 27 - 6: cat - cat || Loss: 0.547753632068634\n",
      "tensor([1., 0.]) tensor([0.7655, 0.2345], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 27 - 7: cat - cat || Loss: 0.5477270483970642\n",
      "tensor([1., 0.]) tensor([0.7655, 0.2345], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 27 - 8: cat - cat || Loss: 0.5476480722427368\n",
      "tensor([1., 0.]) tensor([0.7656, 0.2344], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 27 - 9: cat - cat || Loss: 0.5475217700004578\n",
      "tensor([1., 0.]) tensor([0.7657, 0.2343], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 27 - 10: cat - cat || Loss: 0.5473529100418091\n",
      "tensor([1., 0.]) tensor([0.7659, 0.2341], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 27 - 11: cat - cat || Loss: 0.547146201133728\n",
      "tensor([1., 0.]) tensor([0.7661, 0.2339], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 27 - 12: cat - cat || Loss: 0.546904981136322\n",
      "tensor([1., 0.]) tensor([0.7664, 0.2336], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 27 - 13: cat - cat || Loss: 0.5466331243515015\n",
      "tensor([1., 0.]) tensor([0.7666, 0.2334], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 27 - 14: cat - cat || Loss: 0.5463334321975708\n",
      "tensor([1., 0.]) tensor([0.7669, 0.2331], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 27 - 15: cat - cat || Loss: 0.5460091233253479\n",
      "tensor([1., 0.]) tensor([0.7673, 0.2327], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 27 - 16: cat - cat || Loss: 0.545662522315979\n",
      "tensor([1., 0.]) tensor([0.7676, 0.2324], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 27 - 17: cat - cat || Loss: 0.5452958941459656\n",
      "tensor([1., 0.]) tensor([0.7680, 0.2320], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 27 - 18: cat - cat || Loss: 0.5449115037918091\n",
      "tensor([1., 0.]) tensor([0.7684, 0.2316], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 27 - 19: cat - cat || Loss: 0.5445111393928528\n",
      "tensor([1., 0.]) tensor([0.7688, 0.2312], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 27 - 20: cat - cat || Loss: 0.5440962910652161\n",
      "tensor([1., 0.]) tensor([0.7692, 0.2308], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 27 - 21: cat - cat || Loss: 0.5436688661575317\n",
      "tensor([1., 0.]) tensor([0.7696, 0.2304], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 27 - 22: cat - cat || Loss: 0.543229877948761\n",
      "tensor([1., 0.]) tensor([0.7700, 0.2300], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 27 - 23: cat - cat || Loss: 0.5427807569503784\n",
      "tensor([1., 0.]) tensor([0.7705, 0.2295], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 27 - 24: cat - cat || Loss: 0.5423225164413452\n",
      "tensor([1., 0.]) tensor([0.7709, 0.2291], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 27 - 25: cat - cat || Loss: 0.5418562293052673\n",
      "tensor([1., 0.]) tensor([0.7714, 0.2286], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 27 - 26: cat - cat || Loss: 0.5413827896118164\n",
      "tensor([1., 0.]) tensor([0.7719, 0.2281], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 27 - 27: cat - cat || Loss: 0.5409030318260193\n",
      "tensor([1., 0.]) tensor([0.7724, 0.2276], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 27 - 28: cat - cat || Loss: 0.5404175519943237\n",
      "tensor([1., 0.]) tensor([0.7728, 0.2272], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 27 - 29: cat - cat || Loss: 0.5399271249771118\n",
      "tensor([1., 0.]) tensor([0.7733, 0.2267], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 27 - 30: cat - cat || Loss: 0.5394322872161865\n",
      "tensor([1., 0.]) tensor([0.7738, 0.2262], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 27 - 31: cat - cat || Loss: 0.5389335751533508\n",
      "tensor([1., 0.]) tensor([0.7743, 0.2257], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 27 - 32: cat - cat || Loss: 0.5384314060211182\n",
      "tensor([1., 0.]) tensor([0.7748, 0.2252], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 27 - 33: cat - cat || Loss: 0.537926435470581\n",
      "tensor([1., 0.]) tensor([0.7753, 0.2247], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 27 - 34: cat - cat || Loss: 0.537418782711029\n",
      "tensor([1., 0.]) tensor([0.7758, 0.2242], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 27 - 35: cat - cat || Loss: 0.5369088649749756\n",
      "tensor([1., 0.]) tensor([0.7764, 0.2236], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 27 - 36: cat - cat || Loss: 0.5363971590995789\n",
      "tensor([1., 0.]) tensor([0.7769, 0.2231], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 27 - 37: cat - cat || Loss: 0.5358837842941284\n",
      "tensor([1., 0.]) tensor([0.7774, 0.2226], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 27 - 38: cat - cat || Loss: 0.5353689789772034\n",
      "tensor([1., 0.]) tensor([0.7779, 0.2221], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 27 - 39: cat - cat || Loss: 0.5348531007766724\n",
      "tensor([1., 0.]) tensor([0.7784, 0.2216], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 27 - 40: cat - cat || Loss: 0.5343363881111145\n",
      "tensor([1., 0.]) tensor([0.7789, 0.2211], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 27 - 41: cat - cat || Loss: 0.533818781375885\n",
      "tensor([1., 0.]) tensor([0.7794, 0.2206], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 27 - 42: cat - cat || Loss: 0.5333006978034973\n",
      "tensor([1., 0.]) tensor([0.7800, 0.2200], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 27 - 43: cat - cat || Loss: 0.5327821373939514\n",
      "tensor([1., 0.]) tensor([0.7805, 0.2195], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 27 - 44: cat - cat || Loss: 0.5322633981704712\n",
      "tensor([1., 0.]) tensor([0.7810, 0.2190], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 27 - 45: cat - cat || Loss: 0.5317443013191223\n",
      "tensor([1., 0.]) tensor([0.7815, 0.2185], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 27 - 46: cat - cat || Loss: 0.5312252640724182\n",
      "tensor([1., 0.]) tensor([0.7820, 0.2180], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 27 - 47: cat - cat || Loss: 0.5307062864303589\n",
      "tensor([1., 0.]) tensor([0.7826, 0.2174], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 27 - 48: cat - cat || Loss: 0.5301874279975891\n",
      "tensor([1., 0.]) tensor([0.7831, 0.2169], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 27 - 49: cat - cat || Loss: 0.5296687483787537\n",
      "tensor([1., 0.]) tensor([0.7836, 0.2164], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 27 - 50: cat - cat || Loss: 0.5291504263877869\n",
      "tensor([1., 0.]) tensor([0.7841, 0.2159], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 27 - 51: cat - cat || Loss: 0.5286325216293335\n",
      "tensor([1., 0.]) tensor([0.7846, 0.2154], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 27 - 52: cat - cat || Loss: 0.528114914894104\n",
      "tensor([1., 0.]) tensor([0.7851, 0.2149], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 27 - 53: cat - cat || Loss: 0.5275979042053223\n",
      "tensor([1., 0.]) tensor([0.7857, 0.2143], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 27 - 54: cat - cat || Loss: 0.527081310749054\n",
      "tensor([1., 0.]) tensor([0.7862, 0.2138], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 27 - 55: cat - cat || Loss: 0.5265653133392334\n",
      "tensor([1., 0.]) tensor([0.7867, 0.2133], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 27 - 56: cat - cat || Loss: 0.5260498523712158\n",
      "tensor([1., 0.]) tensor([0.7872, 0.2128], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 27 - 57: cat - cat || Loss: 0.5255350470542908\n",
      "tensor([1., 0.]) tensor([0.7877, 0.2123], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 27 - 58: cat - cat || Loss: 0.525020956993103\n",
      "tensor([1., 0.]) tensor([0.7882, 0.2118], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 27 - 59: cat - cat || Loss: 0.5245075821876526\n",
      "tensor([1., 0.]) tensor([0.7888, 0.2112], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 27 - 60: cat - cat || Loss: 0.5239948034286499\n",
      "tensor([1., 0.]) tensor([0.7893, 0.2107], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 27 - 61: cat - cat || Loss: 0.5234827995300293\n",
      "tensor([1., 0.]) tensor([0.7898, 0.2102], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 27 - 62: cat - cat || Loss: 0.5229715704917908\n",
      "tensor([1., 0.]) tensor([0.7903, 0.2097], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 27 - 63: cat - cat || Loss: 0.5224611759185791\n",
      "tensor([1., 0.]) tensor([0.7908, 0.2092], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 27 - 64: cat - cat || Loss: 0.5219516158103943\n",
      "tensor([1., 0.]) tensor([0.7913, 0.2087], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 27 - 65: cat - cat || Loss: 0.521442711353302\n",
      "tensor([1., 0.]) tensor([0.7918, 0.2082], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 27 - 66: cat - cat || Loss: 0.5209347009658813\n",
      "tensor([1., 0.]) tensor([0.7923, 0.2077], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 27 - 67: cat - cat || Loss: 0.5204275846481323\n",
      "tensor([1., 0.]) tensor([0.7928, 0.2072], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 27 - 68: cat - cat || Loss: 0.5199211835861206\n",
      "tensor([1., 0.]) tensor([0.7933, 0.2067], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 27 - 69: cat - cat || Loss: 0.5194156765937805\n",
      "tensor([1., 0.]) tensor([0.7938, 0.2062], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 27 - 70: cat - cat || Loss: 0.5189111232757568\n",
      "tensor([1., 0.]) tensor([0.7944, 0.2056], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 27 - 71: cat - cat || Loss: 0.51840740442276\n",
      "tensor([1., 0.]) tensor([0.7949, 0.2051], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 27 - 72: cat - cat || Loss: 0.5179044604301453\n",
      "tensor([1., 0.]) tensor([0.7954, 0.2046], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 27 - 73: cat - cat || Loss: 0.5174024105072021\n",
      "tensor([1., 0.]) tensor([0.7959, 0.2041], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 27 - 74: cat - cat || Loss: 0.5169013142585754\n",
      "tensor([1., 0.]) tensor([0.7964, 0.2036], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 27 - 75: cat - cat || Loss: 0.5164012908935547\n",
      "tensor([1., 0.]) tensor([0.7969, 0.2031], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 27 - 76: cat - cat || Loss: 0.5159019231796265\n",
      "tensor([1., 0.]) tensor([0.7974, 0.2026], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 27 - 77: cat - cat || Loss: 0.5154035091400146\n",
      "tensor([1., 0.]) tensor([0.7979, 0.2021], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 27 - 78: cat - cat || Loss: 0.5149060487747192\n",
      "tensor([1., 0.]) tensor([0.7984, 0.2016], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 27 - 79: cat - cat || Loss: 0.5144094824790955\n",
      "tensor([1., 0.]) tensor([0.7989, 0.2011], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 27 - 80: cat - cat || Loss: 0.5139137506484985\n",
      "tensor([1., 0.]) tensor([0.7993, 0.2007], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 27 - 81: cat - cat || Loss: 0.513418972492218\n",
      "tensor([1., 0.]) tensor([0.7998, 0.2002], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 27 - 82: cat - cat || Loss: 0.5129251480102539\n",
      "tensor([1., 0.]) tensor([0.8003, 0.1997], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 27 - 83: cat - cat || Loss: 0.512432336807251\n",
      "tensor([1., 0.]) tensor([0.8008, 0.1992], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 27 - 84: cat - cat || Loss: 0.5119403004646301\n",
      "tensor([1., 0.]) tensor([0.8013, 0.1987], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 27 - 85: cat - cat || Loss: 0.5114492177963257\n",
      "tensor([1., 0.]) tensor([0.8018, 0.1982], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 27 - 86: cat - cat || Loss: 0.5109591484069824\n",
      "tensor([1., 0.]) tensor([0.8023, 0.1977], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 27 - 87: cat - cat || Loss: 0.510469913482666\n",
      "tensor([1., 0.]) tensor([0.8028, 0.1972], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 27 - 88: cat - cat || Loss: 0.509981632232666\n",
      "tensor([1., 0.]) tensor([0.8033, 0.1967], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 27 - 89: cat - cat || Loss: 0.5094943046569824\n",
      "tensor([1., 0.]) tensor([0.8038, 0.1962], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 27 - 90: cat - cat || Loss: 0.5090079307556152\n",
      "tensor([1., 0.]) tensor([0.8043, 0.1957], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 27 - 91: cat - cat || Loss: 0.5085223913192749\n",
      "tensor([1., 0.]) tensor([0.8047, 0.1953], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 27 - 92: cat - cat || Loss: 0.5080379247665405\n",
      "tensor([1., 0.]) tensor([0.8052, 0.1948], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 27 - 93: cat - cat || Loss: 0.507554292678833\n",
      "tensor([1., 0.]) tensor([0.8057, 0.1943], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 27 - 94: cat - cat || Loss: 0.5070716142654419\n",
      "tensor([1., 0.]) tensor([0.8062, 0.1938], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 27 - 95: cat - cat || Loss: 0.5065897703170776\n",
      "tensor([1., 0.]) tensor([0.8067, 0.1933], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 27 - 96: cat - cat || Loss: 0.5061089992523193\n",
      "tensor([1., 0.]) tensor([0.8072, 0.1928], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 27 - 97: cat - cat || Loss: 0.5056291818618774\n",
      "tensor([1., 0.]) tensor([0.8076, 0.1924], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 27 - 98: cat - cat || Loss: 0.5051501989364624\n",
      "tensor([1., 0.]) tensor([0.8081, 0.1919], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 27 - 99: cat - cat || Loss: 0.5046723484992981\n",
      "tensor([1., 0.]) tensor([0.8086, 0.1914], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 27 - 100: cat - cat || Loss: 0.5041952133178711\n",
      "tensor([1., 0.]) tensor([0.8091, 0.1909], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 27 - 101: cat - cat || Loss: 0.5037190914154053\n",
      "tensor([1., 0.]) tensor([0.8095, 0.1905], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 27 - 102: cat - cat || Loss: 0.5032440423965454\n",
      "tensor([1., 0.]) tensor([0.8100, 0.1900], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 27 - 103: cat - cat || Loss: 0.5027697086334229\n",
      "tensor([1., 0.]) tensor([0.8105, 0.1895], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 27 - 104: cat - cat || Loss: 0.5022963881492615\n",
      "tensor([1., 0.]) tensor([0.8110, 0.1890], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 27 - 105: cat - cat || Loss: 0.5018240213394165\n",
      "tensor([1., 0.]) tensor([0.8114, 0.1886], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 27 - 106: cat - cat || Loss: 0.5013526082038879\n",
      "tensor([1., 0.]) tensor([0.8119, 0.1881], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 27 - 107: cat - cat || Loss: 0.500882089138031\n",
      "tensor([1., 0.]) tensor([0.8124, 0.1876], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 27 - 108: cat - cat || Loss: 0.5004125237464905\n",
      "tensor([1., 0.]) tensor([0.8128, 0.1872], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 27 - 109: cat - cat || Loss: 0.49994391202926636\n",
      "tensor([1., 0.]) tensor([0.8133, 0.1867], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 27 - 110: cat - cat || Loss: 0.49947622418403625\n",
      "tensor([1., 0.]) tensor([0.8138, 0.1862], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 27 - 111: cat - cat || Loss: 0.49900954961776733\n",
      "tensor([1., 0.]) tensor([0.8143, 0.1857], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 27 - 112: cat - cat || Loss: 0.4985436797142029\n",
      "tensor([1., 0.]) tensor([0.8147, 0.1853], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 27 - 113: cat - cat || Loss: 0.4980788826942444\n",
      "tensor([1., 0.]) tensor([0.8152, 0.1848], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 27 - 114: cat - cat || Loss: 0.49761486053466797\n",
      "tensor([1., 0.]) tensor([0.8156, 0.1844], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 27 - 115: cat - cat || Loss: 0.4971519410610199\n",
      "tensor([1., 0.]) tensor([0.8161, 0.1839], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 27 - 116: cat - cat || Loss: 0.4966898560523987\n",
      "tensor([1., 0.]) tensor([0.8166, 0.1834], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 27 - 117: cat - cat || Loss: 0.4962286949157715\n",
      "tensor([1., 0.]) tensor([0.8170, 0.1830], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 27 - 118: cat - cat || Loss: 0.49576857686042786\n",
      "tensor([1., 0.]) tensor([0.8175, 0.1825], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 27 - 119: cat - cat || Loss: 0.49530938267707825\n",
      "tensor([1., 0.]) tensor([0.8180, 0.1820], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 27 - 120: cat - cat || Loss: 0.4948509931564331\n",
      "tensor([1., 0.]) tensor([0.8184, 0.1816], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 27 - 121: cat - cat || Loss: 0.49439364671707153\n",
      "tensor([1., 0.]) tensor([0.8189, 0.1811], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 27 - 122: cat - cat || Loss: 0.49393725395202637\n",
      "tensor([1., 0.]) tensor([0.8193, 0.1807], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 27 - 123: cat - cat || Loss: 0.4934818148612976\n",
      "tensor([1., 0.]) tensor([0.8198, 0.1802], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 27 - 124: cat - cat || Loss: 0.4930272102355957\n",
      "tensor([1., 0.]) tensor([0.8202, 0.1798], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 27 - 125: cat - cat || Loss: 0.492573618888855\n",
      "tensor([1., 0.]) tensor([0.8207, 0.1793], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 27 - 126: cat - cat || Loss: 0.4921209514141083\n",
      "tensor([1., 0.]) tensor([0.8211, 0.1789], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 27 - 127: cat - cat || Loss: 0.49166905879974365\n",
      "tensor([1., 0.]) tensor([0.8216, 0.1784], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 27 - 128: cat - cat || Loss: 0.4912182688713074\n",
      "tensor([1., 0.]) tensor([0.8220, 0.1780], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 27 - 129: cat - cat || Loss: 0.4907684028148651\n",
      "tensor([1., 0.]) tensor([0.8225, 0.1775], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 27 - 130: cat - cat || Loss: 0.4903194308280945\n",
      "tensor([1., 0.]) tensor([0.8229, 0.1771], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 27 - 131: cat - cat || Loss: 0.48987138271331787\n",
      "tensor([1., 0.]) tensor([0.8234, 0.1766], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 27 - 132: cat - cat || Loss: 0.4894242584705353\n",
      "tensor([1., 0.]) tensor([0.8238, 0.1762], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 27 - 133: cat - cat || Loss: 0.48897817730903625\n",
      "tensor([1., 0.]) tensor([0.8243, 0.1757], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 27 - 134: cat - cat || Loss: 0.48853278160095215\n",
      "tensor([1., 0.]) tensor([0.8247, 0.1753], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 27 - 135: cat - cat || Loss: 0.48808857798576355\n",
      "tensor([1., 0.]) tensor([0.8252, 0.1748], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 27 - 136: cat - cat || Loss: 0.4876452088356018\n",
      "tensor([1., 0.]) tensor([0.8256, 0.1744], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 27 - 137: cat - cat || Loss: 0.48720264434814453\n",
      "tensor([1., 0.]) tensor([0.8261, 0.1739], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 27 - 138: cat - cat || Loss: 0.4867611527442932\n",
      "tensor([1., 0.]) tensor([0.8265, 0.1735], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 27 - 139: cat - cat || Loss: 0.4863205850124359\n",
      "tensor([1., 0.]) tensor([0.8269, 0.1731], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 27 - 140: cat - cat || Loss: 0.48588091135025024\n",
      "tensor([1., 0.]) tensor([0.8274, 0.1726], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 27 - 141: cat - cat || Loss: 0.48544207215309143\n",
      "tensor([1., 0.]) tensor([0.8278, 0.1722], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 27 - 142: cat - cat || Loss: 0.4850043058395386\n",
      "tensor([1., 0.]) tensor([0.8283, 0.1717], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 27 - 143: cat - cat || Loss: 0.4845672845840454\n",
      "tensor([1., 0.]) tensor([0.8287, 0.1713], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 27 - 144: cat - cat || Loss: 0.484131395816803\n",
      "tensor([1., 0.]) tensor([0.8291, 0.1709], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 27 - 145: cat - cat || Loss: 0.483696311712265\n",
      "tensor([1., 0.]) tensor([0.8296, 0.1704], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 27 - 146: cat - cat || Loss: 0.48326218128204346\n",
      "tensor([1., 0.]) tensor([0.8300, 0.1700], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 27 - 147: cat - cat || Loss: 0.4828290045261383\n",
      "tensor([1., 0.]) tensor([0.8304, 0.1696], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 27 - 148: cat - cat || Loss: 0.48239666223526\n",
      "tensor([1., 0.]) tensor([0.8309, 0.1691], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 27 - 149: cat - cat || Loss: 0.48196524381637573\n",
      "tensor([1., 0.]) tensor([0.8313, 0.1687], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 27 - 150: cat - cat || Loss: 0.48153477907180786\n",
      "tensor([1., 0.]) tensor([0.8317, 0.1683], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 27 - 151: cat - cat || Loss: 0.4811052680015564\n",
      "tensor([1., 0.]) tensor([0.8322, 0.1678], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 27 - 152: cat - cat || Loss: 0.48067665100097656\n",
      "tensor([1., 0.]) tensor([0.8326, 0.1674], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 27 - 153: cat - cat || Loss: 0.4802488684654236\n",
      "tensor([1., 0.]) tensor([0.8330, 0.1670], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 27 - 154: cat - cat || Loss: 0.4798220992088318\n",
      "tensor([1., 0.]) tensor([0.8334, 0.1666], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 27 - 155: cat - cat || Loss: 0.4793962240219116\n",
      "tensor([1., 0.]) tensor([0.8339, 0.1661], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 27 - 156: cat - cat || Loss: 0.47897130250930786\n",
      "tensor([1., 0.]) tensor([0.8343, 0.1657], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 27 - 157: cat - cat || Loss: 0.47854727506637573\n",
      "tensor([1., 0.]) tensor([0.8347, 0.1653], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 27 - 158: cat - cat || Loss: 0.47812408208847046\n",
      "tensor([1., 0.]) tensor([0.8351, 0.1649], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 27 - 159: cat - cat || Loss: 0.4777017831802368\n",
      "tensor([1., 0.]) tensor([0.8356, 0.1644], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 27 - 160: cat - cat || Loss: 0.47728049755096436\n",
      "tensor([1., 0.]) tensor([0.8360, 0.1640], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 27 - 161: cat - cat || Loss: 0.4768601655960083\n",
      "tensor([1., 0.]) tensor([0.8364, 0.1636], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 27 - 162: cat - cat || Loss: 0.4764407277107239\n",
      "tensor([1., 0.]) tensor([0.8368, 0.1632], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 27 - 163: cat - cat || Loss: 0.47602200508117676\n",
      "tensor([1., 0.]) tensor([0.8372, 0.1628], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 27 - 164: cat - cat || Loss: 0.47560441493988037\n",
      "tensor([1., 0.]) tensor([0.8377, 0.1623], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 27 - 165: cat - cat || Loss: 0.4751877188682556\n",
      "tensor([1., 0.]) tensor([0.8381, 0.1619], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 27 - 166: cat - cat || Loss: 0.47477176785469055\n",
      "tensor([1., 0.]) tensor([0.8385, 0.1615], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 27 - 167: cat - cat || Loss: 0.47435685992240906\n",
      "tensor([1., 0.]) tensor([0.8389, 0.1611], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 27 - 168: cat - cat || Loss: 0.47394293546676636\n",
      "tensor([1., 0.]) tensor([0.8393, 0.1607], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 27 - 169: cat - cat || Loss: 0.47352975606918335\n",
      "tensor([1., 0.]) tensor([0.8397, 0.1603], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 27 - 170: cat - cat || Loss: 0.4731176495552063\n",
      "tensor([1., 0.]) tensor([0.8401, 0.1599], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 27 - 171: cat - cat || Loss: 0.4727063775062561\n",
      "tensor([1., 0.]) tensor([0.8406, 0.1594], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 27 - 172: cat - cat || Loss: 0.47229599952697754\n",
      "tensor([1., 0.]) tensor([0.8410, 0.1590], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 27 - 173: cat - cat || Loss: 0.4718865752220154\n",
      "tensor([1., 0.]) tensor([0.8414, 0.1586], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 27 - 174: cat - cat || Loss: 0.47147801518440247\n",
      "tensor([1., 0.]) tensor([0.8418, 0.1582], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 27 - 175: cat - cat || Loss: 0.4710703492164612\n",
      "tensor([1., 0.]) tensor([0.8422, 0.1578], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 27 - 176: cat - cat || Loss: 0.4706636071205139\n",
      "tensor([1., 0.]) tensor([0.8426, 0.1574], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 27 - 177: cat - cat || Loss: 0.4702579379081726\n",
      "tensor([1., 0.]) tensor([0.8430, 0.1570], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 27 - 178: cat - cat || Loss: 0.469853013753891\n",
      "tensor([1., 0.]) tensor([0.8434, 0.1566], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 27 - 179: cat - cat || Loss: 0.46944910287857056\n",
      "tensor([1., 0.]) tensor([0.8438, 0.1562], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 27 - 180: cat - cat || Loss: 0.4690459370613098\n",
      "tensor([1., 0.]) tensor([0.8442, 0.1558], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 27 - 181: cat - cat || Loss: 0.4686437249183655\n",
      "tensor([1., 0.]) tensor([0.8446, 0.1554], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 27 - 182: cat - cat || Loss: 0.46824246644973755\n",
      "tensor([1., 0.]) tensor([0.8450, 0.1550], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 27 - 183: cat - cat || Loss: 0.4678422212600708\n",
      "tensor([1., 0.]) tensor([0.8454, 0.1546], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 27 - 184: cat - cat || Loss: 0.46744269132614136\n",
      "tensor([1., 0.]) tensor([0.8458, 0.1542], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 27 - 185: cat - cat || Loss: 0.4670441150665283\n",
      "tensor([1., 0.]) tensor([0.8462, 0.1538], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 27 - 186: cat - cat || Loss: 0.46664631366729736\n",
      "tensor([1., 0.]) tensor([0.8466, 0.1534], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 27 - 187: cat - cat || Loss: 0.4662494659423828\n",
      "tensor([1., 0.]) tensor([0.8470, 0.1530], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 27 - 188: cat - cat || Loss: 0.4658535122871399\n",
      "tensor([1., 0.]) tensor([0.8474, 0.1526], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 27 - 189: cat - cat || Loss: 0.4654584527015686\n",
      "tensor([1., 0.]) tensor([0.8478, 0.1522], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 27 - 190: dog - cat || Loss: 1.16145920753479\n",
      "tensor([0., 1.]) tensor([0.8482, 0.1518], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 27 - 191: dog - cat || Loss: 1.161774754524231\n",
      "tensor([0., 1.]) tensor([0.8485, 0.1515], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 27 - 192: dog - cat || Loss: 1.1620194911956787\n",
      "tensor([0., 1.]) tensor([0.8488, 0.1512], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 27 - 193: dog - cat || Loss: 1.1622008085250854\n",
      "tensor([0., 1.]) tensor([0.8489, 0.1511], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 27 - 194: dog - cat || Loss: 1.1623250246047974\n",
      "tensor([0., 1.]) tensor([0.8491, 0.1509], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 27 - 195: dog - cat || Loss: 1.1623982191085815\n",
      "tensor([0., 1.]) tensor([0.8491, 0.1509], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 27 - 196: dog - cat || Loss: 1.1624250411987305\n",
      "tensor([0., 1.]) tensor([0.8492, 0.1508], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 27 - 197: dog - cat || Loss: 1.1624103784561157\n",
      "tensor([0., 1.]) tensor([0.8491, 0.1509], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 27 - 198: dog - cat || Loss: 1.1623586416244507\n",
      "tensor([0., 1.]) tensor([0.8491, 0.1509], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 27 - 199: dog - cat || Loss: 1.1622732877731323\n",
      "tensor([0., 1.]) tensor([0.8490, 0.1510], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 27 - 200: dog - cat || Loss: 1.1621575355529785\n",
      "tensor([0., 1.]) tensor([0.8489, 0.1511], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 27 - 201: dog - cat || Loss: 1.1620144844055176\n",
      "tensor([0., 1.]) tensor([0.8488, 0.1512], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 27 - 202: dog - cat || Loss: 1.1618467569351196\n",
      "tensor([0., 1.]) tensor([0.8486, 0.1514], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 27 - 203: dog - cat || Loss: 1.1616570949554443\n",
      "tensor([0., 1.]) tensor([0.8484, 0.1516], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 27 - 204: dog - cat || Loss: 1.1614471673965454\n",
      "tensor([0., 1.]) tensor([0.8482, 0.1518], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 27 - 205: dog - cat || Loss: 1.1612191200256348\n",
      "tensor([0., 1.]) tensor([0.8480, 0.1520], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 27 - 206: dog - cat || Loss: 1.1609747409820557\n",
      "tensor([0., 1.]) tensor([0.8477, 0.1523], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 27 - 207: dog - cat || Loss: 1.1607156991958618\n",
      "tensor([0., 1.]) tensor([0.8475, 0.1525], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 27 - 208: dog - cat || Loss: 1.1604431867599487\n",
      "tensor([0., 1.]) tensor([0.8472, 0.1528], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 27 - 209: dog - cat || Loss: 1.160158634185791\n",
      "tensor([0., 1.]) tensor([0.8469, 0.1531], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 27 - 210: dog - cat || Loss: 1.1598628759384155\n",
      "tensor([0., 1.]) tensor([0.8466, 0.1534], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 27 - 211: dog - cat || Loss: 1.1595574617385864\n",
      "tensor([0., 1.]) tensor([0.8463, 0.1537], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 27 - 212: dog - cat || Loss: 1.1592426300048828\n",
      "tensor([0., 1.]) tensor([0.8460, 0.1540], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 27 - 213: dog - cat || Loss: 1.1589195728302002\n",
      "tensor([0., 1.]) tensor([0.8457, 0.1543], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 27 - 214: dog - cat || Loss: 1.158589243888855\n",
      "tensor([0., 1.]) tensor([0.8453, 0.1547], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 27 - 215: dog - cat || Loss: 1.1582518815994263\n",
      "tensor([0., 1.]) tensor([0.8450, 0.1550], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 27 - 216: dog - cat || Loss: 1.1579084396362305\n",
      "tensor([0., 1.]) tensor([0.8446, 0.1554], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 27 - 217: dog - cat || Loss: 1.1575592756271362\n",
      "tensor([0., 1.]) tensor([0.8443, 0.1557], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 27 - 218: dog - cat || Loss: 1.1572047472000122\n",
      "tensor([0., 1.]) tensor([0.8439, 0.1561], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 27 - 219: dog - cat || Loss: 1.1568455696105957\n",
      "tensor([0., 1.]) tensor([0.8436, 0.1564], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 27 - 220: dog - cat || Loss: 1.1564819812774658\n",
      "tensor([0., 1.]) tensor([0.8432, 0.1568], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 27 - 221: dog - cat || Loss: 1.1561143398284912\n",
      "tensor([0., 1.]) tensor([0.8429, 0.1571], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 27 - 222: dog - cat || Loss: 1.15574312210083\n",
      "tensor([0., 1.]) tensor([0.8425, 0.1575], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 27 - 223: dog - cat || Loss: 1.1553683280944824\n",
      "tensor([0., 1.]) tensor([0.8421, 0.1579], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 27 - 224: dog - cat || Loss: 1.1549904346466064\n",
      "tensor([0., 1.]) tensor([0.8417, 0.1583], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 27 - 225: dog - cat || Loss: 1.1546095609664917\n",
      "tensor([0., 1.]) tensor([0.8413, 0.1587], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 27 - 226: dog - cat || Loss: 1.1542258262634277\n",
      "tensor([0., 1.]) tensor([0.8410, 0.1590], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 27 - 227: dog - cat || Loss: 1.1538395881652832\n",
      "tensor([0., 1.]) tensor([0.8406, 0.1594], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 27 - 228: dog - cat || Loss: 1.1534512042999268\n",
      "tensor([0., 1.]) tensor([0.8402, 0.1598], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 27 - 229: dog - cat || Loss: 1.1530604362487793\n",
      "tensor([0., 1.]) tensor([0.8398, 0.1602], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 27 - 230: dog - cat || Loss: 1.15266752243042\n",
      "tensor([0., 1.]) tensor([0.8394, 0.1606], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 27 - 231: dog - cat || Loss: 1.1522727012634277\n",
      "tensor([0., 1.]) tensor([0.8390, 0.1610], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 27 - 232: dog - cat || Loss: 1.1518760919570923\n",
      "tensor([0., 1.]) tensor([0.8386, 0.1614], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 27 - 233: dog - cat || Loss: 1.151477575302124\n",
      "tensor([0., 1.]) tensor([0.8382, 0.1618], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 27 - 234: dog - cat || Loss: 1.1510775089263916\n",
      "tensor([0., 1.]) tensor([0.8378, 0.1622], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 27 - 235: dog - cat || Loss: 1.1506757736206055\n",
      "tensor([0., 1.]) tensor([0.8374, 0.1626], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 27 - 236: dog - cat || Loss: 1.1502724885940552\n",
      "tensor([0., 1.]) tensor([0.8370, 0.1630], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 27 - 237: dog - cat || Loss: 1.1498678922653198\n",
      "tensor([0., 1.]) tensor([0.8366, 0.1634], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 27 - 238: dog - cat || Loss: 1.1494618654251099\n",
      "tensor([0., 1.]) tensor([0.8362, 0.1638], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 27 - 239: dog - cat || Loss: 1.1490542888641357\n",
      "tensor([0., 1.]) tensor([0.8358, 0.1642], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 27 - 240: dog - cat || Loss: 1.1486456394195557\n",
      "tensor([0., 1.]) tensor([0.8354, 0.1646], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 27 - 241: dog - cat || Loss: 1.148235559463501\n",
      "tensor([0., 1.]) tensor([0.8350, 0.1650], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 27 - 242: dog - cat || Loss: 1.1478244066238403\n",
      "tensor([0., 1.]) tensor([0.8346, 0.1654], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 27 - 243: dog - cat || Loss: 1.1474119424819946\n",
      "tensor([0., 1.]) tensor([0.8342, 0.1658], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 27 - 244: dog - cat || Loss: 1.1469982862472534\n",
      "tensor([0., 1.]) tensor([0.8337, 0.1663], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 27 - 245: dog - cat || Loss: 1.1465837955474854\n",
      "tensor([0., 1.]) tensor([0.8333, 0.1667], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 27 - 246: dog - cat || Loss: 1.1461681127548218\n",
      "tensor([0., 1.]) tensor([0.8329, 0.1671], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 27 - 247: dog - cat || Loss: 1.1457509994506836\n",
      "tensor([0., 1.]) tensor([0.8325, 0.1675], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 27 - 248: dog - cat || Loss: 1.145333170890808\n",
      "tensor([0., 1.]) tensor([0.8321, 0.1679], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 27 - 249: dog - cat || Loss: 1.144914150238037\n",
      "tensor([0., 1.]) tensor([0.8317, 0.1683], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 27 - 250: dog - cat || Loss: 1.1444942951202393\n",
      "tensor([0., 1.]) tensor([0.8312, 0.1688], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 27 - 251: dog - cat || Loss: 1.144073247909546\n",
      "tensor([0., 1.]) tensor([0.8308, 0.1692], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 27 - 252: dog - cat || Loss: 1.1436513662338257\n",
      "tensor([0., 1.]) tensor([0.8304, 0.1696], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 27 - 253: dog - cat || Loss: 1.14322829246521\n",
      "tensor([0., 1.]) tensor([0.8300, 0.1700], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 27 - 254: dog - cat || Loss: 1.1428042650222778\n",
      "tensor([0., 1.]) tensor([0.8295, 0.1705], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 27 - 255: dog - cat || Loss: 1.1423794031143188\n",
      "tensor([0., 1.]) tensor([0.8291, 0.1709], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 27 - 256: dog - cat || Loss: 1.141953468322754\n",
      "tensor([0., 1.]) tensor([0.8287, 0.1713], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 27 - 257: dog - cat || Loss: 1.1415268182754517\n",
      "tensor([0., 1.]) tensor([0.8283, 0.1717], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 27 - 258: dog - cat || Loss: 1.1410990953445435\n",
      "tensor([0., 1.]) tensor([0.8278, 0.1722], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 27 - 259: dog - cat || Loss: 1.1406702995300293\n",
      "tensor([0., 1.]) tensor([0.8274, 0.1726], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 27 - 260: dog - cat || Loss: 1.1402407884597778\n",
      "tensor([0., 1.]) tensor([0.8270, 0.1730], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 27 - 261: dog - cat || Loss: 1.1398102045059204\n",
      "tensor([0., 1.]) tensor([0.8265, 0.1735], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 27 - 262: dog - cat || Loss: 1.1393786668777466\n",
      "tensor([0., 1.]) tensor([0.8261, 0.1739], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 27 - 263: dog - cat || Loss: 1.1389461755752563\n",
      "tensor([0., 1.]) tensor([0.8257, 0.1743], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 27 - 264: dog - cat || Loss: 1.1385129690170288\n",
      "tensor([0., 1.]) tensor([0.8253, 0.1747], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 27 - 265: dog - cat || Loss: 1.1380784511566162\n",
      "tensor([0., 1.]) tensor([0.8248, 0.1752], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 27 - 266: dog - cat || Loss: 1.1376434564590454\n",
      "tensor([0., 1.]) tensor([0.8244, 0.1756], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 27 - 267: dog - cat || Loss: 1.1372075080871582\n",
      "tensor([0., 1.]) tensor([0.8239, 0.1761], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 27 - 268: dog - cat || Loss: 1.136770248413086\n",
      "tensor([0., 1.]) tensor([0.8235, 0.1765], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 27 - 269: dog - cat || Loss: 1.1363325119018555\n",
      "tensor([0., 1.]) tensor([0.8231, 0.1769], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 27 - 270: dog - cat || Loss: 1.135893702507019\n",
      "tensor([0., 1.]) tensor([0.8226, 0.1774], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 27 - 271: dog - cat || Loss: 1.1354539394378662\n",
      "tensor([0., 1.]) tensor([0.8222, 0.1778], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 27 - 272: dog - cat || Loss: 1.135013222694397\n",
      "tensor([0., 1.]) tensor([0.8218, 0.1782], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 27 - 273: dog - cat || Loss: 1.1345717906951904\n",
      "tensor([0., 1.]) tensor([0.8213, 0.1787], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 27 - 274: dog - cat || Loss: 1.1341294050216675\n",
      "tensor([0., 1.]) tensor([0.8209, 0.1791], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 27 - 275: dog - cat || Loss: 1.1336859464645386\n",
      "tensor([0., 1.]) tensor([0.8204, 0.1796], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 27 - 276: dog - cat || Loss: 1.1332417726516724\n",
      "tensor([0., 1.]) tensor([0.8200, 0.1800], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 27 - 277: dog - cat || Loss: 1.1327967643737793\n",
      "tensor([0., 1.]) tensor([0.8195, 0.1805], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 27 - 278: dog - cat || Loss: 1.1323506832122803\n",
      "tensor([0., 1.]) tensor([0.8191, 0.1809], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 27 - 279: dog - cat || Loss: 1.1319037675857544\n",
      "tensor([0., 1.]) tensor([0.8186, 0.1814], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 27 - 280: dog - cat || Loss: 1.131455898284912\n",
      "tensor([0., 1.]) tensor([0.8182, 0.1818], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 27 - 281: dog - cat || Loss: 1.131007194519043\n",
      "tensor([0., 1.]) tensor([0.8177, 0.1823], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 27 - 282: dog - cat || Loss: 1.130557656288147\n",
      "tensor([0., 1.]) tensor([0.8173, 0.1827], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 27 - 283: dog - cat || Loss: 1.1301071643829346\n",
      "tensor([0., 1.]) tensor([0.8168, 0.1832], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 27 - 284: dog - cat || Loss: 1.1296555995941162\n",
      "tensor([0., 1.]) tensor([0.8164, 0.1836], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 27 - 285: dog - cat || Loss: 1.1292035579681396\n",
      "tensor([0., 1.]) tensor([0.8159, 0.1841], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 27 - 286: dog - cat || Loss: 1.1287503242492676\n",
      "tensor([0., 1.]) tensor([0.8155, 0.1845], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 27 - 287: dog - cat || Loss: 1.128296136856079\n",
      "tensor([0., 1.]) tensor([0.8150, 0.1850], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 27 - 288: dog - cat || Loss: 1.1278412342071533\n",
      "tensor([0., 1.]) tensor([0.8146, 0.1854], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 27 - 289: dog - cat || Loss: 1.1273852586746216\n",
      "tensor([0., 1.]) tensor([0.8141, 0.1859], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 27 - 290: dog - cat || Loss: 1.1269285678863525\n",
      "tensor([0., 1.]) tensor([0.8137, 0.1863], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 27 - 291: dog - cat || Loss: 1.1264708042144775\n",
      "tensor([0., 1.]) tensor([0.8132, 0.1868], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 27 - 292: dog - cat || Loss: 1.1260122060775757\n",
      "tensor([0., 1.]) tensor([0.8128, 0.1872], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 27 - 293: dog - cat || Loss: 1.125552773475647\n",
      "tensor([0., 1.]) tensor([0.8123, 0.1877], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 27 - 294: dog - cat || Loss: 1.1250923871994019\n",
      "tensor([0., 1.]) tensor([0.8118, 0.1882], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 27 - 295: dog - cat || Loss: 1.1246311664581299\n",
      "tensor([0., 1.]) tensor([0.8114, 0.1886], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 27 - 296: dog - cat || Loss: 1.1241689920425415\n",
      "tensor([0., 1.]) tensor([0.8109, 0.1891], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 27 - 297: dog - cat || Loss: 1.1237059831619263\n",
      "tensor([0., 1.]) tensor([0.8104, 0.1896], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 27 - 298: dog - cat || Loss: 1.123241901397705\n",
      "tensor([0., 1.]) tensor([0.8100, 0.1900], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 27 - 299: dog - cat || Loss: 1.1227771043777466\n",
      "tensor([0., 1.]) tensor([0.8095, 0.1905], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 27 - 300: dog - cat || Loss: 1.1223113536834717\n",
      "tensor([0., 1.]) tensor([0.8090, 0.1910], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 27 - 301: dog - cat || Loss: 1.1218445301055908\n",
      "tensor([0., 1.]) tensor([0.8086, 0.1914], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 27 - 302: dog - cat || Loss: 1.1213771104812622\n",
      "tensor([0., 1.]) tensor([0.8081, 0.1919], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 27 - 303: dog - cat || Loss: 1.1209086179733276\n",
      "tensor([0., 1.]) tensor([0.8076, 0.1924], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 27 - 304: dog - cat || Loss: 1.1204394102096558\n",
      "tensor([0., 1.]) tensor([0.8072, 0.1928], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 27 - 305: dog - cat || Loss: 1.1199687719345093\n",
      "tensor([0., 1.]) tensor([0.8067, 0.1933], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 27 - 306: dog - cat || Loss: 1.1194977760314941\n",
      "tensor([0., 1.]) tensor([0.8062, 0.1938], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 27 - 307: dog - cat || Loss: 1.1190258264541626\n",
      "tensor([0., 1.]) tensor([0.8058, 0.1942], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 27 - 308: dog - cat || Loss: 1.118552803993225\n",
      "tensor([0., 1.]) tensor([0.8053, 0.1947], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 27 - 309: dog - cat || Loss: 1.1180789470672607\n",
      "tensor([0., 1.]) tensor([0.8048, 0.1952], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 27 - 310: dog - cat || Loss: 1.11760413646698\n",
      "tensor([0., 1.]) tensor([0.8043, 0.1957], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 27 - 311: dog - cat || Loss: 1.1171283721923828\n",
      "tensor([0., 1.]) tensor([0.8039, 0.1961], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 27 - 312: dog - cat || Loss: 1.1166518926620483\n",
      "tensor([0., 1.]) tensor([0.8034, 0.1966], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 27 - 313: dog - cat || Loss: 1.1161744594573975\n",
      "tensor([0., 1.]) tensor([0.8029, 0.1971], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 27 - 314: dog - cat || Loss: 1.1156960725784302\n",
      "tensor([0., 1.]) tensor([0.8024, 0.1976], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 27 - 315: dog - cat || Loss: 1.115216851234436\n",
      "tensor([0., 1.]) tensor([0.8020, 0.1980], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 27 - 316: dog - cat || Loss: 1.114736557006836\n",
      "tensor([0., 1.]) tensor([0.8015, 0.1985], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 27 - 317: dog - cat || Loss: 1.114255428314209\n",
      "tensor([0., 1.]) tensor([0.8010, 0.1990], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 27 - 318: dog - cat || Loss: 1.1137734651565552\n",
      "tensor([0., 1.]) tensor([0.8005, 0.1995], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 27 - 319: dog - cat || Loss: 1.113290548324585\n",
      "tensor([0., 1.]) tensor([0.8000, 0.2000], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 27 - 320: dog - cat || Loss: 1.1128069162368774\n",
      "tensor([0., 1.]) tensor([0.7995, 0.2005], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 27 - 321: dog - cat || Loss: 1.1123220920562744\n",
      "tensor([0., 1.]) tensor([0.7991, 0.2009], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 27 - 322: dog - cat || Loss: 1.111836552619934\n",
      "tensor([0., 1.]) tensor([0.7986, 0.2014], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 27 - 323: dog - cat || Loss: 1.1113499402999878\n",
      "tensor([0., 1.]) tensor([0.7981, 0.2019], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 27 - 324: dog - cat || Loss: 1.1108624935150146\n",
      "tensor([0., 1.]) tensor([0.7976, 0.2024], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 27 - 325: dog - cat || Loss: 1.1103742122650146\n",
      "tensor([0., 1.]) tensor([0.7971, 0.2029], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 27 - 326: dog - cat || Loss: 1.1098848581314087\n",
      "tensor([0., 1.]) tensor([0.7966, 0.2034], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 27 - 327: dog - cat || Loss: 1.1093947887420654\n",
      "tensor([0., 1.]) tensor([0.7961, 0.2039], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 27 - 328: dog - cat || Loss: 1.1089037656784058\n",
      "tensor([0., 1.]) tensor([0.7956, 0.2044], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 27 - 329: dog - cat || Loss: 1.1084117889404297\n",
      "tensor([0., 1.]) tensor([0.7952, 0.2048], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 27 - 330: dog - cat || Loss: 1.1079188585281372\n",
      "tensor([0., 1.]) tensor([0.7947, 0.2053], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 27 - 331: dog - cat || Loss: 1.1074249744415283\n",
      "tensor([0., 1.]) tensor([0.7942, 0.2058], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 27 - 332: dog - cat || Loss: 1.1069303750991821\n",
      "tensor([0., 1.]) tensor([0.7937, 0.2063], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 27 - 333: dog - cat || Loss: 1.1064348220825195\n",
      "tensor([0., 1.]) tensor([0.7932, 0.2068], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 27 - 334: dog - cat || Loss: 1.105938196182251\n",
      "tensor([0., 1.]) tensor([0.7927, 0.2073], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 27 - 335: dog - cat || Loss: 1.1054408550262451\n",
      "tensor([0., 1.]) tensor([0.7922, 0.2078], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 27 - 336: dog - cat || Loss: 1.1049424409866333\n",
      "tensor([0., 1.]) tensor([0.7917, 0.2083], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 27 - 337: dog - cat || Loss: 1.1044433116912842\n",
      "tensor([0., 1.]) tensor([0.7912, 0.2088], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 27 - 338: dog - cat || Loss: 1.103943109512329\n",
      "tensor([0., 1.]) tensor([0.7907, 0.2093], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 27 - 339: dog - cat || Loss: 1.1034420728683472\n",
      "tensor([0., 1.]) tensor([0.7902, 0.2098], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 27 - 340: dog - cat || Loss: 1.1029402017593384\n",
      "tensor([0., 1.]) tensor([0.7897, 0.2103], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 27 - 341: dog - cat || Loss: 1.1024374961853027\n",
      "tensor([0., 1.]) tensor([0.7892, 0.2108], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 27 - 342: dog - cat || Loss: 1.1019337177276611\n",
      "tensor([0., 1.]) tensor([0.7887, 0.2113], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 27 - 343: dog - cat || Loss: 1.1014291048049927\n",
      "tensor([0., 1.]) tensor([0.7882, 0.2118], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 27 - 344: dog - cat || Loss: 1.1009235382080078\n",
      "tensor([0., 1.]) tensor([0.7877, 0.2123], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 27 - 345: dog - cat || Loss: 1.1004172563552856\n",
      "tensor([0., 1.]) tensor([0.7872, 0.2128], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 27 - 346: dog - cat || Loss: 1.0999099016189575\n",
      "tensor([0., 1.]) tensor([0.7866, 0.2134], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 27 - 347: dog - cat || Loss: 1.099401593208313\n",
      "tensor([0., 1.]) tensor([0.7861, 0.2139], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 27 - 348: dog - cat || Loss: 1.0988925695419312\n",
      "tensor([0., 1.]) tensor([0.7856, 0.2144], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 27 - 349: dog - cat || Loss: 1.098382592201233\n",
      "tensor([0., 1.]) tensor([0.7851, 0.2149], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 27 - 350: dog - cat || Loss: 1.0978715419769287\n",
      "tensor([0., 1.]) tensor([0.7846, 0.2154], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 27 - 351: dog - cat || Loss: 1.0973597764968872\n",
      "tensor([0., 1.]) tensor([0.7841, 0.2159], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 27 - 352: dog - cat || Loss: 1.0968470573425293\n",
      "tensor([0., 1.]) tensor([0.7836, 0.2164], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 27 - 353: dog - cat || Loss: 1.0963332653045654\n",
      "tensor([0., 1.]) tensor([0.7831, 0.2169], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 27 - 354: dog - cat || Loss: 1.0958187580108643\n",
      "tensor([0., 1.]) tensor([0.7826, 0.2174], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 27 - 355: dog - cat || Loss: 1.0953032970428467\n",
      "tensor([0., 1.]) tensor([0.7820, 0.2180], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 27 - 356: dog - cat || Loss: 1.0947868824005127\n",
      "tensor([0., 1.]) tensor([0.7815, 0.2185], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 27 - 357: dog - cat || Loss: 1.0942696332931519\n",
      "tensor([0., 1.]) tensor([0.7810, 0.2190], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 27 - 358: dog - cat || Loss: 1.093751311302185\n",
      "tensor([0., 1.]) tensor([0.7805, 0.2195], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 27 - 359: dog - cat || Loss: 1.0932321548461914\n",
      "tensor([0., 1.]) tensor([0.7800, 0.2200], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 27 - 360: dog - cat || Loss: 1.0927122831344604\n",
      "tensor([0., 1.]) tensor([0.7795, 0.2205], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 27 - 361: dog - cat || Loss: 1.0921916961669922\n",
      "tensor([0., 1.]) tensor([0.7789, 0.2211], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 27 - 362: dog - cat || Loss: 1.0916696786880493\n",
      "tensor([0., 1.]) tensor([0.7784, 0.2216], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 27 - 363: dog - cat || Loss: 1.0911471843719482\n",
      "tensor([0., 1.]) tensor([0.7779, 0.2221], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 27 - 364: dog - cat || Loss: 1.0906236171722412\n",
      "tensor([0., 1.]) tensor([0.7774, 0.2226], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 27 - 365: dog - cat || Loss: 1.0900992155075073\n",
      "tensor([0., 1.]) tensor([0.7768, 0.2232], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 27 - 366: dog - cat || Loss: 1.089573621749878\n",
      "tensor([0., 1.]) tensor([0.7763, 0.2237], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 27 - 367: dog - cat || Loss: 1.0890475511550903\n",
      "tensor([0., 1.]) tensor([0.7758, 0.2242], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 27 - 368: dog - cat || Loss: 1.0885202884674072\n",
      "tensor([0., 1.]) tensor([0.7753, 0.2247], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 27 - 369: dog - cat || Loss: 1.0879923105239868\n",
      "tensor([0., 1.]) tensor([0.7747, 0.2253], grad_fn=<SoftmaxBackward0>)\n",
      "=====epoch:28=====\n",
      "Epoch 28 - 0: cat - cat || Loss: 0.539060115814209\n",
      "tensor([1., 0.]) tensor([0.7742, 0.2258], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 28 - 1: cat - cat || Loss: 0.5394830703735352\n",
      "tensor([1., 0.]) tensor([0.7738, 0.2262], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 28 - 2: cat - cat || Loss: 0.5398105382919312\n",
      "tensor([1., 0.]) tensor([0.7735, 0.2265], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 28 - 3: cat - cat || Loss: 0.5400518774986267\n",
      "tensor([1., 0.]) tensor([0.7732, 0.2268], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 28 - 4: cat - cat || Loss: 0.5402156114578247\n",
      "tensor([1., 0.]) tensor([0.7730, 0.2270], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 28 - 5: cat - cat || Loss: 0.5403093099594116\n",
      "tensor([1., 0.]) tensor([0.7730, 0.2270], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 28 - 6: cat - cat || Loss: 0.5403401851654053\n",
      "tensor([1., 0.]) tensor([0.7729, 0.2271], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 28 - 7: cat - cat || Loss: 0.5403143167495728\n",
      "tensor([1., 0.]) tensor([0.7729, 0.2271], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 28 - 8: cat - cat || Loss: 0.5402374267578125\n",
      "tensor([1., 0.]) tensor([0.7730, 0.2270], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 28 - 9: cat - cat || Loss: 0.5401146411895752\n",
      "tensor([1., 0.]) tensor([0.7731, 0.2269], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 28 - 10: cat - cat || Loss: 0.5399506688117981\n",
      "tensor([1., 0.]) tensor([0.7733, 0.2267], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 28 - 11: cat - cat || Loss: 0.539749801158905\n",
      "tensor([1., 0.]) tensor([0.7735, 0.2265], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 28 - 12: cat - cat || Loss: 0.5395154356956482\n",
      "tensor([1., 0.]) tensor([0.7737, 0.2263], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 28 - 13: cat - cat || Loss: 0.5392512679100037\n",
      "tensor([1., 0.]) tensor([0.7740, 0.2260], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 28 - 14: cat - cat || Loss: 0.5389601588249207\n",
      "tensor([1., 0.]) tensor([0.7743, 0.2257], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 28 - 15: cat - cat || Loss: 0.5386450290679932\n",
      "tensor([1., 0.]) tensor([0.7746, 0.2254], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 28 - 16: cat - cat || Loss: 0.538308322429657\n",
      "tensor([1., 0.]) tensor([0.7750, 0.2250], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 28 - 17: cat - cat || Loss: 0.5379521250724792\n",
      "tensor([1., 0.]) tensor([0.7753, 0.2247], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 28 - 18: cat - cat || Loss: 0.5375787615776062\n",
      "tensor([1., 0.]) tensor([0.7757, 0.2243], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 28 - 19: cat - cat || Loss: 0.5371897220611572\n",
      "tensor([1., 0.]) tensor([0.7761, 0.2239], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 28 - 20: cat - cat || Loss: 0.5367867946624756\n",
      "tensor([1., 0.]) tensor([0.7765, 0.2235], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 28 - 21: cat - cat || Loss: 0.5363714694976807\n",
      "tensor([1., 0.]) tensor([0.7769, 0.2231], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 28 - 22: cat - cat || Loss: 0.5359451770782471\n",
      "tensor([1., 0.]) tensor([0.7773, 0.2227], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 28 - 23: cat - cat || Loss: 0.5355088114738464\n",
      "tensor([1., 0.]) tensor([0.7778, 0.2222], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 28 - 24: cat - cat || Loss: 0.5350637435913086\n",
      "tensor([1., 0.]) tensor([0.7782, 0.2218], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 28 - 25: cat - cat || Loss: 0.5346108675003052\n",
      "tensor([1., 0.]) tensor([0.7787, 0.2213], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 28 - 26: cat - cat || Loss: 0.5341509580612183\n",
      "tensor([1., 0.]) tensor([0.7791, 0.2209], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 28 - 27: cat - cat || Loss: 0.5336849689483643\n",
      "tensor([1., 0.]) tensor([0.7796, 0.2204], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 28 - 28: cat - cat || Loss: 0.5332134366035461\n",
      "tensor([1., 0.]) tensor([0.7800, 0.2200], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 28 - 29: cat - cat || Loss: 0.5327369570732117\n",
      "tensor([1., 0.]) tensor([0.7805, 0.2195], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 28 - 30: cat - cat || Loss: 0.5322563648223877\n",
      "tensor([1., 0.]) tensor([0.7810, 0.2190], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 28 - 31: cat - cat || Loss: 0.5317719578742981\n",
      "tensor([1., 0.]) tensor([0.7815, 0.2185], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 28 - 32: cat - cat || Loss: 0.5312843918800354\n",
      "tensor([1., 0.]) tensor([0.7820, 0.2180], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 28 - 33: cat - cat || Loss: 0.530794084072113\n",
      "tensor([1., 0.]) tensor([0.7825, 0.2175], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 28 - 34: cat - cat || Loss: 0.5303012132644653\n",
      "tensor([1., 0.]) tensor([0.7830, 0.2170], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 28 - 35: cat - cat || Loss: 0.5298062562942505\n",
      "tensor([1., 0.]) tensor([0.7835, 0.2165], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 28 - 36: cat - cat || Loss: 0.5293095111846924\n",
      "tensor([1., 0.]) tensor([0.7840, 0.2160], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 28 - 37: cat - cat || Loss: 0.5288112163543701\n",
      "tensor([1., 0.]) tensor([0.7845, 0.2155], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 28 - 38: cat - cat || Loss: 0.5283116102218628\n",
      "tensor([1., 0.]) tensor([0.7850, 0.2150], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 28 - 39: cat - cat || Loss: 0.5278108716011047\n",
      "tensor([1., 0.]) tensor([0.7855, 0.2145], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 28 - 40: cat - cat || Loss: 0.5273094177246094\n",
      "tensor([1., 0.]) tensor([0.7860, 0.2140], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 28 - 41: cat - cat || Loss: 0.5268071293830872\n",
      "tensor([1., 0.]) tensor([0.7865, 0.2135], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 28 - 42: cat - cat || Loss: 0.5263043642044067\n",
      "tensor([1., 0.]) tensor([0.7870, 0.2130], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 28 - 43: cat - cat || Loss: 0.5258010625839233\n",
      "tensor([1., 0.]) tensor([0.7875, 0.2125], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 28 - 44: cat - cat || Loss: 0.5252977609634399\n",
      "tensor([1., 0.]) tensor([0.7880, 0.2120], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 28 - 45: cat - cat || Loss: 0.5247941017150879\n",
      "tensor([1., 0.]) tensor([0.7885, 0.2115], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 28 - 46: cat - cat || Loss: 0.5242904424667358\n",
      "tensor([1., 0.]) tensor([0.7890, 0.2110], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 28 - 47: cat - cat || Loss: 0.5237869620323181\n",
      "tensor([1., 0.]) tensor([0.7895, 0.2105], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 28 - 48: cat - cat || Loss: 0.5232835412025452\n",
      "tensor([1., 0.]) tensor([0.7900, 0.2100], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 28 - 49: cat - cat || Loss: 0.5227802991867065\n",
      "tensor([1., 0.]) tensor([0.7905, 0.2095], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 28 - 50: cat - cat || Loss: 0.5222774744033813\n",
      "tensor([1., 0.]) tensor([0.7910, 0.2090], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 28 - 51: cat - cat || Loss: 0.5217750668525696\n",
      "tensor([1., 0.]) tensor([0.7915, 0.2085], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 28 - 52: cat - cat || Loss: 0.5212728977203369\n",
      "tensor([1., 0.]) tensor([0.7920, 0.2080], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 28 - 53: cat - cat || Loss: 0.520771324634552\n",
      "tensor([1., 0.]) tensor([0.7925, 0.2075], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 28 - 54: cat - cat || Loss: 0.5202702283859253\n",
      "tensor([1., 0.]) tensor([0.7930, 0.2070], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 28 - 55: cat - cat || Loss: 0.5197697281837463\n",
      "tensor([1., 0.]) tensor([0.7935, 0.2065], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 28 - 56: cat - cat || Loss: 0.5192698240280151\n",
      "tensor([1., 0.]) tensor([0.7940, 0.2060], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 28 - 57: cat - cat || Loss: 0.5187704563140869\n",
      "tensor([1., 0.]) tensor([0.7945, 0.2055], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 28 - 58: cat - cat || Loss: 0.5182718634605408\n",
      "tensor([1., 0.]) tensor([0.7950, 0.2050], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 28 - 59: cat - cat || Loss: 0.5177740454673767\n",
      "tensor([1., 0.]) tensor([0.7955, 0.2045], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 28 - 60: cat - cat || Loss: 0.5172768235206604\n",
      "tensor([1., 0.]) tensor([0.7960, 0.2040], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 28 - 61: cat - cat || Loss: 0.5167803764343262\n",
      "tensor([1., 0.]) tensor([0.7965, 0.2035], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 28 - 62: cat - cat || Loss: 0.516284704208374\n",
      "tensor([1., 0.]) tensor([0.7970, 0.2030], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 28 - 63: cat - cat || Loss: 0.5157899856567383\n",
      "tensor([1., 0.]) tensor([0.7975, 0.2025], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 28 - 64: cat - cat || Loss: 0.5152958631515503\n",
      "tensor([1., 0.]) tensor([0.7980, 0.2020], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 28 - 65: cat - cat || Loss: 0.5148026347160339\n",
      "tensor([1., 0.]) tensor([0.7985, 0.2015], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 28 - 66: cat - cat || Loss: 0.5143102407455444\n",
      "tensor([1., 0.]) tensor([0.7990, 0.2010], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 28 - 67: cat - cat || Loss: 0.5138186812400818\n",
      "tensor([1., 0.]) tensor([0.7994, 0.2006], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 28 - 68: cat - cat || Loss: 0.513327956199646\n",
      "tensor([1., 0.]) tensor([0.7999, 0.2001], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 28 - 69: cat - cat || Loss: 0.5128380060195923\n",
      "tensor([1., 0.]) tensor([0.8004, 0.1996], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 28 - 70: cat - cat || Loss: 0.512349009513855\n",
      "tensor([1., 0.]) tensor([0.8009, 0.1991], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 28 - 71: cat - cat || Loss: 0.5118609666824341\n",
      "tensor([1., 0.]) tensor([0.8014, 0.1986], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 28 - 72: cat - cat || Loss: 0.5113736391067505\n",
      "tensor([1., 0.]) tensor([0.8019, 0.1981], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 28 - 73: cat - cat || Loss: 0.5108872652053833\n",
      "tensor([1., 0.]) tensor([0.8024, 0.1976], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 28 - 74: cat - cat || Loss: 0.510401725769043\n",
      "tensor([1., 0.]) tensor([0.8029, 0.1971], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 28 - 75: cat - cat || Loss: 0.5099172592163086\n",
      "tensor([1., 0.]) tensor([0.8033, 0.1967], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 28 - 76: cat - cat || Loss: 0.5094335079193115\n",
      "tensor([1., 0.]) tensor([0.8038, 0.1962], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 28 - 77: cat - cat || Loss: 0.5089508295059204\n",
      "tensor([1., 0.]) tensor([0.8043, 0.1957], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 28 - 78: cat - cat || Loss: 0.5084688663482666\n",
      "tensor([1., 0.]) tensor([0.8048, 0.1952], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 28 - 79: cat - cat || Loss: 0.5079878568649292\n",
      "tensor([1., 0.]) tensor([0.8053, 0.1947], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 28 - 80: cat - cat || Loss: 0.507507860660553\n",
      "tensor([1., 0.]) tensor([0.8058, 0.1942], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 28 - 81: cat - cat || Loss: 0.5070285797119141\n",
      "tensor([1., 0.]) tensor([0.8062, 0.1938], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 28 - 82: cat - cat || Loss: 0.5065503120422363\n",
      "tensor([1., 0.]) tensor([0.8067, 0.1933], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 28 - 83: cat - cat || Loss: 0.5060730576515198\n",
      "tensor([1., 0.]) tensor([0.8072, 0.1928], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 28 - 84: cat - cat || Loss: 0.5055967569351196\n",
      "tensor([1., 0.]) tensor([0.8077, 0.1923], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 28 - 85: cat - cat || Loss: 0.505121111869812\n",
      "tensor([1., 0.]) tensor([0.8081, 0.1919], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 28 - 86: cat - cat || Loss: 0.5046466588973999\n",
      "tensor([1., 0.]) tensor([0.8086, 0.1914], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 28 - 87: cat - cat || Loss: 0.5041730403900146\n",
      "tensor([1., 0.]) tensor([0.8091, 0.1909], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 28 - 88: cat - cat || Loss: 0.5037002563476562\n",
      "tensor([1., 0.]) tensor([0.8096, 0.1904], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 28 - 89: cat - cat || Loss: 0.5032284259796143\n",
      "tensor([1., 0.]) tensor([0.8100, 0.1900], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 28 - 90: cat - cat || Loss: 0.5027575492858887\n",
      "tensor([1., 0.]) tensor([0.8105, 0.1895], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 28 - 91: cat - cat || Loss: 0.5022875070571899\n",
      "tensor([1., 0.]) tensor([0.8110, 0.1890], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 28 - 92: cat - cat || Loss: 0.5018185377120972\n",
      "tensor([1., 0.]) tensor([0.8114, 0.1886], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 28 - 93: cat - cat || Loss: 0.501350462436676\n",
      "tensor([1., 0.]) tensor([0.8119, 0.1881], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 28 - 94: cat - cat || Loss: 0.5008833408355713\n",
      "tensor([1., 0.]) tensor([0.8124, 0.1876], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 28 - 95: cat - cat || Loss: 0.5004170536994934\n",
      "tensor([1., 0.]) tensor([0.8128, 0.1872], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 28 - 96: cat - cat || Loss: 0.4999517798423767\n",
      "tensor([1., 0.]) tensor([0.8133, 0.1867], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 28 - 97: cat - cat || Loss: 0.49948740005493164\n",
      "tensor([1., 0.]) tensor([0.8138, 0.1862], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 28 - 98: cat - cat || Loss: 0.499023973941803\n",
      "tensor([1., 0.]) tensor([0.8142, 0.1858], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 28 - 99: cat - cat || Loss: 0.49856147170066833\n",
      "tensor([1., 0.]) tensor([0.8147, 0.1853], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 28 - 100: cat - cat || Loss: 0.4980999231338501\n",
      "tensor([1., 0.]) tensor([0.8152, 0.1848], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 28 - 101: cat - cat || Loss: 0.49763917922973633\n",
      "tensor([1., 0.]) tensor([0.8156, 0.1844], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 28 - 102: cat - cat || Loss: 0.4971795082092285\n",
      "tensor([1., 0.]) tensor([0.8161, 0.1839], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 28 - 103: cat - cat || Loss: 0.49672067165374756\n",
      "tensor([1., 0.]) tensor([0.8165, 0.1835], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 28 - 104: cat - cat || Loss: 0.496262788772583\n",
      "tensor([1., 0.]) tensor([0.8170, 0.1830], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 28 - 105: cat - cat || Loss: 0.4958058297634125\n",
      "tensor([1., 0.]) tensor([0.8175, 0.1825], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 28 - 106: cat - cat || Loss: 0.49534982442855835\n",
      "tensor([1., 0.]) tensor([0.8179, 0.1821], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 28 - 107: cat - cat || Loss: 0.4948946237564087\n",
      "tensor([1., 0.]) tensor([0.8184, 0.1816], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 28 - 108: cat - cat || Loss: 0.494440495967865\n",
      "tensor([1., 0.]) tensor([0.8188, 0.1812], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 28 - 109: cat - cat || Loss: 0.4939872622489929\n",
      "tensor([1., 0.]) tensor([0.8193, 0.1807], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 28 - 110: cat - cat || Loss: 0.4935348927974701\n",
      "tensor([1., 0.]) tensor([0.8197, 0.1803], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 28 - 111: cat - cat || Loss: 0.4930835962295532\n",
      "tensor([1., 0.]) tensor([0.8202, 0.1798], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 28 - 112: cat - cat || Loss: 0.49263301491737366\n",
      "tensor([1., 0.]) tensor([0.8206, 0.1794], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 28 - 113: cat - cat || Loss: 0.49218350648880005\n",
      "tensor([1., 0.]) tensor([0.8211, 0.1789], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 28 - 114: cat - cat || Loss: 0.4917348325252533\n",
      "tensor([1., 0.]) tensor([0.8215, 0.1785], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 28 - 115: cat - cat || Loss: 0.4912871718406677\n",
      "tensor([1., 0.]) tensor([0.8220, 0.1780], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 28 - 116: cat - cat || Loss: 0.49084043502807617\n",
      "tensor([1., 0.]) tensor([0.8224, 0.1776], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 28 - 117: cat - cat || Loss: 0.4903947114944458\n",
      "tensor([1., 0.]) tensor([0.8229, 0.1771], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 28 - 118: cat - cat || Loss: 0.4899497628211975\n",
      "tensor([1., 0.]) tensor([0.8233, 0.1767], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 28 - 119: cat - cat || Loss: 0.4895058870315552\n",
      "tensor([1., 0.]) tensor([0.8238, 0.1762], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 28 - 120: cat - cat || Loss: 0.48906272649765015\n",
      "tensor([1., 0.]) tensor([0.8242, 0.1758], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 28 - 121: cat - cat || Loss: 0.4886205792427063\n",
      "tensor([1., 0.]) tensor([0.8246, 0.1754], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 28 - 122: cat - cat || Loss: 0.48817944526672363\n",
      "tensor([1., 0.]) tensor([0.8251, 0.1749], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 28 - 123: cat - cat || Loss: 0.487739235162735\n",
      "tensor([1., 0.]) tensor([0.8255, 0.1745], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 28 - 124: cat - cat || Loss: 0.4872997999191284\n",
      "tensor([1., 0.]) tensor([0.8260, 0.1740], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 28 - 125: cat - cat || Loss: 0.4868614375591278\n",
      "tensor([1., 0.]) tensor([0.8264, 0.1736], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 28 - 126: cat - cat || Loss: 0.48642396926879883\n",
      "tensor([1., 0.]) tensor([0.8268, 0.1732], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 28 - 127: cat - cat || Loss: 0.48598724603652954\n",
      "tensor([1., 0.]) tensor([0.8273, 0.1727], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 28 - 128: cat - cat || Loss: 0.485551655292511\n",
      "tensor([1., 0.]) tensor([0.8277, 0.1723], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 28 - 129: cat - cat || Loss: 0.4851168990135193\n",
      "tensor([1., 0.]) tensor([0.8281, 0.1719], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 28 - 130: cat - cat || Loss: 0.484683096408844\n",
      "tensor([1., 0.]) tensor([0.8286, 0.1714], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 28 - 131: cat - cat || Loss: 0.48425012826919556\n",
      "tensor([1., 0.]) tensor([0.8290, 0.1710], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 28 - 132: cat - cat || Loss: 0.4838181436061859\n",
      "tensor([1., 0.]) tensor([0.8294, 0.1706], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 28 - 133: cat - cat || Loss: 0.4833870530128479\n",
      "tensor([1., 0.]) tensor([0.8299, 0.1701], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 28 - 134: cat - cat || Loss: 0.48295682668685913\n",
      "tensor([1., 0.]) tensor([0.8303, 0.1697], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 28 - 135: cat - cat || Loss: 0.4825277030467987\n",
      "tensor([1., 0.]) tensor([0.8307, 0.1693], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 28 - 136: cat - cat || Loss: 0.48209935426712036\n",
      "tensor([1., 0.]) tensor([0.8312, 0.1688], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 28 - 137: cat - cat || Loss: 0.48167186975479126\n",
      "tensor([1., 0.]) tensor([0.8316, 0.1684], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 28 - 138: cat - cat || Loss: 0.48124536871910095\n",
      "tensor([1., 0.]) tensor([0.8320, 0.1680], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 28 - 139: cat - cat || Loss: 0.4808197319507599\n",
      "tensor([1., 0.]) tensor([0.8324, 0.1676], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 28 - 140: cat - cat || Loss: 0.48039501905441284\n",
      "tensor([1., 0.]) tensor([0.8329, 0.1671], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 28 - 141: cat - cat || Loss: 0.4799712896347046\n",
      "tensor([1., 0.]) tensor([0.8333, 0.1667], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 28 - 142: cat - cat || Loss: 0.4795483946800232\n",
      "tensor([1., 0.]) tensor([0.8337, 0.1663], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 28 - 143: cat - cat || Loss: 0.47912636399269104\n",
      "tensor([1., 0.]) tensor([0.8341, 0.1659], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 28 - 144: cat - cat || Loss: 0.47870543599128723\n",
      "tensor([1., 0.]) tensor([0.8346, 0.1654], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 28 - 145: cat - cat || Loss: 0.4782853126525879\n",
      "tensor([1., 0.]) tensor([0.8350, 0.1650], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 28 - 146: cat - cat || Loss: 0.4778660237789154\n",
      "tensor([1., 0.]) tensor([0.8354, 0.1646], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 28 - 147: cat - cat || Loss: 0.4774478077888489\n",
      "tensor([1., 0.]) tensor([0.8358, 0.1642], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 28 - 148: cat - cat || Loss: 0.47703033685684204\n",
      "tensor([1., 0.]) tensor([0.8362, 0.1638], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 28 - 149: cat - cat || Loss: 0.4766138792037964\n",
      "tensor([1., 0.]) tensor([0.8366, 0.1634], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 28 - 150: cat - cat || Loss: 0.47619813680648804\n",
      "tensor([1., 0.]) tensor([0.8371, 0.1629], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 28 - 151: cat - cat || Loss: 0.47578349709510803\n",
      "tensor([1., 0.]) tensor([0.8375, 0.1625], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 28 - 152: cat - cat || Loss: 0.47536975145339966\n",
      "tensor([1., 0.]) tensor([0.8379, 0.1621], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 28 - 153: cat - cat || Loss: 0.47495681047439575\n",
      "tensor([1., 0.]) tensor([0.8383, 0.1617], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 28 - 154: cat - cat || Loss: 0.47454482316970825\n",
      "tensor([1., 0.]) tensor([0.8387, 0.1613], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 28 - 155: cat - cat || Loss: 0.47413361072540283\n",
      "tensor([1., 0.]) tensor([0.8391, 0.1609], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 28 - 156: cat - cat || Loss: 0.47372347116470337\n",
      "tensor([1., 0.]) tensor([0.8395, 0.1605], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 28 - 157: cat - cat || Loss: 0.47331422567367554\n",
      "tensor([1., 0.]) tensor([0.8399, 0.1601], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 28 - 158: cat - cat || Loss: 0.4729057550430298\n",
      "tensor([1., 0.]) tensor([0.8404, 0.1596], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 28 - 159: cat - cat || Loss: 0.47249823808670044\n",
      "tensor([1., 0.]) tensor([0.8408, 0.1592], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 28 - 160: cat - cat || Loss: 0.4720916152000427\n",
      "tensor([1., 0.]) tensor([0.8412, 0.1588], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 28 - 161: cat - cat || Loss: 0.47168588638305664\n",
      "tensor([1., 0.]) tensor([0.8416, 0.1584], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 28 - 162: cat - cat || Loss: 0.47128117084503174\n",
      "tensor([1., 0.]) tensor([0.8420, 0.1580], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 28 - 163: cat - cat || Loss: 0.47087711095809937\n",
      "tensor([1., 0.]) tensor([0.8424, 0.1576], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 28 - 164: cat - cat || Loss: 0.47047412395477295\n",
      "tensor([1., 0.]) tensor([0.8428, 0.1572], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 28 - 165: cat - cat || Loss: 0.4700720012187958\n",
      "tensor([1., 0.]) tensor([0.8432, 0.1568], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 28 - 166: cat - cat || Loss: 0.46967077255249023\n",
      "tensor([1., 0.]) tensor([0.8436, 0.1564], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 28 - 167: cat - cat || Loss: 0.46927037835121155\n",
      "tensor([1., 0.]) tensor([0.8440, 0.1560], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 28 - 168: cat - cat || Loss: 0.46887093782424927\n",
      "tensor([1., 0.]) tensor([0.8444, 0.1556], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 28 - 169: cat - cat || Loss: 0.46847233176231384\n",
      "tensor([1., 0.]) tensor([0.8448, 0.1552], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 28 - 170: cat - cat || Loss: 0.4680746793746948\n",
      "tensor([1., 0.]) tensor([0.8452, 0.1548], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 28 - 171: cat - cat || Loss: 0.46767789125442505\n",
      "tensor([1., 0.]) tensor([0.8456, 0.1544], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 28 - 172: cat - cat || Loss: 0.46728193759918213\n",
      "tensor([1., 0.]) tensor([0.8460, 0.1540], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 28 - 173: cat - cat || Loss: 0.4668870270252228\n",
      "tensor([1., 0.]) tensor([0.8464, 0.1536], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 28 - 174: cat - cat || Loss: 0.46649283170700073\n",
      "tensor([1., 0.]) tensor([0.8468, 0.1532], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 28 - 175: cat - cat || Loss: 0.4660995602607727\n",
      "tensor([1., 0.]) tensor([0.8472, 0.1528], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 28 - 176: cat - cat || Loss: 0.4657071828842163\n",
      "tensor([1., 0.]) tensor([0.8476, 0.1524], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 28 - 177: cat - cat || Loss: 0.46531569957733154\n",
      "tensor([1., 0.]) tensor([0.8479, 0.1521], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 28 - 178: cat - cat || Loss: 0.464925080537796\n",
      "tensor([1., 0.]) tensor([0.8483, 0.1517], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 28 - 179: cat - cat || Loss: 0.4645354151725769\n",
      "tensor([1., 0.]) tensor([0.8487, 0.1513], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 28 - 180: cat - cat || Loss: 0.4641464948654175\n",
      "tensor([1., 0.]) tensor([0.8491, 0.1509], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 28 - 181: cat - cat || Loss: 0.4637584686279297\n",
      "tensor([1., 0.]) tensor([0.8495, 0.1505], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 28 - 182: cat - cat || Loss: 0.4633713960647583\n",
      "tensor([1., 0.]) tensor([0.8499, 0.1501], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 28 - 183: cat - cat || Loss: 0.4629853069782257\n",
      "tensor([1., 0.]) tensor([0.8503, 0.1497], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 28 - 184: cat - cat || Loss: 0.46259990334510803\n",
      "tensor([1., 0.]) tensor([0.8507, 0.1493], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 28 - 185: cat - cat || Loss: 0.4622155427932739\n",
      "tensor([1., 0.]) tensor([0.8510, 0.1490], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 28 - 186: cat - cat || Loss: 0.46183183789253235\n",
      "tensor([1., 0.]) tensor([0.8514, 0.1486], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 28 - 187: cat - cat || Loss: 0.46144914627075195\n",
      "tensor([1., 0.]) tensor([0.8518, 0.1482], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 28 - 188: cat - cat || Loss: 0.461067259311676\n",
      "tensor([1., 0.]) tensor([0.8522, 0.1478], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 28 - 189: cat - cat || Loss: 0.46068626642227173\n",
      "tensor([1., 0.]) tensor([0.8526, 0.1474], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 28 - 190: dog - cat || Loss: 1.16621732711792\n",
      "tensor([0., 1.]) tensor([0.8530, 0.1470], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 28 - 191: dog - cat || Loss: 1.166521430015564\n",
      "tensor([0., 1.]) tensor([0.8533, 0.1467], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 28 - 192: dog - cat || Loss: 1.1667574644088745\n",
      "tensor([0., 1.]) tensor([0.8535, 0.1465], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 28 - 193: dog - cat || Loss: 1.1669323444366455\n",
      "tensor([0., 1.]) tensor([0.8537, 0.1463], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 28 - 194: dog - cat || Loss: 1.167052149772644\n",
      "tensor([0., 1.]) tensor([0.8538, 0.1462], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 28 - 195: dog - cat || Loss: 1.167122721672058\n",
      "tensor([0., 1.]) tensor([0.8539, 0.1461], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 28 - 196: dog - cat || Loss: 1.1671488285064697\n",
      "tensor([0., 1.]) tensor([0.8539, 0.1461], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 28 - 197: dog - cat || Loss: 1.1671347618103027\n",
      "tensor([0., 1.]) tensor([0.8539, 0.1461], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 28 - 198: dog - cat || Loss: 1.1670849323272705\n",
      "tensor([0., 1.]) tensor([0.8538, 0.1462], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 28 - 199: dog - cat || Loss: 1.1670026779174805\n",
      "tensor([0., 1.]) tensor([0.8537, 0.1463], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 28 - 200: dog - cat || Loss: 1.1668912172317505\n",
      "tensor([0., 1.]) tensor([0.8536, 0.1464], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 28 - 201: dog - cat || Loss: 1.1667534112930298\n",
      "tensor([0., 1.]) tensor([0.8535, 0.1465], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 28 - 202: dog - cat || Loss: 1.166591763496399\n",
      "tensor([0., 1.]) tensor([0.8533, 0.1467], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 28 - 203: dog - cat || Loss: 1.166408896446228\n",
      "tensor([0., 1.]) tensor([0.8531, 0.1469], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 28 - 204: dog - cat || Loss: 1.1662065982818604\n",
      "tensor([0., 1.]) tensor([0.8529, 0.1471], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 28 - 205: dog - cat || Loss: 1.1659868955612183\n",
      "tensor([0., 1.]) tensor([0.8527, 0.1473], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 28 - 206: dog - cat || Loss: 1.1657514572143555\n",
      "tensor([0., 1.]) tensor([0.8525, 0.1475], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 28 - 207: dog - cat || Loss: 1.1655018329620361\n",
      "tensor([0., 1.]) tensor([0.8522, 0.1478], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 28 - 208: dog - cat || Loss: 1.1652389764785767\n",
      "tensor([0., 1.]) tensor([0.8520, 0.1480], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 28 - 209: dog - cat || Loss: 1.1649645566940308\n",
      "tensor([0., 1.]) tensor([0.8517, 0.1483], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 28 - 210: dog - cat || Loss: 1.1646795272827148\n",
      "tensor([0., 1.]) tensor([0.8514, 0.1486], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 28 - 211: dog - cat || Loss: 1.1643849611282349\n",
      "tensor([0., 1.]) tensor([0.8511, 0.1489], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 28 - 212: dog - cat || Loss: 1.1640815734863281\n",
      "tensor([0., 1.]) tensor([0.8508, 0.1492], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 28 - 213: dog - cat || Loss: 1.163770079612732\n",
      "tensor([0., 1.]) tensor([0.8505, 0.1495], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 28 - 214: dog - cat || Loss: 1.1634515523910522\n",
      "tensor([0., 1.]) tensor([0.8502, 0.1498], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 28 - 215: dog - cat || Loss: 1.1631264686584473\n",
      "tensor([0., 1.]) tensor([0.8499, 0.1501], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 28 - 216: dog - cat || Loss: 1.1627953052520752\n",
      "tensor([0., 1.]) tensor([0.8495, 0.1505], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 28 - 217: dog - cat || Loss: 1.1624585390090942\n",
      "tensor([0., 1.]) tensor([0.8492, 0.1508], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 28 - 218: dog - cat || Loss: 1.1621167659759521\n",
      "tensor([0., 1.]) tensor([0.8489, 0.1511], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 28 - 219: dog - cat || Loss: 1.1617703437805176\n",
      "tensor([0., 1.]) tensor([0.8485, 0.1515], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 28 - 220: dog - cat || Loss: 1.1614198684692383\n",
      "tensor([0., 1.]) tensor([0.8482, 0.1518], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 28 - 221: dog - cat || Loss: 1.1610653400421143\n",
      "tensor([0., 1.]) tensor([0.8478, 0.1522], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 28 - 222: dog - cat || Loss: 1.1607072353363037\n",
      "tensor([0., 1.]) tensor([0.8474, 0.1526], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 28 - 223: dog - cat || Loss: 1.1603457927703857\n",
      "tensor([0., 1.]) tensor([0.8471, 0.1529], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 28 - 224: dog - cat || Loss: 1.1599812507629395\n",
      "tensor([0., 1.]) tensor([0.8467, 0.1533], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 28 - 225: dog - cat || Loss: 1.159614086151123\n",
      "tensor([0., 1.]) tensor([0.8464, 0.1536], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 28 - 226: dog - cat || Loss: 1.1592440605163574\n",
      "tensor([0., 1.]) tensor([0.8460, 0.1540], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 28 - 227: dog - cat || Loss: 1.1588716506958008\n",
      "tensor([0., 1.]) tensor([0.8456, 0.1544], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 28 - 228: dog - cat || Loss: 1.1584968566894531\n",
      "tensor([0., 1.]) tensor([0.8452, 0.1548], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 28 - 229: dog - cat || Loss: 1.158120036125183\n",
      "tensor([0., 1.]) tensor([0.8449, 0.1551], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 28 - 230: dog - cat || Loss: 1.1577409505844116\n",
      "tensor([0., 1.]) tensor([0.8445, 0.1555], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 28 - 231: dog - cat || Loss: 1.1573600769042969\n",
      "tensor([0., 1.]) tensor([0.8441, 0.1559], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 28 - 232: dog - cat || Loss: 1.1569775342941284\n",
      "tensor([0., 1.]) tensor([0.8437, 0.1563], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 28 - 233: dog - cat || Loss: 1.1565930843353271\n",
      "tensor([0., 1.]) tensor([0.8433, 0.1567], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 28 - 234: dog - cat || Loss: 1.1562070846557617\n",
      "tensor([0., 1.]) tensor([0.8429, 0.1571], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 28 - 235: dog - cat || Loss: 1.1558196544647217\n",
      "tensor([0., 1.]) tensor([0.8426, 0.1574], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 28 - 236: dog - cat || Loss: 1.155430555343628\n",
      "tensor([0., 1.]) tensor([0.8422, 0.1578], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 28 - 237: dog - cat || Loss: 1.1550402641296387\n",
      "tensor([0., 1.]) tensor([0.8418, 0.1582], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 28 - 238: dog - cat || Loss: 1.1546484231948853\n",
      "tensor([0., 1.]) tensor([0.8414, 0.1586], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 28 - 239: dog - cat || Loss: 1.1542552709579468\n",
      "tensor([0., 1.]) tensor([0.8410, 0.1590], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 28 - 240: dog - cat || Loss: 1.1538609266281128\n",
      "tensor([0., 1.]) tensor([0.8406, 0.1594], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 28 - 241: dog - cat || Loss: 1.1534652709960938\n",
      "tensor([0., 1.]) tensor([0.8402, 0.1598], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 28 - 242: dog - cat || Loss: 1.1530685424804688\n",
      "tensor([0., 1.]) tensor([0.8398, 0.1602], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 28 - 243: dog - cat || Loss: 1.1526706218719482\n",
      "tensor([0., 1.]) tensor([0.8394, 0.1606], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 28 - 244: dog - cat || Loss: 1.1522713899612427\n",
      "tensor([0., 1.]) tensor([0.8390, 0.1610], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 28 - 245: dog - cat || Loss: 1.1518714427947998\n",
      "tensor([0., 1.]) tensor([0.8386, 0.1614], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 28 - 246: dog - cat || Loss: 1.1514700651168823\n",
      "tensor([0., 1.]) tensor([0.8382, 0.1618], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 28 - 247: dog - cat || Loss: 1.151067852973938\n",
      "tensor([0., 1.]) tensor([0.8378, 0.1622], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 28 - 248: dog - cat || Loss: 1.1506645679473877\n",
      "tensor([0., 1.]) tensor([0.8374, 0.1626], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 28 - 249: dog - cat || Loss: 1.150260090827942\n",
      "tensor([0., 1.]) tensor([0.8370, 0.1630], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 28 - 250: dog - cat || Loss: 1.1498547792434692\n",
      "tensor([0., 1.]) tensor([0.8366, 0.1634], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 28 - 251: dog - cat || Loss: 1.1494483947753906\n",
      "tensor([0., 1.]) tensor([0.8362, 0.1638], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 28 - 252: dog - cat || Loss: 1.149040937423706\n",
      "tensor([0., 1.]) tensor([0.8358, 0.1642], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 28 - 253: dog - cat || Loss: 1.1486326456069946\n",
      "tensor([0., 1.]) tensor([0.8354, 0.1646], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 28 - 254: dog - cat || Loss: 1.1482235193252563\n",
      "tensor([0., 1.]) tensor([0.8350, 0.1650], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 28 - 255: dog - cat || Loss: 1.1478132009506226\n",
      "tensor([0., 1.]) tensor([0.8346, 0.1654], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 28 - 256: dog - cat || Loss: 1.147402048110962\n",
      "tensor([0., 1.]) tensor([0.8341, 0.1659], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 28 - 257: dog - cat || Loss: 1.1469899415969849\n",
      "tensor([0., 1.]) tensor([0.8337, 0.1663], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 28 - 258: dog - cat || Loss: 1.1465768814086914\n",
      "tensor([0., 1.]) tensor([0.8333, 0.1667], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 28 - 259: dog - cat || Loss: 1.1461631059646606\n",
      "tensor([0., 1.]) tensor([0.8329, 0.1671], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 28 - 260: dog - cat || Loss: 1.1457480192184448\n",
      "tensor([0., 1.]) tensor([0.8325, 0.1675], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 28 - 261: dog - cat || Loss: 1.1453324556350708\n",
      "tensor([0., 1.]) tensor([0.8321, 0.1679], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 28 - 262: dog - cat || Loss: 1.1449155807495117\n",
      "tensor([0., 1.]) tensor([0.8317, 0.1683], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 28 - 263: dog - cat || Loss: 1.1444977521896362\n",
      "tensor([0., 1.]) tensor([0.8312, 0.1688], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 28 - 264: dog - cat || Loss: 1.1440794467926025\n",
      "tensor([0., 1.]) tensor([0.8308, 0.1692], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 28 - 265: dog - cat || Loss: 1.1436599493026733\n",
      "tensor([0., 1.]) tensor([0.8304, 0.1696], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 28 - 266: dog - cat || Loss: 1.1432397365570068\n",
      "tensor([0., 1.]) tensor([0.8300, 0.1700], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 28 - 267: dog - cat || Loss: 1.1428184509277344\n",
      "tensor([0., 1.]) tensor([0.8296, 0.1704], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 28 - 268: dog - cat || Loss: 1.142396330833435\n",
      "tensor([0., 1.]) tensor([0.8291, 0.1709], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 28 - 269: dog - cat || Loss: 1.1419733762741089\n",
      "tensor([0., 1.]) tensor([0.8287, 0.1713], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 28 - 270: dog - cat || Loss: 1.1415493488311768\n",
      "tensor([0., 1.]) tensor([0.8283, 0.1717], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 28 - 271: dog - cat || Loss: 1.1411247253417969\n",
      "tensor([0., 1.]) tensor([0.8279, 0.1721], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 28 - 272: dog - cat || Loss: 1.1406989097595215\n",
      "tensor([0., 1.]) tensor([0.8274, 0.1726], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 28 - 273: dog - cat || Loss: 1.1402723789215088\n",
      "tensor([0., 1.]) tensor([0.8270, 0.1730], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 28 - 274: dog - cat || Loss: 1.1398450136184692\n",
      "tensor([0., 1.]) tensor([0.8266, 0.1734], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 28 - 275: dog - cat || Loss: 1.1394166946411133\n",
      "tensor([0., 1.]) tensor([0.8262, 0.1738], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 28 - 276: dog - cat || Loss: 1.13898766040802\n",
      "tensor([0., 1.]) tensor([0.8257, 0.1743], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 28 - 277: dog - cat || Loss: 1.1385574340820312\n",
      "tensor([0., 1.]) tensor([0.8253, 0.1747], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 28 - 278: dog - cat || Loss: 1.1381263732910156\n",
      "tensor([0., 1.]) tensor([0.8249, 0.1751], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 28 - 279: dog - cat || Loss: 1.1376944780349731\n",
      "tensor([0., 1.]) tensor([0.8244, 0.1756], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 28 - 280: dog - cat || Loss: 1.1372617483139038\n",
      "tensor([0., 1.]) tensor([0.8240, 0.1760], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 28 - 281: dog - cat || Loss: 1.136828064918518\n",
      "tensor([0., 1.]) tensor([0.8236, 0.1764], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 28 - 282: dog - cat || Loss: 1.136393666267395\n",
      "tensor([0., 1.]) tensor([0.8231, 0.1769], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 28 - 283: dog - cat || Loss: 1.1359583139419556\n",
      "tensor([0., 1.]) tensor([0.8227, 0.1773], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 28 - 284: dog - cat || Loss: 1.1355221271514893\n",
      "tensor([0., 1.]) tensor([0.8223, 0.1777], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 28 - 285: dog - cat || Loss: 1.1350847482681274\n",
      "tensor([0., 1.]) tensor([0.8218, 0.1782], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 28 - 286: dog - cat || Loss: 1.1346466541290283\n",
      "tensor([0., 1.]) tensor([0.8214, 0.1786], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 28 - 287: dog - cat || Loss: 1.1342077255249023\n",
      "tensor([0., 1.]) tensor([0.8209, 0.1791], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 28 - 288: dog - cat || Loss: 1.1337679624557495\n",
      "tensor([0., 1.]) tensor([0.8205, 0.1795], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 28 - 289: dog - cat || Loss: 1.1333272457122803\n",
      "tensor([0., 1.]) tensor([0.8201, 0.1799], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 28 - 290: dog - cat || Loss: 1.1328856945037842\n",
      "tensor([0., 1.]) tensor([0.8196, 0.1804], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 28 - 291: dog - cat || Loss: 1.1324433088302612\n",
      "tensor([0., 1.]) tensor([0.8192, 0.1808], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 28 - 292: dog - cat || Loss: 1.1319997310638428\n",
      "tensor([0., 1.]) tensor([0.8187, 0.1813], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 28 - 293: dog - cat || Loss: 1.1315555572509766\n",
      "tensor([0., 1.]) tensor([0.8183, 0.1817], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 28 - 294: dog - cat || Loss: 1.1311103105545044\n",
      "tensor([0., 1.]) tensor([0.8178, 0.1822], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 28 - 295: dog - cat || Loss: 1.130664348602295\n",
      "tensor([0., 1.]) tensor([0.8174, 0.1826], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 28 - 296: dog - cat || Loss: 1.1302173137664795\n",
      "tensor([0., 1.]) tensor([0.8170, 0.1830], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 28 - 297: dog - cat || Loss: 1.1297698020935059\n",
      "tensor([0., 1.]) tensor([0.8165, 0.1835], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 28 - 298: dog - cat || Loss: 1.1293209791183472\n",
      "tensor([0., 1.]) tensor([0.8161, 0.1839], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 28 - 299: dog - cat || Loss: 1.1288714408874512\n",
      "tensor([0., 1.]) tensor([0.8156, 0.1844], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 28 - 300: dog - cat || Loss: 1.1284209489822388\n",
      "tensor([0., 1.]) tensor([0.8152, 0.1848], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 28 - 301: dog - cat || Loss: 1.1279696226119995\n",
      "tensor([0., 1.]) tensor([0.8147, 0.1853], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 28 - 302: dog - cat || Loss: 1.1275173425674438\n",
      "tensor([0., 1.]) tensor([0.8143, 0.1857], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 28 - 303: dog - cat || Loss: 1.1270643472671509\n",
      "tensor([0., 1.]) tensor([0.8138, 0.1862], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 28 - 304: dog - cat || Loss: 1.126610279083252\n",
      "tensor([0., 1.]) tensor([0.8133, 0.1867], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 28 - 305: dog - cat || Loss: 1.1261553764343262\n",
      "tensor([0., 1.]) tensor([0.8129, 0.1871], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 28 - 306: dog - cat || Loss: 1.1256996393203735\n",
      "tensor([0., 1.]) tensor([0.8124, 0.1876], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 28 - 307: dog - cat || Loss: 1.1252429485321045\n",
      "tensor([0., 1.]) tensor([0.8120, 0.1880], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 28 - 308: dog - cat || Loss: 1.124785304069519\n",
      "tensor([0., 1.]) tensor([0.8115, 0.1885], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 28 - 309: dog - cat || Loss: 1.1243270635604858\n",
      "tensor([0., 1.]) tensor([0.8111, 0.1889], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 28 - 310: dog - cat || Loss: 1.1238675117492676\n",
      "tensor([0., 1.]) tensor([0.8106, 0.1894], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 28 - 311: dog - cat || Loss: 1.1234073638916016\n",
      "tensor([0., 1.]) tensor([0.8101, 0.1899], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 28 - 312: dog - cat || Loss: 1.1229462623596191\n",
      "tensor([0., 1.]) tensor([0.8097, 0.1903], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 28 - 313: dog - cat || Loss: 1.1224842071533203\n",
      "tensor([0., 1.]) tensor([0.8092, 0.1908], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 28 - 314: dog - cat || Loss: 1.1220213174819946\n",
      "tensor([0., 1.]) tensor([0.8088, 0.1912], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 28 - 315: dog - cat || Loss: 1.1215574741363525\n",
      "tensor([0., 1.]) tensor([0.8083, 0.1917], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 28 - 316: dog - cat || Loss: 1.1210927963256836\n",
      "tensor([0., 1.]) tensor([0.8078, 0.1922], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 28 - 317: dog - cat || Loss: 1.1206271648406982\n",
      "tensor([0., 1.]) tensor([0.8074, 0.1926], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 28 - 318: dog - cat || Loss: 1.120160698890686\n",
      "tensor([0., 1.]) tensor([0.8069, 0.1931], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 28 - 319: dog - cat || Loss: 1.119693398475647\n",
      "tensor([0., 1.]) tensor([0.8064, 0.1936], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 28 - 320: dog - cat || Loss: 1.1192251443862915\n",
      "tensor([0., 1.]) tensor([0.8060, 0.1940], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 28 - 321: dog - cat || Loss: 1.11875581741333\n",
      "tensor([0., 1.]) tensor([0.8055, 0.1945], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 28 - 322: dog - cat || Loss: 1.1182857751846313\n",
      "tensor([0., 1.]) tensor([0.8050, 0.1950], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 28 - 323: dog - cat || Loss: 1.1178148984909058\n",
      "tensor([0., 1.]) tensor([0.8046, 0.1954], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 28 - 324: dog - cat || Loss: 1.1173430681228638\n",
      "tensor([0., 1.]) tensor([0.8041, 0.1959], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 28 - 325: dog - cat || Loss: 1.1168701648712158\n",
      "tensor([0., 1.]) tensor([0.8036, 0.1964], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 28 - 326: dog - cat || Loss: 1.1163965463638306\n",
      "tensor([0., 1.]) tensor([0.8031, 0.1969], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 28 - 327: dog - cat || Loss: 1.1159220933914185\n",
      "tensor([0., 1.]) tensor([0.8027, 0.1973], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 28 - 328: dog - cat || Loss: 1.11544668674469\n",
      "tensor([0., 1.]) tensor([0.8022, 0.1978], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 28 - 329: dog - cat || Loss: 1.114970326423645\n",
      "tensor([0., 1.]) tensor([0.8017, 0.1983], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 28 - 330: dog - cat || Loss: 1.1144931316375732\n",
      "tensor([0., 1.]) tensor([0.8012, 0.1988], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 28 - 331: dog - cat || Loss: 1.1140148639678955\n",
      "tensor([0., 1.]) tensor([0.8008, 0.1992], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 28 - 332: dog - cat || Loss: 1.11353600025177\n",
      "tensor([0., 1.]) tensor([0.8003, 0.1997], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 28 - 333: dog - cat || Loss: 1.113055944442749\n",
      "tensor([0., 1.]) tensor([0.7998, 0.2002], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 28 - 334: dog - cat || Loss: 1.1125751733779907\n",
      "tensor([0., 1.]) tensor([0.7993, 0.2007], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 28 - 335: dog - cat || Loss: 1.112093448638916\n",
      "tensor([0., 1.]) tensor([0.7988, 0.2012], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 28 - 336: dog - cat || Loss: 1.1116108894348145\n",
      "tensor([0., 1.]) tensor([0.7983, 0.2017], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 28 - 337: dog - cat || Loss: 1.1111273765563965\n",
      "tensor([0., 1.]) tensor([0.7979, 0.2021], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 28 - 338: dog - cat || Loss: 1.1106427907943726\n",
      "tensor([0., 1.]) tensor([0.7974, 0.2026], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 28 - 339: dog - cat || Loss: 1.1101576089859009\n",
      "tensor([0., 1.]) tensor([0.7969, 0.2031], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 28 - 340: dog - cat || Loss: 1.1096712350845337\n",
      "tensor([0., 1.]) tensor([0.7964, 0.2036], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 28 - 341: dog - cat || Loss: 1.1091842651367188\n",
      "tensor([0., 1.]) tensor([0.7959, 0.2041], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 28 - 342: dog - cat || Loss: 1.1086961030960083\n",
      "tensor([0., 1.]) tensor([0.7954, 0.2046], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 28 - 343: dog - cat || Loss: 1.1082072257995605\n",
      "tensor([0., 1.]) tensor([0.7949, 0.2051], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 28 - 344: dog - cat || Loss: 1.107717514038086\n",
      "tensor([0., 1.]) tensor([0.7945, 0.2055], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 28 - 345: dog - cat || Loss: 1.1072267293930054\n",
      "tensor([0., 1.]) tensor([0.7940, 0.2060], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 28 - 346: dog - cat || Loss: 1.106735110282898\n",
      "tensor([0., 1.]) tensor([0.7935, 0.2065], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 28 - 347: dog - cat || Loss: 1.1062425374984741\n",
      "tensor([0., 1.]) tensor([0.7930, 0.2070], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 28 - 348: dog - cat || Loss: 1.1057491302490234\n",
      "tensor([0., 1.]) tensor([0.7925, 0.2075], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 28 - 349: dog - cat || Loss: 1.1052547693252563\n",
      "tensor([0., 1.]) tensor([0.7920, 0.2080], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 28 - 350: dog - cat || Loss: 1.1047595739364624\n",
      "tensor([0., 1.]) tensor([0.7915, 0.2085], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 28 - 351: dog - cat || Loss: 1.104263424873352\n",
      "tensor([0., 1.]) tensor([0.7910, 0.2090], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 28 - 352: dog - cat || Loss: 1.1037663221359253\n",
      "tensor([0., 1.]) tensor([0.7905, 0.2095], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 28 - 353: dog - cat || Loss: 1.1032682657241821\n",
      "tensor([0., 1.]) tensor([0.7900, 0.2100], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 28 - 354: dog - cat || Loss: 1.102769374847412\n",
      "tensor([0., 1.]) tensor([0.7895, 0.2105], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 28 - 355: dog - cat || Loss: 1.1022696495056152\n",
      "tensor([0., 1.]) tensor([0.7890, 0.2110], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 28 - 356: dog - cat || Loss: 1.101768970489502\n",
      "tensor([0., 1.]) tensor([0.7885, 0.2115], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 28 - 357: dog - cat || Loss: 1.1012675762176514\n",
      "tensor([0., 1.]) tensor([0.7880, 0.2120], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 28 - 358: dog - cat || Loss: 1.1007651090621948\n",
      "tensor([0., 1.]) tensor([0.7875, 0.2125], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 28 - 359: dog - cat || Loss: 1.1002616882324219\n",
      "tensor([0., 1.]) tensor([0.7870, 0.2130], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 28 - 360: dog - cat || Loss: 1.099757432937622\n",
      "tensor([0., 1.]) tensor([0.7865, 0.2135], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 28 - 361: dog - cat || Loss: 1.0992523431777954\n",
      "tensor([0., 1.]) tensor([0.7860, 0.2140], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 28 - 362: dog - cat || Loss: 1.0987462997436523\n",
      "tensor([0., 1.]) tensor([0.7855, 0.2145], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 28 - 363: dog - cat || Loss: 1.0982393026351929\n",
      "tensor([0., 1.]) tensor([0.7850, 0.2150], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 28 - 364: dog - cat || Loss: 1.097731590270996\n",
      "tensor([0., 1.]) tensor([0.7845, 0.2155], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 28 - 365: dog - cat || Loss: 1.0972226858139038\n",
      "tensor([0., 1.]) tensor([0.7840, 0.2160], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 28 - 366: dog - cat || Loss: 1.0967130661010742\n",
      "tensor([0., 1.]) tensor([0.7835, 0.2165], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 28 - 367: dog - cat || Loss: 1.0962026119232178\n",
      "tensor([0., 1.]) tensor([0.7829, 0.2171], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 28 - 368: dog - cat || Loss: 1.0956910848617554\n",
      "tensor([0., 1.]) tensor([0.7824, 0.2176], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 28 - 369: dog - cat || Loss: 1.0951787233352661\n",
      "tensor([0., 1.]) tensor([0.7819, 0.2181], grad_fn=<SoftmaxBackward0>)\n",
      "=====epoch:29=====\n",
      "Epoch 29 - 0: cat - cat || Loss: 0.5318578481674194\n",
      "tensor([1., 0.]) tensor([0.7814, 0.2186], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 29 - 1: cat - cat || Loss: 0.5322682857513428\n",
      "tensor([1., 0.]) tensor([0.7810, 0.2190], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 29 - 2: cat - cat || Loss: 0.5325860977172852\n",
      "tensor([1., 0.]) tensor([0.7807, 0.2193], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 29 - 3: cat - cat || Loss: 0.5328201651573181\n",
      "tensor([1., 0.]) tensor([0.7804, 0.2196], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 29 - 4: cat - cat || Loss: 0.5329790115356445\n",
      "tensor([1., 0.]) tensor([0.7803, 0.2197], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 29 - 5: cat - cat || Loss: 0.5330699682235718\n",
      "tensor([1., 0.]) tensor([0.7802, 0.2198], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 29 - 6: cat - cat || Loss: 0.5330997705459595\n",
      "tensor([1., 0.]) tensor([0.7802, 0.2198], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 29 - 7: cat - cat || Loss: 0.5330745577812195\n",
      "tensor([1., 0.]) tensor([0.7802, 0.2198], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 29 - 8: cat - cat || Loss: 0.5329999923706055\n",
      "tensor([1., 0.]) tensor([0.7803, 0.2197], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 29 - 9: cat - cat || Loss: 0.5328806638717651\n",
      "tensor([1., 0.]) tensor([0.7804, 0.2196], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 29 - 10: cat - cat || Loss: 0.5327214598655701\n",
      "tensor([1., 0.]) tensor([0.7805, 0.2195], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 29 - 11: cat - cat || Loss: 0.5325263738632202\n",
      "tensor([1., 0.]) tensor([0.7807, 0.2193], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 29 - 12: cat - cat || Loss: 0.5322988629341125\n",
      "tensor([1., 0.]) tensor([0.7810, 0.2190], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 29 - 13: cat - cat || Loss: 0.5320422649383545\n",
      "tensor([1., 0.]) tensor([0.7812, 0.2188], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 29 - 14: cat - cat || Loss: 0.5317597389221191\n",
      "tensor([1., 0.]) tensor([0.7815, 0.2185], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 29 - 15: cat - cat || Loss: 0.5314537882804871\n",
      "tensor([1., 0.]) tensor([0.7818, 0.2182], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 29 - 16: cat - cat || Loss: 0.5311269760131836\n",
      "tensor([1., 0.]) tensor([0.7821, 0.2179], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 29 - 17: cat - cat || Loss: 0.5307812690734863\n",
      "tensor([1., 0.]) tensor([0.7825, 0.2175], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 29 - 18: cat - cat || Loss: 0.5304187536239624\n",
      "tensor([1., 0.]) tensor([0.7828, 0.2172], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 29 - 19: cat - cat || Loss: 0.5300412774085999\n",
      "tensor([1., 0.]) tensor([0.7832, 0.2168], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 29 - 20: cat - cat || Loss: 0.5296502113342285\n",
      "tensor([1., 0.]) tensor([0.7836, 0.2164], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 29 - 21: cat - cat || Loss: 0.5292472243309021\n",
      "tensor([1., 0.]) tensor([0.7840, 0.2160], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 29 - 22: cat - cat || Loss: 0.5288335084915161\n",
      "tensor([1., 0.]) tensor([0.7844, 0.2156], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 29 - 23: cat - cat || Loss: 0.5284101366996765\n",
      "tensor([1., 0.]) tensor([0.7849, 0.2151], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 29 - 24: cat - cat || Loss: 0.5279781818389893\n",
      "tensor([1., 0.]) tensor([0.7853, 0.2147], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 29 - 25: cat - cat || Loss: 0.5275387763977051\n",
      "tensor([1., 0.]) tensor([0.7857, 0.2143], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 29 - 26: cat - cat || Loss: 0.5270925760269165\n",
      "tensor([1., 0.]) tensor([0.7862, 0.2138], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 29 - 27: cat - cat || Loss: 0.5266404747962952\n",
      "tensor([1., 0.]) tensor([0.7866, 0.2134], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 29 - 28: cat - cat || Loss: 0.526183009147644\n",
      "tensor([1., 0.]) tensor([0.7871, 0.2129], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 29 - 29: cat - cat || Loss: 0.5257208347320557\n",
      "tensor([1., 0.]) tensor([0.7875, 0.2125], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 29 - 30: cat - cat || Loss: 0.5252546668052673\n",
      "tensor([1., 0.]) tensor([0.7880, 0.2120], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 29 - 31: cat - cat || Loss: 0.5247847437858582\n",
      "tensor([1., 0.]) tensor([0.7885, 0.2115], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 29 - 32: cat - cat || Loss: 0.5243117809295654\n",
      "tensor([1., 0.]) tensor([0.7889, 0.2111], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 29 - 33: cat - cat || Loss: 0.5238361954689026\n",
      "tensor([1., 0.]) tensor([0.7894, 0.2106], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 29 - 34: cat - cat || Loss: 0.5233580470085144\n",
      "tensor([1., 0.]) tensor([0.7899, 0.2101], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 29 - 35: cat - cat || Loss: 0.5228779911994934\n",
      "tensor([1., 0.]) tensor([0.7904, 0.2096], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 29 - 36: cat - cat || Loss: 0.5223960876464844\n",
      "tensor([1., 0.]) tensor([0.7909, 0.2091], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 29 - 37: cat - cat || Loss: 0.5219128131866455\n",
      "tensor([1., 0.]) tensor([0.7913, 0.2087], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 29 - 38: cat - cat || Loss: 0.5214282274246216\n",
      "tensor([1., 0.]) tensor([0.7918, 0.2082], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 29 - 39: cat - cat || Loss: 0.5209425687789917\n",
      "tensor([1., 0.]) tensor([0.7923, 0.2077], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 29 - 40: cat - cat || Loss: 0.5204562544822693\n",
      "tensor([1., 0.]) tensor([0.7928, 0.2072], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 29 - 41: cat - cat || Loss: 0.51996910572052\n",
      "tensor([1., 0.]) tensor([0.7933, 0.2067], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 29 - 42: cat - cat || Loss: 0.5194815993309021\n",
      "tensor([1., 0.]) tensor([0.7938, 0.2062], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 29 - 43: cat - cat || Loss: 0.518993616104126\n",
      "tensor([1., 0.]) tensor([0.7943, 0.2057], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 29 - 44: cat - cat || Loss: 0.5185056924819946\n",
      "tensor([1., 0.]) tensor([0.7948, 0.2052], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 29 - 45: cat - cat || Loss: 0.5180174112319946\n",
      "tensor([1., 0.]) tensor([0.7952, 0.2048], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 29 - 46: cat - cat || Loss: 0.5175292491912842\n",
      "tensor([1., 0.]) tensor([0.7957, 0.2043], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 29 - 47: cat - cat || Loss: 0.5170410871505737\n",
      "tensor([1., 0.]) tensor([0.7962, 0.2038], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 29 - 48: cat - cat || Loss: 0.5165532827377319\n",
      "tensor([1., 0.]) tensor([0.7967, 0.2033], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 29 - 49: cat - cat || Loss: 0.5160655975341797\n",
      "tensor([1., 0.]) tensor([0.7972, 0.2028], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 29 - 50: cat - cat || Loss: 0.5155782699584961\n",
      "tensor([1., 0.]) tensor([0.7977, 0.2023], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 29 - 51: cat - cat || Loss: 0.5150913596153259\n",
      "tensor([1., 0.]) tensor([0.7982, 0.2018], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 29 - 52: cat - cat || Loss: 0.5146048069000244\n",
      "tensor([1., 0.]) tensor([0.7987, 0.2013], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 29 - 53: cat - cat || Loss: 0.5141188502311707\n",
      "tensor([1., 0.]) tensor([0.7991, 0.2009], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 29 - 54: cat - cat || Loss: 0.5136333703994751\n",
      "tensor([1., 0.]) tensor([0.7996, 0.2004], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 29 - 55: cat - cat || Loss: 0.5131484270095825\n",
      "tensor([1., 0.]) tensor([0.8001, 0.1999], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 29 - 56: cat - cat || Loss: 0.5126641988754272\n",
      "tensor([1., 0.]) tensor([0.8006, 0.1994], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 29 - 57: cat - cat || Loss: 0.5121804475784302\n",
      "tensor([1., 0.]) tensor([0.8011, 0.1989], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 29 - 58: cat - cat || Loss: 0.51169753074646\n",
      "tensor([1., 0.]) tensor([0.8016, 0.1984], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 29 - 59: cat - cat || Loss: 0.5112152695655823\n",
      "tensor([1., 0.]) tensor([0.8020, 0.1980], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 29 - 60: cat - cat || Loss: 0.5107337236404419\n",
      "tensor([1., 0.]) tensor([0.8025, 0.1975], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 29 - 61: cat - cat || Loss: 0.510252833366394\n",
      "tensor([1., 0.]) tensor([0.8030, 0.1970], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 29 - 62: cat - cat || Loss: 0.5097727179527283\n",
      "tensor([1., 0.]) tensor([0.8035, 0.1965], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 29 - 63: cat - cat || Loss: 0.5092934370040894\n",
      "tensor([1., 0.]) tensor([0.8040, 0.1960], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 29 - 64: cat - cat || Loss: 0.5088149309158325\n",
      "tensor([1., 0.]) tensor([0.8044, 0.1956], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 29 - 65: cat - cat || Loss: 0.5083372592926025\n",
      "tensor([1., 0.]) tensor([0.8049, 0.1951], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 29 - 66: cat - cat || Loss: 0.5078603029251099\n",
      "tensor([1., 0.]) tensor([0.8054, 0.1946], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 29 - 67: cat - cat || Loss: 0.5073843002319336\n",
      "tensor([1., 0.]) tensor([0.8059, 0.1941], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 29 - 68: cat - cat || Loss: 0.5069090723991394\n",
      "tensor([1., 0.]) tensor([0.8064, 0.1936], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 29 - 69: cat - cat || Loss: 0.5064345598220825\n",
      "tensor([1., 0.]) tensor([0.8068, 0.1932], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 29 - 70: cat - cat || Loss: 0.5059611201286316\n",
      "tensor([1., 0.]) tensor([0.8073, 0.1927], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 29 - 71: cat - cat || Loss: 0.5054885149002075\n",
      "tensor([1., 0.]) tensor([0.8078, 0.1922], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 29 - 72: cat - cat || Loss: 0.5050166845321655\n",
      "tensor([1., 0.]) tensor([0.8082, 0.1918], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 29 - 73: cat - cat || Loss: 0.5045456886291504\n",
      "tensor([1., 0.]) tensor([0.8087, 0.1913], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 29 - 74: cat - cat || Loss: 0.5040756464004517\n",
      "tensor([1., 0.]) tensor([0.8092, 0.1908], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 29 - 75: cat - cat || Loss: 0.5036064982414246\n",
      "tensor([1., 0.]) tensor([0.8097, 0.1903], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 29 - 76: cat - cat || Loss: 0.5031383037567139\n",
      "tensor([1., 0.]) tensor([0.8101, 0.1899], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 29 - 77: cat - cat || Loss: 0.5026710033416748\n",
      "tensor([1., 0.]) tensor([0.8106, 0.1894], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 29 - 78: cat - cat || Loss: 0.5022044777870178\n",
      "tensor([1., 0.]) tensor([0.8111, 0.1889], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 29 - 79: cat - cat || Loss: 0.5017390251159668\n",
      "tensor([1., 0.]) tensor([0.8115, 0.1885], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 29 - 80: cat - cat || Loss: 0.5012743473052979\n",
      "tensor([1., 0.]) tensor([0.8120, 0.1880], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 29 - 81: cat - cat || Loss: 0.5008105039596558\n",
      "tensor([1., 0.]) tensor([0.8125, 0.1875], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 29 - 82: cat - cat || Loss: 0.5003476738929749\n",
      "tensor([1., 0.]) tensor([0.8129, 0.1871], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 29 - 83: cat - cat || Loss: 0.49988579750061035\n",
      "tensor([1., 0.]) tensor([0.8134, 0.1866], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 29 - 84: cat - cat || Loss: 0.4994248151779175\n",
      "tensor([1., 0.]) tensor([0.8138, 0.1862], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 29 - 85: cat - cat || Loss: 0.49896472692489624\n",
      "tensor([1., 0.]) tensor([0.8143, 0.1857], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 29 - 86: cat - cat || Loss: 0.498505562543869\n",
      "tensor([1., 0.]) tensor([0.8148, 0.1852], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 29 - 87: cat - cat || Loss: 0.49804723262786865\n",
      "tensor([1., 0.]) tensor([0.8152, 0.1848], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 29 - 88: cat - cat || Loss: 0.4975898265838623\n",
      "tensor([1., 0.]) tensor([0.8157, 0.1843], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 29 - 89: cat - cat || Loss: 0.49713337421417236\n",
      "tensor([1., 0.]) tensor([0.8161, 0.1839], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 29 - 90: cat - cat || Loss: 0.4966779351234436\n",
      "tensor([1., 0.]) tensor([0.8166, 0.1834], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 29 - 91: cat - cat || Loss: 0.49622318148612976\n",
      "tensor([1., 0.]) tensor([0.8170, 0.1830], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 29 - 92: cat - cat || Loss: 0.49576956033706665\n",
      "tensor([1., 0.]) tensor([0.8175, 0.1825], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 29 - 93: cat - cat || Loss: 0.495316743850708\n",
      "tensor([1., 0.]) tensor([0.8179, 0.1821], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 29 - 94: cat - cat || Loss: 0.494864821434021\n",
      "tensor([1., 0.]) tensor([0.8184, 0.1816], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 29 - 95: cat - cat || Loss: 0.4944137930870056\n",
      "tensor([1., 0.]) tensor([0.8188, 0.1812], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 29 - 96: cat - cat || Loss: 0.4939637780189514\n",
      "tensor([1., 0.]) tensor([0.8193, 0.1807], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 29 - 97: cat - cat || Loss: 0.49351465702056885\n",
      "tensor([1., 0.]) tensor([0.8197, 0.1803], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 29 - 98: cat - cat || Loss: 0.49306634068489075\n",
      "tensor([1., 0.]) tensor([0.8202, 0.1798], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 29 - 99: cat - cat || Loss: 0.492619127035141\n",
      "tensor([1., 0.]) tensor([0.8206, 0.1794], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 29 - 100: cat - cat || Loss: 0.4921726584434509\n",
      "tensor([1., 0.]) tensor([0.8211, 0.1789], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 29 - 101: cat - cat || Loss: 0.49172717332839966\n",
      "tensor([1., 0.]) tensor([0.8215, 0.1785], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 29 - 102: cat - cat || Loss: 0.4912826418876648\n",
      "tensor([1., 0.]) tensor([0.8220, 0.1780], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 29 - 103: cat - cat || Loss: 0.49083900451660156\n",
      "tensor([1., 0.]) tensor([0.8224, 0.1776], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 29 - 104: cat - cat || Loss: 0.49039626121520996\n",
      "tensor([1., 0.]) tensor([0.8229, 0.1771], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 29 - 105: cat - cat || Loss: 0.48995447158813477\n",
      "tensor([1., 0.]) tensor([0.8233, 0.1767], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 29 - 106: cat - cat || Loss: 0.4895135760307312\n",
      "tensor([1., 0.]) tensor([0.8237, 0.1763], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 29 - 107: cat - cat || Loss: 0.4890735149383545\n",
      "tensor([1., 0.]) tensor([0.8242, 0.1758], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 29 - 108: cat - cat || Loss: 0.48863452672958374\n",
      "tensor([1., 0.]) tensor([0.8246, 0.1754], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 29 - 109: cat - cat || Loss: 0.48819637298583984\n",
      "tensor([1., 0.]) tensor([0.8251, 0.1749], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 29 - 110: cat - cat || Loss: 0.487758994102478\n",
      "tensor([1., 0.]) tensor([0.8255, 0.1745], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 29 - 111: cat - cat || Loss: 0.48732277750968933\n",
      "tensor([1., 0.]) tensor([0.8259, 0.1741], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 29 - 112: cat - cat || Loss: 0.4868873357772827\n",
      "tensor([1., 0.]) tensor([0.8264, 0.1736], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 29 - 113: cat - cat || Loss: 0.4864528775215149\n",
      "tensor([1., 0.]) tensor([0.8268, 0.1732], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 29 - 114: cat - cat || Loss: 0.48601919412612915\n",
      "tensor([1., 0.]) tensor([0.8272, 0.1728], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 29 - 115: cat - cat || Loss: 0.4855865240097046\n",
      "tensor([1., 0.]) tensor([0.8277, 0.1723], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 29 - 116: cat - cat || Loss: 0.48515474796295166\n",
      "tensor([1., 0.]) tensor([0.8281, 0.1719], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 29 - 117: cat - cat || Loss: 0.48472392559051514\n",
      "tensor([1., 0.]) tensor([0.8285, 0.1715], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 29 - 118: cat - cat || Loss: 0.4842938780784607\n",
      "tensor([1., 0.]) tensor([0.8290, 0.1710], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 29 - 119: cat - cat || Loss: 0.4838649034500122\n",
      "tensor([1., 0.]) tensor([0.8294, 0.1706], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 29 - 120: cat - cat || Loss: 0.4834367036819458\n",
      "tensor([1., 0.]) tensor([0.8298, 0.1702], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 29 - 121: cat - cat || Loss: 0.4830094575881958\n",
      "tensor([1., 0.]) tensor([0.8303, 0.1697], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 29 - 122: cat - cat || Loss: 0.4825831651687622\n",
      "tensor([1., 0.]) tensor([0.8307, 0.1693], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 29 - 123: cat - cat || Loss: 0.48215776681900024\n",
      "tensor([1., 0.]) tensor([0.8311, 0.1689], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 29 - 124: cat - cat || Loss: 0.48173320293426514\n",
      "tensor([1., 0.]) tensor([0.8315, 0.1685], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 29 - 125: cat - cat || Loss: 0.4813096821308136\n",
      "tensor([1., 0.]) tensor([0.8320, 0.1680], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 29 - 126: cat - cat || Loss: 0.4808869957923889\n",
      "tensor([1., 0.]) tensor([0.8324, 0.1676], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 29 - 127: cat - cat || Loss: 0.4804651141166687\n",
      "tensor([1., 0.]) tensor([0.8328, 0.1672], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 29 - 128: cat - cat || Loss: 0.48004430532455444\n",
      "tensor([1., 0.]) tensor([0.8332, 0.1668], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 29 - 129: cat - cat || Loss: 0.47962433099746704\n",
      "tensor([1., 0.]) tensor([0.8336, 0.1664], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 29 - 130: cat - cat || Loss: 0.47920525074005127\n",
      "tensor([1., 0.]) tensor([0.8341, 0.1659], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 29 - 131: cat - cat || Loss: 0.47878706455230713\n",
      "tensor([1., 0.]) tensor([0.8345, 0.1655], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 29 - 132: cat - cat || Loss: 0.4783698320388794\n",
      "tensor([1., 0.]) tensor([0.8349, 0.1651], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 29 - 133: cat - cat || Loss: 0.4779534935951233\n",
      "tensor([1., 0.]) tensor([0.8353, 0.1647], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 29 - 134: cat - cat || Loss: 0.47753795981407166\n",
      "tensor([1., 0.]) tensor([0.8357, 0.1643], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 29 - 135: cat - cat || Loss: 0.477123498916626\n",
      "tensor([1., 0.]) tensor([0.8361, 0.1639], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 29 - 136: cat - cat || Loss: 0.47670984268188477\n",
      "tensor([1., 0.]) tensor([0.8366, 0.1634], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 29 - 137: cat - cat || Loss: 0.4762970209121704\n",
      "tensor([1., 0.]) tensor([0.8370, 0.1630], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 29 - 138: cat - cat || Loss: 0.47588521242141724\n",
      "tensor([1., 0.]) tensor([0.8374, 0.1626], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 29 - 139: cat - cat || Loss: 0.4754742383956909\n",
      "tensor([1., 0.]) tensor([0.8378, 0.1622], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 29 - 140: cat - cat || Loss: 0.47506412863731384\n",
      "tensor([1., 0.]) tensor([0.8382, 0.1618], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 29 - 141: cat - cat || Loss: 0.47465500235557556\n",
      "tensor([1., 0.]) tensor([0.8386, 0.1614], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 29 - 142: cat - cat || Loss: 0.47424671053886414\n",
      "tensor([1., 0.]) tensor([0.8390, 0.1610], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 29 - 143: cat - cat || Loss: 0.4738391935825348\n",
      "tensor([1., 0.]) tensor([0.8394, 0.1606], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 29 - 144: cat - cat || Loss: 0.47343286871910095\n",
      "tensor([1., 0.]) tensor([0.8398, 0.1602], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 29 - 145: cat - cat || Loss: 0.47302722930908203\n",
      "tensor([1., 0.]) tensor([0.8402, 0.1598], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 29 - 146: cat - cat || Loss: 0.4726226329803467\n",
      "tensor([1., 0.]) tensor([0.8406, 0.1594], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 29 - 147: cat - cat || Loss: 0.47221893072128296\n",
      "tensor([1., 0.]) tensor([0.8410, 0.1590], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 29 - 148: cat - cat || Loss: 0.47181597352027893\n",
      "tensor([1., 0.]) tensor([0.8414, 0.1586], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 29 - 149: cat - cat || Loss: 0.4714140295982361\n",
      "tensor([1., 0.]) tensor([0.8418, 0.1582], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 29 - 150: cat - cat || Loss: 0.4710129201412201\n",
      "tensor([1., 0.]) tensor([0.8422, 0.1578], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 29 - 151: cat - cat || Loss: 0.4706127345561981\n",
      "tensor([1., 0.]) tensor([0.8426, 0.1574], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 29 - 152: cat - cat || Loss: 0.4702134430408478\n",
      "tensor([1., 0.]) tensor([0.8430, 0.1570], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 29 - 153: cat - cat || Loss: 0.4698149859905243\n",
      "tensor([1., 0.]) tensor([0.8434, 0.1566], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 29 - 154: cat - cat || Loss: 0.46941742300987244\n",
      "tensor([1., 0.]) tensor([0.8438, 0.1562], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 29 - 155: cat - cat || Loss: 0.46902066469192505\n",
      "tensor([1., 0.]) tensor([0.8442, 0.1558], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 29 - 156: cat - cat || Loss: 0.46862494945526123\n",
      "tensor([1., 0.]) tensor([0.8446, 0.1554], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 29 - 157: cat - cat || Loss: 0.46823006868362427\n",
      "tensor([1., 0.]) tensor([0.8450, 0.1550], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 29 - 158: cat - cat || Loss: 0.46783602237701416\n",
      "tensor([1., 0.]) tensor([0.8454, 0.1546], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 29 - 159: cat - cat || Loss: 0.4674427807331085\n",
      "tensor([1., 0.]) tensor([0.8458, 0.1542], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 29 - 160: cat - cat || Loss: 0.4670504927635193\n",
      "tensor([1., 0.]) tensor([0.8462, 0.1538], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 29 - 161: cat - cat || Loss: 0.46665918827056885\n",
      "tensor([1., 0.]) tensor([0.8466, 0.1534], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 29 - 162: cat - cat || Loss: 0.4662686884403229\n",
      "tensor([1., 0.]) tensor([0.8470, 0.1530], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 29 - 163: cat - cat || Loss: 0.4658789336681366\n",
      "tensor([1., 0.]) tensor([0.8474, 0.1526], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 29 - 164: cat - cat || Loss: 0.4654902219772339\n",
      "tensor([1., 0.]) tensor([0.8478, 0.1522], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 29 - 165: cat - cat || Loss: 0.46510231494903564\n",
      "tensor([1., 0.]) tensor([0.8482, 0.1518], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 29 - 166: cat - cat || Loss: 0.46471527218818665\n",
      "tensor([1., 0.]) tensor([0.8485, 0.1515], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 29 - 167: cat - cat || Loss: 0.4643290936946869\n",
      "tensor([1., 0.]) tensor([0.8489, 0.1511], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 29 - 168: cat - cat || Loss: 0.4639438986778259\n",
      "tensor([1., 0.]) tensor([0.8493, 0.1507], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 29 - 169: cat - cat || Loss: 0.46355944871902466\n",
      "tensor([1., 0.]) tensor([0.8497, 0.1503], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 29 - 170: cat - cat || Loss: 0.46317586302757263\n",
      "tensor([1., 0.]) tensor([0.8501, 0.1499], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 29 - 171: cat - cat || Loss: 0.462793231010437\n",
      "tensor([1., 0.]) tensor([0.8505, 0.1495], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 29 - 172: cat - cat || Loss: 0.46241140365600586\n",
      "tensor([1., 0.]) tensor([0.8509, 0.1491], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 29 - 173: cat - cat || Loss: 0.4620305299758911\n",
      "tensor([1., 0.]) tensor([0.8512, 0.1488], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 29 - 174: cat - cat || Loss: 0.4616505205631256\n",
      "tensor([1., 0.]) tensor([0.8516, 0.1484], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 29 - 175: cat - cat || Loss: 0.4612712860107422\n",
      "tensor([1., 0.]) tensor([0.8520, 0.1480], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 29 - 176: cat - cat || Loss: 0.4608929455280304\n",
      "tensor([1., 0.]) tensor([0.8524, 0.1476], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 29 - 177: cat - cat || Loss: 0.460515558719635\n",
      "tensor([1., 0.]) tensor([0.8527, 0.1473], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 29 - 178: cat - cat || Loss: 0.4601389169692993\n",
      "tensor([1., 0.]) tensor([0.8531, 0.1469], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 29 - 179: cat - cat || Loss: 0.45976319909095764\n",
      "tensor([1., 0.]) tensor([0.8535, 0.1465], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 29 - 180: cat - cat || Loss: 0.45938825607299805\n",
      "tensor([1., 0.]) tensor([0.8539, 0.1461], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 29 - 181: cat - cat || Loss: 0.4590142071247101\n",
      "tensor([1., 0.]) tensor([0.8542, 0.1458], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 29 - 182: cat - cat || Loss: 0.45864105224609375\n",
      "tensor([1., 0.]) tensor([0.8546, 0.1454], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 29 - 183: cat - cat || Loss: 0.4582688510417938\n",
      "tensor([1., 0.]) tensor([0.8550, 0.1450], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 29 - 184: cat - cat || Loss: 0.4578973054885864\n",
      "tensor([1., 0.]) tensor([0.8554, 0.1446], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 29 - 185: cat - cat || Loss: 0.4575268626213074\n",
      "tensor([1., 0.]) tensor([0.8557, 0.1443], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 29 - 186: cat - cat || Loss: 0.4571570158004761\n",
      "tensor([1., 0.]) tensor([0.8561, 0.1439], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 29 - 187: cat - cat || Loss: 0.45678800344467163\n",
      "tensor([1., 0.]) tensor([0.8565, 0.1435], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 29 - 188: cat - cat || Loss: 0.4564199447631836\n",
      "tensor([1., 0.]) tensor([0.8568, 0.1432], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 29 - 189: cat - cat || Loss: 0.4560527205467224\n",
      "tensor([1., 0.]) tensor([0.8572, 0.1428], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 29 - 190: dog - cat || Loss: 1.170837163925171\n",
      "tensor([0., 1.]) tensor([0.8576, 0.1424], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 29 - 191: dog - cat || Loss: 1.1711302995681763\n",
      "tensor([0., 1.]) tensor([0.8579, 0.1421], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 29 - 192: dog - cat || Loss: 1.1713577508926392\n",
      "tensor([0., 1.]) tensor([0.8581, 0.1419], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 29 - 193: dog - cat || Loss: 1.171526312828064\n",
      "tensor([0., 1.]) tensor([0.8583, 0.1417], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 29 - 194: dog - cat || Loss: 1.1716418266296387\n",
      "tensor([0., 1.]) tensor([0.8584, 0.1416], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 29 - 195: dog - cat || Loss: 1.1717098951339722\n",
      "tensor([0., 1.]) tensor([0.8584, 0.1416], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 29 - 196: dog - cat || Loss: 1.1717349290847778\n",
      "tensor([0., 1.]) tensor([0.8585, 0.1415], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 29 - 197: dog - cat || Loss: 1.1717214584350586\n",
      "tensor([0., 1.]) tensor([0.8585, 0.1415], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 29 - 198: dog - cat || Loss: 1.17167329788208\n",
      "tensor([0., 1.]) tensor([0.8584, 0.1416], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 29 - 199: dog - cat || Loss: 1.1715941429138184\n",
      "tensor([0., 1.]) tensor([0.8583, 0.1417], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 29 - 200: dog - cat || Loss: 1.1714866161346436\n",
      "tensor([0., 1.]) tensor([0.8582, 0.1418], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 29 - 201: dog - cat || Loss: 1.171353816986084\n",
      "tensor([0., 1.]) tensor([0.8581, 0.1419], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 29 - 202: dog - cat || Loss: 1.1711981296539307\n",
      "tensor([0., 1.]) tensor([0.8579, 0.1421], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 29 - 203: dog - cat || Loss: 1.171021819114685\n",
      "tensor([0., 1.]) tensor([0.8578, 0.1422], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 29 - 204: dog - cat || Loss: 1.170827031135559\n",
      "tensor([0., 1.]) tensor([0.8576, 0.1424], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 29 - 205: dog - cat || Loss: 1.1706151962280273\n",
      "tensor([0., 1.]) tensor([0.8574, 0.1426], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 29 - 206: dog - cat || Loss: 1.170388102531433\n",
      "tensor([0., 1.]) tensor([0.8571, 0.1429], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 29 - 207: dog - cat || Loss: 1.1701475381851196\n",
      "tensor([0., 1.]) tensor([0.8569, 0.1431], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 29 - 208: dog - cat || Loss: 1.1698943376541138\n",
      "tensor([0., 1.]) tensor([0.8566, 0.1434], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 29 - 209: dog - cat || Loss: 1.1696299314498901\n",
      "tensor([0., 1.]) tensor([0.8564, 0.1436], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 29 - 210: dog - cat || Loss: 1.1693551540374756\n",
      "tensor([0., 1.]) tensor([0.8561, 0.1439], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 29 - 211: dog - cat || Loss: 1.1690714359283447\n",
      "tensor([0., 1.]) tensor([0.8558, 0.1442], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 29 - 212: dog - cat || Loss: 1.1687787771224976\n",
      "tensor([0., 1.]) tensor([0.8555, 0.1445], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 29 - 213: dog - cat || Loss: 1.1684787273406982\n",
      "tensor([0., 1.]) tensor([0.8552, 0.1448], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 29 - 214: dog - cat || Loss: 1.1681716442108154\n",
      "tensor([0., 1.]) tensor([0.8549, 0.1451], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 29 - 215: dog - cat || Loss: 1.1678581237792969\n",
      "tensor([0., 1.]) tensor([0.8546, 0.1454], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 29 - 216: dog - cat || Loss: 1.1675390005111694\n",
      "tensor([0., 1.]) tensor([0.8543, 0.1457], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 29 - 217: dog - cat || Loss: 1.167214274406433\n",
      "tensor([0., 1.]) tensor([0.8540, 0.1460], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 29 - 218: dog - cat || Loss: 1.1668850183486938\n",
      "tensor([0., 1.]) tensor([0.8536, 0.1464], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 29 - 219: dog - cat || Loss: 1.1665509939193726\n",
      "tensor([0., 1.]) tensor([0.8533, 0.1467], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 29 - 220: dog - cat || Loss: 1.166213035583496\n",
      "tensor([0., 1.]) tensor([0.8530, 0.1470], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 29 - 221: dog - cat || Loss: 1.1658713817596436\n",
      "tensor([0., 1.]) tensor([0.8526, 0.1474], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 29 - 222: dog - cat || Loss: 1.1655261516571045\n",
      "tensor([0., 1.]) tensor([0.8523, 0.1477], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 29 - 223: dog - cat || Loss: 1.1651777029037476\n",
      "tensor([0., 1.]) tensor([0.8519, 0.1481], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 29 - 224: dog - cat || Loss: 1.1648263931274414\n",
      "tensor([0., 1.]) tensor([0.8516, 0.1484], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 29 - 225: dog - cat || Loss: 1.164472222328186\n",
      "tensor([0., 1.]) tensor([0.8512, 0.1488], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 29 - 226: dog - cat || Loss: 1.16411554813385\n",
      "tensor([0., 1.]) tensor([0.8509, 0.1491], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 29 - 227: dog - cat || Loss: 1.1637564897537231\n",
      "tensor([0., 1.]) tensor([0.8505, 0.1495], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 29 - 228: dog - cat || Loss: 1.1633951663970947\n",
      "tensor([0., 1.]) tensor([0.8501, 0.1499], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 29 - 229: dog - cat || Loss: 1.163031816482544\n",
      "tensor([0., 1.]) tensor([0.8498, 0.1502], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 29 - 230: dog - cat || Loss: 1.1626663208007812\n",
      "tensor([0., 1.]) tensor([0.8494, 0.1506], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 29 - 231: dog - cat || Loss: 1.1622990369796753\n",
      "tensor([0., 1.]) tensor([0.8490, 0.1510], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 29 - 232: dog - cat || Loss: 1.1619303226470947\n",
      "tensor([0., 1.]) tensor([0.8487, 0.1513], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 29 - 233: dog - cat || Loss: 1.1615597009658813\n",
      "tensor([0., 1.]) tensor([0.8483, 0.1517], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 29 - 234: dog - cat || Loss: 1.1611874103546143\n",
      "tensor([0., 1.]) tensor([0.8479, 0.1521], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 29 - 235: dog - cat || Loss: 1.160813808441162\n",
      "tensor([0., 1.]) tensor([0.8476, 0.1524], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 29 - 236: dog - cat || Loss: 1.1604386568069458\n",
      "tensor([0., 1.]) tensor([0.8472, 0.1528], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 29 - 237: dog - cat || Loss: 1.1600619554519653\n",
      "tensor([0., 1.]) tensor([0.8468, 0.1532], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 29 - 238: dog - cat || Loss: 1.159684181213379\n",
      "tensor([0., 1.]) tensor([0.8464, 0.1536], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 29 - 239: dog - cat || Loss: 1.1593049764633179\n",
      "tensor([0., 1.]) tensor([0.8460, 0.1540], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 29 - 240: dog - cat || Loss: 1.1589245796203613\n",
      "tensor([0., 1.]) tensor([0.8457, 0.1543], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 29 - 241: dog - cat || Loss: 1.1585431098937988\n",
      "tensor([0., 1.]) tensor([0.8453, 0.1547], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 29 - 242: dog - cat || Loss: 1.1581603288650513\n",
      "tensor([0., 1.]) tensor([0.8449, 0.1551], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 29 - 243: dog - cat || Loss: 1.1577765941619873\n",
      "tensor([0., 1.]) tensor([0.8445, 0.1555], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 29 - 244: dog - cat || Loss: 1.1573915481567383\n",
      "tensor([0., 1.]) tensor([0.8441, 0.1559], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 29 - 245: dog - cat || Loss: 1.1570055484771729\n",
      "tensor([0., 1.]) tensor([0.8437, 0.1563], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 29 - 246: dog - cat || Loss: 1.156618595123291\n",
      "tensor([0., 1.]) tensor([0.8434, 0.1566], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 29 - 247: dog - cat || Loss: 1.1562302112579346\n",
      "tensor([0., 1.]) tensor([0.8430, 0.1570], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 29 - 248: dog - cat || Loss: 1.1558411121368408\n",
      "tensor([0., 1.]) tensor([0.8426, 0.1574], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 29 - 249: dog - cat || Loss: 1.1554508209228516\n",
      "tensor([0., 1.]) tensor([0.8422, 0.1578], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 29 - 250: dog - cat || Loss: 1.155059814453125\n",
      "tensor([0., 1.]) tensor([0.8418, 0.1582], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 29 - 251: dog - cat || Loss: 1.154667854309082\n",
      "tensor([0., 1.]) tensor([0.8414, 0.1586], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 29 - 252: dog - cat || Loss: 1.1542747020721436\n",
      "tensor([0., 1.]) tensor([0.8410, 0.1590], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 29 - 253: dog - cat || Loss: 1.1538807153701782\n",
      "tensor([0., 1.]) tensor([0.8406, 0.1594], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 29 - 254: dog - cat || Loss: 1.1534855365753174\n",
      "tensor([0., 1.]) tensor([0.8402, 0.1598], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 29 - 255: dog - cat || Loss: 1.1530897617340088\n",
      "tensor([0., 1.]) tensor([0.8398, 0.1602], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 29 - 256: dog - cat || Loss: 1.1526929140090942\n",
      "tensor([0., 1.]) tensor([0.8394, 0.1606], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 29 - 257: dog - cat || Loss: 1.1522952318191528\n",
      "tensor([0., 1.]) tensor([0.8390, 0.1610], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 29 - 258: dog - cat || Loss: 1.1518964767456055\n",
      "tensor([0., 1.]) tensor([0.8386, 0.1614], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 29 - 259: dog - cat || Loss: 1.1514970064163208\n",
      "tensor([0., 1.]) tensor([0.8382, 0.1618], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 29 - 260: dog - cat || Loss: 1.1510963439941406\n",
      "tensor([0., 1.]) tensor([0.8378, 0.1622], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 29 - 261: dog - cat || Loss: 1.1506950855255127\n",
      "tensor([0., 1.]) tensor([0.8374, 0.1626], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 29 - 262: dog - cat || Loss: 1.1502928733825684\n",
      "tensor([0., 1.]) tensor([0.8370, 0.1630], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 29 - 263: dog - cat || Loss: 1.1498897075653076\n",
      "tensor([0., 1.]) tensor([0.8366, 0.1634], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 29 - 264: dog - cat || Loss: 1.1494855880737305\n",
      "tensor([0., 1.]) tensor([0.8362, 0.1638], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 29 - 265: dog - cat || Loss: 1.1490806341171265\n",
      "tensor([0., 1.]) tensor([0.8358, 0.1642], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 29 - 266: dog - cat || Loss: 1.1486748456954956\n",
      "tensor([0., 1.]) tensor([0.8354, 0.1646], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 29 - 267: dog - cat || Loss: 1.1482681035995483\n",
      "tensor([0., 1.]) tensor([0.8350, 0.1650], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 29 - 268: dog - cat || Loss: 1.1478605270385742\n",
      "tensor([0., 1.]) tensor([0.8346, 0.1654], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 29 - 269: dog - cat || Loss: 1.1474519968032837\n",
      "tensor([0., 1.]) tensor([0.8342, 0.1658], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 29 - 270: dog - cat || Loss: 1.1470427513122559\n",
      "tensor([0., 1.]) tensor([0.8338, 0.1662], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 29 - 271: dog - cat || Loss: 1.1466325521469116\n",
      "tensor([0., 1.]) tensor([0.8334, 0.1666], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 29 - 272: dog - cat || Loss: 1.1462212800979614\n",
      "tensor([0., 1.]) tensor([0.8330, 0.1670], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 29 - 273: dog - cat || Loss: 1.1458094120025635\n",
      "tensor([0., 1.]) tensor([0.8325, 0.1675], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 29 - 274: dog - cat || Loss: 1.1453965902328491\n",
      "tensor([0., 1.]) tensor([0.8321, 0.1679], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 29 - 275: dog - cat || Loss: 1.1449826955795288\n",
      "tensor([0., 1.]) tensor([0.8317, 0.1683], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 29 - 276: dog - cat || Loss: 1.1445683240890503\n",
      "tensor([0., 1.]) tensor([0.8313, 0.1687], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 29 - 277: dog - cat || Loss: 1.1441526412963867\n",
      "tensor([0., 1.]) tensor([0.8309, 0.1691], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 29 - 278: dog - cat || Loss: 1.1437363624572754\n",
      "tensor([0., 1.]) tensor([0.8305, 0.1695], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 29 - 279: dog - cat || Loss: 1.1433192491531372\n",
      "tensor([0., 1.]) tensor([0.8301, 0.1699], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 29 - 280: dog - cat || Loss: 1.142901062965393\n",
      "tensor([0., 1.]) tensor([0.8296, 0.1704], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 29 - 281: dog - cat || Loss: 1.142482042312622\n",
      "tensor([0., 1.]) tensor([0.8292, 0.1708], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 29 - 282: dog - cat || Loss: 1.1420623064041138\n",
      "tensor([0., 1.]) tensor([0.8288, 0.1712], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 29 - 283: dog - cat || Loss: 1.1416417360305786\n",
      "tensor([0., 1.]) tensor([0.8284, 0.1716], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 29 - 284: dog - cat || Loss: 1.1412200927734375\n",
      "tensor([0., 1.]) tensor([0.8280, 0.1720], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 29 - 285: dog - cat || Loss: 1.1407976150512695\n",
      "tensor([0., 1.]) tensor([0.8275, 0.1725], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 29 - 286: dog - cat || Loss: 1.1403741836547852\n",
      "tensor([0., 1.]) tensor([0.8271, 0.1729], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 29 - 287: dog - cat || Loss: 1.1399500370025635\n",
      "tensor([0., 1.]) tensor([0.8267, 0.1733], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 29 - 288: dog - cat || Loss: 1.1395249366760254\n",
      "tensor([0., 1.]) tensor([0.8263, 0.1737], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 29 - 289: dog - cat || Loss: 1.13909912109375\n",
      "tensor([0., 1.]) tensor([0.8258, 0.1742], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 29 - 290: dog - cat || Loss: 1.1386723518371582\n",
      "tensor([0., 1.]) tensor([0.8254, 0.1746], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 29 - 291: dog - cat || Loss: 1.13824462890625\n",
      "tensor([0., 1.]) tensor([0.8250, 0.1750], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 29 - 292: dog - cat || Loss: 1.1378159523010254\n",
      "tensor([0., 1.]) tensor([0.8246, 0.1754], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 29 - 293: dog - cat || Loss: 1.137386679649353\n",
      "tensor([0., 1.]) tensor([0.8241, 0.1759], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 29 - 294: dog - cat || Loss: 1.1369563341140747\n",
      "tensor([0., 1.]) tensor([0.8237, 0.1763], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 29 - 295: dog - cat || Loss: 1.1365251541137695\n",
      "tensor([0., 1.]) tensor([0.8233, 0.1767], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 29 - 296: dog - cat || Loss: 1.1360931396484375\n",
      "tensor([0., 1.]) tensor([0.8228, 0.1772], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 29 - 297: dog - cat || Loss: 1.135660171508789\n",
      "tensor([0., 1.]) tensor([0.8224, 0.1776], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 29 - 298: dog - cat || Loss: 1.1352263689041138\n",
      "tensor([0., 1.]) tensor([0.8220, 0.1780], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 29 - 299: dog - cat || Loss: 1.1347917318344116\n",
      "tensor([0., 1.]) tensor([0.8215, 0.1785], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 29 - 300: dog - cat || Loss: 1.134356141090393\n",
      "tensor([0., 1.]) tensor([0.8211, 0.1789], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 29 - 301: dog - cat || Loss: 1.133919596672058\n",
      "tensor([0., 1.]) tensor([0.8207, 0.1793], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 29 - 302: dog - cat || Loss: 1.1334823369979858\n",
      "tensor([0., 1.]) tensor([0.8202, 0.1798], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 29 - 303: dog - cat || Loss: 1.1330442428588867\n",
      "tensor([0., 1.]) tensor([0.8198, 0.1802], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 29 - 304: dog - cat || Loss: 1.1326051950454712\n",
      "tensor([0., 1.]) tensor([0.8193, 0.1807], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 29 - 305: dog - cat || Loss: 1.1321650743484497\n",
      "tensor([0., 1.]) tensor([0.8189, 0.1811], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 29 - 306: dog - cat || Loss: 1.131724238395691\n",
      "tensor([0., 1.]) tensor([0.8185, 0.1815], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 29 - 307: dog - cat || Loss: 1.1312824487686157\n",
      "tensor([0., 1.]) tensor([0.8180, 0.1820], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 29 - 308: dog - cat || Loss: 1.1308398246765137\n",
      "tensor([0., 1.]) tensor([0.8176, 0.1824], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 29 - 309: dog - cat || Loss: 1.1303963661193848\n",
      "tensor([0., 1.]) tensor([0.8171, 0.1829], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 29 - 310: dog - cat || Loss: 1.129952073097229\n",
      "tensor([0., 1.]) tensor([0.8167, 0.1833], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 29 - 311: dog - cat || Loss: 1.1295065879821777\n",
      "tensor([0., 1.]) tensor([0.8162, 0.1838], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 29 - 312: dog - cat || Loss: 1.1290606260299683\n",
      "tensor([0., 1.]) tensor([0.8158, 0.1842], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 29 - 313: dog - cat || Loss: 1.1286135911941528\n",
      "tensor([0., 1.]) tensor([0.8154, 0.1846], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 29 - 314: dog - cat || Loss: 1.1281657218933105\n",
      "tensor([0., 1.]) tensor([0.8149, 0.1851], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 29 - 315: dog - cat || Loss: 1.1277167797088623\n",
      "tensor([0., 1.]) tensor([0.8145, 0.1855], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 29 - 316: dog - cat || Loss: 1.1272671222686768\n",
      "tensor([0., 1.]) tensor([0.8140, 0.1860], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 29 - 317: dog - cat || Loss: 1.1268163919448853\n",
      "tensor([0., 1.]) tensor([0.8136, 0.1864], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 29 - 318: dog - cat || Loss: 1.1263649463653564\n",
      "tensor([0., 1.]) tensor([0.8131, 0.1869], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 29 - 319: dog - cat || Loss: 1.1259125471115112\n",
      "tensor([0., 1.]) tensor([0.8127, 0.1873], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 29 - 320: dog - cat || Loss: 1.1254593133926392\n",
      "tensor([0., 1.]) tensor([0.8122, 0.1878], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 29 - 321: dog - cat || Loss: 1.1250052452087402\n",
      "tensor([0., 1.]) tensor([0.8117, 0.1883], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 29 - 322: dog - cat || Loss: 1.1245501041412354\n",
      "tensor([0., 1.]) tensor([0.8113, 0.1887], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 29 - 323: dog - cat || Loss: 1.1240941286087036\n",
      "tensor([0., 1.]) tensor([0.8108, 0.1892], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 29 - 324: dog - cat || Loss: 1.123637318611145\n",
      "tensor([0., 1.]) tensor([0.8104, 0.1896], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 29 - 325: dog - cat || Loss: 1.12317955493927\n",
      "tensor([0., 1.]) tensor([0.8099, 0.1901], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 29 - 326: dog - cat || Loss: 1.1227208375930786\n",
      "tensor([0., 1.]) tensor([0.8095, 0.1905], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 29 - 327: dog - cat || Loss: 1.1222615242004395\n",
      "tensor([0., 1.]) tensor([0.8090, 0.1910], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 29 - 328: dog - cat || Loss: 1.1218011379241943\n",
      "tensor([0., 1.]) tensor([0.8085, 0.1915], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 29 - 329: dog - cat || Loss: 1.1213397979736328\n",
      "tensor([0., 1.]) tensor([0.8081, 0.1919], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 29 - 330: dog - cat || Loss: 1.1208776235580444\n",
      "tensor([0., 1.]) tensor([0.8076, 0.1924], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 29 - 331: dog - cat || Loss: 1.1204144954681396\n",
      "tensor([0., 1.]) tensor([0.8072, 0.1928], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 29 - 332: dog - cat || Loss: 1.1199504137039185\n",
      "tensor([0., 1.]) tensor([0.8067, 0.1933], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 29 - 333: dog - cat || Loss: 1.11948561668396\n",
      "tensor([0., 1.]) tensor([0.8062, 0.1938], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 29 - 334: dog - cat || Loss: 1.119019865989685\n",
      "tensor([0., 1.]) tensor([0.8058, 0.1942], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 29 - 335: dog - cat || Loss: 1.1185532808303833\n",
      "tensor([0., 1.]) tensor([0.8053, 0.1947], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 29 - 336: dog - cat || Loss: 1.1180857419967651\n",
      "tensor([0., 1.]) tensor([0.8048, 0.1952], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 29 - 337: dog - cat || Loss: 1.1176173686981201\n",
      "tensor([0., 1.]) tensor([0.8044, 0.1956], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 29 - 338: dog - cat || Loss: 1.1171479225158691\n",
      "tensor([0., 1.]) tensor([0.8039, 0.1961], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 29 - 339: dog - cat || Loss: 1.1166777610778809\n",
      "tensor([0., 1.]) tensor([0.8034, 0.1966], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 29 - 340: dog - cat || Loss: 1.1162065267562866\n",
      "tensor([0., 1.]) tensor([0.8029, 0.1971], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 29 - 341: dog - cat || Loss: 1.115734577178955\n",
      "tensor([0., 1.]) tensor([0.8025, 0.1975], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 29 - 342: dog - cat || Loss: 1.1152615547180176\n",
      "tensor([0., 1.]) tensor([0.8020, 0.1980], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 29 - 343: dog - cat || Loss: 1.1147878170013428\n",
      "tensor([0., 1.]) tensor([0.8015, 0.1985], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 29 - 344: dog - cat || Loss: 1.1143131256103516\n",
      "tensor([0., 1.]) tensor([0.8011, 0.1989], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 29 - 345: dog - cat || Loss: 1.1138373613357544\n",
      "tensor([0., 1.]) tensor([0.8006, 0.1994], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 29 - 346: dog - cat || Loss: 1.11336088180542\n",
      "tensor([0., 1.]) tensor([0.8001, 0.1999], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 29 - 347: dog - cat || Loss: 1.1128835678100586\n",
      "tensor([0., 1.]) tensor([0.7996, 0.2004], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 29 - 348: dog - cat || Loss: 1.1124053001403809\n",
      "tensor([0., 1.]) tensor([0.7991, 0.2009], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 29 - 349: dog - cat || Loss: 1.1119259595870972\n",
      "tensor([0., 1.]) tensor([0.7987, 0.2013], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 29 - 350: dog - cat || Loss: 1.1114457845687866\n",
      "tensor([0., 1.]) tensor([0.7982, 0.2018], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 29 - 351: dog - cat || Loss: 1.1109647750854492\n",
      "tensor([0., 1.]) tensor([0.7977, 0.2023], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 29 - 352: dog - cat || Loss: 1.110482931137085\n",
      "tensor([0., 1.]) tensor([0.7972, 0.2028], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 29 - 353: dog - cat || Loss: 1.1100002527236938\n",
      "tensor([0., 1.]) tensor([0.7967, 0.2033], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 29 - 354: dog - cat || Loss: 1.1095163822174072\n",
      "tensor([0., 1.]) tensor([0.7963, 0.2037], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 29 - 355: dog - cat || Loss: 1.1090317964553833\n",
      "tensor([0., 1.]) tensor([0.7958, 0.2042], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 29 - 356: dog - cat || Loss: 1.1085463762283325\n",
      "tensor([0., 1.]) tensor([0.7953, 0.2047], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 29 - 357: dog - cat || Loss: 1.1080600023269653\n",
      "tensor([0., 1.]) tensor([0.7948, 0.2052], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 29 - 358: dog - cat || Loss: 1.1075727939605713\n",
      "tensor([0., 1.]) tensor([0.7943, 0.2057], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 29 - 359: dog - cat || Loss: 1.1070845127105713\n",
      "tensor([0., 1.]) tensor([0.7938, 0.2062], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 29 - 360: dog - cat || Loss: 1.1065953969955444\n",
      "tensor([0., 1.]) tensor([0.7933, 0.2067], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 29 - 361: dog - cat || Loss: 1.1061054468154907\n",
      "tensor([0., 1.]) tensor([0.7928, 0.2072], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 29 - 362: dog - cat || Loss: 1.1056146621704102\n",
      "tensor([0., 1.]) tensor([0.7924, 0.2076], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 29 - 363: dog - cat || Loss: 1.1051228046417236\n",
      "tensor([0., 1.]) tensor([0.7919, 0.2081], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 29 - 364: dog - cat || Loss: 1.1046302318572998\n",
      "tensor([0., 1.]) tensor([0.7914, 0.2086], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 29 - 365: dog - cat || Loss: 1.1041367053985596\n",
      "tensor([0., 1.]) tensor([0.7909, 0.2091], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 29 - 366: dog - cat || Loss: 1.1036419868469238\n",
      "tensor([0., 1.]) tensor([0.7904, 0.2096], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 29 - 367: dog - cat || Loss: 1.1031469106674194\n",
      "tensor([0., 1.]) tensor([0.7899, 0.2101], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 29 - 368: dog - cat || Loss: 1.1026506423950195\n",
      "tensor([0., 1.]) tensor([0.7894, 0.2106], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 29 - 369: dog - cat || Loss: 1.1021533012390137\n",
      "tensor([0., 1.]) tensor([0.7889, 0.2111], grad_fn=<SoftmaxBackward0>)\n",
      "=====epoch:30=====\n",
      "Epoch 30 - 0: cat - cat || Loss: 0.5248680710792542\n",
      "tensor([1., 0.]) tensor([0.7884, 0.2116], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 30 - 1: cat - cat || Loss: 0.5252663493156433\n",
      "tensor([1., 0.]) tensor([0.7880, 0.2120], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 30 - 2: cat - cat || Loss: 0.5255746841430664\n",
      "tensor([1., 0.]) tensor([0.7877, 0.2123], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 30 - 3: cat - cat || Loss: 0.5258018970489502\n",
      "tensor([1., 0.]) tensor([0.7875, 0.2125], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 30 - 4: cat - cat || Loss: 0.5259559154510498\n",
      "tensor([1., 0.]) tensor([0.7873, 0.2127], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 30 - 5: cat - cat || Loss: 0.5260440707206726\n",
      "tensor([1., 0.]) tensor([0.7872, 0.2128], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 30 - 6: cat - cat || Loss: 0.5260729789733887\n",
      "tensor([1., 0.]) tensor([0.7872, 0.2128], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 30 - 7: cat - cat || Loss: 0.5260484218597412\n",
      "tensor([1., 0.]) tensor([0.7872, 0.2128], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 30 - 8: cat - cat || Loss: 0.5259758830070496\n",
      "tensor([1., 0.]) tensor([0.7873, 0.2127], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 30 - 9: cat - cat || Loss: 0.5258601307868958\n",
      "tensor([1., 0.]) tensor([0.7874, 0.2126], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 30 - 10: cat - cat || Loss: 0.5257055163383484\n",
      "tensor([1., 0.]) tensor([0.7876, 0.2124], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 30 - 11: cat - cat || Loss: 0.5255160927772522\n",
      "tensor([1., 0.]) tensor([0.7877, 0.2123], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 30 - 12: cat - cat || Loss: 0.5252951383590698\n",
      "tensor([1., 0.]) tensor([0.7880, 0.2120], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 30 - 13: cat - cat || Loss: 0.5250461101531982\n",
      "tensor([1., 0.]) tensor([0.7882, 0.2118], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 30 - 14: cat - cat || Loss: 0.5247718095779419\n",
      "tensor([1., 0.]) tensor([0.7885, 0.2115], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 30 - 15: cat - cat || Loss: 0.5244748592376709\n",
      "tensor([1., 0.]) tensor([0.7888, 0.2112], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 30 - 16: cat - cat || Loss: 0.5241574645042419\n",
      "tensor([1., 0.]) tensor([0.7891, 0.2109], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 30 - 17: cat - cat || Loss: 0.5238218903541565\n",
      "tensor([1., 0.]) tensor([0.7894, 0.2106], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 30 - 18: cat - cat || Loss: 0.5234700441360474\n",
      "tensor([1., 0.]) tensor([0.7898, 0.2102], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 30 - 19: cat - cat || Loss: 0.5231035947799683\n",
      "tensor([1., 0.]) tensor([0.7902, 0.2098], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 30 - 20: cat - cat || Loss: 0.5227239727973938\n",
      "tensor([1., 0.]) tensor([0.7905, 0.2095], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 30 - 21: cat - cat || Loss: 0.5223327875137329\n",
      "tensor([1., 0.]) tensor([0.7909, 0.2091], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 30 - 22: cat - cat || Loss: 0.5219312310218811\n",
      "tensor([1., 0.]) tensor([0.7913, 0.2087], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 30 - 23: cat - cat || Loss: 0.5215204358100891\n",
      "tensor([1., 0.]) tensor([0.7917, 0.2083], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 30 - 24: cat - cat || Loss: 0.5211012363433838\n",
      "tensor([1., 0.]) tensor([0.7922, 0.2078], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 30 - 25: cat - cat || Loss: 0.5206748247146606\n",
      "tensor([1., 0.]) tensor([0.7926, 0.2074], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 30 - 26: cat - cat || Loss: 0.520241916179657\n",
      "tensor([1., 0.]) tensor([0.7930, 0.2070], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 30 - 27: cat - cat || Loss: 0.5198031067848206\n",
      "tensor([1., 0.]) tensor([0.7935, 0.2065], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 30 - 28: cat - cat || Loss: 0.5193593502044678\n",
      "tensor([1., 0.]) tensor([0.7939, 0.2061], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 30 - 29: cat - cat || Loss: 0.5189108848571777\n",
      "tensor([1., 0.]) tensor([0.7944, 0.2056], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 30 - 30: cat - cat || Loss: 0.5184586048126221\n",
      "tensor([1., 0.]) tensor([0.7948, 0.2052], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 30 - 31: cat - cat || Loss: 0.5180027484893799\n",
      "tensor([1., 0.]) tensor([0.7953, 0.2047], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 30 - 32: cat - cat || Loss: 0.5175439119338989\n",
      "tensor([1., 0.]) tensor([0.7957, 0.2043], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 30 - 33: cat - cat || Loss: 0.5170825123786926\n",
      "tensor([1., 0.]) tensor([0.7962, 0.2038], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 30 - 34: cat - cat || Loss: 0.5166187286376953\n",
      "tensor([1., 0.]) tensor([0.7966, 0.2034], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 30 - 35: cat - cat || Loss: 0.5161529779434204\n",
      "tensor([1., 0.]) tensor([0.7971, 0.2029], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 30 - 36: cat - cat || Loss: 0.5156856775283813\n",
      "tensor([1., 0.]) tensor([0.7976, 0.2024], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 30 - 37: cat - cat || Loss: 0.5152168273925781\n",
      "tensor([1., 0.]) tensor([0.7980, 0.2020], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 30 - 38: cat - cat || Loss: 0.5147468447685242\n",
      "tensor([1., 0.]) tensor([0.7985, 0.2015], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 30 - 39: cat - cat || Loss: 0.514275848865509\n",
      "tensor([1., 0.]) tensor([0.7990, 0.2010], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 30 - 40: cat - cat || Loss: 0.5138043165206909\n",
      "tensor([1., 0.]) tensor([0.7995, 0.2005], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 30 - 41: cat - cat || Loss: 0.5133318901062012\n",
      "tensor([1., 0.]) tensor([0.7999, 0.2001], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 30 - 42: cat - cat || Loss: 0.5128592252731323\n",
      "tensor([1., 0.]) tensor([0.8004, 0.1996], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 30 - 43: cat - cat || Loss: 0.5123859643936157\n",
      "tensor([1., 0.]) tensor([0.8009, 0.1991], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 30 - 44: cat - cat || Loss: 0.5119128227233887\n",
      "tensor([1., 0.]) tensor([0.8013, 0.1987], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 30 - 45: cat - cat || Loss: 0.5114394426345825\n",
      "tensor([1., 0.]) tensor([0.8018, 0.1982], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 30 - 46: cat - cat || Loss: 0.5109660625457764\n",
      "tensor([1., 0.]) tensor([0.8023, 0.1977], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 30 - 47: cat - cat || Loss: 0.5104928612709045\n",
      "tensor([1., 0.]) tensor([0.8028, 0.1972], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 30 - 48: cat - cat || Loss: 0.510019838809967\n",
      "tensor([1., 0.]) tensor([0.8032, 0.1968], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 30 - 49: cat - cat || Loss: 0.5095470547676086\n",
      "tensor([1., 0.]) tensor([0.8037, 0.1963], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 30 - 50: cat - cat || Loss: 0.5090746879577637\n",
      "tensor([1., 0.]) tensor([0.8042, 0.1958], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 30 - 51: cat - cat || Loss: 0.5086027383804321\n",
      "tensor([1., 0.]) tensor([0.8047, 0.1953], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 30 - 52: cat - cat || Loss: 0.5081311464309692\n",
      "tensor([1., 0.]) tensor([0.8051, 0.1949], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 30 - 53: cat - cat || Loss: 0.5076600313186646\n",
      "tensor([1., 0.]) tensor([0.8056, 0.1944], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 30 - 54: cat - cat || Loss: 0.5071896314620972\n",
      "tensor([1., 0.]) tensor([0.8061, 0.1939], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 30 - 55: cat - cat || Loss: 0.506719708442688\n",
      "tensor([1., 0.]) tensor([0.8065, 0.1935], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 30 - 56: cat - cat || Loss: 0.5062503814697266\n",
      "tensor([1., 0.]) tensor([0.8070, 0.1930], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 30 - 57: cat - cat || Loss: 0.5057816505432129\n",
      "tensor([1., 0.]) tensor([0.8075, 0.1925], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 30 - 58: cat - cat || Loss: 0.5053137540817261\n",
      "tensor([1., 0.]) tensor([0.8079, 0.1921], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 30 - 59: cat - cat || Loss: 0.504846453666687\n",
      "tensor([1., 0.]) tensor([0.8084, 0.1916], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 30 - 60: cat - cat || Loss: 0.5043798685073853\n",
      "tensor([1., 0.]) tensor([0.8089, 0.1911], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 30 - 61: cat - cat || Loss: 0.5039139986038208\n",
      "tensor([1., 0.]) tensor([0.8093, 0.1907], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 30 - 62: cat - cat || Loss: 0.5034488439559937\n",
      "tensor([1., 0.]) tensor([0.8098, 0.1902], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 30 - 63: cat - cat || Loss: 0.5029845833778381\n",
      "tensor([1., 0.]) tensor([0.8103, 0.1897], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 30 - 64: cat - cat || Loss: 0.5025210380554199\n",
      "tensor([1., 0.]) tensor([0.8107, 0.1893], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 30 - 65: cat - cat || Loss: 0.5020582675933838\n",
      "tensor([1., 0.]) tensor([0.8112, 0.1888], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 30 - 66: cat - cat || Loss: 0.5015963912010193\n",
      "tensor([1., 0.]) tensor([0.8117, 0.1883], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 30 - 67: cat - cat || Loss: 0.5011354684829712\n",
      "tensor([1., 0.]) tensor([0.8121, 0.1879], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 30 - 68: cat - cat || Loss: 0.5006751418113708\n",
      "tensor([1., 0.]) tensor([0.8126, 0.1874], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 30 - 69: cat - cat || Loss: 0.5002157688140869\n",
      "tensor([1., 0.]) tensor([0.8130, 0.1870], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 30 - 70: cat - cat || Loss: 0.49975723028182983\n",
      "tensor([1., 0.]) tensor([0.8135, 0.1865], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 30 - 71: cat - cat || Loss: 0.49929964542388916\n",
      "tensor([1., 0.]) tensor([0.8140, 0.1860], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 30 - 72: cat - cat || Loss: 0.49884283542633057\n",
      "tensor([1., 0.]) tensor([0.8144, 0.1856], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 30 - 73: cat - cat || Loss: 0.49838677048683167\n",
      "tensor([1., 0.]) tensor([0.8149, 0.1851], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 30 - 74: cat - cat || Loss: 0.4979317784309387\n",
      "tensor([1., 0.]) tensor([0.8153, 0.1847], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 30 - 75: cat - cat || Loss: 0.4974777102470398\n",
      "tensor([1., 0.]) tensor([0.8158, 0.1842], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 30 - 76: cat - cat || Loss: 0.49702441692352295\n",
      "tensor([1., 0.]) tensor([0.8162, 0.1838], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 30 - 77: cat - cat || Loss: 0.4965721368789673\n",
      "tensor([1., 0.]) tensor([0.8167, 0.1833], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 30 - 78: cat - cat || Loss: 0.4961206316947937\n",
      "tensor([1., 0.]) tensor([0.8171, 0.1829], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 30 - 79: cat - cat || Loss: 0.49567005038261414\n",
      "tensor([1., 0.]) tensor([0.8176, 0.1824], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 30 - 80: cat - cat || Loss: 0.4952203929424286\n",
      "tensor([1., 0.]) tensor([0.8180, 0.1820], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 30 - 81: cat - cat || Loss: 0.4947715401649475\n",
      "tensor([1., 0.]) tensor([0.8185, 0.1815], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 30 - 82: cat - cat || Loss: 0.49432361125946045\n",
      "tensor([1., 0.]) tensor([0.8189, 0.1811], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 30 - 83: cat - cat || Loss: 0.49387669563293457\n",
      "tensor([1., 0.]) tensor([0.8194, 0.1806], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 30 - 84: cat - cat || Loss: 0.49343064427375793\n",
      "tensor([1., 0.]) tensor([0.8198, 0.1802], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 30 - 85: cat - cat || Loss: 0.49298548698425293\n",
      "tensor([1., 0.]) tensor([0.8203, 0.1797], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 30 - 86: cat - cat || Loss: 0.49254122376441956\n",
      "tensor([1., 0.]) tensor([0.8207, 0.1793], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 30 - 87: cat - cat || Loss: 0.4920978248119354\n",
      "tensor([1., 0.]) tensor([0.8212, 0.1788], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 30 - 88: cat - cat || Loss: 0.4916553795337677\n",
      "tensor([1., 0.]) tensor([0.8216, 0.1784], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 30 - 89: cat - cat || Loss: 0.491213858127594\n",
      "tensor([1., 0.]) tensor([0.8220, 0.1780], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 30 - 90: cat - cat || Loss: 0.49077320098876953\n",
      "tensor([1., 0.]) tensor([0.8225, 0.1775], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 30 - 91: cat - cat || Loss: 0.49033334851264954\n",
      "tensor([1., 0.]) tensor([0.8229, 0.1771], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 30 - 92: cat - cat || Loss: 0.4898946285247803\n",
      "tensor([1., 0.]) tensor([0.8234, 0.1766], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 30 - 93: cat - cat || Loss: 0.4894566535949707\n",
      "tensor([1., 0.]) tensor([0.8238, 0.1762], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 30 - 94: cat - cat || Loss: 0.48901963233947754\n",
      "tensor([1., 0.]) tensor([0.8242, 0.1758], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 30 - 95: cat - cat || Loss: 0.48858344554901123\n",
      "tensor([1., 0.]) tensor([0.8247, 0.1753], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 30 - 96: cat - cat || Loss: 0.4881483018398285\n",
      "tensor([1., 0.]) tensor([0.8251, 0.1749], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 30 - 97: cat - cat || Loss: 0.4877140522003174\n",
      "tensor([1., 0.]) tensor([0.8255, 0.1745], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 30 - 98: cat - cat || Loss: 0.48728060722351074\n",
      "tensor([1., 0.]) tensor([0.8260, 0.1740], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 30 - 99: cat - cat || Loss: 0.4868481159210205\n",
      "tensor([1., 0.]) tensor([0.8264, 0.1736], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 30 - 100: cat - cat || Loss: 0.4864165186882019\n",
      "tensor([1., 0.]) tensor([0.8268, 0.1732], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 30 - 101: cat - cat || Loss: 0.4859858751296997\n",
      "tensor([1., 0.]) tensor([0.8273, 0.1727], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 30 - 102: cat - cat || Loss: 0.48555612564086914\n",
      "tensor([1., 0.]) tensor([0.8277, 0.1723], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 30 - 103: cat - cat || Loss: 0.48512718081474304\n",
      "tensor([1., 0.]) tensor([0.8281, 0.1719], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 30 - 104: cat - cat || Loss: 0.48469921946525574\n",
      "tensor([1., 0.]) tensor([0.8286, 0.1714], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 30 - 105: cat - cat || Loss: 0.48427221179008484\n",
      "tensor([1., 0.]) tensor([0.8290, 0.1710], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 30 - 106: cat - cat || Loss: 0.4838460385799408\n",
      "tensor([1., 0.]) tensor([0.8294, 0.1706], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 30 - 107: cat - cat || Loss: 0.483420729637146\n",
      "tensor([1., 0.]) tensor([0.8298, 0.1702], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 30 - 108: cat - cat || Loss: 0.48299646377563477\n",
      "tensor([1., 0.]) tensor([0.8303, 0.1697], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 30 - 109: cat - cat || Loss: 0.4825729429721832\n",
      "tensor([1., 0.]) tensor([0.8307, 0.1693], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 30 - 110: cat - cat || Loss: 0.4821503758430481\n",
      "tensor([1., 0.]) tensor([0.8311, 0.1689], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 30 - 111: cat - cat || Loss: 0.481728732585907\n",
      "tensor([1., 0.]) tensor([0.8315, 0.1685], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 30 - 112: cat - cat || Loss: 0.4813079237937927\n",
      "tensor([1., 0.]) tensor([0.8320, 0.1680], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 30 - 113: cat - cat || Loss: 0.48088812828063965\n",
      "tensor([1., 0.]) tensor([0.8324, 0.1676], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 30 - 114: cat - cat || Loss: 0.4804691672325134\n",
      "tensor([1., 0.]) tensor([0.8328, 0.1672], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 30 - 115: cat - cat || Loss: 0.48005110025405884\n",
      "tensor([1., 0.]) tensor([0.8332, 0.1668], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 30 - 116: cat - cat || Loss: 0.4796339273452759\n",
      "tensor([1., 0.]) tensor([0.8336, 0.1664], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 30 - 117: cat - cat || Loss: 0.47921764850616455\n",
      "tensor([1., 0.]) tensor([0.8340, 0.1660], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 30 - 118: cat - cat || Loss: 0.47880226373672485\n",
      "tensor([1., 0.]) tensor([0.8345, 0.1655], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 30 - 119: cat - cat || Loss: 0.47838783264160156\n",
      "tensor([1., 0.]) tensor([0.8349, 0.1651], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 30 - 120: cat - cat || Loss: 0.47797417640686035\n",
      "tensor([1., 0.]) tensor([0.8353, 0.1647], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 30 - 121: cat - cat || Loss: 0.47756141424179077\n",
      "tensor([1., 0.]) tensor([0.8357, 0.1643], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 30 - 122: cat - cat || Loss: 0.47714972496032715\n",
      "tensor([1., 0.]) tensor([0.8361, 0.1639], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 30 - 123: cat - cat || Loss: 0.4767388701438904\n",
      "tensor([1., 0.]) tensor([0.8365, 0.1635], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 30 - 124: cat - cat || Loss: 0.4763287603855133\n",
      "tensor([1., 0.]) tensor([0.8369, 0.1631], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 30 - 125: cat - cat || Loss: 0.47591978311538696\n",
      "tensor([1., 0.]) tensor([0.8373, 0.1627], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 30 - 126: cat - cat || Loss: 0.47551149129867554\n",
      "tensor([1., 0.]) tensor([0.8378, 0.1622], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 30 - 127: cat - cat || Loss: 0.47510409355163574\n",
      "tensor([1., 0.]) tensor([0.8382, 0.1618], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 30 - 128: cat - cat || Loss: 0.47469770908355713\n",
      "tensor([1., 0.]) tensor([0.8386, 0.1614], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 30 - 129: cat - cat || Loss: 0.47429224848747253\n",
      "tensor([1., 0.]) tensor([0.8390, 0.1610], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 30 - 130: cat - cat || Loss: 0.4738876223564148\n",
      "tensor([1., 0.]) tensor([0.8394, 0.1606], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 30 - 131: cat - cat || Loss: 0.4734838008880615\n",
      "tensor([1., 0.]) tensor([0.8398, 0.1602], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 30 - 132: cat - cat || Loss: 0.47308090329170227\n",
      "tensor([1., 0.]) tensor([0.8402, 0.1598], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 30 - 133: cat - cat || Loss: 0.4726789593696594\n",
      "tensor([1., 0.]) tensor([0.8406, 0.1594], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 30 - 134: cat - cat || Loss: 0.47227779030799866\n",
      "tensor([1., 0.]) tensor([0.8410, 0.1590], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 30 - 135: cat - cat || Loss: 0.47187769412994385\n",
      "tensor([1., 0.]) tensor([0.8414, 0.1586], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 30 - 136: cat - cat || Loss: 0.47147834300994873\n",
      "tensor([1., 0.]) tensor([0.8418, 0.1582], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 30 - 137: cat - cat || Loss: 0.47107988595962524\n",
      "tensor([1., 0.]) tensor([0.8422, 0.1578], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 30 - 138: cat - cat || Loss: 0.47068238258361816\n",
      "tensor([1., 0.]) tensor([0.8426, 0.1574], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 30 - 139: cat - cat || Loss: 0.47028571367263794\n",
      "tensor([1., 0.]) tensor([0.8430, 0.1570], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 30 - 140: cat - cat || Loss: 0.46988987922668457\n",
      "tensor([1., 0.]) tensor([0.8434, 0.1566], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 30 - 141: cat - cat || Loss: 0.4694949984550476\n",
      "tensor([1., 0.]) tensor([0.8438, 0.1562], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 30 - 142: cat - cat || Loss: 0.4691009819507599\n",
      "tensor([1., 0.]) tensor([0.8442, 0.1558], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 30 - 143: cat - cat || Loss: 0.468707799911499\n",
      "tensor([1., 0.]) tensor([0.8446, 0.1554], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 30 - 144: cat - cat || Loss: 0.46831560134887695\n",
      "tensor([1., 0.]) tensor([0.8449, 0.1551], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 30 - 145: cat - cat || Loss: 0.46792423725128174\n",
      "tensor([1., 0.]) tensor([0.8453, 0.1547], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 30 - 146: cat - cat || Loss: 0.4675337076187134\n",
      "tensor([1., 0.]) tensor([0.8457, 0.1543], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 30 - 147: cat - cat || Loss: 0.4671441316604614\n",
      "tensor([1., 0.]) tensor([0.8461, 0.1539], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 30 - 148: cat - cat || Loss: 0.46675533056259155\n",
      "tensor([1., 0.]) tensor([0.8465, 0.1535], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 30 - 149: cat - cat || Loss: 0.4663675129413605\n",
      "tensor([1., 0.]) tensor([0.8469, 0.1531], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 30 - 150: cat - cat || Loss: 0.4659804105758667\n",
      "tensor([1., 0.]) tensor([0.8473, 0.1527], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 30 - 151: cat - cat || Loss: 0.4655942916870117\n",
      "tensor([1., 0.]) tensor([0.8477, 0.1523], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 30 - 152: cat - cat || Loss: 0.46520906686782837\n",
      "tensor([1., 0.]) tensor([0.8481, 0.1519], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 30 - 153: cat - cat || Loss: 0.4648246765136719\n",
      "tensor([1., 0.]) tensor([0.8484, 0.1516], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 30 - 154: cat - cat || Loss: 0.46444112062454224\n",
      "tensor([1., 0.]) tensor([0.8488, 0.1512], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 30 - 155: cat - cat || Loss: 0.46405845880508423\n",
      "tensor([1., 0.]) tensor([0.8492, 0.1508], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 30 - 156: cat - cat || Loss: 0.46367669105529785\n",
      "tensor([1., 0.]) tensor([0.8496, 0.1504], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 30 - 157: cat - cat || Loss: 0.4632958471775055\n",
      "tensor([1., 0.]) tensor([0.8500, 0.1500], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 30 - 158: cat - cat || Loss: 0.46291568875312805\n",
      "tensor([1., 0.]) tensor([0.8503, 0.1497], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 30 - 159: cat - cat || Loss: 0.4625365436077118\n",
      "tensor([1., 0.]) tensor([0.8507, 0.1493], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 30 - 160: cat - cat || Loss: 0.4621581435203552\n",
      "tensor([1., 0.]) tensor([0.8511, 0.1489], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 30 - 161: cat - cat || Loss: 0.46178072690963745\n",
      "tensor([1., 0.]) tensor([0.8515, 0.1485], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 30 - 162: cat - cat || Loss: 0.46140414476394653\n",
      "tensor([1., 0.]) tensor([0.8519, 0.1481], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 30 - 163: cat - cat || Loss: 0.4610283374786377\n",
      "tensor([1., 0.]) tensor([0.8522, 0.1478], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 30 - 164: cat - cat || Loss: 0.4606534242630005\n",
      "tensor([1., 0.]) tensor([0.8526, 0.1474], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 30 - 165: cat - cat || Loss: 0.4602794349193573\n",
      "tensor([1., 0.]) tensor([0.8530, 0.1470], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 30 - 166: cat - cat || Loss: 0.4599062204360962\n",
      "tensor([1., 0.]) tensor([0.8534, 0.1466], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 30 - 167: cat - cat || Loss: 0.4595338702201843\n",
      "tensor([1., 0.]) tensor([0.8537, 0.1463], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 30 - 168: cat - cat || Loss: 0.45916247367858887\n",
      "tensor([1., 0.]) tensor([0.8541, 0.1459], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 30 - 169: cat - cat || Loss: 0.4587917625904083\n",
      "tensor([1., 0.]) tensor([0.8545, 0.1455], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 30 - 170: cat - cat || Loss: 0.4584219455718994\n",
      "tensor([1., 0.]) tensor([0.8548, 0.1452], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 30 - 171: cat - cat || Loss: 0.4580530822277069\n",
      "tensor([1., 0.]) tensor([0.8552, 0.1448], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 30 - 172: cat - cat || Loss: 0.4576849937438965\n",
      "tensor([1., 0.]) tensor([0.8556, 0.1444], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 30 - 173: cat - cat || Loss: 0.45731788873672485\n",
      "tensor([1., 0.]) tensor([0.8559, 0.1441], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 30 - 174: cat - cat || Loss: 0.45695146918296814\n",
      "tensor([1., 0.]) tensor([0.8563, 0.1437], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 30 - 175: cat - cat || Loss: 0.4565858840942383\n",
      "tensor([1., 0.]) tensor([0.8567, 0.1433], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 30 - 176: cat - cat || Loss: 0.45622122287750244\n",
      "tensor([1., 0.]) tensor([0.8570, 0.1430], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 30 - 177: cat - cat || Loss: 0.45585745573043823\n",
      "tensor([1., 0.]) tensor([0.8574, 0.1426], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 30 - 178: cat - cat || Loss: 0.4554945230484009\n",
      "tensor([1., 0.]) tensor([0.8578, 0.1422], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 30 - 179: cat - cat || Loss: 0.4551323652267456\n",
      "tensor([1., 0.]) tensor([0.8581, 0.1419], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 30 - 180: cat - cat || Loss: 0.4547710418701172\n",
      "tensor([1., 0.]) tensor([0.8585, 0.1415], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 30 - 181: cat - cat || Loss: 0.45441049337387085\n",
      "tensor([1., 0.]) tensor([0.8589, 0.1411], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 30 - 182: cat - cat || Loss: 0.4540509283542633\n",
      "tensor([1., 0.]) tensor([0.8592, 0.1408], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 30 - 183: cat - cat || Loss: 0.4536921977996826\n",
      "tensor([1., 0.]) tensor([0.8596, 0.1404], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 30 - 184: cat - cat || Loss: 0.4533342719078064\n",
      "tensor([1., 0.]) tensor([0.8599, 0.1401], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 30 - 185: cat - cat || Loss: 0.45297718048095703\n",
      "tensor([1., 0.]) tensor([0.8603, 0.1397], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 30 - 186: cat - cat || Loss: 0.45262080430984497\n",
      "tensor([1., 0.]) tensor([0.8606, 0.1394], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 30 - 187: cat - cat || Loss: 0.4522653818130493\n",
      "tensor([1., 0.]) tensor([0.8610, 0.1390], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 30 - 188: cat - cat || Loss: 0.45191073417663574\n",
      "tensor([1., 0.]) tensor([0.8614, 0.1386], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 30 - 189: cat - cat || Loss: 0.4515569806098938\n",
      "tensor([1., 0.]) tensor([0.8617, 0.1383], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 30 - 190: dog - cat || Loss: 1.1753194332122803\n",
      "tensor([0., 1.]) tensor([0.8621, 0.1379], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 30 - 191: dog - cat || Loss: 1.175601840019226\n",
      "tensor([0., 1.]) tensor([0.8623, 0.1377], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 30 - 192: dog - cat || Loss: 1.17582106590271\n",
      "tensor([0., 1.]) tensor([0.8626, 0.1374], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 30 - 193: dog - cat || Loss: 1.1759834289550781\n",
      "tensor([0., 1.]) tensor([0.8627, 0.1373], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 30 - 194: dog - cat || Loss: 1.1760947704315186\n",
      "tensor([0., 1.]) tensor([0.8628, 0.1372], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 30 - 195: dog - cat || Loss: 1.176160454750061\n",
      "tensor([0., 1.]) tensor([0.8629, 0.1371], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 30 - 196: dog - cat || Loss: 1.1761845350265503\n",
      "tensor([0., 1.]) tensor([0.8629, 0.1371], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 30 - 197: dog - cat || Loss: 1.1761715412139893\n",
      "tensor([0., 1.]) tensor([0.8629, 0.1371], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 30 - 198: dog - cat || Loss: 1.1761252880096436\n",
      "tensor([0., 1.]) tensor([0.8629, 0.1371], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 30 - 199: dog - cat || Loss: 1.1760488748550415\n",
      "tensor([0., 1.]) tensor([0.8628, 0.1372], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 30 - 200: dog - cat || Loss: 1.1759454011917114\n",
      "tensor([0., 1.]) tensor([0.8627, 0.1373], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 30 - 201: dog - cat || Loss: 1.1758173704147339\n",
      "tensor([0., 1.]) tensor([0.8626, 0.1374], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 30 - 202: dog - cat || Loss: 1.175667405128479\n",
      "tensor([0., 1.]) tensor([0.8624, 0.1376], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 30 - 203: dog - cat || Loss: 1.1754976511001587\n",
      "tensor([0., 1.]) tensor([0.8622, 0.1378], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 30 - 204: dog - cat || Loss: 1.1753097772598267\n",
      "tensor([0., 1.]) tensor([0.8620, 0.1380], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 30 - 205: dog - cat || Loss: 1.1751055717468262\n",
      "tensor([0., 1.]) tensor([0.8618, 0.1382], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 30 - 206: dog - cat || Loss: 1.1748870611190796\n",
      "tensor([0., 1.]) tensor([0.8616, 0.1384], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 30 - 207: dog - cat || Loss: 1.1746551990509033\n",
      "tensor([0., 1.]) tensor([0.8614, 0.1386], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 30 - 208: dog - cat || Loss: 1.1744110584259033\n",
      "tensor([0., 1.]) tensor([0.8611, 0.1389], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 30 - 209: dog - cat || Loss: 1.1741564273834229\n",
      "tensor([0., 1.]) tensor([0.8609, 0.1391], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 30 - 210: dog - cat || Loss: 1.1738916635513306\n",
      "tensor([0., 1.]) tensor([0.8606, 0.1394], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 30 - 211: dog - cat || Loss: 1.173618197441101\n",
      "tensor([0., 1.]) tensor([0.8604, 0.1396], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 30 - 212: dog - cat || Loss: 1.173336386680603\n",
      "tensor([0., 1.]) tensor([0.8601, 0.1399], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 30 - 213: dog - cat || Loss: 1.1730471849441528\n",
      "tensor([0., 1.]) tensor([0.8598, 0.1402], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 30 - 214: dog - cat || Loss: 1.1727511882781982\n",
      "tensor([0., 1.]) tensor([0.8595, 0.1405], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 30 - 215: dog - cat || Loss: 1.1724491119384766\n",
      "tensor([0., 1.]) tensor([0.8592, 0.1408], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 30 - 216: dog - cat || Loss: 1.1721415519714355\n",
      "tensor([0., 1.]) tensor([0.8589, 0.1411], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 30 - 217: dog - cat || Loss: 1.1718287467956543\n",
      "tensor([0., 1.]) tensor([0.8586, 0.1414], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 30 - 218: dog - cat || Loss: 1.1715112924575806\n",
      "tensor([0., 1.]) tensor([0.8582, 0.1418], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 30 - 219: dog - cat || Loss: 1.1711894273757935\n",
      "tensor([0., 1.]) tensor([0.8579, 0.1421], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 30 - 220: dog - cat || Loss: 1.1708637475967407\n",
      "tensor([0., 1.]) tensor([0.8576, 0.1424], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 30 - 221: dog - cat || Loss: 1.1705344915390015\n",
      "tensor([0., 1.]) tensor([0.8573, 0.1427], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 30 - 222: dog - cat || Loss: 1.1702016592025757\n",
      "tensor([0., 1.]) tensor([0.8569, 0.1431], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 30 - 223: dog - cat || Loss: 1.1698658466339111\n",
      "tensor([0., 1.]) tensor([0.8566, 0.1434], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 30 - 224: dog - cat || Loss: 1.1695271730422974\n",
      "tensor([0., 1.]) tensor([0.8563, 0.1437], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 30 - 225: dog - cat || Loss: 1.1691858768463135\n",
      "tensor([0., 1.]) tensor([0.8559, 0.1441], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 30 - 226: dog - cat || Loss: 1.1688419580459595\n",
      "tensor([0., 1.]) tensor([0.8556, 0.1444], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 30 - 227: dog - cat || Loss: 1.1684958934783936\n",
      "tensor([0., 1.]) tensor([0.8552, 0.1448], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 30 - 228: dog - cat || Loss: 1.1681474447250366\n",
      "tensor([0., 1.]) tensor([0.8549, 0.1451], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 30 - 229: dog - cat || Loss: 1.167797327041626\n",
      "tensor([0., 1.]) tensor([0.8545, 0.1455], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 30 - 230: dog - cat || Loss: 1.1674448251724243\n",
      "tensor([0., 1.]) tensor([0.8542, 0.1458], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 30 - 231: dog - cat || Loss: 1.167090892791748\n",
      "tensor([0., 1.]) tensor([0.8538, 0.1462], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 30 - 232: dog - cat || Loss: 1.1667351722717285\n",
      "tensor([0., 1.]) tensor([0.8535, 0.1465], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 30 - 233: dog - cat || Loss: 1.1663777828216553\n",
      "tensor([0., 1.]) tensor([0.8531, 0.1469], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 30 - 234: dog - cat || Loss: 1.1660189628601074\n",
      "tensor([0., 1.]) tensor([0.8528, 0.1472], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 30 - 235: dog - cat || Loss: 1.1656584739685059\n",
      "tensor([0., 1.]) tensor([0.8524, 0.1476], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 30 - 236: dog - cat || Loss: 1.1652966737747192\n",
      "tensor([0., 1.]) tensor([0.8520, 0.1480], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 30 - 237: dog - cat || Loss: 1.1649335622787476\n",
      "tensor([0., 1.]) tensor([0.8517, 0.1483], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 30 - 238: dog - cat || Loss: 1.1645692586898804\n",
      "tensor([0., 1.]) tensor([0.8513, 0.1487], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 30 - 239: dog - cat || Loss: 1.164203405380249\n",
      "tensor([0., 1.]) tensor([0.8509, 0.1491], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 30 - 240: dog - cat || Loss: 1.1638365983963013\n",
      "tensor([0., 1.]) tensor([0.8506, 0.1494], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 30 - 241: dog - cat || Loss: 1.1634684801101685\n",
      "tensor([0., 1.]) tensor([0.8502, 0.1498], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 30 - 242: dog - cat || Loss: 1.1630992889404297\n",
      "tensor([0., 1.]) tensor([0.8498, 0.1502], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 30 - 243: dog - cat || Loss: 1.1627289056777954\n",
      "tensor([0., 1.]) tensor([0.8495, 0.1505], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 30 - 244: dog - cat || Loss: 1.1623576879501343\n",
      "tensor([0., 1.]) tensor([0.8491, 0.1509], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 30 - 245: dog - cat || Loss: 1.1619852781295776\n",
      "tensor([0., 1.]) tensor([0.8487, 0.1513], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 30 - 246: dog - cat || Loss: 1.161611795425415\n",
      "tensor([0., 1.]) tensor([0.8484, 0.1516], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 30 - 247: dog - cat || Loss: 1.161237359046936\n",
      "tensor([0., 1.]) tensor([0.8480, 0.1520], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 30 - 248: dog - cat || Loss: 1.1608619689941406\n",
      "tensor([0., 1.]) tensor([0.8476, 0.1524], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 30 - 249: dog - cat || Loss: 1.1604853868484497\n",
      "tensor([0., 1.]) tensor([0.8472, 0.1528], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 30 - 250: dog - cat || Loss: 1.1601080894470215\n",
      "tensor([0., 1.]) tensor([0.8468, 0.1532], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 30 - 251: dog - cat || Loss: 1.1597297191619873\n",
      "tensor([0., 1.]) tensor([0.8465, 0.1535], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 30 - 252: dog - cat || Loss: 1.1593506336212158\n",
      "tensor([0., 1.]) tensor([0.8461, 0.1539], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 30 - 253: dog - cat || Loss: 1.1589702367782593\n",
      "tensor([0., 1.]) tensor([0.8457, 0.1543], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 30 - 254: dog - cat || Loss: 1.158589243888855\n",
      "tensor([0., 1.]) tensor([0.8453, 0.1547], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 30 - 255: dog - cat || Loss: 1.1582072973251343\n",
      "tensor([0., 1.]) tensor([0.8449, 0.1551], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 30 - 256: dog - cat || Loss: 1.1578242778778076\n",
      "tensor([0., 1.]) tensor([0.8446, 0.1554], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 30 - 257: dog - cat || Loss: 1.1574403047561646\n",
      "tensor([0., 1.]) tensor([0.8442, 0.1558], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 30 - 258: dog - cat || Loss: 1.1570557355880737\n",
      "tensor([0., 1.]) tensor([0.8438, 0.1562], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 30 - 259: dog - cat || Loss: 1.156670093536377\n",
      "tensor([0., 1.]) tensor([0.8434, 0.1566], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 30 - 260: dog - cat || Loss: 1.1562834978103638\n",
      "tensor([0., 1.]) tensor([0.8430, 0.1570], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 30 - 261: dog - cat || Loss: 1.1558961868286133\n",
      "tensor([0., 1.]) tensor([0.8426, 0.1574], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 30 - 262: dog - cat || Loss: 1.1555079221725464\n",
      "tensor([0., 1.]) tensor([0.8422, 0.1578], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 30 - 263: dog - cat || Loss: 1.1551188230514526\n",
      "tensor([0., 1.]) tensor([0.8419, 0.1581], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 30 - 264: dog - cat || Loss: 1.1547287702560425\n",
      "tensor([0., 1.]) tensor([0.8415, 0.1585], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 30 - 265: dog - cat || Loss: 1.1543378829956055\n",
      "tensor([0., 1.]) tensor([0.8411, 0.1589], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 30 - 266: dog - cat || Loss: 1.1539461612701416\n",
      "tensor([0., 1.]) tensor([0.8407, 0.1593], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 30 - 267: dog - cat || Loss: 1.1535536050796509\n",
      "tensor([0., 1.]) tensor([0.8403, 0.1597], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 30 - 268: dog - cat || Loss: 1.1531600952148438\n",
      "tensor([0., 1.]) tensor([0.8399, 0.1601], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 30 - 269: dog - cat || Loss: 1.1527657508850098\n",
      "tensor([0., 1.]) tensor([0.8395, 0.1605], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 30 - 270: dog - cat || Loss: 1.1523704528808594\n",
      "tensor([0., 1.]) tensor([0.8391, 0.1609], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 30 - 271: dog - cat || Loss: 1.1519745588302612\n",
      "tensor([0., 1.]) tensor([0.8387, 0.1613], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 30 - 272: dog - cat || Loss: 1.1515774726867676\n",
      "tensor([0., 1.]) tensor([0.8383, 0.1617], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 30 - 273: dog - cat || Loss: 1.1511799097061157\n",
      "tensor([0., 1.]) tensor([0.8379, 0.1621], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 30 - 274: dog - cat || Loss: 1.1507810354232788\n",
      "tensor([0., 1.]) tensor([0.8375, 0.1625], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 30 - 275: dog - cat || Loss: 1.1503815650939941\n",
      "tensor([0., 1.]) tensor([0.8371, 0.1629], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 30 - 276: dog - cat || Loss: 1.1499812602996826\n",
      "tensor([0., 1.]) tensor([0.8367, 0.1633], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 30 - 277: dog - cat || Loss: 1.1495800018310547\n",
      "tensor([0., 1.]) tensor([0.8363, 0.1637], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 30 - 278: dog - cat || Loss: 1.1491779088974\n",
      "tensor([0., 1.]) tensor([0.8359, 0.1641], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 30 - 279: dog - cat || Loss: 1.1487749814987183\n",
      "tensor([0., 1.]) tensor([0.8355, 0.1645], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 30 - 280: dog - cat || Loss: 1.1483712196350098\n",
      "tensor([0., 1.]) tensor([0.8351, 0.1649], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 30 - 281: dog - cat || Loss: 1.1479663848876953\n",
      "tensor([0., 1.]) tensor([0.8347, 0.1653], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 30 - 282: dog - cat || Loss: 1.147560954093933\n",
      "tensor([0., 1.]) tensor([0.8343, 0.1657], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 30 - 283: dog - cat || Loss: 1.1471545696258545\n",
      "tensor([0., 1.]) tensor([0.8339, 0.1661], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 30 - 284: dog - cat || Loss: 1.1467472314834595\n",
      "tensor([0., 1.]) tensor([0.8335, 0.1665], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 30 - 285: dog - cat || Loss: 1.1463391780853271\n",
      "tensor([0., 1.]) tensor([0.8331, 0.1669], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 30 - 286: dog - cat || Loss: 1.1459301710128784\n",
      "tensor([0., 1.]) tensor([0.8327, 0.1673], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 30 - 287: dog - cat || Loss: 1.1455203294754028\n",
      "tensor([0., 1.]) tensor([0.8323, 0.1677], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 30 - 288: dog - cat || Loss: 1.14510977268219\n",
      "tensor([0., 1.]) tensor([0.8318, 0.1682], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 30 - 289: dog - cat || Loss: 1.1446980237960815\n",
      "tensor([0., 1.]) tensor([0.8314, 0.1686], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 30 - 290: dog - cat || Loss: 1.1442856788635254\n",
      "tensor([0., 1.]) tensor([0.8310, 0.1690], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 30 - 291: dog - cat || Loss: 1.1438724994659424\n",
      "tensor([0., 1.]) tensor([0.8306, 0.1694], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 30 - 292: dog - cat || Loss: 1.1434582471847534\n",
      "tensor([0., 1.]) tensor([0.8302, 0.1698], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 30 - 293: dog - cat || Loss: 1.1430432796478271\n",
      "tensor([0., 1.]) tensor([0.8298, 0.1702], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 30 - 294: dog - cat || Loss: 1.142627477645874\n",
      "tensor([0., 1.]) tensor([0.8294, 0.1706], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 30 - 295: dog - cat || Loss: 1.1422107219696045\n",
      "tensor([0., 1.]) tensor([0.8289, 0.1711], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 30 - 296: dog - cat || Loss: 1.141793131828308\n",
      "tensor([0., 1.]) tensor([0.8285, 0.1715], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 30 - 297: dog - cat || Loss: 1.1413747072219849\n",
      "tensor([0., 1.]) tensor([0.8281, 0.1719], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 30 - 298: dog - cat || Loss: 1.1409554481506348\n",
      "tensor([0., 1.]) tensor([0.8277, 0.1723], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 30 - 299: dog - cat || Loss: 1.1405353546142578\n",
      "tensor([0., 1.]) tensor([0.8273, 0.1727], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 30 - 300: dog - cat || Loss: 1.1401140689849854\n",
      "tensor([0., 1.]) tensor([0.8269, 0.1731], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 30 - 301: dog - cat || Loss: 1.1396921873092651\n",
      "tensor([0., 1.]) tensor([0.8264, 0.1736], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 30 - 302: dog - cat || Loss: 1.139269471168518\n",
      "tensor([0., 1.]) tensor([0.8260, 0.1740], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 30 - 303: dog - cat || Loss: 1.1388458013534546\n",
      "tensor([0., 1.]) tensor([0.8256, 0.1744], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 30 - 304: dog - cat || Loss: 1.1384212970733643\n",
      "tensor([0., 1.]) tensor([0.8252, 0.1748], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 30 - 305: dog - cat || Loss: 1.1379958391189575\n",
      "tensor([0., 1.]) tensor([0.8247, 0.1753], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 30 - 306: dog - cat || Loss: 1.1375696659088135\n",
      "tensor([0., 1.]) tensor([0.8243, 0.1757], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 30 - 307: dog - cat || Loss: 1.1371424198150635\n",
      "tensor([0., 1.]) tensor([0.8239, 0.1761], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 30 - 308: dog - cat || Loss: 1.1367144584655762\n",
      "tensor([0., 1.]) tensor([0.8235, 0.1765], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 30 - 309: dog - cat || Loss: 1.136285662651062\n",
      "tensor([0., 1.]) tensor([0.8230, 0.1770], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 30 - 310: dog - cat || Loss: 1.135855793952942\n",
      "tensor([0., 1.]) tensor([0.8226, 0.1774], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 30 - 311: dog - cat || Loss: 1.1354252099990845\n",
      "tensor([0., 1.]) tensor([0.8222, 0.1778], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 30 - 312: dog - cat || Loss: 1.1349936723709106\n",
      "tensor([0., 1.]) tensor([0.8217, 0.1783], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 30 - 313: dog - cat || Loss: 1.13456130027771\n",
      "tensor([0., 1.]) tensor([0.8213, 0.1787], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 30 - 314: dog - cat || Loss: 1.1341279745101929\n",
      "tensor([0., 1.]) tensor([0.8209, 0.1791], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 30 - 315: dog - cat || Loss: 1.133694052696228\n",
      "tensor([0., 1.]) tensor([0.8204, 0.1796], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 30 - 316: dog - cat || Loss: 1.1332589387893677\n",
      "tensor([0., 1.]) tensor([0.8200, 0.1800], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 30 - 317: dog - cat || Loss: 1.13282310962677\n",
      "tensor([0., 1.]) tensor([0.8196, 0.1804], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 30 - 318: dog - cat || Loss: 1.1323862075805664\n",
      "tensor([0., 1.]) tensor([0.8191, 0.1809], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 30 - 319: dog - cat || Loss: 1.131948709487915\n",
      "tensor([0., 1.]) tensor([0.8187, 0.1813], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 30 - 320: dog - cat || Loss: 1.1315101385116577\n",
      "tensor([0., 1.]) tensor([0.8182, 0.1818], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 30 - 321: dog - cat || Loss: 1.131070852279663\n",
      "tensor([0., 1.]) tensor([0.8178, 0.1822], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 30 - 322: dog - cat || Loss: 1.1306307315826416\n",
      "tensor([0., 1.]) tensor([0.8174, 0.1826], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 30 - 323: dog - cat || Loss: 1.1301894187927246\n",
      "tensor([0., 1.]) tensor([0.8169, 0.1831], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 30 - 324: dog - cat || Loss: 1.1297475099563599\n",
      "tensor([0., 1.]) tensor([0.8165, 0.1835], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 30 - 325: dog - cat || Loss: 1.1293047666549683\n",
      "tensor([0., 1.]) tensor([0.8160, 0.1840], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 30 - 326: dog - cat || Loss: 1.1288608312606812\n",
      "tensor([0., 1.]) tensor([0.8156, 0.1844], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 30 - 327: dog - cat || Loss: 1.1284161806106567\n",
      "tensor([0., 1.]) tensor([0.8152, 0.1848], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 30 - 328: dog - cat || Loss: 1.127970576286316\n",
      "tensor([0., 1.]) tensor([0.8147, 0.1853], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 30 - 329: dog - cat || Loss: 1.1275241374969482\n",
      "tensor([0., 1.]) tensor([0.8143, 0.1857], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 30 - 330: dog - cat || Loss: 1.1270768642425537\n",
      "tensor([0., 1.]) tensor([0.8138, 0.1862], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 30 - 331: dog - cat || Loss: 1.1266287565231323\n",
      "tensor([0., 1.]) tensor([0.8134, 0.1866], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 30 - 332: dog - cat || Loss: 1.1261796951293945\n",
      "tensor([0., 1.]) tensor([0.8129, 0.1871], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 30 - 333: dog - cat || Loss: 1.1257297992706299\n",
      "tensor([0., 1.]) tensor([0.8125, 0.1875], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 30 - 334: dog - cat || Loss: 1.1252788305282593\n",
      "tensor([0., 1.]) tensor([0.8120, 0.1880], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 30 - 335: dog - cat || Loss: 1.1248271465301514\n",
      "tensor([0., 1.]) tensor([0.8116, 0.1884], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 30 - 336: dog - cat || Loss: 1.1243746280670166\n",
      "tensor([0., 1.]) tensor([0.8111, 0.1889], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 30 - 337: dog - cat || Loss: 1.1239210367202759\n",
      "tensor([0., 1.]) tensor([0.8107, 0.1893], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 30 - 338: dog - cat || Loss: 1.1234668493270874\n",
      "tensor([0., 1.]) tensor([0.8102, 0.1898], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 30 - 339: dog - cat || Loss: 1.123011589050293\n",
      "tensor([0., 1.]) tensor([0.8097, 0.1903], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 30 - 340: dog - cat || Loss: 1.1225553750991821\n",
      "tensor([0., 1.]) tensor([0.8093, 0.1907], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 30 - 341: dog - cat || Loss: 1.1220983266830444\n",
      "tensor([0., 1.]) tensor([0.8088, 0.1912], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 30 - 342: dog - cat || Loss: 1.1216404438018799\n",
      "tensor([0., 1.]) tensor([0.8084, 0.1916], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 30 - 343: dog - cat || Loss: 1.121181607246399\n",
      "tensor([0., 1.]) tensor([0.8079, 0.1921], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 30 - 344: dog - cat || Loss: 1.1207220554351807\n",
      "tensor([0., 1.]) tensor([0.8075, 0.1925], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 30 - 345: dog - cat || Loss: 1.1202614307403564\n",
      "tensor([0., 1.]) tensor([0.8070, 0.1930], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 30 - 346: dog - cat || Loss: 1.1197998523712158\n",
      "tensor([0., 1.]) tensor([0.8065, 0.1935], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 30 - 347: dog - cat || Loss: 1.119337558746338\n",
      "tensor([0., 1.]) tensor([0.8061, 0.1939], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 30 - 348: dog - cat || Loss: 1.1188743114471436\n",
      "tensor([0., 1.]) tensor([0.8056, 0.1944], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 30 - 349: dog - cat || Loss: 1.1184102296829224\n",
      "tensor([0., 1.]) tensor([0.8051, 0.1949], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 30 - 350: dog - cat || Loss: 1.1179451942443848\n",
      "tensor([0., 1.]) tensor([0.8047, 0.1953], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 30 - 351: dog - cat || Loss: 1.1174794435501099\n",
      "tensor([0., 1.]) tensor([0.8042, 0.1958], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 30 - 352: dog - cat || Loss: 1.1170125007629395\n",
      "tensor([0., 1.]) tensor([0.8038, 0.1962], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 30 - 353: dog - cat || Loss: 1.1165448427200317\n",
      "tensor([0., 1.]) tensor([0.8033, 0.1967], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 30 - 354: dog - cat || Loss: 1.116075873374939\n",
      "tensor([0., 1.]) tensor([0.8028, 0.1972], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 30 - 355: dog - cat || Loss: 1.115606427192688\n",
      "tensor([0., 1.]) tensor([0.8023, 0.1977], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 30 - 356: dog - cat || Loss: 1.115135908126831\n",
      "tensor([0., 1.]) tensor([0.8019, 0.1981], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 30 - 357: dog - cat || Loss: 1.1146645545959473\n",
      "tensor([0., 1.]) tensor([0.8014, 0.1986], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 30 - 358: dog - cat || Loss: 1.114192247390747\n",
      "tensor([0., 1.]) tensor([0.8009, 0.1991], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 30 - 359: dog - cat || Loss: 1.1137189865112305\n",
      "tensor([0., 1.]) tensor([0.8005, 0.1995], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 30 - 360: dog - cat || Loss: 1.1132450103759766\n",
      "tensor([0., 1.]) tensor([0.8000, 0.2000], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 30 - 361: dog - cat || Loss: 1.1127700805664062\n",
      "tensor([0., 1.]) tensor([0.7995, 0.2005], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 30 - 362: dog - cat || Loss: 1.112294316291809\n",
      "tensor([0., 1.]) tensor([0.7990, 0.2010], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 30 - 363: dog - cat || Loss: 1.1118175983428955\n",
      "tensor([0., 1.]) tensor([0.7986, 0.2014], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 30 - 364: dog - cat || Loss: 1.1113399267196655\n",
      "tensor([0., 1.]) tensor([0.7981, 0.2019], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 30 - 365: dog - cat || Loss: 1.1108615398406982\n",
      "tensor([0., 1.]) tensor([0.7976, 0.2024], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 30 - 366: dog - cat || Loss: 1.1103819608688354\n",
      "tensor([0., 1.]) tensor([0.7971, 0.2029], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 30 - 367: dog - cat || Loss: 1.1099016666412354\n",
      "tensor([0., 1.]) tensor([0.7966, 0.2034], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 30 - 368: dog - cat || Loss: 1.1094204187393188\n",
      "tensor([0., 1.]) tensor([0.7962, 0.2038], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 30 - 369: dog - cat || Loss: 1.108938217163086\n",
      "tensor([0., 1.]) tensor([0.7957, 0.2043], grad_fn=<SoftmaxBackward0>)\n",
      "=====epoch:31=====\n",
      "Epoch 31 - 0: cat - cat || Loss: 0.5180681347846985\n",
      "tensor([1., 0.]) tensor([0.7952, 0.2048], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 31 - 1: cat - cat || Loss: 0.518454372882843\n",
      "tensor([1., 0.]) tensor([0.7948, 0.2052], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 31 - 2: cat - cat || Loss: 0.5187534689903259\n",
      "tensor([1., 0.]) tensor([0.7945, 0.2055], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 31 - 3: cat - cat || Loss: 0.518973708152771\n",
      "tensor([1., 0.]) tensor([0.7943, 0.2057], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 31 - 4: cat - cat || Loss: 0.5191230773925781\n",
      "tensor([1., 0.]) tensor([0.7941, 0.2059], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 31 - 5: cat - cat || Loss: 0.519208550453186\n",
      "tensor([1., 0.]) tensor([0.7941, 0.2059], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 31 - 6: cat - cat || Loss: 0.5192365050315857\n",
      "tensor([1., 0.]) tensor([0.7940, 0.2060], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 31 - 7: cat - cat || Loss: 0.5192126035690308\n",
      "tensor([1., 0.]) tensor([0.7940, 0.2060], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 31 - 8: cat - cat || Loss: 0.5191421508789062\n",
      "tensor([1., 0.]) tensor([0.7941, 0.2059], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 31 - 9: cat - cat || Loss: 0.5190297961235046\n",
      "tensor([1., 0.]) tensor([0.7942, 0.2058], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 31 - 10: cat - cat || Loss: 0.5188796520233154\n",
      "tensor([1., 0.]) tensor([0.7944, 0.2056], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 31 - 11: cat - cat || Loss: 0.5186958312988281\n",
      "tensor([1., 0.]) tensor([0.7946, 0.2054], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 31 - 12: cat - cat || Loss: 0.518481433391571\n",
      "tensor([1., 0.]) tensor([0.7948, 0.2052], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 31 - 13: cat - cat || Loss: 0.5182398557662964\n",
      "tensor([1., 0.]) tensor([0.7950, 0.2050], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 31 - 14: cat - cat || Loss: 0.5179736614227295\n",
      "tensor([1., 0.]) tensor([0.7953, 0.2047], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 31 - 15: cat - cat || Loss: 0.5176855325698853\n",
      "tensor([1., 0.]) tensor([0.7956, 0.2044], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 31 - 16: cat - cat || Loss: 0.5173776745796204\n",
      "tensor([1., 0.]) tensor([0.7959, 0.2041], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 31 - 17: cat - cat || Loss: 0.5170520544052124\n",
      "tensor([1., 0.]) tensor([0.7962, 0.2038], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 31 - 18: cat - cat || Loss: 0.5167108178138733\n",
      "tensor([1., 0.]) tensor([0.7966, 0.2034], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 31 - 19: cat - cat || Loss: 0.5163552761077881\n",
      "tensor([1., 0.]) tensor([0.7969, 0.2031], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 31 - 20: cat - cat || Loss: 0.5159870982170105\n",
      "tensor([1., 0.]) tensor([0.7973, 0.2027], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 31 - 21: cat - cat || Loss: 0.5156075954437256\n",
      "tensor([1., 0.]) tensor([0.7977, 0.2023], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 31 - 22: cat - cat || Loss: 0.5152181386947632\n",
      "tensor([1., 0.]) tensor([0.7980, 0.2020], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 31 - 23: cat - cat || Loss: 0.5148196220397949\n",
      "tensor([1., 0.]) tensor([0.7984, 0.2016], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 31 - 24: cat - cat || Loss: 0.514413058757782\n",
      "tensor([1., 0.]) tensor([0.7988, 0.2012], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 31 - 25: cat - cat || Loss: 0.5139994621276855\n",
      "tensor([1., 0.]) tensor([0.7993, 0.2007], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 31 - 26: cat - cat || Loss: 0.5135796070098877\n",
      "tensor([1., 0.]) tensor([0.7997, 0.2003], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 31 - 27: cat - cat || Loss: 0.5131540298461914\n",
      "tensor([1., 0.]) tensor([0.8001, 0.1999], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 31 - 28: cat - cat || Loss: 0.5127235651016235\n",
      "tensor([1., 0.]) tensor([0.8005, 0.1995], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 31 - 29: cat - cat || Loss: 0.5122886896133423\n",
      "tensor([1., 0.]) tensor([0.8010, 0.1990], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 31 - 30: cat - cat || Loss: 0.5118502378463745\n",
      "tensor([1., 0.]) tensor([0.8014, 0.1986], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 31 - 31: cat - cat || Loss: 0.5114083290100098\n",
      "tensor([1., 0.]) tensor([0.8019, 0.1981], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 31 - 32: cat - cat || Loss: 0.5109634399414062\n",
      "tensor([1., 0.]) tensor([0.8023, 0.1977], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 31 - 33: cat - cat || Loss: 0.5105162858963013\n",
      "tensor([1., 0.]) tensor([0.8027, 0.1973], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 31 - 34: cat - cat || Loss: 0.5100667476654053\n",
      "tensor([1., 0.]) tensor([0.8032, 0.1968], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 31 - 35: cat - cat || Loss: 0.5096153020858765\n",
      "tensor([1., 0.]) tensor([0.8036, 0.1964], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 31 - 36: cat - cat || Loss: 0.509162425994873\n",
      "tensor([1., 0.]) tensor([0.8041, 0.1959], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 31 - 37: cat - cat || Loss: 0.508708119392395\n",
      "tensor([1., 0.]) tensor([0.8046, 0.1954], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 31 - 38: cat - cat || Loss: 0.5082526803016663\n",
      "tensor([1., 0.]) tensor([0.8050, 0.1950], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 31 - 39: cat - cat || Loss: 0.5077962875366211\n",
      "tensor([1., 0.]) tensor([0.8055, 0.1945], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 31 - 40: cat - cat || Loss: 0.5073394775390625\n",
      "tensor([1., 0.]) tensor([0.8059, 0.1941], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 31 - 41: cat - cat || Loss: 0.5068817138671875\n",
      "tensor([1., 0.]) tensor([0.8064, 0.1936], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 31 - 42: cat - cat || Loss: 0.5064237117767334\n",
      "tensor([1., 0.]) tensor([0.8068, 0.1932], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 31 - 43: cat - cat || Loss: 0.5059653520584106\n",
      "tensor([1., 0.]) tensor([0.8073, 0.1927], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 31 - 44: cat - cat || Loss: 0.5055069923400879\n",
      "tensor([1., 0.]) tensor([0.8078, 0.1922], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 31 - 45: cat - cat || Loss: 0.505048394203186\n",
      "tensor([1., 0.]) tensor([0.8082, 0.1918], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 31 - 46: cat - cat || Loss: 0.504589855670929\n",
      "tensor([1., 0.]) tensor([0.8087, 0.1913], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 31 - 47: cat - cat || Loss: 0.5041314959526062\n",
      "tensor([1., 0.]) tensor([0.8091, 0.1909], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 31 - 48: cat - cat || Loss: 0.5036733746528625\n",
      "tensor([1., 0.]) tensor([0.8096, 0.1904], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 31 - 49: cat - cat || Loss: 0.5032155513763428\n",
      "tensor([1., 0.]) tensor([0.8100, 0.1900], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 31 - 50: cat - cat || Loss: 0.5027580261230469\n",
      "tensor([1., 0.]) tensor([0.8105, 0.1895], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 31 - 51: cat - cat || Loss: 0.5023009181022644\n",
      "tensor([1., 0.]) tensor([0.8110, 0.1890], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 31 - 52: cat - cat || Loss: 0.5018442273139954\n",
      "tensor([1., 0.]) tensor([0.8114, 0.1886], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 31 - 53: cat - cat || Loss: 0.5013880729675293\n",
      "tensor([1., 0.]) tensor([0.8119, 0.1881], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 31 - 54: cat - cat || Loss: 0.5009324550628662\n",
      "tensor([1., 0.]) tensor([0.8123, 0.1877], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 31 - 55: cat - cat || Loss: 0.5004774332046509\n",
      "tensor([1., 0.]) tensor([0.8128, 0.1872], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 31 - 56: cat - cat || Loss: 0.5000229477882385\n",
      "tensor([1., 0.]) tensor([0.8132, 0.1868], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 31 - 57: cat - cat || Loss: 0.4995691776275635\n",
      "tensor([1., 0.]) tensor([0.8137, 0.1863], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 31 - 58: cat - cat || Loss: 0.49911603331565857\n",
      "tensor([1., 0.]) tensor([0.8141, 0.1859], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 31 - 59: cat - cat || Loss: 0.49866366386413574\n",
      "tensor([1., 0.]) tensor([0.8146, 0.1854], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 31 - 60: cat - cat || Loss: 0.49821195006370544\n",
      "tensor([1., 0.]) tensor([0.8150, 0.1850], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 31 - 61: cat - cat || Loss: 0.49776092171669006\n",
      "tensor([1., 0.]) tensor([0.8155, 0.1845], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 31 - 62: cat - cat || Loss: 0.49731069803237915\n",
      "tensor([1., 0.]) tensor([0.8160, 0.1840], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 31 - 63: cat - cat || Loss: 0.4968612790107727\n",
      "tensor([1., 0.]) tensor([0.8164, 0.1836], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 31 - 64: cat - cat || Loss: 0.49641263484954834\n",
      "tensor([1., 0.]) tensor([0.8168, 0.1832], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 31 - 65: cat - cat || Loss: 0.4959647059440613\n",
      "tensor([1., 0.]) tensor([0.8173, 0.1827], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 31 - 66: cat - cat || Loss: 0.4955176115036011\n",
      "tensor([1., 0.]) tensor([0.8177, 0.1823], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 31 - 67: cat - cat || Loss: 0.4950713813304901\n",
      "tensor([1., 0.]) tensor([0.8182, 0.1818], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 31 - 68: cat - cat || Loss: 0.49462592601776123\n",
      "tensor([1., 0.]) tensor([0.8186, 0.1814], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 31 - 69: cat - cat || Loss: 0.49418139457702637\n",
      "tensor([1., 0.]) tensor([0.8191, 0.1809], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 31 - 70: cat - cat || Loss: 0.49373769760131836\n",
      "tensor([1., 0.]) tensor([0.8195, 0.1805], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 31 - 71: cat - cat || Loss: 0.4932948350906372\n",
      "tensor([1., 0.]) tensor([0.8200, 0.1800], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 31 - 72: cat - cat || Loss: 0.4928528070449829\n",
      "tensor([1., 0.]) tensor([0.8204, 0.1796], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 31 - 73: cat - cat || Loss: 0.4924115836620331\n",
      "tensor([1., 0.]) tensor([0.8209, 0.1791], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 31 - 74: cat - cat || Loss: 0.4919712543487549\n",
      "tensor([1., 0.]) tensor([0.8213, 0.1787], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 31 - 75: cat - cat || Loss: 0.4915318489074707\n",
      "tensor([1., 0.]) tensor([0.8217, 0.1783], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 31 - 76: cat - cat || Loss: 0.4910932779312134\n",
      "tensor([1., 0.]) tensor([0.8222, 0.1778], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 31 - 77: cat - cat || Loss: 0.4906556308269501\n",
      "tensor([1., 0.]) tensor([0.8226, 0.1774], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 31 - 78: cat - cat || Loss: 0.49021878838539124\n",
      "tensor([1., 0.]) tensor([0.8230, 0.1770], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 31 - 79: cat - cat || Loss: 0.4897828698158264\n",
      "tensor([1., 0.]) tensor([0.8235, 0.1765], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 31 - 80: cat - cat || Loss: 0.489347904920578\n",
      "tensor([1., 0.]) tensor([0.8239, 0.1761], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 31 - 81: cat - cat || Loss: 0.48891371488571167\n",
      "tensor([1., 0.]) tensor([0.8243, 0.1757], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 31 - 82: cat - cat || Loss: 0.48848041892051697\n",
      "tensor([1., 0.]) tensor([0.8248, 0.1752], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 31 - 83: cat - cat || Loss: 0.48804807662963867\n",
      "tensor([1., 0.]) tensor([0.8252, 0.1748], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 31 - 84: cat - cat || Loss: 0.4876166582107544\n",
      "tensor([1., 0.]) tensor([0.8256, 0.1744], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 31 - 85: cat - cat || Loss: 0.48718613386154175\n",
      "tensor([1., 0.]) tensor([0.8261, 0.1739], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 31 - 86: cat - cat || Loss: 0.4867563843727112\n",
      "tensor([1., 0.]) tensor([0.8265, 0.1735], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 31 - 87: cat - cat || Loss: 0.4863276183605194\n",
      "tensor([1., 0.]) tensor([0.8269, 0.1731], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 31 - 88: cat - cat || Loss: 0.48589974641799927\n",
      "tensor([1., 0.]) tensor([0.8274, 0.1726], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 31 - 89: cat - cat || Loss: 0.48547273874282837\n",
      "tensor([1., 0.]) tensor([0.8278, 0.1722], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 31 - 90: cat - cat || Loss: 0.4850466251373291\n",
      "tensor([1., 0.]) tensor([0.8282, 0.1718], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 31 - 91: cat - cat || Loss: 0.4846213459968567\n",
      "tensor([1., 0.]) tensor([0.8286, 0.1714], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 31 - 92: cat - cat || Loss: 0.48419708013534546\n",
      "tensor([1., 0.]) tensor([0.8291, 0.1709], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 31 - 93: cat - cat || Loss: 0.4837736487388611\n",
      "tensor([1., 0.]) tensor([0.8295, 0.1705], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 31 - 94: cat - cat || Loss: 0.48335111141204834\n",
      "tensor([1., 0.]) tensor([0.8299, 0.1701], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 31 - 95: cat - cat || Loss: 0.48292940855026245\n",
      "tensor([1., 0.]) tensor([0.8303, 0.1697], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 31 - 96: cat - cat || Loss: 0.48250871896743774\n",
      "tensor([1., 0.]) tensor([0.8308, 0.1692], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 31 - 97: cat - cat || Loss: 0.48208892345428467\n",
      "tensor([1., 0.]) tensor([0.8312, 0.1688], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 31 - 98: cat - cat || Loss: 0.48166990280151367\n",
      "tensor([1., 0.]) tensor([0.8316, 0.1684], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 31 - 99: cat - cat || Loss: 0.48125189542770386\n",
      "tensor([1., 0.]) tensor([0.8320, 0.1680], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 31 - 100: cat - cat || Loss: 0.4808347225189209\n",
      "tensor([1., 0.]) tensor([0.8324, 0.1676], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 31 - 101: cat - cat || Loss: 0.48041850328445435\n",
      "tensor([1., 0.]) tensor([0.8328, 0.1672], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 31 - 102: cat - cat || Loss: 0.48000311851501465\n",
      "tensor([1., 0.]) tensor([0.8333, 0.1667], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 31 - 103: cat - cat || Loss: 0.4795885980129242\n",
      "tensor([1., 0.]) tensor([0.8337, 0.1663], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 31 - 104: cat - cat || Loss: 0.4791749119758606\n",
      "tensor([1., 0.]) tensor([0.8341, 0.1659], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 31 - 105: cat - cat || Loss: 0.47876232862472534\n",
      "tensor([1., 0.]) tensor([0.8345, 0.1655], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 31 - 106: cat - cat || Loss: 0.47835052013397217\n",
      "tensor([1., 0.]) tensor([0.8349, 0.1651], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 31 - 107: cat - cat || Loss: 0.4779396057128906\n",
      "tensor([1., 0.]) tensor([0.8353, 0.1647], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 31 - 108: cat - cat || Loss: 0.4775296151638031\n",
      "tensor([1., 0.]) tensor([0.8357, 0.1643], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 31 - 109: cat - cat || Loss: 0.4771205186843872\n",
      "tensor([1., 0.]) tensor([0.8361, 0.1639], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 31 - 110: cat - cat || Loss: 0.476712167263031\n",
      "tensor([1., 0.]) tensor([0.8365, 0.1635], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 31 - 111: cat - cat || Loss: 0.47630491852760315\n",
      "tensor([1., 0.]) tensor([0.8370, 0.1630], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 31 - 112: cat - cat || Loss: 0.4758984446525574\n",
      "tensor([1., 0.]) tensor([0.8374, 0.1626], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 31 - 113: cat - cat || Loss: 0.4754928946495056\n",
      "tensor([1., 0.]) tensor([0.8378, 0.1622], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 31 - 114: cat - cat || Loss: 0.4750882089138031\n",
      "tensor([1., 0.]) tensor([0.8382, 0.1618], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 31 - 115: cat - cat || Loss: 0.4746845066547394\n",
      "tensor([1., 0.]) tensor([0.8386, 0.1614], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 31 - 116: cat - cat || Loss: 0.47428154945373535\n",
      "tensor([1., 0.]) tensor([0.8390, 0.1610], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 31 - 117: cat - cat || Loss: 0.47387951612472534\n",
      "tensor([1., 0.]) tensor([0.8394, 0.1606], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 31 - 118: cat - cat || Loss: 0.4734783470630646\n",
      "tensor([1., 0.]) tensor([0.8398, 0.1602], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 31 - 119: cat - cat || Loss: 0.47307825088500977\n",
      "tensor([1., 0.]) tensor([0.8402, 0.1598], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 31 - 120: cat - cat || Loss: 0.4726788103580475\n",
      "tensor([1., 0.]) tensor([0.8406, 0.1594], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 31 - 121: cat - cat || Loss: 0.4722802937030792\n",
      "tensor([1., 0.]) tensor([0.8410, 0.1590], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 31 - 122: cat - cat || Loss: 0.471882700920105\n",
      "tensor([1., 0.]) tensor([0.8414, 0.1586], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 31 - 123: cat - cat || Loss: 0.47148603200912476\n",
      "tensor([1., 0.]) tensor([0.8418, 0.1582], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 31 - 124: cat - cat || Loss: 0.4710901975631714\n",
      "tensor([1., 0.]) tensor([0.8422, 0.1578], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 31 - 125: cat - cat || Loss: 0.4706953167915344\n",
      "tensor([1., 0.]) tensor([0.8426, 0.1574], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 31 - 126: cat - cat || Loss: 0.47030118107795715\n",
      "tensor([1., 0.]) tensor([0.8430, 0.1570], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 31 - 127: cat - cat || Loss: 0.4699079394340515\n",
      "tensor([1., 0.]) tensor([0.8434, 0.1566], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 31 - 128: cat - cat || Loss: 0.4695155918598175\n",
      "tensor([1., 0.]) tensor([0.8437, 0.1563], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 31 - 129: cat - cat || Loss: 0.46912410855293274\n",
      "tensor([1., 0.]) tensor([0.8441, 0.1559], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 31 - 130: cat - cat || Loss: 0.468733549118042\n",
      "tensor([1., 0.]) tensor([0.8445, 0.1555], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 31 - 131: cat - cat || Loss: 0.46834373474121094\n",
      "tensor([1., 0.]) tensor([0.8449, 0.1551], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 31 - 132: cat - cat || Loss: 0.46795493364334106\n",
      "tensor([1., 0.]) tensor([0.8453, 0.1547], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 31 - 133: cat - cat || Loss: 0.46756696701049805\n",
      "tensor([1., 0.]) tensor([0.8457, 0.1543], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 31 - 134: cat - cat || Loss: 0.4671798348426819\n",
      "tensor([1., 0.]) tensor([0.8461, 0.1539], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 31 - 135: cat - cat || Loss: 0.4667937159538269\n",
      "tensor([1., 0.]) tensor([0.8465, 0.1535], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 31 - 136: cat - cat || Loss: 0.4664081931114197\n",
      "tensor([1., 0.]) tensor([0.8469, 0.1531], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 31 - 137: cat - cat || Loss: 0.46602362394332886\n",
      "tensor([1., 0.]) tensor([0.8472, 0.1528], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 31 - 138: cat - cat || Loss: 0.4656400680541992\n",
      "tensor([1., 0.]) tensor([0.8476, 0.1524], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 31 - 139: cat - cat || Loss: 0.4652572274208069\n",
      "tensor([1., 0.]) tensor([0.8480, 0.1520], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 31 - 140: cat - cat || Loss: 0.4648752808570862\n",
      "tensor([1., 0.]) tensor([0.8484, 0.1516], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 31 - 141: cat - cat || Loss: 0.4644942879676819\n",
      "tensor([1., 0.]) tensor([0.8488, 0.1512], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 31 - 142: cat - cat || Loss: 0.4641140103340149\n",
      "tensor([1., 0.]) tensor([0.8491, 0.1509], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 31 - 143: cat - cat || Loss: 0.4637346565723419\n",
      "tensor([1., 0.]) tensor([0.8495, 0.1505], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 31 - 144: cat - cat || Loss: 0.4633561968803406\n",
      "tensor([1., 0.]) tensor([0.8499, 0.1501], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 31 - 145: cat - cat || Loss: 0.4629785418510437\n",
      "tensor([1., 0.]) tensor([0.8503, 0.1497], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 31 - 146: cat - cat || Loss: 0.46260178089141846\n",
      "tensor([1., 0.]) tensor([0.8507, 0.1493], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 31 - 147: cat - cat || Loss: 0.46222585439682007\n",
      "tensor([1., 0.]) tensor([0.8510, 0.1490], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 31 - 148: cat - cat || Loss: 0.46185070276260376\n",
      "tensor([1., 0.]) tensor([0.8514, 0.1486], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 31 - 149: cat - cat || Loss: 0.46147656440734863\n",
      "tensor([1., 0.]) tensor([0.8518, 0.1482], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 31 - 150: cat - cat || Loss: 0.4611031413078308\n",
      "tensor([1., 0.]) tensor([0.8522, 0.1478], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 31 - 151: cat - cat || Loss: 0.4607306718826294\n",
      "tensor([1., 0.]) tensor([0.8525, 0.1475], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 31 - 152: cat - cat || Loss: 0.4603590965270996\n",
      "tensor([1., 0.]) tensor([0.8529, 0.1471], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 31 - 153: cat - cat || Loss: 0.45998823642730713\n",
      "tensor([1., 0.]) tensor([0.8533, 0.1467], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 31 - 154: cat - cat || Loss: 0.45961830019950867\n",
      "tensor([1., 0.]) tensor([0.8536, 0.1464], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 31 - 155: cat - cat || Loss: 0.45924922823905945\n",
      "tensor([1., 0.]) tensor([0.8540, 0.1460], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 31 - 156: cat - cat || Loss: 0.4588809907436371\n",
      "tensor([1., 0.]) tensor([0.8544, 0.1456], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 31 - 157: cat - cat || Loss: 0.45851367712020874\n",
      "tensor([1., 0.]) tensor([0.8547, 0.1453], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 31 - 158: cat - cat || Loss: 0.4581471085548401\n",
      "tensor([1., 0.]) tensor([0.8551, 0.1449], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 31 - 159: cat - cat || Loss: 0.45778143405914307\n",
      "tensor([1., 0.]) tensor([0.8555, 0.1445], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 31 - 160: cat - cat || Loss: 0.4574165344238281\n",
      "tensor([1., 0.]) tensor([0.8558, 0.1442], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 31 - 161: cat - cat || Loss: 0.4570525586605072\n",
      "tensor([1., 0.]) tensor([0.8562, 0.1438], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 31 - 162: cat - cat || Loss: 0.4566894471645355\n",
      "tensor([1., 0.]) tensor([0.8566, 0.1434], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 31 - 163: cat - cat || Loss: 0.45632702112197876\n",
      "tensor([1., 0.]) tensor([0.8569, 0.1431], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 31 - 164: cat - cat || Loss: 0.45596563816070557\n",
      "tensor([1., 0.]) tensor([0.8573, 0.1427], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 31 - 165: cat - cat || Loss: 0.45560505986213684\n",
      "tensor([1., 0.]) tensor([0.8577, 0.1423], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 31 - 166: cat - cat || Loss: 0.45524513721466064\n",
      "tensor([1., 0.]) tensor([0.8580, 0.1420], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 31 - 167: cat - cat || Loss: 0.45488619804382324\n",
      "tensor([1., 0.]) tensor([0.8584, 0.1416], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 31 - 168: cat - cat || Loss: 0.45452815294265747\n",
      "tensor([1., 0.]) tensor([0.8587, 0.1413], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 31 - 169: cat - cat || Loss: 0.454170823097229\n",
      "tensor([1., 0.]) tensor([0.8591, 0.1409], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 31 - 170: cat - cat || Loss: 0.4538143277168274\n",
      "tensor([1., 0.]) tensor([0.8594, 0.1406], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 31 - 171: cat - cat || Loss: 0.4534587860107422\n",
      "tensor([1., 0.]) tensor([0.8598, 0.1402], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 31 - 172: cat - cat || Loss: 0.45310401916503906\n",
      "tensor([1., 0.]) tensor([0.8602, 0.1398], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 31 - 173: cat - cat || Loss: 0.4527500867843628\n",
      "tensor([1., 0.]) tensor([0.8605, 0.1395], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 31 - 174: cat - cat || Loss: 0.4523968994617462\n",
      "tensor([1., 0.]) tensor([0.8609, 0.1391], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 31 - 175: cat - cat || Loss: 0.4520445466041565\n",
      "tensor([1., 0.]) tensor([0.8612, 0.1388], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 31 - 176: cat - cat || Loss: 0.4516930878162384\n",
      "tensor([1., 0.]) tensor([0.8616, 0.1384], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 31 - 177: cat - cat || Loss: 0.45134252309799194\n",
      "tensor([1., 0.]) tensor([0.8619, 0.1381], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 31 - 178: cat - cat || Loss: 0.4509927034378052\n",
      "tensor([1., 0.]) tensor([0.8623, 0.1377], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 31 - 179: cat - cat || Loss: 0.45064374804496765\n",
      "tensor([1., 0.]) tensor([0.8626, 0.1374], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 31 - 180: cat - cat || Loss: 0.45029550790786743\n",
      "tensor([1., 0.]) tensor([0.8630, 0.1370], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 31 - 181: cat - cat || Loss: 0.44994813203811646\n",
      "tensor([1., 0.]) tensor([0.8633, 0.1367], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 31 - 182: cat - cat || Loss: 0.4496016502380371\n",
      "tensor([1., 0.]) tensor([0.8637, 0.1363], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 31 - 183: cat - cat || Loss: 0.4492560923099518\n",
      "tensor([1., 0.]) tensor([0.8640, 0.1360], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 31 - 184: cat - cat || Loss: 0.4489111602306366\n",
      "tensor([1., 0.]) tensor([0.8644, 0.1356], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 31 - 185: cat - cat || Loss: 0.44856715202331543\n",
      "tensor([1., 0.]) tensor([0.8647, 0.1353], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 31 - 186: cat - cat || Loss: 0.44822388887405396\n",
      "tensor([1., 0.]) tensor([0.8650, 0.1350], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 31 - 187: cat - cat || Loss: 0.44788143038749695\n",
      "tensor([1., 0.]) tensor([0.8654, 0.1346], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 31 - 188: cat - cat || Loss: 0.4475398063659668\n",
      "tensor([1., 0.]) tensor([0.8657, 0.1343], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 31 - 189: cat - cat || Loss: 0.4471989870071411\n",
      "tensor([1., 0.]) tensor([0.8661, 0.1339], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 31 - 190: dog - cat || Loss: 1.1796643733978271\n",
      "tensor([0., 1.]) tensor([0.8664, 0.1336], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 31 - 191: dog - cat || Loss: 1.1799365282058716\n",
      "tensor([0., 1.]) tensor([0.8667, 0.1333], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 31 - 192: dog - cat || Loss: 1.1801475286483765\n",
      "tensor([0., 1.]) tensor([0.8669, 0.1331], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 31 - 193: dog - cat || Loss: 1.1803040504455566\n",
      "tensor([0., 1.]) tensor([0.8670, 0.1330], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 31 - 194: dog - cat || Loss: 1.1804111003875732\n",
      "tensor([0., 1.]) tensor([0.8671, 0.1329], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 31 - 195: dog - cat || Loss: 1.1804744005203247\n",
      "tensor([0., 1.]) tensor([0.8672, 0.1328], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 31 - 196: dog - cat || Loss: 1.1804977655410767\n",
      "tensor([0., 1.]) tensor([0.8672, 0.1328], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 31 - 197: dog - cat || Loss: 1.1804852485656738\n",
      "tensor([0., 1.]) tensor([0.8672, 0.1328], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 31 - 198: dog - cat || Loss: 1.1804407835006714\n",
      "tensor([0., 1.]) tensor([0.8672, 0.1328], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 31 - 199: dog - cat || Loss: 1.180367350578308\n",
      "tensor([0., 1.]) tensor([0.8671, 0.1329], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 31 - 200: dog - cat || Loss: 1.1802676916122437\n",
      "tensor([0., 1.]) tensor([0.8670, 0.1330], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 31 - 201: dog - cat || Loss: 1.1801444292068481\n",
      "tensor([0., 1.]) tensor([0.8669, 0.1331], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 31 - 202: dog - cat || Loss: 1.1800000667572021\n",
      "tensor([0., 1.]) tensor([0.8667, 0.1333], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 31 - 203: dog - cat || Loss: 1.179836630821228\n",
      "tensor([0., 1.]) tensor([0.8666, 0.1334], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 31 - 204: dog - cat || Loss: 1.179655909538269\n",
      "tensor([0., 1.]) tensor([0.8664, 0.1336], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 31 - 205: dog - cat || Loss: 1.1794594526290894\n",
      "tensor([0., 1.]) tensor([0.8662, 0.1338], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 31 - 206: dog - cat || Loss: 1.1792488098144531\n",
      "tensor([0., 1.]) tensor([0.8660, 0.1340], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 31 - 207: dog - cat || Loss: 1.1790255308151245\n",
      "tensor([0., 1.]) tensor([0.8658, 0.1342], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 31 - 208: dog - cat || Loss: 1.17879056930542\n",
      "tensor([0., 1.]) tensor([0.8655, 0.1345], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 31 - 209: dog - cat || Loss: 1.1785452365875244\n",
      "tensor([0., 1.]) tensor([0.8653, 0.1347], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 31 - 210: dog - cat || Loss: 1.1782902479171753\n",
      "tensor([0., 1.]) tensor([0.8650, 0.1350], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 31 - 211: dog - cat || Loss: 1.1780269145965576\n",
      "tensor([0., 1.]) tensor([0.8648, 0.1352], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 31 - 212: dog - cat || Loss: 1.17775559425354\n",
      "tensor([0., 1.]) tensor([0.8645, 0.1355], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 31 - 213: dog - cat || Loss: 1.1774771213531494\n",
      "tensor([0., 1.]) tensor([0.8642, 0.1358], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 31 - 214: dog - cat || Loss: 1.1771920919418335\n",
      "tensor([0., 1.]) tensor([0.8639, 0.1361], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 31 - 215: dog - cat || Loss: 1.17690110206604\n",
      "tensor([0., 1.]) tensor([0.8636, 0.1364], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 31 - 216: dog - cat || Loss: 1.1766048669815063\n",
      "tensor([0., 1.]) tensor([0.8633, 0.1367], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 31 - 217: dog - cat || Loss: 1.176303505897522\n",
      "tensor([0., 1.]) tensor([0.8630, 0.1370], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 31 - 218: dog - cat || Loss: 1.1759978532791138\n",
      "tensor([0., 1.]) tensor([0.8627, 0.1373], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 31 - 219: dog - cat || Loss: 1.1756879091262817\n",
      "tensor([0., 1.]) tensor([0.8624, 0.1376], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 31 - 220: dog - cat || Loss: 1.1753740310668945\n",
      "tensor([0., 1.]) tensor([0.8621, 0.1379], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 31 - 221: dog - cat || Loss: 1.1750569343566895\n",
      "tensor([0., 1.]) tensor([0.8618, 0.1382], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 31 - 222: dog - cat || Loss: 1.1747363805770874\n",
      "tensor([0., 1.]) tensor([0.8615, 0.1385], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 31 - 223: dog - cat || Loss: 1.174412727355957\n",
      "tensor([0., 1.]) tensor([0.8612, 0.1388], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 31 - 224: dog - cat || Loss: 1.1740864515304565\n",
      "tensor([0., 1.]) tensor([0.8608, 0.1392], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 31 - 225: dog - cat || Loss: 1.173757791519165\n",
      "tensor([0., 1.]) tensor([0.8605, 0.1395], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 31 - 226: dog - cat || Loss: 1.1734263896942139\n",
      "tensor([0., 1.]) tensor([0.8602, 0.1398], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 31 - 227: dog - cat || Loss: 1.1730928421020508\n",
      "tensor([0., 1.]) tensor([0.8598, 0.1402], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 31 - 228: dog - cat || Loss: 1.1727572679519653\n",
      "tensor([0., 1.]) tensor([0.8595, 0.1405], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 31 - 229: dog - cat || Loss: 1.172419786453247\n",
      "tensor([0., 1.]) tensor([0.8592, 0.1408], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 31 - 230: dog - cat || Loss: 1.1720802783966064\n",
      "tensor([0., 1.]) tensor([0.8588, 0.1412], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 31 - 231: dog - cat || Loss: 1.1717392206192017\n",
      "tensor([0., 1.]) tensor([0.8585, 0.1415], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 31 - 232: dog - cat || Loss: 1.1713963747024536\n",
      "tensor([0., 1.]) tensor([0.8581, 0.1419], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 31 - 233: dog - cat || Loss: 1.1710519790649414\n",
      "tensor([0., 1.]) tensor([0.8578, 0.1422], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 31 - 234: dog - cat || Loss: 1.1707062721252441\n",
      "tensor([0., 1.]) tensor([0.8574, 0.1426], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 31 - 235: dog - cat || Loss: 1.1703591346740723\n",
      "tensor([0., 1.]) tensor([0.8571, 0.1429], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 31 - 236: dog - cat || Loss: 1.1700104475021362\n",
      "tensor([0., 1.]) tensor([0.8567, 0.1433], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 31 - 237: dog - cat || Loss: 1.1696604490280151\n",
      "tensor([0., 1.]) tensor([0.8564, 0.1436], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 31 - 238: dog - cat || Loss: 1.1693092584609985\n",
      "tensor([0., 1.]) tensor([0.8560, 0.1440], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 31 - 239: dog - cat || Loss: 1.1689568758010864\n",
      "tensor([0., 1.]) tensor([0.8557, 0.1443], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 31 - 240: dog - cat || Loss: 1.1686033010482788\n",
      "tensor([0., 1.]) tensor([0.8553, 0.1447], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 31 - 241: dog - cat || Loss: 1.1682486534118652\n",
      "tensor([0., 1.]) tensor([0.8550, 0.1450], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 31 - 242: dog - cat || Loss: 1.1678928136825562\n",
      "tensor([0., 1.]) tensor([0.8546, 0.1454], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 31 - 243: dog - cat || Loss: 1.1675359010696411\n",
      "tensor([0., 1.]) tensor([0.8543, 0.1457], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 31 - 244: dog - cat || Loss: 1.1671781539916992\n",
      "tensor([0., 1.]) tensor([0.8539, 0.1461], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 31 - 245: dog - cat || Loss: 1.1668190956115723\n",
      "tensor([0., 1.]) tensor([0.8536, 0.1464], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 31 - 246: dog - cat || Loss: 1.166459321975708\n",
      "tensor([0., 1.]) tensor([0.8532, 0.1468], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 31 - 247: dog - cat || Loss: 1.1660983562469482\n",
      "tensor([0., 1.]) tensor([0.8528, 0.1472], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 31 - 248: dog - cat || Loss: 1.1657365560531616\n",
      "tensor([0., 1.]) tensor([0.8525, 0.1475], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 31 - 249: dog - cat || Loss: 1.165373682975769\n",
      "tensor([0., 1.]) tensor([0.8521, 0.1479], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 31 - 250: dog - cat || Loss: 1.16500985622406\n",
      "tensor([0., 1.]) tensor([0.8517, 0.1483], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 31 - 251: dog - cat || Loss: 1.1646453142166138\n",
      "tensor([0., 1.]) tensor([0.8514, 0.1486], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 31 - 252: dog - cat || Loss: 1.164279580116272\n",
      "tensor([0., 1.]) tensor([0.8510, 0.1490], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 31 - 253: dog - cat || Loss: 1.1639130115509033\n",
      "tensor([0., 1.]) tensor([0.8507, 0.1493], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 31 - 254: dog - cat || Loss: 1.1635454893112183\n",
      "tensor([0., 1.]) tensor([0.8503, 0.1497], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 31 - 255: dog - cat || Loss: 1.163177251815796\n",
      "tensor([0., 1.]) tensor([0.8499, 0.1501], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 31 - 256: dog - cat || Loss: 1.1628079414367676\n",
      "tensor([0., 1.]) tensor([0.8495, 0.1505], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 31 - 257: dog - cat || Loss: 1.1624380350112915\n",
      "tensor([0., 1.]) tensor([0.8492, 0.1508], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 31 - 258: dog - cat || Loss: 1.1620670557022095\n",
      "tensor([0., 1.]) tensor([0.8488, 0.1512], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 31 - 259: dog - cat || Loss: 1.1616952419281006\n",
      "tensor([0., 1.]) tensor([0.8484, 0.1516], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 31 - 260: dog - cat || Loss: 1.1613225936889648\n",
      "tensor([0., 1.]) tensor([0.8481, 0.1519], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 31 - 261: dog - cat || Loss: 1.1609489917755127\n",
      "tensor([0., 1.]) tensor([0.8477, 0.1523], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 31 - 262: dog - cat || Loss: 1.1605746746063232\n",
      "tensor([0., 1.]) tensor([0.8473, 0.1527], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 31 - 263: dog - cat || Loss: 1.1601994037628174\n",
      "tensor([0., 1.]) tensor([0.8469, 0.1531], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 31 - 264: dog - cat || Loss: 1.1598232984542847\n",
      "tensor([0., 1.]) tensor([0.8466, 0.1534], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 31 - 265: dog - cat || Loss: 1.1594462394714355\n",
      "tensor([0., 1.]) tensor([0.8462, 0.1538], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 31 - 266: dog - cat || Loss: 1.1590684652328491\n",
      "tensor([0., 1.]) tensor([0.8458, 0.1542], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 31 - 267: dog - cat || Loss: 1.1586897373199463\n",
      "tensor([0., 1.]) tensor([0.8454, 0.1546], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 31 - 268: dog - cat || Loss: 1.1583102941513062\n",
      "tensor([0., 1.]) tensor([0.8450, 0.1550], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 31 - 269: dog - cat || Loss: 1.1579298973083496\n",
      "tensor([0., 1.]) tensor([0.8447, 0.1553], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 31 - 270: dog - cat || Loss: 1.1575486660003662\n",
      "tensor([0., 1.]) tensor([0.8443, 0.1557], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 31 - 271: dog - cat || Loss: 1.157166600227356\n",
      "tensor([0., 1.]) tensor([0.8439, 0.1561], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 31 - 272: dog - cat || Loss: 1.1567836999893188\n",
      "tensor([0., 1.]) tensor([0.8435, 0.1565], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 31 - 273: dog - cat || Loss: 1.1563999652862549\n",
      "tensor([0., 1.]) tensor([0.8431, 0.1569], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 31 - 274: dog - cat || Loss: 1.1560152769088745\n",
      "tensor([0., 1.]) tensor([0.8428, 0.1572], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 31 - 275: dog - cat || Loss: 1.1556298732757568\n",
      "tensor([0., 1.]) tensor([0.8424, 0.1576], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 31 - 276: dog - cat || Loss: 1.1552436351776123\n",
      "tensor([0., 1.]) tensor([0.8420, 0.1580], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 31 - 277: dog - cat || Loss: 1.1548564434051514\n",
      "tensor([0., 1.]) tensor([0.8416, 0.1584], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 31 - 278: dog - cat || Loss: 1.1544685363769531\n",
      "tensor([0., 1.]) tensor([0.8412, 0.1588], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 31 - 279: dog - cat || Loss: 1.1540796756744385\n",
      "tensor([0., 1.]) tensor([0.8408, 0.1592], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 31 - 280: dog - cat || Loss: 1.153689980506897\n",
      "tensor([0., 1.]) tensor([0.8404, 0.1596], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 31 - 281: dog - cat || Loss: 1.153299331665039\n",
      "tensor([0., 1.]) tensor([0.8400, 0.1600], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 31 - 282: dog - cat || Loss: 1.1529080867767334\n",
      "tensor([0., 1.]) tensor([0.8396, 0.1604], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 31 - 283: dog - cat || Loss: 1.1525158882141113\n",
      "tensor([0., 1.]) tensor([0.8393, 0.1607], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 31 - 284: dog - cat || Loss: 1.1521227359771729\n",
      "tensor([0., 1.]) tensor([0.8389, 0.1611], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 31 - 285: dog - cat || Loss: 1.151728868484497\n",
      "tensor([0., 1.]) tensor([0.8385, 0.1615], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 31 - 286: dog - cat || Loss: 1.1513341665267944\n",
      "tensor([0., 1.]) tensor([0.8381, 0.1619], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 31 - 287: dog - cat || Loss: 1.1509385108947754\n",
      "tensor([0., 1.]) tensor([0.8377, 0.1623], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 31 - 288: dog - cat || Loss: 1.150542140007019\n",
      "tensor([0., 1.]) tensor([0.8373, 0.1627], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 31 - 289: dog - cat || Loss: 1.1501448154449463\n",
      "tensor([0., 1.]) tensor([0.8369, 0.1631], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 31 - 290: dog - cat || Loss: 1.1497466564178467\n",
      "tensor([0., 1.]) tensor([0.8365, 0.1635], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 31 - 291: dog - cat || Loss: 1.1493477821350098\n",
      "tensor([0., 1.]) tensor([0.8361, 0.1639], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 31 - 292: dog - cat || Loss: 1.148947834968567\n",
      "tensor([0., 1.]) tensor([0.8357, 0.1643], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 31 - 293: dog - cat || Loss: 1.1485471725463867\n",
      "tensor([0., 1.]) tensor([0.8353, 0.1647], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 31 - 294: dog - cat || Loss: 1.1481455564498901\n",
      "tensor([0., 1.]) tensor([0.8349, 0.1651], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 31 - 295: dog - cat || Loss: 1.1477432250976562\n",
      "tensor([0., 1.]) tensor([0.8345, 0.1655], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 31 - 296: dog - cat || Loss: 1.1473400592803955\n",
      "tensor([0., 1.]) tensor([0.8341, 0.1659], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 31 - 297: dog - cat || Loss: 1.1469359397888184\n",
      "tensor([0., 1.]) tensor([0.8337, 0.1663], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 31 - 298: dog - cat || Loss: 1.146531105041504\n",
      "tensor([0., 1.]) tensor([0.8333, 0.1667], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 31 - 299: dog - cat || Loss: 1.146125316619873\n",
      "tensor([0., 1.]) tensor([0.8329, 0.1671], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 31 - 300: dog - cat || Loss: 1.1457185745239258\n",
      "tensor([0., 1.]) tensor([0.8325, 0.1675], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 31 - 301: dog - cat || Loss: 1.1453109979629517\n",
      "tensor([0., 1.]) tensor([0.8320, 0.1680], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 31 - 302: dog - cat || Loss: 1.1449027061462402\n",
      "tensor([0., 1.]) tensor([0.8316, 0.1684], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 31 - 303: dog - cat || Loss: 1.144493579864502\n",
      "tensor([0., 1.]) tensor([0.8312, 0.1688], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 31 - 304: dog - cat || Loss: 1.1440834999084473\n",
      "tensor([0., 1.]) tensor([0.8308, 0.1692], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 31 - 305: dog - cat || Loss: 1.1436724662780762\n",
      "tensor([0., 1.]) tensor([0.8304, 0.1696], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 31 - 306: dog - cat || Loss: 1.1432607173919678\n",
      "tensor([0., 1.]) tensor([0.8300, 0.1700], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 31 - 307: dog - cat || Loss: 1.1428481340408325\n",
      "tensor([0., 1.]) tensor([0.8296, 0.1704], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 31 - 308: dog - cat || Loss: 1.1424345970153809\n",
      "tensor([0., 1.]) tensor([0.8292, 0.1708], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 31 - 309: dog - cat || Loss: 1.142020344734192\n",
      "tensor([0., 1.]) tensor([0.8288, 0.1712], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 31 - 310: dog - cat || Loss: 1.141605019569397\n",
      "tensor([0., 1.]) tensor([0.8283, 0.1717], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 31 - 311: dog - cat || Loss: 1.1411890983581543\n",
      "tensor([0., 1.]) tensor([0.8279, 0.1721], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 31 - 312: dog - cat || Loss: 1.1407721042633057\n",
      "tensor([0., 1.]) tensor([0.8275, 0.1725], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 31 - 313: dog - cat || Loss: 1.1403542757034302\n",
      "tensor([0., 1.]) tensor([0.8271, 0.1729], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 31 - 314: dog - cat || Loss: 1.1399356126785278\n",
      "tensor([0., 1.]) tensor([0.8267, 0.1733], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 31 - 315: dog - cat || Loss: 1.1395162343978882\n",
      "tensor([0., 1.]) tensor([0.8263, 0.1737], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 31 - 316: dog - cat || Loss: 1.139095664024353\n",
      "tensor([0., 1.]) tensor([0.8258, 0.1742], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 31 - 317: dog - cat || Loss: 1.1386744976043701\n",
      "tensor([0., 1.]) tensor([0.8254, 0.1746], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 31 - 318: dog - cat || Loss: 1.1382524967193604\n",
      "tensor([0., 1.]) tensor([0.8250, 0.1750], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 31 - 319: dog - cat || Loss: 1.1378294229507446\n",
      "tensor([0., 1.]) tensor([0.8246, 0.1754], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 31 - 320: dog - cat || Loss: 1.1374057531356812\n",
      "tensor([0., 1.]) tensor([0.8241, 0.1759], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 31 - 321: dog - cat || Loss: 1.1369808912277222\n",
      "tensor([0., 1.]) tensor([0.8237, 0.1763], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 31 - 322: dog - cat || Loss: 1.1365553140640259\n",
      "tensor([0., 1.]) tensor([0.8233, 0.1767], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 31 - 323: dog - cat || Loss: 1.1361287832260132\n",
      "tensor([0., 1.]) tensor([0.8229, 0.1771], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 31 - 324: dog - cat || Loss: 1.1357015371322632\n",
      "tensor([0., 1.]) tensor([0.8224, 0.1776], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 31 - 325: dog - cat || Loss: 1.1352734565734863\n",
      "tensor([0., 1.]) tensor([0.8220, 0.1780], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 31 - 326: dog - cat || Loss: 1.1348443031311035\n",
      "tensor([0., 1.]) tensor([0.8216, 0.1784], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 31 - 327: dog - cat || Loss: 1.1344144344329834\n",
      "tensor([0., 1.]) tensor([0.8212, 0.1788], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 31 - 328: dog - cat || Loss: 1.1339834928512573\n",
      "tensor([0., 1.]) tensor([0.8207, 0.1793], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 31 - 329: dog - cat || Loss: 1.1335519552230835\n",
      "tensor([0., 1.]) tensor([0.8203, 0.1797], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 31 - 330: dog - cat || Loss: 1.1331193447113037\n",
      "tensor([0., 1.]) tensor([0.8199, 0.1801], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 31 - 331: dog - cat || Loss: 1.1326857805252075\n",
      "tensor([0., 1.]) tensor([0.8194, 0.1806], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 31 - 332: dog - cat || Loss: 1.1322516202926636\n",
      "tensor([0., 1.]) tensor([0.8190, 0.1810], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 31 - 333: dog - cat || Loss: 1.1318163871765137\n",
      "tensor([0., 1.]) tensor([0.8186, 0.1814], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 31 - 334: dog - cat || Loss: 1.131380319595337\n",
      "tensor([0., 1.]) tensor([0.8181, 0.1819], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 31 - 335: dog - cat || Loss: 1.1309434175491333\n",
      "tensor([0., 1.]) tensor([0.8177, 0.1823], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 31 - 336: dog - cat || Loss: 1.1305056810379028\n",
      "tensor([0., 1.]) tensor([0.8172, 0.1828], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 31 - 337: dog - cat || Loss: 1.130066990852356\n",
      "tensor([0., 1.]) tensor([0.8168, 0.1832], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 31 - 338: dog - cat || Loss: 1.1296274662017822\n",
      "tensor([0., 1.]) tensor([0.8164, 0.1836], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 31 - 339: dog - cat || Loss: 1.129186987876892\n",
      "tensor([0., 1.]) tensor([0.8159, 0.1841], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 31 - 340: dog - cat || Loss: 1.128745675086975\n",
      "tensor([0., 1.]) tensor([0.8155, 0.1845], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 31 - 341: dog - cat || Loss: 1.1283036470413208\n",
      "tensor([0., 1.]) tensor([0.8150, 0.1850], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 31 - 342: dog - cat || Loss: 1.1278605461120605\n",
      "tensor([0., 1.]) tensor([0.8146, 0.1854], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 31 - 343: dog - cat || Loss: 1.127416729927063\n",
      "tensor([0., 1.]) tensor([0.8142, 0.1858], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 31 - 344: dog - cat || Loss: 1.1269720792770386\n",
      "tensor([0., 1.]) tensor([0.8137, 0.1863], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 31 - 345: dog - cat || Loss: 1.1265262365341187\n",
      "tensor([0., 1.]) tensor([0.8133, 0.1867], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 31 - 346: dog - cat || Loss: 1.1260796785354614\n",
      "tensor([0., 1.]) tensor([0.8128, 0.1872], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 31 - 347: dog - cat || Loss: 1.1256322860717773\n",
      "tensor([0., 1.]) tensor([0.8124, 0.1876], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 31 - 348: dog - cat || Loss: 1.1251838207244873\n",
      "tensor([0., 1.]) tensor([0.8119, 0.1881], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 31 - 349: dog - cat || Loss: 1.1247347593307495\n",
      "tensor([0., 1.]) tensor([0.8115, 0.1885], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 31 - 350: dog - cat || Loss: 1.1242845058441162\n",
      "tensor([0., 1.]) tensor([0.8110, 0.1890], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 31 - 351: dog - cat || Loss: 1.1238336563110352\n",
      "tensor([0., 1.]) tensor([0.8106, 0.1894], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 31 - 352: dog - cat || Loss: 1.1233818531036377\n",
      "tensor([0., 1.]) tensor([0.8101, 0.1899], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 31 - 353: dog - cat || Loss: 1.1229289770126343\n",
      "tensor([0., 1.]) tensor([0.8097, 0.1903], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 31 - 354: dog - cat || Loss: 1.1224753856658936\n",
      "tensor([0., 1.]) tensor([0.8092, 0.1908], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 31 - 355: dog - cat || Loss: 1.122020959854126\n",
      "tensor([0., 1.]) tensor([0.8088, 0.1912], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 31 - 356: dog - cat || Loss: 1.121565580368042\n",
      "tensor([0., 1.]) tensor([0.8083, 0.1917], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 31 - 357: dog - cat || Loss: 1.1211092472076416\n",
      "tensor([0., 1.]) tensor([0.8078, 0.1922], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 31 - 358: dog - cat || Loss: 1.120652198791504\n",
      "tensor([0., 1.]) tensor([0.8074, 0.1926], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 31 - 359: dog - cat || Loss: 1.1201939582824707\n",
      "tensor([0., 1.]) tensor([0.8069, 0.1931], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 31 - 360: dog - cat || Loss: 1.1197348833084106\n",
      "tensor([0., 1.]) tensor([0.8065, 0.1935], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 31 - 361: dog - cat || Loss: 1.1192750930786133\n",
      "tensor([0., 1.]) tensor([0.8060, 0.1940], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 31 - 362: dog - cat || Loss: 1.1188143491744995\n",
      "tensor([0., 1.]) tensor([0.8056, 0.1944], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 31 - 363: dog - cat || Loss: 1.1183526515960693\n",
      "tensor([0., 1.]) tensor([0.8051, 0.1949], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 31 - 364: dog - cat || Loss: 1.1178900003433228\n",
      "tensor([0., 1.]) tensor([0.8046, 0.1954], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 31 - 365: dog - cat || Loss: 1.1174267530441284\n",
      "tensor([0., 1.]) tensor([0.8042, 0.1958], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 31 - 366: dog - cat || Loss: 1.1169623136520386\n",
      "tensor([0., 1.]) tensor([0.8037, 0.1963], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 31 - 367: dog - cat || Loss: 1.1164971590042114\n",
      "tensor([0., 1.]) tensor([0.8032, 0.1968], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 31 - 368: dog - cat || Loss: 1.1160309314727783\n",
      "tensor([0., 1.]) tensor([0.8028, 0.1972], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 31 - 369: dog - cat || Loss: 1.1155638694763184\n",
      "tensor([0., 1.]) tensor([0.8023, 0.1977], grad_fn=<SoftmaxBackward0>)\n",
      "=====epoch:32=====\n",
      "Epoch 32 - 0: cat - cat || Loss: 0.5114274024963379\n",
      "tensor([1., 0.]) tensor([0.8018, 0.1982], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 32 - 1: cat - cat || Loss: 0.511801540851593\n",
      "tensor([1., 0.]) tensor([0.8015, 0.1985], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 32 - 2: cat - cat || Loss: 0.5120912790298462\n",
      "tensor([1., 0.]) tensor([0.8012, 0.1988], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 32 - 3: cat - cat || Loss: 0.5123046636581421\n",
      "tensor([1., 0.]) tensor([0.8010, 0.1990], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 32 - 4: cat - cat || Loss: 0.5124493837356567\n",
      "tensor([1., 0.]) tensor([0.8008, 0.1992], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 32 - 5: cat - cat || Loss: 0.512532114982605\n",
      "tensor([1., 0.]) tensor([0.8007, 0.1993], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 32 - 6: cat - cat || Loss: 0.5125591158866882\n",
      "tensor([1., 0.]) tensor([0.8007, 0.1993], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 32 - 7: cat - cat || Loss: 0.5125359296798706\n",
      "tensor([1., 0.]) tensor([0.8007, 0.1993], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 32 - 8: cat - cat || Loss: 0.512467622756958\n",
      "tensor([1., 0.]) tensor([0.8008, 0.1992], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 32 - 9: cat - cat || Loss: 0.5123586654663086\n",
      "tensor([1., 0.]) tensor([0.8009, 0.1991], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 32 - 10: cat - cat || Loss: 0.5122131109237671\n",
      "tensor([1., 0.]) tensor([0.8010, 0.1990], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 32 - 11: cat - cat || Loss: 0.5120348930358887\n",
      "tensor([1., 0.]) tensor([0.8012, 0.1988], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 32 - 12: cat - cat || Loss: 0.5118271112442017\n",
      "tensor([1., 0.]) tensor([0.8014, 0.1986], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 32 - 13: cat - cat || Loss: 0.5115928649902344\n",
      "tensor([1., 0.]) tensor([0.8017, 0.1983], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 32 - 14: cat - cat || Loss: 0.5113349556922913\n",
      "tensor([1., 0.]) tensor([0.8019, 0.1981], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 32 - 15: cat - cat || Loss: 0.5110557079315186\n",
      "tensor([1., 0.]) tensor([0.8022, 0.1978], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 32 - 16: cat - cat || Loss: 0.5107572674751282\n",
      "tensor([1., 0.]) tensor([0.8025, 0.1975], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 32 - 17: cat - cat || Loss: 0.510441780090332\n",
      "tensor([1., 0.]) tensor([0.8028, 0.1972], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 32 - 18: cat - cat || Loss: 0.5101110339164734\n",
      "tensor([1., 0.]) tensor([0.8032, 0.1968], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 32 - 19: cat - cat || Loss: 0.5097665786743164\n",
      "tensor([1., 0.]) tensor([0.8035, 0.1965], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 32 - 20: cat - cat || Loss: 0.5094097852706909\n",
      "tensor([1., 0.]) tensor([0.8039, 0.1961], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 32 - 21: cat - cat || Loss: 0.5090421438217163\n",
      "tensor([1., 0.]) tensor([0.8042, 0.1958], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 32 - 22: cat - cat || Loss: 0.5086647272109985\n",
      "tensor([1., 0.]) tensor([0.8046, 0.1954], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 32 - 23: cat - cat || Loss: 0.5082786679267883\n",
      "tensor([1., 0.]) tensor([0.8050, 0.1950], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 32 - 24: cat - cat || Loss: 0.5078848600387573\n",
      "tensor([1., 0.]) tensor([0.8054, 0.1946], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 32 - 25: cat - cat || Loss: 0.5074841976165771\n",
      "tensor([1., 0.]) tensor([0.8058, 0.1942], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 32 - 26: cat - cat || Loss: 0.5070775151252747\n",
      "tensor([1., 0.]) tensor([0.8062, 0.1938], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 32 - 27: cat - cat || Loss: 0.5066654682159424\n",
      "tensor([1., 0.]) tensor([0.8066, 0.1934], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 32 - 28: cat - cat || Loss: 0.5062486529350281\n",
      "tensor([1., 0.]) tensor([0.8070, 0.1930], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 32 - 29: cat - cat || Loss: 0.5058274269104004\n",
      "tensor([1., 0.]) tensor([0.8074, 0.1926], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 32 - 30: cat - cat || Loss: 0.5054028034210205\n",
      "tensor([1., 0.]) tensor([0.8079, 0.1921], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 32 - 31: cat - cat || Loss: 0.5049747824668884\n",
      "tensor([1., 0.]) tensor([0.8083, 0.1917], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 32 - 32: cat - cat || Loss: 0.5045440196990967\n",
      "tensor([1., 0.]) tensor([0.8087, 0.1913], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 32 - 33: cat - cat || Loss: 0.5041108727455139\n",
      "tensor([1., 0.]) tensor([0.8092, 0.1908], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 32 - 34: cat - cat || Loss: 0.5036755800247192\n",
      "tensor([1., 0.]) tensor([0.8096, 0.1904], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 32 - 35: cat - cat || Loss: 0.5032384991645813\n",
      "tensor([1., 0.]) tensor([0.8100, 0.1900], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 32 - 36: cat - cat || Loss: 0.5027998685836792\n",
      "tensor([1., 0.]) tensor([0.8105, 0.1895], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 32 - 37: cat - cat || Loss: 0.5023599863052368\n",
      "tensor([1., 0.]) tensor([0.8109, 0.1891], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 32 - 38: cat - cat || Loss: 0.5019189119338989\n",
      "tensor([1., 0.]) tensor([0.8113, 0.1887], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 32 - 39: cat - cat || Loss: 0.501477062702179\n",
      "tensor([1., 0.]) tensor([0.8118, 0.1882], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 32 - 40: cat - cat || Loss: 0.501034677028656\n",
      "tensor([1., 0.]) tensor([0.8122, 0.1878], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 32 - 41: cat - cat || Loss: 0.500591516494751\n",
      "tensor([1., 0.]) tensor([0.8127, 0.1873], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 32 - 42: cat - cat || Loss: 0.5001481771469116\n",
      "tensor([1., 0.]) tensor([0.8131, 0.1869], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 32 - 43: cat - cat || Loss: 0.49970436096191406\n",
      "tensor([1., 0.]) tensor([0.8136, 0.1864], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 32 - 44: cat - cat || Loss: 0.4992606043815613\n",
      "tensor([1., 0.]) tensor([0.8140, 0.1860], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 32 - 45: cat - cat || Loss: 0.49881672859191895\n",
      "tensor([1., 0.]) tensor([0.8144, 0.1856], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 32 - 46: cat - cat || Loss: 0.4983729422092438\n",
      "tensor([1., 0.]) tensor([0.8149, 0.1851], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 32 - 47: cat - cat || Loss: 0.49792930483818054\n",
      "tensor([1., 0.]) tensor([0.8153, 0.1847], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 32 - 48: cat - cat || Loss: 0.497485876083374\n",
      "tensor([1., 0.]) tensor([0.8158, 0.1842], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 32 - 49: cat - cat || Loss: 0.4970426559448242\n",
      "tensor([1., 0.]) tensor([0.8162, 0.1838], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 32 - 50: cat - cat || Loss: 0.49659988284111023\n",
      "tensor([1., 0.]) tensor([0.8167, 0.1833], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 32 - 51: cat - cat || Loss: 0.49615752696990967\n",
      "tensor([1., 0.]) tensor([0.8171, 0.1829], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 32 - 52: cat - cat || Loss: 0.49571558833122253\n",
      "tensor([1., 0.]) tensor([0.8175, 0.1825], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 32 - 53: cat - cat || Loss: 0.49527424573898315\n",
      "tensor([1., 0.]) tensor([0.8180, 0.1820], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 32 - 54: cat - cat || Loss: 0.4948332905769348\n",
      "tensor([1., 0.]) tensor([0.8184, 0.1816], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 32 - 55: cat - cat || Loss: 0.494392991065979\n",
      "tensor([1., 0.]) tensor([0.8189, 0.1811], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 32 - 56: cat - cat || Loss: 0.49395325779914856\n",
      "tensor([1., 0.]) tensor([0.8193, 0.1807], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 32 - 57: cat - cat || Loss: 0.49351418018341064\n",
      "tensor([1., 0.]) tensor([0.8197, 0.1803], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 32 - 58: cat - cat || Loss: 0.49307581782341003\n",
      "tensor([1., 0.]) tensor([0.8202, 0.1798], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 32 - 59: cat - cat || Loss: 0.49263817071914673\n",
      "tensor([1., 0.]) tensor([0.8206, 0.1794], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 32 - 60: cat - cat || Loss: 0.49220120906829834\n",
      "tensor([1., 0.]) tensor([0.8211, 0.1789], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 32 - 61: cat - cat || Loss: 0.4917649030685425\n",
      "tensor([1., 0.]) tensor([0.8215, 0.1785], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 32 - 62: cat - cat || Loss: 0.49132949113845825\n",
      "tensor([1., 0.]) tensor([0.8219, 0.1781], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 32 - 63: cat - cat || Loss: 0.4908948242664337\n",
      "tensor([1., 0.]) tensor([0.8224, 0.1776], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 32 - 64: cat - cat || Loss: 0.4904608726501465\n",
      "tensor([1., 0.]) tensor([0.8228, 0.1772], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 32 - 65: cat - cat || Loss: 0.49002766609191895\n",
      "tensor([1., 0.]) tensor([0.8232, 0.1768], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 32 - 66: cat - cat || Loss: 0.48959532380104065\n",
      "tensor([1., 0.]) tensor([0.8237, 0.1763], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 32 - 67: cat - cat || Loss: 0.48916390538215637\n",
      "tensor([1., 0.]) tensor([0.8241, 0.1759], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 32 - 68: cat - cat || Loss: 0.4887331426143646\n",
      "tensor([1., 0.]) tensor([0.8245, 0.1755], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 32 - 69: cat - cat || Loss: 0.4883032441139221\n",
      "tensor([1., 0.]) tensor([0.8250, 0.1750], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 32 - 70: cat - cat || Loss: 0.48787420988082886\n",
      "tensor([1., 0.]) tensor([0.8254, 0.1746], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 32 - 71: cat - cat || Loss: 0.48744603991508484\n",
      "tensor([1., 0.]) tensor([0.8258, 0.1742], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 32 - 72: cat - cat || Loss: 0.4870186150074005\n",
      "tensor([1., 0.]) tensor([0.8262, 0.1738], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 32 - 73: cat - cat || Loss: 0.4865921139717102\n",
      "tensor([1., 0.]) tensor([0.8267, 0.1733], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 32 - 74: cat - cat || Loss: 0.486166387796402\n",
      "tensor([1., 0.]) tensor([0.8271, 0.1729], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 32 - 75: cat - cat || Loss: 0.48574167490005493\n",
      "tensor([1., 0.]) tensor([0.8275, 0.1725], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 32 - 76: cat - cat || Loss: 0.4853176772594452\n",
      "tensor([1., 0.]) tensor([0.8279, 0.1721], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 32 - 77: cat - cat || Loss: 0.48489469289779663\n",
      "tensor([1., 0.]) tensor([0.8284, 0.1716], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 32 - 78: cat - cat || Loss: 0.48447245359420776\n",
      "tensor([1., 0.]) tensor([0.8288, 0.1712], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 32 - 79: cat - cat || Loss: 0.4840511083602905\n",
      "tensor([1., 0.]) tensor([0.8292, 0.1708], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 32 - 80: cat - cat || Loss: 0.4836306571960449\n",
      "tensor([1., 0.]) tensor([0.8296, 0.1704], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 32 - 81: cat - cat || Loss: 0.4832109808921814\n",
      "tensor([1., 0.]) tensor([0.8301, 0.1699], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 32 - 82: cat - cat || Loss: 0.48279231786727905\n",
      "tensor([1., 0.]) tensor([0.8305, 0.1695], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 32 - 83: cat - cat || Loss: 0.48237448930740356\n",
      "tensor([1., 0.]) tensor([0.8309, 0.1691], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 32 - 84: cat - cat || Loss: 0.4819575548171997\n",
      "tensor([1., 0.]) tensor([0.8313, 0.1687], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 32 - 85: cat - cat || Loss: 0.4815415143966675\n",
      "tensor([1., 0.]) tensor([0.8317, 0.1683], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 32 - 86: cat - cat || Loss: 0.4811263084411621\n",
      "tensor([1., 0.]) tensor([0.8321, 0.1679], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 32 - 87: cat - cat || Loss: 0.48071199655532837\n",
      "tensor([1., 0.]) tensor([0.8325, 0.1675], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 32 - 88: cat - cat || Loss: 0.48029863834381104\n",
      "tensor([1., 0.]) tensor([0.8330, 0.1670], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 32 - 89: cat - cat || Loss: 0.4798860549926758\n",
      "tensor([1., 0.]) tensor([0.8334, 0.1666], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 32 - 90: cat - cat || Loss: 0.47947442531585693\n",
      "tensor([1., 0.]) tensor([0.8338, 0.1662], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 32 - 91: cat - cat || Loss: 0.47906363010406494\n",
      "tensor([1., 0.]) tensor([0.8342, 0.1658], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 32 - 92: cat - cat || Loss: 0.4786537289619446\n",
      "tensor([1., 0.]) tensor([0.8346, 0.1654], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 32 - 93: cat - cat || Loss: 0.47824472188949585\n",
      "tensor([1., 0.]) tensor([0.8350, 0.1650], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 32 - 94: cat - cat || Loss: 0.477836549282074\n",
      "tensor([1., 0.]) tensor([0.8354, 0.1646], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 32 - 95: cat - cat || Loss: 0.47742927074432373\n",
      "tensor([1., 0.]) tensor([0.8358, 0.1642], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 32 - 96: cat - cat || Loss: 0.4770229160785675\n",
      "tensor([1., 0.]) tensor([0.8362, 0.1638], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 32 - 97: cat - cat || Loss: 0.47661739587783813\n",
      "tensor([1., 0.]) tensor([0.8366, 0.1634], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 32 - 98: cat - cat || Loss: 0.4762127995491028\n",
      "tensor([1., 0.]) tensor([0.8370, 0.1630], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 32 - 99: cat - cat || Loss: 0.47580909729003906\n",
      "tensor([1., 0.]) tensor([0.8375, 0.1625], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 32 - 100: cat - cat || Loss: 0.4754061996936798\n",
      "tensor([1., 0.]) tensor([0.8379, 0.1621], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 32 - 101: cat - cat || Loss: 0.4750041961669922\n",
      "tensor([1., 0.]) tensor([0.8383, 0.1617], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 32 - 102: cat - cat || Loss: 0.47460317611694336\n",
      "tensor([1., 0.]) tensor([0.8387, 0.1613], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 32 - 103: cat - cat || Loss: 0.47420287132263184\n",
      "tensor([1., 0.]) tensor([0.8391, 0.1609], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 32 - 104: cat - cat || Loss: 0.4738035798072815\n",
      "tensor([1., 0.]) tensor([0.8395, 0.1605], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 32 - 105: cat - cat || Loss: 0.47340506315231323\n",
      "tensor([1., 0.]) tensor([0.8399, 0.1601], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 32 - 106: cat - cat || Loss: 0.4730075001716614\n",
      "tensor([1., 0.]) tensor([0.8403, 0.1597], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 32 - 107: cat - cat || Loss: 0.4726107120513916\n",
      "tensor([1., 0.]) tensor([0.8407, 0.1593], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 32 - 108: cat - cat || Loss: 0.47221487760543823\n",
      "tensor([1., 0.]) tensor([0.8410, 0.1590], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 32 - 109: cat - cat || Loss: 0.4718198776245117\n",
      "tensor([1., 0.]) tensor([0.8414, 0.1586], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 32 - 110: cat - cat || Loss: 0.47142571210861206\n",
      "tensor([1., 0.]) tensor([0.8418, 0.1582], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 32 - 111: cat - cat || Loss: 0.4710325598716736\n",
      "tensor([1., 0.]) tensor([0.8422, 0.1578], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 32 - 112: cat - cat || Loss: 0.4706401824951172\n",
      "tensor([1., 0.]) tensor([0.8426, 0.1574], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 32 - 113: cat - cat || Loss: 0.4702486991882324\n",
      "tensor([1., 0.]) tensor([0.8430, 0.1570], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 32 - 114: cat - cat || Loss: 0.4698581099510193\n",
      "tensor([1., 0.]) tensor([0.8434, 0.1566], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 32 - 115: cat - cat || Loss: 0.4694684147834778\n",
      "tensor([1., 0.]) tensor([0.8438, 0.1562], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 32 - 116: cat - cat || Loss: 0.4690794348716736\n",
      "tensor([1., 0.]) tensor([0.8442, 0.1558], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 32 - 117: cat - cat || Loss: 0.46869149804115295\n",
      "tensor([1., 0.]) tensor([0.8446, 0.1554], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 32 - 118: cat - cat || Loss: 0.4683043360710144\n",
      "tensor([1., 0.]) tensor([0.8450, 0.1550], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 32 - 119: cat - cat || Loss: 0.46791815757751465\n",
      "tensor([1., 0.]) tensor([0.8453, 0.1547], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 32 - 120: cat - cat || Loss: 0.46753278374671936\n",
      "tensor([1., 0.]) tensor([0.8457, 0.1543], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 32 - 121: cat - cat || Loss: 0.46714818477630615\n",
      "tensor([1., 0.]) tensor([0.8461, 0.1539], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 32 - 122: cat - cat || Loss: 0.46676453948020935\n",
      "tensor([1., 0.]) tensor([0.8465, 0.1535], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 32 - 123: cat - cat || Loss: 0.4663817882537842\n",
      "tensor([1., 0.]) tensor([0.8469, 0.1531], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 32 - 124: cat - cat || Loss: 0.46599987149238586\n",
      "tensor([1., 0.]) tensor([0.8473, 0.1527], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 32 - 125: cat - cat || Loss: 0.4656187891960144\n",
      "tensor([1., 0.]) tensor([0.8476, 0.1524], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 32 - 126: cat - cat || Loss: 0.4652385711669922\n",
      "tensor([1., 0.]) tensor([0.8480, 0.1520], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 32 - 127: cat - cat || Loss: 0.4648591876029968\n",
      "tensor([1., 0.]) tensor([0.8484, 0.1516], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 32 - 128: cat - cat || Loss: 0.46448075771331787\n",
      "tensor([1., 0.]) tensor([0.8488, 0.1512], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 32 - 129: cat - cat || Loss: 0.4641030430793762\n",
      "tensor([1., 0.]) tensor([0.8492, 0.1508], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 32 - 130: cat - cat || Loss: 0.4637264013290405\n",
      "tensor([1., 0.]) tensor([0.8495, 0.1505], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 32 - 131: cat - cat || Loss: 0.46335044503211975\n",
      "tensor([1., 0.]) tensor([0.8499, 0.1501], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 32 - 132: cat - cat || Loss: 0.46297532320022583\n",
      "tensor([1., 0.]) tensor([0.8503, 0.1497], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 32 - 133: cat - cat || Loss: 0.4626011252403259\n",
      "tensor([1., 0.]) tensor([0.8507, 0.1493], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 32 - 134: cat - cat || Loss: 0.4622277021408081\n",
      "tensor([1., 0.]) tensor([0.8510, 0.1490], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 32 - 135: cat - cat || Loss: 0.4618552625179291\n",
      "tensor([1., 0.]) tensor([0.8514, 0.1486], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 32 - 136: cat - cat || Loss: 0.46148359775543213\n",
      "tensor([1., 0.]) tensor([0.8518, 0.1482], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 32 - 137: cat - cat || Loss: 0.46111273765563965\n",
      "tensor([1., 0.]) tensor([0.8521, 0.1479], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 32 - 138: cat - cat || Loss: 0.4607428312301636\n",
      "tensor([1., 0.]) tensor([0.8525, 0.1475], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 32 - 139: cat - cat || Loss: 0.4603736996650696\n",
      "tensor([1., 0.]) tensor([0.8529, 0.1471], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 32 - 140: cat - cat || Loss: 0.4600054621696472\n",
      "tensor([1., 0.]) tensor([0.8533, 0.1467], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 32 - 141: cat - cat || Loss: 0.45963793992996216\n",
      "tensor([1., 0.]) tensor([0.8536, 0.1464], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 32 - 142: cat - cat || Loss: 0.4592713713645935\n",
      "tensor([1., 0.]) tensor([0.8540, 0.1460], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 32 - 143: cat - cat || Loss: 0.4589056372642517\n",
      "tensor([1., 0.]) tensor([0.8544, 0.1456], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 32 - 144: cat - cat || Loss: 0.45854073762893677\n",
      "tensor([1., 0.]) tensor([0.8547, 0.1453], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 32 - 145: cat - cat || Loss: 0.4581766426563263\n",
      "tensor([1., 0.]) tensor([0.8551, 0.1449], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 32 - 146: cat - cat || Loss: 0.45781344175338745\n",
      "tensor([1., 0.]) tensor([0.8554, 0.1446], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 32 - 147: cat - cat || Loss: 0.45745107531547546\n",
      "tensor([1., 0.]) tensor([0.8558, 0.1442], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 32 - 148: cat - cat || Loss: 0.4570894241333008\n",
      "tensor([1., 0.]) tensor([0.8562, 0.1438], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 32 - 149: cat - cat || Loss: 0.45672881603240967\n",
      "tensor([1., 0.]) tensor([0.8565, 0.1435], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 32 - 150: cat - cat || Loss: 0.4563688635826111\n",
      "tensor([1., 0.]) tensor([0.8569, 0.1431], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 32 - 151: cat - cat || Loss: 0.4560098946094513\n",
      "tensor([1., 0.]) tensor([0.8573, 0.1427], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 32 - 152: cat - cat || Loss: 0.4556517004966736\n",
      "tensor([1., 0.]) tensor([0.8576, 0.1424], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 32 - 153: cat - cat || Loss: 0.45529431104660034\n",
      "tensor([1., 0.]) tensor([0.8580, 0.1420], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 32 - 154: cat - cat || Loss: 0.4549376964569092\n",
      "tensor([1., 0.]) tensor([0.8583, 0.1417], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 32 - 155: cat - cat || Loss: 0.4545820355415344\n",
      "tensor([1., 0.]) tensor([0.8587, 0.1413], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 32 - 156: cat - cat || Loss: 0.45422714948654175\n",
      "tensor([1., 0.]) tensor([0.8590, 0.1410], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 32 - 157: cat - cat || Loss: 0.4538731873035431\n",
      "tensor([1., 0.]) tensor([0.8594, 0.1406], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 32 - 158: cat - cat || Loss: 0.45351988077163696\n",
      "tensor([1., 0.]) tensor([0.8597, 0.1403], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 32 - 159: cat - cat || Loss: 0.4531674385070801\n",
      "tensor([1., 0.]) tensor([0.8601, 0.1399], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 32 - 160: cat - cat || Loss: 0.4528158903121948\n",
      "tensor([1., 0.]) tensor([0.8604, 0.1396], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 32 - 161: cat - cat || Loss: 0.45246508717536926\n",
      "tensor([1., 0.]) tensor([0.8608, 0.1392], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 32 - 162: cat - cat || Loss: 0.4521152675151825\n",
      "tensor([1., 0.]) tensor([0.8611, 0.1389], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 32 - 163: cat - cat || Loss: 0.4517660140991211\n",
      "tensor([1., 0.]) tensor([0.8615, 0.1385], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 32 - 164: cat - cat || Loss: 0.4514177441596985\n",
      "tensor([1., 0.]) tensor([0.8618, 0.1382], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 32 - 165: cat - cat || Loss: 0.4510703384876251\n",
      "tensor([1., 0.]) tensor([0.8622, 0.1378], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 32 - 166: cat - cat || Loss: 0.4507236182689667\n",
      "tensor([1., 0.]) tensor([0.8625, 0.1375], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 32 - 167: cat - cat || Loss: 0.45037776231765747\n",
      "tensor([1., 0.]) tensor([0.8629, 0.1371], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 32 - 168: cat - cat || Loss: 0.4500328600406647\n",
      "tensor([1., 0.]) tensor([0.8632, 0.1368], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 32 - 169: cat - cat || Loss: 0.44968852400779724\n",
      "tensor([1., 0.]) tensor([0.8636, 0.1364], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 32 - 170: cat - cat || Loss: 0.44934511184692383\n",
      "tensor([1., 0.]) tensor([0.8639, 0.1361], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 32 - 171: cat - cat || Loss: 0.44900256395339966\n",
      "tensor([1., 0.]) tensor([0.8643, 0.1357], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 32 - 172: cat - cat || Loss: 0.4486607015132904\n",
      "tensor([1., 0.]) tensor([0.8646, 0.1354], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 32 - 173: cat - cat || Loss: 0.44831976294517517\n",
      "tensor([1., 0.]) tensor([0.8649, 0.1351], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 32 - 174: cat - cat || Loss: 0.44797956943511963\n",
      "tensor([1., 0.]) tensor([0.8653, 0.1347], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 32 - 175: cat - cat || Loss: 0.44764021039009094\n",
      "tensor([1., 0.]) tensor([0.8656, 0.1344], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 32 - 176: cat - cat || Loss: 0.44730159640312195\n",
      "tensor([1., 0.]) tensor([0.8660, 0.1340], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 32 - 177: cat - cat || Loss: 0.4469638466835022\n",
      "tensor([1., 0.]) tensor([0.8663, 0.1337], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 32 - 178: cat - cat || Loss: 0.4466268718242645\n",
      "tensor([1., 0.]) tensor([0.8666, 0.1334], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 32 - 179: cat - cat || Loss: 0.4462907314300537\n",
      "tensor([1., 0.]) tensor([0.8670, 0.1330], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 32 - 180: cat - cat || Loss: 0.4459553360939026\n",
      "tensor([1., 0.]) tensor([0.8673, 0.1327], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 32 - 181: cat - cat || Loss: 0.44562074542045593\n",
      "tensor([1., 0.]) tensor([0.8676, 0.1324], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 32 - 182: cat - cat || Loss: 0.44528698921203613\n",
      "tensor([1., 0.]) tensor([0.8680, 0.1320], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 32 - 183: cat - cat || Loss: 0.4449540972709656\n",
      "tensor([1., 0.]) tensor([0.8683, 0.1317], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 32 - 184: cat - cat || Loss: 0.44462189078330994\n",
      "tensor([1., 0.]) tensor([0.8686, 0.1314], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 32 - 185: cat - cat || Loss: 0.44429051876068115\n",
      "tensor([1., 0.]) tensor([0.8690, 0.1310], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 32 - 186: cat - cat || Loss: 0.44395989179611206\n",
      "tensor([1., 0.]) tensor([0.8693, 0.1307], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 32 - 187: cat - cat || Loss: 0.44363003969192505\n",
      "tensor([1., 0.]) tensor([0.8696, 0.1304], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 32 - 188: cat - cat || Loss: 0.4433009624481201\n",
      "tensor([1., 0.]) tensor([0.8700, 0.1300], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 32 - 189: cat - cat || Loss: 0.44297271966934204\n",
      "tensor([1., 0.]) tensor([0.8703, 0.1297], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 32 - 190: dog - cat || Loss: 1.1838781833648682\n",
      "tensor([0., 1.]) tensor([0.8706, 0.1294], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 32 - 191: dog - cat || Loss: 1.1841403245925903\n",
      "tensor([0., 1.]) tensor([0.8709, 0.1291], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 32 - 192: dog - cat || Loss: 1.1843435764312744\n",
      "tensor([0., 1.]) tensor([0.8711, 0.1289], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 32 - 193: dog - cat || Loss: 1.1844942569732666\n",
      "tensor([0., 1.]) tensor([0.8712, 0.1288], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 32 - 194: dog - cat || Loss: 1.1845974922180176\n",
      "tensor([0., 1.]) tensor([0.8713, 0.1287], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 32 - 195: dog - cat || Loss: 1.184658408164978\n",
      "tensor([0., 1.]) tensor([0.8714, 0.1286], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 32 - 196: dog - cat || Loss: 1.1846808195114136\n",
      "tensor([0., 1.]) tensor([0.8714, 0.1286], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 32 - 197: dog - cat || Loss: 1.184668779373169\n",
      "tensor([0., 1.]) tensor([0.8714, 0.1286], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 32 - 198: dog - cat || Loss: 1.1846258640289307\n",
      "tensor([0., 1.]) tensor([0.8714, 0.1286], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 32 - 199: dog - cat || Loss: 1.184554934501648\n",
      "tensor([0., 1.]) tensor([0.8713, 0.1287], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 32 - 200: dog - cat || Loss: 1.1844589710235596\n",
      "tensor([0., 1.]) tensor([0.8712, 0.1288], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 32 - 201: dog - cat || Loss: 1.184340238571167\n",
      "tensor([0., 1.]) tensor([0.8711, 0.1289], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 32 - 202: dog - cat || Loss: 1.1842011213302612\n",
      "tensor([0., 1.]) tensor([0.8709, 0.1291], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 32 - 203: dog - cat || Loss: 1.184043526649475\n",
      "tensor([0., 1.]) tensor([0.8708, 0.1292], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 32 - 204: dog - cat || Loss: 1.183869481086731\n",
      "tensor([0., 1.]) tensor([0.8706, 0.1294], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 32 - 205: dog - cat || Loss: 1.1836801767349243\n",
      "tensor([0., 1.]) tensor([0.8704, 0.1296], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 32 - 206: dog - cat || Loss: 1.1834774017333984\n",
      "tensor([0., 1.]) tensor([0.8702, 0.1298], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 32 - 207: dog - cat || Loss: 1.1832622289657593\n",
      "tensor([0., 1.]) tensor([0.8700, 0.1300], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 32 - 208: dog - cat || Loss: 1.183035969734192\n",
      "tensor([0., 1.]) tensor([0.8698, 0.1302], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 32 - 209: dog - cat || Loss: 1.1827996969223022\n",
      "tensor([0., 1.]) tensor([0.8695, 0.1305], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 32 - 210: dog - cat || Loss: 1.1825542449951172\n",
      "tensor([0., 1.]) tensor([0.8693, 0.1307], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 32 - 211: dog - cat || Loss: 1.1823004484176636\n",
      "tensor([0., 1.]) tensor([0.8690, 0.1310], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 32 - 212: dog - cat || Loss: 1.1820390224456787\n",
      "tensor([0., 1.]) tensor([0.8688, 0.1312], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 32 - 213: dog - cat || Loss: 1.1817708015441895\n",
      "tensor([0., 1.]) tensor([0.8685, 0.1315], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 32 - 214: dog - cat || Loss: 1.181496262550354\n",
      "tensor([0., 1.]) tensor([0.8682, 0.1318], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 32 - 215: dog - cat || Loss: 1.1812160015106201\n",
      "tensor([0., 1.]) tensor([0.8680, 0.1320], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 32 - 216: dog - cat || Loss: 1.1809308528900146\n",
      "tensor([0., 1.]) tensor([0.8677, 0.1323], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 32 - 217: dog - cat || Loss: 1.1806405782699585\n",
      "tensor([0., 1.]) tensor([0.8674, 0.1326], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 32 - 218: dog - cat || Loss: 1.180345892906189\n",
      "tensor([0., 1.]) tensor([0.8671, 0.1329], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 32 - 219: dog - cat || Loss: 1.180047631263733\n",
      "tensor([0., 1.]) tensor([0.8668, 0.1332], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 32 - 220: dog - cat || Loss: 1.1797453165054321\n",
      "tensor([0., 1.]) tensor([0.8665, 0.1335], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 32 - 221: dog - cat || Loss: 1.1794397830963135\n",
      "tensor([0., 1.]) tensor([0.8662, 0.1338], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 32 - 222: dog - cat || Loss: 1.179131031036377\n",
      "tensor([0., 1.]) tensor([0.8659, 0.1341], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 32 - 223: dog - cat || Loss: 1.1788194179534912\n",
      "tensor([0., 1.]) tensor([0.8656, 0.1344], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 32 - 224: dog - cat || Loss: 1.1785051822662354\n",
      "tensor([0., 1.]) tensor([0.8652, 0.1348], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 32 - 225: dog - cat || Loss: 1.178188443183899\n",
      "tensor([0., 1.]) tensor([0.8649, 0.1351], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 32 - 226: dog - cat || Loss: 1.1778693199157715\n",
      "tensor([0., 1.]) tensor([0.8646, 0.1354], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 32 - 227: dog - cat || Loss: 1.1775481700897217\n",
      "tensor([0., 1.]) tensor([0.8643, 0.1357], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 32 - 228: dog - cat || Loss: 1.17722487449646\n",
      "tensor([0., 1.]) tensor([0.8640, 0.1360], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 32 - 229: dog - cat || Loss: 1.176899790763855\n",
      "tensor([0., 1.]) tensor([0.8636, 0.1364], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 32 - 230: dog - cat || Loss: 1.176572561264038\n",
      "tensor([0., 1.]) tensor([0.8633, 0.1367], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 32 - 231: dog - cat || Loss: 1.1762441396713257\n",
      "tensor([0., 1.]) tensor([0.8630, 0.1370], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 32 - 232: dog - cat || Loss: 1.17591392993927\n",
      "tensor([0., 1.]) tensor([0.8627, 0.1373], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 32 - 233: dog - cat || Loss: 1.1755820512771606\n",
      "tensor([0., 1.]) tensor([0.8623, 0.1377], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 32 - 234: dog - cat || Loss: 1.1752489805221558\n",
      "tensor([0., 1.]) tensor([0.8620, 0.1380], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 32 - 235: dog - cat || Loss: 1.1749143600463867\n",
      "tensor([0., 1.]) tensor([0.8617, 0.1383], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 32 - 236: dog - cat || Loss: 1.1745784282684326\n",
      "tensor([0., 1.]) tensor([0.8613, 0.1387], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 32 - 237: dog - cat || Loss: 1.1742414236068726\n",
      "tensor([0., 1.]) tensor([0.8610, 0.1390], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 32 - 238: dog - cat || Loss: 1.173902988433838\n",
      "tensor([0., 1.]) tensor([0.8606, 0.1394], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 32 - 239: dog - cat || Loss: 1.1735633611679077\n",
      "tensor([0., 1.]) tensor([0.8603, 0.1397], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 32 - 240: dog - cat || Loss: 1.1732226610183716\n",
      "tensor([0., 1.]) tensor([0.8600, 0.1400], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 32 - 241: dog - cat || Loss: 1.1728808879852295\n",
      "tensor([0., 1.]) tensor([0.8596, 0.1404], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 32 - 242: dog - cat || Loss: 1.1725380420684814\n",
      "tensor([0., 1.]) tensor([0.8593, 0.1407], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 32 - 243: dog - cat || Loss: 1.1721941232681274\n",
      "tensor([0., 1.]) tensor([0.8589, 0.1411], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 32 - 244: dog - cat || Loss: 1.171849250793457\n",
      "tensor([0., 1.]) tensor([0.8586, 0.1414], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 32 - 245: dog - cat || Loss: 1.1715035438537598\n",
      "tensor([0., 1.]) tensor([0.8582, 0.1418], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 32 - 246: dog - cat || Loss: 1.171156406402588\n",
      "tensor([0., 1.]) tensor([0.8579, 0.1421], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 32 - 247: dog - cat || Loss: 1.1708085536956787\n",
      "tensor([0., 1.]) tensor([0.8575, 0.1425], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 32 - 248: dog - cat || Loss: 1.1704598665237427\n",
      "tensor([0., 1.]) tensor([0.8572, 0.1428], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 32 - 249: dog - cat || Loss: 1.1701099872589111\n",
      "tensor([0., 1.]) tensor([0.8568, 0.1432], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 32 - 250: dog - cat || Loss: 1.1697593927383423\n",
      "tensor([0., 1.]) tensor([0.8565, 0.1435], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 32 - 251: dog - cat || Loss: 1.169407844543457\n",
      "tensor([0., 1.]) tensor([0.8561, 0.1439], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 32 - 252: dog - cat || Loss: 1.1690553426742554\n",
      "tensor([0., 1.]) tensor([0.8558, 0.1442], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 32 - 253: dog - cat || Loss: 1.1687021255493164\n",
      "tensor([0., 1.]) tensor([0.8554, 0.1446], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 32 - 254: dog - cat || Loss: 1.1683478355407715\n",
      "tensor([0., 1.]) tensor([0.8551, 0.1449], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 32 - 255: dog - cat || Loss: 1.1679927110671997\n",
      "tensor([0., 1.]) tensor([0.8547, 0.1453], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 32 - 256: dog - cat || Loss: 1.167636752128601\n",
      "tensor([0., 1.]) tensor([0.8544, 0.1456], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 32 - 257: dog - cat || Loss: 1.167279839515686\n",
      "tensor([0., 1.]) tensor([0.8540, 0.1460], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 32 - 258: dog - cat || Loss: 1.1669223308563232\n",
      "tensor([0., 1.]) tensor([0.8537, 0.1463], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 32 - 259: dog - cat || Loss: 1.166563868522644\n",
      "tensor([0., 1.]) tensor([0.8533, 0.1467], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 32 - 260: dog - cat || Loss: 1.1662044525146484\n",
      "tensor([0., 1.]) tensor([0.8529, 0.1471], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 32 - 261: dog - cat || Loss: 1.1658443212509155\n",
      "tensor([0., 1.]) tensor([0.8526, 0.1474], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 32 - 262: dog - cat || Loss: 1.1654832363128662\n",
      "tensor([0., 1.]) tensor([0.8522, 0.1478], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 32 - 263: dog - cat || Loss: 1.16512131690979\n",
      "tensor([0., 1.]) tensor([0.8519, 0.1481], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 32 - 264: dog - cat || Loss: 1.164758563041687\n",
      "tensor([0., 1.]) tensor([0.8515, 0.1485], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 32 - 265: dog - cat || Loss: 1.1643950939178467\n",
      "tensor([0., 1.]) tensor([0.8511, 0.1489], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 32 - 266: dog - cat || Loss: 1.1640307903289795\n",
      "tensor([0., 1.]) tensor([0.8508, 0.1492], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 32 - 267: dog - cat || Loss: 1.1636656522750854\n",
      "tensor([0., 1.]) tensor([0.8504, 0.1496], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 32 - 268: dog - cat || Loss: 1.163299560546875\n",
      "tensor([0., 1.]) tensor([0.8500, 0.1500], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 32 - 269: dog - cat || Loss: 1.1629327535629272\n",
      "tensor([0., 1.]) tensor([0.8497, 0.1503], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 32 - 270: dog - cat || Loss: 1.1625651121139526\n",
      "tensor([0., 1.]) tensor([0.8493, 0.1507], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 32 - 271: dog - cat || Loss: 1.1621965169906616\n",
      "tensor([0., 1.]) tensor([0.8489, 0.1511], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 32 - 272: dog - cat || Loss: 1.1618272066116333\n",
      "tensor([0., 1.]) tensor([0.8486, 0.1514], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 32 - 273: dog - cat || Loss: 1.1614570617675781\n",
      "tensor([0., 1.]) tensor([0.8482, 0.1518], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 32 - 274: dog - cat || Loss: 1.1610859632492065\n",
      "tensor([0., 1.]) tensor([0.8478, 0.1522], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 32 - 275: dog - cat || Loss: 1.1607141494750977\n",
      "tensor([0., 1.]) tensor([0.8475, 0.1525], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 32 - 276: dog - cat || Loss: 1.160341501235962\n",
      "tensor([0., 1.]) tensor([0.8471, 0.1529], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 32 - 277: dog - cat || Loss: 1.1599680185317993\n",
      "tensor([0., 1.]) tensor([0.8467, 0.1533], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 32 - 278: dog - cat || Loss: 1.1595938205718994\n",
      "tensor([0., 1.]) tensor([0.8463, 0.1537], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 32 - 279: dog - cat || Loss: 1.159218668937683\n",
      "tensor([0., 1.]) tensor([0.8460, 0.1540], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 32 - 280: dog - cat || Loss: 1.15884268283844\n",
      "tensor([0., 1.]) tensor([0.8456, 0.1544], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 32 - 281: dog - cat || Loss: 1.1584659814834595\n",
      "tensor([0., 1.]) tensor([0.8452, 0.1548], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 32 - 282: dog - cat || Loss: 1.1580883264541626\n",
      "tensor([0., 1.]) tensor([0.8448, 0.1552], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 32 - 283: dog - cat || Loss: 1.1577099561691284\n",
      "tensor([0., 1.]) tensor([0.8444, 0.1556], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 32 - 284: dog - cat || Loss: 1.1573307514190674\n",
      "tensor([0., 1.]) tensor([0.8441, 0.1559], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 32 - 285: dog - cat || Loss: 1.15695059299469\n",
      "tensor([0., 1.]) tensor([0.8437, 0.1563], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 32 - 286: dog - cat || Loss: 1.1565697193145752\n",
      "tensor([0., 1.]) tensor([0.8433, 0.1567], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 32 - 287: dog - cat || Loss: 1.1561880111694336\n",
      "tensor([0., 1.]) tensor([0.8429, 0.1571], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 32 - 288: dog - cat || Loss: 1.1558054685592651\n",
      "tensor([0., 1.]) tensor([0.8425, 0.1575], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 32 - 289: dog - cat || Loss: 1.1554219722747803\n",
      "tensor([0., 1.]) tensor([0.8422, 0.1578], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 32 - 290: dog - cat || Loss: 1.155037760734558\n",
      "tensor([0., 1.]) tensor([0.8418, 0.1582], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 32 - 291: dog - cat || Loss: 1.154652714729309\n",
      "tensor([0., 1.]) tensor([0.8414, 0.1586], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 32 - 292: dog - cat || Loss: 1.1542668342590332\n",
      "tensor([0., 1.]) tensor([0.8410, 0.1590], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 32 - 293: dog - cat || Loss: 1.153880000114441\n",
      "tensor([0., 1.]) tensor([0.8406, 0.1594], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 32 - 294: dog - cat || Loss: 1.1534925699234009\n",
      "tensor([0., 1.]) tensor([0.8402, 0.1598], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 32 - 295: dog - cat || Loss: 1.1531041860580444\n",
      "tensor([0., 1.]) tensor([0.8398, 0.1602], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 32 - 296: dog - cat || Loss: 1.1527148485183716\n",
      "tensor([0., 1.]) tensor([0.8395, 0.1605], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 32 - 297: dog - cat || Loss: 1.152324914932251\n",
      "tensor([0., 1.]) tensor([0.8391, 0.1609], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 32 - 298: dog - cat || Loss: 1.1519339084625244\n",
      "tensor([0., 1.]) tensor([0.8387, 0.1613], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 32 - 299: dog - cat || Loss: 1.1515421867370605\n",
      "tensor([0., 1.]) tensor([0.8383, 0.1617], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 32 - 300: dog - cat || Loss: 1.1511496305465698\n",
      "tensor([0., 1.]) tensor([0.8379, 0.1621], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 32 - 301: dog - cat || Loss: 1.1507561206817627\n",
      "tensor([0., 1.]) tensor([0.8375, 0.1625], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 32 - 302: dog - cat || Loss: 1.1503620147705078\n",
      "tensor([0., 1.]) tensor([0.8371, 0.1629], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 32 - 303: dog - cat || Loss: 1.149966835975647\n",
      "tensor([0., 1.]) tensor([0.8367, 0.1633], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 32 - 304: dog - cat || Loss: 1.1495709419250488\n",
      "tensor([0., 1.]) tensor([0.8363, 0.1637], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 32 - 305: dog - cat || Loss: 1.1491740942001343\n",
      "tensor([0., 1.]) tensor([0.8359, 0.1641], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 32 - 306: dog - cat || Loss: 1.1487765312194824\n",
      "tensor([0., 1.]) tensor([0.8355, 0.1645], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 32 - 307: dog - cat || Loss: 1.1483780145645142\n",
      "tensor([0., 1.]) tensor([0.8351, 0.1649], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 32 - 308: dog - cat || Loss: 1.1479787826538086\n",
      "tensor([0., 1.]) tensor([0.8347, 0.1653], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 32 - 309: dog - cat || Loss: 1.1475785970687866\n",
      "tensor([0., 1.]) tensor([0.8343, 0.1657], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 32 - 310: dog - cat || Loss: 1.1471776962280273\n",
      "tensor([0., 1.]) tensor([0.8339, 0.1661], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 32 - 311: dog - cat || Loss: 1.146775722503662\n",
      "tensor([0., 1.]) tensor([0.8335, 0.1665], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 32 - 312: dog - cat || Loss: 1.1463730335235596\n",
      "tensor([0., 1.]) tensor([0.8331, 0.1669], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 32 - 313: dog - cat || Loss: 1.1459693908691406\n",
      "tensor([0., 1.]) tensor([0.8327, 0.1673], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 32 - 314: dog - cat || Loss: 1.1455650329589844\n",
      "tensor([0., 1.]) tensor([0.8323, 0.1677], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 32 - 315: dog - cat || Loss: 1.1451598405838013\n",
      "tensor([0., 1.]) tensor([0.8319, 0.1681], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 32 - 316: dog - cat || Loss: 1.1447538137435913\n",
      "tensor([0., 1.]) tensor([0.8315, 0.1685], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 32 - 317: dog - cat || Loss: 1.1443467140197754\n",
      "tensor([0., 1.]) tensor([0.8311, 0.1689], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 32 - 318: dog - cat || Loss: 1.1439390182495117\n",
      "tensor([0., 1.]) tensor([0.8307, 0.1693], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 32 - 319: dog - cat || Loss: 1.1435303688049316\n",
      "tensor([0., 1.]) tensor([0.8303, 0.1697], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 32 - 320: dog - cat || Loss: 1.1431210041046143\n",
      "tensor([0., 1.]) tensor([0.8299, 0.1701], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 32 - 321: dog - cat || Loss: 1.1427104473114014\n",
      "tensor([0., 1.]) tensor([0.8294, 0.1706], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 32 - 322: dog - cat || Loss: 1.1422994136810303\n",
      "tensor([0., 1.]) tensor([0.8290, 0.1710], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 32 - 323: dog - cat || Loss: 1.1418871879577637\n",
      "tensor([0., 1.]) tensor([0.8286, 0.1714], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 32 - 324: dog - cat || Loss: 1.1414743661880493\n",
      "tensor([0., 1.]) tensor([0.8282, 0.1718], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 32 - 325: dog - cat || Loss: 1.141060709953308\n",
      "tensor([0., 1.]) tensor([0.8278, 0.1722], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 32 - 326: dog - cat || Loss: 1.1406458616256714\n",
      "tensor([0., 1.]) tensor([0.8274, 0.1726], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 32 - 327: dog - cat || Loss: 1.1402305364608765\n",
      "tensor([0., 1.]) tensor([0.8270, 0.1730], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 32 - 328: dog - cat || Loss: 1.1398141384124756\n",
      "tensor([0., 1.]) tensor([0.8266, 0.1734], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 32 - 329: dog - cat || Loss: 1.1393970251083374\n",
      "tensor([0., 1.]) tensor([0.8261, 0.1739], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 32 - 330: dog - cat || Loss: 1.1389790773391724\n",
      "tensor([0., 1.]) tensor([0.8257, 0.1743], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 32 - 331: dog - cat || Loss: 1.1385599374771118\n",
      "tensor([0., 1.]) tensor([0.8253, 0.1747], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 32 - 332: dog - cat || Loss: 1.1381402015686035\n",
      "tensor([0., 1.]) tensor([0.8249, 0.1751], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 32 - 333: dog - cat || Loss: 1.1377195119857788\n",
      "tensor([0., 1.]) tensor([0.8245, 0.1755], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 32 - 334: dog - cat || Loss: 1.1372979879379272\n",
      "tensor([0., 1.]) tensor([0.8240, 0.1760], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 32 - 335: dog - cat || Loss: 1.1368753910064697\n",
      "tensor([0., 1.]) tensor([0.8236, 0.1764], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 32 - 336: dog - cat || Loss: 1.1364524364471436\n",
      "tensor([0., 1.]) tensor([0.8232, 0.1768], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 32 - 337: dog - cat || Loss: 1.1360282897949219\n",
      "tensor([0., 1.]) tensor([0.8228, 0.1772], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 32 - 338: dog - cat || Loss: 1.1356033086776733\n",
      "tensor([0., 1.]) tensor([0.8223, 0.1777], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 32 - 339: dog - cat || Loss: 1.1351773738861084\n",
      "tensor([0., 1.]) tensor([0.8219, 0.1781], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 32 - 340: dog - cat || Loss: 1.1347506046295166\n",
      "tensor([0., 1.]) tensor([0.8215, 0.1785], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 32 - 341: dog - cat || Loss: 1.1343231201171875\n",
      "tensor([0., 1.]) tensor([0.8211, 0.1789], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 32 - 342: dog - cat || Loss: 1.133894681930542\n",
      "tensor([0., 1.]) tensor([0.8206, 0.1794], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 32 - 343: dog - cat || Loss: 1.1334654092788696\n",
      "tensor([0., 1.]) tensor([0.8202, 0.1798], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 32 - 344: dog - cat || Loss: 1.1330350637435913\n",
      "tensor([0., 1.]) tensor([0.8198, 0.1802], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 32 - 345: dog - cat || Loss: 1.1326040029525757\n",
      "tensor([0., 1.]) tensor([0.8193, 0.1807], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 32 - 346: dog - cat || Loss: 1.1321721076965332\n",
      "tensor([0., 1.]) tensor([0.8189, 0.1811], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 32 - 347: dog - cat || Loss: 1.1317394971847534\n",
      "tensor([0., 1.]) tensor([0.8185, 0.1815], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 32 - 348: dog - cat || Loss: 1.1313055753707886\n",
      "tensor([0., 1.]) tensor([0.8180, 0.1820], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 32 - 349: dog - cat || Loss: 1.130871057510376\n",
      "tensor([0., 1.]) tensor([0.8176, 0.1824], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 32 - 350: dog - cat || Loss: 1.130435585975647\n",
      "tensor([0., 1.]) tensor([0.8172, 0.1828], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 32 - 351: dog - cat || Loss: 1.1299992799758911\n",
      "tensor([0., 1.]) tensor([0.8167, 0.1833], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 32 - 352: dog - cat || Loss: 1.1295620203018188\n",
      "tensor([0., 1.]) tensor([0.8163, 0.1837], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 32 - 353: dog - cat || Loss: 1.1291239261627197\n",
      "tensor([0., 1.]) tensor([0.8159, 0.1841], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 32 - 354: dog - cat || Loss: 1.1286851167678833\n",
      "tensor([0., 1.]) tensor([0.8154, 0.1846], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 32 - 355: dog - cat || Loss: 1.128245234489441\n",
      "tensor([0., 1.]) tensor([0.8150, 0.1850], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 32 - 356: dog - cat || Loss: 1.1278045177459717\n",
      "tensor([0., 1.]) tensor([0.8145, 0.1855], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 32 - 357: dog - cat || Loss: 1.1273630857467651\n",
      "tensor([0., 1.]) tensor([0.8141, 0.1859], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 32 - 358: dog - cat || Loss: 1.1269205808639526\n",
      "tensor([0., 1.]) tensor([0.8137, 0.1863], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 32 - 359: dog - cat || Loss: 1.1264773607254028\n",
      "tensor([0., 1.]) tensor([0.8132, 0.1868], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 32 - 360: dog - cat || Loss: 1.1260331869125366\n",
      "tensor([0., 1.]) tensor([0.8128, 0.1872], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 32 - 361: dog - cat || Loss: 1.125588059425354\n",
      "tensor([0., 1.]) tensor([0.8123, 0.1877], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 32 - 362: dog - cat || Loss: 1.125141978263855\n",
      "tensor([0., 1.]) tensor([0.8119, 0.1881], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 32 - 363: dog - cat || Loss: 1.1246953010559082\n",
      "tensor([0., 1.]) tensor([0.8114, 0.1886], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 32 - 364: dog - cat || Loss: 1.1242475509643555\n",
      "tensor([0., 1.]) tensor([0.8110, 0.1890], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 32 - 365: dog - cat || Loss: 1.1237990856170654\n",
      "tensor([0., 1.]) tensor([0.8105, 0.1895], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 32 - 366: dog - cat || Loss: 1.1233495473861694\n",
      "tensor([0., 1.]) tensor([0.8101, 0.1899], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 32 - 367: dog - cat || Loss: 1.1228992938995361\n",
      "tensor([0., 1.]) tensor([0.8096, 0.1904], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 32 - 368: dog - cat || Loss: 1.1224480867385864\n",
      "tensor([0., 1.]) tensor([0.8092, 0.1908], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 32 - 369: dog - cat || Loss: 1.1219959259033203\n",
      "tensor([0., 1.]) tensor([0.8087, 0.1913], grad_fn=<SoftmaxBackward0>)\n",
      "=====epoch:33=====\n",
      "Epoch 33 - 0: cat - cat || Loss: 0.5049803256988525\n",
      "tensor([1., 0.]) tensor([0.8083, 0.1917], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 33 - 1: cat - cat || Loss: 0.5053426027297974\n",
      "tensor([1., 0.]) tensor([0.8079, 0.1921], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 33 - 2: cat - cat || Loss: 0.5056230425834656\n",
      "tensor([1., 0.]) tensor([0.8076, 0.1924], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 33 - 3: cat - cat || Loss: 0.5058295726776123\n",
      "tensor([1., 0.]) tensor([0.8074, 0.1926], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 33 - 4: cat - cat || Loss: 0.5059696435928345\n",
      "tensor([1., 0.]) tensor([0.8073, 0.1927], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 33 - 5: cat - cat || Loss: 0.5060497522354126\n",
      "tensor([1., 0.]) tensor([0.8072, 0.1928], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 33 - 6: cat - cat || Loss: 0.5060758590698242\n",
      "tensor([1., 0.]) tensor([0.8072, 0.1928], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 33 - 7: cat - cat || Loss: 0.5060533285140991\n",
      "tensor([1., 0.]) tensor([0.8072, 0.1928], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 33 - 8: cat - cat || Loss: 0.5059871673583984\n",
      "tensor([1., 0.]) tensor([0.8073, 0.1927], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 33 - 9: cat - cat || Loss: 0.5058816075325012\n",
      "tensor([1., 0.]) tensor([0.8074, 0.1926], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 33 - 10: cat - cat || Loss: 0.5057406425476074\n",
      "tensor([1., 0.]) tensor([0.8075, 0.1925], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 33 - 11: cat - cat || Loss: 0.5055680871009827\n",
      "tensor([1., 0.]) tensor([0.8077, 0.1923], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 33 - 12: cat - cat || Loss: 0.5053669214248657\n",
      "tensor([1., 0.]) tensor([0.8079, 0.1921], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 33 - 13: cat - cat || Loss: 0.5051401853561401\n",
      "tensor([1., 0.]) tensor([0.8081, 0.1919], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 33 - 14: cat - cat || Loss: 0.5048904418945312\n",
      "tensor([1., 0.]) tensor([0.8084, 0.1916], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 33 - 15: cat - cat || Loss: 0.5046198964118958\n",
      "tensor([1., 0.]) tensor([0.8086, 0.1914], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 33 - 16: cat - cat || Loss: 0.5043309926986694\n",
      "tensor([1., 0.]) tensor([0.8089, 0.1911], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 33 - 17: cat - cat || Loss: 0.5040254592895508\n",
      "tensor([1., 0.]) tensor([0.8092, 0.1908], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 33 - 18: cat - cat || Loss: 0.5037052631378174\n",
      "tensor([1., 0.]) tensor([0.8096, 0.1904], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 33 - 19: cat - cat || Loss: 0.5033717155456543\n",
      "tensor([1., 0.]) tensor([0.8099, 0.1901], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 33 - 20: cat - cat || Loss: 0.5030262470245361\n",
      "tensor([1., 0.]) tensor([0.8102, 0.1898], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 33 - 21: cat - cat || Loss: 0.502670407295227\n",
      "tensor([1., 0.]) tensor([0.8106, 0.1894], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 33 - 22: cat - cat || Loss: 0.5023050308227539\n",
      "tensor([1., 0.]) tensor([0.8110, 0.1890], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 33 - 23: cat - cat || Loss: 0.5019313097000122\n",
      "tensor([1., 0.]) tensor([0.8113, 0.1887], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 33 - 24: cat - cat || Loss: 0.5015500783920288\n",
      "tensor([1., 0.]) tensor([0.8117, 0.1883], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 33 - 25: cat - cat || Loss: 0.5011621713638306\n",
      "tensor([1., 0.]) tensor([0.8121, 0.1879], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 33 - 26: cat - cat || Loss: 0.5007684230804443\n",
      "tensor([1., 0.]) tensor([0.8125, 0.1875], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 33 - 27: cat - cat || Loss: 0.5003694295883179\n",
      "tensor([1., 0.]) tensor([0.8129, 0.1871], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 33 - 28: cat - cat || Loss: 0.49996596574783325\n",
      "tensor([1., 0.]) tensor([0.8133, 0.1867], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 33 - 29: cat - cat || Loss: 0.4995582103729248\n",
      "tensor([1., 0.]) tensor([0.8137, 0.1863], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 33 - 30: cat - cat || Loss: 0.49914705753326416\n",
      "tensor([1., 0.]) tensor([0.8141, 0.1859], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 33 - 31: cat - cat || Loss: 0.4987327456474304\n",
      "tensor([1., 0.]) tensor([0.8145, 0.1855], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 33 - 32: cat - cat || Loss: 0.4983157515525818\n",
      "tensor([1., 0.]) tensor([0.8149, 0.1851], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 33 - 33: cat - cat || Loss: 0.4978964924812317\n",
      "tensor([1., 0.]) tensor([0.8154, 0.1846], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 33 - 34: cat - cat || Loss: 0.4974750876426697\n",
      "tensor([1., 0.]) tensor([0.8158, 0.1842], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 33 - 35: cat - cat || Loss: 0.49705198407173157\n",
      "tensor([1., 0.]) tensor([0.8162, 0.1838], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 33 - 36: cat - cat || Loss: 0.4966273903846741\n",
      "tensor([1., 0.]) tensor([0.8166, 0.1834], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 33 - 37: cat - cat || Loss: 0.49620166420936584\n",
      "tensor([1., 0.]) tensor([0.8171, 0.1829], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 33 - 38: cat - cat || Loss: 0.4957748055458069\n",
      "tensor([1., 0.]) tensor([0.8175, 0.1825], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 33 - 39: cat - cat || Loss: 0.49534714221954346\n",
      "tensor([1., 0.]) tensor([0.8179, 0.1821], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 33 - 40: cat - cat || Loss: 0.4949190616607666\n",
      "tensor([1., 0.]) tensor([0.8183, 0.1817], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 33 - 41: cat - cat || Loss: 0.4944901764392853\n",
      "tensor([1., 0.]) tensor([0.8188, 0.1812], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 33 - 42: cat - cat || Loss: 0.49406108260154724\n",
      "tensor([1., 0.]) tensor([0.8192, 0.1808], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 33 - 43: cat - cat || Loss: 0.49363166093826294\n",
      "tensor([1., 0.]) tensor([0.8196, 0.1804], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 33 - 44: cat - cat || Loss: 0.4932023584842682\n",
      "tensor([1., 0.]) tensor([0.8201, 0.1799], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 33 - 45: cat - cat || Loss: 0.4927728772163391\n",
      "tensor([1., 0.]) tensor([0.8205, 0.1795], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 33 - 46: cat - cat || Loss: 0.4923434257507324\n",
      "tensor([1., 0.]) tensor([0.8209, 0.1791], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 33 - 47: cat - cat || Loss: 0.4919142723083496\n",
      "tensor([1., 0.]) tensor([0.8213, 0.1787], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 33 - 48: cat - cat || Loss: 0.4914853572845459\n",
      "tensor([1., 0.]) tensor([0.8218, 0.1782], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 33 - 49: cat - cat || Loss: 0.4910566806793213\n",
      "tensor([1., 0.]) tensor([0.8222, 0.1778], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 33 - 50: cat - cat || Loss: 0.49062833189964294\n",
      "tensor([1., 0.]) tensor([0.8226, 0.1774], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 33 - 51: cat - cat || Loss: 0.4902004599571228\n",
      "tensor([1., 0.]) tensor([0.8231, 0.1769], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 33 - 52: cat - cat || Loss: 0.48977306485176086\n",
      "tensor([1., 0.]) tensor([0.8235, 0.1765], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 33 - 53: cat - cat || Loss: 0.48934614658355713\n",
      "tensor([1., 0.]) tensor([0.8239, 0.1761], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 33 - 54: cat - cat || Loss: 0.48891976475715637\n",
      "tensor([1., 0.]) tensor([0.8243, 0.1757], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 33 - 55: cat - cat || Loss: 0.48849397897720337\n",
      "tensor([1., 0.]) tensor([0.8248, 0.1752], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 33 - 56: cat - cat || Loss: 0.4880688786506653\n",
      "tensor([1., 0.]) tensor([0.8252, 0.1748], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 33 - 57: cat - cat || Loss: 0.4876441955566406\n",
      "tensor([1., 0.]) tensor([0.8256, 0.1744], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 33 - 58: cat - cat || Loss: 0.4872204065322876\n",
      "tensor([1., 0.]) tensor([0.8260, 0.1740], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 33 - 59: cat - cat || Loss: 0.4867972433567047\n",
      "tensor([1., 0.]) tensor([0.8265, 0.1735], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 33 - 60: cat - cat || Loss: 0.48637479543685913\n",
      "tensor([1., 0.]) tensor([0.8269, 0.1731], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 33 - 61: cat - cat || Loss: 0.48595303297042847\n",
      "tensor([1., 0.]) tensor([0.8273, 0.1727], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 33 - 62: cat - cat || Loss: 0.4855320453643799\n",
      "tensor([1., 0.]) tensor([0.8277, 0.1723], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 33 - 63: cat - cat || Loss: 0.4851118326187134\n",
      "tensor([1., 0.]) tensor([0.8281, 0.1719], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 33 - 64: cat - cat || Loss: 0.4846923053264618\n",
      "tensor([1., 0.]) tensor([0.8286, 0.1714], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 33 - 65: cat - cat || Loss: 0.48427367210388184\n",
      "tensor([1., 0.]) tensor([0.8290, 0.1710], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 33 - 66: cat - cat || Loss: 0.4838557839393616\n",
      "tensor([1., 0.]) tensor([0.8294, 0.1706], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 33 - 67: cat - cat || Loss: 0.48343873023986816\n",
      "tensor([1., 0.]) tensor([0.8298, 0.1702], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 33 - 68: cat - cat || Loss: 0.48302245140075684\n",
      "tensor([1., 0.]) tensor([0.8302, 0.1698], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 33 - 69: cat - cat || Loss: 0.4826069474220276\n",
      "tensor([1., 0.]) tensor([0.8307, 0.1693], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 33 - 70: cat - cat || Loss: 0.48219233751296997\n",
      "tensor([1., 0.]) tensor([0.8311, 0.1689], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 33 - 71: cat - cat || Loss: 0.4817785620689392\n",
      "tensor([1., 0.]) tensor([0.8315, 0.1685], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 33 - 72: cat - cat || Loss: 0.48136550188064575\n",
      "tensor([1., 0.]) tensor([0.8319, 0.1681], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 33 - 73: cat - cat || Loss: 0.4809533953666687\n",
      "tensor([1., 0.]) tensor([0.8323, 0.1677], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 33 - 74: cat - cat || Loss: 0.48054203391075134\n",
      "tensor([1., 0.]) tensor([0.8327, 0.1673], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 33 - 75: cat - cat || Loss: 0.48013168573379517\n",
      "tensor([1., 0.]) tensor([0.8331, 0.1669], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 33 - 76: cat - cat || Loss: 0.4797220826148987\n",
      "tensor([1., 0.]) tensor([0.8335, 0.1665], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 33 - 77: cat - cat || Loss: 0.47931334376335144\n",
      "tensor([1., 0.]) tensor([0.8339, 0.1661], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 33 - 78: cat - cat || Loss: 0.47890543937683105\n",
      "tensor([1., 0.]) tensor([0.8344, 0.1656], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 33 - 79: cat - cat || Loss: 0.4784984588623047\n",
      "tensor([1., 0.]) tensor([0.8348, 0.1652], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 33 - 80: cat - cat || Loss: 0.4780922532081604\n",
      "tensor([1., 0.]) tensor([0.8352, 0.1648], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 33 - 81: cat - cat || Loss: 0.4776868224143982\n",
      "tensor([1., 0.]) tensor([0.8356, 0.1644], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 33 - 82: cat - cat || Loss: 0.47728240489959717\n",
      "tensor([1., 0.]) tensor([0.8360, 0.1640], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 33 - 83: cat - cat || Loss: 0.4768787920475006\n",
      "tensor([1., 0.]) tensor([0.8364, 0.1636], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 33 - 84: cat - cat || Loss: 0.47647613286972046\n",
      "tensor([1., 0.]) tensor([0.8368, 0.1632], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 33 - 85: cat - cat || Loss: 0.47607421875\n",
      "tensor([1., 0.]) tensor([0.8372, 0.1628], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 33 - 86: cat - cat || Loss: 0.47567325830459595\n",
      "tensor([1., 0.]) tensor([0.8376, 0.1624], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 33 - 87: cat - cat || Loss: 0.475273072719574\n",
      "tensor([1., 0.]) tensor([0.8380, 0.1620], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 33 - 88: cat - cat || Loss: 0.4748738706111908\n",
      "tensor([1., 0.]) tensor([0.8384, 0.1616], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 33 - 89: cat - cat || Loss: 0.4744754433631897\n",
      "tensor([1., 0.]) tensor([0.8388, 0.1612], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 33 - 90: cat - cat || Loss: 0.4740779399871826\n",
      "tensor([1., 0.]) tensor([0.8392, 0.1608], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 33 - 91: cat - cat || Loss: 0.4736812114715576\n",
      "tensor([1., 0.]) tensor([0.8396, 0.1604], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 33 - 92: cat - cat || Loss: 0.473285436630249\n",
      "tensor([1., 0.]) tensor([0.8400, 0.1600], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 33 - 93: cat - cat || Loss: 0.4728905260562897\n",
      "tensor([1., 0.]) tensor([0.8404, 0.1596], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 33 - 94: cat - cat || Loss: 0.4724964201450348\n",
      "tensor([1., 0.]) tensor([0.8408, 0.1592], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 33 - 95: cat - cat || Loss: 0.47210317850112915\n",
      "tensor([1., 0.]) tensor([0.8412, 0.1588], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 33 - 96: cat - cat || Loss: 0.47171086072921753\n",
      "tensor([1., 0.]) tensor([0.8416, 0.1584], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 33 - 97: cat - cat || Loss: 0.47131940722465515\n",
      "tensor([1., 0.]) tensor([0.8419, 0.1581], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 33 - 98: cat - cat || Loss: 0.47092872858047485\n",
      "tensor([1., 0.]) tensor([0.8423, 0.1577], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 33 - 99: cat - cat || Loss: 0.47053903341293335\n",
      "tensor([1., 0.]) tensor([0.8427, 0.1573], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 33 - 100: cat - cat || Loss: 0.4701501727104187\n",
      "tensor([1., 0.]) tensor([0.8431, 0.1569], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 33 - 101: cat - cat || Loss: 0.4697621464729309\n",
      "tensor([1., 0.]) tensor([0.8435, 0.1565], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 33 - 102: cat - cat || Loss: 0.46937504410743713\n",
      "tensor([1., 0.]) tensor([0.8439, 0.1561], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 33 - 103: cat - cat || Loss: 0.46898865699768066\n",
      "tensor([1., 0.]) tensor([0.8443, 0.1557], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 33 - 104: cat - cat || Loss: 0.46860331296920776\n",
      "tensor([1., 0.]) tensor([0.8447, 0.1553], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 33 - 105: cat - cat || Loss: 0.46821871399879456\n",
      "tensor([1., 0.]) tensor([0.8450, 0.1550], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 33 - 106: cat - cat || Loss: 0.467835009098053\n",
      "tensor([1., 0.]) tensor([0.8454, 0.1546], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 33 - 107: cat - cat || Loss: 0.46745210886001587\n",
      "tensor([1., 0.]) tensor([0.8458, 0.1542], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 33 - 108: cat - cat || Loss: 0.46707022190093994\n",
      "tensor([1., 0.]) tensor([0.8462, 0.1538], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 33 - 109: cat - cat || Loss: 0.4666890501976013\n",
      "tensor([1., 0.]) tensor([0.8466, 0.1534], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 33 - 110: cat - cat || Loss: 0.4663087725639343\n",
      "tensor([1., 0.]) tensor([0.8470, 0.1530], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 33 - 111: cat - cat || Loss: 0.4659293293952942\n",
      "tensor([1., 0.]) tensor([0.8473, 0.1527], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 33 - 112: cat - cat || Loss: 0.4655507504940033\n",
      "tensor([1., 0.]) tensor([0.8477, 0.1523], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 33 - 113: cat - cat || Loss: 0.46517300605773926\n",
      "tensor([1., 0.]) tensor([0.8481, 0.1519], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 33 - 114: cat - cat || Loss: 0.4647960662841797\n",
      "tensor([1., 0.]) tensor([0.8485, 0.1515], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 33 - 115: cat - cat || Loss: 0.46442005038261414\n",
      "tensor([1., 0.]) tensor([0.8488, 0.1512], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 33 - 116: cat - cat || Loss: 0.46404486894607544\n",
      "tensor([1., 0.]) tensor([0.8492, 0.1508], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 33 - 117: cat - cat || Loss: 0.463670551776886\n",
      "tensor([1., 0.]) tensor([0.8496, 0.1504], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 33 - 118: cat - cat || Loss: 0.4632970690727234\n",
      "tensor([1., 0.]) tensor([0.8500, 0.1500], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 33 - 119: cat - cat || Loss: 0.4629245400428772\n",
      "tensor([1., 0.]) tensor([0.8503, 0.1497], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 33 - 120: cat - cat || Loss: 0.4625527262687683\n",
      "tensor([1., 0.]) tensor([0.8507, 0.1493], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 33 - 121: cat - cat || Loss: 0.46218177676200867\n",
      "tensor([1., 0.]) tensor([0.8511, 0.1489], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 33 - 122: cat - cat || Loss: 0.46181169152259827\n",
      "tensor([1., 0.]) tensor([0.8514, 0.1486], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 33 - 123: cat - cat || Loss: 0.4614425301551819\n",
      "tensor([1., 0.]) tensor([0.8518, 0.1482], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 33 - 124: cat - cat || Loss: 0.4610741138458252\n",
      "tensor([1., 0.]) tensor([0.8522, 0.1478], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 33 - 125: cat - cat || Loss: 0.4607066512107849\n",
      "tensor([1., 0.]) tensor([0.8526, 0.1474], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 33 - 126: cat - cat || Loss: 0.46033990383148193\n",
      "tensor([1., 0.]) tensor([0.8529, 0.1471], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 33 - 127: cat - cat || Loss: 0.4599739909172058\n",
      "tensor([1., 0.]) tensor([0.8533, 0.1467], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 33 - 128: cat - cat || Loss: 0.4596089720726013\n",
      "tensor([1., 0.]) tensor([0.8537, 0.1463], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 33 - 129: cat - cat || Loss: 0.4592447280883789\n",
      "tensor([1., 0.]) tensor([0.8540, 0.1460], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 33 - 130: cat - cat || Loss: 0.4588814377784729\n",
      "tensor([1., 0.]) tensor([0.8544, 0.1456], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 33 - 131: cat - cat || Loss: 0.4585188627243042\n",
      "tensor([1., 0.]) tensor([0.8547, 0.1453], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 33 - 132: cat - cat || Loss: 0.45815718173980713\n",
      "tensor([1., 0.]) tensor([0.8551, 0.1449], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 33 - 133: cat - cat || Loss: 0.4577963054180145\n",
      "tensor([1., 0.]) tensor([0.8555, 0.1445], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 33 - 134: cat - cat || Loss: 0.457436203956604\n",
      "tensor([1., 0.]) tensor([0.8558, 0.1442], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 33 - 135: cat - cat || Loss: 0.45707714557647705\n",
      "tensor([1., 0.]) tensor([0.8562, 0.1438], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 33 - 136: cat - cat || Loss: 0.45671865344047546\n",
      "tensor([1., 0.]) tensor([0.8565, 0.1435], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 33 - 137: cat - cat || Loss: 0.4563610851764679\n",
      "tensor([1., 0.]) tensor([0.8569, 0.1431], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 33 - 138: cat - cat || Loss: 0.45600441098213196\n",
      "tensor([1., 0.]) tensor([0.8573, 0.1427], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 33 - 139: cat - cat || Loss: 0.4556485116481781\n",
      "tensor([1., 0.]) tensor([0.8576, 0.1424], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 33 - 140: cat - cat || Loss: 0.4552933871746063\n",
      "tensor([1., 0.]) tensor([0.8580, 0.1420], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 33 - 141: cat - cat || Loss: 0.4549391269683838\n",
      "tensor([1., 0.]) tensor([0.8583, 0.1417], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 33 - 142: cat - cat || Loss: 0.4545857310295105\n",
      "tensor([1., 0.]) tensor([0.8587, 0.1413], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 33 - 143: cat - cat || Loss: 0.4542331099510193\n",
      "tensor([1., 0.]) tensor([0.8590, 0.1410], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 33 - 144: cat - cat || Loss: 0.4538813829421997\n",
      "tensor([1., 0.]) tensor([0.8594, 0.1406], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 33 - 145: cat - cat || Loss: 0.4535304307937622\n",
      "tensor([1., 0.]) tensor([0.8597, 0.1403], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 33 - 146: cat - cat || Loss: 0.4531802535057068\n",
      "tensor([1., 0.]) tensor([0.8601, 0.1399], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 33 - 147: cat - cat || Loss: 0.4528310000896454\n",
      "tensor([1., 0.]) tensor([0.8604, 0.1396], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 33 - 148: cat - cat || Loss: 0.45248252153396606\n",
      "tensor([1., 0.]) tensor([0.8608, 0.1392], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 33 - 149: cat - cat || Loss: 0.452134907245636\n",
      "tensor([1., 0.]) tensor([0.8611, 0.1389], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 33 - 150: cat - cat || Loss: 0.4517880082130432\n",
      "tensor([1., 0.]) tensor([0.8615, 0.1385], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 33 - 151: cat - cat || Loss: 0.45144200325012207\n",
      "tensor([1., 0.]) tensor([0.8618, 0.1382], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 33 - 152: cat - cat || Loss: 0.451096773147583\n",
      "tensor([1., 0.]) tensor([0.8622, 0.1378], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 33 - 153: cat - cat || Loss: 0.45075228810310364\n",
      "tensor([1., 0.]) tensor([0.8625, 0.1375], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 33 - 154: cat - cat || Loss: 0.4504086375236511\n",
      "tensor([1., 0.]) tensor([0.8629, 0.1371], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 33 - 155: cat - cat || Loss: 0.45006585121154785\n",
      "tensor([1., 0.]) tensor([0.8632, 0.1368], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 33 - 156: cat - cat || Loss: 0.44972389936447144\n",
      "tensor([1., 0.]) tensor([0.8635, 0.1365], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 33 - 157: cat - cat || Loss: 0.4493827819824219\n",
      "tensor([1., 0.]) tensor([0.8639, 0.1361], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 33 - 158: cat - cat || Loss: 0.44904232025146484\n",
      "tensor([1., 0.]) tensor([0.8642, 0.1358], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 33 - 159: cat - cat || Loss: 0.44870275259017944\n",
      "tensor([1., 0.]) tensor([0.8646, 0.1354], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 33 - 160: cat - cat || Loss: 0.4483639597892761\n",
      "tensor([1., 0.]) tensor([0.8649, 0.1351], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 33 - 161: cat - cat || Loss: 0.44802600145339966\n",
      "tensor([1., 0.]) tensor([0.8652, 0.1348], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 33 - 162: cat - cat || Loss: 0.44768887758255005\n",
      "tensor([1., 0.]) tensor([0.8656, 0.1344], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 33 - 163: cat - cat || Loss: 0.44735246896743774\n",
      "tensor([1., 0.]) tensor([0.8659, 0.1341], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 33 - 164: cat - cat || Loss: 0.4470168352127075\n",
      "tensor([1., 0.]) tensor([0.8662, 0.1338], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 33 - 165: cat - cat || Loss: 0.4466821551322937\n",
      "tensor([1., 0.]) tensor([0.8666, 0.1334], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 33 - 166: cat - cat || Loss: 0.4463481307029724\n",
      "tensor([1., 0.]) tensor([0.8669, 0.1331], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 33 - 167: cat - cat || Loss: 0.446014940738678\n",
      "tensor([1., 0.]) tensor([0.8672, 0.1328], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 33 - 168: cat - cat || Loss: 0.4456825256347656\n",
      "tensor([1., 0.]) tensor([0.8676, 0.1324], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 33 - 169: cat - cat || Loss: 0.44535091519355774\n",
      "tensor([1., 0.]) tensor([0.8679, 0.1321], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 33 - 170: cat - cat || Loss: 0.4450201392173767\n",
      "tensor([1., 0.]) tensor([0.8682, 0.1318], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 33 - 171: cat - cat || Loss: 0.44469010829925537\n",
      "tensor([1., 0.]) tensor([0.8686, 0.1314], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 33 - 172: cat - cat || Loss: 0.4443608820438385\n",
      "tensor([1., 0.]) tensor([0.8689, 0.1311], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 33 - 173: cat - cat || Loss: 0.4440324902534485\n",
      "tensor([1., 0.]) tensor([0.8692, 0.1308], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 33 - 174: cat - cat || Loss: 0.4437047839164734\n",
      "tensor([1., 0.]) tensor([0.8696, 0.1304], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 33 - 175: cat - cat || Loss: 0.44337791204452515\n",
      "tensor([1., 0.]) tensor([0.8699, 0.1301], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 33 - 176: cat - cat || Loss: 0.4430517554283142\n",
      "tensor([1., 0.]) tensor([0.8702, 0.1298], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 33 - 177: cat - cat || Loss: 0.4427264630794525\n",
      "tensor([1., 0.]) tensor([0.8705, 0.1295], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 33 - 178: cat - cat || Loss: 0.4424018859863281\n",
      "tensor([1., 0.]) tensor([0.8709, 0.1291], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 33 - 179: cat - cat || Loss: 0.4420781135559082\n",
      "tensor([1., 0.]) tensor([0.8712, 0.1288], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 33 - 180: cat - cat || Loss: 0.44175517559051514\n",
      "tensor([1., 0.]) tensor([0.8715, 0.1285], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 33 - 181: cat - cat || Loss: 0.4414329528808594\n",
      "tensor([1., 0.]) tensor([0.8718, 0.1282], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 33 - 182: cat - cat || Loss: 0.44111156463623047\n",
      "tensor([1., 0.]) tensor([0.8722, 0.1278], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 33 - 183: cat - cat || Loss: 0.44079095125198364\n",
      "tensor([1., 0.]) tensor([0.8725, 0.1275], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 33 - 184: cat - cat || Loss: 0.4404710829257965\n",
      "tensor([1., 0.]) tensor([0.8728, 0.1272], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 33 - 185: cat - cat || Loss: 0.44015198945999146\n",
      "tensor([1., 0.]) tensor([0.8731, 0.1269], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 33 - 186: cat - cat || Loss: 0.4398335814476013\n",
      "tensor([1., 0.]) tensor([0.8734, 0.1266], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 33 - 187: cat - cat || Loss: 0.43951600790023804\n",
      "tensor([1., 0.]) tensor([0.8737, 0.1263], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 33 - 188: cat - cat || Loss: 0.43919914960861206\n",
      "tensor([1., 0.]) tensor([0.8741, 0.1259], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 33 - 189: cat - cat || Loss: 0.43888306617736816\n",
      "tensor([1., 0.]) tensor([0.8744, 0.1256], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 33 - 190: dog - cat || Loss: 1.187955617904663\n",
      "tensor([0., 1.]) tensor([0.8747, 0.1253], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 33 - 191: dog - cat || Loss: 1.1882081031799316\n",
      "tensor([0., 1.]) tensor([0.8749, 0.1251], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 33 - 192: dog - cat || Loss: 1.1884037256240845\n",
      "tensor([0., 1.]) tensor([0.8751, 0.1249], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 33 - 193: dog - cat || Loss: 1.1885489225387573\n",
      "tensor([0., 1.]) tensor([0.8753, 0.1247], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 33 - 194: dog - cat || Loss: 1.1886483430862427\n",
      "tensor([0., 1.]) tensor([0.8754, 0.1246], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 33 - 195: dog - cat || Loss: 1.1887069940567017\n",
      "tensor([0., 1.]) tensor([0.8754, 0.1246], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 33 - 196: dog - cat || Loss: 1.1887286901474\n",
      "tensor([0., 1.]) tensor([0.8755, 0.1245], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 33 - 197: dog - cat || Loss: 1.188717246055603\n",
      "tensor([0., 1.]) tensor([0.8755, 0.1245], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 33 - 198: dog - cat || Loss: 1.188676118850708\n",
      "tensor([0., 1.]) tensor([0.8754, 0.1246], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 33 - 199: dog - cat || Loss: 1.188607931137085\n",
      "tensor([0., 1.]) tensor([0.8753, 0.1247], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 33 - 200: dog - cat || Loss: 1.188515543937683\n",
      "tensor([0., 1.]) tensor([0.8753, 0.1247], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 33 - 201: dog - cat || Loss: 1.188401460647583\n",
      "tensor([0., 1.]) tensor([0.8751, 0.1249], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 33 - 202: dog - cat || Loss: 1.1882675886154175\n",
      "tensor([0., 1.]) tensor([0.8750, 0.1250], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 33 - 203: dog - cat || Loss: 1.188116192817688\n",
      "tensor([0., 1.]) tensor([0.8749, 0.1251], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 33 - 204: dog - cat || Loss: 1.1879485845565796\n",
      "tensor([0., 1.]) tensor([0.8747, 0.1253], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 33 - 205: dog - cat || Loss: 1.1877663135528564\n",
      "tensor([0., 1.]) tensor([0.8745, 0.1255], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 33 - 206: dog - cat || Loss: 1.1875710487365723\n",
      "tensor([0., 1.]) tensor([0.8743, 0.1257], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 33 - 207: dog - cat || Loss: 1.187364101409912\n",
      "tensor([0., 1.]) tensor([0.8741, 0.1259], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 33 - 208: dog - cat || Loss: 1.1871461868286133\n",
      "tensor([0., 1.]) tensor([0.8739, 0.1261], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 33 - 209: dog - cat || Loss: 1.1869187355041504\n",
      "tensor([0., 1.]) tensor([0.8737, 0.1263], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 33 - 210: dog - cat || Loss: 1.1866825819015503\n",
      "tensor([0., 1.]) tensor([0.8734, 0.1266], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 33 - 211: dog - cat || Loss: 1.1864382028579712\n",
      "tensor([0., 1.]) tensor([0.8732, 0.1268], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 33 - 212: dog - cat || Loss: 1.186186671257019\n",
      "tensor([0., 1.]) tensor([0.8729, 0.1271], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 33 - 213: dog - cat || Loss: 1.185928463935852\n",
      "tensor([0., 1.]) tensor([0.8727, 0.1273], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 33 - 214: dog - cat || Loss: 1.185664176940918\n",
      "tensor([0., 1.]) tensor([0.8724, 0.1276], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 33 - 215: dog - cat || Loss: 1.1853944063186646\n",
      "tensor([0., 1.]) tensor([0.8721, 0.1279], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 33 - 216: dog - cat || Loss: 1.18511962890625\n",
      "tensor([0., 1.]) tensor([0.8719, 0.1281], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 33 - 217: dog - cat || Loss: 1.1848403215408325\n",
      "tensor([0., 1.]) tensor([0.8716, 0.1284], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 33 - 218: dog - cat || Loss: 1.1845567226409912\n",
      "tensor([0., 1.]) tensor([0.8713, 0.1287], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 33 - 219: dog - cat || Loss: 1.1842693090438843\n",
      "tensor([0., 1.]) tensor([0.8710, 0.1290], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 33 - 220: dog - cat || Loss: 1.1839781999588013\n",
      "tensor([0., 1.]) tensor([0.8707, 0.1293], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 33 - 221: dog - cat || Loss: 1.1836838722229004\n",
      "tensor([0., 1.]) tensor([0.8704, 0.1296], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 33 - 222: dog - cat || Loss: 1.1833865642547607\n",
      "tensor([0., 1.]) tensor([0.8701, 0.1299], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 33 - 223: dog - cat || Loss: 1.1830865144729614\n",
      "tensor([0., 1.]) tensor([0.8698, 0.1302], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 33 - 224: dog - cat || Loss: 1.182783842086792\n",
      "tensor([0., 1.]) tensor([0.8695, 0.1305], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 33 - 225: dog - cat || Loss: 1.182478904724121\n",
      "tensor([0., 1.]) tensor([0.8692, 0.1308], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 33 - 226: dog - cat || Loss: 1.1821714639663696\n",
      "tensor([0., 1.]) tensor([0.8689, 0.1311], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 33 - 227: dog - cat || Loss: 1.1818621158599854\n",
      "tensor([0., 1.]) tensor([0.8686, 0.1314], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 33 - 228: dog - cat || Loss: 1.1815509796142578\n",
      "tensor([0., 1.]) tensor([0.8683, 0.1317], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 33 - 229: dog - cat || Loss: 1.1812376976013184\n",
      "tensor([0., 1.]) tensor([0.8680, 0.1320], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 33 - 230: dog - cat || Loss: 1.1809226274490356\n",
      "tensor([0., 1.]) tensor([0.8677, 0.1323], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 33 - 231: dog - cat || Loss: 1.1806062459945679\n",
      "tensor([0., 1.]) tensor([0.8673, 0.1327], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 33 - 232: dog - cat || Loss: 1.1802880764007568\n",
      "tensor([0., 1.]) tensor([0.8670, 0.1330], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 33 - 233: dog - cat || Loss: 1.1799685955047607\n",
      "tensor([0., 1.]) tensor([0.8667, 0.1333], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 33 - 234: dog - cat || Loss: 1.17964768409729\n",
      "tensor([0., 1.]) tensor([0.8664, 0.1336], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 33 - 235: dog - cat || Loss: 1.1793253421783447\n",
      "tensor([0., 1.]) tensor([0.8661, 0.1339], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 33 - 236: dog - cat || Loss: 1.1790016889572144\n",
      "tensor([0., 1.]) tensor([0.8657, 0.1343], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 33 - 237: dog - cat || Loss: 1.1786770820617676\n",
      "tensor([0., 1.]) tensor([0.8654, 0.1346], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 33 - 238: dog - cat || Loss: 1.1783511638641357\n",
      "tensor([0., 1.]) tensor([0.8651, 0.1349], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 33 - 239: dog - cat || Loss: 1.1780239343643188\n",
      "tensor([0., 1.]) tensor([0.8648, 0.1352], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 33 - 240: dog - cat || Loss: 1.177695631980896\n",
      "tensor([0., 1.]) tensor([0.8644, 0.1356], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 33 - 241: dog - cat || Loss: 1.1773664951324463\n",
      "tensor([0., 1.]) tensor([0.8641, 0.1359], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 33 - 242: dog - cat || Loss: 1.1770360469818115\n",
      "tensor([0., 1.]) tensor([0.8638, 0.1362], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 33 - 243: dog - cat || Loss: 1.1767046451568604\n",
      "tensor([0., 1.]) tensor([0.8634, 0.1366], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 33 - 244: dog - cat || Loss: 1.1763725280761719\n",
      "tensor([0., 1.]) tensor([0.8631, 0.1369], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 33 - 245: dog - cat || Loss: 1.1760390996932983\n",
      "tensor([0., 1.]) tensor([0.8628, 0.1372], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 33 - 246: dog - cat || Loss: 1.175704836845398\n",
      "tensor([0., 1.]) tensor([0.8624, 0.1376], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 33 - 247: dog - cat || Loss: 1.1753696203231812\n",
      "tensor([0., 1.]) tensor([0.8621, 0.1379], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 33 - 248: dog - cat || Loss: 1.1750335693359375\n",
      "tensor([0., 1.]) tensor([0.8618, 0.1382], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 33 - 249: dog - cat || Loss: 1.174696445465088\n",
      "tensor([0., 1.]) tensor([0.8614, 0.1386], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 33 - 250: dog - cat || Loss: 1.174358606338501\n",
      "tensor([0., 1.]) tensor([0.8611, 0.1389], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 33 - 251: dog - cat || Loss: 1.1740199327468872\n",
      "tensor([0., 1.]) tensor([0.8608, 0.1392], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 33 - 252: dog - cat || Loss: 1.173680067062378\n",
      "tensor([0., 1.]) tensor([0.8604, 0.1396], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 33 - 253: dog - cat || Loss: 1.1733394861221313\n",
      "tensor([0., 1.]) tensor([0.8601, 0.1399], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 33 - 254: dog - cat || Loss: 1.172998070716858\n",
      "tensor([0., 1.]) tensor([0.8597, 0.1403], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 33 - 255: dog - cat || Loss: 1.1726559400558472\n",
      "tensor([0., 1.]) tensor([0.8594, 0.1406], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 33 - 256: dog - cat || Loss: 1.17231285572052\n",
      "tensor([0., 1.]) tensor([0.8591, 0.1409], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 33 - 257: dog - cat || Loss: 1.1719688177108765\n",
      "tensor([0., 1.]) tensor([0.8587, 0.1413], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 33 - 258: dog - cat || Loss: 1.1716243028640747\n",
      "tensor([0., 1.]) tensor([0.8584, 0.1416], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 33 - 259: dog - cat || Loss: 1.171278715133667\n",
      "tensor([0., 1.]) tensor([0.8580, 0.1420], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 33 - 260: dog - cat || Loss: 1.1709322929382324\n",
      "tensor([0., 1.]) tensor([0.8577, 0.1423], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 33 - 261: dog - cat || Loss: 1.170585036277771\n",
      "tensor([0., 1.]) tensor([0.8573, 0.1427], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 33 - 262: dog - cat || Loss: 1.1702369451522827\n",
      "tensor([0., 1.]) tensor([0.8570, 0.1430], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 33 - 263: dog - cat || Loss: 1.1698880195617676\n",
      "tensor([0., 1.]) tensor([0.8566, 0.1434], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 33 - 264: dog - cat || Loss: 1.1695384979248047\n",
      "tensor([0., 1.]) tensor([0.8563, 0.1437], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 33 - 265: dog - cat || Loss: 1.1691879034042358\n",
      "tensor([0., 1.]) tensor([0.8559, 0.1441], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 33 - 266: dog - cat || Loss: 1.1688367128372192\n",
      "tensor([0., 1.]) tensor([0.8556, 0.1444], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 33 - 267: dog - cat || Loss: 1.1684845685958862\n",
      "tensor([0., 1.]) tensor([0.8552, 0.1448], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 33 - 268: dog - cat || Loss: 1.1681315898895264\n",
      "tensor([0., 1.]) tensor([0.8549, 0.1451], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 33 - 269: dog - cat || Loss: 1.1677777767181396\n",
      "tensor([0., 1.]) tensor([0.8545, 0.1455], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 33 - 270: dog - cat || Loss: 1.1674233675003052\n",
      "tensor([0., 1.]) tensor([0.8542, 0.1458], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 33 - 271: dog - cat || Loss: 1.1670681238174438\n",
      "tensor([0., 1.]) tensor([0.8538, 0.1462], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 33 - 272: dog - cat || Loss: 1.1667118072509766\n",
      "tensor([0., 1.]) tensor([0.8535, 0.1465], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 33 - 273: dog - cat || Loss: 1.166355013847351\n",
      "tensor([0., 1.]) tensor([0.8531, 0.1469], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 33 - 274: dog - cat || Loss: 1.16599702835083\n",
      "tensor([0., 1.]) tensor([0.8527, 0.1473], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 33 - 275: dog - cat || Loss: 1.1656385660171509\n",
      "tensor([0., 1.]) tensor([0.8524, 0.1476], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 33 - 276: dog - cat || Loss: 1.1652792692184448\n",
      "tensor([0., 1.]) tensor([0.8520, 0.1480], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 33 - 277: dog - cat || Loss: 1.1649190187454224\n",
      "tensor([0., 1.]) tensor([0.8517, 0.1483], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 33 - 278: dog - cat || Loss: 1.1645580530166626\n",
      "tensor([0., 1.]) tensor([0.8513, 0.1487], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 33 - 279: dog - cat || Loss: 1.164196252822876\n",
      "tensor([0., 1.]) tensor([0.8509, 0.1491], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 33 - 280: dog - cat || Loss: 1.1638336181640625\n",
      "tensor([0., 1.]) tensor([0.8506, 0.1494], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 33 - 281: dog - cat || Loss: 1.1634701490402222\n",
      "tensor([0., 1.]) tensor([0.8502, 0.1498], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 33 - 282: dog - cat || Loss: 1.1631059646606445\n",
      "tensor([0., 1.]) tensor([0.8498, 0.1502], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 33 - 283: dog - cat || Loss: 1.16274094581604\n",
      "tensor([0., 1.]) tensor([0.8495, 0.1505], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 33 - 284: dog - cat || Loss: 1.1623749732971191\n",
      "tensor([0., 1.]) tensor([0.8491, 0.1509], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 33 - 285: dog - cat || Loss: 1.1620084047317505\n",
      "tensor([0., 1.]) tensor([0.8487, 0.1513], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 33 - 286: dog - cat || Loss: 1.1616408824920654\n",
      "tensor([0., 1.]) tensor([0.8484, 0.1516], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 33 - 287: dog - cat || Loss: 1.1612725257873535\n",
      "tensor([0., 1.]) tensor([0.8480, 0.1520], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 33 - 288: dog - cat || Loss: 1.1609034538269043\n",
      "tensor([0., 1.]) tensor([0.8476, 0.1524], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 33 - 289: dog - cat || Loss: 1.1605335474014282\n",
      "tensor([0., 1.]) tensor([0.8473, 0.1527], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 33 - 290: dog - cat || Loss: 1.1601628065109253\n",
      "tensor([0., 1.]) tensor([0.8469, 0.1531], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 33 - 291: dog - cat || Loss: 1.1597912311553955\n",
      "tensor([0., 1.]) tensor([0.8465, 0.1535], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 33 - 292: dog - cat || Loss: 1.1594188213348389\n",
      "tensor([0., 1.]) tensor([0.8462, 0.1538], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 33 - 293: dog - cat || Loss: 1.1590455770492554\n",
      "tensor([0., 1.]) tensor([0.8458, 0.1542], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 33 - 294: dog - cat || Loss: 1.1586717367172241\n",
      "tensor([0., 1.]) tensor([0.8454, 0.1546], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 33 - 295: dog - cat || Loss: 1.158296823501587\n",
      "tensor([0., 1.]) tensor([0.8450, 0.1550], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 33 - 296: dog - cat || Loss: 1.1579211950302124\n",
      "tensor([0., 1.]) tensor([0.8447, 0.1553], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 33 - 297: dog - cat || Loss: 1.157544732093811\n",
      "tensor([0., 1.]) tensor([0.8443, 0.1557], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 33 - 298: dog - cat || Loss: 1.1571675539016724\n",
      "tensor([0., 1.]) tensor([0.8439, 0.1561], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 33 - 299: dog - cat || Loss: 1.1567891836166382\n",
      "tensor([0., 1.]) tensor([0.8435, 0.1565], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 33 - 300: dog - cat || Loss: 1.1564103364944458\n",
      "tensor([0., 1.]) tensor([0.8431, 0.1569], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 33 - 301: dog - cat || Loss: 1.156030535697937\n",
      "tensor([0., 1.]) tensor([0.8428, 0.1572], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 33 - 302: dog - cat || Loss: 1.15565025806427\n",
      "tensor([0., 1.]) tensor([0.8424, 0.1576], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 33 - 303: dog - cat || Loss: 1.155268669128418\n",
      "tensor([0., 1.]) tensor([0.8420, 0.1580], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 33 - 304: dog - cat || Loss: 1.1548864841461182\n",
      "tensor([0., 1.]) tensor([0.8416, 0.1584], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 33 - 305: dog - cat || Loss: 1.154503345489502\n",
      "tensor([0., 1.]) tensor([0.8412, 0.1588], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 33 - 306: dog - cat || Loss: 1.1541194915771484\n",
      "tensor([0., 1.]) tensor([0.8409, 0.1591], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 33 - 307: dog - cat || Loss: 1.153734803199768\n",
      "tensor([0., 1.]) tensor([0.8405, 0.1595], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 33 - 308: dog - cat || Loss: 1.1533492803573608\n",
      "tensor([0., 1.]) tensor([0.8401, 0.1599], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 33 - 309: dog - cat || Loss: 1.1529630422592163\n",
      "tensor([0., 1.]) tensor([0.8397, 0.1603], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 33 - 310: dog - cat || Loss: 1.1525758504867554\n",
      "tensor([0., 1.]) tensor([0.8393, 0.1607], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 33 - 311: dog - cat || Loss: 1.1521878242492676\n",
      "tensor([0., 1.]) tensor([0.8389, 0.1611], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 33 - 312: dog - cat || Loss: 1.1517988443374634\n",
      "tensor([0., 1.]) tensor([0.8385, 0.1615], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 33 - 313: dog - cat || Loss: 1.1514092683792114\n",
      "tensor([0., 1.]) tensor([0.8381, 0.1619], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 33 - 314: dog - cat || Loss: 1.1510186195373535\n",
      "tensor([0., 1.]) tensor([0.8378, 0.1622], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 33 - 315: dog - cat || Loss: 1.1506274938583374\n",
      "tensor([0., 1.]) tensor([0.8374, 0.1626], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 33 - 316: dog - cat || Loss: 1.1502352952957153\n",
      "tensor([0., 1.]) tensor([0.8370, 0.1630], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 33 - 317: dog - cat || Loss: 1.149842381477356\n",
      "tensor([0., 1.]) tensor([0.8366, 0.1634], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 33 - 318: dog - cat || Loss: 1.1494483947753906\n",
      "tensor([0., 1.]) tensor([0.8362, 0.1638], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 33 - 319: dog - cat || Loss: 1.149053692817688\n",
      "tensor([0., 1.]) tensor([0.8358, 0.1642], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 33 - 320: dog - cat || Loss: 1.148658275604248\n",
      "tensor([0., 1.]) tensor([0.8354, 0.1646], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 33 - 321: dog - cat || Loss: 1.1482619047164917\n",
      "tensor([0., 1.]) tensor([0.8350, 0.1650], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 33 - 322: dog - cat || Loss: 1.147864818572998\n",
      "tensor([0., 1.]) tensor([0.8346, 0.1654], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 33 - 323: dog - cat || Loss: 1.1474665403366089\n",
      "tensor([0., 1.]) tensor([0.8342, 0.1658], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 33 - 324: dog - cat || Loss: 1.147067666053772\n",
      "tensor([0., 1.]) tensor([0.8338, 0.1662], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 33 - 325: dog - cat || Loss: 1.1466680765151978\n",
      "tensor([0., 1.]) tensor([0.8334, 0.1666], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 33 - 326: dog - cat || Loss: 1.1462674140930176\n",
      "tensor([0., 1.]) tensor([0.8330, 0.1670], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 33 - 327: dog - cat || Loss: 1.1458659172058105\n",
      "tensor([0., 1.]) tensor([0.8326, 0.1674], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 33 - 328: dog - cat || Loss: 1.1454635858535767\n",
      "tensor([0., 1.]) tensor([0.8322, 0.1678], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 33 - 329: dog - cat || Loss: 1.1450605392456055\n",
      "tensor([0., 1.]) tensor([0.8318, 0.1682], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 33 - 330: dog - cat || Loss: 1.1446566581726074\n",
      "tensor([0., 1.]) tensor([0.8314, 0.1686], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 33 - 331: dog - cat || Loss: 1.1442517042160034\n",
      "tensor([0., 1.]) tensor([0.8310, 0.1690], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 33 - 332: dog - cat || Loss: 1.1438461542129517\n",
      "tensor([0., 1.]) tensor([0.8306, 0.1694], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 33 - 333: dog - cat || Loss: 1.143439531326294\n",
      "tensor([0., 1.]) tensor([0.8302, 0.1698], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 33 - 334: dog - cat || Loss: 1.1430320739746094\n",
      "tensor([0., 1.]) tensor([0.8298, 0.1702], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 33 - 335: dog - cat || Loss: 1.1426239013671875\n",
      "tensor([0., 1.]) tensor([0.8294, 0.1706], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 33 - 336: dog - cat || Loss: 1.1422148942947388\n",
      "tensor([0., 1.]) tensor([0.8290, 0.1710], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 33 - 337: dog - cat || Loss: 1.1418049335479736\n",
      "tensor([0., 1.]) tensor([0.8285, 0.1715], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 33 - 338: dog - cat || Loss: 1.1413941383361816\n",
      "tensor([0., 1.]) tensor([0.8281, 0.1719], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 33 - 339: dog - cat || Loss: 1.1409823894500732\n",
      "tensor([0., 1.]) tensor([0.8277, 0.1723], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 33 - 340: dog - cat || Loss: 1.140569806098938\n",
      "tensor([0., 1.]) tensor([0.8273, 0.1727], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 33 - 341: dog - cat || Loss: 1.1401565074920654\n",
      "tensor([0., 1.]) tensor([0.8269, 0.1731], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 33 - 342: dog - cat || Loss: 1.139742136001587\n",
      "tensor([0., 1.]) tensor([0.8265, 0.1735], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 33 - 343: dog - cat || Loss: 1.139327049255371\n",
      "tensor([0., 1.]) tensor([0.8261, 0.1739], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 33 - 344: dog - cat || Loss: 1.1389110088348389\n",
      "tensor([0., 1.]) tensor([0.8256, 0.1744], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 33 - 345: dog - cat || Loss: 1.1384942531585693\n",
      "tensor([0., 1.]) tensor([0.8252, 0.1748], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 33 - 346: dog - cat || Loss: 1.1380765438079834\n",
      "tensor([0., 1.]) tensor([0.8248, 0.1752], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 33 - 347: dog - cat || Loss: 1.1376579999923706\n",
      "tensor([0., 1.]) tensor([0.8244, 0.1756], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 33 - 348: dog - cat || Loss: 1.1372385025024414\n",
      "tensor([0., 1.]) tensor([0.8240, 0.1760], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 33 - 349: dog - cat || Loss: 1.136818289756775\n",
      "tensor([0., 1.]) tensor([0.8236, 0.1764], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 33 - 350: dog - cat || Loss: 1.136397123336792\n",
      "tensor([0., 1.]) tensor([0.8231, 0.1769], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 33 - 351: dog - cat || Loss: 1.1359751224517822\n",
      "tensor([0., 1.]) tensor([0.8227, 0.1773], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 33 - 352: dog - cat || Loss: 1.1355522871017456\n",
      "tensor([0., 1.]) tensor([0.8223, 0.1777], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 33 - 353: dog - cat || Loss: 1.1351284980773926\n",
      "tensor([0., 1.]) tensor([0.8219, 0.1781], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 33 - 354: dog - cat || Loss: 1.1347036361694336\n",
      "tensor([0., 1.]) tensor([0.8214, 0.1786], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 33 - 355: dog - cat || Loss: 1.1342782974243164\n",
      "tensor([0., 1.]) tensor([0.8210, 0.1790], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 33 - 356: dog - cat || Loss: 1.1338520050048828\n",
      "tensor([0., 1.]) tensor([0.8206, 0.1794], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 33 - 357: dog - cat || Loss: 1.1334247589111328\n",
      "tensor([0., 1.]) tensor([0.8202, 0.1798], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 33 - 358: dog - cat || Loss: 1.1329967975616455\n",
      "tensor([0., 1.]) tensor([0.8197, 0.1803], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 33 - 359: dog - cat || Loss: 1.1325677633285522\n",
      "tensor([0., 1.]) tensor([0.8193, 0.1807], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 33 - 360: dog - cat || Loss: 1.1321377754211426\n",
      "tensor([0., 1.]) tensor([0.8189, 0.1811], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 33 - 361: dog - cat || Loss: 1.1317070722579956\n",
      "tensor([0., 1.]) tensor([0.8184, 0.1816], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 33 - 362: dog - cat || Loss: 1.1312755346298218\n",
      "tensor([0., 1.]) tensor([0.8180, 0.1820], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 33 - 363: dog - cat || Loss: 1.130843162536621\n",
      "tensor([0., 1.]) tensor([0.8176, 0.1824], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 33 - 364: dog - cat || Loss: 1.130409598350525\n",
      "tensor([0., 1.]) tensor([0.8171, 0.1829], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 33 - 365: dog - cat || Loss: 1.12997567653656\n",
      "tensor([0., 1.]) tensor([0.8167, 0.1833], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 33 - 366: dog - cat || Loss: 1.1295405626296997\n",
      "tensor([0., 1.]) tensor([0.8163, 0.1837], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 33 - 367: dog - cat || Loss: 1.1291046142578125\n",
      "tensor([0., 1.]) tensor([0.8158, 0.1842], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 33 - 368: dog - cat || Loss: 1.1286677122116089\n",
      "tensor([0., 1.]) tensor([0.8154, 0.1846], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 33 - 369: dog - cat || Loss: 1.128230094909668\n",
      "tensor([0., 1.]) tensor([0.8150, 0.1850], grad_fn=<SoftmaxBackward0>)\n",
      "=====epoch:34=====\n",
      "Epoch 34 - 0: cat - cat || Loss: 0.498731791973114\n",
      "tensor([1., 0.]) tensor([0.8145, 0.1855], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 34 - 1: cat - cat || Loss: 0.4990825057029724\n",
      "tensor([1., 0.]) tensor([0.8142, 0.1858], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 34 - 2: cat - cat || Loss: 0.4993540048599243\n",
      "tensor([1., 0.]) tensor([0.8139, 0.1861], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 34 - 3: cat - cat || Loss: 0.49955397844314575\n",
      "tensor([1., 0.]) tensor([0.8137, 0.1863], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 34 - 4: cat - cat || Loss: 0.499689519405365\n",
      "tensor([1., 0.]) tensor([0.8136, 0.1864], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 34 - 5: cat - cat || Loss: 0.4997670352458954\n",
      "tensor([1., 0.]) tensor([0.8135, 0.1865], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 34 - 6: cat - cat || Loss: 0.49979227781295776\n",
      "tensor([1., 0.]) tensor([0.8135, 0.1865], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 34 - 7: cat - cat || Loss: 0.4997703433036804\n",
      "tensor([1., 0.]) tensor([0.8135, 0.1865], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 34 - 8: cat - cat || Loss: 0.4997061491012573\n",
      "tensor([1., 0.]) tensor([0.8136, 0.1864], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 34 - 9: cat - cat || Loss: 0.49960392713546753\n",
      "tensor([1., 0.]) tensor([0.8137, 0.1863], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 34 - 10: cat - cat || Loss: 0.4994673430919647\n",
      "tensor([1., 0.]) tensor([0.8138, 0.1862], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 34 - 11: cat - cat || Loss: 0.49930015206336975\n",
      "tensor([1., 0.]) tensor([0.8140, 0.1860], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 34 - 12: cat - cat || Loss: 0.4991052746772766\n",
      "tensor([1., 0.]) tensor([0.8142, 0.1858], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 34 - 13: cat - cat || Loss: 0.4988856315612793\n",
      "tensor([1., 0.]) tensor([0.8144, 0.1856], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 34 - 14: cat - cat || Loss: 0.498643696308136\n",
      "tensor([1., 0.]) tensor([0.8146, 0.1854], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 34 - 15: cat - cat || Loss: 0.4983817934989929\n",
      "tensor([1., 0.]) tensor([0.8149, 0.1851], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 34 - 16: cat - cat || Loss: 0.49810200929641724\n",
      "tensor([1., 0.]) tensor([0.8152, 0.1848], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 34 - 17: cat - cat || Loss: 0.497806191444397\n",
      "tensor([1., 0.]) tensor([0.8155, 0.1845], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 34 - 18: cat - cat || Loss: 0.4974960386753082\n",
      "tensor([1., 0.]) tensor([0.8158, 0.1842], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 34 - 19: cat - cat || Loss: 0.4971730709075928\n",
      "tensor([1., 0.]) tensor([0.8161, 0.1839], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 34 - 20: cat - cat || Loss: 0.4968385696411133\n",
      "tensor([1., 0.]) tensor([0.8164, 0.1836], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 34 - 21: cat - cat || Loss: 0.49649396538734436\n",
      "tensor([1., 0.]) tensor([0.8168, 0.1832], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 34 - 22: cat - cat || Loss: 0.4961402416229248\n",
      "tensor([1., 0.]) tensor([0.8171, 0.1829], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 34 - 23: cat - cat || Loss: 0.49577832221984863\n",
      "tensor([1., 0.]) tensor([0.8175, 0.1825], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 34 - 24: cat - cat || Loss: 0.49540913105010986\n",
      "tensor([1., 0.]) tensor([0.8179, 0.1821], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 34 - 25: cat - cat || Loss: 0.4950336217880249\n",
      "tensor([1., 0.]) tensor([0.8182, 0.1818], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 34 - 26: cat - cat || Loss: 0.49465250968933105\n",
      "tensor([1., 0.]) tensor([0.8186, 0.1814], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 34 - 27: cat - cat || Loss: 0.4942663013935089\n",
      "tensor([1., 0.]) tensor([0.8190, 0.1810], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 34 - 28: cat - cat || Loss: 0.4938756227493286\n",
      "tensor([1., 0.]) tensor([0.8194, 0.1806], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 34 - 29: cat - cat || Loss: 0.49348098039627075\n",
      "tensor([1., 0.]) tensor([0.8198, 0.1802], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 34 - 30: cat - cat || Loss: 0.49308305978775024\n",
      "tensor([1., 0.]) tensor([0.8202, 0.1798], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 34 - 31: cat - cat || Loss: 0.49268198013305664\n",
      "tensor([1., 0.]) tensor([0.8206, 0.1794], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 34 - 32: cat - cat || Loss: 0.49227842688560486\n",
      "tensor([1., 0.]) tensor([0.8210, 0.1790], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 34 - 33: cat - cat || Loss: 0.4918726086616516\n",
      "tensor([1., 0.]) tensor([0.8214, 0.1786], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 34 - 34: cat - cat || Loss: 0.49146485328674316\n",
      "tensor([1., 0.]) tensor([0.8218, 0.1782], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 34 - 35: cat - cat || Loss: 0.491055428981781\n",
      "tensor([1., 0.]) tensor([0.8222, 0.1778], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 34 - 36: cat - cat || Loss: 0.490644633769989\n",
      "tensor([1., 0.]) tensor([0.8226, 0.1774], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 34 - 37: cat - cat || Loss: 0.4902327060699463\n",
      "tensor([1., 0.]) tensor([0.8230, 0.1770], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 34 - 38: cat - cat || Loss: 0.4898196756839752\n",
      "tensor([1., 0.]) tensor([0.8234, 0.1766], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 34 - 39: cat - cat || Loss: 0.48940593004226685\n",
      "tensor([1., 0.]) tensor([0.8239, 0.1761], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 34 - 40: cat - cat || Loss: 0.4889916777610779\n",
      "tensor([1., 0.]) tensor([0.8243, 0.1757], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 34 - 41: cat - cat || Loss: 0.488576740026474\n",
      "tensor([1., 0.]) tensor([0.8247, 0.1753], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 34 - 42: cat - cat || Loss: 0.48816174268722534\n",
      "tensor([1., 0.]) tensor([0.8251, 0.1749], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 34 - 43: cat - cat || Loss: 0.48774635791778564\n",
      "tensor([1., 0.]) tensor([0.8255, 0.1745], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 34 - 44: cat - cat || Loss: 0.48733097314834595\n",
      "tensor([1., 0.]) tensor([0.8259, 0.1741], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 34 - 45: cat - cat || Loss: 0.48691558837890625\n",
      "tensor([1., 0.]) tensor([0.8263, 0.1737], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 34 - 46: cat - cat || Loss: 0.48650026321411133\n",
      "tensor([1., 0.]) tensor([0.8268, 0.1732], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 34 - 47: cat - cat || Loss: 0.48608505725860596\n",
      "tensor([1., 0.]) tensor([0.8272, 0.1728], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 34 - 48: cat - cat || Loss: 0.4856700897216797\n",
      "tensor([1., 0.]) tensor([0.8276, 0.1724], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 34 - 49: cat - cat || Loss: 0.48525553941726685\n",
      "tensor([1., 0.]) tensor([0.8280, 0.1720], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 34 - 50: cat - cat || Loss: 0.4848412871360779\n",
      "tensor([1., 0.]) tensor([0.8284, 0.1716], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 34 - 51: cat - cat || Loss: 0.4844275712966919\n",
      "tensor([1., 0.]) tensor([0.8288, 0.1712], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 34 - 52: cat - cat || Loss: 0.4840141832828522\n",
      "tensor([1., 0.]) tensor([0.8292, 0.1708], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 34 - 53: cat - cat || Loss: 0.483601450920105\n",
      "tensor([1., 0.]) tensor([0.8297, 0.1703], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 34 - 54: cat - cat || Loss: 0.4831892251968384\n",
      "tensor([1., 0.]) tensor([0.8301, 0.1699], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 34 - 55: cat - cat || Loss: 0.48277759552001953\n",
      "tensor([1., 0.]) tensor([0.8305, 0.1695], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 34 - 56: cat - cat || Loss: 0.48236653208732605\n",
      "tensor([1., 0.]) tensor([0.8309, 0.1691], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 34 - 57: cat - cat || Loss: 0.48195600509643555\n",
      "tensor([1., 0.]) tensor([0.8313, 0.1687], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 34 - 58: cat - cat || Loss: 0.4815463721752167\n",
      "tensor([1., 0.]) tensor([0.8317, 0.1683], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 34 - 59: cat - cat || Loss: 0.48113739490509033\n",
      "tensor([1., 0.]) tensor([0.8321, 0.1679], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 34 - 60: cat - cat || Loss: 0.48072904348373413\n",
      "tensor([1., 0.]) tensor([0.8325, 0.1675], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 34 - 61: cat - cat || Loss: 0.48032131791114807\n",
      "tensor([1., 0.]) tensor([0.8329, 0.1671], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 34 - 62: cat - cat || Loss: 0.47991442680358887\n",
      "tensor([1., 0.]) tensor([0.8333, 0.1667], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 34 - 63: cat - cat || Loss: 0.47950831055641174\n",
      "tensor([1., 0.]) tensor([0.8338, 0.1662], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 34 - 64: cat - cat || Loss: 0.4791029095649719\n",
      "tensor([1., 0.]) tensor([0.8342, 0.1658], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 34 - 65: cat - cat || Loss: 0.4786982536315918\n",
      "tensor([1., 0.]) tensor([0.8346, 0.1654], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 34 - 66: cat - cat || Loss: 0.4782944321632385\n",
      "tensor([1., 0.]) tensor([0.8350, 0.1650], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 34 - 67: cat - cat || Loss: 0.4778914451599121\n",
      "tensor([1., 0.]) tensor([0.8354, 0.1646], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 34 - 68: cat - cat || Loss: 0.477489173412323\n",
      "tensor([1., 0.]) tensor([0.8358, 0.1642], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 34 - 69: cat - cat || Loss: 0.47708770632743835\n",
      "tensor([1., 0.]) tensor([0.8362, 0.1638], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 34 - 70: cat - cat || Loss: 0.47668710350990295\n",
      "tensor([1., 0.]) tensor([0.8366, 0.1634], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 34 - 71: cat - cat || Loss: 0.4762873351573944\n",
      "tensor([1., 0.]) tensor([0.8370, 0.1630], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 34 - 72: cat - cat || Loss: 0.47588834166526794\n",
      "tensor([1., 0.]) tensor([0.8374, 0.1626], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 34 - 73: cat - cat || Loss: 0.4754902124404907\n",
      "tensor([1., 0.]) tensor([0.8378, 0.1622], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 34 - 74: cat - cat || Loss: 0.4750927686691284\n",
      "tensor([1., 0.]) tensor([0.8382, 0.1618], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 34 - 75: cat - cat || Loss: 0.4746963381767273\n",
      "tensor([1., 0.]) tensor([0.8386, 0.1614], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 34 - 76: cat - cat || Loss: 0.47430065274238586\n",
      "tensor([1., 0.]) tensor([0.8390, 0.1610], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 34 - 77: cat - cat || Loss: 0.47390592098236084\n",
      "tensor([1., 0.]) tensor([0.8394, 0.1606], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 34 - 78: cat - cat || Loss: 0.47351187467575073\n",
      "tensor([1., 0.]) tensor([0.8397, 0.1603], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 34 - 79: cat - cat || Loss: 0.47311878204345703\n",
      "tensor([1., 0.]) tensor([0.8401, 0.1599], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 34 - 80: cat - cat || Loss: 0.4727264642715454\n",
      "tensor([1., 0.]) tensor([0.8405, 0.1595], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 34 - 81: cat - cat || Loss: 0.47233492136001587\n",
      "tensor([1., 0.]) tensor([0.8409, 0.1591], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 34 - 82: cat - cat || Loss: 0.47194424271583557\n",
      "tensor([1., 0.]) tensor([0.8413, 0.1587], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 34 - 83: cat - cat || Loss: 0.4715545177459717\n",
      "tensor([1., 0.]) tensor([0.8417, 0.1583], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 34 - 84: cat - cat || Loss: 0.47116562724113464\n",
      "tensor([1., 0.]) tensor([0.8421, 0.1579], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 34 - 85: cat - cat || Loss: 0.47077757120132446\n",
      "tensor([1., 0.]) tensor([0.8425, 0.1575], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 34 - 86: cat - cat || Loss: 0.4703903794288635\n",
      "tensor([1., 0.]) tensor([0.8429, 0.1571], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 34 - 87: cat - cat || Loss: 0.47000396251678467\n",
      "tensor([1., 0.]) tensor([0.8433, 0.1567], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 34 - 88: cat - cat || Loss: 0.4696184992790222\n",
      "tensor([1., 0.]) tensor([0.8436, 0.1564], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 34 - 89: cat - cat || Loss: 0.46923375129699707\n",
      "tensor([1., 0.]) tensor([0.8440, 0.1560], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 34 - 90: cat - cat || Loss: 0.46884995698928833\n",
      "tensor([1., 0.]) tensor([0.8444, 0.1556], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 34 - 91: cat - cat || Loss: 0.4684669077396393\n",
      "tensor([1., 0.]) tensor([0.8448, 0.1552], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 34 - 92: cat - cat || Loss: 0.46808481216430664\n",
      "tensor([1., 0.]) tensor([0.8452, 0.1548], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 34 - 93: cat - cat || Loss: 0.46770358085632324\n",
      "tensor([1., 0.]) tensor([0.8456, 0.1544], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 34 - 94: cat - cat || Loss: 0.4673231244087219\n",
      "tensor([1., 0.]) tensor([0.8459, 0.1541], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 34 - 95: cat - cat || Loss: 0.46694350242614746\n",
      "tensor([1., 0.]) tensor([0.8463, 0.1537], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 34 - 96: cat - cat || Loss: 0.466564804315567\n",
      "tensor([1., 0.]) tensor([0.8467, 0.1533], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 34 - 97: cat - cat || Loss: 0.46618688106536865\n",
      "tensor([1., 0.]) tensor([0.8471, 0.1529], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 34 - 98: cat - cat || Loss: 0.46580982208251953\n",
      "tensor([1., 0.]) tensor([0.8475, 0.1525], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 34 - 99: cat - cat || Loss: 0.46543368697166443\n",
      "tensor([1., 0.]) tensor([0.8478, 0.1522], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 34 - 100: cat - cat || Loss: 0.4650583267211914\n",
      "tensor([1., 0.]) tensor([0.8482, 0.1518], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 34 - 101: cat - cat || Loss: 0.4646838307380676\n",
      "tensor([1., 0.]) tensor([0.8486, 0.1514], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 34 - 102: cat - cat || Loss: 0.46431025862693787\n",
      "tensor([1., 0.]) tensor([0.8490, 0.1510], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 34 - 103: cat - cat || Loss: 0.46393728256225586\n",
      "tensor([1., 0.]) tensor([0.8493, 0.1507], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 34 - 104: cat - cat || Loss: 0.4635653495788574\n",
      "tensor([1., 0.]) tensor([0.8497, 0.1503], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 34 - 105: cat - cat || Loss: 0.4631943106651306\n",
      "tensor([1., 0.]) tensor([0.8501, 0.1499], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 34 - 106: cat - cat || Loss: 0.4628239870071411\n",
      "tensor([1., 0.]) tensor([0.8504, 0.1496], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 34 - 107: cat - cat || Loss: 0.46245449781417847\n",
      "tensor([1., 0.]) tensor([0.8508, 0.1492], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 34 - 108: cat - cat || Loss: 0.46208590269088745\n",
      "tensor([1., 0.]) tensor([0.8512, 0.1488], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 34 - 109: cat - cat || Loss: 0.46171820163726807\n",
      "tensor([1., 0.]) tensor([0.8515, 0.1485], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 34 - 110: cat - cat || Loss: 0.4613511860370636\n",
      "tensor([1., 0.]) tensor([0.8519, 0.1481], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 34 - 111: cat - cat || Loss: 0.46098512411117554\n",
      "tensor([1., 0.]) tensor([0.8523, 0.1477], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 34 - 112: cat - cat || Loss: 0.46061986684799194\n",
      "tensor([1., 0.]) tensor([0.8526, 0.1474], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 34 - 113: cat - cat || Loss: 0.46025538444519043\n",
      "tensor([1., 0.]) tensor([0.8530, 0.1470], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 34 - 114: cat - cat || Loss: 0.45989173650741577\n",
      "tensor([1., 0.]) tensor([0.8534, 0.1466], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 34 - 115: cat - cat || Loss: 0.4595290720462799\n",
      "tensor([1., 0.]) tensor([0.8537, 0.1463], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 34 - 116: cat - cat || Loss: 0.45916712284088135\n",
      "tensor([1., 0.]) tensor([0.8541, 0.1459], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 34 - 117: cat - cat || Loss: 0.45880603790283203\n",
      "tensor([1., 0.]) tensor([0.8545, 0.1455], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 34 - 118: cat - cat || Loss: 0.45844578742980957\n",
      "tensor([1., 0.]) tensor([0.8548, 0.1452], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 34 - 119: cat - cat || Loss: 0.45808643102645874\n",
      "tensor([1., 0.]) tensor([0.8552, 0.1448], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 34 - 120: cat - cat || Loss: 0.4577277898788452\n",
      "tensor([1., 0.]) tensor([0.8555, 0.1445], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 34 - 121: cat - cat || Loss: 0.45736998319625854\n",
      "tensor([1., 0.]) tensor([0.8559, 0.1441], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 34 - 122: cat - cat || Loss: 0.4570130705833435\n",
      "tensor([1., 0.]) tensor([0.8562, 0.1438], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 34 - 123: cat - cat || Loss: 0.4566569924354553\n",
      "tensor([1., 0.]) tensor([0.8566, 0.1434], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 34 - 124: cat - cat || Loss: 0.456301748752594\n",
      "tensor([1., 0.]) tensor([0.8570, 0.1430], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 34 - 125: cat - cat || Loss: 0.45594727993011475\n",
      "tensor([1., 0.]) tensor([0.8573, 0.1427], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 34 - 126: cat - cat || Loss: 0.45559361577033997\n",
      "tensor([1., 0.]) tensor([0.8577, 0.1423], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 34 - 127: cat - cat || Loss: 0.45524078607559204\n",
      "tensor([1., 0.]) tensor([0.8580, 0.1420], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 34 - 128: cat - cat || Loss: 0.45488879084587097\n",
      "tensor([1., 0.]) tensor([0.8584, 0.1416], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 34 - 129: cat - cat || Loss: 0.454537570476532\n",
      "tensor([1., 0.]) tensor([0.8587, 0.1413], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 34 - 130: cat - cat || Loss: 0.454187273979187\n",
      "tensor([1., 0.]) tensor([0.8591, 0.1409], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 34 - 131: cat - cat || Loss: 0.4538375735282898\n",
      "tensor([1., 0.]) tensor([0.8594, 0.1406], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 34 - 132: cat - cat || Loss: 0.453488826751709\n",
      "tensor([1., 0.]) tensor([0.8598, 0.1402], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 34 - 133: cat - cat || Loss: 0.4531410336494446\n",
      "tensor([1., 0.]) tensor([0.8601, 0.1399], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 34 - 134: cat - cat || Loss: 0.45279377698898315\n",
      "tensor([1., 0.]) tensor([0.8605, 0.1395], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 34 - 135: cat - cat || Loss: 0.4524475634098053\n",
      "tensor([1., 0.]) tensor([0.8608, 0.1392], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 34 - 136: cat - cat || Loss: 0.45210203528404236\n",
      "tensor([1., 0.]) tensor([0.8612, 0.1388], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 34 - 137: cat - cat || Loss: 0.4517573118209839\n",
      "tensor([1., 0.]) tensor([0.8615, 0.1385], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 34 - 138: cat - cat || Loss: 0.4514133930206299\n",
      "tensor([1., 0.]) tensor([0.8618, 0.1382], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 34 - 139: cat - cat || Loss: 0.4510703384876251\n",
      "tensor([1., 0.]) tensor([0.8622, 0.1378], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 34 - 140: cat - cat || Loss: 0.4507281184196472\n",
      "tensor([1., 0.]) tensor([0.8625, 0.1375], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 34 - 141: cat - cat || Loss: 0.45038658380508423\n",
      "tensor([1., 0.]) tensor([0.8629, 0.1371], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 34 - 142: cat - cat || Loss: 0.4500459134578705\n",
      "tensor([1., 0.]) tensor([0.8632, 0.1368], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 34 - 143: cat - cat || Loss: 0.4497060179710388\n",
      "tensor([1., 0.]) tensor([0.8636, 0.1364], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 34 - 144: cat - cat || Loss: 0.4493670165538788\n",
      "tensor([1., 0.]) tensor([0.8639, 0.1361], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 34 - 145: cat - cat || Loss: 0.44902873039245605\n",
      "tensor([1., 0.]) tensor([0.8642, 0.1358], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 34 - 146: cat - cat || Loss: 0.4486912786960602\n",
      "tensor([1., 0.]) tensor([0.8646, 0.1354], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 34 - 147: cat - cat || Loss: 0.4483546316623688\n",
      "tensor([1., 0.]) tensor([0.8649, 0.1351], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 34 - 148: cat - cat || Loss: 0.4480186402797699\n",
      "tensor([1., 0.]) tensor([0.8652, 0.1348], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 34 - 149: cat - cat || Loss: 0.4476836621761322\n",
      "tensor([1., 0.]) tensor([0.8656, 0.1344], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 34 - 150: cat - cat || Loss: 0.44734930992126465\n",
      "tensor([1., 0.]) tensor([0.8659, 0.1341], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 34 - 151: cat - cat || Loss: 0.44701582193374634\n",
      "tensor([1., 0.]) tensor([0.8662, 0.1338], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 34 - 152: cat - cat || Loss: 0.4466831386089325\n",
      "tensor([1., 0.]) tensor([0.8666, 0.1334], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 34 - 153: cat - cat || Loss: 0.44635123014450073\n",
      "tensor([1., 0.]) tensor([0.8669, 0.1331], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 34 - 154: cat - cat || Loss: 0.44602012634277344\n",
      "tensor([1., 0.]) tensor([0.8672, 0.1328], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 34 - 155: cat - cat || Loss: 0.4456897974014282\n",
      "tensor([1., 0.]) tensor([0.8676, 0.1324], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 34 - 156: cat - cat || Loss: 0.44536030292510986\n",
      "tensor([1., 0.]) tensor([0.8679, 0.1321], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 34 - 157: cat - cat || Loss: 0.44503164291381836\n",
      "tensor([1., 0.]) tensor([0.8682, 0.1318], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 34 - 158: cat - cat || Loss: 0.4447035491466522\n",
      "tensor([1., 0.]) tensor([0.8686, 0.1314], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 34 - 159: cat - cat || Loss: 0.4443764090538025\n",
      "tensor([1., 0.]) tensor([0.8689, 0.1311], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 34 - 160: cat - cat || Loss: 0.4440499544143677\n",
      "tensor([1., 0.]) tensor([0.8692, 0.1308], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 34 - 161: cat - cat || Loss: 0.4437244236469269\n",
      "tensor([1., 0.]) tensor([0.8695, 0.1305], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 34 - 162: cat - cat || Loss: 0.44339966773986816\n",
      "tensor([1., 0.]) tensor([0.8699, 0.1301], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 34 - 163: cat - cat || Loss: 0.4430755376815796\n",
      "tensor([1., 0.]) tensor([0.8702, 0.1298], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 34 - 164: cat - cat || Loss: 0.44275230169296265\n",
      "tensor([1., 0.]) tensor([0.8705, 0.1295], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 34 - 165: cat - cat || Loss: 0.442429780960083\n",
      "tensor([1., 0.]) tensor([0.8708, 0.1292], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 34 - 166: cat - cat || Loss: 0.44210803508758545\n",
      "tensor([1., 0.]) tensor([0.8712, 0.1288], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 34 - 167: cat - cat || Loss: 0.44178712368011475\n",
      "tensor([1., 0.]) tensor([0.8715, 0.1285], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 34 - 168: cat - cat || Loss: 0.44146692752838135\n",
      "tensor([1., 0.]) tensor([0.8718, 0.1282], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 34 - 169: cat - cat || Loss: 0.44114744663238525\n",
      "tensor([1., 0.]) tensor([0.8721, 0.1279], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 34 - 170: cat - cat || Loss: 0.440828800201416\n",
      "tensor([1., 0.]) tensor([0.8724, 0.1276], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 34 - 171: cat - cat || Loss: 0.44051092863082886\n",
      "tensor([1., 0.]) tensor([0.8728, 0.1272], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 34 - 172: cat - cat || Loss: 0.4401938319206238\n",
      "tensor([1., 0.]) tensor([0.8731, 0.1269], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 34 - 173: cat - cat || Loss: 0.4398775100708008\n",
      "tensor([1., 0.]) tensor([0.8734, 0.1266], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 34 - 174: cat - cat || Loss: 0.43956196308135986\n",
      "tensor([1., 0.]) tensor([0.8737, 0.1263], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 34 - 175: cat - cat || Loss: 0.43924710154533386\n",
      "tensor([1., 0.]) tensor([0.8740, 0.1260], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 34 - 176: cat - cat || Loss: 0.43893301486968994\n",
      "tensor([1., 0.]) tensor([0.8743, 0.1257], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 34 - 177: cat - cat || Loss: 0.43861979246139526\n",
      "tensor([1., 0.]) tensor([0.8746, 0.1254], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 34 - 178: cat - cat || Loss: 0.4383071959018707\n",
      "tensor([1., 0.]) tensor([0.8750, 0.1250], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 34 - 179: cat - cat || Loss: 0.43799546360969543\n",
      "tensor([1., 0.]) tensor([0.8753, 0.1247], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 34 - 180: cat - cat || Loss: 0.43768441677093506\n",
      "tensor([1., 0.]) tensor([0.8756, 0.1244], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 34 - 181: cat - cat || Loss: 0.43737414479255676\n",
      "tensor([1., 0.]) tensor([0.8759, 0.1241], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 34 - 182: cat - cat || Loss: 0.43706464767456055\n",
      "tensor([1., 0.]) tensor([0.8762, 0.1238], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 34 - 183: cat - cat || Loss: 0.4367559552192688\n",
      "tensor([1., 0.]) tensor([0.8765, 0.1235], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 34 - 184: cat - cat || Loss: 0.4364479184150696\n",
      "tensor([1., 0.]) tensor([0.8768, 0.1232], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 34 - 185: cat - cat || Loss: 0.436140775680542\n",
      "tensor([1., 0.]) tensor([0.8771, 0.1229], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 34 - 186: cat - cat || Loss: 0.4358341693878174\n",
      "tensor([1., 0.]) tensor([0.8774, 0.1226], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 34 - 187: cat - cat || Loss: 0.4355284571647644\n",
      "tensor([1., 0.]) tensor([0.8777, 0.1223], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 34 - 188: cat - cat || Loss: 0.43522340059280396\n",
      "tensor([1., 0.]) tensor([0.8780, 0.1220], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 34 - 189: cat - cat || Loss: 0.4349190890789032\n",
      "tensor([1., 0.]) tensor([0.8783, 0.1217], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 34 - 190: dog - cat || Loss: 1.1919078826904297\n",
      "tensor([0., 1.]) tensor([0.8786, 0.1214], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 34 - 191: dog - cat || Loss: 1.1921508312225342\n",
      "tensor([0., 1.]) tensor([0.8789, 0.1211], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 34 - 192: dog - cat || Loss: 1.192339301109314\n",
      "tensor([0., 1.]) tensor([0.8791, 0.1209], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 34 - 193: dog - cat || Loss: 1.192478895187378\n",
      "tensor([0., 1.]) tensor([0.8792, 0.1208], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 34 - 194: dog - cat || Loss: 1.1925747394561768\n",
      "tensor([0., 1.]) tensor([0.8793, 0.1207], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 34 - 195: dog - cat || Loss: 1.1926311254501343\n",
      "tensor([0., 1.]) tensor([0.8794, 0.1206], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 34 - 196: dog - cat || Loss: 1.1926519870758057\n",
      "tensor([0., 1.]) tensor([0.8794, 0.1206], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 34 - 197: dog - cat || Loss: 1.192640781402588\n",
      "tensor([0., 1.]) tensor([0.8794, 0.1206], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 34 - 198: dog - cat || Loss: 1.1926010847091675\n",
      "tensor([0., 1.]) tensor([0.8793, 0.1207], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 34 - 199: dog - cat || Loss: 1.1925355195999146\n",
      "tensor([0., 1.]) tensor([0.8793, 0.1207], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 34 - 200: dog - cat || Loss: 1.1924464702606201\n",
      "tensor([0., 1.]) tensor([0.8792, 0.1208], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 34 - 201: dog - cat || Loss: 1.1923365592956543\n",
      "tensor([0., 1.]) tensor([0.8791, 0.1209], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 34 - 202: dog - cat || Loss: 1.1922078132629395\n",
      "tensor([0., 1.]) tensor([0.8789, 0.1211], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 34 - 203: dog - cat || Loss: 1.1920617818832397\n",
      "tensor([0., 1.]) tensor([0.8788, 0.1212], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 34 - 204: dog - cat || Loss: 1.191900372505188\n",
      "tensor([0., 1.]) tensor([0.8786, 0.1214], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 34 - 205: dog - cat || Loss: 1.1917250156402588\n",
      "tensor([0., 1.]) tensor([0.8785, 0.1215], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 34 - 206: dog - cat || Loss: 1.1915371417999268\n",
      "tensor([0., 1.]) tensor([0.8783, 0.1217], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 34 - 207: dog - cat || Loss: 1.1913379430770874\n",
      "tensor([0., 1.]) tensor([0.8781, 0.1219], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 34 - 208: dog - cat || Loss: 1.191128134727478\n",
      "tensor([0., 1.]) tensor([0.8779, 0.1221], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 34 - 209: dog - cat || Loss: 1.1909091472625732\n",
      "tensor([0., 1.]) tensor([0.8776, 0.1224], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 34 - 210: dog - cat || Loss: 1.1906816959381104\n",
      "tensor([0., 1.]) tensor([0.8774, 0.1226], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 34 - 211: dog - cat || Loss: 1.1904464960098267\n",
      "tensor([0., 1.]) tensor([0.8772, 0.1228], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 34 - 212: dog - cat || Loss: 1.1902042627334595\n",
      "tensor([0., 1.]) tensor([0.8769, 0.1231], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 34 - 213: dog - cat || Loss: 1.1899555921554565\n",
      "tensor([0., 1.]) tensor([0.8767, 0.1233], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 34 - 214: dog - cat || Loss: 1.1897011995315552\n",
      "tensor([0., 1.]) tensor([0.8764, 0.1236], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 34 - 215: dog - cat || Loss: 1.189441442489624\n",
      "tensor([0., 1.]) tensor([0.8762, 0.1238], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 34 - 216: dog - cat || Loss: 1.1891769170761108\n",
      "tensor([0., 1.]) tensor([0.8759, 0.1241], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 34 - 217: dog - cat || Loss: 1.1889078617095947\n",
      "tensor([0., 1.]) tensor([0.8756, 0.1244], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 34 - 218: dog - cat || Loss: 1.1886347532272339\n",
      "tensor([0., 1.]) tensor([0.8754, 0.1246], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 34 - 219: dog - cat || Loss: 1.1883580684661865\n",
      "tensor([0., 1.]) tensor([0.8751, 0.1249], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 34 - 220: dog - cat || Loss: 1.1880778074264526\n",
      "tensor([0., 1.]) tensor([0.8748, 0.1252], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 34 - 221: dog - cat || Loss: 1.18779456615448\n",
      "tensor([0., 1.]) tensor([0.8745, 0.1255], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 34 - 222: dog - cat || Loss: 1.187508225440979\n",
      "tensor([0., 1.]) tensor([0.8742, 0.1258], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 34 - 223: dog - cat || Loss: 1.187219262123108\n",
      "tensor([0., 1.]) tensor([0.8740, 0.1260], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 34 - 224: dog - cat || Loss: 1.1869277954101562\n",
      "tensor([0., 1.]) tensor([0.8737, 0.1263], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 34 - 225: dog - cat || Loss: 1.1866340637207031\n",
      "tensor([0., 1.]) tensor([0.8734, 0.1266], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 34 - 226: dog - cat || Loss: 1.1863380670547485\n",
      "tensor([0., 1.]) tensor([0.8731, 0.1269], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 34 - 227: dog - cat || Loss: 1.1860401630401611\n",
      "tensor([0., 1.]) tensor([0.8728, 0.1272], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 34 - 228: dog - cat || Loss: 1.1857402324676514\n",
      "tensor([0., 1.]) tensor([0.8725, 0.1275], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 34 - 229: dog - cat || Loss: 1.185438871383667\n",
      "tensor([0., 1.]) tensor([0.8722, 0.1278], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 34 - 230: dog - cat || Loss: 1.1851354837417603\n",
      "tensor([0., 1.]) tensor([0.8719, 0.1281], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 34 - 231: dog - cat || Loss: 1.184830665588379\n",
      "tensor([0., 1.]) tensor([0.8716, 0.1284], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 34 - 232: dog - cat || Loss: 1.1845241785049438\n",
      "tensor([0., 1.]) tensor([0.8713, 0.1287], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 34 - 233: dog - cat || Loss: 1.1842164993286133\n",
      "tensor([0., 1.]) tensor([0.8710, 0.1290], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 34 - 234: dog - cat || Loss: 1.183907389640808\n",
      "tensor([0., 1.]) tensor([0.8706, 0.1294], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 34 - 235: dog - cat || Loss: 1.1835969686508179\n",
      "tensor([0., 1.]) tensor([0.8703, 0.1297], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 34 - 236: dog - cat || Loss: 1.1832853555679321\n",
      "tensor([0., 1.]) tensor([0.8700, 0.1300], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 34 - 237: dog - cat || Loss: 1.1829725503921509\n",
      "tensor([0., 1.]) tensor([0.8697, 0.1303], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 34 - 238: dog - cat || Loss: 1.1826585531234741\n",
      "tensor([0., 1.]) tensor([0.8694, 0.1306], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 34 - 239: dog - cat || Loss: 1.1823433637619019\n",
      "tensor([0., 1.]) tensor([0.8691, 0.1309], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 34 - 240: dog - cat || Loss: 1.1820272207260132\n",
      "tensor([0., 1.]) tensor([0.8688, 0.1312], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 34 - 241: dog - cat || Loss: 1.181709885597229\n",
      "tensor([0., 1.]) tensor([0.8684, 0.1316], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 34 - 242: dog - cat || Loss: 1.181391716003418\n",
      "tensor([0., 1.]) tensor([0.8681, 0.1319], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 34 - 243: dog - cat || Loss: 1.1810725927352905\n",
      "tensor([0., 1.]) tensor([0.8678, 0.1322], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 34 - 244: dog - cat || Loss: 1.1807523965835571\n",
      "tensor([0., 1.]) tensor([0.8675, 0.1325], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 34 - 245: dog - cat || Loss: 1.1804313659667969\n",
      "tensor([0., 1.]) tensor([0.8672, 0.1328], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 34 - 246: dog - cat || Loss: 1.1801093816757202\n",
      "tensor([0., 1.]) tensor([0.8668, 0.1332], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 34 - 247: dog - cat || Loss: 1.1797863245010376\n",
      "tensor([0., 1.]) tensor([0.8665, 0.1335], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 34 - 248: dog - cat || Loss: 1.1794626712799072\n",
      "tensor([0., 1.]) tensor([0.8662, 0.1338], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 34 - 249: dog - cat || Loss: 1.1791378259658813\n",
      "tensor([0., 1.]) tensor([0.8659, 0.1341], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 34 - 250: dog - cat || Loss: 1.1788123846054077\n",
      "tensor([0., 1.]) tensor([0.8656, 0.1344], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 34 - 251: dog - cat || Loss: 1.1784858703613281\n",
      "tensor([0., 1.]) tensor([0.8652, 0.1348], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 34 - 252: dog - cat || Loss: 1.1781586408615112\n",
      "tensor([0., 1.]) tensor([0.8649, 0.1351], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 34 - 253: dog - cat || Loss: 1.177830457687378\n",
      "tensor([0., 1.]) tensor([0.8646, 0.1354], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 34 - 254: dog - cat || Loss: 1.1775014400482178\n",
      "tensor([0., 1.]) tensor([0.8642, 0.1358], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 34 - 255: dog - cat || Loss: 1.1771715879440308\n",
      "tensor([0., 1.]) tensor([0.8639, 0.1361], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 34 - 256: dog - cat || Loss: 1.176841139793396\n",
      "tensor([0., 1.]) tensor([0.8636, 0.1364], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 34 - 257: dog - cat || Loss: 1.1765097379684448\n",
      "tensor([0., 1.]) tensor([0.8632, 0.1368], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 34 - 258: dog - cat || Loss: 1.1761775016784668\n",
      "tensor([0., 1.]) tensor([0.8629, 0.1371], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 34 - 259: dog - cat || Loss: 1.1758445501327515\n",
      "tensor([0., 1.]) tensor([0.8626, 0.1374], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 34 - 260: dog - cat || Loss: 1.1755105257034302\n",
      "tensor([0., 1.]) tensor([0.8622, 0.1378], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 34 - 261: dog - cat || Loss: 1.1751760244369507\n",
      "tensor([0., 1.]) tensor([0.8619, 0.1381], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 34 - 262: dog - cat || Loss: 1.1748406887054443\n",
      "tensor([0., 1.]) tensor([0.8616, 0.1384], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 34 - 263: dog - cat || Loss: 1.1745043992996216\n",
      "tensor([0., 1.]) tensor([0.8612, 0.1388], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 34 - 264: dog - cat || Loss: 1.1741673946380615\n",
      "tensor([0., 1.]) tensor([0.8609, 0.1391], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 34 - 265: dog - cat || Loss: 1.1738295555114746\n",
      "tensor([0., 1.]) tensor([0.8606, 0.1394], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 34 - 266: dog - cat || Loss: 1.1734908819198608\n",
      "tensor([0., 1.]) tensor([0.8602, 0.1398], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 34 - 267: dog - cat || Loss: 1.1731516122817993\n",
      "tensor([0., 1.]) tensor([0.8599, 0.1401], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 34 - 268: dog - cat || Loss: 1.1728113889694214\n",
      "tensor([0., 1.]) tensor([0.8595, 0.1405], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 34 - 269: dog - cat || Loss: 1.1724703311920166\n",
      "tensor([0., 1.]) tensor([0.8592, 0.1408], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 34 - 270: dog - cat || Loss: 1.172128677368164\n",
      "tensor([0., 1.]) tensor([0.8589, 0.1411], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 34 - 271: dog - cat || Loss: 1.1717860698699951\n",
      "tensor([0., 1.]) tensor([0.8585, 0.1415], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 34 - 272: dog - cat || Loss: 1.1714426279067993\n",
      "tensor([0., 1.]) tensor([0.8582, 0.1418], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 34 - 273: dog - cat || Loss: 1.1710984706878662\n",
      "tensor([0., 1.]) tensor([0.8578, 0.1422], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 34 - 274: dog - cat || Loss: 1.1707537174224854\n",
      "tensor([0., 1.]) tensor([0.8575, 0.1425], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 34 - 275: dog - cat || Loss: 1.1704078912734985\n",
      "tensor([0., 1.]) tensor([0.8571, 0.1429], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 34 - 276: dog - cat || Loss: 1.170061469078064\n",
      "tensor([0., 1.]) tensor([0.8568, 0.1432], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 34 - 277: dog - cat || Loss: 1.169714093208313\n",
      "tensor([0., 1.]) tensor([0.8565, 0.1435], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 34 - 278: dog - cat || Loss: 1.1693661212921143\n",
      "tensor([0., 1.]) tensor([0.8561, 0.1439], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 34 - 279: dog - cat || Loss: 1.1690171957015991\n",
      "tensor([0., 1.]) tensor([0.8558, 0.1442], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 34 - 280: dog - cat || Loss: 1.1686675548553467\n",
      "tensor([0., 1.]) tensor([0.8554, 0.1446], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 34 - 281: dog - cat || Loss: 1.1683170795440674\n",
      "tensor([0., 1.]) tensor([0.8551, 0.1449], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 34 - 282: dog - cat || Loss: 1.1679657697677612\n",
      "tensor([0., 1.]) tensor([0.8547, 0.1453], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 34 - 283: dog - cat || Loss: 1.1676137447357178\n",
      "tensor([0., 1.]) tensor([0.8544, 0.1456], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 34 - 284: dog - cat || Loss: 1.167260766029358\n",
      "tensor([0., 1.]) tensor([0.8540, 0.1460], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 34 - 285: dog - cat || Loss: 1.1669070720672607\n",
      "tensor([0., 1.]) tensor([0.8536, 0.1464], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 34 - 286: dog - cat || Loss: 1.1665527820587158\n",
      "tensor([0., 1.]) tensor([0.8533, 0.1467], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 34 - 287: dog - cat || Loss: 1.166197419166565\n",
      "tensor([0., 1.]) tensor([0.8529, 0.1471], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 34 - 288: dog - cat || Loss: 1.1658415794372559\n",
      "tensor([0., 1.]) tensor([0.8526, 0.1474], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 34 - 289: dog - cat || Loss: 1.1654846668243408\n",
      "tensor([0., 1.]) tensor([0.8522, 0.1478], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 34 - 290: dog - cat || Loss: 1.1651270389556885\n",
      "tensor([0., 1.]) tensor([0.8519, 0.1481], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 34 - 291: dog - cat || Loss: 1.1647686958312988\n",
      "tensor([0., 1.]) tensor([0.8515, 0.1485], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 34 - 292: dog - cat || Loss: 1.1644092798233032\n",
      "tensor([0., 1.]) tensor([0.8511, 0.1489], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 34 - 293: dog - cat || Loss: 1.1640493869781494\n",
      "tensor([0., 1.]) tensor([0.8508, 0.1492], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 34 - 294: dog - cat || Loss: 1.1636886596679688\n",
      "tensor([0., 1.]) tensor([0.8504, 0.1496], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 34 - 295: dog - cat || Loss: 1.1633268594741821\n",
      "tensor([0., 1.]) tensor([0.8501, 0.1499], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 34 - 296: dog - cat || Loss: 1.1629644632339478\n",
      "tensor([0., 1.]) tensor([0.8497, 0.1503], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 34 - 297: dog - cat || Loss: 1.162601351737976\n",
      "tensor([0., 1.]) tensor([0.8493, 0.1507], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 34 - 298: dog - cat || Loss: 1.162237286567688\n",
      "tensor([0., 1.]) tensor([0.8490, 0.1510], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 34 - 299: dog - cat || Loss: 1.1618725061416626\n",
      "tensor([0., 1.]) tensor([0.8486, 0.1514], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 34 - 300: dog - cat || Loss: 1.1615068912506104\n",
      "tensor([0., 1.]) tensor([0.8482, 0.1518], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 34 - 301: dog - cat || Loss: 1.1611403226852417\n",
      "tensor([0., 1.]) tensor([0.8479, 0.1521], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 34 - 302: dog - cat || Loss: 1.1607731580734253\n",
      "tensor([0., 1.]) tensor([0.8475, 0.1525], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 34 - 303: dog - cat || Loss: 1.1604050397872925\n",
      "tensor([0., 1.]) tensor([0.8471, 0.1529], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 34 - 304: dog - cat || Loss: 1.1600362062454224\n",
      "tensor([0., 1.]) tensor([0.8468, 0.1532], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 34 - 305: dog - cat || Loss: 1.1596662998199463\n",
      "tensor([0., 1.]) tensor([0.8464, 0.1536], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 34 - 306: dog - cat || Loss: 1.159295916557312\n",
      "tensor([0., 1.]) tensor([0.8460, 0.1540], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 34 - 307: dog - cat || Loss: 1.1589245796203613\n",
      "tensor([0., 1.]) tensor([0.8457, 0.1543], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 34 - 308: dog - cat || Loss: 1.1585524082183838\n",
      "tensor([0., 1.]) tensor([0.8453, 0.1547], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 34 - 309: dog - cat || Loss: 1.158179521560669\n",
      "tensor([0., 1.]) tensor([0.8449, 0.1551], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 34 - 310: dog - cat || Loss: 1.1578056812286377\n",
      "tensor([0., 1.]) tensor([0.8445, 0.1555], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 34 - 311: dog - cat || Loss: 1.1574310064315796\n",
      "tensor([0., 1.]) tensor([0.8442, 0.1558], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 34 - 312: dog - cat || Loss: 1.1570557355880737\n",
      "tensor([0., 1.]) tensor([0.8438, 0.1562], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 34 - 313: dog - cat || Loss: 1.1566795110702515\n",
      "tensor([0., 1.]) tensor([0.8434, 0.1566], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 34 - 314: dog - cat || Loss: 1.1563024520874023\n",
      "tensor([0., 1.]) tensor([0.8430, 0.1570], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 34 - 315: dog - cat || Loss: 1.155924677848816\n",
      "tensor([0., 1.]) tensor([0.8427, 0.1573], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 34 - 316: dog - cat || Loss: 1.155545949935913\n",
      "tensor([0., 1.]) tensor([0.8423, 0.1577], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 34 - 317: dog - cat || Loss: 1.1551663875579834\n",
      "tensor([0., 1.]) tensor([0.8419, 0.1581], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 34 - 318: dog - cat || Loss: 1.1547861099243164\n",
      "tensor([0., 1.]) tensor([0.8415, 0.1585], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 34 - 319: dog - cat || Loss: 1.154404878616333\n",
      "tensor([0., 1.]) tensor([0.8411, 0.1589], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 34 - 320: dog - cat || Loss: 1.1540230512619019\n",
      "tensor([0., 1.]) tensor([0.8408, 0.1592], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 34 - 321: dog - cat || Loss: 1.1536401510238647\n",
      "tensor([0., 1.]) tensor([0.8404, 0.1596], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 34 - 322: dog - cat || Loss: 1.1532566547393799\n",
      "tensor([0., 1.]) tensor([0.8400, 0.1600], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 34 - 323: dog - cat || Loss: 1.152872085571289\n",
      "tensor([0., 1.]) tensor([0.8396, 0.1604], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 34 - 324: dog - cat || Loss: 1.15248703956604\n",
      "tensor([0., 1.]) tensor([0.8392, 0.1608], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 34 - 325: dog - cat || Loss: 1.1521008014678955\n",
      "tensor([0., 1.]) tensor([0.8388, 0.1612], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 34 - 326: dog - cat || Loss: 1.1517137289047241\n",
      "tensor([0., 1.]) tensor([0.8385, 0.1615], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 34 - 327: dog - cat || Loss: 1.1513259410858154\n",
      "tensor([0., 1.]) tensor([0.8381, 0.1619], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 34 - 328: dog - cat || Loss: 1.1509374380111694\n",
      "tensor([0., 1.]) tensor([0.8377, 0.1623], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 34 - 329: dog - cat || Loss: 1.1505482196807861\n",
      "tensor([0., 1.]) tensor([0.8373, 0.1627], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 34 - 330: dog - cat || Loss: 1.1501578092575073\n",
      "tensor([0., 1.]) tensor([0.8369, 0.1631], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 34 - 331: dog - cat || Loss: 1.1497668027877808\n",
      "tensor([0., 1.]) tensor([0.8365, 0.1635], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 34 - 332: dog - cat || Loss: 1.1493748426437378\n",
      "tensor([0., 1.]) tensor([0.8361, 0.1639], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 34 - 333: dog - cat || Loss: 1.148982048034668\n",
      "tensor([0., 1.]) tensor([0.8357, 0.1643], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 34 - 334: dog - cat || Loss: 1.1485884189605713\n",
      "tensor([0., 1.]) tensor([0.8353, 0.1647], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 34 - 335: dog - cat || Loss: 1.1481940746307373\n",
      "tensor([0., 1.]) tensor([0.8349, 0.1651], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 34 - 336: dog - cat || Loss: 1.147798776626587\n",
      "tensor([0., 1.]) tensor([0.8345, 0.1655], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 34 - 337: dog - cat || Loss: 1.1474027633666992\n",
      "tensor([0., 1.]) tensor([0.8341, 0.1659], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 34 - 338: dog - cat || Loss: 1.1470056772232056\n",
      "tensor([0., 1.]) tensor([0.8337, 0.1663], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 34 - 339: dog - cat || Loss: 1.1466078758239746\n",
      "tensor([0., 1.]) tensor([0.8333, 0.1667], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 34 - 340: dog - cat || Loss: 1.1462092399597168\n",
      "tensor([0., 1.]) tensor([0.8329, 0.1671], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 34 - 341: dog - cat || Loss: 1.1458097696304321\n",
      "tensor([0., 1.]) tensor([0.8325, 0.1675], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 34 - 342: dog - cat || Loss: 1.1454094648361206\n",
      "tensor([0., 1.]) tensor([0.8321, 0.1679], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 34 - 343: dog - cat || Loss: 1.1450082063674927\n",
      "tensor([0., 1.]) tensor([0.8317, 0.1683], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 34 - 344: dog - cat || Loss: 1.144606351852417\n",
      "tensor([0., 1.]) tensor([0.8313, 0.1687], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 34 - 345: dog - cat || Loss: 1.1442033052444458\n",
      "tensor([0., 1.]) tensor([0.8309, 0.1691], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 34 - 346: dog - cat || Loss: 1.1437997817993164\n",
      "tensor([0., 1.]) tensor([0.8305, 0.1695], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 34 - 347: dog - cat || Loss: 1.1433950662612915\n",
      "tensor([0., 1.]) tensor([0.8301, 0.1699], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 34 - 348: dog - cat || Loss: 1.1429896354675293\n",
      "tensor([0., 1.]) tensor([0.8297, 0.1703], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 34 - 349: dog - cat || Loss: 1.1425833702087402\n",
      "tensor([0., 1.]) tensor([0.8293, 0.1707], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 34 - 350: dog - cat || Loss: 1.1421762704849243\n",
      "tensor([0., 1.]) tensor([0.8289, 0.1711], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 34 - 351: dog - cat || Loss: 1.1417683362960815\n",
      "tensor([0., 1.]) tensor([0.8285, 0.1715], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 34 - 352: dog - cat || Loss: 1.1413594484329224\n",
      "tensor([0., 1.]) tensor([0.8281, 0.1719], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 34 - 353: dog - cat || Loss: 1.1409497261047363\n",
      "tensor([0., 1.]) tensor([0.8277, 0.1723], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 34 - 354: dog - cat || Loss: 1.1405390501022339\n",
      "tensor([0., 1.]) tensor([0.8273, 0.1727], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 34 - 355: dog - cat || Loss: 1.1401276588439941\n",
      "tensor([0., 1.]) tensor([0.8269, 0.1731], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 34 - 356: dog - cat || Loss: 1.1397156715393066\n",
      "tensor([0., 1.]) tensor([0.8265, 0.1735], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 34 - 357: dog - cat || Loss: 1.1393022537231445\n",
      "tensor([0., 1.]) tensor([0.8260, 0.1740], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 34 - 358: dog - cat || Loss: 1.1388883590698242\n",
      "tensor([0., 1.]) tensor([0.8256, 0.1744], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 34 - 359: dog - cat || Loss: 1.1384735107421875\n",
      "tensor([0., 1.]) tensor([0.8252, 0.1748], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 34 - 360: dog - cat || Loss: 1.138057827949524\n",
      "tensor([0., 1.]) tensor([0.8248, 0.1752], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 34 - 361: dog - cat || Loss: 1.1376413106918335\n",
      "tensor([0., 1.]) tensor([0.8244, 0.1756], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 34 - 362: dog - cat || Loss: 1.137223720550537\n",
      "tensor([0., 1.]) tensor([0.8240, 0.1760], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 34 - 363: dog - cat || Loss: 1.136805534362793\n",
      "tensor([0., 1.]) tensor([0.8235, 0.1765], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 34 - 364: dog - cat || Loss: 1.1363862752914429\n",
      "tensor([0., 1.]) tensor([0.8231, 0.1769], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 34 - 365: dog - cat || Loss: 1.1359665393829346\n",
      "tensor([0., 1.]) tensor([0.8227, 0.1773], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 34 - 366: dog - cat || Loss: 1.1355454921722412\n",
      "tensor([0., 1.]) tensor([0.8223, 0.1777], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 34 - 367: dog - cat || Loss: 1.1351238489151\n",
      "tensor([0., 1.]) tensor([0.8219, 0.1781], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 34 - 368: dog - cat || Loss: 1.134701132774353\n",
      "tensor([0., 1.]) tensor([0.8214, 0.1786], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 34 - 369: dog - cat || Loss: 1.134277582168579\n",
      "tensor([0., 1.]) tensor([0.8210, 0.1790], grad_fn=<SoftmaxBackward0>)\n",
      "=====epoch:35=====\n",
      "Epoch 35 - 0: cat - cat || Loss: 0.4926699697971344\n",
      "tensor([1., 0.]) tensor([0.8206, 0.1794], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 35 - 1: cat - cat || Loss: 0.4930093288421631\n",
      "tensor([1., 0.]) tensor([0.8203, 0.1797], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 35 - 2: cat - cat || Loss: 0.49327200651168823\n",
      "tensor([1., 0.]) tensor([0.8200, 0.1800], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 35 - 3: cat - cat || Loss: 0.4934654235839844\n",
      "tensor([1., 0.]) tensor([0.8198, 0.1802], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 35 - 4: cat - cat || Loss: 0.49359655380249023\n",
      "tensor([1., 0.]) tensor([0.8197, 0.1803], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 35 - 5: cat - cat || Loss: 0.4936714768409729\n",
      "tensor([1., 0.]) tensor([0.8196, 0.1804], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 35 - 6: cat - cat || Loss: 0.49369579553604126\n",
      "tensor([1., 0.]) tensor([0.8196, 0.1804], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 35 - 7: cat - cat || Loss: 0.49367451667785645\n",
      "tensor([1., 0.]) tensor([0.8196, 0.1804], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 35 - 8: cat - cat || Loss: 0.49361252784729004\n",
      "tensor([1., 0.]) tensor([0.8196, 0.1804], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 35 - 9: cat - cat || Loss: 0.49351346492767334\n",
      "tensor([1., 0.]) tensor([0.8197, 0.1803], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 35 - 10: cat - cat || Loss: 0.4933813214302063\n",
      "tensor([1., 0.]) tensor([0.8199, 0.1801], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 35 - 11: cat - cat || Loss: 0.49321943521499634\n",
      "tensor([1., 0.]) tensor([0.8200, 0.1800], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 35 - 12: cat - cat || Loss: 0.4930308163166046\n",
      "tensor([1., 0.]) tensor([0.8202, 0.1798], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 35 - 13: cat - cat || Loss: 0.4928181767463684\n",
      "tensor([1., 0.]) tensor([0.8204, 0.1796], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 35 - 14: cat - cat || Loss: 0.4925839900970459\n",
      "tensor([1., 0.]) tensor([0.8207, 0.1793], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 35 - 15: cat - cat || Loss: 0.49233055114746094\n",
      "tensor([1., 0.]) tensor([0.8209, 0.1791], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 35 - 16: cat - cat || Loss: 0.49205970764160156\n",
      "tensor([1., 0.]) tensor([0.8212, 0.1788], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 35 - 17: cat - cat || Loss: 0.49177342653274536\n",
      "tensor([1., 0.]) tensor([0.8215, 0.1785], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 35 - 18: cat - cat || Loss: 0.4914732575416565\n",
      "tensor([1., 0.]) tensor([0.8218, 0.1782], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 35 - 19: cat - cat || Loss: 0.4911607503890991\n",
      "tensor([1., 0.]) tensor([0.8221, 0.1779], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 35 - 20: cat - cat || Loss: 0.490837037563324\n",
      "tensor([1., 0.]) tensor([0.8224, 0.1776], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 35 - 21: cat - cat || Loss: 0.4905034899711609\n",
      "tensor([1., 0.]) tensor([0.8228, 0.1772], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 35 - 22: cat - cat || Loss: 0.4901612102985382\n",
      "tensor([1., 0.]) tensor([0.8231, 0.1769], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 35 - 23: cat - cat || Loss: 0.4898110330104828\n",
      "tensor([1., 0.]) tensor([0.8235, 0.1765], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 35 - 24: cat - cat || Loss: 0.48945388197898865\n",
      "tensor([1., 0.]) tensor([0.8238, 0.1762], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 35 - 25: cat - cat || Loss: 0.48909053206443787\n",
      "tensor([1., 0.]) tensor([0.8242, 0.1758], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 35 - 26: cat - cat || Loss: 0.48872172832489014\n",
      "tensor([1., 0.]) tensor([0.8245, 0.1755], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 35 - 27: cat - cat || Loss: 0.4883480668067932\n",
      "tensor([1., 0.]) tensor([0.8249, 0.1751], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 35 - 28: cat - cat || Loss: 0.48797011375427246\n",
      "tensor([1., 0.]) tensor([0.8253, 0.1747], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 35 - 29: cat - cat || Loss: 0.4875882863998413\n",
      "tensor([1., 0.]) tensor([0.8257, 0.1743], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 35 - 30: cat - cat || Loss: 0.48720329999923706\n",
      "tensor([1., 0.]) tensor([0.8261, 0.1739], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 35 - 31: cat - cat || Loss: 0.48681530356407166\n",
      "tensor([1., 0.]) tensor([0.8264, 0.1736], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 35 - 32: cat - cat || Loss: 0.48642492294311523\n",
      "tensor([1., 0.]) tensor([0.8268, 0.1732], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 35 - 33: cat - cat || Loss: 0.4860324263572693\n",
      "tensor([1., 0.]) tensor([0.8272, 0.1728], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 35 - 34: cat - cat || Loss: 0.48563793301582336\n",
      "tensor([1., 0.]) tensor([0.8276, 0.1724], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 35 - 35: cat - cat || Loss: 0.4852418899536133\n",
      "tensor([1., 0.]) tensor([0.8280, 0.1720], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 35 - 36: cat - cat || Loss: 0.4848446249961853\n",
      "tensor([1., 0.]) tensor([0.8284, 0.1716], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 35 - 37: cat - cat || Loss: 0.4844462275505066\n",
      "tensor([1., 0.]) tensor([0.8288, 0.1712], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 35 - 38: cat - cat || Loss: 0.4840468764305115\n",
      "tensor([1., 0.]) tensor([0.8292, 0.1708], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 35 - 39: cat - cat || Loss: 0.48364681005477905\n",
      "tensor([1., 0.]) tensor([0.8296, 0.1704], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 35 - 40: cat - cat || Loss: 0.4832462668418884\n",
      "tensor([1., 0.]) tensor([0.8300, 0.1700], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 35 - 41: cat - cat || Loss: 0.4828450679779053\n",
      "tensor([1., 0.]) tensor([0.8304, 0.1696], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 35 - 42: cat - cat || Loss: 0.48244374990463257\n",
      "tensor([1., 0.]) tensor([0.8308, 0.1692], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 35 - 43: cat - cat || Loss: 0.4820421636104584\n",
      "tensor([1., 0.]) tensor([0.8312, 0.1688], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 35 - 44: cat - cat || Loss: 0.48164063692092896\n",
      "tensor([1., 0.]) tensor([0.8316, 0.1684], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 35 - 45: cat - cat || Loss: 0.4812390208244324\n",
      "tensor([1., 0.]) tensor([0.8320, 0.1680], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 35 - 46: cat - cat || Loss: 0.48083746433258057\n",
      "tensor([1., 0.]) tensor([0.8324, 0.1676], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 35 - 47: cat - cat || Loss: 0.480436235666275\n",
      "tensor([1., 0.]) tensor([0.8328, 0.1672], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 35 - 48: cat - cat || Loss: 0.4800351560115814\n",
      "tensor([1., 0.]) tensor([0.8332, 0.1668], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 35 - 49: cat - cat || Loss: 0.4796343445777893\n",
      "tensor([1., 0.]) tensor([0.8336, 0.1664], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 35 - 50: cat - cat || Loss: 0.479233980178833\n",
      "tensor([1., 0.]) tensor([0.8340, 0.1660], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 35 - 51: cat - cat || Loss: 0.4788341522216797\n",
      "tensor([1., 0.]) tensor([0.8344, 0.1656], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 35 - 52: cat - cat || Loss: 0.47843456268310547\n",
      "tensor([1., 0.]) tensor([0.8348, 0.1652], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 35 - 53: cat - cat || Loss: 0.47803565859794617\n",
      "tensor([1., 0.]) tensor([0.8352, 0.1648], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 35 - 54: cat - cat || Loss: 0.4776371717453003\n",
      "tensor([1., 0.]) tensor([0.8356, 0.1644], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 35 - 55: cat - cat || Loss: 0.47723931074142456\n",
      "tensor([1., 0.]) tensor([0.8360, 0.1640], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 35 - 56: cat - cat || Loss: 0.4768420457839966\n",
      "tensor([1., 0.]) tensor([0.8364, 0.1636], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 35 - 57: cat - cat || Loss: 0.4764453172683716\n",
      "tensor([1., 0.]) tensor([0.8368, 0.1632], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 35 - 58: cat - cat || Loss: 0.47604942321777344\n",
      "tensor([1., 0.]) tensor([0.8372, 0.1628], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 35 - 59: cat - cat || Loss: 0.47565412521362305\n",
      "tensor([1., 0.]) tensor([0.8376, 0.1624], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 35 - 60: cat - cat || Loss: 0.47525954246520996\n",
      "tensor([1., 0.]) tensor([0.8380, 0.1620], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 35 - 61: cat - cat || Loss: 0.47486555576324463\n",
      "tensor([1., 0.]) tensor([0.8384, 0.1616], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 35 - 62: cat - cat || Loss: 0.4744723439216614\n",
      "tensor([1., 0.]) tensor([0.8388, 0.1612], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 35 - 63: cat - cat || Loss: 0.47408002614974976\n",
      "tensor([1., 0.]) tensor([0.8392, 0.1608], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 35 - 64: cat - cat || Loss: 0.4736883044242859\n",
      "tensor([1., 0.]) tensor([0.8396, 0.1604], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 35 - 65: cat - cat || Loss: 0.4732973575592041\n",
      "tensor([1., 0.]) tensor([0.8400, 0.1600], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 35 - 66: cat - cat || Loss: 0.4729071259498596\n",
      "tensor([1., 0.]) tensor([0.8404, 0.1596], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 35 - 67: cat - cat || Loss: 0.47251781821250916\n",
      "tensor([1., 0.]) tensor([0.8407, 0.1593], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 35 - 68: cat - cat || Loss: 0.4721291661262512\n",
      "tensor([1., 0.]) tensor([0.8411, 0.1589], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 35 - 69: cat - cat || Loss: 0.47174128890037537\n",
      "tensor([1., 0.]) tensor([0.8415, 0.1585], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 35 - 70: cat - cat || Loss: 0.47135424613952637\n",
      "tensor([1., 0.]) tensor([0.8419, 0.1581], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 35 - 71: cat - cat || Loss: 0.4709681272506714\n",
      "tensor([1., 0.]) tensor([0.8423, 0.1577], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 35 - 72: cat - cat || Loss: 0.4705827236175537\n",
      "tensor([1., 0.]) tensor([0.8427, 0.1573], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 35 - 73: cat - cat || Loss: 0.47019803524017334\n",
      "tensor([1., 0.]) tensor([0.8431, 0.1569], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 35 - 74: cat - cat || Loss: 0.4698142409324646\n",
      "tensor([1., 0.]) tensor([0.8434, 0.1566], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 35 - 75: cat - cat || Loss: 0.4694313406944275\n",
      "tensor([1., 0.]) tensor([0.8438, 0.1562], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 35 - 76: cat - cat || Loss: 0.4690491557121277\n",
      "tensor([1., 0.]) tensor([0.8442, 0.1558], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 35 - 77: cat - cat || Loss: 0.46866798400878906\n",
      "tensor([1., 0.]) tensor([0.8446, 0.1554], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 35 - 78: cat - cat || Loss: 0.4682874083518982\n",
      "tensor([1., 0.]) tensor([0.8450, 0.1550], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 35 - 79: cat - cat || Loss: 0.4679078161716461\n",
      "tensor([1., 0.]) tensor([0.8454, 0.1546], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 35 - 80: cat - cat || Loss: 0.46752893924713135\n",
      "tensor([1., 0.]) tensor([0.8457, 0.1543], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 35 - 81: cat - cat || Loss: 0.4671509265899658\n",
      "tensor([1., 0.]) tensor([0.8461, 0.1539], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 35 - 82: cat - cat || Loss: 0.46677374839782715\n",
      "tensor([1., 0.]) tensor([0.8465, 0.1535], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 35 - 83: cat - cat || Loss: 0.46639740467071533\n",
      "tensor([1., 0.]) tensor([0.8469, 0.1531], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 35 - 84: cat - cat || Loss: 0.4660220444202423\n",
      "tensor([1., 0.]) tensor([0.8472, 0.1528], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 35 - 85: cat - cat || Loss: 0.4656473398208618\n",
      "tensor([1., 0.]) tensor([0.8476, 0.1524], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 35 - 86: cat - cat || Loss: 0.46527355909347534\n",
      "tensor([1., 0.]) tensor([0.8480, 0.1520], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 35 - 87: cat - cat || Loss: 0.46490055322647095\n",
      "tensor([1., 0.]) tensor([0.8484, 0.1516], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 35 - 88: cat - cat || Loss: 0.4645284414291382\n",
      "tensor([1., 0.]) tensor([0.8487, 0.1513], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 35 - 89: cat - cat || Loss: 0.4641571640968323\n",
      "tensor([1., 0.]) tensor([0.8491, 0.1509], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 35 - 90: cat - cat || Loss: 0.46378669142723083\n",
      "tensor([1., 0.]) tensor([0.8495, 0.1505], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 35 - 91: cat - cat || Loss: 0.4634169936180115\n",
      "tensor([1., 0.]) tensor([0.8498, 0.1502], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 35 - 92: cat - cat || Loss: 0.46304821968078613\n",
      "tensor([1., 0.]) tensor([0.8502, 0.1498], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 35 - 93: cat - cat || Loss: 0.46268025040626526\n",
      "tensor([1., 0.]) tensor([0.8506, 0.1494], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 35 - 94: cat - cat || Loss: 0.46231305599212646\n",
      "tensor([1., 0.]) tensor([0.8509, 0.1491], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 35 - 95: cat - cat || Loss: 0.4619467258453369\n",
      "tensor([1., 0.]) tensor([0.8513, 0.1487], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 35 - 96: cat - cat || Loss: 0.461581289768219\n",
      "tensor([1., 0.]) tensor([0.8517, 0.1483], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 35 - 97: cat - cat || Loss: 0.46121668815612793\n",
      "tensor([1., 0.]) tensor([0.8520, 0.1480], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 35 - 98: cat - cat || Loss: 0.46085280179977417\n",
      "tensor([1., 0.]) tensor([0.8524, 0.1476], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 35 - 99: cat - cat || Loss: 0.4604899287223816\n",
      "tensor([1., 0.]) tensor([0.8528, 0.1472], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 35 - 100: cat - cat || Loss: 0.46012774109840393\n",
      "tensor([1., 0.]) tensor([0.8531, 0.1469], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 35 - 101: cat - cat || Loss: 0.4597664475440979\n",
      "tensor([1., 0.]) tensor([0.8535, 0.1465], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 35 - 102: cat - cat || Loss: 0.4594059884548187\n",
      "tensor([1., 0.]) tensor([0.8539, 0.1461], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 35 - 103: cat - cat || Loss: 0.45904624462127686\n",
      "tensor([1., 0.]) tensor([0.8542, 0.1458], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 35 - 104: cat - cat || Loss: 0.4586873948574066\n",
      "tensor([1., 0.]) tensor([0.8546, 0.1454], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 35 - 105: cat - cat || Loss: 0.458329439163208\n",
      "tensor([1., 0.]) tensor([0.8549, 0.1451], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 35 - 106: cat - cat || Loss: 0.4579722285270691\n",
      "tensor([1., 0.]) tensor([0.8553, 0.1447], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 35 - 107: cat - cat || Loss: 0.45761582255363464\n",
      "tensor([1., 0.]) tensor([0.8556, 0.1444], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 35 - 108: cat - cat || Loss: 0.4572603702545166\n",
      "tensor([1., 0.]) tensor([0.8560, 0.1440], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 35 - 109: cat - cat || Loss: 0.4569056034088135\n",
      "tensor([1., 0.]) tensor([0.8564, 0.1436], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 35 - 110: cat - cat || Loss: 0.4565516710281372\n",
      "tensor([1., 0.]) tensor([0.8567, 0.1433], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 35 - 111: cat - cat || Loss: 0.4561985731124878\n",
      "tensor([1., 0.]) tensor([0.8571, 0.1429], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 35 - 112: cat - cat || Loss: 0.45584627985954285\n",
      "tensor([1., 0.]) tensor([0.8574, 0.1426], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 35 - 113: cat - cat || Loss: 0.45549482107162476\n",
      "tensor([1., 0.]) tensor([0.8578, 0.1422], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 35 - 114: cat - cat || Loss: 0.45514416694641113\n",
      "tensor([1., 0.]) tensor([0.8581, 0.1419], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 35 - 115: cat - cat || Loss: 0.45479434728622437\n",
      "tensor([1., 0.]) tensor([0.8585, 0.1415], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 35 - 116: cat - cat || Loss: 0.4544453024864197\n",
      "tensor([1., 0.]) tensor([0.8588, 0.1412], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 35 - 117: cat - cat || Loss: 0.45409709215164185\n",
      "tensor([1., 0.]) tensor([0.8592, 0.1408], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 35 - 118: cat - cat || Loss: 0.45374974608421326\n",
      "tensor([1., 0.]) tensor([0.8595, 0.1405], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 35 - 119: cat - cat || Loss: 0.45340317487716675\n",
      "tensor([1., 0.]) tensor([0.8599, 0.1401], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 35 - 120: cat - cat || Loss: 0.4530573785305023\n",
      "tensor([1., 0.]) tensor([0.8602, 0.1398], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 35 - 121: cat - cat || Loss: 0.45271241664886475\n",
      "tensor([1., 0.]) tensor([0.8605, 0.1395], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 35 - 122: cat - cat || Loss: 0.45236828923225403\n",
      "tensor([1., 0.]) tensor([0.8609, 0.1391], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 35 - 123: cat - cat || Loss: 0.4520249366760254\n",
      "tensor([1., 0.]) tensor([0.8612, 0.1388], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 35 - 124: cat - cat || Loss: 0.451682448387146\n",
      "tensor([1., 0.]) tensor([0.8616, 0.1384], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 35 - 125: cat - cat || Loss: 0.45134079456329346\n",
      "tensor([1., 0.]) tensor([0.8619, 0.1381], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 35 - 126: cat - cat || Loss: 0.45099979639053345\n",
      "tensor([1., 0.]) tensor([0.8623, 0.1377], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 35 - 127: cat - cat || Loss: 0.4506596326828003\n",
      "tensor([1., 0.]) tensor([0.8626, 0.1374], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 35 - 128: cat - cat || Loss: 0.45032036304473877\n",
      "tensor([1., 0.]) tensor([0.8629, 0.1371], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 35 - 129: cat - cat || Loss: 0.44998180866241455\n",
      "tensor([1., 0.]) tensor([0.8633, 0.1367], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 35 - 130: cat - cat || Loss: 0.44964414834976196\n",
      "tensor([1., 0.]) tensor([0.8636, 0.1364], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 35 - 131: cat - cat || Loss: 0.4493071436882019\n",
      "tensor([1., 0.]) tensor([0.8640, 0.1360], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 35 - 132: cat - cat || Loss: 0.4489709734916687\n",
      "tensor([1., 0.]) tensor([0.8643, 0.1357], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 35 - 133: cat - cat || Loss: 0.4486357569694519\n",
      "tensor([1., 0.]) tensor([0.8646, 0.1354], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 35 - 134: cat - cat || Loss: 0.4483010768890381\n",
      "tensor([1., 0.]) tensor([0.8650, 0.1350], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 35 - 135: cat - cat || Loss: 0.44796738028526306\n",
      "tensor([1., 0.]) tensor([0.8653, 0.1347], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 35 - 136: cat - cat || Loss: 0.44763439893722534\n",
      "tensor([1., 0.]) tensor([0.8656, 0.1344], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 35 - 137: cat - cat || Loss: 0.4473021924495697\n",
      "tensor([1., 0.]) tensor([0.8660, 0.1340], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 35 - 138: cat - cat || Loss: 0.4469708800315857\n",
      "tensor([1., 0.]) tensor([0.8663, 0.1337], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 35 - 139: cat - cat || Loss: 0.4466402232646942\n",
      "tensor([1., 0.]) tensor([0.8666, 0.1334], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 35 - 140: cat - cat || Loss: 0.4463103711605072\n",
      "tensor([1., 0.]) tensor([0.8670, 0.1330], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 35 - 141: cat - cat || Loss: 0.44598132371902466\n",
      "tensor([1., 0.]) tensor([0.8673, 0.1327], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 35 - 142: cat - cat || Loss: 0.4456530213356018\n",
      "tensor([1., 0.]) tensor([0.8676, 0.1324], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 35 - 143: cat - cat || Loss: 0.4453255534172058\n",
      "tensor([1., 0.]) tensor([0.8679, 0.1321], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 35 - 144: cat - cat || Loss: 0.4449988603591919\n",
      "tensor([1., 0.]) tensor([0.8683, 0.1317], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 35 - 145: cat - cat || Loss: 0.4446730315685272\n",
      "tensor([1., 0.]) tensor([0.8686, 0.1314], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 35 - 146: cat - cat || Loss: 0.4443478584289551\n",
      "tensor([1., 0.]) tensor([0.8689, 0.1311], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 35 - 147: cat - cat || Loss: 0.4440235495567322\n",
      "tensor([1., 0.]) tensor([0.8692, 0.1308], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 35 - 148: cat - cat || Loss: 0.44369998574256897\n",
      "tensor([1., 0.]) tensor([0.8696, 0.1304], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 35 - 149: cat - cat || Loss: 0.44337716698646545\n",
      "tensor([1., 0.]) tensor([0.8699, 0.1301], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 35 - 150: cat - cat || Loss: 0.44305509328842163\n",
      "tensor([1., 0.]) tensor([0.8702, 0.1298], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 35 - 151: cat - cat || Loss: 0.44273391366004944\n",
      "tensor([1., 0.]) tensor([0.8705, 0.1295], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 35 - 152: cat - cat || Loss: 0.44241344928741455\n",
      "tensor([1., 0.]) tensor([0.8708, 0.1292], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 35 - 153: cat - cat || Loss: 0.4420936703681946\n",
      "tensor([1., 0.]) tensor([0.8712, 0.1288], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 35 - 154: cat - cat || Loss: 0.44177472591400146\n",
      "tensor([1., 0.]) tensor([0.8715, 0.1285], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 35 - 155: cat - cat || Loss: 0.44145649671554565\n",
      "tensor([1., 0.]) tensor([0.8718, 0.1282], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 35 - 156: cat - cat || Loss: 0.4411391615867615\n",
      "tensor([1., 0.]) tensor([0.8721, 0.1279], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 35 - 157: cat - cat || Loss: 0.4408226013183594\n",
      "tensor([1., 0.]) tensor([0.8724, 0.1276], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 35 - 158: cat - cat || Loss: 0.44050660729408264\n",
      "tensor([1., 0.]) tensor([0.8728, 0.1272], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 35 - 159: cat - cat || Loss: 0.44019144773483276\n",
      "tensor([1., 0.]) tensor([0.8731, 0.1269], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 35 - 160: cat - cat || Loss: 0.43987709283828735\n",
      "tensor([1., 0.]) tensor([0.8734, 0.1266], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 35 - 161: cat - cat || Loss: 0.439563512802124\n",
      "tensor([1., 0.]) tensor([0.8737, 0.1263], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 35 - 162: cat - cat || Loss: 0.4392507076263428\n",
      "tensor([1., 0.]) tensor([0.8740, 0.1260], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 35 - 163: cat - cat || Loss: 0.43893852829933167\n",
      "tensor([1., 0.]) tensor([0.8743, 0.1257], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 35 - 164: cat - cat || Loss: 0.4386271834373474\n",
      "tensor([1., 0.]) tensor([0.8746, 0.1254], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 35 - 165: cat - cat || Loss: 0.4383166432380676\n",
      "tensor([1., 0.]) tensor([0.8749, 0.1251], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 35 - 166: cat - cat || Loss: 0.43800681829452515\n",
      "tensor([1., 0.]) tensor([0.8753, 0.1247], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 35 - 167: cat - cat || Loss: 0.43769776821136475\n",
      "tensor([1., 0.]) tensor([0.8756, 0.1244], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 35 - 168: cat - cat || Loss: 0.43738940358161926\n",
      "tensor([1., 0.]) tensor([0.8759, 0.1241], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 35 - 169: cat - cat || Loss: 0.43708178400993347\n",
      "tensor([1., 0.]) tensor([0.8762, 0.1238], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 35 - 170: cat - cat || Loss: 0.43677493929862976\n",
      "tensor([1., 0.]) tensor([0.8765, 0.1235], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 35 - 171: cat - cat || Loss: 0.4364689886569977\n",
      "tensor([1., 0.]) tensor([0.8768, 0.1232], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 35 - 172: cat - cat || Loss: 0.4361635744571686\n",
      "tensor([1., 0.]) tensor([0.8771, 0.1229], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 35 - 173: cat - cat || Loss: 0.4358590245246887\n",
      "tensor([1., 0.]) tensor([0.8774, 0.1226], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 35 - 174: cat - cat || Loss: 0.4355551302433014\n",
      "tensor([1., 0.]) tensor([0.8777, 0.1223], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 35 - 175: cat - cat || Loss: 0.43525195121765137\n",
      "tensor([1., 0.]) tensor([0.8780, 0.1220], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 35 - 176: cat - cat || Loss: 0.43494951725006104\n",
      "tensor([1., 0.]) tensor([0.8783, 0.1217], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 35 - 177: cat - cat || Loss: 0.43464791774749756\n",
      "tensor([1., 0.]) tensor([0.8786, 0.1214], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 35 - 178: cat - cat || Loss: 0.4343469738960266\n",
      "tensor([1., 0.]) tensor([0.8789, 0.1211], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 35 - 179: cat - cat || Loss: 0.4340468943119049\n",
      "tensor([1., 0.]) tensor([0.8792, 0.1208], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 35 - 180: cat - cat || Loss: 0.43374744057655334\n",
      "tensor([1., 0.]) tensor([0.8795, 0.1205], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 35 - 181: cat - cat || Loss: 0.4334486722946167\n",
      "tensor([1., 0.]) tensor([0.8798, 0.1202], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 35 - 182: cat - cat || Loss: 0.4331508278846741\n",
      "tensor([1., 0.]) tensor([0.8801, 0.1199], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 35 - 183: cat - cat || Loss: 0.432853639125824\n",
      "tensor([1., 0.]) tensor([0.8804, 0.1196], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 35 - 184: cat - cat || Loss: 0.4325571060180664\n",
      "tensor([1., 0.]) tensor([0.8807, 0.1193], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 35 - 185: cat - cat || Loss: 0.43226146697998047\n",
      "tensor([1., 0.]) tensor([0.8810, 0.1190], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 35 - 186: cat - cat || Loss: 0.4319663643836975\n",
      "tensor([1., 0.]) tensor([0.8813, 0.1187], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 35 - 187: cat - cat || Loss: 0.4316721558570862\n",
      "tensor([1., 0.]) tensor([0.8816, 0.1184], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 35 - 188: cat - cat || Loss: 0.4313785135746002\n",
      "tensor([1., 0.]) tensor([0.8819, 0.1181], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 35 - 189: cat - cat || Loss: 0.43108561635017395\n",
      "tensor([1., 0.]) tensor([0.8822, 0.1178], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 35 - 190: dog - cat || Loss: 1.1957299709320068\n",
      "tensor([0., 1.]) tensor([0.8825, 0.1175], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 35 - 191: dog - cat || Loss: 1.1959638595581055\n",
      "tensor([0., 1.]) tensor([0.8827, 0.1173], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 35 - 192: dog - cat || Loss: 1.1961452960968018\n",
      "tensor([0., 1.]) tensor([0.8829, 0.1171], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 35 - 193: dog - cat || Loss: 1.196279764175415\n",
      "tensor([0., 1.]) tensor([0.8830, 0.1170], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 35 - 194: dog - cat || Loss: 1.1963719129562378\n",
      "tensor([0., 1.]) tensor([0.8831, 0.1169], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 35 - 195: dog - cat || Loss: 1.196426272392273\n",
      "tensor([0., 1.]) tensor([0.8832, 0.1168], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 35 - 196: dog - cat || Loss: 1.196446180343628\n",
      "tensor([0., 1.]) tensor([0.8832, 0.1168], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 35 - 197: dog - cat || Loss: 1.1964354515075684\n",
      "tensor([0., 1.]) tensor([0.8832, 0.1168], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 35 - 198: dog - cat || Loss: 1.196397304534912\n",
      "tensor([0., 1.]) tensor([0.8831, 0.1169], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 35 - 199: dog - cat || Loss: 1.1963341236114502\n",
      "tensor([0., 1.]) tensor([0.8831, 0.1169], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 35 - 200: dog - cat || Loss: 1.1962485313415527\n",
      "tensor([0., 1.]) tensor([0.8830, 0.1170], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 35 - 201: dog - cat || Loss: 1.1961427927017212\n",
      "tensor([0., 1.]) tensor([0.8829, 0.1171], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 35 - 202: dog - cat || Loss: 1.1960186958312988\n",
      "tensor([0., 1.]) tensor([0.8828, 0.1172], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 35 - 203: dog - cat || Loss: 1.1958781480789185\n",
      "tensor([0., 1.]) tensor([0.8826, 0.1174], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 35 - 204: dog - cat || Loss: 1.1957229375839233\n",
      "tensor([0., 1.]) tensor([0.8825, 0.1175], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 35 - 205: dog - cat || Loss: 1.1955538988113403\n",
      "tensor([0., 1.]) tensor([0.8823, 0.1177], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 35 - 206: dog - cat || Loss: 1.1953731775283813\n",
      "tensor([0., 1.]) tensor([0.8821, 0.1179], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 35 - 207: dog - cat || Loss: 1.1951813697814941\n",
      "tensor([0., 1.]) tensor([0.8819, 0.1181], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 35 - 208: dog - cat || Loss: 1.1949794292449951\n",
      "tensor([0., 1.]) tensor([0.8817, 0.1183], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 35 - 209: dog - cat || Loss: 1.1947685480117798\n",
      "tensor([0., 1.]) tensor([0.8815, 0.1185], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 35 - 210: dog - cat || Loss: 1.1945496797561646\n",
      "tensor([0., 1.]) tensor([0.8813, 0.1187], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 35 - 211: dog - cat || Loss: 1.1943233013153076\n",
      "tensor([0., 1.]) tensor([0.8811, 0.1189], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 35 - 212: dog - cat || Loss: 1.1940900087356567\n",
      "tensor([0., 1.]) tensor([0.8808, 0.1192], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 35 - 213: dog - cat || Loss: 1.1938506364822388\n",
      "tensor([0., 1.]) tensor([0.8806, 0.1194], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 35 - 214: dog - cat || Loss: 1.193605661392212\n",
      "tensor([0., 1.]) tensor([0.8803, 0.1197], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 35 - 215: dog - cat || Loss: 1.1933555603027344\n",
      "tensor([0., 1.]) tensor([0.8801, 0.1199], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 35 - 216: dog - cat || Loss: 1.193100929260254\n",
      "tensor([0., 1.]) tensor([0.8798, 0.1202], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 35 - 217: dog - cat || Loss: 1.19284188747406\n",
      "tensor([0., 1.]) tensor([0.8796, 0.1204], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 35 - 218: dog - cat || Loss: 1.1925790309906006\n",
      "tensor([0., 1.]) tensor([0.8793, 0.1207], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 35 - 219: dog - cat || Loss: 1.192312479019165\n",
      "tensor([0., 1.]) tensor([0.8791, 0.1209], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 35 - 220: dog - cat || Loss: 1.1920427083969116\n",
      "tensor([0., 1.]) tensor([0.8788, 0.1212], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 35 - 221: dog - cat || Loss: 1.1917697191238403\n",
      "tensor([0., 1.]) tensor([0.8785, 0.1215], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 35 - 222: dog - cat || Loss: 1.1914942264556885\n",
      "tensor([0., 1.]) tensor([0.8782, 0.1218], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 35 - 223: dog - cat || Loss: 1.1912158727645874\n",
      "tensor([0., 1.]) tensor([0.8780, 0.1220], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 35 - 224: dog - cat || Loss: 1.1909352540969849\n",
      "tensor([0., 1.]) tensor([0.8777, 0.1223], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 35 - 225: dog - cat || Loss: 1.19065260887146\n",
      "tensor([0., 1.]) tensor([0.8774, 0.1226], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 35 - 226: dog - cat || Loss: 1.190367579460144\n",
      "tensor([0., 1.]) tensor([0.8771, 0.1229], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 35 - 227: dog - cat || Loss: 1.1900806427001953\n",
      "tensor([0., 1.]) tensor([0.8768, 0.1232], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 35 - 228: dog - cat || Loss: 1.1897919178009033\n",
      "tensor([0., 1.]) tensor([0.8765, 0.1235], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 35 - 229: dog - cat || Loss: 1.1895017623901367\n",
      "tensor([0., 1.]) tensor([0.8762, 0.1238], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 35 - 230: dog - cat || Loss: 1.1892095804214478\n",
      "tensor([0., 1.]) tensor([0.8759, 0.1241], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 35 - 231: dog - cat || Loss: 1.1889158487319946\n",
      "tensor([0., 1.]) tensor([0.8757, 0.1243], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 35 - 232: dog - cat || Loss: 1.1886208057403564\n",
      "tensor([0., 1.]) tensor([0.8754, 0.1246], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 35 - 233: dog - cat || Loss: 1.1883245706558228\n",
      "tensor([0., 1.]) tensor([0.8751, 0.1249], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 35 - 234: dog - cat || Loss: 1.188027024269104\n",
      "tensor([0., 1.]) tensor([0.8748, 0.1252], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 35 - 235: dog - cat || Loss: 1.1877281665802002\n",
      "tensor([0., 1.]) tensor([0.8745, 0.1255], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 35 - 236: dog - cat || Loss: 1.1874278783798218\n",
      "tensor([0., 1.]) tensor([0.8742, 0.1258], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 35 - 237: dog - cat || Loss: 1.1871265172958374\n",
      "tensor([0., 1.]) tensor([0.8739, 0.1261], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 35 - 238: dog - cat || Loss: 1.1868243217468262\n",
      "tensor([0., 1.]) tensor([0.8736, 0.1264], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 35 - 239: dog - cat || Loss: 1.1865206956863403\n",
      "tensor([0., 1.]) tensor([0.8733, 0.1267], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 35 - 240: dog - cat || Loss: 1.1862162351608276\n",
      "tensor([0., 1.]) tensor([0.8730, 0.1270], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 35 - 241: dog - cat || Loss: 1.185910701751709\n",
      "tensor([0., 1.]) tensor([0.8726, 0.1274], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 35 - 242: dog - cat || Loss: 1.1856043338775635\n",
      "tensor([0., 1.]) tensor([0.8723, 0.1277], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 35 - 243: dog - cat || Loss: 1.185296893119812\n",
      "tensor([0., 1.]) tensor([0.8720, 0.1280], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 35 - 244: dog - cat || Loss: 1.1849883794784546\n",
      "tensor([0., 1.]) tensor([0.8717, 0.1283], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 35 - 245: dog - cat || Loss: 1.1846792697906494\n",
      "tensor([0., 1.]) tensor([0.8714, 0.1286], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 35 - 246: dog - cat || Loss: 1.1843690872192383\n",
      "tensor([0., 1.]) tensor([0.8711, 0.1289], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 35 - 247: dog - cat || Loss: 1.1840579509735107\n",
      "tensor([0., 1.]) tensor([0.8708, 0.1292], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 35 - 248: dog - cat || Loss: 1.183746099472046\n",
      "tensor([0., 1.]) tensor([0.8705, 0.1295], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 35 - 249: dog - cat || Loss: 1.1834332942962646\n",
      "tensor([0., 1.]) tensor([0.8702, 0.1298], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 35 - 250: dog - cat || Loss: 1.183119773864746\n",
      "tensor([0., 1.]) tensor([0.8699, 0.1301], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 35 - 251: dog - cat || Loss: 1.1828052997589111\n",
      "tensor([0., 1.]) tensor([0.8695, 0.1305], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 35 - 252: dog - cat || Loss: 1.1824899911880493\n",
      "tensor([0., 1.]) tensor([0.8692, 0.1308], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 35 - 253: dog - cat || Loss: 1.1821738481521606\n",
      "tensor([0., 1.]) tensor([0.8689, 0.1311], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 35 - 254: dog - cat || Loss: 1.1818571090698242\n",
      "tensor([0., 1.]) tensor([0.8686, 0.1314], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 35 - 255: dog - cat || Loss: 1.1815394163131714\n",
      "tensor([0., 1.]) tensor([0.8683, 0.1317], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 35 - 256: dog - cat || Loss: 1.1812207698822021\n",
      "tensor([0., 1.]) tensor([0.8680, 0.1320], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 35 - 257: dog - cat || Loss: 1.1809015274047852\n",
      "tensor([0., 1.]) tensor([0.8676, 0.1324], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 35 - 258: dog - cat || Loss: 1.1805814504623413\n",
      "tensor([0., 1.]) tensor([0.8673, 0.1327], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 35 - 259: dog - cat || Loss: 1.1802606582641602\n",
      "tensor([0., 1.]) tensor([0.8670, 0.1330], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 35 - 260: dog - cat || Loss: 1.179938793182373\n",
      "tensor([0., 1.]) tensor([0.8667, 0.1333], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 35 - 261: dog - cat || Loss: 1.1796165704727173\n",
      "tensor([0., 1.]) tensor([0.8664, 0.1336], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 35 - 262: dog - cat || Loss: 1.1792933940887451\n",
      "tensor([0., 1.]) tensor([0.8660, 0.1340], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 35 - 263: dog - cat || Loss: 1.1789692640304565\n",
      "tensor([0., 1.]) tensor([0.8657, 0.1343], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 35 - 264: dog - cat || Loss: 1.1786446571350098\n",
      "tensor([0., 1.]) tensor([0.8654, 0.1346], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 35 - 265: dog - cat || Loss: 1.178318977355957\n",
      "tensor([0., 1.]) tensor([0.8651, 0.1349], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 35 - 266: dog - cat || Loss: 1.177992820739746\n",
      "tensor([0., 1.]) tensor([0.8647, 0.1353], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 35 - 267: dog - cat || Loss: 1.1776658296585083\n",
      "tensor([0., 1.]) tensor([0.8644, 0.1356], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 35 - 268: dog - cat || Loss: 1.177337884902954\n",
      "tensor([0., 1.]) tensor([0.8641, 0.1359], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 35 - 269: dog - cat || Loss: 1.1770092248916626\n",
      "tensor([0., 1.]) tensor([0.8637, 0.1363], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 35 - 270: dog - cat || Loss: 1.1766798496246338\n",
      "tensor([0., 1.]) tensor([0.8634, 0.1366], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 35 - 271: dog - cat || Loss: 1.1763498783111572\n",
      "tensor([0., 1.]) tensor([0.8631, 0.1369], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 35 - 272: dog - cat || Loss: 1.1760188341140747\n",
      "tensor([0., 1.]) tensor([0.8628, 0.1372], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 35 - 273: dog - cat || Loss: 1.1756871938705444\n",
      "tensor([0., 1.]) tensor([0.8624, 0.1376], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 35 - 274: dog - cat || Loss: 1.1753548383712769\n",
      "tensor([0., 1.]) tensor([0.8621, 0.1379], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 35 - 275: dog - cat || Loss: 1.1750215291976929\n",
      "tensor([0., 1.]) tensor([0.8618, 0.1382], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 35 - 276: dog - cat || Loss: 1.1746876239776611\n",
      "tensor([0., 1.]) tensor([0.8614, 0.1386], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 35 - 277: dog - cat || Loss: 1.174352765083313\n",
      "tensor([0., 1.]) tensor([0.8611, 0.1389], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 35 - 278: dog - cat || Loss: 1.174017310142517\n",
      "tensor([0., 1.]) tensor([0.8608, 0.1392], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 35 - 279: dog - cat || Loss: 1.1736811399459839\n",
      "tensor([0., 1.]) tensor([0.8604, 0.1396], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 35 - 280: dog - cat || Loss: 1.1733440160751343\n",
      "tensor([0., 1.]) tensor([0.8601, 0.1399], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 35 - 281: dog - cat || Loss: 1.1730061769485474\n",
      "tensor([0., 1.]) tensor([0.8597, 0.1403], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 35 - 282: dog - cat || Loss: 1.1726675033569336\n",
      "tensor([0., 1.]) tensor([0.8594, 0.1406], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 35 - 283: dog - cat || Loss: 1.1723281145095825\n",
      "tensor([0., 1.]) tensor([0.8591, 0.1409], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 35 - 284: dog - cat || Loss: 1.1719880104064941\n",
      "tensor([0., 1.]) tensor([0.8587, 0.1413], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 35 - 285: dog - cat || Loss: 1.171647071838379\n",
      "tensor([0., 1.]) tensor([0.8584, 0.1416], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 35 - 286: dog - cat || Loss: 1.1713054180145264\n",
      "tensor([0., 1.]) tensor([0.8580, 0.1420], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 35 - 287: dog - cat || Loss: 1.170962929725647\n",
      "tensor([0., 1.]) tensor([0.8577, 0.1423], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 35 - 288: dog - cat || Loss: 1.1706197261810303\n",
      "tensor([0., 1.]) tensor([0.8574, 0.1426], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 35 - 289: dog - cat || Loss: 1.1702756881713867\n",
      "tensor([0., 1.]) tensor([0.8570, 0.1430], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 35 - 290: dog - cat || Loss: 1.1699309349060059\n",
      "tensor([0., 1.]) tensor([0.8567, 0.1433], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 35 - 291: dog - cat || Loss: 1.1695853471755981\n",
      "tensor([0., 1.]) tensor([0.8563, 0.1437], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 35 - 292: dog - cat || Loss: 1.169238805770874\n",
      "tensor([0., 1.]) tensor([0.8560, 0.1440], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 35 - 293: dog - cat || Loss: 1.1688916683197021\n",
      "tensor([0., 1.]) tensor([0.8556, 0.1444], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 35 - 294: dog - cat || Loss: 1.1685439348220825\n",
      "tensor([0., 1.]) tensor([0.8553, 0.1447], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 35 - 295: dog - cat || Loss: 1.1681952476501465\n",
      "tensor([0., 1.]) tensor([0.8549, 0.1451], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 35 - 296: dog - cat || Loss: 1.1678454875946045\n",
      "tensor([0., 1.]) tensor([0.8546, 0.1454], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 35 - 297: dog - cat || Loss: 1.1674953699111938\n",
      "tensor([0., 1.]) tensor([0.8542, 0.1458], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 35 - 298: dog - cat || Loss: 1.1671442985534668\n",
      "tensor([0., 1.]) tensor([0.8539, 0.1461], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 35 - 299: dog - cat || Loss: 1.1667925119400024\n",
      "tensor([0., 1.]) tensor([0.8535, 0.1465], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 35 - 300: dog - cat || Loss: 1.1664397716522217\n",
      "tensor([0., 1.]) tensor([0.8532, 0.1468], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 35 - 301: dog - cat || Loss: 1.1660864353179932\n",
      "tensor([0., 1.]) tensor([0.8528, 0.1472], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 35 - 302: dog - cat || Loss: 1.1657321453094482\n",
      "tensor([0., 1.]) tensor([0.8525, 0.1475], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 35 - 303: dog - cat || Loss: 1.1653772592544556\n",
      "tensor([0., 1.]) tensor([0.8521, 0.1479], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 35 - 304: dog - cat || Loss: 1.165021538734436\n",
      "tensor([0., 1.]) tensor([0.8518, 0.1482], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 35 - 305: dog - cat || Loss: 1.164664626121521\n",
      "tensor([0., 1.]) tensor([0.8514, 0.1486], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 35 - 306: dog - cat || Loss: 1.1643074750900269\n",
      "tensor([0., 1.]) tensor([0.8510, 0.1490], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 35 - 307: dog - cat || Loss: 1.1639492511749268\n",
      "tensor([0., 1.]) tensor([0.8507, 0.1493], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 35 - 308: dog - cat || Loss: 1.1635901927947998\n",
      "tensor([0., 1.]) tensor([0.8503, 0.1497], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 35 - 309: dog - cat || Loss: 1.1632304191589355\n",
      "tensor([0., 1.]) tensor([0.8500, 0.1500], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 35 - 310: dog - cat || Loss: 1.1628700494766235\n",
      "tensor([0., 1.]) tensor([0.8496, 0.1504], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 35 - 311: dog - cat || Loss: 1.162508487701416\n",
      "tensor([0., 1.]) tensor([0.8492, 0.1508], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 35 - 312: dog - cat || Loss: 1.1621463298797607\n",
      "tensor([0., 1.]) tensor([0.8489, 0.1511], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 35 - 313: dog - cat || Loss: 1.1617834568023682\n",
      "tensor([0., 1.]) tensor([0.8485, 0.1515], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 35 - 314: dog - cat || Loss: 1.1614196300506592\n",
      "tensor([0., 1.]) tensor([0.8482, 0.1518], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 35 - 315: dog - cat || Loss: 1.1610552072525024\n",
      "tensor([0., 1.]) tensor([0.8478, 0.1522], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 35 - 316: dog - cat || Loss: 1.1606895923614502\n",
      "tensor([0., 1.]) tensor([0.8474, 0.1526], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 35 - 317: dog - cat || Loss: 1.1603235006332397\n",
      "tensor([0., 1.]) tensor([0.8471, 0.1529], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 35 - 318: dog - cat || Loss: 1.159956693649292\n",
      "tensor([0., 1.]) tensor([0.8467, 0.1533], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 35 - 319: dog - cat || Loss: 1.1595886945724487\n",
      "tensor([0., 1.]) tensor([0.8463, 0.1537], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 35 - 320: dog - cat || Loss: 1.1592203378677368\n",
      "tensor([0., 1.]) tensor([0.8460, 0.1540], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 35 - 321: dog - cat || Loss: 1.1588505506515503\n",
      "tensor([0., 1.]) tensor([0.8456, 0.1544], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 35 - 322: dog - cat || Loss: 1.1584805250167847\n",
      "tensor([0., 1.]) tensor([0.8452, 0.1548], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 35 - 323: dog - cat || Loss: 1.158109426498413\n",
      "tensor([0., 1.]) tensor([0.8448, 0.1552], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 35 - 324: dog - cat || Loss: 1.1577376127243042\n",
      "tensor([0., 1.]) tensor([0.8445, 0.1555], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 35 - 325: dog - cat || Loss: 1.1573649644851685\n",
      "tensor([0., 1.]) tensor([0.8441, 0.1559], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 35 - 326: dog - cat || Loss: 1.1569913625717163\n",
      "tensor([0., 1.]) tensor([0.8437, 0.1563], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 35 - 327: dog - cat || Loss: 1.1566171646118164\n",
      "tensor([0., 1.]) tensor([0.8434, 0.1566], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 35 - 328: dog - cat || Loss: 1.1562421321868896\n",
      "tensor([0., 1.]) tensor([0.8430, 0.1570], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 35 - 329: dog - cat || Loss: 1.155866265296936\n",
      "tensor([0., 1.]) tensor([0.8426, 0.1574], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 35 - 330: dog - cat || Loss: 1.155489444732666\n",
      "tensor([0., 1.]) tensor([0.8422, 0.1578], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 35 - 331: dog - cat || Loss: 1.1551117897033691\n",
      "tensor([0., 1.]) tensor([0.8419, 0.1581], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 35 - 332: dog - cat || Loss: 1.1547333002090454\n",
      "tensor([0., 1.]) tensor([0.8415, 0.1585], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 35 - 333: dog - cat || Loss: 1.154354214668274\n",
      "tensor([0., 1.]) tensor([0.8411, 0.1589], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 35 - 334: dog - cat || Loss: 1.1539740562438965\n",
      "tensor([0., 1.]) tensor([0.8407, 0.1593], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 35 - 335: dog - cat || Loss: 1.1535931825637817\n",
      "tensor([0., 1.]) tensor([0.8403, 0.1597], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 35 - 336: dog - cat || Loss: 1.1532115936279297\n",
      "tensor([0., 1.]) tensor([0.8399, 0.1601], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 35 - 337: dog - cat || Loss: 1.1528290510177612\n",
      "tensor([0., 1.]) tensor([0.8396, 0.1604], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 35 - 338: dog - cat || Loss: 1.152445673942566\n",
      "tensor([0., 1.]) tensor([0.8392, 0.1608], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 35 - 339: dog - cat || Loss: 1.1520614624023438\n",
      "tensor([0., 1.]) tensor([0.8388, 0.1612], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 35 - 340: dog - cat || Loss: 1.1516764163970947\n",
      "tensor([0., 1.]) tensor([0.8384, 0.1616], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 35 - 341: dog - cat || Loss: 1.1512905359268188\n",
      "tensor([0., 1.]) tensor([0.8380, 0.1620], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 35 - 342: dog - cat || Loss: 1.1509038209915161\n",
      "tensor([0., 1.]) tensor([0.8376, 0.1624], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 35 - 343: dog - cat || Loss: 1.150516390800476\n",
      "tensor([0., 1.]) tensor([0.8373, 0.1627], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 35 - 344: dog - cat || Loss: 1.1501280069351196\n",
      "tensor([0., 1.]) tensor([0.8369, 0.1631], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 35 - 345: dog - cat || Loss: 1.1497386693954468\n",
      "tensor([0., 1.]) tensor([0.8365, 0.1635], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 35 - 346: dog - cat || Loss: 1.1493487358093262\n",
      "tensor([0., 1.]) tensor([0.8361, 0.1639], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 35 - 347: dog - cat || Loss: 1.1489578485488892\n",
      "tensor([0., 1.]) tensor([0.8357, 0.1643], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 35 - 348: dog - cat || Loss: 1.1485661268234253\n",
      "tensor([0., 1.]) tensor([0.8353, 0.1647], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 35 - 349: dog - cat || Loss: 1.1481735706329346\n",
      "tensor([0., 1.]) tensor([0.8349, 0.1651], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 35 - 350: dog - cat || Loss: 1.1477800607681274\n",
      "tensor([0., 1.]) tensor([0.8345, 0.1655], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 35 - 351: dog - cat || Loss: 1.1473859548568726\n",
      "tensor([0., 1.]) tensor([0.8341, 0.1659], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 35 - 352: dog - cat || Loss: 1.1469907760620117\n",
      "tensor([0., 1.]) tensor([0.8337, 0.1663], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 35 - 353: dog - cat || Loss: 1.1465950012207031\n",
      "tensor([0., 1.]) tensor([0.8333, 0.1667], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 35 - 354: dog - cat || Loss: 1.146198034286499\n",
      "tensor([0., 1.]) tensor([0.8329, 0.1671], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 35 - 355: dog - cat || Loss: 1.1458004713058472\n",
      "tensor([0., 1.]) tensor([0.8325, 0.1675], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 35 - 356: dog - cat || Loss: 1.1454020738601685\n",
      "tensor([0., 1.]) tensor([0.8321, 0.1679], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 35 - 357: dog - cat || Loss: 1.1450027227401733\n",
      "tensor([0., 1.]) tensor([0.8317, 0.1683], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 35 - 358: dog - cat || Loss: 1.1446025371551514\n",
      "tensor([0., 1.]) tensor([0.8313, 0.1687], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 35 - 359: dog - cat || Loss: 1.144201636314392\n",
      "tensor([0., 1.]) tensor([0.8309, 0.1691], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 35 - 360: dog - cat || Loss: 1.1437997817993164\n",
      "tensor([0., 1.]) tensor([0.8305, 0.1695], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 35 - 361: dog - cat || Loss: 1.1433969736099243\n",
      "tensor([0., 1.]) tensor([0.8301, 0.1699], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 35 - 362: dog - cat || Loss: 1.142993450164795\n",
      "tensor([0., 1.]) tensor([0.8297, 0.1703], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 35 - 363: dog - cat || Loss: 1.1425888538360596\n",
      "tensor([0., 1.]) tensor([0.8293, 0.1707], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 35 - 364: dog - cat || Loss: 1.142183780670166\n",
      "tensor([0., 1.]) tensor([0.8289, 0.1711], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 35 - 365: dog - cat || Loss: 1.141777753829956\n",
      "tensor([0., 1.]) tensor([0.8285, 0.1715], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 35 - 366: dog - cat || Loss: 1.1413705348968506\n",
      "tensor([0., 1.]) tensor([0.8281, 0.1719], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 35 - 367: dog - cat || Loss: 1.140962839126587\n",
      "tensor([0., 1.]) tensor([0.8277, 0.1723], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 35 - 368: dog - cat || Loss: 1.1405540704727173\n",
      "tensor([0., 1.]) tensor([0.8273, 0.1727], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 35 - 369: dog - cat || Loss: 1.1401442289352417\n",
      "tensor([0., 1.]) tensor([0.8269, 0.1731], grad_fn=<SoftmaxBackward0>)\n",
      "=====epoch:36=====\n",
      "Epoch 36 - 0: cat - cat || Loss: 0.4867892265319824\n",
      "tensor([1., 0.]) tensor([0.8265, 0.1735], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 36 - 1: cat - cat || Loss: 0.4871175289154053\n",
      "tensor([1., 0.]) tensor([0.8261, 0.1739], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 36 - 2: cat - cat || Loss: 0.487371563911438\n",
      "tensor([1., 0.]) tensor([0.8259, 0.1741], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 36 - 3: cat - cat || Loss: 0.4875586926937103\n",
      "tensor([1., 0.]) tensor([0.8257, 0.1743], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 36 - 4: cat - cat || Loss: 0.4876854419708252\n",
      "tensor([1., 0.]) tensor([0.8256, 0.1744], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 36 - 5: cat - cat || Loss: 0.48775798082351685\n",
      "tensor([1., 0.]) tensor([0.8255, 0.1745], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 36 - 6: cat - cat || Loss: 0.48778146505355835\n",
      "tensor([1., 0.]) tensor([0.8255, 0.1745], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 36 - 7: cat - cat || Loss: 0.4877607822418213\n",
      "tensor([1., 0.]) tensor([0.8255, 0.1745], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 36 - 8: cat - cat || Loss: 0.48770052194595337\n",
      "tensor([1., 0.]) tensor([0.8256, 0.1744], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 36 - 9: cat - cat || Loss: 0.48760467767715454\n",
      "tensor([1., 0.]) tensor([0.8257, 0.1743], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 36 - 10: cat - cat || Loss: 0.4874767065048218\n",
      "tensor([1., 0.]) tensor([0.8258, 0.1742], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 36 - 11: cat - cat || Loss: 0.48732009530067444\n",
      "tensor([1., 0.]) tensor([0.8259, 0.1741], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 36 - 12: cat - cat || Loss: 0.48713746666908264\n",
      "tensor([1., 0.]) tensor([0.8261, 0.1739], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 36 - 13: cat - cat || Loss: 0.4869317412376404\n",
      "tensor([1., 0.]) tensor([0.8263, 0.1737], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 36 - 14: cat - cat || Loss: 0.48670506477355957\n",
      "tensor([1., 0.]) tensor([0.8266, 0.1734], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 36 - 15: cat - cat || Loss: 0.4864598512649536\n",
      "tensor([1., 0.]) tensor([0.8268, 0.1732], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 36 - 16: cat - cat || Loss: 0.4861977994441986\n",
      "tensor([1., 0.]) tensor([0.8271, 0.1729], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 36 - 17: cat - cat || Loss: 0.48592084646224976\n",
      "tensor([1., 0.]) tensor([0.8273, 0.1727], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 36 - 18: cat - cat || Loss: 0.48563045263290405\n",
      "tensor([1., 0.]) tensor([0.8276, 0.1724], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 36 - 19: cat - cat || Loss: 0.4853280186653137\n",
      "tensor([1., 0.]) tensor([0.8279, 0.1721], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 36 - 20: cat - cat || Loss: 0.4850148856639862\n",
      "tensor([1., 0.]) tensor([0.8282, 0.1718], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 36 - 21: cat - cat || Loss: 0.484692245721817\n",
      "tensor([1., 0.]) tensor([0.8286, 0.1714], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 36 - 22: cat - cat || Loss: 0.4843611419200897\n",
      "tensor([1., 0.]) tensor([0.8289, 0.1711], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 36 - 23: cat - cat || Loss: 0.48402243852615356\n",
      "tensor([1., 0.]) tensor([0.8292, 0.1708], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 36 - 24: cat - cat || Loss: 0.483676940202713\n",
      "tensor([1., 0.]) tensor([0.8296, 0.1704], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 36 - 25: cat - cat || Loss: 0.4833255410194397\n",
      "tensor([1., 0.]) tensor([0.8299, 0.1701], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 36 - 26: cat - cat || Loss: 0.48296886682510376\n",
      "tensor([1., 0.]) tensor([0.8303, 0.1697], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 36 - 27: cat - cat || Loss: 0.48260751366615295\n",
      "tensor([1., 0.]) tensor([0.8307, 0.1693], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 36 - 28: cat - cat || Loss: 0.4822421073913574\n",
      "tensor([1., 0.]) tensor([0.8310, 0.1690], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 36 - 29: cat - cat || Loss: 0.48187294602394104\n",
      "tensor([1., 0.]) tensor([0.8314, 0.1686], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 36 - 30: cat - cat || Loss: 0.48150062561035156\n",
      "tensor([1., 0.]) tensor([0.8318, 0.1682], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 36 - 31: cat - cat || Loss: 0.48112553358078003\n",
      "tensor([1., 0.]) tensor([0.8321, 0.1679], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 36 - 32: cat - cat || Loss: 0.48074814677238464\n",
      "tensor([1., 0.]) tensor([0.8325, 0.1675], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 36 - 33: cat - cat || Loss: 0.48036864399909973\n",
      "tensor([1., 0.]) tensor([0.8329, 0.1671], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 36 - 34: cat - cat || Loss: 0.47998732328414917\n",
      "tensor([1., 0.]) tensor([0.8333, 0.1667], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 36 - 35: cat - cat || Loss: 0.47960448265075684\n",
      "tensor([1., 0.]) tensor([0.8337, 0.1663], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 36 - 36: cat - cat || Loss: 0.47922050952911377\n",
      "tensor([1., 0.]) tensor([0.8340, 0.1660], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 36 - 37: cat - cat || Loss: 0.4788352847099304\n",
      "tensor([1., 0.]) tensor([0.8344, 0.1656], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 36 - 38: cat - cat || Loss: 0.4784492254257202\n",
      "tensor([1., 0.]) tensor([0.8348, 0.1652], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 36 - 39: cat - cat || Loss: 0.47806236147880554\n",
      "tensor([1., 0.]) tensor([0.8352, 0.1648], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 36 - 40: cat - cat || Loss: 0.47767531871795654\n",
      "tensor([1., 0.]) tensor([0.8356, 0.1644], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 36 - 41: cat - cat || Loss: 0.4772874712944031\n",
      "tensor([1., 0.]) tensor([0.8360, 0.1640], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 36 - 42: cat - cat || Loss: 0.4768996238708496\n",
      "tensor([1., 0.]) tensor([0.8364, 0.1636], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 36 - 43: cat - cat || Loss: 0.47651147842407227\n",
      "tensor([1., 0.]) tensor([0.8368, 0.1632], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 36 - 44: cat - cat || Loss: 0.4761233925819397\n",
      "tensor([1., 0.]) tensor([0.8371, 0.1629], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 36 - 45: cat - cat || Loss: 0.47573530673980713\n",
      "tensor([1., 0.]) tensor([0.8375, 0.1625], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 36 - 46: cat - cat || Loss: 0.4753473699092865\n",
      "tensor([1., 0.]) tensor([0.8379, 0.1621], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 36 - 47: cat - cat || Loss: 0.47495967149734497\n",
      "tensor([1., 0.]) tensor([0.8383, 0.1617], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 36 - 48: cat - cat || Loss: 0.47457215189933777\n",
      "tensor([1., 0.]) tensor([0.8387, 0.1613], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 36 - 49: cat - cat || Loss: 0.4741849899291992\n",
      "tensor([1., 0.]) tensor([0.8391, 0.1609], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 36 - 50: cat - cat || Loss: 0.4737982153892517\n",
      "tensor([1., 0.]) tensor([0.8395, 0.1605], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 36 - 51: cat - cat || Loss: 0.4734118580818176\n",
      "tensor([1., 0.]) tensor([0.8398, 0.1602], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 36 - 52: cat - cat || Loss: 0.473025918006897\n",
      "tensor([1., 0.]) tensor([0.8402, 0.1598], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 36 - 53: cat - cat || Loss: 0.4726405143737793\n",
      "tensor([1., 0.]) tensor([0.8406, 0.1594], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 36 - 54: cat - cat || Loss: 0.4722557067871094\n",
      "tensor([1., 0.]) tensor([0.8410, 0.1590], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 36 - 55: cat - cat || Loss: 0.47187140583992004\n",
      "tensor([1., 0.]) tensor([0.8414, 0.1586], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 36 - 56: cat - cat || Loss: 0.47148776054382324\n",
      "tensor([1., 0.]) tensor([0.8418, 0.1582], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 36 - 57: cat - cat || Loss: 0.47110456228256226\n",
      "tensor([1., 0.]) tensor([0.8422, 0.1578], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 36 - 58: cat - cat || Loss: 0.4707222282886505\n",
      "tensor([1., 0.]) tensor([0.8425, 0.1575], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 36 - 59: cat - cat || Loss: 0.4703405201435089\n",
      "tensor([1., 0.]) tensor([0.8429, 0.1571], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 36 - 60: cat - cat || Loss: 0.46995943784713745\n",
      "tensor([1., 0.]) tensor([0.8433, 0.1567], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 36 - 61: cat - cat || Loss: 0.4695790708065033\n",
      "tensor([1., 0.]) tensor([0.8437, 0.1563], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 36 - 62: cat - cat || Loss: 0.46919941902160645\n",
      "tensor([1., 0.]) tensor([0.8441, 0.1559], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 36 - 63: cat - cat || Loss: 0.4688205122947693\n",
      "tensor([1., 0.]) tensor([0.8444, 0.1556], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 36 - 64: cat - cat || Loss: 0.4684423804283142\n",
      "tensor([1., 0.]) tensor([0.8448, 0.1552], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 36 - 65: cat - cat || Loss: 0.46806493401527405\n",
      "tensor([1., 0.]) tensor([0.8452, 0.1548], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 36 - 66: cat - cat || Loss: 0.46768826246261597\n",
      "tensor([1., 0.]) tensor([0.8456, 0.1544], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 36 - 67: cat - cat || Loss: 0.46731242537498474\n",
      "tensor([1., 0.]) tensor([0.8459, 0.1541], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 36 - 68: cat - cat || Loss: 0.4669373035430908\n",
      "tensor([1., 0.]) tensor([0.8463, 0.1537], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 36 - 69: cat - cat || Loss: 0.4665628969669342\n",
      "tensor([1., 0.]) tensor([0.8467, 0.1533], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 36 - 70: cat - cat || Loss: 0.4661893844604492\n",
      "tensor([1., 0.]) tensor([0.8471, 0.1529], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 36 - 71: cat - cat || Loss: 0.4658166766166687\n",
      "tensor([1., 0.]) tensor([0.8474, 0.1526], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 36 - 72: cat - cat || Loss: 0.4654446244239807\n",
      "tensor([1., 0.]) tensor([0.8478, 0.1522], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 36 - 73: cat - cat || Loss: 0.4650734066963196\n",
      "tensor([1., 0.]) tensor([0.8482, 0.1518], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 36 - 74: cat - cat || Loss: 0.4647029638290405\n",
      "tensor([1., 0.]) tensor([0.8486, 0.1514], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 36 - 75: cat - cat || Loss: 0.4643334746360779\n",
      "tensor([1., 0.]) tensor([0.8489, 0.1511], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 36 - 76: cat - cat || Loss: 0.46396470069885254\n",
      "tensor([1., 0.]) tensor([0.8493, 0.1507], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 36 - 77: cat - cat || Loss: 0.46359673142433167\n",
      "tensor([1., 0.]) tensor([0.8497, 0.1503], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 36 - 78: cat - cat || Loss: 0.4632295072078705\n",
      "tensor([1., 0.]) tensor([0.8500, 0.1500], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 36 - 79: cat - cat || Loss: 0.46286317706108093\n",
      "tensor([1., 0.]) tensor([0.8504, 0.1496], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 36 - 80: cat - cat || Loss: 0.46249765157699585\n",
      "tensor([1., 0.]) tensor([0.8508, 0.1492], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 36 - 81: cat - cat || Loss: 0.46213290095329285\n",
      "tensor([1., 0.]) tensor([0.8511, 0.1489], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 36 - 82: cat - cat || Loss: 0.4617689549922943\n",
      "tensor([1., 0.]) tensor([0.8515, 0.1485], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 36 - 83: cat - cat || Loss: 0.461405873298645\n",
      "tensor([1., 0.]) tensor([0.8519, 0.1481], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 36 - 84: cat - cat || Loss: 0.46104365587234497\n",
      "tensor([1., 0.]) tensor([0.8522, 0.1478], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 36 - 85: cat - cat || Loss: 0.46068209409713745\n",
      "tensor([1., 0.]) tensor([0.8526, 0.1474], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 36 - 86: cat - cat || Loss: 0.46032148599624634\n",
      "tensor([1., 0.]) tensor([0.8529, 0.1471], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 36 - 87: cat - cat || Loss: 0.4599617123603821\n",
      "tensor([1., 0.]) tensor([0.8533, 0.1467], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 36 - 88: cat - cat || Loss: 0.4596026837825775\n",
      "tensor([1., 0.]) tensor([0.8537, 0.1463], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 36 - 89: cat - cat || Loss: 0.45924443006515503\n",
      "tensor([1., 0.]) tensor([0.8540, 0.1460], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 36 - 90: cat - cat || Loss: 0.45888710021972656\n",
      "tensor([1., 0.]) tensor([0.8544, 0.1456], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 36 - 91: cat - cat || Loss: 0.4585304856300354\n",
      "tensor([1., 0.]) tensor([0.8547, 0.1453], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 36 - 92: cat - cat || Loss: 0.45817479491233826\n",
      "tensor([1., 0.]) tensor([0.8551, 0.1449], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 36 - 93: cat - cat || Loss: 0.4578198790550232\n",
      "tensor([1., 0.]) tensor([0.8554, 0.1446], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 36 - 94: cat - cat || Loss: 0.4574657082557678\n",
      "tensor([1., 0.]) tensor([0.8558, 0.1442], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 36 - 95: cat - cat || Loss: 0.4571123719215393\n",
      "tensor([1., 0.]) tensor([0.8561, 0.1439], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 36 - 96: cat - cat || Loss: 0.4567599296569824\n",
      "tensor([1., 0.]) tensor([0.8565, 0.1435], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 36 - 97: cat - cat || Loss: 0.4564082622528076\n",
      "tensor([1., 0.]) tensor([0.8569, 0.1431], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 36 - 98: cat - cat || Loss: 0.4560573101043701\n",
      "tensor([1., 0.]) tensor([0.8572, 0.1428], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 36 - 99: cat - cat || Loss: 0.4557073414325714\n",
      "tensor([1., 0.]) tensor([0.8576, 0.1424], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 36 - 100: cat - cat || Loss: 0.4553580582141876\n",
      "tensor([1., 0.]) tensor([0.8579, 0.1421], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 36 - 101: cat - cat || Loss: 0.4550096392631531\n",
      "tensor([1., 0.]) tensor([0.8583, 0.1417], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 36 - 102: cat - cat || Loss: 0.4546620845794678\n",
      "tensor([1., 0.]) tensor([0.8586, 0.1414], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 36 - 103: cat - cat || Loss: 0.454315185546875\n",
      "tensor([1., 0.]) tensor([0.8589, 0.1411], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 36 - 104: cat - cat || Loss: 0.45396918058395386\n",
      "tensor([1., 0.]) tensor([0.8593, 0.1407], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 36 - 105: cat - cat || Loss: 0.45362401008605957\n",
      "tensor([1., 0.]) tensor([0.8596, 0.1404], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 36 - 106: cat - cat || Loss: 0.45327961444854736\n",
      "tensor([1., 0.]) tensor([0.8600, 0.1400], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 36 - 107: cat - cat || Loss: 0.45293593406677246\n",
      "tensor([1., 0.]) tensor([0.8603, 0.1397], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 36 - 108: cat - cat || Loss: 0.4525931477546692\n",
      "tensor([1., 0.]) tensor([0.8607, 0.1393], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 36 - 109: cat - cat || Loss: 0.452251136302948\n",
      "tensor([1., 0.]) tensor([0.8610, 0.1390], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 36 - 110: cat - cat || Loss: 0.4519098997116089\n",
      "tensor([1., 0.]) tensor([0.8614, 0.1386], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 36 - 111: cat - cat || Loss: 0.4515696167945862\n",
      "tensor([1., 0.]) tensor([0.8617, 0.1383], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 36 - 112: cat - cat || Loss: 0.45122987031936646\n",
      "tensor([1., 0.]) tensor([0.8620, 0.1380], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 36 - 113: cat - cat || Loss: 0.4508911371231079\n",
      "tensor([1., 0.]) tensor([0.8624, 0.1376], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 36 - 114: cat - cat || Loss: 0.4505530297756195\n",
      "tensor([1., 0.]) tensor([0.8627, 0.1373], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 36 - 115: cat - cat || Loss: 0.45021581649780273\n",
      "tensor([1., 0.]) tensor([0.8630, 0.1370], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 36 - 116: cat - cat || Loss: 0.44987934827804565\n",
      "tensor([1., 0.]) tensor([0.8634, 0.1366], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 36 - 117: cat - cat || Loss: 0.44954371452331543\n",
      "tensor([1., 0.]) tensor([0.8637, 0.1363], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 36 - 118: cat - cat || Loss: 0.4492088556289673\n",
      "tensor([1., 0.]) tensor([0.8641, 0.1359], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 36 - 119: cat - cat || Loss: 0.448874831199646\n",
      "tensor([1., 0.]) tensor([0.8644, 0.1356], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 36 - 120: cat - cat || Loss: 0.4485414922237396\n",
      "tensor([1., 0.]) tensor([0.8647, 0.1353], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 36 - 121: cat - cat || Loss: 0.44820892810821533\n",
      "tensor([1., 0.]) tensor([0.8651, 0.1349], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 36 - 122: cat - cat || Loss: 0.44787728786468506\n",
      "tensor([1., 0.]) tensor([0.8654, 0.1346], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 36 - 123: cat - cat || Loss: 0.4475463032722473\n",
      "tensor([1., 0.]) tensor([0.8657, 0.1343], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 36 - 124: cat - cat || Loss: 0.447216272354126\n",
      "tensor([1., 0.]) tensor([0.8660, 0.1340], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 36 - 125: cat - cat || Loss: 0.44688689708709717\n",
      "tensor([1., 0.]) tensor([0.8664, 0.1336], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 36 - 126: cat - cat || Loss: 0.44655829668045044\n",
      "tensor([1., 0.]) tensor([0.8667, 0.1333], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 36 - 127: cat - cat || Loss: 0.4462304711341858\n",
      "tensor([1., 0.]) tensor([0.8670, 0.1330], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 36 - 128: cat - cat || Loss: 0.4459034204483032\n",
      "tensor([1., 0.]) tensor([0.8674, 0.1326], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 36 - 129: cat - cat || Loss: 0.4455771744251251\n",
      "tensor([1., 0.]) tensor([0.8677, 0.1323], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 36 - 130: cat - cat || Loss: 0.4452517628669739\n",
      "tensor([1., 0.]) tensor([0.8680, 0.1320], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 36 - 131: cat - cat || Loss: 0.444926917552948\n",
      "tensor([1., 0.]) tensor([0.8683, 0.1317], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 36 - 132: cat - cat || Loss: 0.4446030259132385\n",
      "tensor([1., 0.]) tensor([0.8687, 0.1313], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 36 - 133: cat - cat || Loss: 0.44427990913391113\n",
      "tensor([1., 0.]) tensor([0.8690, 0.1310], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 36 - 134: cat - cat || Loss: 0.44395750761032104\n",
      "tensor([1., 0.]) tensor([0.8693, 0.1307], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 36 - 135: cat - cat || Loss: 0.4436360001564026\n",
      "tensor([1., 0.]) tensor([0.8696, 0.1304], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 36 - 136: cat - cat || Loss: 0.4433150887489319\n",
      "tensor([1., 0.]) tensor([0.8699, 0.1301], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 36 - 137: cat - cat || Loss: 0.44299495220184326\n",
      "tensor([1., 0.]) tensor([0.8703, 0.1297], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 36 - 138: cat - cat || Loss: 0.44267570972442627\n",
      "tensor([1., 0.]) tensor([0.8706, 0.1294], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 36 - 139: cat - cat || Loss: 0.4423571228981018\n",
      "tensor([1., 0.]) tensor([0.8709, 0.1291], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 36 - 140: cat - cat || Loss: 0.4420393407344818\n",
      "tensor([1., 0.]) tensor([0.8712, 0.1288], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 36 - 141: cat - cat || Loss: 0.4417223036289215\n",
      "tensor([1., 0.]) tensor([0.8715, 0.1285], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 36 - 142: cat - cat || Loss: 0.4414060711860657\n",
      "tensor([1., 0.]) tensor([0.8719, 0.1281], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 36 - 143: cat - cat || Loss: 0.44109052419662476\n",
      "tensor([1., 0.]) tensor([0.8722, 0.1278], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 36 - 144: cat - cat || Loss: 0.4407758414745331\n",
      "tensor([1., 0.]) tensor([0.8725, 0.1275], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 36 - 145: cat - cat || Loss: 0.44046181440353394\n",
      "tensor([1., 0.]) tensor([0.8728, 0.1272], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 36 - 146: cat - cat || Loss: 0.44014865159988403\n",
      "tensor([1., 0.]) tensor([0.8731, 0.1269], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 36 - 147: cat - cat || Loss: 0.43983614444732666\n",
      "tensor([1., 0.]) tensor([0.8734, 0.1266], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 36 - 148: cat - cat || Loss: 0.43952441215515137\n",
      "tensor([1., 0.]) tensor([0.8737, 0.1263], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 36 - 149: cat - cat || Loss: 0.43921345472335815\n",
      "tensor([1., 0.]) tensor([0.8740, 0.1260], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 36 - 150: cat - cat || Loss: 0.43890315294265747\n",
      "tensor([1., 0.]) tensor([0.8744, 0.1256], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 36 - 151: cat - cat || Loss: 0.4385937452316284\n",
      "tensor([1., 0.]) tensor([0.8747, 0.1253], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 36 - 152: cat - cat || Loss: 0.43828511238098145\n",
      "tensor([1., 0.]) tensor([0.8750, 0.1250], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 36 - 153: cat - cat || Loss: 0.4379771053791046\n",
      "tensor([1., 0.]) tensor([0.8753, 0.1247], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 36 - 154: cat - cat || Loss: 0.43766993284225464\n",
      "tensor([1., 0.]) tensor([0.8756, 0.1244], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 36 - 155: cat - cat || Loss: 0.4373633861541748\n",
      "tensor([1., 0.]) tensor([0.8759, 0.1241], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 36 - 156: cat - cat || Loss: 0.4370577037334442\n",
      "tensor([1., 0.]) tensor([0.8762, 0.1238], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 36 - 157: cat - cat || Loss: 0.4367528557777405\n",
      "tensor([1., 0.]) tensor([0.8765, 0.1235], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 36 - 158: cat - cat || Loss: 0.43644845485687256\n",
      "tensor([1., 0.]) tensor([0.8768, 0.1232], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 36 - 159: cat - cat || Loss: 0.4361448884010315\n",
      "tensor([1., 0.]) tensor([0.8771, 0.1229], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 36 - 160: cat - cat || Loss: 0.4358421564102173\n",
      "tensor([1., 0.]) tensor([0.8774, 0.1226], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 36 - 161: cat - cat || Loss: 0.435540109872818\n",
      "tensor([1., 0.]) tensor([0.8777, 0.1223], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 36 - 162: cat - cat || Loss: 0.43523886799812317\n",
      "tensor([1., 0.]) tensor([0.8780, 0.1220], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 36 - 163: cat - cat || Loss: 0.4349382221698761\n",
      "tensor([1., 0.]) tensor([0.8783, 0.1217], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 36 - 164: cat - cat || Loss: 0.43463844060897827\n",
      "tensor([1., 0.]) tensor([0.8786, 0.1214], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 36 - 165: cat - cat || Loss: 0.434339314699173\n",
      "tensor([1., 0.]) tensor([0.8789, 0.1211], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 36 - 166: cat - cat || Loss: 0.43404093384742737\n",
      "tensor([1., 0.]) tensor([0.8792, 0.1208], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 36 - 167: cat - cat || Loss: 0.43374329805374146\n",
      "tensor([1., 0.]) tensor([0.8795, 0.1205], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 36 - 168: cat - cat || Loss: 0.43344640731811523\n",
      "tensor([1., 0.]) tensor([0.8798, 0.1202], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 36 - 169: cat - cat || Loss: 0.43315011262893677\n",
      "tensor([1., 0.]) tensor([0.8801, 0.1199], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 36 - 170: cat - cat || Loss: 0.43285462260246277\n",
      "tensor([1., 0.]) tensor([0.8804, 0.1196], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 36 - 171: cat - cat || Loss: 0.43255990743637085\n",
      "tensor([1., 0.]) tensor([0.8807, 0.1193], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 36 - 172: cat - cat || Loss: 0.4322658181190491\n",
      "tensor([1., 0.]) tensor([0.8810, 0.1190], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 36 - 173: cat - cat || Loss: 0.43197259306907654\n",
      "tensor([1., 0.]) tensor([0.8813, 0.1187], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 36 - 174: cat - cat || Loss: 0.43167999386787415\n",
      "tensor([1., 0.]) tensor([0.8816, 0.1184], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 36 - 175: cat - cat || Loss: 0.4313880503177643\n",
      "tensor([1., 0.]) tensor([0.8819, 0.1181], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 36 - 176: cat - cat || Loss: 0.4310969412326813\n",
      "tensor([1., 0.]) tensor([0.8822, 0.1178], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 36 - 177: cat - cat || Loss: 0.4308064877986908\n",
      "tensor([1., 0.]) tensor([0.8825, 0.1175], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 36 - 178: cat - cat || Loss: 0.43051671981811523\n",
      "tensor([1., 0.]) tensor([0.8827, 0.1173], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 36 - 179: cat - cat || Loss: 0.43022769689559937\n",
      "tensor([1., 0.]) tensor([0.8830, 0.1170], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 36 - 180: cat - cat || Loss: 0.4299393892288208\n",
      "tensor([1., 0.]) tensor([0.8833, 0.1167], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 36 - 181: cat - cat || Loss: 0.42965179681777954\n",
      "tensor([1., 0.]) tensor([0.8836, 0.1164], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 36 - 182: cat - cat || Loss: 0.42936497926712036\n",
      "tensor([1., 0.]) tensor([0.8839, 0.1161], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 36 - 183: cat - cat || Loss: 0.42907899618148804\n",
      "tensor([1., 0.]) tensor([0.8842, 0.1158], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 36 - 184: cat - cat || Loss: 0.4287935793399811\n",
      "tensor([1., 0.]) tensor([0.8845, 0.1155], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 36 - 185: cat - cat || Loss: 0.4285089671611786\n",
      "tensor([1., 0.]) tensor([0.8848, 0.1152], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 36 - 186: cat - cat || Loss: 0.42822492122650146\n",
      "tensor([1., 0.]) tensor([0.8850, 0.1150], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 36 - 187: cat - cat || Loss: 0.42794159054756165\n",
      "tensor([1., 0.]) tensor([0.8853, 0.1147], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 36 - 188: cat - cat || Loss: 0.42765897512435913\n",
      "tensor([1., 0.]) tensor([0.8856, 0.1144], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 36 - 189: cat - cat || Loss: 0.42737701535224915\n",
      "tensor([1., 0.]) tensor([0.8859, 0.1141], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 36 - 190: dog - cat || Loss: 1.1994274854660034\n",
      "tensor([0., 1.]) tensor([0.8862, 0.1138], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 36 - 191: dog - cat || Loss: 1.1996527910232544\n",
      "tensor([0., 1.]) tensor([0.8864, 0.1136], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 36 - 192: dog - cat || Loss: 1.1998275518417358\n",
      "tensor([0., 1.]) tensor([0.8866, 0.1134], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 36 - 193: dog - cat || Loss: 1.199957013130188\n",
      "tensor([0., 1.]) tensor([0.8867, 0.1133], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 36 - 194: dog - cat || Loss: 1.2000455856323242\n",
      "tensor([0., 1.]) tensor([0.8868, 0.1132], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 36 - 195: dog - cat || Loss: 1.2000977993011475\n",
      "tensor([0., 1.]) tensor([0.8868, 0.1132], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 36 - 196: dog - cat || Loss: 1.2001171112060547\n",
      "tensor([0., 1.]) tensor([0.8869, 0.1131], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 36 - 197: dog - cat || Loss: 1.2001069784164429\n",
      "tensor([0., 1.]) tensor([0.8868, 0.1132], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 36 - 198: dog - cat || Loss: 1.2000701427459717\n",
      "tensor([0., 1.]) tensor([0.8868, 0.1132], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 36 - 199: dog - cat || Loss: 1.2000094652175903\n",
      "tensor([0., 1.]) tensor([0.8867, 0.1133], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 36 - 200: dog - cat || Loss: 1.1999269723892212\n",
      "tensor([0., 1.]) tensor([0.8867, 0.1133], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 36 - 201: dog - cat || Loss: 1.1998251676559448\n",
      "tensor([0., 1.]) tensor([0.8866, 0.1134], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 36 - 202: dog - cat || Loss: 1.199705719947815\n",
      "tensor([0., 1.]) tensor([0.8864, 0.1136], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 36 - 203: dog - cat || Loss: 1.1995705366134644\n",
      "tensor([0., 1.]) tensor([0.8863, 0.1137], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 36 - 204: dog - cat || Loss: 1.1994210481643677\n",
      "tensor([0., 1.]) tensor([0.8862, 0.1138], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 36 - 205: dog - cat || Loss: 1.19925856590271\n",
      "tensor([0., 1.]) tensor([0.8860, 0.1140], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 36 - 206: dog - cat || Loss: 1.199084758758545\n",
      "tensor([0., 1.]) tensor([0.8858, 0.1142], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 36 - 207: dog - cat || Loss: 1.1989001035690308\n",
      "tensor([0., 1.]) tensor([0.8856, 0.1144], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 36 - 208: dog - cat || Loss: 1.1987059116363525\n",
      "tensor([0., 1.]) tensor([0.8854, 0.1146], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 36 - 209: dog - cat || Loss: 1.1985028982162476\n",
      "tensor([0., 1.]) tensor([0.8852, 0.1148], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 36 - 210: dog - cat || Loss: 1.1982922554016113\n",
      "tensor([0., 1.]) tensor([0.8850, 0.1150], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 36 - 211: dog - cat || Loss: 1.198074460029602\n",
      "tensor([0., 1.]) tensor([0.8848, 0.1152], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 36 - 212: dog - cat || Loss: 1.1978501081466675\n",
      "tensor([0., 1.]) tensor([0.8846, 0.1154], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 36 - 213: dog - cat || Loss: 1.197619915008545\n",
      "tensor([0., 1.]) tensor([0.8844, 0.1156], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 36 - 214: dog - cat || Loss: 1.1973841190338135\n",
      "tensor([0., 1.]) tensor([0.8841, 0.1159], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 36 - 215: dog - cat || Loss: 1.1971435546875\n",
      "tensor([0., 1.]) tensor([0.8839, 0.1161], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 36 - 216: dog - cat || Loss: 1.1968984603881836\n",
      "tensor([0., 1.]) tensor([0.8836, 0.1164], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 36 - 217: dog - cat || Loss: 1.196649193763733\n",
      "tensor([0., 1.]) tensor([0.8834, 0.1166], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 36 - 218: dog - cat || Loss: 1.1963963508605957\n",
      "tensor([0., 1.]) tensor([0.8831, 0.1169], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 36 - 219: dog - cat || Loss: 1.196139931678772\n",
      "tensor([0., 1.]) tensor([0.8829, 0.1171], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 36 - 220: dog - cat || Loss: 1.19588041305542\n",
      "tensor([0., 1.]) tensor([0.8826, 0.1174], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 36 - 221: dog - cat || Loss: 1.1956177949905396\n",
      "tensor([0., 1.]) tensor([0.8824, 0.1176], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 36 - 222: dog - cat || Loss: 1.195352554321289\n",
      "tensor([0., 1.]) tensor([0.8821, 0.1179], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 36 - 223: dog - cat || Loss: 1.195084810256958\n",
      "tensor([0., 1.]) tensor([0.8818, 0.1182], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 36 - 224: dog - cat || Loss: 1.1948148012161255\n",
      "tensor([0., 1.]) tensor([0.8816, 0.1184], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 36 - 225: dog - cat || Loss: 1.194542646408081\n",
      "tensor([0., 1.]) tensor([0.8813, 0.1187], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 36 - 226: dog - cat || Loss: 1.1942684650421143\n",
      "tensor([0., 1.]) tensor([0.8810, 0.1190], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 36 - 227: dog - cat || Loss: 1.1939923763275146\n",
      "tensor([0., 1.]) tensor([0.8807, 0.1193], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 36 - 228: dog - cat || Loss: 1.1937143802642822\n",
      "tensor([0., 1.]) tensor([0.8805, 0.1195], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 36 - 229: dog - cat || Loss: 1.1934350728988647\n",
      "tensor([0., 1.]) tensor([0.8802, 0.1198], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 36 - 230: dog - cat || Loss: 1.1931538581848145\n",
      "tensor([0., 1.]) tensor([0.8799, 0.1201], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 36 - 231: dog - cat || Loss: 1.192871332168579\n",
      "tensor([0., 1.]) tensor([0.8796, 0.1204], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 36 - 232: dog - cat || Loss: 1.1925872564315796\n",
      "tensor([0., 1.]) tensor([0.8793, 0.1207], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 36 - 233: dog - cat || Loss: 1.1923022270202637\n",
      "tensor([0., 1.]) tensor([0.8790, 0.1210], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 36 - 234: dog - cat || Loss: 1.1920156478881836\n",
      "tensor([0., 1.]) tensor([0.8788, 0.1212], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 36 - 235: dog - cat || Loss: 1.1917277574539185\n",
      "tensor([0., 1.]) tensor([0.8785, 0.1215], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 36 - 236: dog - cat || Loss: 1.191438913345337\n",
      "tensor([0., 1.]) tensor([0.8782, 0.1218], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 36 - 237: dog - cat || Loss: 1.1911488771438599\n",
      "tensor([0., 1.]) tensor([0.8779, 0.1221], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 36 - 238: dog - cat || Loss: 1.1908578872680664\n",
      "tensor([0., 1.]) tensor([0.8776, 0.1224], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 36 - 239: dog - cat || Loss: 1.1905657052993774\n",
      "tensor([0., 1.]) tensor([0.8773, 0.1227], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 36 - 240: dog - cat || Loss: 1.190272569656372\n",
      "tensor([0., 1.]) tensor([0.8770, 0.1230], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 36 - 241: dog - cat || Loss: 1.1899785995483398\n",
      "tensor([0., 1.]) tensor([0.8767, 0.1233], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 36 - 242: dog - cat || Loss: 1.189683437347412\n",
      "tensor([0., 1.]) tensor([0.8764, 0.1236], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 36 - 243: dog - cat || Loss: 1.1893874406814575\n",
      "tensor([0., 1.]) tensor([0.8761, 0.1239], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 36 - 244: dog - cat || Loss: 1.189090609550476\n",
      "tensor([0., 1.]) tensor([0.8758, 0.1242], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 36 - 245: dog - cat || Loss: 1.1887929439544678\n",
      "tensor([0., 1.]) tensor([0.8755, 0.1245], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 36 - 246: dog - cat || Loss: 1.188494324684143\n",
      "tensor([0., 1.]) tensor([0.8752, 0.1248], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 36 - 247: dog - cat || Loss: 1.188194751739502\n",
      "tensor([0., 1.]) tensor([0.8749, 0.1251], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 36 - 248: dog - cat || Loss: 1.187894582748413\n",
      "tensor([0., 1.]) tensor([0.8746, 0.1254], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 36 - 249: dog - cat || Loss: 1.1875933408737183\n",
      "tensor([0., 1.]) tensor([0.8743, 0.1257], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 36 - 250: dog - cat || Loss: 1.1872913837432861\n",
      "tensor([0., 1.]) tensor([0.8740, 0.1260], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 36 - 251: dog - cat || Loss: 1.1869887113571167\n",
      "tensor([0., 1.]) tensor([0.8737, 0.1263], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 36 - 252: dog - cat || Loss: 1.1866849660873413\n",
      "tensor([0., 1.]) tensor([0.8734, 0.1266], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 36 - 253: dog - cat || Loss: 1.1863806247711182\n",
      "tensor([0., 1.]) tensor([0.8731, 0.1269], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 36 - 254: dog - cat || Loss: 1.1860754489898682\n",
      "tensor([0., 1.]) tensor([0.8728, 0.1272], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 36 - 255: dog - cat || Loss: 1.1857695579528809\n",
      "tensor([0., 1.]) tensor([0.8725, 0.1275], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 36 - 256: dog - cat || Loss: 1.1854628324508667\n",
      "tensor([0., 1.]) tensor([0.8722, 0.1278], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 36 - 257: dog - cat || Loss: 1.1851552724838257\n",
      "tensor([0., 1.]) tensor([0.8719, 0.1281], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 36 - 258: dog - cat || Loss: 1.184847116470337\n",
      "tensor([0., 1.]) tensor([0.8716, 0.1284], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 36 - 259: dog - cat || Loss: 1.1845381259918213\n",
      "tensor([0., 1.]) tensor([0.8713, 0.1287], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 36 - 260: dog - cat || Loss: 1.1842283010482788\n",
      "tensor([0., 1.]) tensor([0.8710, 0.1290], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 36 - 261: dog - cat || Loss: 1.183917760848999\n",
      "tensor([0., 1.]) tensor([0.8707, 0.1293], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 36 - 262: dog - cat || Loss: 1.183606505393982\n",
      "tensor([0., 1.]) tensor([0.8703, 0.1297], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 36 - 263: dog - cat || Loss: 1.1832945346832275\n",
      "tensor([0., 1.]) tensor([0.8700, 0.1300], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 36 - 264: dog - cat || Loss: 1.1829817295074463\n",
      "tensor([0., 1.]) tensor([0.8697, 0.1303], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 36 - 265: dog - cat || Loss: 1.1826682090759277\n",
      "tensor([0., 1.]) tensor([0.8694, 0.1306], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 36 - 266: dog - cat || Loss: 1.1823538541793823\n",
      "tensor([0., 1.]) tensor([0.8691, 0.1309], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 36 - 267: dog - cat || Loss: 1.1820387840270996\n",
      "tensor([0., 1.]) tensor([0.8688, 0.1312], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 36 - 268: dog - cat || Loss: 1.1817231178283691\n",
      "tensor([0., 1.]) tensor([0.8685, 0.1315], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 36 - 269: dog - cat || Loss: 1.1814064979553223\n",
      "tensor([0., 1.]) tensor([0.8681, 0.1319], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 36 - 270: dog - cat || Loss: 1.1810892820358276\n",
      "tensor([0., 1.]) tensor([0.8678, 0.1322], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 36 - 271: dog - cat || Loss: 1.1807712316513062\n",
      "tensor([0., 1.]) tensor([0.8675, 0.1325], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 36 - 272: dog - cat || Loss: 1.1804524660110474\n",
      "tensor([0., 1.]) tensor([0.8672, 0.1328], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 36 - 273: dog - cat || Loss: 1.1801328659057617\n",
      "tensor([0., 1.]) tensor([0.8669, 0.1331], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 36 - 274: dog - cat || Loss: 1.1798125505447388\n",
      "tensor([0., 1.]) tensor([0.8666, 0.1334], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 36 - 275: dog - cat || Loss: 1.179491639137268\n",
      "tensor([0., 1.]) tensor([0.8662, 0.1338], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 36 - 276: dog - cat || Loss: 1.179169774055481\n",
      "tensor([0., 1.]) tensor([0.8659, 0.1341], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 36 - 277: dog - cat || Loss: 1.1788474321365356\n",
      "tensor([0., 1.]) tensor([0.8656, 0.1344], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 36 - 278: dog - cat || Loss: 1.1785240173339844\n",
      "tensor([0., 1.]) tensor([0.8653, 0.1347], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 36 - 279: dog - cat || Loss: 1.178200125694275\n",
      "tensor([0., 1.]) tensor([0.8649, 0.1351], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 36 - 280: dog - cat || Loss: 1.177875280380249\n",
      "tensor([0., 1.]) tensor([0.8646, 0.1354], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 36 - 281: dog - cat || Loss: 1.1775498390197754\n",
      "tensor([0., 1.]) tensor([0.8643, 0.1357], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 36 - 282: dog - cat || Loss: 1.177223563194275\n",
      "tensor([0., 1.]) tensor([0.8640, 0.1360], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 36 - 283: dog - cat || Loss: 1.176896572113037\n",
      "tensor([0., 1.]) tensor([0.8636, 0.1364], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 36 - 284: dog - cat || Loss: 1.176568865776062\n",
      "tensor([0., 1.]) tensor([0.8633, 0.1367], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 36 - 285: dog - cat || Loss: 1.17624032497406\n",
      "tensor([0., 1.]) tensor([0.8630, 0.1370], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 36 - 286: dog - cat || Loss: 1.1759109497070312\n",
      "tensor([0., 1.]) tensor([0.8626, 0.1374], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 36 - 287: dog - cat || Loss: 1.1755809783935547\n",
      "tensor([0., 1.]) tensor([0.8623, 0.1377], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 36 - 288: dog - cat || Loss: 1.1752501726150513\n",
      "tensor([0., 1.]) tensor([0.8620, 0.1380], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 36 - 289: dog - cat || Loss: 1.174918532371521\n",
      "tensor([0., 1.]) tensor([0.8617, 0.1383], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 36 - 290: dog - cat || Loss: 1.174586296081543\n",
      "tensor([0., 1.]) tensor([0.8613, 0.1387], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 36 - 291: dog - cat || Loss: 1.1742531061172485\n",
      "tensor([0., 1.]) tensor([0.8610, 0.1390], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 36 - 292: dog - cat || Loss: 1.173919439315796\n",
      "tensor([0., 1.]) tensor([0.8607, 0.1393], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 36 - 293: dog - cat || Loss: 1.1735848188400269\n",
      "tensor([0., 1.]) tensor([0.8603, 0.1397], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 36 - 294: dog - cat || Loss: 1.173249363899231\n",
      "tensor([0., 1.]) tensor([0.8600, 0.1400], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 36 - 295: dog - cat || Loss: 1.1729133129119873\n",
      "tensor([0., 1.]) tensor([0.8597, 0.1403], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 36 - 296: dog - cat || Loss: 1.1725764274597168\n",
      "tensor([0., 1.]) tensor([0.8593, 0.1407], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 36 - 297: dog - cat || Loss: 1.1722389459609985\n",
      "tensor([0., 1.]) tensor([0.8590, 0.1410], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 36 - 298: dog - cat || Loss: 1.1719003915786743\n",
      "tensor([0., 1.]) tensor([0.8586, 0.1414], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 36 - 299: dog - cat || Loss: 1.1715612411499023\n",
      "tensor([0., 1.]) tensor([0.8583, 0.1417], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 36 - 300: dog - cat || Loss: 1.171221375465393\n",
      "tensor([0., 1.]) tensor([0.8580, 0.1420], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 36 - 301: dog - cat || Loss: 1.170880675315857\n",
      "tensor([0., 1.]) tensor([0.8576, 0.1424], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 36 - 302: dog - cat || Loss: 1.1705392599105835\n",
      "tensor([0., 1.]) tensor([0.8573, 0.1427], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 36 - 303: dog - cat || Loss: 1.1701968908309937\n",
      "tensor([0., 1.]) tensor([0.8569, 0.1431], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 36 - 304: dog - cat || Loss: 1.1698540449142456\n",
      "tensor([0., 1.]) tensor([0.8566, 0.1434], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 36 - 305: dog - cat || Loss: 1.169510006904602\n",
      "tensor([0., 1.]) tensor([0.8562, 0.1438], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 36 - 306: dog - cat || Loss: 1.1691656112670898\n",
      "tensor([0., 1.]) tensor([0.8559, 0.1441], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 36 - 307: dog - cat || Loss: 1.1688201427459717\n",
      "tensor([0., 1.]) tensor([0.8556, 0.1444], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 36 - 308: dog - cat || Loss: 1.1684739589691162\n",
      "tensor([0., 1.]) tensor([0.8552, 0.1448], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 36 - 309: dog - cat || Loss: 1.168127179145813\n",
      "tensor([0., 1.]) tensor([0.8549, 0.1451], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 36 - 310: dog - cat || Loss: 1.1677794456481934\n",
      "tensor([0., 1.]) tensor([0.8545, 0.1455], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 36 - 311: dog - cat || Loss: 1.1674308776855469\n",
      "tensor([0., 1.]) tensor([0.8542, 0.1458], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 36 - 312: dog - cat || Loss: 1.1670817136764526\n",
      "tensor([0., 1.]) tensor([0.8538, 0.1462], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 36 - 313: dog - cat || Loss: 1.166731595993042\n",
      "tensor([0., 1.]) tensor([0.8535, 0.1465], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 36 - 314: dog - cat || Loss: 1.1663810014724731\n",
      "tensor([0., 1.]) tensor([0.8531, 0.1469], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 36 - 315: dog - cat || Loss: 1.1660293340682983\n",
      "tensor([0., 1.]) tensor([0.8528, 0.1472], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 36 - 316: dog - cat || Loss: 1.1656768321990967\n",
      "tensor([0., 1.]) tensor([0.8524, 0.1476], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 36 - 317: dog - cat || Loss: 1.1653237342834473\n",
      "tensor([0., 1.]) tensor([0.8521, 0.1479], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 36 - 318: dog - cat || Loss: 1.164969801902771\n",
      "tensor([0., 1.]) tensor([0.8517, 0.1483], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 36 - 319: dog - cat || Loss: 1.1646150350570679\n",
      "tensor([0., 1.]) tensor([0.8514, 0.1486], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 36 - 320: dog - cat || Loss: 1.164259672164917\n",
      "tensor([0., 1.]) tensor([0.8510, 0.1490], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 36 - 321: dog - cat || Loss: 1.1639032363891602\n",
      "tensor([0., 1.]) tensor([0.8506, 0.1494], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 36 - 322: dog - cat || Loss: 1.1635462045669556\n",
      "tensor([0., 1.]) tensor([0.8503, 0.1497], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 36 - 323: dog - cat || Loss: 1.1631882190704346\n",
      "tensor([0., 1.]) tensor([0.8499, 0.1501], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 36 - 324: dog - cat || Loss: 1.1628296375274658\n",
      "tensor([0., 1.]) tensor([0.8496, 0.1504], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 36 - 325: dog - cat || Loss: 1.1624702215194702\n",
      "tensor([0., 1.]) tensor([0.8492, 0.1508], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 36 - 326: dog - cat || Loss: 1.1621099710464478\n",
      "tensor([0., 1.]) tensor([0.8488, 0.1512], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 36 - 327: dog - cat || Loss: 1.1617488861083984\n",
      "tensor([0., 1.]) tensor([0.8485, 0.1515], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 36 - 328: dog - cat || Loss: 1.1613870859146118\n",
      "tensor([0., 1.]) tensor([0.8481, 0.1519], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 36 - 329: dog - cat || Loss: 1.1610243320465088\n",
      "tensor([0., 1.]) tensor([0.8478, 0.1522], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 36 - 330: dog - cat || Loss: 1.160660982131958\n",
      "tensor([0., 1.]) tensor([0.8474, 0.1526], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 36 - 331: dog - cat || Loss: 1.1602966785430908\n",
      "tensor([0., 1.]) tensor([0.8470, 0.1530], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 36 - 332: dog - cat || Loss: 1.1599315404891968\n",
      "tensor([0., 1.]) tensor([0.8467, 0.1533], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 36 - 333: dog - cat || Loss: 1.1595656871795654\n",
      "tensor([0., 1.]) tensor([0.8463, 0.1537], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 36 - 334: dog - cat || Loss: 1.1591988801956177\n",
      "tensor([0., 1.]) tensor([0.8459, 0.1541], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 36 - 335: dog - cat || Loss: 1.1588315963745117\n",
      "tensor([0., 1.]) tensor([0.8456, 0.1544], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 36 - 336: dog - cat || Loss: 1.1584632396697998\n",
      "tensor([0., 1.]) tensor([0.8452, 0.1548], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 36 - 337: dog - cat || Loss: 1.1580941677093506\n",
      "tensor([0., 1.]) tensor([0.8448, 0.1552], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 36 - 338: dog - cat || Loss: 1.1577242612838745\n",
      "tensor([0., 1.]) tensor([0.8445, 0.1555], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 36 - 339: dog - cat || Loss: 1.1573536396026611\n",
      "tensor([0., 1.]) tensor([0.8441, 0.1559], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 36 - 340: dog - cat || Loss: 1.156982183456421\n",
      "tensor([0., 1.]) tensor([0.8437, 0.1563], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 36 - 341: dog - cat || Loss: 1.1566098928451538\n",
      "tensor([0., 1.]) tensor([0.8433, 0.1567], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 36 - 342: dog - cat || Loss: 1.1562367677688599\n",
      "tensor([0., 1.]) tensor([0.8430, 0.1570], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 36 - 343: dog - cat || Loss: 1.1558629274368286\n",
      "tensor([0., 1.]) tensor([0.8426, 0.1574], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 36 - 344: dog - cat || Loss: 1.155488133430481\n",
      "tensor([0., 1.]) tensor([0.8422, 0.1578], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 36 - 345: dog - cat || Loss: 1.155112385749817\n",
      "tensor([0., 1.]) tensor([0.8419, 0.1581], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 36 - 346: dog - cat || Loss: 1.1547362804412842\n",
      "tensor([0., 1.]) tensor([0.8415, 0.1585], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 36 - 347: dog - cat || Loss: 1.154358983039856\n",
      "tensor([0., 1.]) tensor([0.8411, 0.1589], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 36 - 348: dog - cat || Loss: 1.1539809703826904\n",
      "tensor([0., 1.]) tensor([0.8407, 0.1593], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 36 - 349: dog - cat || Loss: 1.153602123260498\n",
      "tensor([0., 1.]) tensor([0.8403, 0.1597], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 36 - 350: dog - cat || Loss: 1.1532224416732788\n",
      "tensor([0., 1.]) tensor([0.8400, 0.1600], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 36 - 351: dog - cat || Loss: 1.1528418064117432\n",
      "tensor([0., 1.]) tensor([0.8396, 0.1604], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 36 - 352: dog - cat || Loss: 1.1524605751037598\n",
      "tensor([0., 1.]) tensor([0.8392, 0.1608], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 36 - 353: dog - cat || Loss: 1.1520785093307495\n",
      "tensor([0., 1.]) tensor([0.8388, 0.1612], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 36 - 354: dog - cat || Loss: 1.1516954898834229\n",
      "tensor([0., 1.]) tensor([0.8384, 0.1616], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 36 - 355: dog - cat || Loss: 1.1513118743896484\n",
      "tensor([0., 1.]) tensor([0.8381, 0.1619], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 36 - 356: dog - cat || Loss: 1.1509273052215576\n",
      "tensor([0., 1.]) tensor([0.8377, 0.1623], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 36 - 357: dog - cat || Loss: 1.1505416631698608\n",
      "tensor([0., 1.]) tensor([0.8373, 0.1627], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 36 - 358: dog - cat || Loss: 1.1501555442810059\n",
      "tensor([0., 1.]) tensor([0.8369, 0.1631], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 36 - 359: dog - cat || Loss: 1.1497684717178345\n",
      "tensor([0., 1.]) tensor([0.8365, 0.1635], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 36 - 360: dog - cat || Loss: 1.1493806838989258\n",
      "tensor([0., 1.]) tensor([0.8361, 0.1639], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 36 - 361: dog - cat || Loss: 1.1489917039871216\n",
      "tensor([0., 1.]) tensor([0.8357, 0.1643], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 36 - 362: dog - cat || Loss: 1.1486022472381592\n",
      "tensor([0., 1.]) tensor([0.8353, 0.1647], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 36 - 363: dog - cat || Loss: 1.1482118368148804\n",
      "tensor([0., 1.]) tensor([0.8350, 0.1650], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 36 - 364: dog - cat || Loss: 1.1478205919265747\n",
      "tensor([0., 1.]) tensor([0.8346, 0.1654], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 36 - 365: dog - cat || Loss: 1.1474286317825317\n",
      "tensor([0., 1.]) tensor([0.8342, 0.1658], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 36 - 366: dog - cat || Loss: 1.1470355987548828\n",
      "tensor([0., 1.]) tensor([0.8338, 0.1662], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 36 - 367: dog - cat || Loss: 1.1466419696807861\n",
      "tensor([0., 1.]) tensor([0.8334, 0.1666], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 36 - 368: dog - cat || Loss: 1.1462472677230835\n",
      "tensor([0., 1.]) tensor([0.8330, 0.1670], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 36 - 369: dog - cat || Loss: 1.1458518505096436\n",
      "tensor([0., 1.]) tensor([0.8326, 0.1674], grad_fn=<SoftmaxBackward0>)\n",
      "=====epoch:37=====\n",
      "Epoch 37 - 0: cat - cat || Loss: 0.4810676574707031\n",
      "tensor([1., 0.]) tensor([0.8322, 0.1678], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 37 - 1: cat - cat || Loss: 0.4813844561576843\n",
      "tensor([1., 0.]) tensor([0.8319, 0.1681], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 37 - 2: cat - cat || Loss: 0.48162978887557983\n",
      "tensor([1., 0.]) tensor([0.8316, 0.1684], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 37 - 3: cat - cat || Loss: 0.48181039094924927\n",
      "tensor([1., 0.]) tensor([0.8315, 0.1685], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 37 - 4: cat - cat || Loss: 0.48193278908729553\n",
      "tensor([1., 0.]) tensor([0.8313, 0.1687], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 37 - 5: cat - cat || Loss: 0.4820026755332947\n",
      "tensor([1., 0.]) tensor([0.8313, 0.1687], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 37 - 6: cat - cat || Loss: 0.4820253849029541\n",
      "tensor([1., 0.]) tensor([0.8312, 0.1688], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 37 - 7: cat - cat || Loss: 0.4820055365562439\n",
      "tensor([1., 0.]) tensor([0.8313, 0.1687], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 37 - 8: cat - cat || Loss: 0.4819473922252655\n",
      "tensor([1., 0.]) tensor([0.8313, 0.1687], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 37 - 9: cat - cat || Loss: 0.4818548560142517\n",
      "tensor([1., 0.]) tensor([0.8314, 0.1686], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 37 - 10: cat - cat || Loss: 0.48173123598098755\n",
      "tensor([1., 0.]) tensor([0.8315, 0.1685], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 37 - 11: cat - cat || Loss: 0.4815800189971924\n",
      "tensor([1., 0.]) tensor([0.8317, 0.1683], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 37 - 12: cat - cat || Loss: 0.4814037084579468\n",
      "tensor([1., 0.]) tensor([0.8319, 0.1681], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 37 - 13: cat - cat || Loss: 0.481205016374588\n",
      "tensor([1., 0.]) tensor([0.8321, 0.1679], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 37 - 14: cat - cat || Loss: 0.4809862971305847\n",
      "tensor([1., 0.]) tensor([0.8323, 0.1677], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 37 - 15: cat - cat || Loss: 0.4807494282722473\n",
      "tensor([1., 0.]) tensor([0.8325, 0.1675], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 37 - 16: cat - cat || Loss: 0.48049643635749817\n",
      "tensor([1., 0.]) tensor([0.8328, 0.1672], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 37 - 17: cat - cat || Loss: 0.4802289605140686\n",
      "tensor([1., 0.]) tensor([0.8330, 0.1670], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 37 - 18: cat - cat || Loss: 0.47994861006736755\n",
      "tensor([1., 0.]) tensor([0.8333, 0.1667], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 37 - 19: cat - cat || Loss: 0.4796566367149353\n",
      "tensor([1., 0.]) tensor([0.8336, 0.1664], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 37 - 20: cat - cat || Loss: 0.47935420274734497\n",
      "tensor([1., 0.]) tensor([0.8339, 0.1661], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 37 - 21: cat - cat || Loss: 0.4790426790714264\n",
      "tensor([1., 0.]) tensor([0.8342, 0.1658], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 37 - 22: cat - cat || Loss: 0.4787229895591736\n",
      "tensor([1., 0.]) tensor([0.8345, 0.1655], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 37 - 23: cat - cat || Loss: 0.47839590907096863\n",
      "tensor([1., 0.]) tensor([0.8349, 0.1651], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 37 - 24: cat - cat || Loss: 0.47806239128112793\n",
      "tensor([1., 0.]) tensor([0.8352, 0.1648], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 37 - 25: cat - cat || Loss: 0.4777231216430664\n",
      "tensor([1., 0.]) tensor([0.8355, 0.1645], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 37 - 26: cat - cat || Loss: 0.477378785610199\n",
      "tensor([1., 0.]) tensor([0.8359, 0.1641], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 37 - 27: cat - cat || Loss: 0.47702980041503906\n",
      "tensor([1., 0.]) tensor([0.8362, 0.1638], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 37 - 28: cat - cat || Loss: 0.4766770601272583\n",
      "tensor([1., 0.]) tensor([0.8366, 0.1634], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 37 - 29: cat - cat || Loss: 0.4763205945491791\n",
      "tensor([1., 0.]) tensor([0.8369, 0.1631], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 37 - 30: cat - cat || Loss: 0.47596120834350586\n",
      "tensor([1., 0.]) tensor([0.8373, 0.1627], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 37 - 31: cat - cat || Loss: 0.4755990505218506\n",
      "tensor([1., 0.]) tensor([0.8377, 0.1623], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 37 - 32: cat - cat || Loss: 0.47523462772369385\n",
      "tensor([1., 0.]) tensor([0.8380, 0.1620], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 37 - 33: cat - cat || Loss: 0.4748682975769043\n",
      "tensor([1., 0.]) tensor([0.8384, 0.1616], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 37 - 34: cat - cat || Loss: 0.4745001792907715\n",
      "tensor([1., 0.]) tensor([0.8388, 0.1612], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 37 - 35: cat - cat || Loss: 0.4741305708885193\n",
      "tensor([1., 0.]) tensor([0.8391, 0.1609], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 37 - 36: cat - cat || Loss: 0.4737597107887268\n",
      "tensor([1., 0.]) tensor([0.8395, 0.1605], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 37 - 37: cat - cat || Loss: 0.4733878970146179\n",
      "tensor([1., 0.]) tensor([0.8399, 0.1601], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 37 - 38: cat - cat || Loss: 0.4730152487754822\n",
      "tensor([1., 0.]) tensor([0.8402, 0.1598], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 37 - 39: cat - cat || Loss: 0.47264188528060913\n",
      "tensor([1., 0.]) tensor([0.8406, 0.1594], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 37 - 40: cat - cat || Loss: 0.4722682237625122\n",
      "tensor([1., 0.]) tensor([0.8410, 0.1590], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 37 - 41: cat - cat || Loss: 0.47189390659332275\n",
      "tensor([1., 0.]) tensor([0.8414, 0.1586], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 37 - 42: cat - cat || Loss: 0.4715195596218109\n",
      "tensor([1., 0.]) tensor([0.8417, 0.1583], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 37 - 43: cat - cat || Loss: 0.4711449146270752\n",
      "tensor([1., 0.]) tensor([0.8421, 0.1579], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 37 - 44: cat - cat || Loss: 0.4707704484462738\n",
      "tensor([1., 0.]) tensor([0.8425, 0.1575], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 37 - 45: cat - cat || Loss: 0.4703957736492157\n",
      "tensor([1., 0.]) tensor([0.8429, 0.1571], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 37 - 46: cat - cat || Loss: 0.4700212776660919\n",
      "tensor([1., 0.]) tensor([0.8432, 0.1568], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 37 - 47: cat - cat || Loss: 0.46964704990386963\n",
      "tensor([1., 0.]) tensor([0.8436, 0.1564], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 37 - 48: cat - cat || Loss: 0.46927309036254883\n",
      "tensor([1., 0.]) tensor([0.8440, 0.1560], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 37 - 49: cat - cat || Loss: 0.4688993990421295\n",
      "tensor([1., 0.]) tensor([0.8444, 0.1556], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 37 - 50: cat - cat || Loss: 0.46852606534957886\n",
      "tensor([1., 0.]) tensor([0.8447, 0.1553], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 37 - 51: cat - cat || Loss: 0.4681532382965088\n",
      "tensor([1., 0.]) tensor([0.8451, 0.1549], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 37 - 52: cat - cat || Loss: 0.4677807092666626\n",
      "tensor([1., 0.]) tensor([0.8455, 0.1545], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 37 - 53: cat - cat || Loss: 0.4674087166786194\n",
      "tensor([1., 0.]) tensor([0.8459, 0.1541], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 37 - 54: cat - cat || Loss: 0.4670373499393463\n",
      "tensor([1., 0.]) tensor([0.8462, 0.1538], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 37 - 55: cat - cat || Loss: 0.46666648983955383\n",
      "tensor([1., 0.]) tensor([0.8466, 0.1534], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 37 - 56: cat - cat || Loss: 0.4662961959838867\n",
      "tensor([1., 0.]) tensor([0.8470, 0.1530], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 37 - 57: cat - cat || Loss: 0.4659264087677002\n",
      "tensor([1., 0.]) tensor([0.8473, 0.1527], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 37 - 58: cat - cat || Loss: 0.4655574858188629\n",
      "tensor([1., 0.]) tensor([0.8477, 0.1523], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 37 - 59: cat - cat || Loss: 0.4651891589164734\n",
      "tensor([1., 0.]) tensor([0.8481, 0.1519], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 37 - 60: cat - cat || Loss: 0.46482139825820923\n",
      "tensor([1., 0.]) tensor([0.8484, 0.1516], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 37 - 61: cat - cat || Loss: 0.4644542634487152\n",
      "tensor([1., 0.]) tensor([0.8488, 0.1512], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 37 - 62: cat - cat || Loss: 0.46408796310424805\n",
      "tensor([1., 0.]) tensor([0.8492, 0.1508], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 37 - 63: cat - cat || Loss: 0.46372246742248535\n",
      "tensor([1., 0.]) tensor([0.8495, 0.1505], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 37 - 64: cat - cat || Loss: 0.46335750818252563\n",
      "tensor([1., 0.]) tensor([0.8499, 0.1501], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 37 - 65: cat - cat || Loss: 0.462993323802948\n",
      "tensor([1., 0.]) tensor([0.8503, 0.1497], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 37 - 66: cat - cat || Loss: 0.46262991428375244\n",
      "tensor([1., 0.]) tensor([0.8506, 0.1494], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 37 - 67: cat - cat || Loss: 0.4622672200202942\n",
      "tensor([1., 0.]) tensor([0.8510, 0.1490], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 37 - 68: cat - cat || Loss: 0.4619053602218628\n",
      "tensor([1., 0.]) tensor([0.8514, 0.1486], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 37 - 69: cat - cat || Loss: 0.46154412627220154\n",
      "tensor([1., 0.]) tensor([0.8517, 0.1483], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 37 - 70: cat - cat || Loss: 0.4611837863922119\n",
      "tensor([1., 0.]) tensor([0.8521, 0.1479], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 37 - 71: cat - cat || Loss: 0.460824191570282\n",
      "tensor([1., 0.]) tensor([0.8524, 0.1476], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 37 - 72: cat - cat || Loss: 0.4604652523994446\n",
      "tensor([1., 0.]) tensor([0.8528, 0.1472], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 37 - 73: cat - cat || Loss: 0.4601072072982788\n",
      "tensor([1., 0.]) tensor([0.8532, 0.1468], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 37 - 74: cat - cat || Loss: 0.45974990725517273\n",
      "tensor([1., 0.]) tensor([0.8535, 0.1465], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 37 - 75: cat - cat || Loss: 0.45939338207244873\n",
      "tensor([1., 0.]) tensor([0.8539, 0.1461], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 37 - 76: cat - cat || Loss: 0.4590376615524292\n",
      "tensor([1., 0.]) tensor([0.8542, 0.1458], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 37 - 77: cat - cat || Loss: 0.4586828052997589\n",
      "tensor([1., 0.]) tensor([0.8546, 0.1454], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 37 - 78: cat - cat || Loss: 0.45832857489585876\n",
      "tensor([1., 0.]) tensor([0.8549, 0.1451], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 37 - 79: cat - cat || Loss: 0.45797520875930786\n",
      "tensor([1., 0.]) tensor([0.8553, 0.1447], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 37 - 80: cat - cat || Loss: 0.4576227068901062\n",
      "tensor([1., 0.]) tensor([0.8556, 0.1444], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 37 - 81: cat - cat || Loss: 0.45727092027664185\n",
      "tensor([1., 0.]) tensor([0.8560, 0.1440], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 37 - 82: cat - cat || Loss: 0.45691990852355957\n",
      "tensor([1., 0.]) tensor([0.8563, 0.1437], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 37 - 83: cat - cat || Loss: 0.45656973123550415\n",
      "tensor([1., 0.]) tensor([0.8567, 0.1433], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 37 - 84: cat - cat || Loss: 0.45622044801712036\n",
      "tensor([1., 0.]) tensor([0.8570, 0.1430], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 37 - 85: cat - cat || Loss: 0.4558718204498291\n",
      "tensor([1., 0.]) tensor([0.8574, 0.1426], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 37 - 86: cat - cat || Loss: 0.4555240869522095\n",
      "tensor([1., 0.]) tensor([0.8577, 0.1423], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 37 - 87: cat - cat || Loss: 0.4551771283149719\n",
      "tensor([1., 0.]) tensor([0.8581, 0.1419], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 37 - 88: cat - cat || Loss: 0.45483097434043884\n",
      "tensor([1., 0.]) tensor([0.8584, 0.1416], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 37 - 89: cat - cat || Loss: 0.45448559522628784\n",
      "tensor([1., 0.]) tensor([0.8588, 0.1412], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 37 - 90: cat - cat || Loss: 0.4541410207748413\n",
      "tensor([1., 0.]) tensor([0.8591, 0.1409], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 37 - 91: cat - cat || Loss: 0.4537971019744873\n",
      "tensor([1., 0.]) tensor([0.8595, 0.1405], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 37 - 92: cat - cat || Loss: 0.4534541666507721\n",
      "tensor([1., 0.]) tensor([0.8598, 0.1402], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 37 - 93: cat - cat || Loss: 0.45311206579208374\n",
      "tensor([1., 0.]) tensor([0.8601, 0.1399], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 37 - 94: cat - cat || Loss: 0.45277053117752075\n",
      "tensor([1., 0.]) tensor([0.8605, 0.1395], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 37 - 95: cat - cat || Loss: 0.4524298906326294\n",
      "tensor([1., 0.]) tensor([0.8608, 0.1392], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 37 - 96: cat - cat || Loss: 0.4520901143550873\n",
      "tensor([1., 0.]) tensor([0.8612, 0.1388], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 37 - 97: cat - cat || Loss: 0.45175105333328247\n",
      "tensor([1., 0.]) tensor([0.8615, 0.1385], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 37 - 98: cat - cat || Loss: 0.45141273736953735\n",
      "tensor([1., 0.]) tensor([0.8618, 0.1382], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 37 - 99: cat - cat || Loss: 0.45107534527778625\n",
      "tensor([1., 0.]) tensor([0.8622, 0.1378], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 37 - 100: cat - cat || Loss: 0.4507386386394501\n",
      "tensor([1., 0.]) tensor([0.8625, 0.1375], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 37 - 101: cat - cat || Loss: 0.45040270686149597\n",
      "tensor([1., 0.]) tensor([0.8629, 0.1371], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 37 - 102: cat - cat || Loss: 0.4500676691532135\n",
      "tensor([1., 0.]) tensor([0.8632, 0.1368], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 37 - 103: cat - cat || Loss: 0.44973331689834595\n",
      "tensor([1., 0.]) tensor([0.8635, 0.1365], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 37 - 104: cat - cat || Loss: 0.44939976930618286\n",
      "tensor([1., 0.]) tensor([0.8639, 0.1361], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 37 - 105: cat - cat || Loss: 0.449067085981369\n",
      "tensor([1., 0.]) tensor([0.8642, 0.1358], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 37 - 106: cat - cat || Loss: 0.4487350583076477\n",
      "tensor([1., 0.]) tensor([0.8645, 0.1355], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 37 - 107: cat - cat || Loss: 0.44840389490127563\n",
      "tensor([1., 0.]) tensor([0.8649, 0.1351], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 37 - 108: cat - cat || Loss: 0.4480735659599304\n",
      "tensor([1., 0.]) tensor([0.8652, 0.1348], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 37 - 109: cat - cat || Loss: 0.44774389266967773\n",
      "tensor([1., 0.]) tensor([0.8655, 0.1345], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 37 - 110: cat - cat || Loss: 0.4474150538444519\n",
      "tensor([1., 0.]) tensor([0.8658, 0.1342], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 37 - 111: cat - cat || Loss: 0.44708704948425293\n",
      "tensor([1., 0.]) tensor([0.8662, 0.1338], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 37 - 112: cat - cat || Loss: 0.4467596709728241\n",
      "tensor([1., 0.]) tensor([0.8665, 0.1335], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 37 - 113: cat - cat || Loss: 0.44643324613571167\n",
      "tensor([1., 0.]) tensor([0.8668, 0.1332], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 37 - 114: cat - cat || Loss: 0.4461074471473694\n",
      "tensor([1., 0.]) tensor([0.8672, 0.1328], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 37 - 115: cat - cat || Loss: 0.44578248262405396\n",
      "tensor([1., 0.]) tensor([0.8675, 0.1325], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 37 - 116: cat - cat || Loss: 0.4454582929611206\n",
      "tensor([1., 0.]) tensor([0.8678, 0.1322], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 37 - 117: cat - cat || Loss: 0.44513481855392456\n",
      "tensor([1., 0.]) tensor([0.8681, 0.1319], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 37 - 118: cat - cat || Loss: 0.44481220841407776\n",
      "tensor([1., 0.]) tensor([0.8684, 0.1316], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 37 - 119: cat - cat || Loss: 0.4444904029369354\n",
      "tensor([1., 0.]) tensor([0.8688, 0.1312], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 37 - 120: cat - cat || Loss: 0.4441692531108856\n",
      "tensor([1., 0.]) tensor([0.8691, 0.1309], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 37 - 121: cat - cat || Loss: 0.44384878873825073\n",
      "tensor([1., 0.]) tensor([0.8694, 0.1306], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 37 - 122: cat - cat || Loss: 0.44352927803993225\n",
      "tensor([1., 0.]) tensor([0.8697, 0.1303], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 37 - 123: cat - cat || Loss: 0.4432104527950287\n",
      "tensor([1., 0.]) tensor([0.8701, 0.1299], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 37 - 124: cat - cat || Loss: 0.4428923726081848\n",
      "tensor([1., 0.]) tensor([0.8704, 0.1296], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 37 - 125: cat - cat || Loss: 0.4425750970840454\n",
      "tensor([1., 0.]) tensor([0.8707, 0.1293], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 37 - 126: cat - cat || Loss: 0.4422585368156433\n",
      "tensor([1., 0.]) tensor([0.8710, 0.1290], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 37 - 127: cat - cat || Loss: 0.44194263219833374\n",
      "tensor([1., 0.]) tensor([0.8713, 0.1287], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 37 - 128: cat - cat || Loss: 0.4416276812553406\n",
      "tensor([1., 0.]) tensor([0.8716, 0.1284], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 37 - 129: cat - cat || Loss: 0.4413134455680847\n",
      "tensor([1., 0.]) tensor([0.8719, 0.1281], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 37 - 130: cat - cat || Loss: 0.44099992513656616\n",
      "tensor([1., 0.]) tensor([0.8723, 0.1277], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 37 - 131: cat - cat || Loss: 0.4406871199607849\n",
      "tensor([1., 0.]) tensor([0.8726, 0.1274], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 37 - 132: cat - cat || Loss: 0.44037508964538574\n",
      "tensor([1., 0.]) tensor([0.8729, 0.1271], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 37 - 133: cat - cat || Loss: 0.44006383419036865\n",
      "tensor([1., 0.]) tensor([0.8732, 0.1268], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 37 - 134: cat - cat || Loss: 0.43975332379341125\n",
      "tensor([1., 0.]) tensor([0.8735, 0.1265], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 37 - 135: cat - cat || Loss: 0.4394436478614807\n",
      "tensor([1., 0.]) tensor([0.8738, 0.1262], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 37 - 136: cat - cat || Loss: 0.4391345977783203\n",
      "tensor([1., 0.]) tensor([0.8741, 0.1259], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 37 - 137: cat - cat || Loss: 0.438826322555542\n",
      "tensor([1., 0.]) tensor([0.8744, 0.1256], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 37 - 138: cat - cat || Loss: 0.43851882219314575\n",
      "tensor([1., 0.]) tensor([0.8747, 0.1253], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 37 - 139: cat - cat || Loss: 0.4382120966911316\n",
      "tensor([1., 0.]) tensor([0.8750, 0.1250], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 37 - 140: cat - cat || Loss: 0.43790608644485474\n",
      "tensor([1., 0.]) tensor([0.8754, 0.1246], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 37 - 141: cat - cat || Loss: 0.4376007616519928\n",
      "tensor([1., 0.]) tensor([0.8757, 0.1243], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 37 - 142: cat - cat || Loss: 0.4372962713241577\n",
      "tensor([1., 0.]) tensor([0.8760, 0.1240], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 37 - 143: cat - cat || Loss: 0.43699243664741516\n",
      "tensor([1., 0.]) tensor([0.8763, 0.1237], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 37 - 144: cat - cat || Loss: 0.4366894066333771\n",
      "tensor([1., 0.]) tensor([0.8766, 0.1234], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 37 - 145: cat - cat || Loss: 0.4363870620727539\n",
      "tensor([1., 0.]) tensor([0.8769, 0.1231], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 37 - 146: cat - cat || Loss: 0.4360854923725128\n",
      "tensor([1., 0.]) tensor([0.8772, 0.1228], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 37 - 147: cat - cat || Loss: 0.43578460812568665\n",
      "tensor([1., 0.]) tensor([0.8775, 0.1225], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 37 - 148: cat - cat || Loss: 0.43548446893692017\n",
      "tensor([1., 0.]) tensor([0.8778, 0.1222], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 37 - 149: cat - cat || Loss: 0.4351850152015686\n",
      "tensor([1., 0.]) tensor([0.8781, 0.1219], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 37 - 150: cat - cat || Loss: 0.43488627672195435\n",
      "tensor([1., 0.]) tensor([0.8784, 0.1216], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 37 - 151: cat - cat || Loss: 0.4345884323120117\n",
      "tensor([1., 0.]) tensor([0.8787, 0.1213], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 37 - 152: cat - cat || Loss: 0.4342912435531616\n",
      "tensor([1., 0.]) tensor([0.8790, 0.1210], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 37 - 153: cat - cat || Loss: 0.43399471044540405\n",
      "tensor([1., 0.]) tensor([0.8793, 0.1207], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 37 - 154: cat - cat || Loss: 0.43369895219802856\n",
      "tensor([1., 0.]) tensor([0.8796, 0.1204], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 37 - 155: cat - cat || Loss: 0.4334038496017456\n",
      "tensor([1., 0.]) tensor([0.8799, 0.1201], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 37 - 156: cat - cat || Loss: 0.4331095814704895\n",
      "tensor([1., 0.]) tensor([0.8802, 0.1198], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 37 - 157: cat - cat || Loss: 0.4328160285949707\n",
      "tensor([1., 0.]) tensor([0.8804, 0.1196], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 37 - 158: cat - cat || Loss: 0.43252307176589966\n",
      "tensor([1., 0.]) tensor([0.8807, 0.1193], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 37 - 159: cat - cat || Loss: 0.4322308897972107\n",
      "tensor([1., 0.]) tensor([0.8810, 0.1190], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 37 - 160: cat - cat || Loss: 0.43193936347961426\n",
      "tensor([1., 0.]) tensor([0.8813, 0.1187], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 37 - 161: cat - cat || Loss: 0.4316486716270447\n",
      "tensor([1., 0.]) tensor([0.8816, 0.1184], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 37 - 162: cat - cat || Loss: 0.4313586950302124\n",
      "tensor([1., 0.]) tensor([0.8819, 0.1181], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 37 - 163: cat - cat || Loss: 0.43106937408447266\n",
      "tensor([1., 0.]) tensor([0.8822, 0.1178], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 37 - 164: cat - cat || Loss: 0.4307807385921478\n",
      "tensor([1., 0.]) tensor([0.8825, 0.1175], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 37 - 165: cat - cat || Loss: 0.43049293756484985\n",
      "tensor([1., 0.]) tensor([0.8828, 0.1172], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 37 - 166: cat - cat || Loss: 0.43020570278167725\n",
      "tensor([1., 0.]) tensor([0.8831, 0.1169], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 37 - 167: cat - cat || Loss: 0.4299192428588867\n",
      "tensor([1., 0.]) tensor([0.8833, 0.1167], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 37 - 168: cat - cat || Loss: 0.4296334683895111\n",
      "tensor([1., 0.]) tensor([0.8836, 0.1164], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 37 - 169: cat - cat || Loss: 0.4293483793735504\n",
      "tensor([1., 0.]) tensor([0.8839, 0.1161], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 37 - 170: cat - cat || Loss: 0.4290640652179718\n",
      "tensor([1., 0.]) tensor([0.8842, 0.1158], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 37 - 171: cat - cat || Loss: 0.4287804365158081\n",
      "tensor([1., 0.]) tensor([0.8845, 0.1155], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 37 - 172: cat - cat || Loss: 0.4284974932670593\n",
      "tensor([1., 0.]) tensor([0.8848, 0.1152], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 37 - 173: cat - cat || Loss: 0.4282153248786926\n",
      "tensor([1., 0.]) tensor([0.8850, 0.1150], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 37 - 174: cat - cat || Loss: 0.4279337525367737\n",
      "tensor([1., 0.]) tensor([0.8853, 0.1147], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 37 - 175: cat - cat || Loss: 0.42765286564826965\n",
      "tensor([1., 0.]) tensor([0.8856, 0.1144], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 37 - 176: cat - cat || Loss: 0.42737266421318054\n",
      "tensor([1., 0.]) tensor([0.8859, 0.1141], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 37 - 177: cat - cat || Loss: 0.4270932078361511\n",
      "tensor([1., 0.]) tensor([0.8862, 0.1138], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 37 - 178: cat - cat || Loss: 0.4268144369125366\n",
      "tensor([1., 0.]) tensor([0.8864, 0.1136], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 37 - 179: cat - cat || Loss: 0.42653632164001465\n",
      "tensor([1., 0.]) tensor([0.8867, 0.1133], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 37 - 180: cat - cat || Loss: 0.42625898122787476\n",
      "tensor([1., 0.]) tensor([0.8870, 0.1130], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 37 - 181: cat - cat || Loss: 0.42598217725753784\n",
      "tensor([1., 0.]) tensor([0.8873, 0.1127], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 37 - 182: cat - cat || Loss: 0.425706148147583\n",
      "tensor([1., 0.]) tensor([0.8876, 0.1124], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 37 - 183: cat - cat || Loss: 0.42543089389801025\n",
      "tensor([1., 0.]) tensor([0.8878, 0.1122], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 37 - 184: cat - cat || Loss: 0.4251561760902405\n",
      "tensor([1., 0.]) tensor([0.8881, 0.1119], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 37 - 185: cat - cat || Loss: 0.4248822331428528\n",
      "tensor([1., 0.]) tensor([0.8884, 0.1116], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 37 - 186: cat - cat || Loss: 0.42460882663726807\n",
      "tensor([1., 0.]) tensor([0.8887, 0.1113], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 37 - 187: cat - cat || Loss: 0.42433619499206543\n",
      "tensor([1., 0.]) tensor([0.8889, 0.1111], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 37 - 188: cat - cat || Loss: 0.42406418919563293\n",
      "tensor([1., 0.]) tensor([0.8892, 0.1108], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 37 - 189: cat - cat || Loss: 0.4237927794456482\n",
      "tensor([1., 0.]) tensor([0.8895, 0.1105], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 37 - 190: dog - cat || Loss: 1.2030012607574463\n",
      "tensor([0., 1.]) tensor([0.8897, 0.1103], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 37 - 191: dog - cat || Loss: 1.20321786403656\n",
      "tensor([0., 1.]) tensor([0.8900, 0.1100], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 37 - 192: dog - cat || Loss: 1.2033860683441162\n",
      "tensor([0., 1.]) tensor([0.8901, 0.1099], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 37 - 193: dog - cat || Loss: 1.2035105228424072\n",
      "tensor([0., 1.]) tensor([0.8902, 0.1098], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 37 - 194: dog - cat || Loss: 1.2035958766937256\n",
      "tensor([0., 1.]) tensor([0.8903, 0.1097], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 37 - 195: dog - cat || Loss: 1.203646183013916\n",
      "tensor([0., 1.]) tensor([0.8904, 0.1096], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 37 - 196: dog - cat || Loss: 1.203664779663086\n",
      "tensor([0., 1.]) tensor([0.8904, 0.1096], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 37 - 197: dog - cat || Loss: 1.2036548852920532\n",
      "tensor([0., 1.]) tensor([0.8904, 0.1096], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 37 - 198: dog - cat || Loss: 1.2036194801330566\n",
      "tensor([0., 1.]) tensor([0.8904, 0.1096], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 37 - 199: dog - cat || Loss: 1.2035610675811768\n",
      "tensor([0., 1.]) tensor([0.8903, 0.1097], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 37 - 200: dog - cat || Loss: 1.2034817934036255\n",
      "tensor([0., 1.]) tensor([0.8902, 0.1098], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 37 - 201: dog - cat || Loss: 1.2033836841583252\n",
      "tensor([0., 1.]) tensor([0.8901, 0.1099], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 37 - 202: dog - cat || Loss: 1.2032687664031982\n",
      "tensor([0., 1.]) tensor([0.8900, 0.1100], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 37 - 203: dog - cat || Loss: 1.2031387090682983\n",
      "tensor([0., 1.]) tensor([0.8899, 0.1101], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 37 - 204: dog - cat || Loss: 1.2029948234558105\n",
      "tensor([0., 1.]) tensor([0.8897, 0.1103], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 37 - 205: dog - cat || Loss: 1.20283842086792\n",
      "tensor([0., 1.]) tensor([0.8896, 0.1104], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 37 - 206: dog - cat || Loss: 1.2026710510253906\n",
      "tensor([0., 1.]) tensor([0.8894, 0.1106], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 37 - 207: dog - cat || Loss: 1.20249342918396\n",
      "tensor([0., 1.]) tensor([0.8892, 0.1108], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 37 - 208: dog - cat || Loss: 1.2023062705993652\n",
      "tensor([0., 1.]) tensor([0.8890, 0.1110], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 37 - 209: dog - cat || Loss: 1.202111005783081\n",
      "tensor([0., 1.]) tensor([0.8888, 0.1112], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 37 - 210: dog - cat || Loss: 1.2019083499908447\n",
      "tensor([0., 1.]) tensor([0.8886, 0.1114], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 37 - 211: dog - cat || Loss: 1.201698899269104\n",
      "tensor([0., 1.]) tensor([0.8884, 0.1116], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 37 - 212: dog - cat || Loss: 1.201482892036438\n",
      "tensor([0., 1.]) tensor([0.8882, 0.1118], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 37 - 213: dog - cat || Loss: 1.201261281967163\n",
      "tensor([0., 1.]) tensor([0.8880, 0.1120], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 37 - 214: dog - cat || Loss: 1.201034426689148\n",
      "tensor([0., 1.]) tensor([0.8878, 0.1122], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 37 - 215: dog - cat || Loss: 1.2008029222488403\n",
      "tensor([0., 1.]) tensor([0.8875, 0.1125], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 37 - 216: dog - cat || Loss: 1.2005670070648193\n",
      "tensor([0., 1.]) tensor([0.8873, 0.1127], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 37 - 217: dog - cat || Loss: 1.2003271579742432\n",
      "tensor([0., 1.]) tensor([0.8871, 0.1129], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 37 - 218: dog - cat || Loss: 1.20008385181427\n",
      "tensor([0., 1.]) tensor([0.8868, 0.1132], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 37 - 219: dog - cat || Loss: 1.1998369693756104\n",
      "tensor([0., 1.]) tensor([0.8866, 0.1134], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 37 - 220: dog - cat || Loss: 1.1995872259140015\n",
      "tensor([0., 1.]) tensor([0.8863, 0.1137], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 37 - 221: dog - cat || Loss: 1.1993346214294434\n",
      "tensor([0., 1.]) tensor([0.8861, 0.1139], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 37 - 222: dog - cat || Loss: 1.1990792751312256\n",
      "tensor([0., 1.]) tensor([0.8858, 0.1142], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 37 - 223: dog - cat || Loss: 1.198821783065796\n",
      "tensor([0., 1.]) tensor([0.8856, 0.1144], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 37 - 224: dog - cat || Loss: 1.1985617876052856\n",
      "tensor([0., 1.]) tensor([0.8853, 0.1147], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 37 - 225: dog - cat || Loss: 1.1982998847961426\n",
      "tensor([0., 1.]) tensor([0.8850, 0.1150], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 37 - 226: dog - cat || Loss: 1.1980359554290771\n",
      "tensor([0., 1.]) tensor([0.8848, 0.1152], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 37 - 227: dog - cat || Loss: 1.1977702379226685\n",
      "tensor([0., 1.]) tensor([0.8845, 0.1155], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 37 - 228: dog - cat || Loss: 1.197502851486206\n",
      "tensor([0., 1.]) tensor([0.8842, 0.1158], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 37 - 229: dog - cat || Loss: 1.1972339153289795\n",
      "tensor([0., 1.]) tensor([0.8840, 0.1160], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 37 - 230: dog - cat || Loss: 1.1969631910324097\n",
      "tensor([0., 1.]) tensor([0.8837, 0.1163], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 37 - 231: dog - cat || Loss: 1.1966913938522339\n",
      "tensor([0., 1.]) tensor([0.8834, 0.1166], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 37 - 232: dog - cat || Loss: 1.1964181661605835\n",
      "tensor([0., 1.]) tensor([0.8832, 0.1168], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 37 - 233: dog - cat || Loss: 1.1961435079574585\n",
      "tensor([0., 1.]) tensor([0.8829, 0.1171], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 37 - 234: dog - cat || Loss: 1.195867657661438\n",
      "tensor([0., 1.]) tensor([0.8826, 0.1174], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 37 - 235: dog - cat || Loss: 1.195590853691101\n",
      "tensor([0., 1.]) tensor([0.8823, 0.1177], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 37 - 236: dog - cat || Loss: 1.195312738418579\n",
      "tensor([0., 1.]) tensor([0.8821, 0.1179], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 37 - 237: dog - cat || Loss: 1.1950335502624512\n",
      "tensor([0., 1.]) tensor([0.8818, 0.1182], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 37 - 238: dog - cat || Loss: 1.1947534084320068\n",
      "tensor([0., 1.]) tensor([0.8815, 0.1185], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 37 - 239: dog - cat || Loss: 1.1944721937179565\n",
      "tensor([0., 1.]) tensor([0.8812, 0.1188], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 37 - 240: dog - cat || Loss: 1.1941901445388794\n",
      "tensor([0., 1.]) tensor([0.8809, 0.1191], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 37 - 241: dog - cat || Loss: 1.1939071416854858\n",
      "tensor([0., 1.]) tensor([0.8806, 0.1194], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 37 - 242: dog - cat || Loss: 1.1936230659484863\n",
      "tensor([0., 1.]) tensor([0.8804, 0.1196], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 37 - 243: dog - cat || Loss: 1.19333815574646\n",
      "tensor([0., 1.]) tensor([0.8801, 0.1199], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 37 - 244: dog - cat || Loss: 1.1930524110794067\n",
      "tensor([0., 1.]) tensor([0.8798, 0.1202], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 37 - 245: dog - cat || Loss: 1.1927658319473267\n",
      "tensor([0., 1.]) tensor([0.8795, 0.1205], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 37 - 246: dog - cat || Loss: 1.1924784183502197\n",
      "tensor([0., 1.]) tensor([0.8792, 0.1208], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 37 - 247: dog - cat || Loss: 1.192190170288086\n",
      "tensor([0., 1.]) tensor([0.8789, 0.1211], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 37 - 248: dog - cat || Loss: 1.1919010877609253\n",
      "tensor([0., 1.]) tensor([0.8786, 0.1214], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 37 - 249: dog - cat || Loss: 1.1916111707687378\n",
      "tensor([0., 1.]) tensor([0.8783, 0.1217], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 37 - 250: dog - cat || Loss: 1.1913204193115234\n",
      "tensor([0., 1.]) tensor([0.8781, 0.1219], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 37 - 251: dog - cat || Loss: 1.1910290718078613\n",
      "tensor([0., 1.]) tensor([0.8778, 0.1222], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 37 - 252: dog - cat || Loss: 1.1907367706298828\n",
      "tensor([0., 1.]) tensor([0.8775, 0.1225], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 37 - 253: dog - cat || Loss: 1.1904436349868774\n",
      "tensor([0., 1.]) tensor([0.8772, 0.1228], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 37 - 254: dog - cat || Loss: 1.1901500225067139\n",
      "tensor([0., 1.]) tensor([0.8769, 0.1231], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 37 - 255: dog - cat || Loss: 1.1898554563522339\n",
      "tensor([0., 1.]) tensor([0.8766, 0.1234], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 37 - 256: dog - cat || Loss: 1.1895601749420166\n",
      "tensor([0., 1.]) tensor([0.8763, 0.1237], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 37 - 257: dog - cat || Loss: 1.1892640590667725\n",
      "tensor([0., 1.]) tensor([0.8760, 0.1240], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 37 - 258: dog - cat || Loss: 1.1889674663543701\n",
      "tensor([0., 1.]) tensor([0.8757, 0.1243], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 37 - 259: dog - cat || Loss: 1.188670039176941\n",
      "tensor([0., 1.]) tensor([0.8754, 0.1246], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 37 - 260: dog - cat || Loss: 1.1883716583251953\n",
      "tensor([0., 1.]) tensor([0.8751, 0.1249], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 37 - 261: dog - cat || Loss: 1.1880728006362915\n",
      "tensor([0., 1.]) tensor([0.8748, 0.1252], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 37 - 262: dog - cat || Loss: 1.1877731084823608\n",
      "tensor([0., 1.]) tensor([0.8745, 0.1255], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 37 - 263: dog - cat || Loss: 1.1874727010726929\n",
      "tensor([0., 1.]) tensor([0.8742, 0.1258], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 37 - 264: dog - cat || Loss: 1.187171459197998\n",
      "tensor([0., 1.]) tensor([0.8739, 0.1261], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 37 - 265: dog - cat || Loss: 1.1868696212768555\n",
      "tensor([0., 1.]) tensor([0.8736, 0.1264], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 37 - 266: dog - cat || Loss: 1.1865670680999756\n",
      "tensor([0., 1.]) tensor([0.8733, 0.1267], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 37 - 267: dog - cat || Loss: 1.1862636804580688\n",
      "tensor([0., 1.]) tensor([0.8730, 0.1270], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 37 - 268: dog - cat || Loss: 1.1859594583511353\n",
      "tensor([0., 1.]) tensor([0.8727, 0.1273], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 37 - 269: dog - cat || Loss: 1.1856547594070435\n",
      "tensor([0., 1.]) tensor([0.8724, 0.1276], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 37 - 270: dog - cat || Loss: 1.1853493452072144\n",
      "tensor([0., 1.]) tensor([0.8721, 0.1279], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 37 - 271: dog - cat || Loss: 1.185043215751648\n",
      "tensor([0., 1.]) tensor([0.8718, 0.1282], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 37 - 272: dog - cat || Loss: 1.1847360134124756\n",
      "tensor([0., 1.]) tensor([0.8715, 0.1285], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 37 - 273: dog - cat || Loss: 1.184428334236145\n",
      "tensor([0., 1.]) tensor([0.8712, 0.1288], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 37 - 274: dog - cat || Loss: 1.184119701385498\n",
      "tensor([0., 1.]) tensor([0.8709, 0.1291], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 37 - 275: dog - cat || Loss: 1.1838105916976929\n",
      "tensor([0., 1.]) tensor([0.8705, 0.1295], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 37 - 276: dog - cat || Loss: 1.1835007667541504\n",
      "tensor([0., 1.]) tensor([0.8702, 0.1298], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 37 - 277: dog - cat || Loss: 1.1831902265548706\n",
      "tensor([0., 1.]) tensor([0.8699, 0.1301], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 37 - 278: dog - cat || Loss: 1.1828789710998535\n",
      "tensor([0., 1.]) tensor([0.8696, 0.1304], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 37 - 279: dog - cat || Loss: 1.1825668811798096\n",
      "tensor([0., 1.]) tensor([0.8693, 0.1307], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 37 - 280: dog - cat || Loss: 1.1822539567947388\n",
      "tensor([0., 1.]) tensor([0.8690, 0.1310], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 37 - 281: dog - cat || Loss: 1.1819405555725098\n",
      "tensor([0., 1.]) tensor([0.8687, 0.1313], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 37 - 282: dog - cat || Loss: 1.181626319885254\n",
      "tensor([0., 1.]) tensor([0.8684, 0.1316], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 37 - 283: dog - cat || Loss: 1.1813113689422607\n",
      "tensor([0., 1.]) tensor([0.8680, 0.1320], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 37 - 284: dog - cat || Loss: 1.1809954643249512\n",
      "tensor([0., 1.]) tensor([0.8677, 0.1323], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 37 - 285: dog - cat || Loss: 1.1806790828704834\n",
      "tensor([0., 1.]) tensor([0.8674, 0.1326], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 37 - 286: dog - cat || Loss: 1.1803618669509888\n",
      "tensor([0., 1.]) tensor([0.8671, 0.1329], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 37 - 287: dog - cat || Loss: 1.1800439357757568\n",
      "tensor([0., 1.]) tensor([0.8668, 0.1332], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 37 - 288: dog - cat || Loss: 1.1797254085540771\n",
      "tensor([0., 1.]) tensor([0.8665, 0.1335], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 37 - 289: dog - cat || Loss: 1.1794058084487915\n",
      "tensor([0., 1.]) tensor([0.8661, 0.1339], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 37 - 290: dog - cat || Loss: 1.1790857315063477\n",
      "tensor([0., 1.]) tensor([0.8658, 0.1342], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 37 - 291: dog - cat || Loss: 1.1787649393081665\n",
      "tensor([0., 1.]) tensor([0.8655, 0.1345], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 37 - 292: dog - cat || Loss: 1.1784433126449585\n",
      "tensor([0., 1.]) tensor([0.8652, 0.1348], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 37 - 293: dog - cat || Loss: 1.1781208515167236\n",
      "tensor([0., 1.]) tensor([0.8649, 0.1351], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 37 - 294: dog - cat || Loss: 1.177797794342041\n",
      "tensor([0., 1.]) tensor([0.8645, 0.1355], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 37 - 295: dog - cat || Loss: 1.1774739027023315\n",
      "tensor([0., 1.]) tensor([0.8642, 0.1358], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 37 - 296: dog - cat || Loss: 1.1771494150161743\n",
      "tensor([0., 1.]) tensor([0.8639, 0.1361], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 37 - 297: dog - cat || Loss: 1.1768240928649902\n",
      "tensor([0., 1.]) tensor([0.8636, 0.1364], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 37 - 298: dog - cat || Loss: 1.1764979362487793\n",
      "tensor([0., 1.]) tensor([0.8632, 0.1368], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 37 - 299: dog - cat || Loss: 1.176171064376831\n",
      "tensor([0., 1.]) tensor([0.8629, 0.1371], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 37 - 300: dog - cat || Loss: 1.1758434772491455\n",
      "tensor([0., 1.]) tensor([0.8626, 0.1374], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 37 - 301: dog - cat || Loss: 1.175515055656433\n",
      "tensor([0., 1.]) tensor([0.8623, 0.1377], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 37 - 302: dog - cat || Loss: 1.1751861572265625\n",
      "tensor([0., 1.]) tensor([0.8619, 0.1381], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 37 - 303: dog - cat || Loss: 1.174856185913086\n",
      "tensor([0., 1.]) tensor([0.8616, 0.1384], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 37 - 304: dog - cat || Loss: 1.174525499343872\n",
      "tensor([0., 1.]) tensor([0.8613, 0.1387], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 37 - 305: dog - cat || Loss: 1.174194097518921\n",
      "tensor([0., 1.]) tensor([0.8609, 0.1391], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 37 - 306: dog - cat || Loss: 1.1738622188568115\n",
      "tensor([0., 1.]) tensor([0.8606, 0.1394], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 37 - 307: dog - cat || Loss: 1.1735292673110962\n",
      "tensor([0., 1.]) tensor([0.8603, 0.1397], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 37 - 308: dog - cat || Loss: 1.1731956005096436\n",
      "tensor([0., 1.]) tensor([0.8599, 0.1401], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 37 - 309: dog - cat || Loss: 1.1728612184524536\n",
      "tensor([0., 1.]) tensor([0.8596, 0.1404], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 37 - 310: dog - cat || Loss: 1.1725261211395264\n",
      "tensor([0., 1.]) tensor([0.8593, 0.1407], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 37 - 311: dog - cat || Loss: 1.1721900701522827\n",
      "tensor([0., 1.]) tensor([0.8589, 0.1411], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 37 - 312: dog - cat || Loss: 1.1718535423278809\n",
      "tensor([0., 1.]) tensor([0.8586, 0.1414], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 37 - 313: dog - cat || Loss: 1.1715160608291626\n",
      "tensor([0., 1.]) tensor([0.8583, 0.1417], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 37 - 314: dog - cat || Loss: 1.171177864074707\n",
      "tensor([0., 1.]) tensor([0.8579, 0.1421], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 37 - 315: dog - cat || Loss: 1.1708389520645142\n",
      "tensor([0., 1.]) tensor([0.8576, 0.1424], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 37 - 316: dog - cat || Loss: 1.1704990863800049\n",
      "tensor([0., 1.]) tensor([0.8572, 0.1428], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 37 - 317: dog - cat || Loss: 1.1701585054397583\n",
      "tensor([0., 1.]) tensor([0.8569, 0.1431], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 37 - 318: dog - cat || Loss: 1.169817328453064\n",
      "tensor([0., 1.]) tensor([0.8566, 0.1434], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 37 - 319: dog - cat || Loss: 1.1694753170013428\n",
      "tensor([0., 1.]) tensor([0.8562, 0.1438], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 37 - 320: dog - cat || Loss: 1.1691325902938843\n",
      "tensor([0., 1.]) tensor([0.8559, 0.1441], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 37 - 321: dog - cat || Loss: 1.168789029121399\n",
      "tensor([0., 1.]) tensor([0.8555, 0.1445], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 37 - 322: dog - cat || Loss: 1.1684446334838867\n",
      "tensor([0., 1.]) tensor([0.8552, 0.1448], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 37 - 323: dog - cat || Loss: 1.1680994033813477\n",
      "tensor([0., 1.]) tensor([0.8548, 0.1452], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 37 - 324: dog - cat || Loss: 1.1677535772323608\n",
      "tensor([0., 1.]) tensor([0.8545, 0.1455], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 37 - 325: dog - cat || Loss: 1.1674067974090576\n",
      "tensor([0., 1.]) tensor([0.8541, 0.1459], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 37 - 326: dog - cat || Loss: 1.1670594215393066\n",
      "tensor([0., 1.]) tensor([0.8538, 0.1462], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 37 - 327: dog - cat || Loss: 1.1667112112045288\n",
      "tensor([0., 1.]) tensor([0.8534, 0.1466], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 37 - 328: dog - cat || Loss: 1.1663620471954346\n",
      "tensor([0., 1.]) tensor([0.8531, 0.1469], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 37 - 329: dog - cat || Loss: 1.1660122871398926\n",
      "tensor([0., 1.]) tensor([0.8528, 0.1472], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 37 - 330: dog - cat || Loss: 1.1656616926193237\n",
      "tensor([0., 1.]) tensor([0.8524, 0.1476], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 37 - 331: dog - cat || Loss: 1.165310263633728\n",
      "tensor([0., 1.]) tensor([0.8520, 0.1480], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 37 - 332: dog - cat || Loss: 1.164958119392395\n",
      "tensor([0., 1.]) tensor([0.8517, 0.1483], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 37 - 333: dog - cat || Loss: 1.1646051406860352\n",
      "tensor([0., 1.]) tensor([0.8513, 0.1487], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 37 - 334: dog - cat || Loss: 1.1642513275146484\n",
      "tensor([0., 1.]) tensor([0.8510, 0.1490], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 37 - 335: dog - cat || Loss: 1.163896918296814\n",
      "tensor([0., 1.]) tensor([0.8506, 0.1494], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 37 - 336: dog - cat || Loss: 1.1635417938232422\n",
      "tensor([0., 1.]) tensor([0.8503, 0.1497], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 37 - 337: dog - cat || Loss: 1.163185477256775\n",
      "tensor([0., 1.]) tensor([0.8499, 0.1501], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 37 - 338: dog - cat || Loss: 1.1628286838531494\n",
      "tensor([0., 1.]) tensor([0.8496, 0.1504], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 37 - 339: dog - cat || Loss: 1.162471055984497\n",
      "tensor([0., 1.]) tensor([0.8492, 0.1508], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 37 - 340: dog - cat || Loss: 1.1621125936508179\n",
      "tensor([0., 1.]) tensor([0.8489, 0.1511], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 37 - 341: dog - cat || Loss: 1.1617532968521118\n",
      "tensor([0., 1.]) tensor([0.8485, 0.1515], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 37 - 342: dog - cat || Loss: 1.161393165588379\n",
      "tensor([0., 1.]) tensor([0.8481, 0.1519], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 37 - 343: dog - cat || Loss: 1.1610324382781982\n",
      "tensor([0., 1.]) tensor([0.8478, 0.1522], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 37 - 344: dog - cat || Loss: 1.1606707572937012\n",
      "tensor([0., 1.]) tensor([0.8474, 0.1526], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 37 - 345: dog - cat || Loss: 1.1603082418441772\n",
      "tensor([0., 1.]) tensor([0.8470, 0.1530], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 37 - 346: dog - cat || Loss: 1.1599451303482056\n",
      "tensor([0., 1.]) tensor([0.8467, 0.1533], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 37 - 347: dog - cat || Loss: 1.1595810651779175\n",
      "tensor([0., 1.]) tensor([0.8463, 0.1537], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 37 - 348: dog - cat || Loss: 1.159216284751892\n",
      "tensor([0., 1.]) tensor([0.8460, 0.1540], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 37 - 349: dog - cat || Loss: 1.1588506698608398\n",
      "tensor([0., 1.]) tensor([0.8456, 0.1544], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 37 - 350: dog - cat || Loss: 1.1584842205047607\n",
      "tensor([0., 1.]) tensor([0.8452, 0.1548], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 37 - 351: dog - cat || Loss: 1.1581170558929443\n",
      "tensor([0., 1.]) tensor([0.8449, 0.1551], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 37 - 352: dog - cat || Loss: 1.157749056816101\n",
      "tensor([0., 1.]) tensor([0.8445, 0.1555], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 37 - 353: dog - cat || Loss: 1.157380223274231\n",
      "tensor([0., 1.]) tensor([0.8441, 0.1559], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 37 - 354: dog - cat || Loss: 1.157010555267334\n",
      "tensor([0., 1.]) tensor([0.8437, 0.1563], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 37 - 355: dog - cat || Loss: 1.1566400527954102\n",
      "tensor([0., 1.]) tensor([0.8434, 0.1566], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 37 - 356: dog - cat || Loss: 1.156268835067749\n",
      "tensor([0., 1.]) tensor([0.8430, 0.1570], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 37 - 357: dog - cat || Loss: 1.1558966636657715\n",
      "tensor([0., 1.]) tensor([0.8426, 0.1574], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 37 - 358: dog - cat || Loss: 1.1555238962173462\n",
      "tensor([0., 1.]) tensor([0.8423, 0.1577], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 37 - 359: dog - cat || Loss: 1.1551501750946045\n",
      "tensor([0., 1.]) tensor([0.8419, 0.1581], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 37 - 360: dog - cat || Loss: 1.154775619506836\n",
      "tensor([0., 1.]) tensor([0.8415, 0.1585], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 37 - 361: dog - cat || Loss: 1.15440034866333\n",
      "tensor([0., 1.]) tensor([0.8411, 0.1589], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 37 - 362: dog - cat || Loss: 1.1540242433547974\n",
      "tensor([0., 1.]) tensor([0.8408, 0.1592], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 37 - 363: dog - cat || Loss: 1.1536473035812378\n",
      "tensor([0., 1.]) tensor([0.8404, 0.1596], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 37 - 364: dog - cat || Loss: 1.1532694101333618\n",
      "tensor([0., 1.]) tensor([0.8400, 0.1600], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 37 - 365: dog - cat || Loss: 1.152890920639038\n",
      "tensor([0., 1.]) tensor([0.8396, 0.1604], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 37 - 366: dog - cat || Loss: 1.1525113582611084\n",
      "tensor([0., 1.]) tensor([0.8392, 0.1608], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 37 - 367: dog - cat || Loss: 1.152131199836731\n",
      "tensor([0., 1.]) tensor([0.8389, 0.1611], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 37 - 368: dog - cat || Loss: 1.1517502069473267\n",
      "tensor([0., 1.]) tensor([0.8385, 0.1615], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 37 - 369: dog - cat || Loss: 1.1513681411743164\n",
      "tensor([0., 1.]) tensor([0.8381, 0.1619], grad_fn=<SoftmaxBackward0>)\n",
      "=====epoch:38=====\n",
      "Epoch 38 - 0: cat - cat || Loss: 0.47553783655166626\n",
      "tensor([1., 0.]) tensor([0.8377, 0.1623], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 38 - 1: cat - cat || Loss: 0.47584396600723267\n",
      "tensor([1., 0.]) tensor([0.8374, 0.1626], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 38 - 2: cat - cat || Loss: 0.47608083486557007\n",
      "tensor([1., 0.]) tensor([0.8372, 0.1628], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 38 - 3: cat - cat || Loss: 0.47625529766082764\n",
      "tensor([1., 0.]) tensor([0.8370, 0.1630], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 38 - 4: cat - cat || Loss: 0.476373553276062\n",
      "tensor([1., 0.]) tensor([0.8369, 0.1631], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 38 - 5: cat - cat || Loss: 0.47644102573394775\n",
      "tensor([1., 0.]) tensor([0.8368, 0.1632], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 38 - 6: cat - cat || Loss: 0.47646284103393555\n",
      "tensor([1., 0.]) tensor([0.8368, 0.1632], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 38 - 7: cat - cat || Loss: 0.4764435291290283\n",
      "tensor([1., 0.]) tensor([0.8368, 0.1632], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 38 - 8: cat - cat || Loss: 0.4763873219490051\n",
      "tensor([1., 0.]) tensor([0.8369, 0.1631], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 38 - 9: cat - cat || Loss: 0.47629785537719727\n",
      "tensor([1., 0.]) tensor([0.8370, 0.1630], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 38 - 10: cat - cat || Loss: 0.476178377866745\n",
      "tensor([1., 0.]) tensor([0.8371, 0.1629], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 38 - 11: cat - cat || Loss: 0.4760321378707886\n",
      "tensor([1., 0.]) tensor([0.8372, 0.1628], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 38 - 12: cat - cat || Loss: 0.4758618474006653\n",
      "tensor([1., 0.]) tensor([0.8374, 0.1626], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 38 - 13: cat - cat || Loss: 0.4756697416305542\n",
      "tensor([1., 0.]) tensor([0.8376, 0.1624], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 38 - 14: cat - cat || Loss: 0.4754583537578583\n",
      "tensor([1., 0.]) tensor([0.8378, 0.1622], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 38 - 15: cat - cat || Loss: 0.47522956132888794\n",
      "tensor([1., 0.]) tensor([0.8380, 0.1620], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 38 - 16: cat - cat || Loss: 0.47498518228530884\n",
      "tensor([1., 0.]) tensor([0.8383, 0.1617], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 38 - 17: cat - cat || Loss: 0.47472670674324036\n",
      "tensor([1., 0.]) tensor([0.8385, 0.1615], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 38 - 18: cat - cat || Loss: 0.47445595264434814\n",
      "tensor([1., 0.]) tensor([0.8388, 0.1612], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 38 - 19: cat - cat || Loss: 0.4741738438606262\n",
      "tensor([1., 0.]) tensor([0.8391, 0.1609], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 38 - 20: cat - cat || Loss: 0.47388172149658203\n",
      "tensor([1., 0.]) tensor([0.8394, 0.1606], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 38 - 21: cat - cat || Loss: 0.47358086705207825\n",
      "tensor([1., 0.]) tensor([0.8397, 0.1603], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 38 - 22: cat - cat || Loss: 0.47327208518981934\n",
      "tensor([1., 0.]) tensor([0.8400, 0.1600], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 38 - 23: cat - cat || Loss: 0.47295624017715454\n",
      "tensor([1., 0.]) tensor([0.8403, 0.1597], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 38 - 24: cat - cat || Loss: 0.4726340174674988\n",
      "tensor([1., 0.]) tensor([0.8406, 0.1594], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 38 - 25: cat - cat || Loss: 0.4723063111305237\n",
      "tensor([1., 0.]) tensor([0.8410, 0.1590], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 38 - 26: cat - cat || Loss: 0.47197380661964417\n",
      "tensor([1., 0.]) tensor([0.8413, 0.1587], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 38 - 27: cat - cat || Loss: 0.4716368615627289\n",
      "tensor([1., 0.]) tensor([0.8416, 0.1584], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 38 - 28: cat - cat || Loss: 0.47129613161087036\n",
      "tensor([1., 0.]) tensor([0.8420, 0.1580], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 38 - 29: cat - cat || Loss: 0.4709518849849701\n",
      "tensor([1., 0.]) tensor([0.8423, 0.1577], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 38 - 30: cat - cat || Loss: 0.47060492634773254\n",
      "tensor([1., 0.]) tensor([0.8427, 0.1573], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 38 - 31: cat - cat || Loss: 0.4702552258968353\n",
      "tensor([1., 0.]) tensor([0.8430, 0.1570], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 38 - 32: cat - cat || Loss: 0.4699033498764038\n",
      "tensor([1., 0.]) tensor([0.8434, 0.1566], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 38 - 33: cat - cat || Loss: 0.46954965591430664\n",
      "tensor([1., 0.]) tensor([0.8437, 0.1563], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 38 - 34: cat - cat || Loss: 0.4691941738128662\n",
      "tensor([1., 0.]) tensor([0.8441, 0.1559], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 38 - 35: cat - cat || Loss: 0.46883732080459595\n",
      "tensor([1., 0.]) tensor([0.8444, 0.1556], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 38 - 36: cat - cat || Loss: 0.46847933530807495\n",
      "tensor([1., 0.]) tensor([0.8448, 0.1552], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 38 - 37: cat - cat || Loss: 0.4681204557418823\n",
      "tensor([1., 0.]) tensor([0.8451, 0.1549], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 38 - 38: cat - cat || Loss: 0.46776068210601807\n",
      "tensor([1., 0.]) tensor([0.8455, 0.1545], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 38 - 39: cat - cat || Loss: 0.4674002230167389\n",
      "tensor([1., 0.]) tensor([0.8459, 0.1541], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 38 - 40: cat - cat || Loss: 0.4670395255088806\n",
      "tensor([1., 0.]) tensor([0.8462, 0.1538], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 38 - 41: cat - cat || Loss: 0.4666782021522522\n",
      "tensor([1., 0.]) tensor([0.8466, 0.1534], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 38 - 42: cat - cat || Loss: 0.466316819190979\n",
      "tensor([1., 0.]) tensor([0.8469, 0.1531], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 38 - 43: cat - cat || Loss: 0.4659551978111267\n",
      "tensor([1., 0.]) tensor([0.8473, 0.1527], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 38 - 44: cat - cat || Loss: 0.46559369564056396\n",
      "tensor([1., 0.]) tensor([0.8477, 0.1523], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 38 - 45: cat - cat || Loss: 0.46523207426071167\n",
      "tensor([1., 0.]) tensor([0.8480, 0.1520], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 38 - 46: cat - cat || Loss: 0.4648706316947937\n",
      "tensor([1., 0.]) tensor([0.8484, 0.1516], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 38 - 47: cat - cat || Loss: 0.46450942754745483\n",
      "tensor([1., 0.]) tensor([0.8488, 0.1512], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 38 - 48: cat - cat || Loss: 0.4641484022140503\n",
      "tensor([1., 0.]) tensor([0.8491, 0.1509], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 38 - 49: cat - cat || Loss: 0.4637877345085144\n",
      "tensor([1., 0.]) tensor([0.8495, 0.1505], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 38 - 50: cat - cat || Loss: 0.46342748403549194\n",
      "tensor([1., 0.]) tensor([0.8498, 0.1502], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 38 - 51: cat - cat || Loss: 0.4630676507949829\n",
      "tensor([1., 0.]) tensor([0.8502, 0.1498], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 38 - 52: cat - cat || Loss: 0.46270817518234253\n",
      "tensor([1., 0.]) tensor([0.8506, 0.1494], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 38 - 53: cat - cat || Loss: 0.4623492956161499\n",
      "tensor([1., 0.]) tensor([0.8509, 0.1491], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 38 - 54: cat - cat || Loss: 0.4619908928871155\n",
      "tensor([1., 0.]) tensor([0.8513, 0.1487], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 38 - 55: cat - cat || Loss: 0.46163302659988403\n",
      "tensor([1., 0.]) tensor([0.8516, 0.1484], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 38 - 56: cat - cat || Loss: 0.46127572655677795\n",
      "tensor([1., 0.]) tensor([0.8520, 0.1480], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 38 - 57: cat - cat || Loss: 0.46091896295547485\n",
      "tensor([1., 0.]) tensor([0.8523, 0.1477], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 38 - 58: cat - cat || Loss: 0.46056288480758667\n",
      "tensor([1., 0.]) tensor([0.8527, 0.1473], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 38 - 59: cat - cat || Loss: 0.4602075219154358\n",
      "tensor([1., 0.]) tensor([0.8531, 0.1469], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 38 - 60: cat - cat || Loss: 0.45985275506973267\n",
      "tensor([1., 0.]) tensor([0.8534, 0.1466], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 38 - 61: cat - cat || Loss: 0.4594986140727997\n",
      "tensor([1., 0.]) tensor([0.8538, 0.1462], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 38 - 62: cat - cat || Loss: 0.459145188331604\n",
      "tensor([1., 0.]) tensor([0.8541, 0.1459], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 38 - 63: cat - cat || Loss: 0.4587925672531128\n",
      "tensor([1., 0.]) tensor([0.8545, 0.1455], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 38 - 64: cat - cat || Loss: 0.45844054222106934\n",
      "tensor([1., 0.]) tensor([0.8548, 0.1452], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 38 - 65: cat - cat || Loss: 0.4580892324447632\n",
      "tensor([1., 0.]) tensor([0.8552, 0.1448], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 38 - 66: cat - cat || Loss: 0.45773863792419434\n",
      "tensor([1., 0.]) tensor([0.8555, 0.1445], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 38 - 67: cat - cat || Loss: 0.45738887786865234\n",
      "tensor([1., 0.]) tensor([0.8559, 0.1441], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 38 - 68: cat - cat || Loss: 0.45703980326652527\n",
      "tensor([1., 0.]) tensor([0.8562, 0.1438], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 38 - 69: cat - cat || Loss: 0.4566913843154907\n",
      "tensor([1., 0.]) tensor([0.8566, 0.1434], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 38 - 70: cat - cat || Loss: 0.4563438296318054\n",
      "tensor([1., 0.]) tensor([0.8569, 0.1431], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 38 - 71: cat - cat || Loss: 0.4559970498085022\n",
      "tensor([1., 0.]) tensor([0.8573, 0.1427], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 38 - 72: cat - cat || Loss: 0.4556509852409363\n",
      "tensor([1., 0.]) tensor([0.8576, 0.1424], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 38 - 73: cat - cat || Loss: 0.4553055763244629\n",
      "tensor([1., 0.]) tensor([0.8580, 0.1420], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 38 - 74: cat - cat || Loss: 0.45496106147766113\n",
      "tensor([1., 0.]) tensor([0.8583, 0.1417], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 38 - 75: cat - cat || Loss: 0.4546172618865967\n",
      "tensor([1., 0.]) tensor([0.8586, 0.1414], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 38 - 76: cat - cat || Loss: 0.45427435636520386\n",
      "tensor([1., 0.]) tensor([0.8590, 0.1410], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 38 - 77: cat - cat || Loss: 0.45393216609954834\n",
      "tensor([1., 0.]) tensor([0.8593, 0.1407], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 38 - 78: cat - cat || Loss: 0.4535906910896301\n",
      "tensor([1., 0.]) tensor([0.8597, 0.1403], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 38 - 79: cat - cat || Loss: 0.453249990940094\n",
      "tensor([1., 0.]) tensor([0.8600, 0.1400], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 38 - 80: cat - cat || Loss: 0.4529101252555847\n",
      "tensor([1., 0.]) tensor([0.8604, 0.1396], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 38 - 81: cat - cat || Loss: 0.4525708556175232\n",
      "tensor([1., 0.]) tensor([0.8607, 0.1393], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 38 - 82: cat - cat || Loss: 0.4522325098514557\n",
      "tensor([1., 0.]) tensor([0.8610, 0.1390], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 38 - 83: cat - cat || Loss: 0.45189493894577026\n",
      "tensor([1., 0.]) tensor([0.8614, 0.1386], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 38 - 84: cat - cat || Loss: 0.4515581727027893\n",
      "tensor([1., 0.]) tensor([0.8617, 0.1383], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 38 - 85: cat - cat || Loss: 0.45122218132019043\n",
      "tensor([1., 0.]) tensor([0.8620, 0.1380], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 38 - 86: cat - cat || Loss: 0.45088690519332886\n",
      "tensor([1., 0.]) tensor([0.8624, 0.1376], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 38 - 87: cat - cat || Loss: 0.45055246353149414\n",
      "tensor([1., 0.]) tensor([0.8627, 0.1373], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 38 - 88: cat - cat || Loss: 0.45021873712539673\n",
      "tensor([1., 0.]) tensor([0.8630, 0.1370], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 38 - 89: cat - cat || Loss: 0.44988584518432617\n",
      "tensor([1., 0.]) tensor([0.8634, 0.1366], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 38 - 90: cat - cat || Loss: 0.4495537579059601\n",
      "tensor([1., 0.]) tensor([0.8637, 0.1363], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 38 - 91: cat - cat || Loss: 0.4492223560810089\n",
      "tensor([1., 0.]) tensor([0.8640, 0.1360], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 38 - 92: cat - cat || Loss: 0.4488917589187622\n",
      "tensor([1., 0.]) tensor([0.8644, 0.1356], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 38 - 93: cat - cat || Loss: 0.44856202602386475\n",
      "tensor([1., 0.]) tensor([0.8647, 0.1353], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 38 - 94: cat - cat || Loss: 0.44823288917541504\n",
      "tensor([1., 0.]) tensor([0.8650, 0.1350], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 38 - 95: cat - cat || Loss: 0.44790464639663696\n",
      "tensor([1., 0.]) tensor([0.8654, 0.1346], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 38 - 96: cat - cat || Loss: 0.4475771486759186\n",
      "tensor([1., 0.]) tensor([0.8657, 0.1343], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 38 - 97: cat - cat || Loss: 0.44725045561790466\n",
      "tensor([1., 0.]) tensor([0.8660, 0.1340], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 38 - 98: cat - cat || Loss: 0.44692447781562805\n",
      "tensor([1., 0.]) tensor([0.8663, 0.1337], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 38 - 99: cat - cat || Loss: 0.4465993344783783\n",
      "tensor([1., 0.]) tensor([0.8667, 0.1333], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 38 - 100: cat - cat || Loss: 0.44627487659454346\n",
      "tensor([1., 0.]) tensor([0.8670, 0.1330], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 38 - 101: cat - cat || Loss: 0.44595131278038025\n",
      "tensor([1., 0.]) tensor([0.8673, 0.1327], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 38 - 102: cat - cat || Loss: 0.44562846422195435\n",
      "tensor([1., 0.]) tensor([0.8676, 0.1324], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 38 - 103: cat - cat || Loss: 0.4453062415122986\n",
      "tensor([1., 0.]) tensor([0.8680, 0.1320], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 38 - 104: cat - cat || Loss: 0.44498488306999207\n",
      "tensor([1., 0.]) tensor([0.8683, 0.1317], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 38 - 105: cat - cat || Loss: 0.44466432929039\n",
      "tensor([1., 0.]) tensor([0.8686, 0.1314], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 38 - 106: cat - cat || Loss: 0.4443444609642029\n",
      "tensor([1., 0.]) tensor([0.8689, 0.1311], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 38 - 107: cat - cat || Loss: 0.4440253973007202\n",
      "tensor([1., 0.]) tensor([0.8692, 0.1308], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 38 - 108: cat - cat || Loss: 0.44370704889297485\n",
      "tensor([1., 0.]) tensor([0.8696, 0.1304], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 38 - 109: cat - cat || Loss: 0.44338953495025635\n",
      "tensor([1., 0.]) tensor([0.8699, 0.1301], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 38 - 110: cat - cat || Loss: 0.44307273626327515\n",
      "tensor([1., 0.]) tensor([0.8702, 0.1298], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 38 - 111: cat - cat || Loss: 0.442756712436676\n",
      "tensor([1., 0.]) tensor([0.8705, 0.1295], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 38 - 112: cat - cat || Loss: 0.44244134426116943\n",
      "tensor([1., 0.]) tensor([0.8708, 0.1292], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 38 - 113: cat - cat || Loss: 0.44212692975997925\n",
      "tensor([1., 0.]) tensor([0.8711, 0.1289], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 38 - 114: cat - cat || Loss: 0.4418131113052368\n",
      "tensor([1., 0.]) tensor([0.8714, 0.1286], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 38 - 115: cat - cat || Loss: 0.44150012731552124\n",
      "tensor([1., 0.]) tensor([0.8718, 0.1282], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 38 - 116: cat - cat || Loss: 0.4411878287792206\n",
      "tensor([1., 0.]) tensor([0.8721, 0.1279], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 38 - 117: cat - cat || Loss: 0.4408763349056244\n",
      "tensor([1., 0.]) tensor([0.8724, 0.1276], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 38 - 118: cat - cat || Loss: 0.4405655860900879\n",
      "tensor([1., 0.]) tensor([0.8727, 0.1273], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 38 - 119: cat - cat || Loss: 0.44025561213493347\n",
      "tensor([1., 0.]) tensor([0.8730, 0.1270], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 38 - 120: cat - cat || Loss: 0.4399462938308716\n",
      "tensor([1., 0.]) tensor([0.8733, 0.1267], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 38 - 121: cat - cat || Loss: 0.4396377205848694\n",
      "tensor([1., 0.]) tensor([0.8736, 0.1264], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 38 - 122: cat - cat || Loss: 0.43932998180389404\n",
      "tensor([1., 0.]) tensor([0.8739, 0.1261], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 38 - 123: cat - cat || Loss: 0.439022958278656\n",
      "tensor([1., 0.]) tensor([0.8742, 0.1258], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 38 - 124: cat - cat || Loss: 0.4387166500091553\n",
      "tensor([1., 0.]) tensor([0.8745, 0.1255], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 38 - 125: cat - cat || Loss: 0.4384111762046814\n",
      "tensor([1., 0.]) tensor([0.8749, 0.1251], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 38 - 126: cat - cat || Loss: 0.43810632824897766\n",
      "tensor([1., 0.]) tensor([0.8752, 0.1248], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 38 - 127: cat - cat || Loss: 0.43780219554901123\n",
      "tensor([1., 0.]) tensor([0.8755, 0.1245], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 38 - 128: cat - cat || Loss: 0.43749892711639404\n",
      "tensor([1., 0.]) tensor([0.8758, 0.1242], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 38 - 129: cat - cat || Loss: 0.4371962547302246\n",
      "tensor([1., 0.]) tensor([0.8761, 0.1239], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 38 - 130: cat - cat || Loss: 0.4368944764137268\n",
      "tensor([1., 0.]) tensor([0.8764, 0.1236], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 38 - 131: cat - cat || Loss: 0.43659326434135437\n",
      "tensor([1., 0.]) tensor([0.8767, 0.1233], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 38 - 132: cat - cat || Loss: 0.4362927973270416\n",
      "tensor([1., 0.]) tensor([0.8770, 0.1230], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 38 - 133: cat - cat || Loss: 0.4359931945800781\n",
      "tensor([1., 0.]) tensor([0.8773, 0.1227], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 38 - 134: cat - cat || Loss: 0.43569415807724\n",
      "tensor([1., 0.]) tensor([0.8776, 0.1224], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 38 - 135: cat - cat || Loss: 0.4353959560394287\n",
      "tensor([1., 0.]) tensor([0.8779, 0.1221], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 38 - 136: cat - cat || Loss: 0.43509840965270996\n",
      "tensor([1., 0.]) tensor([0.8782, 0.1218], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 38 - 137: cat - cat || Loss: 0.4348016381263733\n",
      "tensor([1., 0.]) tensor([0.8785, 0.1215], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 38 - 138: cat - cat || Loss: 0.4345056116580963\n",
      "tensor([1., 0.]) tensor([0.8788, 0.1212], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 38 - 139: cat - cat || Loss: 0.43421024084091187\n",
      "tensor([1., 0.]) tensor([0.8791, 0.1209], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 38 - 140: cat - cat || Loss: 0.4339156448841095\n",
      "tensor([1., 0.]) tensor([0.8793, 0.1207], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 38 - 141: cat - cat || Loss: 0.43362170457839966\n",
      "tensor([1., 0.]) tensor([0.8796, 0.1204], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 38 - 142: cat - cat || Loss: 0.4333285093307495\n",
      "tensor([1., 0.]) tensor([0.8799, 0.1201], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 38 - 143: cat - cat || Loss: 0.43303608894348145\n",
      "tensor([1., 0.]) tensor([0.8802, 0.1198], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 38 - 144: cat - cat || Loss: 0.4327443838119507\n",
      "tensor([1., 0.]) tensor([0.8805, 0.1195], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 38 - 145: cat - cat || Loss: 0.43245336413383484\n",
      "tensor([1., 0.]) tensor([0.8808, 0.1192], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 38 - 146: cat - cat || Loss: 0.43216297030448914\n",
      "tensor([1., 0.]) tensor([0.8811, 0.1189], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 38 - 147: cat - cat || Loss: 0.4318733811378479\n",
      "tensor([1., 0.]) tensor([0.8814, 0.1186], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 38 - 148: cat - cat || Loss: 0.4315844178199768\n",
      "tensor([1., 0.]) tensor([0.8817, 0.1183], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 38 - 149: cat - cat || Loss: 0.4312962591648102\n",
      "tensor([1., 0.]) tensor([0.8820, 0.1180], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 38 - 150: cat - cat || Loss: 0.4310087561607361\n",
      "tensor([1., 0.]) tensor([0.8823, 0.1177], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 38 - 151: cat - cat || Loss: 0.4307219982147217\n",
      "tensor([1., 0.]) tensor([0.8825, 0.1175], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 38 - 152: cat - cat || Loss: 0.4304359555244446\n",
      "tensor([1., 0.]) tensor([0.8828, 0.1172], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 38 - 153: cat - cat || Loss: 0.43015050888061523\n",
      "tensor([1., 0.]) tensor([0.8831, 0.1169], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 38 - 154: cat - cat || Loss: 0.42986583709716797\n",
      "tensor([1., 0.]) tensor([0.8834, 0.1166], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 38 - 155: cat - cat || Loss: 0.429581880569458\n",
      "tensor([1., 0.]) tensor([0.8837, 0.1163], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 38 - 156: cat - cat || Loss: 0.4292985796928406\n",
      "tensor([1., 0.]) tensor([0.8840, 0.1160], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 38 - 157: cat - cat || Loss: 0.4290160536766052\n",
      "tensor([1., 0.]) tensor([0.8842, 0.1158], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 38 - 158: cat - cat || Loss: 0.42873406410217285\n",
      "tensor([1., 0.]) tensor([0.8845, 0.1155], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 38 - 159: cat - cat || Loss: 0.42845284938812256\n",
      "tensor([1., 0.]) tensor([0.8848, 0.1152], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 38 - 160: cat - cat || Loss: 0.42817234992980957\n",
      "tensor([1., 0.]) tensor([0.8851, 0.1149], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 38 - 161: cat - cat || Loss: 0.4278925657272339\n",
      "tensor([1., 0.]) tensor([0.8854, 0.1146], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 38 - 162: cat - cat || Loss: 0.4276134669780731\n",
      "tensor([1., 0.]) tensor([0.8856, 0.1144], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 38 - 163: cat - cat || Loss: 0.4273349642753601\n",
      "tensor([1., 0.]) tensor([0.8859, 0.1141], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 38 - 164: cat - cat || Loss: 0.42705729603767395\n",
      "tensor([1., 0.]) tensor([0.8862, 0.1138], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 38 - 165: cat - cat || Loss: 0.42678016424179077\n",
      "tensor([1., 0.]) tensor([0.8865, 0.1135], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 38 - 166: cat - cat || Loss: 0.4265037178993225\n",
      "tensor([1., 0.]) tensor([0.8868, 0.1132], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 38 - 167: cat - cat || Loss: 0.4262280762195587\n",
      "tensor([1., 0.]) tensor([0.8870, 0.1130], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 38 - 168: cat - cat || Loss: 0.4259530305862427\n",
      "tensor([1., 0.]) tensor([0.8873, 0.1127], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 38 - 169: cat - cat || Loss: 0.42567867040634155\n",
      "tensor([1., 0.]) tensor([0.8876, 0.1124], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 38 - 170: cat - cat || Loss: 0.42540502548217773\n",
      "tensor([1., 0.]) tensor([0.8879, 0.1121], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 38 - 171: cat - cat || Loss: 0.4251320958137512\n",
      "tensor([1., 0.]) tensor([0.8881, 0.1119], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 38 - 172: cat - cat || Loss: 0.4248597025871277\n",
      "tensor([1., 0.]) tensor([0.8884, 0.1116], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 38 - 173: cat - cat || Loss: 0.424588143825531\n",
      "tensor([1., 0.]) tensor([0.8887, 0.1113], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 38 - 174: cat - cat || Loss: 0.4243171811103821\n",
      "tensor([1., 0.]) tensor([0.8889, 0.1111], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 38 - 175: cat - cat || Loss: 0.42404693365097046\n",
      "tensor([1., 0.]) tensor([0.8892, 0.1108], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 38 - 176: cat - cat || Loss: 0.4237772822380066\n",
      "tensor([1., 0.]) tensor([0.8895, 0.1105], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 38 - 177: cat - cat || Loss: 0.4235084056854248\n",
      "tensor([1., 0.]) tensor([0.8898, 0.1102], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 38 - 178: cat - cat || Loss: 0.4232400953769684\n",
      "tensor([1., 0.]) tensor([0.8900, 0.1100], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 38 - 179: cat - cat || Loss: 0.42297255992889404\n",
      "tensor([1., 0.]) tensor([0.8903, 0.1097], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 38 - 180: cat - cat || Loss: 0.42270559072494507\n",
      "tensor([1., 0.]) tensor([0.8906, 0.1094], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 38 - 181: cat - cat || Loss: 0.42243921756744385\n",
      "tensor([1., 0.]) tensor([0.8908, 0.1092], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 38 - 182: cat - cat || Loss: 0.42217370867729187\n",
      "tensor([1., 0.]) tensor([0.8911, 0.1089], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 38 - 183: cat - cat || Loss: 0.42190879583358765\n",
      "tensor([1., 0.]) tensor([0.8914, 0.1086], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 38 - 184: cat - cat || Loss: 0.4216444492340088\n",
      "tensor([1., 0.]) tensor([0.8916, 0.1084], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 38 - 185: cat - cat || Loss: 0.4213809370994568\n",
      "tensor([1., 0.]) tensor([0.8919, 0.1081], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 38 - 186: cat - cat || Loss: 0.4211178421974182\n",
      "tensor([1., 0.]) tensor([0.8921, 0.1079], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 38 - 187: cat - cat || Loss: 0.4208555519580841\n",
      "tensor([1., 0.]) tensor([0.8924, 0.1076], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 38 - 188: cat - cat || Loss: 0.42059391736984253\n",
      "tensor([1., 0.]) tensor([0.8927, 0.1073], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 38 - 189: cat - cat || Loss: 0.42033281922340393\n",
      "tensor([1., 0.]) tensor([0.8929, 0.1071], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 38 - 190: dog - cat || Loss: 1.2064507007598877\n",
      "tensor([0., 1.]) tensor([0.8932, 0.1068], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 38 - 191: dog - cat || Loss: 1.2066593170166016\n",
      "tensor([0., 1.]) tensor([0.8934, 0.1066], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 38 - 192: dog - cat || Loss: 1.206821084022522\n",
      "tensor([0., 1.]) tensor([0.8936, 0.1064], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 38 - 193: dog - cat || Loss: 1.206940770149231\n",
      "tensor([0., 1.]) tensor([0.8937, 0.1063], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 38 - 194: dog - cat || Loss: 1.2070229053497314\n",
      "tensor([0., 1.]) tensor([0.8938, 0.1062], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 38 - 195: dog - cat || Loss: 1.2070714235305786\n",
      "tensor([0., 1.]) tensor([0.8938, 0.1062], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 38 - 196: dog - cat || Loss: 1.2070893049240112\n",
      "tensor([0., 1.]) tensor([0.8938, 0.1062], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 38 - 197: dog - cat || Loss: 1.2070797681808472\n",
      "tensor([0., 1.]) tensor([0.8938, 0.1062], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 38 - 198: dog - cat || Loss: 1.2070459127426147\n",
      "tensor([0., 1.]) tensor([0.8938, 0.1062], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 38 - 199: dog - cat || Loss: 1.2069894075393677\n",
      "tensor([0., 1.]) tensor([0.8937, 0.1063], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 38 - 200: dog - cat || Loss: 1.2069132328033447\n",
      "tensor([0., 1.]) tensor([0.8937, 0.1063], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 38 - 201: dog - cat || Loss: 1.20681893825531\n",
      "tensor([0., 1.]) tensor([0.8936, 0.1064], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 38 - 202: dog - cat || Loss: 1.2067084312438965\n",
      "tensor([0., 1.]) tensor([0.8934, 0.1066], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 38 - 203: dog - cat || Loss: 1.2065832614898682\n",
      "tensor([0., 1.]) tensor([0.8933, 0.1067], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 38 - 204: dog - cat || Loss: 1.2064448595046997\n",
      "tensor([0., 1.]) tensor([0.8932, 0.1068], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 38 - 205: dog - cat || Loss: 1.2062945365905762\n",
      "tensor([0., 1.]) tensor([0.8930, 0.1070], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 38 - 206: dog - cat || Loss: 1.2061333656311035\n",
      "tensor([0., 1.]) tensor([0.8929, 0.1071], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 38 - 207: dog - cat || Loss: 1.2059625387191772\n",
      "tensor([0., 1.]) tensor([0.8927, 0.1073], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 38 - 208: dog - cat || Loss: 1.2057825326919556\n",
      "tensor([0., 1.]) tensor([0.8925, 0.1075], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 38 - 209: dog - cat || Loss: 1.2055946588516235\n",
      "tensor([0., 1.]) tensor([0.8923, 0.1077], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 38 - 210: dog - cat || Loss: 1.2053993940353394\n",
      "tensor([0., 1.]) tensor([0.8921, 0.1079], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 38 - 211: dog - cat || Loss: 1.2051975727081299\n",
      "tensor([0., 1.]) tensor([0.8919, 0.1081], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 38 - 212: dog - cat || Loss: 1.2049899101257324\n",
      "tensor([0., 1.]) tensor([0.8917, 0.1083], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 38 - 213: dog - cat || Loss: 1.204776644706726\n",
      "tensor([0., 1.]) tensor([0.8915, 0.1085], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 38 - 214: dog - cat || Loss: 1.2045583724975586\n",
      "tensor([0., 1.]) tensor([0.8913, 0.1087], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 38 - 215: dog - cat || Loss: 1.2043354511260986\n",
      "tensor([0., 1.]) tensor([0.8911, 0.1089], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 38 - 216: dog - cat || Loss: 1.2041085958480835\n",
      "tensor([0., 1.]) tensor([0.8908, 0.1092], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 38 - 217: dog - cat || Loss: 1.203877568244934\n",
      "tensor([0., 1.]) tensor([0.8906, 0.1094], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 38 - 218: dog - cat || Loss: 1.2036433219909668\n",
      "tensor([0., 1.]) tensor([0.8904, 0.1096], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 38 - 219: dog - cat || Loss: 1.2034058570861816\n",
      "tensor([0., 1.]) tensor([0.8901, 0.1099], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 38 - 220: dog - cat || Loss: 1.2031655311584473\n",
      "tensor([0., 1.]) tensor([0.8899, 0.1101], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 38 - 221: dog - cat || Loss: 1.2029223442077637\n",
      "tensor([0., 1.]) tensor([0.8897, 0.1103], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 38 - 222: dog - cat || Loss: 1.2026766538619995\n",
      "tensor([0., 1.]) tensor([0.8894, 0.1106], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 38 - 223: dog - cat || Loss: 1.2024285793304443\n",
      "tensor([0., 1.]) tensor([0.8892, 0.1108], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 38 - 224: dog - cat || Loss: 1.2021783590316772\n",
      "tensor([0., 1.]) tensor([0.8889, 0.1111], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 38 - 225: dog - cat || Loss: 1.2019262313842773\n",
      "tensor([0., 1.]) tensor([0.8887, 0.1113], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 38 - 226: dog - cat || Loss: 1.201672077178955\n",
      "tensor([0., 1.]) tensor([0.8884, 0.1116], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 38 - 227: dog - cat || Loss: 1.2014163732528687\n",
      "tensor([0., 1.]) tensor([0.8882, 0.1118], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 38 - 228: dog - cat || Loss: 1.201158881187439\n",
      "tensor([0., 1.]) tensor([0.8879, 0.1121], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 38 - 229: dog - cat || Loss: 1.2008998394012451\n",
      "tensor([0., 1.]) tensor([0.8876, 0.1124], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 38 - 230: dog - cat || Loss: 1.2006393671035767\n",
      "tensor([0., 1.]) tensor([0.8874, 0.1126], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 38 - 231: dog - cat || Loss: 1.2003777027130127\n",
      "tensor([0., 1.]) tensor([0.8871, 0.1129], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 38 - 232: dog - cat || Loss: 1.2001144886016846\n",
      "tensor([0., 1.]) tensor([0.8869, 0.1131], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 38 - 233: dog - cat || Loss: 1.1998502016067505\n",
      "tensor([0., 1.]) tensor([0.8866, 0.1134], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 38 - 234: dog - cat || Loss: 1.199584722518921\n",
      "tensor([0., 1.]) tensor([0.8863, 0.1137], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 38 - 235: dog - cat || Loss: 1.1993180513381958\n",
      "tensor([0., 1.]) tensor([0.8861, 0.1139], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 38 - 236: dog - cat || Loss: 1.1990503072738647\n",
      "tensor([0., 1.]) tensor([0.8858, 0.1142], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 38 - 237: dog - cat || Loss: 1.1987814903259277\n",
      "tensor([0., 1.]) tensor([0.8855, 0.1145], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 38 - 238: dog - cat || Loss: 1.1985117197036743\n",
      "tensor([0., 1.]) tensor([0.8853, 0.1147], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 38 - 239: dog - cat || Loss: 1.1982409954071045\n",
      "tensor([0., 1.]) tensor([0.8850, 0.1150], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 38 - 240: dog - cat || Loss: 1.1979691982269287\n",
      "tensor([0., 1.]) tensor([0.8847, 0.1153], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 38 - 241: dog - cat || Loss: 1.1976966857910156\n",
      "tensor([0., 1.]) tensor([0.8844, 0.1156], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 38 - 242: dog - cat || Loss: 1.1974232196807861\n",
      "tensor([0., 1.]) tensor([0.8842, 0.1158], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 38 - 243: dog - cat || Loss: 1.1971487998962402\n",
      "tensor([0., 1.]) tensor([0.8839, 0.1161], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 38 - 244: dog - cat || Loss: 1.1968735456466675\n",
      "tensor([0., 1.]) tensor([0.8836, 0.1164], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 38 - 245: dog - cat || Loss: 1.196597695350647\n",
      "tensor([0., 1.]) tensor([0.8833, 0.1167], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 38 - 246: dog - cat || Loss: 1.1963207721710205\n",
      "tensor([0., 1.]) tensor([0.8831, 0.1169], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 38 - 247: dog - cat || Loss: 1.1960430145263672\n",
      "tensor([0., 1.]) tensor([0.8828, 0.1172], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 38 - 248: dog - cat || Loss: 1.1957646608352661\n",
      "tensor([0., 1.]) tensor([0.8825, 0.1175], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 38 - 249: dog - cat || Loss: 1.1954854726791382\n",
      "tensor([0., 1.]) tensor([0.8822, 0.1178], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 38 - 250: dog - cat || Loss: 1.195205569267273\n",
      "tensor([0., 1.]) tensor([0.8819, 0.1181], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 38 - 251: dog - cat || Loss: 1.1949247121810913\n",
      "tensor([0., 1.]) tensor([0.8817, 0.1183], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 38 - 252: dog - cat || Loss: 1.194643497467041\n",
      "tensor([0., 1.]) tensor([0.8814, 0.1186], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 38 - 253: dog - cat || Loss: 1.1943610906600952\n",
      "tensor([0., 1.]) tensor([0.8811, 0.1189], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 38 - 254: dog - cat || Loss: 1.1940780878067017\n",
      "tensor([0., 1.]) tensor([0.8808, 0.1192], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 38 - 255: dog - cat || Loss: 1.1937943696975708\n",
      "tensor([0., 1.]) tensor([0.8805, 0.1195], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 38 - 256: dog - cat || Loss: 1.1935099363327026\n",
      "tensor([0., 1.]) tensor([0.8802, 0.1198], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 38 - 257: dog - cat || Loss: 1.1932246685028076\n",
      "tensor([0., 1.]) tensor([0.8800, 0.1200], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 38 - 258: dog - cat || Loss: 1.192939043045044\n",
      "tensor([0., 1.]) tensor([0.8797, 0.1203], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 38 - 259: dog - cat || Loss: 1.1926523447036743\n",
      "tensor([0., 1.]) tensor([0.8794, 0.1206], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 38 - 260: dog - cat || Loss: 1.1923648118972778\n",
      "tensor([0., 1.]) tensor([0.8791, 0.1209], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 38 - 261: dog - cat || Loss: 1.1920770406723022\n",
      "tensor([0., 1.]) tensor([0.8788, 0.1212], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 38 - 262: dog - cat || Loss: 1.1917881965637207\n",
      "tensor([0., 1.]) tensor([0.8785, 0.1215], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 38 - 263: dog - cat || Loss: 1.1914986371994019\n",
      "tensor([0., 1.]) tensor([0.8782, 0.1218], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 38 - 264: dog - cat || Loss: 1.1912086009979248\n",
      "tensor([0., 1.]) tensor([0.8779, 0.1221], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 38 - 265: dog - cat || Loss: 1.1909176111221313\n",
      "tensor([0., 1.]) tensor([0.8777, 0.1223], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 38 - 266: dog - cat || Loss: 1.1906262636184692\n",
      "tensor([0., 1.]) tensor([0.8774, 0.1226], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 38 - 267: dog - cat || Loss: 1.1903338432312012\n",
      "tensor([0., 1.]) tensor([0.8771, 0.1229], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 38 - 268: dog - cat || Loss: 1.1900408267974854\n",
      "tensor([0., 1.]) tensor([0.8768, 0.1232], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 38 - 269: dog - cat || Loss: 1.1897472143173218\n",
      "tensor([0., 1.]) tensor([0.8765, 0.1235], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 38 - 270: dog - cat || Loss: 1.1894527673721313\n",
      "tensor([0., 1.]) tensor([0.8762, 0.1238], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 38 - 271: dog - cat || Loss: 1.1891578435897827\n",
      "tensor([0., 1.]) tensor([0.8759, 0.1241], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 38 - 272: dog - cat || Loss: 1.1888618469238281\n",
      "tensor([0., 1.]) tensor([0.8756, 0.1244], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 38 - 273: dog - cat || Loss: 1.1885654926300049\n",
      "tensor([0., 1.]) tensor([0.8753, 0.1247], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 38 - 274: dog - cat || Loss: 1.1882683038711548\n",
      "tensor([0., 1.]) tensor([0.8750, 0.1250], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 38 - 275: dog - cat || Loss: 1.1879701614379883\n",
      "tensor([0., 1.]) tensor([0.8747, 0.1253], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 38 - 276: dog - cat || Loss: 1.1876715421676636\n",
      "tensor([0., 1.]) tensor([0.8744, 0.1256], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 38 - 277: dog - cat || Loss: 1.187372088432312\n",
      "tensor([0., 1.]) tensor([0.8741, 0.1259], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 38 - 278: dog - cat || Loss: 1.1870720386505127\n",
      "tensor([0., 1.]) tensor([0.8738, 0.1262], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 38 - 279: dog - cat || Loss: 1.1867713928222656\n",
      "tensor([0., 1.]) tensor([0.8735, 0.1265], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 38 - 280: dog - cat || Loss: 1.1864697933197021\n",
      "tensor([0., 1.]) tensor([0.8732, 0.1268], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 38 - 281: dog - cat || Loss: 1.1861674785614014\n",
      "tensor([0., 1.]) tensor([0.8729, 0.1271], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 38 - 282: dog - cat || Loss: 1.1858645677566528\n",
      "tensor([0., 1.]) tensor([0.8726, 0.1274], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 38 - 283: dog - cat || Loss: 1.1855610609054565\n",
      "tensor([0., 1.]) tensor([0.8723, 0.1277], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 38 - 284: dog - cat || Loss: 1.1852566003799438\n",
      "tensor([0., 1.]) tensor([0.8720, 0.1280], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 38 - 285: dog - cat || Loss: 1.1849514245986938\n",
      "tensor([0., 1.]) tensor([0.8717, 0.1283], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 38 - 286: dog - cat || Loss: 1.1846457719802856\n",
      "tensor([0., 1.]) tensor([0.8714, 0.1286], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 38 - 287: dog - cat || Loss: 1.184339165687561\n",
      "tensor([0., 1.]) tensor([0.8711, 0.1289], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 38 - 288: dog - cat || Loss: 1.1840319633483887\n",
      "tensor([0., 1.]) tensor([0.8708, 0.1292], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 38 - 289: dog - cat || Loss: 1.1837239265441895\n",
      "tensor([0., 1.]) tensor([0.8705, 0.1295], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 38 - 290: dog - cat || Loss: 1.183415412902832\n",
      "tensor([0., 1.]) tensor([0.8702, 0.1298], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 38 - 291: dog - cat || Loss: 1.1831060647964478\n",
      "tensor([0., 1.]) tensor([0.8698, 0.1302], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 38 - 292: dog - cat || Loss: 1.182795763015747\n",
      "tensor([0., 1.]) tensor([0.8695, 0.1305], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 38 - 293: dog - cat || Loss: 1.1824849843978882\n",
      "tensor([0., 1.]) tensor([0.8692, 0.1308], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 38 - 294: dog - cat || Loss: 1.1821733713150024\n",
      "tensor([0., 1.]) tensor([0.8689, 0.1311], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 38 - 295: dog - cat || Loss: 1.1818610429763794\n",
      "tensor([0., 1.]) tensor([0.8686, 0.1314], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 38 - 296: dog - cat || Loss: 1.1815481185913086\n",
      "tensor([0., 1.]) tensor([0.8683, 0.1317], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 38 - 297: dog - cat || Loss: 1.1812344789505005\n",
      "tensor([0., 1.]) tensor([0.8680, 0.1320], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 38 - 298: dog - cat || Loss: 1.180919885635376\n",
      "tensor([0., 1.]) tensor([0.8677, 0.1323], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 38 - 299: dog - cat || Loss: 1.1806046962738037\n",
      "tensor([0., 1.]) tensor([0.8673, 0.1327], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 38 - 300: dog - cat || Loss: 1.1802886724472046\n",
      "tensor([0., 1.]) tensor([0.8670, 0.1330], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 38 - 301: dog - cat || Loss: 1.1799719333648682\n",
      "tensor([0., 1.]) tensor([0.8667, 0.1333], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 38 - 302: dog - cat || Loss: 1.179654836654663\n",
      "tensor([0., 1.]) tensor([0.8664, 0.1336], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 38 - 303: dog - cat || Loss: 1.1793365478515625\n",
      "tensor([0., 1.]) tensor([0.8661, 0.1339], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 38 - 304: dog - cat || Loss: 1.1790176630020142\n",
      "tensor([0., 1.]) tensor([0.8658, 0.1342], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 38 - 305: dog - cat || Loss: 1.1786978244781494\n",
      "tensor([0., 1.]) tensor([0.8654, 0.1346], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 38 - 306: dog - cat || Loss: 1.1783777475357056\n",
      "tensor([0., 1.]) tensor([0.8651, 0.1349], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 38 - 307: dog - cat || Loss: 1.1780565977096558\n",
      "tensor([0., 1.]) tensor([0.8648, 0.1352], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 38 - 308: dog - cat || Loss: 1.1777347326278687\n",
      "tensor([0., 1.]) tensor([0.8645, 0.1355], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 38 - 309: dog - cat || Loss: 1.1774121522903442\n",
      "tensor([0., 1.]) tensor([0.8642, 0.1358], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 38 - 310: dog - cat || Loss: 1.1770888566970825\n",
      "tensor([0., 1.]) tensor([0.8638, 0.1362], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 38 - 311: dog - cat || Loss: 1.1767648458480835\n",
      "tensor([0., 1.]) tensor([0.8635, 0.1365], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 38 - 312: dog - cat || Loss: 1.1764401197433472\n",
      "tensor([0., 1.]) tensor([0.8632, 0.1368], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 38 - 313: dog - cat || Loss: 1.1761144399642944\n",
      "tensor([0., 1.]) tensor([0.8629, 0.1371], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 38 - 314: dog - cat || Loss: 1.175788402557373\n",
      "tensor([0., 1.]) tensor([0.8625, 0.1375], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 38 - 315: dog - cat || Loss: 1.1754612922668457\n",
      "tensor([0., 1.]) tensor([0.8622, 0.1378], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 38 - 316: dog - cat || Loss: 1.175133466720581\n",
      "tensor([0., 1.]) tensor([0.8619, 0.1381], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 38 - 317: dog - cat || Loss: 1.174804925918579\n",
      "tensor([0., 1.]) tensor([0.8615, 0.1385], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 38 - 318: dog - cat || Loss: 1.1744756698608398\n",
      "tensor([0., 1.]) tensor([0.8612, 0.1388], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 38 - 319: dog - cat || Loss: 1.1741455793380737\n",
      "tensor([0., 1.]) tensor([0.8609, 0.1391], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 38 - 320: dog - cat || Loss: 1.1738147735595703\n",
      "tensor([0., 1.]) tensor([0.8606, 0.1394], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 38 - 321: dog - cat || Loss: 1.1734832525253296\n",
      "tensor([0., 1.]) tensor([0.8602, 0.1398], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 38 - 322: dog - cat || Loss: 1.1731510162353516\n",
      "tensor([0., 1.]) tensor([0.8599, 0.1401], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 38 - 323: dog - cat || Loss: 1.1728178262710571\n",
      "tensor([0., 1.]) tensor([0.8596, 0.1404], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 38 - 324: dog - cat || Loss: 1.172484040260315\n",
      "tensor([0., 1.]) tensor([0.8592, 0.1408], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 38 - 325: dog - cat || Loss: 1.1721495389938354\n",
      "tensor([0., 1.]) tensor([0.8589, 0.1411], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 38 - 326: dog - cat || Loss: 1.171814203262329\n",
      "tensor([0., 1.]) tensor([0.8586, 0.1414], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 38 - 327: dog - cat || Loss: 1.1714781522750854\n",
      "tensor([0., 1.]) tensor([0.8582, 0.1418], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 38 - 328: dog - cat || Loss: 1.171141266822815\n",
      "tensor([0., 1.]) tensor([0.8579, 0.1421], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 38 - 329: dog - cat || Loss: 1.1708036661148071\n",
      "tensor([0., 1.]) tensor([0.8575, 0.1425], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 38 - 330: dog - cat || Loss: 1.1704652309417725\n",
      "tensor([0., 1.]) tensor([0.8572, 0.1428], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 38 - 331: dog - cat || Loss: 1.1701260805130005\n",
      "tensor([0., 1.]) tensor([0.8569, 0.1431], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 38 - 332: dog - cat || Loss: 1.1697862148284912\n",
      "tensor([0., 1.]) tensor([0.8565, 0.1435], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 38 - 333: dog - cat || Loss: 1.169445514678955\n",
      "tensor([0., 1.]) tensor([0.8562, 0.1438], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 38 - 334: dog - cat || Loss: 1.1691040992736816\n",
      "tensor([0., 1.]) tensor([0.8558, 0.1442], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 38 - 335: dog - cat || Loss: 1.1687618494033813\n",
      "tensor([0., 1.]) tensor([0.8555, 0.1445], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 38 - 336: dog - cat || Loss: 1.1684188842773438\n",
      "tensor([0., 1.]) tensor([0.8552, 0.1448], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 38 - 337: dog - cat || Loss: 1.1680749654769897\n",
      "tensor([0., 1.]) tensor([0.8548, 0.1452], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 38 - 338: dog - cat || Loss: 1.1677305698394775\n",
      "tensor([0., 1.]) tensor([0.8545, 0.1455], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 38 - 339: dog - cat || Loss: 1.1673851013183594\n",
      "tensor([0., 1.]) tensor([0.8541, 0.1459], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 38 - 340: dog - cat || Loss: 1.167039155960083\n",
      "tensor([0., 1.]) tensor([0.8538, 0.1462], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 38 - 341: dog - cat || Loss: 1.1666921377182007\n",
      "tensor([0., 1.]) tensor([0.8534, 0.1466], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 38 - 342: dog - cat || Loss: 1.1663446426391602\n",
      "tensor([0., 1.]) tensor([0.8531, 0.1469], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 38 - 343: dog - cat || Loss: 1.1659960746765137\n",
      "tensor([0., 1.]) tensor([0.8527, 0.1473], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 38 - 344: dog - cat || Loss: 1.165647029876709\n",
      "tensor([0., 1.]) tensor([0.8524, 0.1476], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 38 - 345: dog - cat || Loss: 1.1652969121932983\n",
      "tensor([0., 1.]) tensor([0.8520, 0.1480], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 38 - 346: dog - cat || Loss: 1.16494619846344\n",
      "tensor([0., 1.]) tensor([0.8517, 0.1483], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 38 - 347: dog - cat || Loss: 1.1645946502685547\n",
      "tensor([0., 1.]) tensor([0.8513, 0.1487], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 38 - 348: dog - cat || Loss: 1.1642422676086426\n",
      "tensor([0., 1.]) tensor([0.8510, 0.1490], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 38 - 349: dog - cat || Loss: 1.1638891696929932\n",
      "tensor([0., 1.]) tensor([0.8506, 0.1494], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 38 - 350: dog - cat || Loss: 1.163535237312317\n",
      "tensor([0., 1.]) tensor([0.8503, 0.1497], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 38 - 351: dog - cat || Loss: 1.1631804704666138\n",
      "tensor([0., 1.]) tensor([0.8499, 0.1501], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 38 - 352: dog - cat || Loss: 1.162825107574463\n",
      "tensor([0., 1.]) tensor([0.8496, 0.1504], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 38 - 353: dog - cat || Loss: 1.1624689102172852\n",
      "tensor([0., 1.]) tensor([0.8492, 0.1508], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 38 - 354: dog - cat || Loss: 1.1621116399765015\n",
      "tensor([0., 1.]) tensor([0.8489, 0.1511], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 38 - 355: dog - cat || Loss: 1.1617538928985596\n",
      "tensor([0., 1.]) tensor([0.8485, 0.1515], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 38 - 356: dog - cat || Loss: 1.1613953113555908\n",
      "tensor([0., 1.]) tensor([0.8481, 0.1519], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 38 - 357: dog - cat || Loss: 1.1610357761383057\n",
      "tensor([0., 1.]) tensor([0.8478, 0.1522], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 38 - 358: dog - cat || Loss: 1.1606755256652832\n",
      "tensor([0., 1.]) tensor([0.8474, 0.1526], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 38 - 359: dog - cat || Loss: 1.1603144407272339\n",
      "tensor([0., 1.]) tensor([0.8471, 0.1529], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 38 - 360: dog - cat || Loss: 1.1599524021148682\n",
      "tensor([0., 1.]) tensor([0.8467, 0.1533], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 38 - 361: dog - cat || Loss: 1.1595897674560547\n",
      "tensor([0., 1.]) tensor([0.8463, 0.1537], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 38 - 362: dog - cat || Loss: 1.1592262983322144\n",
      "tensor([0., 1.]) tensor([0.8460, 0.1540], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 38 - 363: dog - cat || Loss: 1.1588621139526367\n",
      "tensor([0., 1.]) tensor([0.8456, 0.1544], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 38 - 364: dog - cat || Loss: 1.1584968566894531\n",
      "tensor([0., 1.]) tensor([0.8452, 0.1548], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 38 - 365: dog - cat || Loss: 1.1581311225891113\n",
      "tensor([0., 1.]) tensor([0.8449, 0.1551], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 38 - 366: dog - cat || Loss: 1.1577643156051636\n",
      "tensor([0., 1.]) tensor([0.8445, 0.1555], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 38 - 367: dog - cat || Loss: 1.157396912574768\n",
      "tensor([0., 1.]) tensor([0.8441, 0.1559], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 38 - 368: dog - cat || Loss: 1.1570286750793457\n",
      "tensor([0., 1.]) tensor([0.8438, 0.1562], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 38 - 369: dog - cat || Loss: 1.156659483909607\n",
      "tensor([0., 1.]) tensor([0.8434, 0.1566], grad_fn=<SoftmaxBackward0>)\n",
      "=====epoch:39=====\n",
      "Epoch 39 - 0: cat - cat || Loss: 0.47023385763168335\n",
      "tensor([1., 0.]) tensor([0.8430, 0.1570], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 39 - 1: cat - cat || Loss: 0.4705296754837036\n",
      "tensor([1., 0.]) tensor([0.8427, 0.1573], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 39 - 2: cat - cat || Loss: 0.4707586169242859\n",
      "tensor([1., 0.]) tensor([0.8425, 0.1575], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 39 - 3: cat - cat || Loss: 0.47092723846435547\n",
      "tensor([1., 0.]) tensor([0.8423, 0.1577], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 39 - 4: cat - cat || Loss: 0.4710414409637451\n",
      "tensor([1., 0.]) tensor([0.8422, 0.1578], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 39 - 5: cat - cat || Loss: 0.47110670804977417\n",
      "tensor([1., 0.]) tensor([0.8422, 0.1578], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 39 - 6: cat - cat || Loss: 0.4711277484893799\n",
      "tensor([1., 0.]) tensor([0.8421, 0.1579], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 39 - 7: cat - cat || Loss: 0.4711090326309204\n",
      "tensor([1., 0.]) tensor([0.8422, 0.1578], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 39 - 8: cat - cat || Loss: 0.47105467319488525\n",
      "tensor([1., 0.]) tensor([0.8422, 0.1578], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 39 - 9: cat - cat || Loss: 0.4709681272506714\n",
      "tensor([1., 0.]) tensor([0.8423, 0.1577], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 39 - 10: cat - cat || Loss: 0.4708525538444519\n",
      "tensor([1., 0.]) tensor([0.8424, 0.1576], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 39 - 11: cat - cat || Loss: 0.47071123123168945\n",
      "tensor([1., 0.]) tensor([0.8426, 0.1574], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 39 - 12: cat - cat || Loss: 0.47054654359817505\n",
      "tensor([1., 0.]) tensor([0.8427, 0.1573], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 39 - 13: cat - cat || Loss: 0.4703609347343445\n",
      "tensor([1., 0.]) tensor([0.8429, 0.1571], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 39 - 14: cat - cat || Loss: 0.4701564610004425\n",
      "tensor([1., 0.]) tensor([0.8431, 0.1569], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 39 - 15: cat - cat || Loss: 0.46993523836135864\n",
      "tensor([1., 0.]) tensor([0.8433, 0.1567], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 39 - 16: cat - cat || Loss: 0.469698965549469\n",
      "tensor([1., 0.]) tensor([0.8436, 0.1564], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 39 - 17: cat - cat || Loss: 0.46944910287857056\n",
      "tensor([1., 0.]) tensor([0.8438, 0.1562], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 39 - 18: cat - cat || Loss: 0.46918725967407227\n",
      "tensor([1., 0.]) tensor([0.8441, 0.1559], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 39 - 19: cat - cat || Loss: 0.46891456842422485\n",
      "tensor([1., 0.]) tensor([0.8443, 0.1557], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 39 - 20: cat - cat || Loss: 0.46863219141960144\n",
      "tensor([1., 0.]) tensor([0.8446, 0.1554], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 39 - 21: cat - cat || Loss: 0.46834129095077515\n",
      "tensor([1., 0.]) tensor([0.8449, 0.1551], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 39 - 22: cat - cat || Loss: 0.4680427610874176\n",
      "tensor([1., 0.]) tensor([0.8452, 0.1548], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 39 - 23: cat - cat || Loss: 0.46773743629455566\n",
      "tensor([1., 0.]) tensor([0.8455, 0.1545], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 39 - 24: cat - cat || Loss: 0.46742597222328186\n",
      "tensor([1., 0.]) tensor([0.8458, 0.1542], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 39 - 25: cat - cat || Loss: 0.4671092629432678\n",
      "tensor([1., 0.]) tensor([0.8462, 0.1538], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 39 - 26: cat - cat || Loss: 0.46678781509399414\n",
      "tensor([1., 0.]) tensor([0.8465, 0.1535], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 39 - 27: cat - cat || Loss: 0.4664621353149414\n",
      "tensor([1., 0.]) tensor([0.8468, 0.1532], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 39 - 28: cat - cat || Loss: 0.46613287925720215\n",
      "tensor([1., 0.]) tensor([0.8471, 0.1529], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 39 - 29: cat - cat || Loss: 0.4658002257347107\n",
      "tensor([1., 0.]) tensor([0.8475, 0.1525], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 39 - 30: cat - cat || Loss: 0.46546489000320435\n",
      "tensor([1., 0.]) tensor([0.8478, 0.1522], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 39 - 31: cat - cat || Loss: 0.4651269316673279\n",
      "tensor([1., 0.]) tensor([0.8481, 0.1519], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 39 - 32: cat - cat || Loss: 0.4647868871688843\n",
      "tensor([1., 0.]) tensor([0.8485, 0.1515], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 39 - 33: cat - cat || Loss: 0.4644450545310974\n",
      "tensor([1., 0.]) tensor([0.8488, 0.1512], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 39 - 34: cat - cat || Loss: 0.4641016125679016\n",
      "tensor([1., 0.]) tensor([0.8492, 0.1508], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 39 - 35: cat - cat || Loss: 0.463756799697876\n",
      "tensor([1., 0.]) tensor([0.8495, 0.1505], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 39 - 36: cat - cat || Loss: 0.46341097354888916\n",
      "tensor([1., 0.]) tensor([0.8499, 0.1501], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 39 - 37: cat - cat || Loss: 0.46306413412094116\n",
      "tensor([1., 0.]) tensor([0.8502, 0.1498], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 39 - 38: cat - cat || Loss: 0.4627165198326111\n",
      "tensor([1., 0.]) tensor([0.8505, 0.1495], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 39 - 39: cat - cat || Loss: 0.46236830949783325\n",
      "tensor([1., 0.]) tensor([0.8509, 0.1491], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 39 - 40: cat - cat || Loss: 0.4620198607444763\n",
      "tensor([1., 0.]) tensor([0.8512, 0.1488], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 39 - 41: cat - cat || Loss: 0.4616708755493164\n",
      "tensor([1., 0.]) tensor([0.8516, 0.1484], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 39 - 42: cat - cat || Loss: 0.46132177114486694\n",
      "tensor([1., 0.]) tensor([0.8519, 0.1481], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 39 - 43: cat - cat || Loss: 0.4609723687171936\n",
      "tensor([1., 0.]) tensor([0.8523, 0.1477], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 39 - 44: cat - cat || Loss: 0.4606231451034546\n",
      "tensor([1., 0.]) tensor([0.8526, 0.1474], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 39 - 45: cat - cat || Loss: 0.4602739214897156\n",
      "tensor([1., 0.]) tensor([0.8530, 0.1470], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 39 - 46: cat - cat || Loss: 0.45992475748062134\n",
      "tensor([1., 0.]) tensor([0.8533, 0.1467], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 39 - 47: cat - cat || Loss: 0.4595758616924286\n",
      "tensor([1., 0.]) tensor([0.8537, 0.1463], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 39 - 48: cat - cat || Loss: 0.4592273235321045\n",
      "tensor([1., 0.]) tensor([0.8540, 0.1460], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 39 - 49: cat - cat || Loss: 0.45887887477874756\n",
      "tensor([1., 0.]) tensor([0.8544, 0.1456], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 39 - 50: cat - cat || Loss: 0.4585309624671936\n",
      "tensor([1., 0.]) tensor([0.8547, 0.1453], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 39 - 51: cat - cat || Loss: 0.45818349719047546\n",
      "tensor([1., 0.]) tensor([0.8551, 0.1449], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 39 - 52: cat - cat || Loss: 0.4578363299369812\n",
      "tensor([1., 0.]) tensor([0.8554, 0.1446], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 39 - 53: cat - cat || Loss: 0.45748981833457947\n",
      "tensor([1., 0.]) tensor([0.8558, 0.1442], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 39 - 54: cat - cat || Loss: 0.4571436941623688\n",
      "tensor([1., 0.]) tensor([0.8561, 0.1439], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 39 - 55: cat - cat || Loss: 0.4567981958389282\n",
      "tensor([1., 0.]) tensor([0.8565, 0.1435], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 39 - 56: cat - cat || Loss: 0.4564531743526459\n",
      "tensor([1., 0.]) tensor([0.8568, 0.1432], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 39 - 57: cat - cat || Loss: 0.4561087489128113\n",
      "tensor([1., 0.]) tensor([0.8572, 0.1428], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 39 - 58: cat - cat || Loss: 0.4557650089263916\n",
      "tensor([1., 0.]) tensor([0.8575, 0.1425], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 39 - 59: cat - cat || Loss: 0.4554218649864197\n",
      "tensor([1., 0.]) tensor([0.8578, 0.1422], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 39 - 60: cat - cat || Loss: 0.4550793766975403\n",
      "tensor([1., 0.]) tensor([0.8582, 0.1418], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 39 - 61: cat - cat || Loss: 0.4547375440597534\n",
      "tensor([1., 0.]) tensor([0.8585, 0.1415], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 39 - 62: cat - cat || Loss: 0.4543963074684143\n",
      "tensor([1., 0.]) tensor([0.8589, 0.1411], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 39 - 63: cat - cat || Loss: 0.45405590534210205\n",
      "tensor([1., 0.]) tensor([0.8592, 0.1408], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 39 - 64: cat - cat || Loss: 0.4537160396575928\n",
      "tensor([1., 0.]) tensor([0.8595, 0.1405], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 39 - 65: cat - cat || Loss: 0.45337697863578796\n",
      "tensor([1., 0.]) tensor([0.8599, 0.1401], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 39 - 66: cat - cat || Loss: 0.4530385136604309\n",
      "tensor([1., 0.]) tensor([0.8602, 0.1398], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 39 - 67: cat - cat || Loss: 0.45270097255706787\n",
      "tensor([1., 0.]) tensor([0.8606, 0.1394], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 39 - 68: cat - cat || Loss: 0.4523639678955078\n",
      "tensor([1., 0.]) tensor([0.8609, 0.1391], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 39 - 69: cat - cat || Loss: 0.4520277976989746\n",
      "tensor([1., 0.]) tensor([0.8612, 0.1388], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 39 - 70: cat - cat || Loss: 0.45169228315353394\n",
      "tensor([1., 0.]) tensor([0.8616, 0.1384], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 39 - 71: cat - cat || Loss: 0.4513576030731201\n",
      "tensor([1., 0.]) tensor([0.8619, 0.1381], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 39 - 72: cat - cat || Loss: 0.45102357864379883\n",
      "tensor([1., 0.]) tensor([0.8622, 0.1378], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 39 - 73: cat - cat || Loss: 0.45069029927253723\n",
      "tensor([1., 0.]) tensor([0.8626, 0.1374], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 39 - 74: cat - cat || Loss: 0.4503577947616577\n",
      "tensor([1., 0.]) tensor([0.8629, 0.1371], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 39 - 75: cat - cat || Loss: 0.45002609491348267\n",
      "tensor([1., 0.]) tensor([0.8632, 0.1368], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 39 - 76: cat - cat || Loss: 0.4496951103210449\n",
      "tensor([1., 0.]) tensor([0.8636, 0.1364], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 39 - 77: cat - cat || Loss: 0.44936490058898926\n",
      "tensor([1., 0.]) tensor([0.8639, 0.1361], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 39 - 78: cat - cat || Loss: 0.4490353465080261\n",
      "tensor([1., 0.]) tensor([0.8642, 0.1358], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 39 - 79: cat - cat || Loss: 0.44870665669441223\n",
      "tensor([1., 0.]) tensor([0.8646, 0.1354], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 39 - 80: cat - cat || Loss: 0.44837868213653564\n",
      "tensor([1., 0.]) tensor([0.8649, 0.1351], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 39 - 81: cat - cat || Loss: 0.448051393032074\n",
      "tensor([1., 0.]) tensor([0.8652, 0.1348], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 39 - 82: cat - cat || Loss: 0.44772493839263916\n",
      "tensor([1., 0.]) tensor([0.8655, 0.1345], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 39 - 83: cat - cat || Loss: 0.44739919900894165\n",
      "tensor([1., 0.]) tensor([0.8659, 0.1341], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 39 - 84: cat - cat || Loss: 0.44707438349723816\n",
      "tensor([1., 0.]) tensor([0.8662, 0.1338], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 39 - 85: cat - cat || Loss: 0.44675010442733765\n",
      "tensor([1., 0.]) tensor([0.8665, 0.1335], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 39 - 86: cat - cat || Loss: 0.44642674922943115\n",
      "tensor([1., 0.]) tensor([0.8668, 0.1332], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 39 - 87: cat - cat || Loss: 0.4461040496826172\n",
      "tensor([1., 0.]) tensor([0.8672, 0.1328], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 39 - 88: cat - cat || Loss: 0.4457821547985077\n",
      "tensor([1., 0.]) tensor([0.8675, 0.1325], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 39 - 89: cat - cat || Loss: 0.4454610049724579\n",
      "tensor([1., 0.]) tensor([0.8678, 0.1322], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 39 - 90: cat - cat || Loss: 0.4451406002044678\n",
      "tensor([1., 0.]) tensor([0.8681, 0.1319], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 39 - 91: cat - cat || Loss: 0.44482094049453735\n",
      "tensor([1., 0.]) tensor([0.8684, 0.1316], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 39 - 92: cat - cat || Loss: 0.4445021152496338\n",
      "tensor([1., 0.]) tensor([0.8688, 0.1312], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 39 - 93: cat - cat || Loss: 0.44418394565582275\n",
      "tensor([1., 0.]) tensor([0.8691, 0.1309], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 39 - 94: cat - cat || Loss: 0.4438665509223938\n",
      "tensor([1., 0.]) tensor([0.8694, 0.1306], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 39 - 95: cat - cat || Loss: 0.44354987144470215\n",
      "tensor([1., 0.]) tensor([0.8697, 0.1303], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 39 - 96: cat - cat || Loss: 0.44323408603668213\n",
      "tensor([1., 0.]) tensor([0.8700, 0.1300], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 39 - 97: cat - cat || Loss: 0.44291892647743225\n",
      "tensor([1., 0.]) tensor([0.8703, 0.1297], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 39 - 98: cat - cat || Loss: 0.44260454177856445\n",
      "tensor([1., 0.]) tensor([0.8707, 0.1293], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 39 - 99: cat - cat || Loss: 0.4422909915447235\n",
      "tensor([1., 0.]) tensor([0.8710, 0.1290], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 39 - 100: cat - cat || Loss: 0.4419780969619751\n",
      "tensor([1., 0.]) tensor([0.8713, 0.1287], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 39 - 101: cat - cat || Loss: 0.44166600704193115\n",
      "tensor([1., 0.]) tensor([0.8716, 0.1284], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 39 - 102: cat - cat || Loss: 0.4413546919822693\n",
      "tensor([1., 0.]) tensor([0.8719, 0.1281], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 39 - 103: cat - cat || Loss: 0.4410439729690552\n",
      "tensor([1., 0.]) tensor([0.8722, 0.1278], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 39 - 104: cat - cat || Loss: 0.4407341480255127\n",
      "tensor([1., 0.]) tensor([0.8725, 0.1275], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 39 - 105: cat - cat || Loss: 0.4404250383377075\n",
      "tensor([1., 0.]) tensor([0.8728, 0.1272], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 39 - 106: cat - cat || Loss: 0.4401167035102844\n",
      "tensor([1., 0.]) tensor([0.8731, 0.1269], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 39 - 107: cat - cat || Loss: 0.43980902433395386\n",
      "tensor([1., 0.]) tensor([0.8735, 0.1265], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 39 - 108: cat - cat || Loss: 0.43950212001800537\n",
      "tensor([1., 0.]) tensor([0.8738, 0.1262], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 39 - 109: cat - cat || Loss: 0.43919602036476135\n",
      "tensor([1., 0.]) tensor([0.8741, 0.1259], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 39 - 110: cat - cat || Loss: 0.43889063596725464\n",
      "tensor([1., 0.]) tensor([0.8744, 0.1256], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 39 - 111: cat - cat || Loss: 0.4385859966278076\n",
      "tensor([1., 0.]) tensor([0.8747, 0.1253], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 39 - 112: cat - cat || Loss: 0.43828195333480835\n",
      "tensor([1., 0.]) tensor([0.8750, 0.1250], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 39 - 113: cat - cat || Loss: 0.4379788041114807\n",
      "tensor([1., 0.]) tensor([0.8753, 0.1247], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 39 - 114: cat - cat || Loss: 0.4376763105392456\n",
      "tensor([1., 0.]) tensor([0.8756, 0.1244], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 39 - 115: cat - cat || Loss: 0.4373745918273926\n",
      "tensor([1., 0.]) tensor([0.8759, 0.1241], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 39 - 116: cat - cat || Loss: 0.43707364797592163\n",
      "tensor([1., 0.]) tensor([0.8762, 0.1238], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 39 - 117: cat - cat || Loss: 0.4367733299732208\n",
      "tensor([1., 0.]) tensor([0.8765, 0.1235], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 39 - 118: cat - cat || Loss: 0.43647387623786926\n",
      "tensor([1., 0.]) tensor([0.8768, 0.1232], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 39 - 119: cat - cat || Loss: 0.43617504835128784\n",
      "tensor([1., 0.]) tensor([0.8771, 0.1229], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 39 - 120: cat - cat || Loss: 0.43587690591812134\n",
      "tensor([1., 0.]) tensor([0.8774, 0.1226], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 39 - 121: cat - cat || Loss: 0.4355795681476593\n",
      "tensor([1., 0.]) tensor([0.8777, 0.1223], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 39 - 122: cat - cat || Loss: 0.43528300523757935\n",
      "tensor([1., 0.]) tensor([0.8780, 0.1220], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 39 - 123: cat - cat || Loss: 0.4349871277809143\n",
      "tensor([1., 0.]) tensor([0.8783, 0.1217], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 39 - 124: cat - cat || Loss: 0.4346919059753418\n",
      "tensor([1., 0.]) tensor([0.8786, 0.1214], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 39 - 125: cat - cat || Loss: 0.43439751863479614\n",
      "tensor([1., 0.]) tensor([0.8789, 0.1211], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 39 - 126: cat - cat || Loss: 0.43410372734069824\n",
      "tensor([1., 0.]) tensor([0.8792, 0.1208], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 39 - 127: cat - cat || Loss: 0.43381065130233765\n",
      "tensor([1., 0.]) tensor([0.8795, 0.1205], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 39 - 128: cat - cat || Loss: 0.4335184097290039\n",
      "tensor([1., 0.]) tensor([0.8797, 0.1203], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 39 - 129: cat - cat || Loss: 0.4332268238067627\n",
      "tensor([1., 0.]) tensor([0.8800, 0.1200], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 39 - 130: cat - cat || Loss: 0.43293601274490356\n",
      "tensor([1., 0.]) tensor([0.8803, 0.1197], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 39 - 131: cat - cat || Loss: 0.4326457381248474\n",
      "tensor([1., 0.]) tensor([0.8806, 0.1194], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 39 - 132: cat - cat || Loss: 0.43235623836517334\n",
      "tensor([1., 0.]) tensor([0.8809, 0.1191], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 39 - 133: cat - cat || Loss: 0.4320675730705261\n",
      "tensor([1., 0.]) tensor([0.8812, 0.1188], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 39 - 134: cat - cat || Loss: 0.4317794740200043\n",
      "tensor([1., 0.]) tensor([0.8815, 0.1185], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 39 - 135: cat - cat || Loss: 0.43149223923683167\n",
      "tensor([1., 0.]) tensor([0.8818, 0.1182], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 39 - 136: cat - cat || Loss: 0.4312055706977844\n",
      "tensor([1., 0.]) tensor([0.8821, 0.1179], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 39 - 137: cat - cat || Loss: 0.4309196472167969\n",
      "tensor([1., 0.]) tensor([0.8823, 0.1177], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 39 - 138: cat - cat || Loss: 0.43063437938690186\n",
      "tensor([1., 0.]) tensor([0.8826, 0.1174], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 39 - 139: cat - cat || Loss: 0.4303498864173889\n",
      "tensor([1., 0.]) tensor([0.8829, 0.1171], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 39 - 140: cat - cat || Loss: 0.43006592988967896\n",
      "tensor([1., 0.]) tensor([0.8832, 0.1168], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 39 - 141: cat - cat || Loss: 0.42978280782699585\n",
      "tensor([1., 0.]) tensor([0.8835, 0.1165], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 39 - 142: cat - cat || Loss: 0.42950043082237244\n",
      "tensor([1., 0.]) tensor([0.8838, 0.1162], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 39 - 143: cat - cat || Loss: 0.4292186498641968\n",
      "tensor([1., 0.]) tensor([0.8840, 0.1160], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 39 - 144: cat - cat || Loss: 0.42893773317337036\n",
      "tensor([1., 0.]) tensor([0.8843, 0.1157], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 39 - 145: cat - cat || Loss: 0.4286574125289917\n",
      "tensor([1., 0.]) tensor([0.8846, 0.1154], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 39 - 146: cat - cat || Loss: 0.42837774753570557\n",
      "tensor([1., 0.]) tensor([0.8849, 0.1151], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 39 - 147: cat - cat || Loss: 0.42809879779815674\n",
      "tensor([1., 0.]) tensor([0.8852, 0.1148], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 39 - 148: cat - cat || Loss: 0.42782050371170044\n",
      "tensor([1., 0.]) tensor([0.8854, 0.1146], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 39 - 149: cat - cat || Loss: 0.42754292488098145\n",
      "tensor([1., 0.]) tensor([0.8857, 0.1143], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 39 - 150: cat - cat || Loss: 0.42726606130599976\n",
      "tensor([1., 0.]) tensor([0.8860, 0.1140], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 39 - 151: cat - cat || Loss: 0.426989883184433\n",
      "tensor([1., 0.]) tensor([0.8863, 0.1137], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 39 - 152: cat - cat || Loss: 0.42671439051628113\n",
      "tensor([1., 0.]) tensor([0.8865, 0.1135], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 39 - 153: cat - cat || Loss: 0.426439493894577\n",
      "tensor([1., 0.]) tensor([0.8868, 0.1132], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 39 - 154: cat - cat || Loss: 0.4261654019355774\n",
      "tensor([1., 0.]) tensor([0.8871, 0.1129], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 39 - 155: cat - cat || Loss: 0.4258918762207031\n",
      "tensor([1., 0.]) tensor([0.8874, 0.1126], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 39 - 156: cat - cat || Loss: 0.42561909556388855\n",
      "tensor([1., 0.]) tensor([0.8876, 0.1124], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 39 - 157: cat - cat || Loss: 0.42534705996513367\n",
      "tensor([1., 0.]) tensor([0.8879, 0.1121], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 39 - 158: cat - cat || Loss: 0.42507559061050415\n",
      "tensor([1., 0.]) tensor([0.8882, 0.1118], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 39 - 159: cat - cat || Loss: 0.42480477690696716\n",
      "tensor([1., 0.]) tensor([0.8885, 0.1115], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 39 - 160: cat - cat || Loss: 0.4245346188545227\n",
      "tensor([1., 0.]) tensor([0.8887, 0.1113], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 39 - 161: cat - cat || Loss: 0.4242652356624603\n",
      "tensor([1., 0.]) tensor([0.8890, 0.1110], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 39 - 162: cat - cat || Loss: 0.42399656772613525\n",
      "tensor([1., 0.]) tensor([0.8893, 0.1107], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 39 - 163: cat - cat || Loss: 0.423728346824646\n",
      "tensor([1., 0.]) tensor([0.8895, 0.1105], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 39 - 164: cat - cat || Loss: 0.42346104979515076\n",
      "tensor([1., 0.]) tensor([0.8898, 0.1102], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 39 - 165: cat - cat || Loss: 0.4231942892074585\n",
      "tensor([1., 0.]) tensor([0.8901, 0.1099], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 39 - 166: cat - cat || Loss: 0.4229281544685364\n",
      "tensor([1., 0.]) tensor([0.8903, 0.1097], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 39 - 167: cat - cat || Loss: 0.42266273498535156\n",
      "tensor([1., 0.]) tensor([0.8906, 0.1094], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 39 - 168: cat - cat || Loss: 0.42239806056022644\n",
      "tensor([1., 0.]) tensor([0.8909, 0.1091], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 39 - 169: cat - cat || Loss: 0.4221338629722595\n",
      "tensor([1., 0.]) tensor([0.8911, 0.1089], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 39 - 170: cat - cat || Loss: 0.4218704104423523\n",
      "tensor([1., 0.]) tensor([0.8914, 0.1086], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 39 - 171: cat - cat || Loss: 0.42160770297050476\n",
      "tensor([1., 0.]) tensor([0.8917, 0.1083], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 39 - 172: cat - cat || Loss: 0.4213455319404602\n",
      "tensor([1., 0.]) tensor([0.8919, 0.1081], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 39 - 173: cat - cat || Loss: 0.42108413577079773\n",
      "tensor([1., 0.]) tensor([0.8922, 0.1078], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 39 - 174: cat - cat || Loss: 0.42082327604293823\n",
      "tensor([1., 0.]) tensor([0.8924, 0.1076], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 39 - 175: cat - cat || Loss: 0.4205631613731384\n",
      "tensor([1., 0.]) tensor([0.8927, 0.1073], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 39 - 176: cat - cat || Loss: 0.4203035831451416\n",
      "tensor([1., 0.]) tensor([0.8930, 0.1070], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 39 - 177: cat - cat || Loss: 0.42004480957984924\n",
      "tensor([1., 0.]) tensor([0.8932, 0.1068], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 39 - 178: cat - cat || Loss: 0.41978657245635986\n",
      "tensor([1., 0.]) tensor([0.8935, 0.1065], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 39 - 179: cat - cat || Loss: 0.41952911019325256\n",
      "tensor([1., 0.]) tensor([0.8937, 0.1063], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 39 - 180: cat - cat || Loss: 0.41927218437194824\n",
      "tensor([1., 0.]) tensor([0.8940, 0.1060], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 39 - 181: cat - cat || Loss: 0.41901594400405884\n",
      "tensor([1., 0.]) tensor([0.8942, 0.1058], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 39 - 182: cat - cat || Loss: 0.41876041889190674\n",
      "tensor([1., 0.]) tensor([0.8945, 0.1055], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 39 - 183: cat - cat || Loss: 0.41850557923316956\n",
      "tensor([1., 0.]) tensor([0.8948, 0.1052], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 39 - 184: cat - cat || Loss: 0.41825127601623535\n",
      "tensor([1., 0.]) tensor([0.8950, 0.1050], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 39 - 185: cat - cat || Loss: 0.41799765825271606\n",
      "tensor([1., 0.]) tensor([0.8953, 0.1047], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 39 - 186: cat - cat || Loss: 0.41774460673332214\n",
      "tensor([1., 0.]) tensor([0.8955, 0.1045], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 39 - 187: cat - cat || Loss: 0.41749221086502075\n",
      "tensor([1., 0.]) tensor([0.8958, 0.1042], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 39 - 188: cat - cat || Loss: 0.4172403812408447\n",
      "tensor([1., 0.]) tensor([0.8960, 0.1040], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 39 - 189: cat - cat || Loss: 0.41698914766311646\n",
      "tensor([1., 0.]) tensor([0.8963, 0.1037], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 39 - 190: dog - cat || Loss: 1.209784746170044\n",
      "tensor([0., 1.]) tensor([0.8965, 0.1035], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 39 - 191: dog - cat || Loss: 1.2099852561950684\n",
      "tensor([0., 1.]) tensor([0.8967, 0.1033], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 39 - 192: dog - cat || Loss: 1.2101409435272217\n",
      "tensor([0., 1.]) tensor([0.8969, 0.1031], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 39 - 193: dog - cat || Loss: 1.2102562189102173\n",
      "tensor([0., 1.]) tensor([0.8970, 0.1030], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 39 - 194: dog - cat || Loss: 1.2103352546691895\n",
      "tensor([0., 1.]) tensor([0.8971, 0.1029], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 39 - 195: dog - cat || Loss: 1.2103817462921143\n",
      "tensor([0., 1.]) tensor([0.8971, 0.1029], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 39 - 196: dog - cat || Loss: 1.2103989124298096\n",
      "tensor([0., 1.]) tensor([0.8971, 0.1029], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 39 - 197: dog - cat || Loss: 1.2103899717330933\n",
      "tensor([0., 1.]) tensor([0.8971, 0.1029], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 39 - 198: dog - cat || Loss: 1.2103570699691772\n",
      "tensor([0., 1.]) tensor([0.8971, 0.1029], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 39 - 199: dog - cat || Loss: 1.2103029489517212\n",
      "tensor([0., 1.]) tensor([0.8970, 0.1030], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 39 - 200: dog - cat || Loss: 1.210229516029358\n",
      "tensor([0., 1.]) tensor([0.8970, 0.1030], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 39 - 201: dog - cat || Loss: 1.2101386785507202\n",
      "tensor([0., 1.]) tensor([0.8969, 0.1031], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 39 - 202: dog - cat || Loss: 1.2100324630737305\n",
      "tensor([0., 1.]) tensor([0.8968, 0.1032], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 39 - 203: dog - cat || Loss: 1.2099119424819946\n",
      "tensor([0., 1.]) tensor([0.8967, 0.1033], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 39 - 204: dog - cat || Loss: 1.209778904914856\n",
      "tensor([0., 1.]) tensor([0.8965, 0.1035], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 39 - 205: dog - cat || Loss: 1.2096341848373413\n",
      "tensor([0., 1.]) tensor([0.8964, 0.1036], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 39 - 206: dog - cat || Loss: 1.2094793319702148\n",
      "tensor([0., 1.]) tensor([0.8962, 0.1038], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 39 - 207: dog - cat || Loss: 1.2093149423599243\n",
      "tensor([0., 1.]) tensor([0.8961, 0.1039], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 39 - 208: dog - cat || Loss: 1.2091416120529175\n",
      "tensor([0., 1.]) tensor([0.8959, 0.1041], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 39 - 209: dog - cat || Loss: 1.208961009979248\n",
      "tensor([0., 1.]) tensor([0.8957, 0.1043], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 39 - 210: dog - cat || Loss: 1.2087733745574951\n",
      "tensor([0., 1.]) tensor([0.8955, 0.1045], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 39 - 211: dog - cat || Loss: 1.2085793018341064\n",
      "tensor([0., 1.]) tensor([0.8953, 0.1047], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 39 - 212: dog - cat || Loss: 1.2083792686462402\n",
      "tensor([0., 1.]) tensor([0.8951, 0.1049], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 39 - 213: dog - cat || Loss: 1.2081743478775024\n",
      "tensor([0., 1.]) tensor([0.8949, 0.1051], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 39 - 214: dog - cat || Loss: 1.207964301109314\n",
      "tensor([0., 1.]) tensor([0.8947, 0.1053], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 39 - 215: dog - cat || Loss: 1.2077500820159912\n",
      "tensor([0., 1.]) tensor([0.8945, 0.1055], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 39 - 216: dog - cat || Loss: 1.2075316905975342\n",
      "tensor([0., 1.]) tensor([0.8943, 0.1057], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 39 - 217: dog - cat || Loss: 1.2073097229003906\n",
      "tensor([0., 1.]) tensor([0.8940, 0.1060], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 39 - 218: dog - cat || Loss: 1.2070844173431396\n",
      "tensor([0., 1.]) tensor([0.8938, 0.1062], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 39 - 219: dog - cat || Loss: 1.2068558931350708\n",
      "tensor([0., 1.]) tensor([0.8936, 0.1064], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 39 - 220: dog - cat || Loss: 1.2066246271133423\n",
      "tensor([0., 1.]) tensor([0.8934, 0.1066], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 39 - 221: dog - cat || Loss: 1.2063908576965332\n",
      "tensor([0., 1.]) tensor([0.8931, 0.1069], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 39 - 222: dog - cat || Loss: 1.206154465675354\n",
      "tensor([0., 1.]) tensor([0.8929, 0.1071], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 39 - 223: dog - cat || Loss: 1.205915927886963\n",
      "tensor([0., 1.]) tensor([0.8927, 0.1073], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 39 - 224: dog - cat || Loss: 1.2056752443313599\n",
      "tensor([0., 1.]) tensor([0.8924, 0.1076], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 39 - 225: dog - cat || Loss: 1.2054327726364136\n",
      "tensor([0., 1.]) tensor([0.8922, 0.1078], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 39 - 226: dog - cat || Loss: 1.2051883935928345\n",
      "tensor([0., 1.]) tensor([0.8919, 0.1081], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 39 - 227: dog - cat || Loss: 1.2049423456192017\n",
      "tensor([0., 1.]) tensor([0.8917, 0.1083], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 39 - 228: dog - cat || Loss: 1.2046947479248047\n",
      "tensor([0., 1.]) tensor([0.8914, 0.1086], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 39 - 229: dog - cat || Loss: 1.2044458389282227\n",
      "tensor([0., 1.]) tensor([0.8912, 0.1088], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 39 - 230: dog - cat || Loss: 1.204195261001587\n",
      "tensor([0., 1.]) tensor([0.8909, 0.1091], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 39 - 231: dog - cat || Loss: 1.2039434909820557\n",
      "tensor([0., 1.]) tensor([0.8907, 0.1093], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 39 - 232: dog - cat || Loss: 1.2036904096603394\n",
      "tensor([0., 1.]) tensor([0.8904, 0.1096], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 39 - 233: dog - cat || Loss: 1.2034361362457275\n",
      "tensor([0., 1.]) tensor([0.8902, 0.1098], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 39 - 234: dog - cat || Loss: 1.2031807899475098\n",
      "tensor([0., 1.]) tensor([0.8899, 0.1101], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 39 - 235: dog - cat || Loss: 1.202924370765686\n",
      "tensor([0., 1.]) tensor([0.8897, 0.1103], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 39 - 236: dog - cat || Loss: 1.2026667594909668\n",
      "tensor([0., 1.]) tensor([0.8894, 0.1106], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 39 - 237: dog - cat || Loss: 1.2024083137512207\n",
      "tensor([0., 1.]) tensor([0.8891, 0.1109], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 39 - 238: dog - cat || Loss: 1.2021487951278687\n",
      "tensor([0., 1.]) tensor([0.8889, 0.1111], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 39 - 239: dog - cat || Loss: 1.2018884420394897\n",
      "tensor([0., 1.]) tensor([0.8886, 0.1114], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 39 - 240: dog - cat || Loss: 1.2016270160675049\n",
      "tensor([0., 1.]) tensor([0.8884, 0.1116], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 39 - 241: dog - cat || Loss: 1.2013648748397827\n",
      "tensor([0., 1.]) tensor([0.8881, 0.1119], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 39 - 242: dog - cat || Loss: 1.2011016607284546\n",
      "tensor([0., 1.]) tensor([0.8878, 0.1122], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 39 - 243: dog - cat || Loss: 1.2008379697799683\n",
      "tensor([0., 1.]) tensor([0.8876, 0.1124], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 39 - 244: dog - cat || Loss: 1.200573205947876\n",
      "tensor([0., 1.]) tensor([0.8873, 0.1127], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 39 - 245: dog - cat || Loss: 1.2003077268600464\n",
      "tensor([0., 1.]) tensor([0.8870, 0.1130], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 39 - 246: dog - cat || Loss: 1.20004141330719\n",
      "tensor([0., 1.]) tensor([0.8868, 0.1132], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 39 - 247: dog - cat || Loss: 1.1997742652893066\n",
      "tensor([0., 1.]) tensor([0.8865, 0.1135], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 39 - 248: dog - cat || Loss: 1.199506402015686\n",
      "tensor([0., 1.]) tensor([0.8862, 0.1138], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 39 - 249: dog - cat || Loss: 1.1992378234863281\n",
      "tensor([0., 1.]) tensor([0.8860, 0.1140], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 39 - 250: dog - cat || Loss: 1.1989686489105225\n",
      "tensor([0., 1.]) tensor([0.8857, 0.1143], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 39 - 251: dog - cat || Loss: 1.1986985206604004\n",
      "tensor([0., 1.]) tensor([0.8854, 0.1146], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 39 - 252: dog - cat || Loss: 1.1984277963638306\n",
      "tensor([0., 1.]) tensor([0.8852, 0.1148], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 39 - 253: dog - cat || Loss: 1.1981562376022339\n",
      "tensor([0., 1.]) tensor([0.8849, 0.1151], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 39 - 254: dog - cat || Loss: 1.1978840827941895\n",
      "tensor([0., 1.]) tensor([0.8846, 0.1154], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 39 - 255: dog - cat || Loss: 1.1976110935211182\n",
      "tensor([0., 1.]) tensor([0.8843, 0.1157], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 39 - 256: dog - cat || Loss: 1.1973375082015991\n",
      "tensor([0., 1.]) tensor([0.8841, 0.1159], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 39 - 257: dog - cat || Loss: 1.1970630884170532\n",
      "tensor([0., 1.]) tensor([0.8838, 0.1162], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 39 - 258: dog - cat || Loss: 1.1967881917953491\n",
      "tensor([0., 1.]) tensor([0.8835, 0.1165], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 39 - 259: dog - cat || Loss: 1.1965123414993286\n",
      "tensor([0., 1.]) tensor([0.8833, 0.1167], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 39 - 260: dog - cat || Loss: 1.1962358951568604\n",
      "tensor([0., 1.]) tensor([0.8830, 0.1170], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 39 - 261: dog - cat || Loss: 1.1959588527679443\n",
      "tensor([0., 1.]) tensor([0.8827, 0.1173], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 39 - 262: dog - cat || Loss: 1.1956812143325806\n",
      "tensor([0., 1.]) tensor([0.8824, 0.1176], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 39 - 263: dog - cat || Loss: 1.1954026222229004\n",
      "tensor([0., 1.]) tensor([0.8821, 0.1179], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 39 - 264: dog - cat || Loss: 1.1951234340667725\n",
      "tensor([0., 1.]) tensor([0.8819, 0.1181], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 39 - 265: dog - cat || Loss: 1.1948435306549072\n",
      "tensor([0., 1.]) tensor([0.8816, 0.1184], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 39 - 266: dog - cat || Loss: 1.1945630311965942\n",
      "tensor([0., 1.]) tensor([0.8813, 0.1187], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 39 - 267: dog - cat || Loss: 1.1942819356918335\n",
      "tensor([0., 1.]) tensor([0.8810, 0.1190], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 39 - 268: dog - cat || Loss: 1.194000005722046\n",
      "tensor([0., 1.]) tensor([0.8807, 0.1193], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 39 - 269: dog - cat || Loss: 1.1937172412872314\n",
      "tensor([0., 1.]) tensor([0.8805, 0.1195], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 39 - 270: dog - cat || Loss: 1.1934340000152588\n",
      "tensor([0., 1.]) tensor([0.8802, 0.1198], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 39 - 271: dog - cat || Loss: 1.1931500434875488\n",
      "tensor([0., 1.]) tensor([0.8799, 0.1201], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 39 - 272: dog - cat || Loss: 1.1928654909133911\n",
      "tensor([0., 1.]) tensor([0.8796, 0.1204], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 39 - 273: dog - cat || Loss: 1.1925801038742065\n",
      "tensor([0., 1.]) tensor([0.8793, 0.1207], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 39 - 274: dog - cat || Loss: 1.1922940015792847\n",
      "tensor([0., 1.]) tensor([0.8790, 0.1210], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 39 - 275: dog - cat || Loss: 1.1920074224472046\n",
      "tensor([0., 1.]) tensor([0.8787, 0.1213], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 39 - 276: dog - cat || Loss: 1.1917200088500977\n",
      "tensor([0., 1.]) tensor([0.8785, 0.1215], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 39 - 277: dog - cat || Loss: 1.191431999206543\n",
      "tensor([0., 1.]) tensor([0.8782, 0.1218], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 39 - 278: dog - cat || Loss: 1.1911431550979614\n",
      "tensor([0., 1.]) tensor([0.8779, 0.1221], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 39 - 279: dog - cat || Loss: 1.1908537149429321\n",
      "tensor([0., 1.]) tensor([0.8776, 0.1224], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 39 - 280: dog - cat || Loss: 1.190563678741455\n",
      "tensor([0., 1.]) tensor([0.8773, 0.1227], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 39 - 281: dog - cat || Loss: 1.1902726888656616\n",
      "tensor([0., 1.]) tensor([0.8770, 0.1230], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 39 - 282: dog - cat || Loss: 1.1899813413619995\n",
      "tensor([0., 1.]) tensor([0.8767, 0.1233], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 39 - 283: dog - cat || Loss: 1.189689040184021\n",
      "tensor([0., 1.]) tensor([0.8764, 0.1236], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 39 - 284: dog - cat || Loss: 1.1893961429595947\n",
      "tensor([0., 1.]) tensor([0.8761, 0.1239], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 39 - 285: dog - cat || Loss: 1.1891024112701416\n",
      "tensor([0., 1.]) tensor([0.8758, 0.1242], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 39 - 286: dog - cat || Loss: 1.1888082027435303\n",
      "tensor([0., 1.]) tensor([0.8755, 0.1245], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 39 - 287: dog - cat || Loss: 1.1885132789611816\n",
      "tensor([0., 1.]) tensor([0.8753, 0.1247], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 39 - 288: dog - cat || Loss: 1.1882175207138062\n",
      "tensor([0., 1.]) tensor([0.8750, 0.1250], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 39 - 289: dog - cat || Loss: 1.1879210472106934\n",
      "tensor([0., 1.]) tensor([0.8747, 0.1253], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 39 - 290: dog - cat || Loss: 1.1876239776611328\n",
      "tensor([0., 1.]) tensor([0.8744, 0.1256], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 39 - 291: dog - cat || Loss: 1.187326192855835\n",
      "tensor([0., 1.]) tensor([0.8741, 0.1259], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 39 - 292: dog - cat || Loss: 1.1870276927947998\n",
      "tensor([0., 1.]) tensor([0.8738, 0.1262], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 39 - 293: dog - cat || Loss: 1.1867284774780273\n",
      "tensor([0., 1.]) tensor([0.8735, 0.1265], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 39 - 294: dog - cat || Loss: 1.186428427696228\n",
      "tensor([0., 1.]) tensor([0.8732, 0.1268], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 39 - 295: dog - cat || Loss: 1.1861279010772705\n",
      "tensor([0., 1.]) tensor([0.8729, 0.1271], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 39 - 296: dog - cat || Loss: 1.1858265399932861\n",
      "tensor([0., 1.]) tensor([0.8726, 0.1274], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 39 - 297: dog - cat || Loss: 1.185524582862854\n",
      "tensor([0., 1.]) tensor([0.8723, 0.1277], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 39 - 298: dog - cat || Loss: 1.185221791267395\n",
      "tensor([0., 1.]) tensor([0.8720, 0.1280], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 39 - 299: dog - cat || Loss: 1.1849182844161987\n",
      "tensor([0., 1.]) tensor([0.8717, 0.1283], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 39 - 300: dog - cat || Loss: 1.1846141815185547\n",
      "tensor([0., 1.]) tensor([0.8714, 0.1286], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 39 - 301: dog - cat || Loss: 1.1843092441558838\n",
      "tensor([0., 1.]) tensor([0.8710, 0.1290], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 39 - 302: dog - cat || Loss: 1.1840038299560547\n",
      "tensor([0., 1.]) tensor([0.8707, 0.1293], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 39 - 303: dog - cat || Loss: 1.1836974620819092\n",
      "tensor([0., 1.]) tensor([0.8704, 0.1296], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 39 - 304: dog - cat || Loss: 1.1833903789520264\n",
      "tensor([0., 1.]) tensor([0.8701, 0.1299], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 39 - 305: dog - cat || Loss: 1.1830825805664062\n",
      "tensor([0., 1.]) tensor([0.8698, 0.1302], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 39 - 306: dog - cat || Loss: 1.182774305343628\n",
      "tensor([0., 1.]) tensor([0.8695, 0.1305], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 39 - 307: dog - cat || Loss: 1.1824649572372437\n",
      "tensor([0., 1.]) tensor([0.8692, 0.1308], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 39 - 308: dog - cat || Loss: 1.1821550130844116\n",
      "tensor([0., 1.]) tensor([0.8689, 0.1311], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 39 - 309: dog - cat || Loss: 1.1818445920944214\n",
      "tensor([0., 1.]) tensor([0.8686, 0.1314], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 39 - 310: dog - cat || Loss: 1.1815332174301147\n",
      "tensor([0., 1.]) tensor([0.8683, 0.1317], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 39 - 311: dog - cat || Loss: 1.1812210083007812\n",
      "tensor([0., 1.]) tensor([0.8680, 0.1320], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 39 - 312: dog - cat || Loss: 1.1809083223342896\n",
      "tensor([0., 1.]) tensor([0.8676, 0.1324], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 39 - 313: dog - cat || Loss: 1.180594801902771\n",
      "tensor([0., 1.]) tensor([0.8673, 0.1327], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 39 - 314: dog - cat || Loss: 1.1802806854248047\n",
      "tensor([0., 1.]) tensor([0.8670, 0.1330], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 39 - 315: dog - cat || Loss: 1.179965615272522\n",
      "tensor([0., 1.]) tensor([0.8667, 0.1333], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 39 - 316: dog - cat || Loss: 1.1796499490737915\n",
      "tensor([0., 1.]) tensor([0.8664, 0.1336], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 39 - 317: dog - cat || Loss: 1.1793335676193237\n",
      "tensor([0., 1.]) tensor([0.8661, 0.1339], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 39 - 318: dog - cat || Loss: 1.1790164709091187\n",
      "tensor([0., 1.]) tensor([0.8658, 0.1342], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 39 - 319: dog - cat || Loss: 1.1786985397338867\n",
      "tensor([0., 1.]) tensor([0.8654, 0.1346], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 39 - 320: dog - cat || Loss: 1.178380012512207\n",
      "tensor([0., 1.]) tensor([0.8651, 0.1349], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 39 - 321: dog - cat || Loss: 1.178060531616211\n",
      "tensor([0., 1.]) tensor([0.8648, 0.1352], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 39 - 322: dog - cat || Loss: 1.1777405738830566\n",
      "tensor([0., 1.]) tensor([0.8645, 0.1355], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 39 - 323: dog - cat || Loss: 1.177419662475586\n",
      "tensor([0., 1.]) tensor([0.8642, 0.1358], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 39 - 324: dog - cat || Loss: 1.1770981550216675\n",
      "tensor([0., 1.]) tensor([0.8638, 0.1362], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 39 - 325: dog - cat || Loss: 1.1767759323120117\n",
      "tensor([0., 1.]) tensor([0.8635, 0.1365], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 39 - 326: dog - cat || Loss: 1.176452875137329\n",
      "tensor([0., 1.]) tensor([0.8632, 0.1368], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 39 - 327: dog - cat || Loss: 1.1761291027069092\n",
      "tensor([0., 1.]) tensor([0.8629, 0.1371], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 39 - 328: dog - cat || Loss: 1.175804615020752\n",
      "tensor([0., 1.]) tensor([0.8625, 0.1375], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 39 - 329: dog - cat || Loss: 1.1754792928695679\n",
      "tensor([0., 1.]) tensor([0.8622, 0.1378], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 39 - 330: dog - cat || Loss: 1.175153374671936\n",
      "tensor([0., 1.]) tensor([0.8619, 0.1381], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 39 - 331: dog - cat || Loss: 1.1748266220092773\n",
      "tensor([0., 1.]) tensor([0.8616, 0.1384], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 39 - 332: dog - cat || Loss: 1.1744990348815918\n",
      "tensor([0., 1.]) tensor([0.8612, 0.1388], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 39 - 333: dog - cat || Loss: 1.1741708517074585\n",
      "tensor([0., 1.]) tensor([0.8609, 0.1391], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 39 - 334: dog - cat || Loss: 1.173841953277588\n",
      "tensor([0., 1.]) tensor([0.8606, 0.1394], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 39 - 335: dog - cat || Loss: 1.1735119819641113\n",
      "tensor([0., 1.]) tensor([0.8603, 0.1397], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 39 - 336: dog - cat || Loss: 1.1731815338134766\n",
      "tensor([0., 1.]) tensor([0.8599, 0.1401], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 39 - 337: dog - cat || Loss: 1.1728503704071045\n",
      "tensor([0., 1.]) tensor([0.8596, 0.1404], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 39 - 338: dog - cat || Loss: 1.1725183725357056\n",
      "tensor([0., 1.]) tensor([0.8593, 0.1407], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 39 - 339: dog - cat || Loss: 1.1721856594085693\n",
      "tensor([0., 1.]) tensor([0.8589, 0.1411], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 39 - 340: dog - cat || Loss: 1.1718519926071167\n",
      "tensor([0., 1.]) tensor([0.8586, 0.1414], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 39 - 341: dog - cat || Loss: 1.1715178489685059\n",
      "tensor([0., 1.]) tensor([0.8583, 0.1417], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 39 - 342: dog - cat || Loss: 1.1711827516555786\n",
      "tensor([0., 1.]) tensor([0.8579, 0.1421], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 39 - 343: dog - cat || Loss: 1.1708471775054932\n",
      "tensor([0., 1.]) tensor([0.8576, 0.1424], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 39 - 344: dog - cat || Loss: 1.1705105304718018\n",
      "tensor([0., 1.]) tensor([0.8572, 0.1428], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 39 - 345: dog - cat || Loss: 1.170173168182373\n",
      "tensor([0., 1.]) tensor([0.8569, 0.1431], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 39 - 346: dog - cat || Loss: 1.169835090637207\n",
      "tensor([0., 1.]) tensor([0.8566, 0.1434], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 39 - 347: dog - cat || Loss: 1.1694962978363037\n",
      "tensor([0., 1.]) tensor([0.8562, 0.1438], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 39 - 348: dog - cat || Loss: 1.1691566705703735\n",
      "tensor([0., 1.]) tensor([0.8559, 0.1441], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 39 - 349: dog - cat || Loss: 1.168816328048706\n",
      "tensor([0., 1.]) tensor([0.8556, 0.1444], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 39 - 350: dog - cat || Loss: 1.1684751510620117\n",
      "tensor([0., 1.]) tensor([0.8552, 0.1448], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 39 - 351: dog - cat || Loss: 1.1681333780288696\n",
      "tensor([0., 1.]) tensor([0.8549, 0.1451], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 39 - 352: dog - cat || Loss: 1.1677905321121216\n",
      "tensor([0., 1.]) tensor([0.8545, 0.1455], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 39 - 353: dog - cat || Loss: 1.1674470901489258\n",
      "tensor([0., 1.]) tensor([0.8542, 0.1458], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 39 - 354: dog - cat || Loss: 1.1671028137207031\n",
      "tensor([0., 1.]) tensor([0.8538, 0.1462], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 39 - 355: dog - cat || Loss: 1.1667578220367432\n",
      "tensor([0., 1.]) tensor([0.8535, 0.1465], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 39 - 356: dog - cat || Loss: 1.1664122343063354\n",
      "tensor([0., 1.]) tensor([0.8532, 0.1468], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 39 - 357: dog - cat || Loss: 1.1660654544830322\n",
      "tensor([0., 1.]) tensor([0.8528, 0.1472], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 39 - 358: dog - cat || Loss: 1.1657180786132812\n",
      "tensor([0., 1.]) tensor([0.8525, 0.1475], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 39 - 359: dog - cat || Loss: 1.165369987487793\n",
      "tensor([0., 1.]) tensor([0.8521, 0.1479], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 39 - 360: dog - cat || Loss: 1.1650210618972778\n",
      "tensor([0., 1.]) tensor([0.8518, 0.1482], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 39 - 361: dog - cat || Loss: 1.1646714210510254\n",
      "tensor([0., 1.]) tensor([0.8514, 0.1486], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 39 - 362: dog - cat || Loss: 1.164320945739746\n",
      "tensor([0., 1.]) tensor([0.8511, 0.1489], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 39 - 363: dog - cat || Loss: 1.1639697551727295\n",
      "tensor([0., 1.]) tensor([0.8507, 0.1493], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 39 - 364: dog - cat || Loss: 1.163617730140686\n",
      "tensor([0., 1.]) tensor([0.8504, 0.1496], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 39 - 365: dog - cat || Loss: 1.1632649898529053\n",
      "tensor([0., 1.]) tensor([0.8500, 0.1500], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 39 - 366: dog - cat || Loss: 1.162911295890808\n",
      "tensor([0., 1.]) tensor([0.8496, 0.1504], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 39 - 367: dog - cat || Loss: 1.1625568866729736\n",
      "tensor([0., 1.]) tensor([0.8493, 0.1507], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 39 - 368: dog - cat || Loss: 1.1622017621994019\n",
      "tensor([0., 1.]) tensor([0.8489, 0.1511], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 39 - 369: dog - cat || Loss: 1.1618456840515137\n",
      "tensor([0., 1.]) tensor([0.8486, 0.1514], grad_fn=<SoftmaxBackward0>)\n",
      "=====epoch:40=====\n",
      "Epoch 40 - 0: cat - cat || Loss: 0.4650343060493469\n",
      "tensor([1., 0.]) tensor([0.8482, 0.1518], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 40 - 1: cat - cat || Loss: 0.46531960368156433\n",
      "tensor([1., 0.]) tensor([0.8479, 0.1521], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 40 - 2: cat - cat || Loss: 0.46554040908813477\n",
      "tensor([1., 0.]) tensor([0.8477, 0.1523], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 40 - 3: cat - cat || Loss: 0.46570298075675964\n",
      "tensor([1., 0.]) tensor([0.8476, 0.1524], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 40 - 4: cat - cat || Loss: 0.46581315994262695\n",
      "tensor([1., 0.]) tensor([0.8474, 0.1526], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 40 - 5: cat - cat || Loss: 0.46587610244750977\n",
      "tensor([1., 0.]) tensor([0.8474, 0.1526], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 40 - 6: cat - cat || Loss: 0.4658963680267334\n",
      "tensor([1., 0.]) tensor([0.8474, 0.1526], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 40 - 7: cat - cat || Loss: 0.46587833762168884\n",
      "tensor([1., 0.]) tensor([0.8474, 0.1526], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 40 - 8: cat - cat || Loss: 0.4658258855342865\n",
      "tensor([1., 0.]) tensor([0.8474, 0.1526], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 40 - 9: cat - cat || Loss: 0.4657423496246338\n",
      "tensor([1., 0.]) tensor([0.8475, 0.1525], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 40 - 10: cat - cat || Loss: 0.46563097834587097\n",
      "tensor([1., 0.]) tensor([0.8476, 0.1524], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 40 - 11: cat - cat || Loss: 0.46549463272094727\n",
      "tensor([1., 0.]) tensor([0.8478, 0.1522], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 40 - 12: cat - cat || Loss: 0.46533578634262085\n",
      "tensor([1., 0.]) tensor([0.8479, 0.1521], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 40 - 13: cat - cat || Loss: 0.4651566445827484\n",
      "tensor([1., 0.]) tensor([0.8481, 0.1519], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 40 - 14: cat - cat || Loss: 0.4649595618247986\n",
      "tensor([1., 0.]) tensor([0.8483, 0.1517], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 40 - 15: cat - cat || Loss: 0.46474605798721313\n",
      "tensor([1., 0.]) tensor([0.8485, 0.1515], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 40 - 16: cat - cat || Loss: 0.4645181894302368\n",
      "tensor([1., 0.]) tensor([0.8487, 0.1513], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 40 - 17: cat - cat || Loss: 0.4642772078514099\n",
      "tensor([1., 0.]) tensor([0.8490, 0.1510], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 40 - 18: cat - cat || Loss: 0.4640246629714966\n",
      "tensor([1., 0.]) tensor([0.8492, 0.1508], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 40 - 19: cat - cat || Loss: 0.4637615978717804\n",
      "tensor([1., 0.]) tensor([0.8495, 0.1505], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 40 - 20: cat - cat || Loss: 0.463489294052124\n",
      "tensor([1., 0.]) tensor([0.8498, 0.1502], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 40 - 21: cat - cat || Loss: 0.46320873498916626\n",
      "tensor([1., 0.]) tensor([0.8501, 0.1499], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 40 - 22: cat - cat || Loss: 0.4629208445549011\n",
      "tensor([1., 0.]) tensor([0.8503, 0.1497], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 40 - 23: cat - cat || Loss: 0.4626263380050659\n",
      "tensor([1., 0.]) tensor([0.8506, 0.1494], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 40 - 24: cat - cat || Loss: 0.4623259902000427\n",
      "tensor([1., 0.]) tensor([0.8509, 0.1491], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 40 - 25: cat - cat || Loss: 0.46202051639556885\n",
      "tensor([1., 0.]) tensor([0.8512, 0.1488], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 40 - 26: cat - cat || Loss: 0.46171051263809204\n",
      "tensor([1., 0.]) tensor([0.8516, 0.1484], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 40 - 27: cat - cat || Loss: 0.4613964259624481\n",
      "tensor([1., 0.]) tensor([0.8519, 0.1481], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 40 - 28: cat - cat || Loss: 0.46107882261276245\n",
      "tensor([1., 0.]) tensor([0.8522, 0.1478], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 40 - 29: cat - cat || Loss: 0.4607579708099365\n",
      "tensor([1., 0.]) tensor([0.8525, 0.1475], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 40 - 30: cat - cat || Loss: 0.46043455600738525\n",
      "tensor([1., 0.]) tensor([0.8528, 0.1472], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 40 - 31: cat - cat || Loss: 0.46010857820510864\n",
      "tensor([1., 0.]) tensor([0.8532, 0.1468], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 40 - 32: cat - cat || Loss: 0.4597806930541992\n",
      "tensor([1., 0.]) tensor([0.8535, 0.1465], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 40 - 33: cat - cat || Loss: 0.4594511091709137\n",
      "tensor([1., 0.]) tensor([0.8538, 0.1462], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 40 - 34: cat - cat || Loss: 0.45911985635757446\n",
      "tensor([1., 0.]) tensor([0.8541, 0.1459], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 40 - 35: cat - cat || Loss: 0.4587874412536621\n",
      "tensor([1., 0.]) tensor([0.8545, 0.1455], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 40 - 36: cat - cat || Loss: 0.458453893661499\n",
      "tensor([1., 0.]) tensor([0.8548, 0.1452], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 40 - 37: cat - cat || Loss: 0.45811957120895386\n",
      "tensor([1., 0.]) tensor([0.8551, 0.1449], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 40 - 38: cat - cat || Loss: 0.45778435468673706\n",
      "tensor([1., 0.]) tensor([0.8555, 0.1445], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 40 - 39: cat - cat || Loss: 0.4574486315250397\n",
      "tensor([1., 0.]) tensor([0.8558, 0.1442], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 40 - 40: cat - cat || Loss: 0.45711269974708557\n",
      "tensor([1., 0.]) tensor([0.8561, 0.1439], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 40 - 41: cat - cat || Loss: 0.45677611231803894\n",
      "tensor([1., 0.]) tensor([0.8565, 0.1435], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 40 - 42: cat - cat || Loss: 0.4564395546913147\n",
      "tensor([1., 0.]) tensor([0.8568, 0.1432], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 40 - 43: cat - cat || Loss: 0.45610278844833374\n",
      "tensor([1., 0.]) tensor([0.8572, 0.1428], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 40 - 44: cat - cat || Loss: 0.4557661712169647\n",
      "tensor([1., 0.]) tensor([0.8575, 0.1425], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 40 - 45: cat - cat || Loss: 0.45542943477630615\n",
      "tensor([1., 0.]) tensor([0.8578, 0.1422], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 40 - 46: cat - cat || Loss: 0.4550928473472595\n",
      "tensor([1., 0.]) tensor([0.8582, 0.1418], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 40 - 47: cat - cat || Loss: 0.45475658774375916\n",
      "tensor([1., 0.]) tensor([0.8585, 0.1415], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 40 - 48: cat - cat || Loss: 0.4544205665588379\n",
      "tensor([1., 0.]) tensor([0.8588, 0.1412], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 40 - 49: cat - cat || Loss: 0.45408475399017334\n",
      "tensor([1., 0.]) tensor([0.8592, 0.1408], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 40 - 50: cat - cat || Loss: 0.4537494480609894\n",
      "tensor([1., 0.]) tensor([0.8595, 0.1405], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 40 - 51: cat - cat || Loss: 0.4534144401550293\n",
      "tensor([1., 0.]) tensor([0.8598, 0.1402], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 40 - 52: cat - cat || Loss: 0.45307987928390503\n",
      "tensor([1., 0.]) tensor([0.8602, 0.1398], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 40 - 53: cat - cat || Loss: 0.45274579524993896\n",
      "tensor([1., 0.]) tensor([0.8605, 0.1395], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 40 - 54: cat - cat || Loss: 0.4524122476577759\n",
      "tensor([1., 0.]) tensor([0.8608, 0.1392], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 40 - 55: cat - cat || Loss: 0.45207923650741577\n",
      "tensor([1., 0.]) tensor([0.8612, 0.1388], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 40 - 56: cat - cat || Loss: 0.45174676179885864\n",
      "tensor([1., 0.]) tensor([0.8615, 0.1385], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 40 - 57: cat - cat || Loss: 0.4514148235321045\n",
      "tensor([1., 0.]) tensor([0.8618, 0.1382], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 40 - 58: cat - cat || Loss: 0.45108354091644287\n",
      "tensor([1., 0.]) tensor([0.8622, 0.1378], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 40 - 59: cat - cat || Loss: 0.4507529139518738\n",
      "tensor([1., 0.]) tensor([0.8625, 0.1375], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 40 - 60: cat - cat || Loss: 0.45042282342910767\n",
      "tensor([1., 0.]) tensor([0.8628, 0.1372], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 40 - 61: cat - cat || Loss: 0.45009341835975647\n",
      "tensor([1., 0.]) tensor([0.8632, 0.1368], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 40 - 62: cat - cat || Loss: 0.449764609336853\n",
      "tensor([1., 0.]) tensor([0.8635, 0.1365], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 40 - 63: cat - cat || Loss: 0.44943660497665405\n",
      "tensor([1., 0.]) tensor([0.8638, 0.1362], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 40 - 64: cat - cat || Loss: 0.44910919666290283\n",
      "tensor([1., 0.]) tensor([0.8642, 0.1358], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 40 - 65: cat - cat || Loss: 0.44878244400024414\n",
      "tensor([1., 0.]) tensor([0.8645, 0.1355], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 40 - 66: cat - cat || Loss: 0.44845640659332275\n",
      "tensor([1., 0.]) tensor([0.8648, 0.1352], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 40 - 67: cat - cat || Loss: 0.44813117384910583\n",
      "tensor([1., 0.]) tensor([0.8651, 0.1349], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 40 - 68: cat - cat || Loss: 0.44780653715133667\n",
      "tensor([1., 0.]) tensor([0.8655, 0.1345], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 40 - 69: cat - cat || Loss: 0.4474826157093048\n",
      "tensor([1., 0.]) tensor([0.8658, 0.1342], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 40 - 70: cat - cat || Loss: 0.44715946912765503\n",
      "tensor([1., 0.]) tensor([0.8661, 0.1339], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 40 - 71: cat - cat || Loss: 0.44683706760406494\n",
      "tensor([1., 0.]) tensor([0.8664, 0.1336], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 40 - 72: cat - cat || Loss: 0.4465153217315674\n",
      "tensor([1., 0.]) tensor([0.8667, 0.1333], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 40 - 73: cat - cat || Loss: 0.44619429111480713\n",
      "tensor([1., 0.]) tensor([0.8671, 0.1329], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 40 - 74: cat - cat || Loss: 0.4458739161491394\n",
      "tensor([1., 0.]) tensor([0.8674, 0.1326], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 40 - 75: cat - cat || Loss: 0.44555437564849854\n",
      "tensor([1., 0.]) tensor([0.8677, 0.1323], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 40 - 76: cat - cat || Loss: 0.44523561000823975\n",
      "tensor([1., 0.]) tensor([0.8680, 0.1320], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 40 - 77: cat - cat || Loss: 0.4449175000190735\n",
      "tensor([1., 0.]) tensor([0.8683, 0.1317], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 40 - 78: cat - cat || Loss: 0.44460010528564453\n",
      "tensor([1., 0.]) tensor([0.8687, 0.1313], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 40 - 79: cat - cat || Loss: 0.44428351521492004\n",
      "tensor([1., 0.]) tensor([0.8690, 0.1310], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 40 - 80: cat - cat || Loss: 0.44396767020225525\n",
      "tensor([1., 0.]) tensor([0.8693, 0.1307], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 40 - 81: cat - cat || Loss: 0.44365236163139343\n",
      "tensor([1., 0.]) tensor([0.8696, 0.1304], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 40 - 82: cat - cat || Loss: 0.44333794713020325\n",
      "tensor([1., 0.]) tensor([0.8699, 0.1301], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 40 - 83: cat - cat || Loss: 0.443024218082428\n",
      "tensor([1., 0.]) tensor([0.8702, 0.1298], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 40 - 84: cat - cat || Loss: 0.44271141290664673\n",
      "tensor([1., 0.]) tensor([0.8706, 0.1294], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 40 - 85: cat - cat || Loss: 0.44239914417266846\n",
      "tensor([1., 0.]) tensor([0.8709, 0.1291], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 40 - 86: cat - cat || Loss: 0.44208765029907227\n",
      "tensor([1., 0.]) tensor([0.8712, 0.1288], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 40 - 87: cat - cat || Loss: 0.44177693128585815\n",
      "tensor([1., 0.]) tensor([0.8715, 0.1285], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 40 - 88: cat - cat || Loss: 0.4414668679237366\n",
      "tensor([1., 0.]) tensor([0.8718, 0.1282], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 40 - 89: cat - cat || Loss: 0.44115760922431946\n",
      "tensor([1., 0.]) tensor([0.8721, 0.1279], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 40 - 90: cat - cat || Loss: 0.4408491253852844\n",
      "tensor([1., 0.]) tensor([0.8724, 0.1276], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 40 - 91: cat - cat || Loss: 0.44054123759269714\n",
      "tensor([1., 0.]) tensor([0.8727, 0.1273], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 40 - 92: cat - cat || Loss: 0.4402342438697815\n",
      "tensor([1., 0.]) tensor([0.8730, 0.1270], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 40 - 93: cat - cat || Loss: 0.43992793560028076\n",
      "tensor([1., 0.]) tensor([0.8733, 0.1267], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 40 - 94: cat - cat || Loss: 0.43962228298187256\n",
      "tensor([1., 0.]) tensor([0.8736, 0.1264], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 40 - 95: cat - cat || Loss: 0.43931740522384644\n",
      "tensor([1., 0.]) tensor([0.8739, 0.1261], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 40 - 96: cat - cat || Loss: 0.4390133321285248\n",
      "tensor([1., 0.]) tensor([0.8742, 0.1258], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 40 - 97: cat - cat || Loss: 0.43870994448661804\n",
      "tensor([1., 0.]) tensor([0.8746, 0.1254], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 40 - 98: cat - cat || Loss: 0.43840718269348145\n",
      "tensor([1., 0.]) tensor([0.8749, 0.1251], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 40 - 99: cat - cat || Loss: 0.43810534477233887\n",
      "tensor([1., 0.]) tensor([0.8752, 0.1248], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 40 - 100: cat - cat || Loss: 0.4378041625022888\n",
      "tensor([1., 0.]) tensor([0.8755, 0.1245], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 40 - 101: cat - cat || Loss: 0.43750375509262085\n",
      "tensor([1., 0.]) tensor([0.8758, 0.1242], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 40 - 102: cat - cat || Loss: 0.4372040331363678\n",
      "tensor([1., 0.]) tensor([0.8761, 0.1239], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 40 - 103: cat - cat || Loss: 0.4369049370288849\n",
      "tensor([1., 0.]) tensor([0.8764, 0.1236], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 40 - 104: cat - cat || Loss: 0.43660667538642883\n",
      "tensor([1., 0.]) tensor([0.8767, 0.1233], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 40 - 105: cat - cat || Loss: 0.4363091289997101\n",
      "tensor([1., 0.]) tensor([0.8770, 0.1230], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 40 - 106: cat - cat || Loss: 0.43601226806640625\n",
      "tensor([1., 0.]) tensor([0.8772, 0.1228], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 40 - 107: cat - cat || Loss: 0.4357161521911621\n",
      "tensor([1., 0.]) tensor([0.8775, 0.1225], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 40 - 108: cat - cat || Loss: 0.43542078137397766\n",
      "tensor([1., 0.]) tensor([0.8778, 0.1222], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 40 - 109: cat - cat || Loss: 0.4351261258125305\n",
      "tensor([1., 0.]) tensor([0.8781, 0.1219], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 40 - 110: cat - cat || Loss: 0.4348321557044983\n",
      "tensor([1., 0.]) tensor([0.8784, 0.1216], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 40 - 111: cat - cat || Loss: 0.43453896045684814\n",
      "tensor([1., 0.]) tensor([0.8787, 0.1213], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 40 - 112: cat - cat || Loss: 0.43424636125564575\n",
      "tensor([1., 0.]) tensor([0.8790, 0.1210], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 40 - 113: cat - cat || Loss: 0.43395453691482544\n",
      "tensor([1., 0.]) tensor([0.8793, 0.1207], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 40 - 114: cat - cat || Loss: 0.43366342782974243\n",
      "tensor([1., 0.]) tensor([0.8796, 0.1204], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 40 - 115: cat - cat || Loss: 0.43337303400039673\n",
      "tensor([1., 0.]) tensor([0.8799, 0.1201], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 40 - 116: cat - cat || Loss: 0.43308332562446594\n",
      "tensor([1., 0.]) tensor([0.8802, 0.1198], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 40 - 117: cat - cat || Loss: 0.43279433250427246\n",
      "tensor([1., 0.]) tensor([0.8805, 0.1195], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 40 - 118: cat - cat || Loss: 0.4325060248374939\n",
      "tensor([1., 0.]) tensor([0.8808, 0.1192], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 40 - 119: cat - cat || Loss: 0.4322185516357422\n",
      "tensor([1., 0.]) tensor([0.8810, 0.1190], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 40 - 120: cat - cat || Loss: 0.43193164467811584\n",
      "tensor([1., 0.]) tensor([0.8813, 0.1187], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 40 - 121: cat - cat || Loss: 0.43164539337158203\n",
      "tensor([1., 0.]) tensor([0.8816, 0.1184], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 40 - 122: cat - cat || Loss: 0.4313599467277527\n",
      "tensor([1., 0.]) tensor([0.8819, 0.1181], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 40 - 123: cat - cat || Loss: 0.43107521533966064\n",
      "tensor([1., 0.]) tensor([0.8822, 0.1178], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 40 - 124: cat - cat || Loss: 0.43079113960266113\n",
      "tensor([1., 0.]) tensor([0.8825, 0.1175], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 40 - 125: cat - cat || Loss: 0.4305078089237213\n",
      "tensor([1., 0.]) tensor([0.8828, 0.1172], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 40 - 126: cat - cat || Loss: 0.43022510409355164\n",
      "tensor([1., 0.]) tensor([0.8830, 0.1170], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 40 - 127: cat - cat || Loss: 0.4299430847167969\n",
      "tensor([1., 0.]) tensor([0.8833, 0.1167], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 40 - 128: cat - cat || Loss: 0.42966175079345703\n",
      "tensor([1., 0.]) tensor([0.8836, 0.1164], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 40 - 129: cat - cat || Loss: 0.4293811619281769\n",
      "tensor([1., 0.]) tensor([0.8839, 0.1161], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 40 - 130: cat - cat || Loss: 0.4291013479232788\n",
      "tensor([1., 0.]) tensor([0.8842, 0.1158], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 40 - 131: cat - cat || Loss: 0.4288220703601837\n",
      "tensor([1., 0.]) tensor([0.8844, 0.1156], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 40 - 132: cat - cat || Loss: 0.42854347825050354\n",
      "tensor([1., 0.]) tensor([0.8847, 0.1153], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 40 - 133: cat - cat || Loss: 0.42826569080352783\n",
      "tensor([1., 0.]) tensor([0.8850, 0.1150], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 40 - 134: cat - cat || Loss: 0.4279884994029999\n",
      "tensor([1., 0.]) tensor([0.8853, 0.1147], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 40 - 135: cat - cat || Loss: 0.427712082862854\n",
      "tensor([1., 0.]) tensor([0.8855, 0.1145], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 40 - 136: cat - cat || Loss: 0.42743629217147827\n",
      "tensor([1., 0.]) tensor([0.8858, 0.1142], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 40 - 137: cat - cat || Loss: 0.42716115713119507\n",
      "tensor([1., 0.]) tensor([0.8861, 0.1139], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 40 - 138: cat - cat || Loss: 0.42688676714897156\n",
      "tensor([1., 0.]) tensor([0.8864, 0.1136], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 40 - 139: cat - cat || Loss: 0.4266130030155182\n",
      "tensor([1., 0.]) tensor([0.8866, 0.1134], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 40 - 140: cat - cat || Loss: 0.42633992433547974\n",
      "tensor([1., 0.]) tensor([0.8869, 0.1131], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 40 - 141: cat - cat || Loss: 0.4260675609111786\n",
      "tensor([1., 0.]) tensor([0.8872, 0.1128], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 40 - 142: cat - cat || Loss: 0.42579585313796997\n",
      "tensor([1., 0.]) tensor([0.8875, 0.1125], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 40 - 143: cat - cat || Loss: 0.4255247712135315\n",
      "tensor([1., 0.]) tensor([0.8877, 0.1123], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 40 - 144: cat - cat || Loss: 0.4252544641494751\n",
      "tensor([1., 0.]) tensor([0.8880, 0.1120], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 40 - 145: cat - cat || Loss: 0.42498475313186646\n",
      "tensor([1., 0.]) tensor([0.8883, 0.1117], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 40 - 146: cat - cat || Loss: 0.4247157573699951\n",
      "tensor([1., 0.]) tensor([0.8885, 0.1115], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 40 - 147: cat - cat || Loss: 0.4244474172592163\n",
      "tensor([1., 0.]) tensor([0.8888, 0.1112], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 40 - 148: cat - cat || Loss: 0.4241796135902405\n",
      "tensor([1., 0.]) tensor([0.8891, 0.1109], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 40 - 149: cat - cat || Loss: 0.4239126443862915\n",
      "tensor([1., 0.]) tensor([0.8893, 0.1107], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 40 - 150: cat - cat || Loss: 0.4236462116241455\n",
      "tensor([1., 0.]) tensor([0.8896, 0.1104], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 40 - 151: cat - cat || Loss: 0.4233805537223816\n",
      "tensor([1., 0.]) tensor([0.8899, 0.1101], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 40 - 152: cat - cat || Loss: 0.4231155216693878\n",
      "tensor([1., 0.]) tensor([0.8901, 0.1099], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 40 - 153: cat - cat || Loss: 0.4228510856628418\n",
      "tensor([1., 0.]) tensor([0.8904, 0.1096], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 40 - 154: cat - cat || Loss: 0.4225873351097107\n",
      "tensor([1., 0.]) tensor([0.8907, 0.1093], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 40 - 155: cat - cat || Loss: 0.4223242998123169\n",
      "tensor([1., 0.]) tensor([0.8909, 0.1091], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 40 - 156: cat - cat || Loss: 0.42206186056137085\n",
      "tensor([1., 0.]) tensor([0.8912, 0.1088], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 40 - 157: cat - cat || Loss: 0.4218001365661621\n",
      "tensor([1., 0.]) tensor([0.8915, 0.1085], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 40 - 158: cat - cat || Loss: 0.42153897881507874\n",
      "tensor([1., 0.]) tensor([0.8917, 0.1083], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 40 - 159: cat - cat || Loss: 0.42127853631973267\n",
      "tensor([1., 0.]) tensor([0.8920, 0.1080], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 40 - 160: cat - cat || Loss: 0.42101871967315674\n",
      "tensor([1., 0.]) tensor([0.8922, 0.1078], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 40 - 161: cat - cat || Loss: 0.42075955867767334\n",
      "tensor([1., 0.]) tensor([0.8925, 0.1075], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 40 - 162: cat - cat || Loss: 0.42050105333328247\n",
      "tensor([1., 0.]) tensor([0.8928, 0.1072], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 40 - 163: cat - cat || Loss: 0.42024314403533936\n",
      "tensor([1., 0.]) tensor([0.8930, 0.1070], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 40 - 164: cat - cat || Loss: 0.41998592019081116\n",
      "tensor([1., 0.]) tensor([0.8933, 0.1067], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 40 - 165: cat - cat || Loss: 0.4197293519973755\n",
      "tensor([1., 0.]) tensor([0.8935, 0.1065], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 40 - 166: cat - cat || Loss: 0.4194733798503876\n",
      "tensor([1., 0.]) tensor([0.8938, 0.1062], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 40 - 167: cat - cat || Loss: 0.4192180931568146\n",
      "tensor([1., 0.]) tensor([0.8940, 0.1060], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 40 - 168: cat - cat || Loss: 0.41896340250968933\n",
      "tensor([1., 0.]) tensor([0.8943, 0.1057], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 40 - 169: cat - cat || Loss: 0.41870933771133423\n",
      "tensor([1., 0.]) tensor([0.8946, 0.1054], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 40 - 170: cat - cat || Loss: 0.41845595836639404\n",
      "tensor([1., 0.]) tensor([0.8948, 0.1052], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 40 - 171: cat - cat || Loss: 0.4182032346725464\n",
      "tensor([1., 0.]) tensor([0.8951, 0.1049], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 40 - 172: cat - cat || Loss: 0.4179510176181793\n",
      "tensor([1., 0.]) tensor([0.8953, 0.1047], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 40 - 173: cat - cat || Loss: 0.41769957542419434\n",
      "tensor([1., 0.]) tensor([0.8956, 0.1044], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 40 - 174: cat - cat || Loss: 0.41744863986968994\n",
      "tensor([1., 0.]) tensor([0.8958, 0.1042], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 40 - 175: cat - cat || Loss: 0.4171983599662781\n",
      "tensor([1., 0.]) tensor([0.8961, 0.1039], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 40 - 176: cat - cat || Loss: 0.4169487953186035\n",
      "tensor([1., 0.]) tensor([0.8963, 0.1037], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 40 - 177: cat - cat || Loss: 0.4166998267173767\n",
      "tensor([1., 0.]) tensor([0.8966, 0.1034], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 40 - 178: cat - cat || Loss: 0.41645142436027527\n",
      "tensor([1., 0.]) tensor([0.8968, 0.1032], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 40 - 179: cat - cat || Loss: 0.41620367765426636\n",
      "tensor([1., 0.]) tensor([0.8971, 0.1029], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 40 - 180: cat - cat || Loss: 0.4159565567970276\n",
      "tensor([1., 0.]) tensor([0.8973, 0.1027], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 40 - 181: cat - cat || Loss: 0.4157099723815918\n",
      "tensor([1., 0.]) tensor([0.8976, 0.1024], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 40 - 182: cat - cat || Loss: 0.4154641032218933\n",
      "tensor([1., 0.]) tensor([0.8978, 0.1022], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 40 - 183: cat - cat || Loss: 0.41521891951560974\n",
      "tensor([1., 0.]) tensor([0.8980, 0.1020], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 40 - 184: cat - cat || Loss: 0.4149742126464844\n",
      "tensor([1., 0.]) tensor([0.8983, 0.1017], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 40 - 185: cat - cat || Loss: 0.4147302210330963\n",
      "tensor([1., 0.]) tensor([0.8985, 0.1015], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 40 - 186: cat - cat || Loss: 0.41448670625686646\n",
      "tensor([1., 0.]) tensor([0.8988, 0.1012], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 40 - 187: cat - cat || Loss: 0.4142439365386963\n",
      "tensor([1., 0.]) tensor([0.8990, 0.1010], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 40 - 188: cat - cat || Loss: 0.4140017032623291\n",
      "tensor([1., 0.]) tensor([0.8993, 0.1007], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 40 - 189: cat - cat || Loss: 0.41376012563705444\n",
      "tensor([1., 0.]) tensor([0.8995, 0.1005], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 40 - 190: dog - cat || Loss: 1.2130043506622314\n",
      "tensor([0., 1.]) tensor([0.8997, 0.1003], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 40 - 191: dog - cat || Loss: 1.2131973505020142\n",
      "tensor([0., 1.]) tensor([0.8999, 0.1001], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 40 - 192: dog - cat || Loss: 1.2133469581604004\n",
      "tensor([0., 1.]) tensor([0.9001, 0.0999], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 40 - 193: dog - cat || Loss: 1.2134578227996826\n",
      "tensor([0., 1.]) tensor([0.9002, 0.0998], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 40 - 194: dog - cat || Loss: 1.213533878326416\n",
      "tensor([0., 1.]) tensor([0.9003, 0.0997], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 40 - 195: dog - cat || Loss: 1.213578701019287\n",
      "tensor([0., 1.]) tensor([0.9003, 0.0997], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 40 - 196: dog - cat || Loss: 1.2135951519012451\n",
      "tensor([0., 1.]) tensor([0.9003, 0.0997], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 40 - 197: dog - cat || Loss: 1.2135863304138184\n",
      "tensor([0., 1.]) tensor([0.9003, 0.0997], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 40 - 198: dog - cat || Loss: 1.213554859161377\n",
      "tensor([0., 1.]) tensor([0.9003, 0.0997], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 40 - 199: dog - cat || Loss: 1.2135027647018433\n",
      "tensor([0., 1.]) tensor([0.9002, 0.0998], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 40 - 200: dog - cat || Loss: 1.2134323120117188\n",
      "tensor([0., 1.]) tensor([0.9002, 0.0998], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 40 - 201: dog - cat || Loss: 1.213344931602478\n",
      "tensor([0., 1.]) tensor([0.9001, 0.0999], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 40 - 202: dog - cat || Loss: 1.2132426500320435\n",
      "tensor([0., 1.]) tensor([0.9000, 0.1000], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 40 - 203: dog - cat || Loss: 1.2131266593933105\n",
      "tensor([0., 1.]) tensor([0.8999, 0.1001], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 40 - 204: dog - cat || Loss: 1.212998867034912\n",
      "tensor([0., 1.]) tensor([0.8997, 0.1003], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 40 - 205: dog - cat || Loss: 1.2128595113754272\n",
      "tensor([0., 1.]) tensor([0.8996, 0.1004], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 40 - 206: dog - cat || Loss: 1.2127104997634888\n",
      "tensor([0., 1.]) tensor([0.8994, 0.1006], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 40 - 207: dog - cat || Loss: 1.2125521898269653\n",
      "tensor([0., 1.]) tensor([0.8993, 0.1007], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 40 - 208: dog - cat || Loss: 1.212385892868042\n",
      "tensor([0., 1.]) tensor([0.8991, 0.1009], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 40 - 209: dog - cat || Loss: 1.2122119665145874\n",
      "tensor([0., 1.]) tensor([0.8990, 0.1010], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 40 - 210: dog - cat || Loss: 1.212031364440918\n",
      "tensor([0., 1.]) tensor([0.8988, 0.1012], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 40 - 211: dog - cat || Loss: 1.2118446826934814\n",
      "tensor([0., 1.]) tensor([0.8986, 0.1014], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 40 - 212: dog - cat || Loss: 1.211652398109436\n",
      "tensor([0., 1.]) tensor([0.8984, 0.1016], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 40 - 213: dog - cat || Loss: 1.2114551067352295\n",
      "tensor([0., 1.]) tensor([0.8982, 0.1018], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 40 - 214: dog - cat || Loss: 1.2112529277801514\n",
      "tensor([0., 1.]) tensor([0.8980, 0.1020], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 40 - 215: dog - cat || Loss: 1.2110469341278076\n",
      "tensor([0., 1.]) tensor([0.8978, 0.1022], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 40 - 216: dog - cat || Loss: 1.2108367681503296\n",
      "tensor([0., 1.]) tensor([0.8976, 0.1024], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 40 - 217: dog - cat || Loss: 1.2106231451034546\n",
      "tensor([0., 1.]) tensor([0.8974, 0.1026], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 40 - 218: dog - cat || Loss: 1.2104063034057617\n",
      "tensor([0., 1.]) tensor([0.8971, 0.1029], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 40 - 219: dog - cat || Loss: 1.21018648147583\n",
      "tensor([0., 1.]) tensor([0.8969, 0.1031], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 40 - 220: dog - cat || Loss: 1.2099641561508179\n",
      "tensor([0., 1.]) tensor([0.8967, 0.1033], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 40 - 221: dog - cat || Loss: 1.209738850593567\n",
      "tensor([0., 1.]) tensor([0.8965, 0.1035], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 40 - 222: dog - cat || Loss: 1.2095115184783936\n",
      "tensor([0., 1.]) tensor([0.8962, 0.1038], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 40 - 223: dog - cat || Loss: 1.2092821598052979\n",
      "tensor([0., 1.]) tensor([0.8960, 0.1040], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 40 - 224: dog - cat || Loss: 1.2090505361557007\n",
      "tensor([0., 1.]) tensor([0.8958, 0.1042], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 40 - 225: dog - cat || Loss: 1.2088171243667603\n",
      "tensor([0., 1.]) tensor([0.8956, 0.1044], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 40 - 226: dog - cat || Loss: 1.2085820436477661\n",
      "tensor([0., 1.]) tensor([0.8953, 0.1047], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 40 - 227: dog - cat || Loss: 1.2083452939987183\n",
      "tensor([0., 1.]) tensor([0.8951, 0.1049], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 40 - 228: dog - cat || Loss: 1.2081071138381958\n",
      "tensor([0., 1.]) tensor([0.8948, 0.1052], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 40 - 229: dog - cat || Loss: 1.2078675031661987\n",
      "tensor([0., 1.]) tensor([0.8946, 0.1054], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 40 - 230: dog - cat || Loss: 1.207626461982727\n",
      "tensor([0., 1.]) tensor([0.8944, 0.1056], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 40 - 231: dog - cat || Loss: 1.2073839902877808\n",
      "tensor([0., 1.]) tensor([0.8941, 0.1059], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 40 - 232: dog - cat || Loss: 1.2071404457092285\n",
      "tensor([0., 1.]) tensor([0.8939, 0.1061], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 40 - 233: dog - cat || Loss: 1.2068959474563599\n",
      "tensor([0., 1.]) tensor([0.8936, 0.1064], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 40 - 234: dog - cat || Loss: 1.2066502571105957\n",
      "tensor([0., 1.]) tensor([0.8934, 0.1066], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 40 - 235: dog - cat || Loss: 1.206403374671936\n",
      "tensor([0., 1.]) tensor([0.8931, 0.1069], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 40 - 236: dog - cat || Loss: 1.20615553855896\n",
      "tensor([0., 1.]) tensor([0.8929, 0.1071], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 40 - 237: dog - cat || Loss: 1.2059067487716675\n",
      "tensor([0., 1.]) tensor([0.8926, 0.1074], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 40 - 238: dog - cat || Loss: 1.2056570053100586\n",
      "tensor([0., 1.]) tensor([0.8924, 0.1076], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 40 - 239: dog - cat || Loss: 1.2054064273834229\n",
      "tensor([0., 1.]) tensor([0.8921, 0.1079], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 40 - 240: dog - cat || Loss: 1.2051550149917603\n",
      "tensor([0., 1.]) tensor([0.8919, 0.1081], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 40 - 241: dog - cat || Loss: 1.2049025297164917\n",
      "tensor([0., 1.]) tensor([0.8916, 0.1084], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 40 - 242: dog - cat || Loss: 1.2046493291854858\n",
      "tensor([0., 1.]) tensor([0.8914, 0.1086], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 40 - 243: dog - cat || Loss: 1.2043954133987427\n",
      "tensor([0., 1.]) tensor([0.8911, 0.1089], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 40 - 244: dog - cat || Loss: 1.2041406631469727\n",
      "tensor([0., 1.]) tensor([0.8909, 0.1091], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 40 - 245: dog - cat || Loss: 1.2038851976394653\n",
      "tensor([0., 1.]) tensor([0.8906, 0.1094], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 40 - 246: dog - cat || Loss: 1.2036287784576416\n",
      "tensor([0., 1.]) tensor([0.8904, 0.1096], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 40 - 247: dog - cat || Loss: 1.2033717632293701\n",
      "tensor([0., 1.]) tensor([0.8901, 0.1099], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 40 - 248: dog - cat || Loss: 1.2031139135360718\n",
      "tensor([0., 1.]) tensor([0.8899, 0.1101], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 40 - 249: dog - cat || Loss: 1.2028554677963257\n",
      "tensor([0., 1.]) tensor([0.8896, 0.1104], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 40 - 250: dog - cat || Loss: 1.2025963068008423\n",
      "tensor([0., 1.]) tensor([0.8893, 0.1107], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 40 - 251: dog - cat || Loss: 1.2023364305496216\n",
      "tensor([0., 1.]) tensor([0.8891, 0.1109], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 40 - 252: dog - cat || Loss: 1.202075719833374\n",
      "tensor([0., 1.]) tensor([0.8888, 0.1112], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 40 - 253: dog - cat || Loss: 1.2018144130706787\n",
      "tensor([0., 1.]) tensor([0.8886, 0.1114], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 40 - 254: dog - cat || Loss: 1.201552391052246\n",
      "tensor([0., 1.]) tensor([0.8883, 0.1117], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 40 - 255: dog - cat || Loss: 1.2012895345687866\n",
      "tensor([0., 1.]) tensor([0.8880, 0.1120], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 40 - 256: dog - cat || Loss: 1.201026201248169\n",
      "tensor([0., 1.]) tensor([0.8878, 0.1122], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 40 - 257: dog - cat || Loss: 1.200762152671814\n",
      "tensor([0., 1.]) tensor([0.8875, 0.1125], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 40 - 258: dog - cat || Loss: 1.2004973888397217\n",
      "tensor([0., 1.]) tensor([0.8872, 0.1128], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 40 - 259: dog - cat || Loss: 1.2002320289611816\n",
      "tensor([0., 1.]) tensor([0.8870, 0.1130], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 40 - 260: dog - cat || Loss: 1.1999657154083252\n",
      "tensor([0., 1.]) tensor([0.8867, 0.1133], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 40 - 261: dog - cat || Loss: 1.1996991634368896\n",
      "tensor([0., 1.]) tensor([0.8864, 0.1136], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 40 - 262: dog - cat || Loss: 1.1994316577911377\n",
      "tensor([0., 1.]) tensor([0.8862, 0.1138], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 40 - 263: dog - cat || Loss: 1.199163556098938\n",
      "tensor([0., 1.]) tensor([0.8859, 0.1141], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 40 - 264: dog - cat || Loss: 1.1988948583602905\n",
      "tensor([0., 1.]) tensor([0.8856, 0.1144], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 40 - 265: dog - cat || Loss: 1.1986253261566162\n",
      "tensor([0., 1.]) tensor([0.8854, 0.1146], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 40 - 266: dog - cat || Loss: 1.1983553171157837\n",
      "tensor([0., 1.]) tensor([0.8851, 0.1149], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 40 - 267: dog - cat || Loss: 1.1980845928192139\n",
      "tensor([0., 1.]) tensor([0.8848, 0.1152], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 40 - 268: dog - cat || Loss: 1.1978130340576172\n",
      "tensor([0., 1.]) tensor([0.8846, 0.1154], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 40 - 269: dog - cat || Loss: 1.1975408792495728\n",
      "tensor([0., 1.]) tensor([0.8843, 0.1157], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 40 - 270: dog - cat || Loss: 1.1972682476043701\n",
      "tensor([0., 1.]) tensor([0.8840, 0.1160], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 40 - 271: dog - cat || Loss: 1.1969947814941406\n",
      "tensor([0., 1.]) tensor([0.8837, 0.1163], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 40 - 272: dog - cat || Loss: 1.196720838546753\n",
      "tensor([0., 1.]) tensor([0.8835, 0.1165], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 40 - 273: dog - cat || Loss: 1.1964459419250488\n",
      "tensor([0., 1.]) tensor([0.8832, 0.1168], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 40 - 274: dog - cat || Loss: 1.196170687675476\n",
      "tensor([0., 1.]) tensor([0.8829, 0.1171], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 40 - 275: dog - cat || Loss: 1.195894479751587\n",
      "tensor([0., 1.]) tensor([0.8826, 0.1174], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 40 - 276: dog - cat || Loss: 1.1956177949905396\n",
      "tensor([0., 1.]) tensor([0.8824, 0.1176], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 40 - 277: dog - cat || Loss: 1.1953403949737549\n",
      "tensor([0., 1.]) tensor([0.8821, 0.1179], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 40 - 278: dog - cat || Loss: 1.1950623989105225\n",
      "tensor([0., 1.]) tensor([0.8818, 0.1182], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 40 - 279: dog - cat || Loss: 1.1947835683822632\n",
      "tensor([0., 1.]) tensor([0.8815, 0.1185], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 40 - 280: dog - cat || Loss: 1.1945041418075562\n",
      "tensor([0., 1.]) tensor([0.8812, 0.1188], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 40 - 281: dog - cat || Loss: 1.1942239999771118\n",
      "tensor([0., 1.]) tensor([0.8810, 0.1190], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 40 - 282: dog - cat || Loss: 1.1939433813095093\n",
      "tensor([0., 1.]) tensor([0.8807, 0.1193], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 40 - 283: dog - cat || Loss: 1.1936619281768799\n",
      "tensor([0., 1.]) tensor([0.8804, 0.1196], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 40 - 284: dog - cat || Loss: 1.1933798789978027\n",
      "tensor([0., 1.]) tensor([0.8801, 0.1199], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 40 - 285: dog - cat || Loss: 1.1930971145629883\n",
      "tensor([0., 1.]) tensor([0.8798, 0.1202], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 40 - 286: dog - cat || Loss: 1.192813754081726\n",
      "tensor([0., 1.]) tensor([0.8796, 0.1204], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 40 - 287: dog - cat || Loss: 1.192529559135437\n",
      "tensor([0., 1.]) tensor([0.8793, 0.1207], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 40 - 288: dog - cat || Loss: 1.1922447681427002\n",
      "tensor([0., 1.]) tensor([0.8790, 0.1210], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 40 - 289: dog - cat || Loss: 1.191959261894226\n",
      "tensor([0., 1.]) tensor([0.8787, 0.1213], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 40 - 290: dog - cat || Loss: 1.1916731595993042\n",
      "tensor([0., 1.]) tensor([0.8784, 0.1216], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 40 - 291: dog - cat || Loss: 1.191386342048645\n",
      "tensor([0., 1.]) tensor([0.8781, 0.1219], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 40 - 292: dog - cat || Loss: 1.191098690032959\n",
      "tensor([0., 1.]) tensor([0.8778, 0.1222], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 40 - 293: dog - cat || Loss: 1.1908106803894043\n",
      "tensor([0., 1.]) tensor([0.8775, 0.1225], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 40 - 294: dog - cat || Loss: 1.1905217170715332\n",
      "tensor([0., 1.]) tensor([0.8773, 0.1227], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 40 - 295: dog - cat || Loss: 1.1902321577072144\n",
      "tensor([0., 1.]) tensor([0.8770, 0.1230], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 40 - 296: dog - cat || Loss: 1.1899420022964478\n",
      "tensor([0., 1.]) tensor([0.8767, 0.1233], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 40 - 297: dog - cat || Loss: 1.1896510124206543\n",
      "tensor([0., 1.]) tensor([0.8764, 0.1236], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 40 - 298: dog - cat || Loss: 1.1893595457077026\n",
      "tensor([0., 1.]) tensor([0.8761, 0.1239], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 40 - 299: dog - cat || Loss: 1.1890672445297241\n",
      "tensor([0., 1.]) tensor([0.8758, 0.1242], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 40 - 300: dog - cat || Loss: 1.1887742280960083\n",
      "tensor([0., 1.]) tensor([0.8755, 0.1245], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 40 - 301: dog - cat || Loss: 1.1884804964065552\n",
      "tensor([0., 1.]) tensor([0.8752, 0.1248], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 40 - 302: dog - cat || Loss: 1.1881862878799438\n",
      "tensor([0., 1.]) tensor([0.8749, 0.1251], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 40 - 303: dog - cat || Loss: 1.1878911256790161\n",
      "tensor([0., 1.]) tensor([0.8746, 0.1254], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 40 - 304: dog - cat || Loss: 1.1875953674316406\n",
      "tensor([0., 1.]) tensor([0.8743, 0.1257], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 40 - 305: dog - cat || Loss: 1.1872988939285278\n",
      "tensor([0., 1.]) tensor([0.8740, 0.1260], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 40 - 306: dog - cat || Loss: 1.1870017051696777\n",
      "tensor([0., 1.]) tensor([0.8737, 0.1263], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 40 - 307: dog - cat || Loss: 1.1867039203643799\n",
      "tensor([0., 1.]) tensor([0.8734, 0.1266], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 40 - 308: dog - cat || Loss: 1.1864054203033447\n",
      "tensor([0., 1.]) tensor([0.8731, 0.1269], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 40 - 309: dog - cat || Loss: 1.1861062049865723\n",
      "tensor([0., 1.]) tensor([0.8728, 0.1272], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 40 - 310: dog - cat || Loss: 1.185806155204773\n",
      "tensor([0., 1.]) tensor([0.8725, 0.1275], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 40 - 311: dog - cat || Loss: 1.1855053901672363\n",
      "tensor([0., 1.]) tensor([0.8722, 0.1278], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 40 - 312: dog - cat || Loss: 1.1852041482925415\n",
      "tensor([0., 1.]) tensor([0.8719, 0.1281], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 40 - 313: dog - cat || Loss: 1.1849019527435303\n",
      "tensor([0., 1.]) tensor([0.8716, 0.1284], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 40 - 314: dog - cat || Loss: 1.1845993995666504\n",
      "tensor([0., 1.]) tensor([0.8713, 0.1287], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 40 - 315: dog - cat || Loss: 1.184295892715454\n",
      "tensor([0., 1.]) tensor([0.8710, 0.1290], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 40 - 316: dog - cat || Loss: 1.1839916706085205\n",
      "tensor([0., 1.]) tensor([0.8707, 0.1293], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 40 - 317: dog - cat || Loss: 1.1836868524551392\n",
      "tensor([0., 1.]) tensor([0.8704, 0.1296], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 40 - 318: dog - cat || Loss: 1.1833810806274414\n",
      "tensor([0., 1.]) tensor([0.8701, 0.1299], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 40 - 319: dog - cat || Loss: 1.1830748319625854\n",
      "tensor([0., 1.]) tensor([0.8698, 0.1302], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 40 - 320: dog - cat || Loss: 1.1827678680419922\n",
      "tensor([0., 1.]) tensor([0.8695, 0.1305], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 40 - 321: dog - cat || Loss: 1.1824601888656616\n",
      "tensor([0., 1.]) tensor([0.8692, 0.1308], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 40 - 322: dog - cat || Loss: 1.1821515560150146\n",
      "tensor([0., 1.]) tensor([0.8689, 0.1311], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 40 - 323: dog - cat || Loss: 1.181842565536499\n",
      "tensor([0., 1.]) tensor([0.8686, 0.1314], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 40 - 324: dog - cat || Loss: 1.181532621383667\n",
      "tensor([0., 1.]) tensor([0.8683, 0.1317], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 40 - 325: dog - cat || Loss: 1.1812219619750977\n",
      "tensor([0., 1.]) tensor([0.8680, 0.1320], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 40 - 326: dog - cat || Loss: 1.1809107065200806\n",
      "tensor([0., 1.]) tensor([0.8676, 0.1324], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 40 - 327: dog - cat || Loss: 1.1805987358093262\n",
      "tensor([0., 1.]) tensor([0.8673, 0.1327], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 40 - 328: dog - cat || Loss: 1.180285930633545\n",
      "tensor([0., 1.]) tensor([0.8670, 0.1330], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 40 - 329: dog - cat || Loss: 1.1799722909927368\n",
      "tensor([0., 1.]) tensor([0.8667, 0.1333], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 40 - 330: dog - cat || Loss: 1.1796581745147705\n",
      "tensor([0., 1.]) tensor([0.8664, 0.1336], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 40 - 331: dog - cat || Loss: 1.1793432235717773\n",
      "tensor([0., 1.]) tensor([0.8661, 0.1339], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 40 - 332: dog - cat || Loss: 1.1790274381637573\n",
      "tensor([0., 1.]) tensor([0.8658, 0.1342], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 40 - 333: dog - cat || Loss: 1.1787109375\n",
      "tensor([0., 1.]) tensor([0.8654, 0.1346], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 40 - 334: dog - cat || Loss: 1.178393840789795\n",
      "tensor([0., 1.]) tensor([0.8651, 0.1349], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 40 - 335: dog - cat || Loss: 1.178075909614563\n",
      "tensor([0., 1.]) tensor([0.8648, 0.1352], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 40 - 336: dog - cat || Loss: 1.1777573823928833\n",
      "tensor([0., 1.]) tensor([0.8645, 0.1355], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 40 - 337: dog - cat || Loss: 1.1774380207061768\n",
      "tensor([0., 1.]) tensor([0.8642, 0.1358], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 40 - 338: dog - cat || Loss: 1.1771178245544434\n",
      "tensor([0., 1.]) tensor([0.8639, 0.1361], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 40 - 339: dog - cat || Loss: 1.1767971515655518\n",
      "tensor([0., 1.]) tensor([0.8635, 0.1365], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 40 - 340: dog - cat || Loss: 1.1764754056930542\n",
      "tensor([0., 1.]) tensor([0.8632, 0.1368], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 40 - 341: dog - cat || Loss: 1.1761531829833984\n",
      "tensor([0., 1.]) tensor([0.8629, 0.1371], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 40 - 342: dog - cat || Loss: 1.1758302450180054\n",
      "tensor([0., 1.]) tensor([0.8626, 0.1374], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 40 - 343: dog - cat || Loss: 1.175506353378296\n",
      "tensor([0., 1.]) tensor([0.8622, 0.1378], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 40 - 344: dog - cat || Loss: 1.1751817464828491\n",
      "tensor([0., 1.]) tensor([0.8619, 0.1381], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 40 - 345: dog - cat || Loss: 1.1748563051223755\n",
      "tensor([0., 1.]) tensor([0.8616, 0.1384], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 40 - 346: dog - cat || Loss: 1.1745303869247437\n",
      "tensor([0., 1.]) tensor([0.8613, 0.1387], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 40 - 347: dog - cat || Loss: 1.1742037534713745\n",
      "tensor([0., 1.]) tensor([0.8609, 0.1391], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 40 - 348: dog - cat || Loss: 1.1738760471343994\n",
      "tensor([0., 1.]) tensor([0.8606, 0.1394], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 40 - 349: dog - cat || Loss: 1.1735478639602661\n",
      "tensor([0., 1.]) tensor([0.8603, 0.1397], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 40 - 350: dog - cat || Loss: 1.173218846321106\n",
      "tensor([0., 1.]) tensor([0.8600, 0.1400], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 40 - 351: dog - cat || Loss: 1.172888994216919\n",
      "tensor([0., 1.]) tensor([0.8596, 0.1404], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 40 - 352: dog - cat || Loss: 1.1725585460662842\n",
      "tensor([0., 1.]) tensor([0.8593, 0.1407], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 40 - 353: dog - cat || Loss: 1.172227144241333\n",
      "tensor([0., 1.]) tensor([0.8590, 0.1410], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 40 - 354: dog - cat || Loss: 1.171895146369934\n",
      "tensor([0., 1.]) tensor([0.8586, 0.1414], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 40 - 355: dog - cat || Loss: 1.1715621948242188\n",
      "tensor([0., 1.]) tensor([0.8583, 0.1417], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 40 - 356: dog - cat || Loss: 1.1712288856506348\n",
      "tensor([0., 1.]) tensor([0.8580, 0.1420], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 40 - 357: dog - cat || Loss: 1.1708945035934448\n",
      "tensor([0., 1.]) tensor([0.8576, 0.1424], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 40 - 358: dog - cat || Loss: 1.1705594062805176\n",
      "tensor([0., 1.]) tensor([0.8573, 0.1427], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 40 - 359: dog - cat || Loss: 1.170223593711853\n",
      "tensor([0., 1.]) tensor([0.8570, 0.1430], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 40 - 360: dog - cat || Loss: 1.169886827468872\n",
      "tensor([0., 1.]) tensor([0.8566, 0.1434], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 40 - 361: dog - cat || Loss: 1.169549584388733\n",
      "tensor([0., 1.]) tensor([0.8563, 0.1437], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 40 - 362: dog - cat || Loss: 1.1692113876342773\n",
      "tensor([0., 1.]) tensor([0.8559, 0.1441], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 40 - 363: dog - cat || Loss: 1.168872594833374\n",
      "tensor([0., 1.]) tensor([0.8556, 0.1444], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 40 - 364: dog - cat || Loss: 1.1685328483581543\n",
      "tensor([0., 1.]) tensor([0.8553, 0.1447], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 40 - 365: dog - cat || Loss: 1.1681926250457764\n",
      "tensor([0., 1.]) tensor([0.8549, 0.1451], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 40 - 366: dog - cat || Loss: 1.167851448059082\n",
      "tensor([0., 1.]) tensor([0.8546, 0.1454], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 40 - 367: dog - cat || Loss: 1.1675094366073608\n",
      "tensor([0., 1.]) tensor([0.8542, 0.1458], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 40 - 368: dog - cat || Loss: 1.1671665906906128\n",
      "tensor([0., 1.]) tensor([0.8539, 0.1461], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 40 - 369: dog - cat || Loss: 1.166823148727417\n",
      "tensor([0., 1.]) tensor([0.8536, 0.1464], grad_fn=<SoftmaxBackward0>)\n",
      "=====epoch:41=====\n",
      "Epoch 41 - 0: cat - cat || Loss: 0.4600445032119751\n",
      "tensor([1., 0.]) tensor([0.8532, 0.1468], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 41 - 1: cat - cat || Loss: 0.46031975746154785\n",
      "tensor([1., 0.]) tensor([0.8529, 0.1471], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 41 - 2: cat - cat || Loss: 0.46053290367126465\n",
      "tensor([1., 0.]) tensor([0.8527, 0.1473], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 41 - 3: cat - cat || Loss: 0.4606897234916687\n",
      "tensor([1., 0.]) tensor([0.8526, 0.1474], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 41 - 4: cat - cat || Loss: 0.4607960283756256\n",
      "tensor([1., 0.]) tensor([0.8525, 0.1475], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 41 - 5: cat - cat || Loss: 0.46085667610168457\n",
      "tensor([1., 0.]) tensor([0.8524, 0.1476], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 41 - 6: cat - cat || Loss: 0.4608762860298157\n",
      "tensor([1., 0.]) tensor([0.8524, 0.1476], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 41 - 7: cat - cat || Loss: 0.46085885167121887\n",
      "tensor([1., 0.]) tensor([0.8524, 0.1476], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 41 - 8: cat - cat || Loss: 0.4608082175254822\n",
      "tensor([1., 0.]) tensor([0.8525, 0.1475], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 41 - 9: cat - cat || Loss: 0.4607275724411011\n",
      "tensor([1., 0.]) tensor([0.8525, 0.1475], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 41 - 10: cat - cat || Loss: 0.46062004566192627\n",
      "tensor([1., 0.]) tensor([0.8526, 0.1474], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 41 - 11: cat - cat || Loss: 0.4604884386062622\n",
      "tensor([1., 0.]) tensor([0.8528, 0.1472], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 41 - 12: cat - cat || Loss: 0.46033501625061035\n",
      "tensor([1., 0.]) tensor([0.8529, 0.1471], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 41 - 13: cat - cat || Loss: 0.4601621627807617\n",
      "tensor([1., 0.]) tensor([0.8531, 0.1469], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 41 - 14: cat - cat || Loss: 0.4599718451499939\n",
      "tensor([1., 0.]) tensor([0.8533, 0.1467], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 41 - 15: cat - cat || Loss: 0.45976588129997253\n",
      "tensor([1., 0.]) tensor([0.8535, 0.1465], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 41 - 16: cat - cat || Loss: 0.4595458507537842\n",
      "tensor([1., 0.]) tensor([0.8537, 0.1463], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 41 - 17: cat - cat || Loss: 0.4593132436275482\n",
      "tensor([1., 0.]) tensor([0.8539, 0.1461], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 41 - 18: cat - cat || Loss: 0.45906952023506165\n",
      "tensor([1., 0.]) tensor([0.8542, 0.1458], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 41 - 19: cat - cat || Loss: 0.45881569385528564\n",
      "tensor([1., 0.]) tensor([0.8544, 0.1456], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 41 - 20: cat - cat || Loss: 0.4585527777671814\n",
      "tensor([1., 0.]) tensor([0.8547, 0.1453], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 41 - 21: cat - cat || Loss: 0.4582820236682892\n",
      "tensor([1., 0.]) tensor([0.8550, 0.1450], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 41 - 22: cat - cat || Loss: 0.4580042362213135\n",
      "tensor([1., 0.]) tensor([0.8553, 0.1447], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 41 - 23: cat - cat || Loss: 0.45771998167037964\n",
      "tensor([1., 0.]) tensor([0.8555, 0.1445], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 41 - 24: cat - cat || Loss: 0.4574301242828369\n",
      "tensor([1., 0.]) tensor([0.8558, 0.1442], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 41 - 25: cat - cat || Loss: 0.457135409116745\n",
      "tensor([1., 0.]) tensor([0.8561, 0.1439], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 41 - 26: cat - cat || Loss: 0.4568362236022949\n",
      "tensor([1., 0.]) tensor([0.8564, 0.1436], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 41 - 27: cat - cat || Loss: 0.4565330743789673\n",
      "tensor([1., 0.]) tensor([0.8567, 0.1433], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 41 - 28: cat - cat || Loss: 0.4562266767024994\n",
      "tensor([1., 0.]) tensor([0.8570, 0.1430], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 41 - 29: cat - cat || Loss: 0.4559171199798584\n",
      "tensor([1., 0.]) tensor([0.8573, 0.1427], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 41 - 30: cat - cat || Loss: 0.45560500025749207\n",
      "tensor([1., 0.]) tensor([0.8577, 0.1423], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 41 - 31: cat - cat || Loss: 0.4552905559539795\n",
      "tensor([1., 0.]) tensor([0.8580, 0.1420], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 41 - 32: cat - cat || Loss: 0.4549741744995117\n",
      "tensor([1., 0.]) tensor([0.8583, 0.1417], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 41 - 33: cat - cat || Loss: 0.454656183719635\n",
      "tensor([1., 0.]) tensor([0.8586, 0.1414], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 41 - 34: cat - cat || Loss: 0.45433658361434937\n",
      "tensor([1., 0.]) tensor([0.8589, 0.1411], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 41 - 35: cat - cat || Loss: 0.4540158808231354\n",
      "tensor([1., 0.]) tensor([0.8592, 0.1408], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 41 - 36: cat - cat || Loss: 0.45369404554367065\n",
      "tensor([1., 0.]) tensor([0.8596, 0.1404], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 41 - 37: cat - cat || Loss: 0.45337149500846863\n",
      "tensor([1., 0.]) tensor([0.8599, 0.1401], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 41 - 38: cat - cat || Loss: 0.4530481696128845\n",
      "tensor([1., 0.]) tensor([0.8602, 0.1398], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 41 - 39: cat - cat || Loss: 0.4527243375778198\n",
      "tensor([1., 0.]) tensor([0.8605, 0.1395], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 41 - 40: cat - cat || Loss: 0.45240020751953125\n",
      "tensor([1., 0.]) tensor([0.8609, 0.1391], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 41 - 41: cat - cat || Loss: 0.4520755708217621\n",
      "tensor([1., 0.]) tensor([0.8612, 0.1388], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 41 - 42: cat - cat || Loss: 0.45175087451934814\n",
      "tensor([1., 0.]) tensor([0.8615, 0.1385], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 41 - 43: cat - cat || Loss: 0.4514259696006775\n",
      "tensor([1., 0.]) tensor([0.8618, 0.1382], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 41 - 44: cat - cat || Loss: 0.45110124349594116\n",
      "tensor([1., 0.]) tensor([0.8622, 0.1378], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 41 - 45: cat - cat || Loss: 0.45077642798423767\n",
      "tensor([1., 0.]) tensor([0.8625, 0.1375], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 41 - 46: cat - cat || Loss: 0.45045191049575806\n",
      "tensor([1., 0.]) tensor([0.8628, 0.1372], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 41 - 47: cat - cat || Loss: 0.4501274824142456\n",
      "tensor([1., 0.]) tensor([0.8631, 0.1369], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 41 - 48: cat - cat || Loss: 0.4498033821582794\n",
      "tensor([1., 0.]) tensor([0.8635, 0.1365], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 41 - 49: cat - cat || Loss: 0.4494795799255371\n",
      "tensor([1., 0.]) tensor([0.8638, 0.1362], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 41 - 50: cat - cat || Loss: 0.44915610551834106\n",
      "tensor([1., 0.]) tensor([0.8641, 0.1359], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 41 - 51: cat - cat || Loss: 0.4488331079483032\n",
      "tensor([1., 0.]) tensor([0.8644, 0.1356], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 41 - 52: cat - cat || Loss: 0.44851046800613403\n",
      "tensor([1., 0.]) tensor([0.8648, 0.1352], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 41 - 53: cat - cat || Loss: 0.44818833470344543\n",
      "tensor([1., 0.]) tensor([0.8651, 0.1349], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 41 - 54: cat - cat || Loss: 0.4478667080402374\n",
      "tensor([1., 0.]) tensor([0.8654, 0.1346], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 41 - 55: cat - cat || Loss: 0.44754558801651\n",
      "tensor([1., 0.]) tensor([0.8657, 0.1343], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 41 - 56: cat - cat || Loss: 0.44722503423690796\n",
      "tensor([1., 0.]) tensor([0.8660, 0.1340], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 41 - 57: cat - cat || Loss: 0.4469049572944641\n",
      "tensor([1., 0.]) tensor([0.8664, 0.1336], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 41 - 58: cat - cat || Loss: 0.44658559560775757\n",
      "tensor([1., 0.]) tensor([0.8667, 0.1333], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 41 - 59: cat - cat || Loss: 0.4462668299674988\n",
      "tensor([1., 0.]) tensor([0.8670, 0.1330], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 41 - 60: cat - cat || Loss: 0.44594860076904297\n",
      "tensor([1., 0.]) tensor([0.8673, 0.1327], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 41 - 61: cat - cat || Loss: 0.4456310272216797\n",
      "tensor([1., 0.]) tensor([0.8676, 0.1324], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 41 - 62: cat - cat || Loss: 0.44531404972076416\n",
      "tensor([1., 0.]) tensor([0.8679, 0.1321], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 41 - 63: cat - cat || Loss: 0.4449979066848755\n",
      "tensor([1., 0.]) tensor([0.8683, 0.1317], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 41 - 64: cat - cat || Loss: 0.4446823000907898\n",
      "tensor([1., 0.]) tensor([0.8686, 0.1314], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 41 - 65: cat - cat || Loss: 0.44436728954315186\n",
      "tensor([1., 0.]) tensor([0.8689, 0.1311], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 41 - 66: cat - cat || Loss: 0.4440529942512512\n",
      "tensor([1., 0.]) tensor([0.8692, 0.1308], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 41 - 67: cat - cat || Loss: 0.44373947381973267\n",
      "tensor([1., 0.]) tensor([0.8695, 0.1305], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 41 - 68: cat - cat || Loss: 0.44342654943466187\n",
      "tensor([1., 0.]) tensor([0.8698, 0.1302], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 41 - 69: cat - cat || Loss: 0.44311439990997314\n",
      "tensor([1., 0.]) tensor([0.8701, 0.1299], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 41 - 70: cat - cat || Loss: 0.44280290603637695\n",
      "tensor([1., 0.]) tensor([0.8705, 0.1295], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 41 - 71: cat - cat || Loss: 0.44249212741851807\n",
      "tensor([1., 0.]) tensor([0.8708, 0.1292], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 41 - 72: cat - cat || Loss: 0.4421820044517517\n",
      "tensor([1., 0.]) tensor([0.8711, 0.1289], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 41 - 73: cat - cat || Loss: 0.4418725371360779\n",
      "tensor([1., 0.]) tensor([0.8714, 0.1286], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 41 - 74: cat - cat || Loss: 0.4415638744831085\n",
      "tensor([1., 0.]) tensor([0.8717, 0.1283], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 41 - 75: cat - cat || Loss: 0.44125598669052124\n",
      "tensor([1., 0.]) tensor([0.8720, 0.1280], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 41 - 76: cat - cat || Loss: 0.4409487247467041\n",
      "tensor([1., 0.]) tensor([0.8723, 0.1277], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 41 - 77: cat - cat || Loss: 0.44064217805862427\n",
      "tensor([1., 0.]) tensor([0.8726, 0.1274], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 41 - 78: cat - cat || Loss: 0.44033628702163696\n",
      "tensor([1., 0.]) tensor([0.8729, 0.1271], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 41 - 79: cat - cat || Loss: 0.44003117084503174\n",
      "tensor([1., 0.]) tensor([0.8732, 0.1268], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 41 - 80: cat - cat || Loss: 0.4397268295288086\n",
      "tensor([1., 0.]) tensor([0.8735, 0.1265], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 41 - 81: cat - cat || Loss: 0.4394230842590332\n",
      "tensor([1., 0.]) tensor([0.8738, 0.1262], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 41 - 82: cat - cat || Loss: 0.4391201138496399\n",
      "tensor([1., 0.]) tensor([0.8741, 0.1259], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 41 - 83: cat - cat || Loss: 0.4388178884983063\n",
      "tensor([1., 0.]) tensor([0.8744, 0.1256], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 41 - 84: cat - cat || Loss: 0.43851643800735474\n",
      "tensor([1., 0.]) tensor([0.8747, 0.1253], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 41 - 85: cat - cat || Loss: 0.43821561336517334\n",
      "tensor([1., 0.]) tensor([0.8750, 0.1250], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 41 - 86: cat - cat || Loss: 0.43791550397872925\n",
      "tensor([1., 0.]) tensor([0.8753, 0.1247], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 41 - 87: cat - cat || Loss: 0.43761616945266724\n",
      "tensor([1., 0.]) tensor([0.8756, 0.1244], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 41 - 88: cat - cat || Loss: 0.43731749057769775\n",
      "tensor([1., 0.]) tensor([0.8759, 0.1241], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 41 - 89: cat - cat || Loss: 0.43701958656311035\n",
      "tensor([1., 0.]) tensor([0.8762, 0.1238], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 41 - 90: cat - cat || Loss: 0.4367223381996155\n",
      "tensor([1., 0.]) tensor([0.8765, 0.1235], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 41 - 91: cat - cat || Loss: 0.4364258050918579\n",
      "tensor([1., 0.]) tensor([0.8768, 0.1232], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 41 - 92: cat - cat || Loss: 0.4361300766468048\n",
      "tensor([1., 0.]) tensor([0.8771, 0.1229], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 41 - 93: cat - cat || Loss: 0.43583494424819946\n",
      "tensor([1., 0.]) tensor([0.8774, 0.1226], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 41 - 94: cat - cat || Loss: 0.4355405569076538\n",
      "tensor([1., 0.]) tensor([0.8777, 0.1223], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 41 - 95: cat - cat || Loss: 0.43524688482284546\n",
      "tensor([1., 0.]) tensor([0.8780, 0.1220], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 41 - 96: cat - cat || Loss: 0.4349539875984192\n",
      "tensor([1., 0.]) tensor([0.8783, 0.1217], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 41 - 97: cat - cat || Loss: 0.43466174602508545\n",
      "tensor([1., 0.]) tensor([0.8786, 0.1214], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 41 - 98: cat - cat || Loss: 0.43437016010284424\n",
      "tensor([1., 0.]) tensor([0.8789, 0.1211], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 41 - 99: cat - cat || Loss: 0.4340794086456299\n",
      "tensor([1., 0.]) tensor([0.8792, 0.1208], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 41 - 100: cat - cat || Loss: 0.43378931283950806\n",
      "tensor([1., 0.]) tensor([0.8795, 0.1205], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 41 - 101: cat - cat || Loss: 0.43349987268447876\n",
      "tensor([1., 0.]) tensor([0.8798, 0.1202], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 41 - 102: cat - cat || Loss: 0.43321120738983154\n",
      "tensor([1., 0.]) tensor([0.8801, 0.1199], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 41 - 103: cat - cat || Loss: 0.4329231381416321\n",
      "tensor([1., 0.]) tensor([0.8803, 0.1197], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 41 - 104: cat - cat || Loss: 0.4326359033584595\n",
      "tensor([1., 0.]) tensor([0.8806, 0.1194], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 41 - 105: cat - cat || Loss: 0.432349294424057\n",
      "tensor([1., 0.]) tensor([0.8809, 0.1191], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 41 - 106: cat - cat || Loss: 0.43206337094306946\n",
      "tensor([1., 0.]) tensor([0.8812, 0.1188], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 41 - 107: cat - cat || Loss: 0.4317781925201416\n",
      "tensor([1., 0.]) tensor([0.8815, 0.1185], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 41 - 108: cat - cat || Loss: 0.43149372935295105\n",
      "tensor([1., 0.]) tensor([0.8818, 0.1182], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 41 - 109: cat - cat || Loss: 0.431209921836853\n",
      "tensor([1., 0.]) tensor([0.8821, 0.1179], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 41 - 110: cat - cat || Loss: 0.4309267997741699\n",
      "tensor([1., 0.]) tensor([0.8823, 0.1177], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 41 - 111: cat - cat || Loss: 0.4306444525718689\n",
      "tensor([1., 0.]) tensor([0.8826, 0.1174], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 41 - 112: cat - cat || Loss: 0.4303625822067261\n",
      "tensor([1., 0.]) tensor([0.8829, 0.1171], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 41 - 113: cat - cat || Loss: 0.4300816059112549\n",
      "tensor([1., 0.]) tensor([0.8832, 0.1168], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 41 - 114: cat - cat || Loss: 0.4298012852668762\n",
      "tensor([1., 0.]) tensor([0.8835, 0.1165], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 41 - 115: cat - cat || Loss: 0.4295215904712677\n",
      "tensor([1., 0.]) tensor([0.8837, 0.1163], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 41 - 116: cat - cat || Loss: 0.4292426109313965\n",
      "tensor([1., 0.]) tensor([0.8840, 0.1160], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 41 - 117: cat - cat || Loss: 0.42896437644958496\n",
      "tensor([1., 0.]) tensor([0.8843, 0.1157], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 41 - 118: cat - cat || Loss: 0.4286867678165436\n",
      "tensor([1., 0.]) tensor([0.8846, 0.1154], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 41 - 119: cat - cat || Loss: 0.4284099340438843\n",
      "tensor([1., 0.]) tensor([0.8849, 0.1151], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 41 - 120: cat - cat || Loss: 0.42813360691070557\n",
      "tensor([1., 0.]) tensor([0.8851, 0.1149], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 41 - 121: cat - cat || Loss: 0.42785805463790894\n",
      "tensor([1., 0.]) tensor([0.8854, 0.1146], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 41 - 122: cat - cat || Loss: 0.4275832176208496\n",
      "tensor([1., 0.]) tensor([0.8857, 0.1143], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 41 - 123: cat - cat || Loss: 0.4273090958595276\n",
      "tensor([1., 0.]) tensor([0.8860, 0.1140], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 41 - 124: cat - cat || Loss: 0.42703554034233093\n",
      "tensor([1., 0.]) tensor([0.8862, 0.1138], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 41 - 125: cat - cat || Loss: 0.42676281929016113\n",
      "tensor([1., 0.]) tensor([0.8865, 0.1135], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 41 - 126: cat - cat || Loss: 0.4264906346797943\n",
      "tensor([1., 0.]) tensor([0.8868, 0.1132], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 41 - 127: cat - cat || Loss: 0.42621910572052\n",
      "tensor([1., 0.]) tensor([0.8870, 0.1130], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 41 - 128: cat - cat || Loss: 0.4259483516216278\n",
      "tensor([1., 0.]) tensor([0.8873, 0.1127], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 41 - 129: cat - cat || Loss: 0.42567816376686096\n",
      "tensor([1., 0.]) tensor([0.8876, 0.1124], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 41 - 130: cat - cat || Loss: 0.4254087507724762\n",
      "tensor([1., 0.]) tensor([0.8879, 0.1121], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 41 - 131: cat - cat || Loss: 0.4251399040222168\n",
      "tensor([1., 0.]) tensor([0.8881, 0.1119], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 41 - 132: cat - cat || Loss: 0.4248717427253723\n",
      "tensor([1., 0.]) tensor([0.8884, 0.1116], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 41 - 133: cat - cat || Loss: 0.4246043562889099\n",
      "tensor([1., 0.]) tensor([0.8887, 0.1113], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 41 - 134: cat - cat || Loss: 0.4243374466896057\n",
      "tensor([1., 0.]) tensor([0.8889, 0.1111], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 41 - 135: cat - cat || Loss: 0.42407137155532837\n",
      "tensor([1., 0.]) tensor([0.8892, 0.1108], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 41 - 136: cat - cat || Loss: 0.42380592226982117\n",
      "tensor([1., 0.]) tensor([0.8895, 0.1105], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 41 - 137: cat - cat || Loss: 0.42354100942611694\n",
      "tensor([1., 0.]) tensor([0.8897, 0.1103], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 41 - 138: cat - cat || Loss: 0.4232769012451172\n",
      "tensor([1., 0.]) tensor([0.8900, 0.1100], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 41 - 139: cat - cat || Loss: 0.4230133593082428\n",
      "tensor([1., 0.]) tensor([0.8902, 0.1098], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 41 - 140: cat - cat || Loss: 0.4227505326271057\n",
      "tensor([1., 0.]) tensor([0.8905, 0.1095], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 41 - 141: cat - cat || Loss: 0.4224883019924164\n",
      "tensor([1., 0.]) tensor([0.8908, 0.1092], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 41 - 142: cat - cat || Loss: 0.42222675681114197\n",
      "tensor([1., 0.]) tensor([0.8910, 0.1090], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 41 - 143: cat - cat || Loss: 0.4219657778739929\n",
      "tensor([1., 0.]) tensor([0.8913, 0.1087], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 41 - 144: cat - cat || Loss: 0.42170557379722595\n",
      "tensor([1., 0.]) tensor([0.8916, 0.1084], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 41 - 145: cat - cat || Loss: 0.42144596576690674\n",
      "tensor([1., 0.]) tensor([0.8918, 0.1082], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 41 - 146: cat - cat || Loss: 0.42118707299232483\n",
      "tensor([1., 0.]) tensor([0.8921, 0.1079], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 41 - 147: cat - cat || Loss: 0.4209287166595459\n",
      "tensor([1., 0.]) tensor([0.8923, 0.1077], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 41 - 148: cat - cat || Loss: 0.4206710457801819\n",
      "tensor([1., 0.]) tensor([0.8926, 0.1074], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 41 - 149: cat - cat || Loss: 0.4204140901565552\n",
      "tensor([1., 0.]) tensor([0.8928, 0.1072], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 41 - 150: cat - cat || Loss: 0.4201575517654419\n",
      "tensor([1., 0.]) tensor([0.8931, 0.1069], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 41 - 151: cat - cat || Loss: 0.41990190744400024\n",
      "tensor([1., 0.]) tensor([0.8934, 0.1066], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 41 - 152: cat - cat || Loss: 0.4196467995643616\n",
      "tensor([1., 0.]) tensor([0.8936, 0.1064], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 41 - 153: cat - cat || Loss: 0.41939228773117065\n",
      "tensor([1., 0.]) tensor([0.8939, 0.1061], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 41 - 154: cat - cat || Loss: 0.41913843154907227\n",
      "tensor([1., 0.]) tensor([0.8941, 0.1059], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 41 - 155: cat - cat || Loss: 0.4188852310180664\n",
      "tensor([1., 0.]) tensor([0.8944, 0.1056], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 41 - 156: cat - cat || Loss: 0.4186326861381531\n",
      "tensor([1., 0.]) tensor([0.8946, 0.1054], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 41 - 157: cat - cat || Loss: 0.41838082671165466\n",
      "tensor([1., 0.]) tensor([0.8949, 0.1051], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 41 - 158: cat - cat || Loss: 0.41812947392463684\n",
      "tensor([1., 0.]) tensor([0.8951, 0.1049], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 41 - 159: cat - cat || Loss: 0.41787880659103394\n",
      "tensor([1., 0.]) tensor([0.8954, 0.1046], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 41 - 160: cat - cat || Loss: 0.41762879490852356\n",
      "tensor([1., 0.]) tensor([0.8956, 0.1044], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 41 - 161: cat - cat || Loss: 0.41737937927246094\n",
      "tensor([1., 0.]) tensor([0.8959, 0.1041], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 41 - 162: cat - cat || Loss: 0.41713064908981323\n",
      "tensor([1., 0.]) tensor([0.8961, 0.1039], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 41 - 163: cat - cat || Loss: 0.4168824553489685\n",
      "tensor([1., 0.]) tensor([0.8964, 0.1036], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 41 - 164: cat - cat || Loss: 0.41663503646850586\n",
      "tensor([1., 0.]) tensor([0.8966, 0.1034], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 41 - 165: cat - cat || Loss: 0.41638806462287903\n",
      "tensor([1., 0.]) tensor([0.8969, 0.1031], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 41 - 166: cat - cat || Loss: 0.4161417484283447\n",
      "tensor([1., 0.]) tensor([0.8971, 0.1029], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 41 - 167: cat - cat || Loss: 0.41589611768722534\n",
      "tensor([1., 0.]) tensor([0.8974, 0.1026], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 41 - 168: cat - cat || Loss: 0.4156511425971985\n",
      "tensor([1., 0.]) tensor([0.8976, 0.1024], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 41 - 169: cat - cat || Loss: 0.41540661454200745\n",
      "tensor([1., 0.]) tensor([0.8979, 0.1021], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 41 - 170: cat - cat || Loss: 0.4151628017425537\n",
      "tensor([1., 0.]) tensor([0.8981, 0.1019], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 41 - 171: cat - cat || Loss: 0.4149196147918701\n",
      "tensor([1., 0.]) tensor([0.8983, 0.1017], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 41 - 172: cat - cat || Loss: 0.4146769046783447\n",
      "tensor([1., 0.]) tensor([0.8986, 0.1014], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 41 - 173: cat - cat || Loss: 0.4144350290298462\n",
      "tensor([1., 0.]) tensor([0.8988, 0.1012], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 41 - 174: cat - cat || Loss: 0.4141935706138611\n",
      "tensor([1., 0.]) tensor([0.8991, 0.1009], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 41 - 175: cat - cat || Loss: 0.4139528274536133\n",
      "tensor([1., 0.]) tensor([0.8993, 0.1007], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 41 - 176: cat - cat || Loss: 0.41371262073516846\n",
      "tensor([1., 0.]) tensor([0.8995, 0.1005], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 41 - 177: cat - cat || Loss: 0.4134731888771057\n",
      "tensor([1., 0.]) tensor([0.8998, 0.1002], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 41 - 178: cat - cat || Loss: 0.4132341742515564\n",
      "tensor([1., 0.]) tensor([0.9000, 0.1000], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 41 - 179: cat - cat || Loss: 0.4129958748817444\n",
      "tensor([1., 0.]) tensor([0.9003, 0.0997], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 41 - 180: cat - cat || Loss: 0.41275811195373535\n",
      "tensor([1., 0.]) tensor([0.9005, 0.0995], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 41 - 181: cat - cat || Loss: 0.4125209450721741\n",
      "tensor([1., 0.]) tensor([0.9007, 0.0993], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 41 - 182: cat - cat || Loss: 0.4122844338417053\n",
      "tensor([1., 0.]) tensor([0.9010, 0.0990], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 41 - 183: cat - cat || Loss: 0.4120485186576843\n",
      "tensor([1., 0.]) tensor([0.9012, 0.0988], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 41 - 184: cat - cat || Loss: 0.41181308031082153\n",
      "tensor([1., 0.]) tensor([0.9014, 0.0986], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 41 - 185: cat - cat || Loss: 0.41157835721969604\n",
      "tensor([1., 0.]) tensor([0.9017, 0.0983], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 41 - 186: cat - cat || Loss: 0.41134411096572876\n",
      "tensor([1., 0.]) tensor([0.9019, 0.0981], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 41 - 187: cat - cat || Loss: 0.41111046075820923\n",
      "tensor([1., 0.]) tensor([0.9022, 0.0978], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 41 - 188: cat - cat || Loss: 0.41087740659713745\n",
      "tensor([1., 0.]) tensor([0.9024, 0.0976], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 41 - 189: cat - cat || Loss: 0.4106448292732239\n",
      "tensor([1., 0.]) tensor([0.9026, 0.0974], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 41 - 190: dog - cat || Loss: 1.2161104679107666\n",
      "tensor([0., 1.]) tensor([0.9028, 0.0972], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 41 - 191: dog - cat || Loss: 1.2162961959838867\n",
      "tensor([0., 1.]) tensor([0.9030, 0.0970], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 41 - 192: dog - cat || Loss: 1.2164400815963745\n",
      "tensor([0., 1.]) tensor([0.9032, 0.0968], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 41 - 193: dog - cat || Loss: 1.216546893119812\n",
      "tensor([0., 1.]) tensor([0.9033, 0.0967], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 41 - 194: dog - cat || Loss: 1.2166200876235962\n",
      "tensor([0., 1.]) tensor([0.9034, 0.0966], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 41 - 195: dog - cat || Loss: 1.216663122177124\n",
      "tensor([0., 1.]) tensor([0.9034, 0.0966], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 41 - 196: dog - cat || Loss: 1.2166790962219238\n",
      "tensor([0., 1.]) tensor([0.9034, 0.0966], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 41 - 197: dog - cat || Loss: 1.2166706323623657\n",
      "tensor([0., 1.]) tensor([0.9034, 0.0966], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 41 - 198: dog - cat || Loss: 1.2166403532028198\n",
      "tensor([0., 1.]) tensor([0.9034, 0.0966], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 41 - 199: dog - cat || Loss: 1.2165902853012085\n",
      "tensor([0., 1.]) tensor([0.9033, 0.0967], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 41 - 200: dog - cat || Loss: 1.2165223360061646\n",
      "tensor([0., 1.]) tensor([0.9033, 0.0967], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 41 - 201: dog - cat || Loss: 1.2164382934570312\n",
      "tensor([0., 1.]) tensor([0.9032, 0.0968], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 41 - 202: dog - cat || Loss: 1.2163399457931519\n",
      "tensor([0., 1.]) tensor([0.9031, 0.0969], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 41 - 203: dog - cat || Loss: 1.2162284851074219\n",
      "tensor([0., 1.]) tensor([0.9030, 0.0970], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 41 - 204: dog - cat || Loss: 1.216105341911316\n",
      "tensor([0., 1.]) tensor([0.9028, 0.0972], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 41 - 205: dog - cat || Loss: 1.2159713506698608\n",
      "tensor([0., 1.]) tensor([0.9027, 0.0973], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 41 - 206: dog - cat || Loss: 1.2158278226852417\n",
      "tensor([0., 1.]) tensor([0.9026, 0.0974], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 41 - 207: dog - cat || Loss: 1.2156758308410645\n",
      "tensor([0., 1.]) tensor([0.9024, 0.0976], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 41 - 208: dog - cat || Loss: 1.2155154943466187\n",
      "tensor([0., 1.]) tensor([0.9023, 0.0977], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 41 - 209: dog - cat || Loss: 1.215348243713379\n",
      "tensor([0., 1.]) tensor([0.9021, 0.0979], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 41 - 210: dog - cat || Loss: 1.215174674987793\n",
      "tensor([0., 1.]) tensor([0.9019, 0.0981], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 41 - 211: dog - cat || Loss: 1.2149951457977295\n",
      "tensor([0., 1.]) tensor([0.9017, 0.0983], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 41 - 212: dog - cat || Loss: 1.2148101329803467\n",
      "tensor([0., 1.]) tensor([0.9015, 0.0985], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 41 - 213: dog - cat || Loss: 1.2146203517913818\n",
      "tensor([0., 1.]) tensor([0.9014, 0.0986], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 41 - 214: dog - cat || Loss: 1.214426040649414\n",
      "tensor([0., 1.]) tensor([0.9012, 0.0988], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 41 - 215: dog - cat || Loss: 1.2142276763916016\n",
      "tensor([0., 1.]) tensor([0.9010, 0.0990], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 41 - 216: dog - cat || Loss: 1.214025616645813\n",
      "tensor([0., 1.]) tensor([0.9008, 0.0992], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 41 - 217: dog - cat || Loss: 1.213820219039917\n",
      "tensor([0., 1.]) tensor([0.9006, 0.0994], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 41 - 218: dog - cat || Loss: 1.2136116027832031\n",
      "tensor([0., 1.]) tensor([0.9004, 0.0996], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 41 - 219: dog - cat || Loss: 1.2134002447128296\n",
      "tensor([0., 1.]) tensor([0.9001, 0.0999], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 41 - 220: dog - cat || Loss: 1.213186264038086\n",
      "tensor([0., 1.]) tensor([0.8999, 0.1001], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 41 - 221: dog - cat || Loss: 1.2129698991775513\n",
      "tensor([0., 1.]) tensor([0.8997, 0.1003], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 41 - 222: dog - cat || Loss: 1.2127511501312256\n",
      "tensor([0., 1.]) tensor([0.8995, 0.1005], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 41 - 223: dog - cat || Loss: 1.212530255317688\n",
      "tensor([0., 1.]) tensor([0.8993, 0.1007], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 41 - 224: dog - cat || Loss: 1.2123076915740967\n",
      "tensor([0., 1.]) tensor([0.8990, 0.1010], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 41 - 225: dog - cat || Loss: 1.212083339691162\n",
      "tensor([0., 1.]) tensor([0.8988, 0.1012], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 41 - 226: dog - cat || Loss: 1.2118573188781738\n",
      "tensor([0., 1.]) tensor([0.8986, 0.1014], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 41 - 227: dog - cat || Loss: 1.2116296291351318\n",
      "tensor([0., 1.]) tensor([0.8984, 0.1016], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 41 - 228: dog - cat || Loss: 1.2114003896713257\n",
      "tensor([0., 1.]) tensor([0.8981, 0.1019], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 41 - 229: dog - cat || Loss: 1.211169958114624\n",
      "tensor([0., 1.]) tensor([0.8979, 0.1021], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 41 - 230: dog - cat || Loss: 1.2109380960464478\n",
      "tensor([0., 1.]) tensor([0.8977, 0.1023], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 41 - 231: dog - cat || Loss: 1.210705041885376\n",
      "tensor([0., 1.]) tensor([0.8974, 0.1026], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 41 - 232: dog - cat || Loss: 1.2104710340499878\n",
      "tensor([0., 1.]) tensor([0.8972, 0.1028], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 41 - 233: dog - cat || Loss: 1.210235595703125\n",
      "tensor([0., 1.]) tensor([0.8970, 0.1030], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 41 - 234: dog - cat || Loss: 1.2099993228912354\n",
      "tensor([0., 1.]) tensor([0.8967, 0.1033], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 41 - 235: dog - cat || Loss: 1.2097618579864502\n",
      "tensor([0., 1.]) tensor([0.8965, 0.1035], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 41 - 236: dog - cat || Loss: 1.2095234394073486\n",
      "tensor([0., 1.]) tensor([0.8963, 0.1037], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 41 - 237: dog - cat || Loss: 1.2092843055725098\n",
      "tensor([0., 1.]) tensor([0.8960, 0.1040], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 41 - 238: dog - cat || Loss: 1.2090442180633545\n",
      "tensor([0., 1.]) tensor([0.8958, 0.1042], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 41 - 239: dog - cat || Loss: 1.2088030576705933\n",
      "tensor([0., 1.]) tensor([0.8955, 0.1045], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 41 - 240: dog - cat || Loss: 1.2085613012313843\n",
      "tensor([0., 1.]) tensor([0.8953, 0.1047], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 41 - 241: dog - cat || Loss: 1.2083184719085693\n",
      "tensor([0., 1.]) tensor([0.8951, 0.1049], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 41 - 242: dog - cat || Loss: 1.2080750465393066\n",
      "tensor([0., 1.]) tensor([0.8948, 0.1052], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 41 - 243: dog - cat || Loss: 1.2078306674957275\n",
      "tensor([0., 1.]) tensor([0.8946, 0.1054], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 41 - 244: dog - cat || Loss: 1.2075856924057007\n",
      "tensor([0., 1.]) tensor([0.8943, 0.1057], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 41 - 245: dog - cat || Loss: 1.2073400020599365\n",
      "tensor([0., 1.]) tensor([0.8941, 0.1059], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 41 - 246: dog - cat || Loss: 1.2070934772491455\n",
      "tensor([0., 1.]) tensor([0.8938, 0.1062], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 41 - 247: dog - cat || Loss: 1.2068462371826172\n",
      "tensor([0., 1.]) tensor([0.8936, 0.1064], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 41 - 248: dog - cat || Loss: 1.2065982818603516\n",
      "tensor([0., 1.]) tensor([0.8933, 0.1067], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 41 - 249: dog - cat || Loss: 1.206349492073059\n",
      "tensor([0., 1.]) tensor([0.8931, 0.1069], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 41 - 250: dog - cat || Loss: 1.2061002254486084\n",
      "tensor([0., 1.]) tensor([0.8928, 0.1072], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 41 - 251: dog - cat || Loss: 1.2058502435684204\n",
      "tensor([0., 1.]) tensor([0.8926, 0.1074], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 41 - 252: dog - cat || Loss: 1.2055994272232056\n",
      "tensor([0., 1.]) tensor([0.8923, 0.1077], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 41 - 253: dog - cat || Loss: 1.205348014831543\n",
      "tensor([0., 1.]) tensor([0.8921, 0.1079], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 41 - 254: dog - cat || Loss: 1.205095887184143\n",
      "tensor([0., 1.]) tensor([0.8918, 0.1082], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 41 - 255: dog - cat || Loss: 1.2048431634902954\n",
      "tensor([0., 1.]) tensor([0.8916, 0.1084], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 41 - 256: dog - cat || Loss: 1.2045897245407104\n",
      "tensor([0., 1.]) tensor([0.8913, 0.1087], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 41 - 257: dog - cat || Loss: 1.2043356895446777\n",
      "tensor([0., 1.]) tensor([0.8911, 0.1089], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 41 - 258: dog - cat || Loss: 1.2040809392929077\n",
      "tensor([0., 1.]) tensor([0.8908, 0.1092], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 41 - 259: dog - cat || Loss: 1.20382559299469\n",
      "tensor([0., 1.]) tensor([0.8906, 0.1094], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 41 - 260: dog - cat || Loss: 1.2035694122314453\n",
      "tensor([0., 1.]) tensor([0.8903, 0.1097], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 41 - 261: dog - cat || Loss: 1.203312873840332\n",
      "tensor([0., 1.]) tensor([0.8901, 0.1099], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 41 - 262: dog - cat || Loss: 1.203055739402771\n",
      "tensor([0., 1.]) tensor([0.8898, 0.1102], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 41 - 263: dog - cat || Loss: 1.2027976512908936\n",
      "tensor([0., 1.]) tensor([0.8895, 0.1105], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 41 - 264: dog - cat || Loss: 1.2025389671325684\n",
      "tensor([0., 1.]) tensor([0.8893, 0.1107], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 41 - 265: dog - cat || Loss: 1.2022796869277954\n",
      "tensor([0., 1.]) tensor([0.8890, 0.1110], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 41 - 266: dog - cat || Loss: 1.2020198106765747\n",
      "tensor([0., 1.]) tensor([0.8888, 0.1112], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 41 - 267: dog - cat || Loss: 1.2017594575881958\n",
      "tensor([0., 1.]) tensor([0.8885, 0.1115], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 41 - 268: dog - cat || Loss: 1.201498031616211\n",
      "tensor([0., 1.]) tensor([0.8882, 0.1118], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 41 - 269: dog - cat || Loss: 1.2012362480163574\n",
      "tensor([0., 1.]) tensor([0.8880, 0.1120], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 41 - 270: dog - cat || Loss: 1.2009737491607666\n",
      "tensor([0., 1.]) tensor([0.8877, 0.1123], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 41 - 271: dog - cat || Loss: 1.2007107734680176\n",
      "tensor([0., 1.]) tensor([0.8874, 0.1126], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 41 - 272: dog - cat || Loss: 1.2004469633102417\n",
      "tensor([0., 1.]) tensor([0.8872, 0.1128], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 41 - 273: dog - cat || Loss: 1.2001826763153076\n",
      "tensor([0., 1.]) tensor([0.8869, 0.1131], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 41 - 274: dog - cat || Loss: 1.1999175548553467\n",
      "tensor([0., 1.]) tensor([0.8867, 0.1133], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 41 - 275: dog - cat || Loss: 1.199651837348938\n",
      "tensor([0., 1.]) tensor([0.8864, 0.1136], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 41 - 276: dog - cat || Loss: 1.1993855237960815\n",
      "tensor([0., 1.]) tensor([0.8861, 0.1139], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 41 - 277: dog - cat || Loss: 1.1991186141967773\n",
      "tensor([0., 1.]) tensor([0.8859, 0.1141], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 41 - 278: dog - cat || Loss: 1.1988509893417358\n",
      "tensor([0., 1.]) tensor([0.8856, 0.1144], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 41 - 279: dog - cat || Loss: 1.198582649230957\n",
      "tensor([0., 1.]) tensor([0.8853, 0.1147], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 41 - 280: dog - cat || Loss: 1.1983137130737305\n",
      "tensor([0., 1.]) tensor([0.8851, 0.1149], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 41 - 281: dog - cat || Loss: 1.1980441808700562\n",
      "tensor([0., 1.]) tensor([0.8848, 0.1152], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 41 - 282: dog - cat || Loss: 1.197774052619934\n",
      "tensor([0., 1.]) tensor([0.8845, 0.1155], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 41 - 283: dog - cat || Loss: 1.1975030899047852\n",
      "tensor([0., 1.]) tensor([0.8842, 0.1158], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 41 - 284: dog - cat || Loss: 1.1972315311431885\n",
      "tensor([0., 1.]) tensor([0.8840, 0.1160], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 41 - 285: dog - cat || Loss: 1.196959376335144\n",
      "tensor([0., 1.]) tensor([0.8837, 0.1163], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 41 - 286: dog - cat || Loss: 1.1966866254806519\n",
      "tensor([0., 1.]) tensor([0.8834, 0.1166], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 41 - 287: dog - cat || Loss: 1.1964131593704224\n",
      "tensor([0., 1.]) tensor([0.8832, 0.1168], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 41 - 288: dog - cat || Loss: 1.1961389780044556\n",
      "tensor([0., 1.]) tensor([0.8829, 0.1171], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 41 - 289: dog - cat || Loss: 1.195864200592041\n",
      "tensor([0., 1.]) tensor([0.8826, 0.1174], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 41 - 290: dog - cat || Loss: 1.1955887079238892\n",
      "tensor([0., 1.]) tensor([0.8823, 0.1177], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 41 - 291: dog - cat || Loss: 1.195312738418579\n",
      "tensor([0., 1.]) tensor([0.8821, 0.1179], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 41 - 292: dog - cat || Loss: 1.1950358152389526\n",
      "tensor([0., 1.]) tensor([0.8818, 0.1182], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 41 - 293: dog - cat || Loss: 1.194758415222168\n",
      "tensor([0., 1.]) tensor([0.8815, 0.1185], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 41 - 294: dog - cat || Loss: 1.194480299949646\n",
      "tensor([0., 1.]) tensor([0.8812, 0.1188], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 41 - 295: dog - cat || Loss: 1.1942015886306763\n",
      "tensor([0., 1.]) tensor([0.8809, 0.1191], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 41 - 296: dog - cat || Loss: 1.1939222812652588\n",
      "tensor([0., 1.]) tensor([0.8807, 0.1193], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 41 - 297: dog - cat || Loss: 1.193642258644104\n",
      "tensor([0., 1.]) tensor([0.8804, 0.1196], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 41 - 298: dog - cat || Loss: 1.1933614015579224\n",
      "tensor([0., 1.]) tensor([0.8801, 0.1199], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 41 - 299: dog - cat || Loss: 1.1930800676345825\n",
      "tensor([0., 1.]) tensor([0.8798, 0.1202], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 41 - 300: dog - cat || Loss: 1.1927980184555054\n",
      "tensor([0., 1.]) tensor([0.8795, 0.1205], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 41 - 301: dog - cat || Loss: 1.1925151348114014\n",
      "tensor([0., 1.]) tensor([0.8793, 0.1207], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 41 - 302: dog - cat || Loss: 1.1922318935394287\n",
      "tensor([0., 1.]) tensor([0.8790, 0.1210], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 41 - 303: dog - cat || Loss: 1.1919476985931396\n",
      "tensor([0., 1.]) tensor([0.8787, 0.1213], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 41 - 304: dog - cat || Loss: 1.1916629076004028\n",
      "tensor([0., 1.]) tensor([0.8784, 0.1216], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 41 - 305: dog - cat || Loss: 1.1913775205612183\n",
      "tensor([0., 1.]) tensor([0.8781, 0.1219], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 41 - 306: dog - cat || Loss: 1.1910914182662964\n",
      "tensor([0., 1.]) tensor([0.8778, 0.1222], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 41 - 307: dog - cat || Loss: 1.1908046007156372\n",
      "tensor([0., 1.]) tensor([0.8775, 0.1225], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 41 - 308: dog - cat || Loss: 1.1905170679092407\n",
      "tensor([0., 1.]) tensor([0.8773, 0.1227], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 41 - 309: dog - cat || Loss: 1.190229058265686\n",
      "tensor([0., 1.]) tensor([0.8770, 0.1230], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 41 - 310: dog - cat || Loss: 1.1899402141571045\n",
      "tensor([0., 1.]) tensor([0.8767, 0.1233], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 41 - 311: dog - cat || Loss: 1.1896506547927856\n",
      "tensor([0., 1.]) tensor([0.8764, 0.1236], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 41 - 312: dog - cat || Loss: 1.189360499382019\n",
      "tensor([0., 1.]) tensor([0.8761, 0.1239], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 41 - 313: dog - cat || Loss: 1.1890695095062256\n",
      "tensor([0., 1.]) tensor([0.8758, 0.1242], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 41 - 314: dog - cat || Loss: 1.1887779235839844\n",
      "tensor([0., 1.]) tensor([0.8755, 0.1245], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 41 - 315: dog - cat || Loss: 1.1884857416152954\n",
      "tensor([0., 1.]) tensor([0.8752, 0.1248], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 41 - 316: dog - cat || Loss: 1.1881927251815796\n",
      "tensor([0., 1.]) tensor([0.8749, 0.1251], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 41 - 317: dog - cat || Loss: 1.187899112701416\n",
      "tensor([0., 1.]) tensor([0.8746, 0.1254], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 41 - 318: dog - cat || Loss: 1.1876047849655151\n",
      "tensor([0., 1.]) tensor([0.8743, 0.1257], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 41 - 319: dog - cat || Loss: 1.1873096227645874\n",
      "tensor([0., 1.]) tensor([0.8740, 0.1260], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 41 - 320: dog - cat || Loss: 1.1870139837265015\n",
      "tensor([0., 1.]) tensor([0.8738, 0.1262], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 41 - 321: dog - cat || Loss: 1.1867175102233887\n",
      "tensor([0., 1.]) tensor([0.8735, 0.1265], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 41 - 322: dog - cat || Loss: 1.1864204406738281\n",
      "tensor([0., 1.]) tensor([0.8732, 0.1268], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 41 - 323: dog - cat || Loss: 1.1861227750778198\n",
      "tensor([0., 1.]) tensor([0.8729, 0.1271], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 41 - 324: dog - cat || Loss: 1.1858242750167847\n",
      "tensor([0., 1.]) tensor([0.8726, 0.1274], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 41 - 325: dog - cat || Loss: 1.1855249404907227\n",
      "tensor([0., 1.]) tensor([0.8723, 0.1277], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 41 - 326: dog - cat || Loss: 1.185225009918213\n",
      "tensor([0., 1.]) tensor([0.8720, 0.1280], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 41 - 327: dog - cat || Loss: 1.1849243640899658\n",
      "tensor([0., 1.]) tensor([0.8717, 0.1283], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 41 - 328: dog - cat || Loss: 1.1846230030059814\n",
      "tensor([0., 1.]) tensor([0.8714, 0.1286], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 41 - 329: dog - cat || Loss: 1.1843212842941284\n",
      "tensor([0., 1.]) tensor([0.8711, 0.1289], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 41 - 330: dog - cat || Loss: 1.1840183734893799\n",
      "tensor([0., 1.]) tensor([0.8708, 0.1292], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 41 - 331: dog - cat || Loss: 1.1837149858474731\n",
      "tensor([0., 1.]) tensor([0.8705, 0.1295], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 41 - 332: dog - cat || Loss: 1.183410882949829\n",
      "tensor([0., 1.]) tensor([0.8701, 0.1299], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 41 - 333: dog - cat || Loss: 1.1831059455871582\n",
      "tensor([0., 1.]) tensor([0.8698, 0.1302], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 41 - 334: dog - cat || Loss: 1.1828004121780396\n",
      "tensor([0., 1.]) tensor([0.8695, 0.1305], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 41 - 335: dog - cat || Loss: 1.1824941635131836\n",
      "tensor([0., 1.]) tensor([0.8692, 0.1308], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 41 - 336: dog - cat || Loss: 1.1821870803833008\n",
      "tensor([0., 1.]) tensor([0.8689, 0.1311], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 41 - 337: dog - cat || Loss: 1.1818795204162598\n",
      "tensor([0., 1.]) tensor([0.8686, 0.1314], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 41 - 338: dog - cat || Loss: 1.1815710067749023\n",
      "tensor([0., 1.]) tensor([0.8683, 0.1317], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 41 - 339: dog - cat || Loss: 1.1812620162963867\n",
      "tensor([0., 1.]) tensor([0.8680, 0.1320], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 41 - 340: dog - cat || Loss: 1.1809521913528442\n",
      "tensor([0., 1.]) tensor([0.8677, 0.1323], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 41 - 341: dog - cat || Loss: 1.1806416511535645\n",
      "tensor([0., 1.]) tensor([0.8674, 0.1326], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 41 - 342: dog - cat || Loss: 1.1803303956985474\n",
      "tensor([0., 1.]) tensor([0.8671, 0.1329], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 41 - 343: dog - cat || Loss: 1.1800183057785034\n",
      "tensor([0., 1.]) tensor([0.8668, 0.1332], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 41 - 344: dog - cat || Loss: 1.1797057390213013\n",
      "tensor([0., 1.]) tensor([0.8664, 0.1336], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 41 - 345: dog - cat || Loss: 1.1793922185897827\n",
      "tensor([0., 1.]) tensor([0.8661, 0.1339], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 41 - 346: dog - cat || Loss: 1.1790781021118164\n",
      "tensor([0., 1.]) tensor([0.8658, 0.1342], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 41 - 347: dog - cat || Loss: 1.1787632703781128\n",
      "tensor([0., 1.]) tensor([0.8655, 0.1345], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 41 - 348: dog - cat || Loss: 1.1784477233886719\n",
      "tensor([0., 1.]) tensor([0.8652, 0.1348], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 41 - 349: dog - cat || Loss: 1.178131341934204\n",
      "tensor([0., 1.]) tensor([0.8649, 0.1351], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 41 - 350: dog - cat || Loss: 1.177814245223999\n",
      "tensor([0., 1.]) tensor([0.8646, 0.1354], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 41 - 351: dog - cat || Loss: 1.1774966716766357\n",
      "tensor([0., 1.]) tensor([0.8642, 0.1358], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 41 - 352: dog - cat || Loss: 1.1771780252456665\n",
      "tensor([0., 1.]) tensor([0.8639, 0.1361], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 41 - 353: dog - cat || Loss: 1.1768587827682495\n",
      "tensor([0., 1.]) tensor([0.8636, 0.1364], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 41 - 354: dog - cat || Loss: 1.1765387058258057\n",
      "tensor([0., 1.]) tensor([0.8633, 0.1367], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 41 - 355: dog - cat || Loss: 1.1762181520462036\n",
      "tensor([0., 1.]) tensor([0.8630, 0.1370], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 41 - 356: dog - cat || Loss: 1.1758966445922852\n",
      "tensor([0., 1.]) tensor([0.8626, 0.1374], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 41 - 357: dog - cat || Loss: 1.1755743026733398\n",
      "tensor([0., 1.]) tensor([0.8623, 0.1377], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 41 - 358: dog - cat || Loss: 1.1752513647079468\n",
      "tensor([0., 1.]) tensor([0.8620, 0.1380], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 41 - 359: dog - cat || Loss: 1.1749277114868164\n",
      "tensor([0., 1.]) tensor([0.8617, 0.1383], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 41 - 360: dog - cat || Loss: 1.1746032238006592\n",
      "tensor([0., 1.]) tensor([0.8613, 0.1387], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 41 - 361: dog - cat || Loss: 1.1742781400680542\n",
      "tensor([0., 1.]) tensor([0.8610, 0.1390], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 41 - 362: dog - cat || Loss: 1.1739522218704224\n",
      "tensor([0., 1.]) tensor([0.8607, 0.1393], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 41 - 363: dog - cat || Loss: 1.1736255884170532\n",
      "tensor([0., 1.]) tensor([0.8604, 0.1396], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 41 - 364: dog - cat || Loss: 1.1732980012893677\n",
      "tensor([0., 1.]) tensor([0.8600, 0.1400], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 41 - 365: dog - cat || Loss: 1.172969937324524\n",
      "tensor([0., 1.]) tensor([0.8597, 0.1403], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 41 - 366: dog - cat || Loss: 1.1726410388946533\n",
      "tensor([0., 1.]) tensor([0.8594, 0.1406], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 41 - 367: dog - cat || Loss: 1.172311544418335\n",
      "tensor([0., 1.]) tensor([0.8590, 0.1410], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 41 - 368: dog - cat || Loss: 1.1719809770584106\n",
      "tensor([0., 1.]) tensor([0.8587, 0.1413], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 41 - 369: dog - cat || Loss: 1.1716498136520386\n",
      "tensor([0., 1.]) tensor([0.8584, 0.1416], grad_fn=<SoftmaxBackward0>)\n",
      "=====epoch:42=====\n",
      "Epoch 42 - 0: cat - cat || Loss: 0.455205500125885\n",
      "tensor([1., 0.]) tensor([0.8581, 0.1419], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 42 - 1: cat - cat || Loss: 0.4554709196090698\n",
      "tensor([1., 0.]) tensor([0.8578, 0.1422], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 42 - 2: cat - cat || Loss: 0.4556763768196106\n",
      "tensor([1., 0.]) tensor([0.8576, 0.1424], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 42 - 3: cat - cat || Loss: 0.45582759380340576\n",
      "tensor([1., 0.]) tensor([0.8574, 0.1426], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 42 - 4: cat - cat || Loss: 0.45593008399009705\n",
      "tensor([1., 0.]) tensor([0.8573, 0.1427], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 42 - 5: cat - cat || Loss: 0.4559885561466217\n",
      "tensor([1., 0.]) tensor([0.8573, 0.1427], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 42 - 6: cat - cat || Loss: 0.45600736141204834\n",
      "tensor([1., 0.]) tensor([0.8573, 0.1427], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 42 - 7: cat - cat || Loss: 0.4559905230998993\n",
      "tensor([1., 0.]) tensor([0.8573, 0.1427], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 42 - 8: cat - cat || Loss: 0.4559416174888611\n",
      "tensor([1., 0.]) tensor([0.8573, 0.1427], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 42 - 9: cat - cat || Loss: 0.4558638334274292\n",
      "tensor([1., 0.]) tensor([0.8574, 0.1426], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 42 - 10: cat - cat || Loss: 0.45576009154319763\n",
      "tensor([1., 0.]) tensor([0.8575, 0.1425], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 42 - 11: cat - cat || Loss: 0.45563310384750366\n",
      "tensor([1., 0.]) tensor([0.8576, 0.1424], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 42 - 12: cat - cat || Loss: 0.45548519492149353\n",
      "tensor([1., 0.]) tensor([0.8578, 0.1422], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 42 - 13: cat - cat || Loss: 0.45531851053237915\n",
      "tensor([1., 0.]) tensor([0.8579, 0.1421], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 42 - 14: cat - cat || Loss: 0.4551350176334381\n",
      "tensor([1., 0.]) tensor([0.8581, 0.1419], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 42 - 15: cat - cat || Loss: 0.45493632555007935\n",
      "tensor([1., 0.]) tensor([0.8583, 0.1417], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 42 - 16: cat - cat || Loss: 0.45472419261932373\n",
      "tensor([1., 0.]) tensor([0.8585, 0.1415], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 42 - 17: cat - cat || Loss: 0.45449990034103394\n",
      "tensor([1., 0.]) tensor([0.8588, 0.1412], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 42 - 18: cat - cat || Loss: 0.4542648494243622\n",
      "tensor([1., 0.]) tensor([0.8590, 0.1410], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 42 - 19: cat - cat || Loss: 0.45402008295059204\n",
      "tensor([1., 0.]) tensor([0.8592, 0.1408], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 42 - 20: cat - cat || Loss: 0.4537665843963623\n",
      "tensor([1., 0.]) tensor([0.8595, 0.1405], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 42 - 21: cat - cat || Loss: 0.4535055160522461\n",
      "tensor([1., 0.]) tensor([0.8598, 0.1402], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 42 - 22: cat - cat || Loss: 0.4532376527786255\n",
      "tensor([1., 0.]) tensor([0.8600, 0.1400], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 42 - 23: cat - cat || Loss: 0.452963650226593\n",
      "tensor([1., 0.]) tensor([0.8603, 0.1397], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 42 - 24: cat - cat || Loss: 0.452684223651886\n",
      "tensor([1., 0.]) tensor([0.8606, 0.1394], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 42 - 25: cat - cat || Loss: 0.45239996910095215\n",
      "tensor([1., 0.]) tensor([0.8609, 0.1391], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 42 - 26: cat - cat || Loss: 0.4521116018295288\n",
      "tensor([1., 0.]) tensor([0.8612, 0.1388], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 42 - 27: cat - cat || Loss: 0.45181939005851746\n",
      "tensor([1., 0.]) tensor([0.8614, 0.1386], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 42 - 28: cat - cat || Loss: 0.4515239894390106\n",
      "tensor([1., 0.]) tensor([0.8617, 0.1383], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 42 - 29: cat - cat || Loss: 0.45122554898262024\n",
      "tensor([1., 0.]) tensor([0.8620, 0.1380], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 42 - 30: cat - cat || Loss: 0.45092469453811646\n",
      "tensor([1., 0.]) tensor([0.8623, 0.1377], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 42 - 31: cat - cat || Loss: 0.4506216049194336\n",
      "tensor([1., 0.]) tensor([0.8626, 0.1374], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 42 - 32: cat - cat || Loss: 0.4503166675567627\n",
      "tensor([1., 0.]) tensor([0.8629, 0.1371], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 42 - 33: cat - cat || Loss: 0.45001012086868286\n",
      "tensor([1., 0.]) tensor([0.8633, 0.1367], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 42 - 34: cat - cat || Loss: 0.44970211386680603\n",
      "tensor([1., 0.]) tensor([0.8636, 0.1364], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 42 - 35: cat - cat || Loss: 0.44939297437667847\n",
      "tensor([1., 0.]) tensor([0.8639, 0.1361], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 42 - 36: cat - cat || Loss: 0.4490828216075897\n",
      "tensor([1., 0.]) tensor([0.8642, 0.1358], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 42 - 37: cat - cat || Loss: 0.4487718939781189\n",
      "tensor([1., 0.]) tensor([0.8645, 0.1355], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 42 - 38: cat - cat || Loss: 0.44846031069755554\n",
      "tensor([1., 0.]) tensor([0.8648, 0.1352], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 42 - 39: cat - cat || Loss: 0.4481481611728668\n",
      "tensor([1., 0.]) tensor([0.8651, 0.1349], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 42 - 40: cat - cat || Loss: 0.4478358030319214\n",
      "tensor([1., 0.]) tensor([0.8654, 0.1346], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 42 - 41: cat - cat || Loss: 0.44752293825149536\n",
      "tensor([1., 0.]) tensor([0.8657, 0.1343], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 42 - 42: cat - cat || Loss: 0.44721001386642456\n",
      "tensor([1., 0.]) tensor([0.8661, 0.1339], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 42 - 43: cat - cat || Loss: 0.4468969702720642\n",
      "tensor([1., 0.]) tensor([0.8664, 0.1336], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 42 - 44: cat - cat || Loss: 0.4465840458869934\n",
      "tensor([1., 0.]) tensor([0.8667, 0.1333], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 42 - 45: cat - cat || Loss: 0.44627106189727783\n",
      "tensor([1., 0.]) tensor([0.8670, 0.1330], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 42 - 46: cat - cat || Loss: 0.4459582269191742\n",
      "tensor([1., 0.]) tensor([0.8673, 0.1327], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 42 - 47: cat - cat || Loss: 0.44564563035964966\n",
      "tensor([1., 0.]) tensor([0.8676, 0.1324], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 42 - 48: cat - cat || Loss: 0.445333331823349\n",
      "tensor([1., 0.]) tensor([0.8679, 0.1321], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 42 - 49: cat - cat || Loss: 0.44502130150794983\n",
      "tensor([1., 0.]) tensor([0.8682, 0.1318], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 42 - 50: cat - cat || Loss: 0.4447096288204193\n",
      "tensor([1., 0.]) tensor([0.8686, 0.1314], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 42 - 51: cat - cat || Loss: 0.4443983733654022\n",
      "tensor([1., 0.]) tensor([0.8689, 0.1311], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 42 - 52: cat - cat || Loss: 0.4440874755382538\n",
      "tensor([1., 0.]) tensor([0.8692, 0.1308], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 42 - 53: cat - cat || Loss: 0.44377708435058594\n",
      "tensor([1., 0.]) tensor([0.8695, 0.1305], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 42 - 54: cat - cat || Loss: 0.4434671998023987\n",
      "tensor([1., 0.]) tensor([0.8698, 0.1302], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 42 - 55: cat - cat || Loss: 0.44315779209136963\n",
      "tensor([1., 0.]) tensor([0.8701, 0.1299], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 42 - 56: cat - cat || Loss: 0.4428488612174988\n",
      "tensor([1., 0.]) tensor([0.8704, 0.1296], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 42 - 57: cat - cat || Loss: 0.4425404667854309\n",
      "tensor([1., 0.]) tensor([0.8707, 0.1293], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 42 - 58: cat - cat || Loss: 0.44223278760910034\n",
      "tensor([1., 0.]) tensor([0.8710, 0.1290], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 42 - 59: cat - cat || Loss: 0.44192561507225037\n",
      "tensor([1., 0.]) tensor([0.8713, 0.1287], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 42 - 60: cat - cat || Loss: 0.44161897897720337\n",
      "tensor([1., 0.]) tensor([0.8716, 0.1284], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 42 - 61: cat - cat || Loss: 0.44131308794021606\n",
      "tensor([1., 0.]) tensor([0.8719, 0.1281], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 42 - 62: cat - cat || Loss: 0.4410076141357422\n",
      "tensor([1., 0.]) tensor([0.8723, 0.1277], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 42 - 63: cat - cat || Loss: 0.44070297479629517\n",
      "tensor([1., 0.]) tensor([0.8726, 0.1274], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 42 - 64: cat - cat || Loss: 0.4403988718986511\n",
      "tensor([1., 0.]) tensor([0.8729, 0.1271], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 42 - 65: cat - cat || Loss: 0.4400954246520996\n",
      "tensor([1., 0.]) tensor([0.8732, 0.1268], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 42 - 66: cat - cat || Loss: 0.4397926330566406\n",
      "tensor([1., 0.]) tensor([0.8735, 0.1265], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 42 - 67: cat - cat || Loss: 0.4394906163215637\n",
      "tensor([1., 0.]) tensor([0.8738, 0.1262], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 42 - 68: cat - cat || Loss: 0.439189076423645\n",
      "tensor([1., 0.]) tensor([0.8741, 0.1259], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 42 - 69: cat - cat || Loss: 0.4388883709907532\n",
      "tensor([1., 0.]) tensor([0.8744, 0.1256], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 42 - 70: cat - cat || Loss: 0.43858832120895386\n",
      "tensor([1., 0.]) tensor([0.8747, 0.1253], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 42 - 71: cat - cat || Loss: 0.43828892707824707\n",
      "tensor([1., 0.]) tensor([0.8750, 0.1250], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 42 - 72: cat - cat || Loss: 0.4379901885986328\n",
      "tensor([1., 0.]) tensor([0.8753, 0.1247], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 42 - 73: cat - cat || Loss: 0.4376921057701111\n",
      "tensor([1., 0.]) tensor([0.8756, 0.1244], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 42 - 74: cat - cat || Loss: 0.43739479780197144\n",
      "tensor([1., 0.]) tensor([0.8759, 0.1241], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 42 - 75: cat - cat || Loss: 0.4370981454849243\n",
      "tensor([1., 0.]) tensor([0.8762, 0.1238], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 42 - 76: cat - cat || Loss: 0.4368022084236145\n",
      "tensor([1., 0.]) tensor([0.8765, 0.1235], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 42 - 77: cat - cat || Loss: 0.4365069270133972\n",
      "tensor([1., 0.]) tensor([0.8768, 0.1232], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 42 - 78: cat - cat || Loss: 0.436212420463562\n",
      "tensor([1., 0.]) tensor([0.8770, 0.1230], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 42 - 79: cat - cat || Loss: 0.43591853976249695\n",
      "tensor([1., 0.]) tensor([0.8773, 0.1227], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 42 - 80: cat - cat || Loss: 0.4356253743171692\n",
      "tensor([1., 0.]) tensor([0.8776, 0.1224], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 42 - 81: cat - cat || Loss: 0.4353328347206116\n",
      "tensor([1., 0.]) tensor([0.8779, 0.1221], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 42 - 82: cat - cat || Loss: 0.4350410997867584\n",
      "tensor([1., 0.]) tensor([0.8782, 0.1218], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 42 - 83: cat - cat || Loss: 0.4347500205039978\n",
      "tensor([1., 0.]) tensor([0.8785, 0.1215], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 42 - 84: cat - cat || Loss: 0.43445974588394165\n",
      "tensor([1., 0.]) tensor([0.8788, 0.1212], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 42 - 85: cat - cat || Loss: 0.43417003750801086\n",
      "tensor([1., 0.]) tensor([0.8791, 0.1209], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 42 - 86: cat - cat || Loss: 0.4338810443878174\n",
      "tensor([1., 0.]) tensor([0.8794, 0.1206], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 42 - 87: cat - cat || Loss: 0.4335927963256836\n",
      "tensor([1., 0.]) tensor([0.8797, 0.1203], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 42 - 88: cat - cat || Loss: 0.43330514430999756\n",
      "tensor([1., 0.]) tensor([0.8800, 0.1200], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 42 - 89: cat - cat || Loss: 0.433018296957016\n",
      "tensor([1., 0.]) tensor([0.8802, 0.1198], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 42 - 90: cat - cat || Loss: 0.43273216485977173\n",
      "tensor([1., 0.]) tensor([0.8805, 0.1195], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 42 - 91: cat - cat || Loss: 0.43244659900665283\n",
      "tensor([1., 0.]) tensor([0.8808, 0.1192], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 42 - 92: cat - cat || Loss: 0.43216177821159363\n",
      "tensor([1., 0.]) tensor([0.8811, 0.1189], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 42 - 93: cat - cat || Loss: 0.43187767267227173\n",
      "tensor([1., 0.]) tensor([0.8814, 0.1186], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 42 - 94: cat - cat || Loss: 0.43159425258636475\n",
      "tensor([1., 0.]) tensor([0.8817, 0.1183], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 42 - 95: cat - cat || Loss: 0.4313114881515503\n",
      "tensor([1., 0.]) tensor([0.8820, 0.1180], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 42 - 96: cat - cat || Loss: 0.43102943897247314\n",
      "tensor([1., 0.]) tensor([0.8822, 0.1178], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 42 - 97: cat - cat || Loss: 0.4307480752468109\n",
      "tensor([1., 0.]) tensor([0.8825, 0.1175], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 42 - 98: cat - cat || Loss: 0.430467426776886\n",
      "tensor([1., 0.]) tensor([0.8828, 0.1172], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 42 - 99: cat - cat || Loss: 0.430187463760376\n",
      "tensor([1., 0.]) tensor([0.8831, 0.1169], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 42 - 100: cat - cat || Loss: 0.4299080967903137\n",
      "tensor([1., 0.]) tensor([0.8834, 0.1166], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 42 - 101: cat - cat || Loss: 0.42962950468063354\n",
      "tensor([1., 0.]) tensor([0.8836, 0.1164], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 42 - 102: cat - cat || Loss: 0.4293516278266907\n",
      "tensor([1., 0.]) tensor([0.8839, 0.1161], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 42 - 103: cat - cat || Loss: 0.4290742874145508\n",
      "tensor([1., 0.]) tensor([0.8842, 0.1158], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 42 - 104: cat - cat || Loss: 0.42879778146743774\n",
      "tensor([1., 0.]) tensor([0.8845, 0.1155], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 42 - 105: cat - cat || Loss: 0.42852190136909485\n",
      "tensor([1., 0.]) tensor([0.8847, 0.1153], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 42 - 106: cat - cat || Loss: 0.4282466769218445\n",
      "tensor([1., 0.]) tensor([0.8850, 0.1150], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 42 - 107: cat - cat || Loss: 0.42797213792800903\n",
      "tensor([1., 0.]) tensor([0.8853, 0.1147], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 42 - 108: cat - cat || Loss: 0.4276982545852661\n",
      "tensor([1., 0.]) tensor([0.8856, 0.1144], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 42 - 109: cat - cat || Loss: 0.4274250566959381\n",
      "tensor([1., 0.]) tensor([0.8858, 0.1142], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 42 - 110: cat - cat || Loss: 0.4271525740623474\n",
      "tensor([1., 0.]) tensor([0.8861, 0.1139], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 42 - 111: cat - cat || Loss: 0.42688077688217163\n",
      "tensor([1., 0.]) tensor([0.8864, 0.1136], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 42 - 112: cat - cat || Loss: 0.42660951614379883\n",
      "tensor([1., 0.]) tensor([0.8867, 0.1133], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 42 - 113: cat - cat || Loss: 0.4263390600681305\n",
      "tensor([1., 0.]) tensor([0.8869, 0.1131], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 42 - 114: cat - cat || Loss: 0.42606914043426514\n",
      "tensor([1., 0.]) tensor([0.8872, 0.1128], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 42 - 115: cat - cat || Loss: 0.42580002546310425\n",
      "tensor([1., 0.]) tensor([0.8875, 0.1125], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 42 - 116: cat - cat || Loss: 0.42553144693374634\n",
      "tensor([1., 0.]) tensor([0.8877, 0.1123], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 42 - 117: cat - cat || Loss: 0.4252636432647705\n",
      "tensor([1., 0.]) tensor([0.8880, 0.1120], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 42 - 118: cat - cat || Loss: 0.4249964654445648\n",
      "tensor([1., 0.]) tensor([0.8883, 0.1117], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 42 - 119: cat - cat || Loss: 0.4247300326824188\n",
      "tensor([1., 0.]) tensor([0.8885, 0.1115], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 42 - 120: cat - cat || Loss: 0.4244641065597534\n",
      "tensor([1., 0.]) tensor([0.8888, 0.1112], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 42 - 121: cat - cat || Loss: 0.42419886589050293\n",
      "tensor([1., 0.]) tensor([0.8891, 0.1109], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 42 - 122: cat - cat || Loss: 0.4239344298839569\n",
      "tensor([1., 0.]) tensor([0.8893, 0.1107], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 42 - 123: cat - cat || Loss: 0.42367053031921387\n",
      "tensor([1., 0.]) tensor([0.8896, 0.1104], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 42 - 124: cat - cat || Loss: 0.42340734601020813\n",
      "tensor([1., 0.]) tensor([0.8899, 0.1101], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 42 - 125: cat - cat || Loss: 0.4231448173522949\n",
      "tensor([1., 0.]) tensor([0.8901, 0.1099], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 42 - 126: cat - cat || Loss: 0.4228828549385071\n",
      "tensor([1., 0.]) tensor([0.8904, 0.1096], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 42 - 127: cat - cat || Loss: 0.42262154817581177\n",
      "tensor([1., 0.]) tensor([0.8906, 0.1094], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 42 - 128: cat - cat || Loss: 0.42236098647117615\n",
      "tensor([1., 0.]) tensor([0.8909, 0.1091], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 42 - 129: cat - cat || Loss: 0.4221010208129883\n",
      "tensor([1., 0.]) tensor([0.8912, 0.1088], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 42 - 130: cat - cat || Loss: 0.42184174060821533\n",
      "tensor([1., 0.]) tensor([0.8914, 0.1086], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 42 - 131: cat - cat || Loss: 0.42158299684524536\n",
      "tensor([1., 0.]) tensor([0.8917, 0.1083], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 42 - 132: cat - cat || Loss: 0.4213249683380127\n",
      "tensor([1., 0.]) tensor([0.8919, 0.1081], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 42 - 133: cat - cat || Loss: 0.42106759548187256\n",
      "tensor([1., 0.]) tensor([0.8922, 0.1078], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 42 - 134: cat - cat || Loss: 0.4208108186721802\n",
      "tensor([1., 0.]) tensor([0.8925, 0.1075], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 42 - 135: cat - cat || Loss: 0.4205547571182251\n",
      "tensor([1., 0.]) tensor([0.8927, 0.1073], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 42 - 136: cat - cat || Loss: 0.420299232006073\n",
      "tensor([1., 0.]) tensor([0.8930, 0.1070], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 42 - 137: cat - cat || Loss: 0.4200444221496582\n",
      "tensor([1., 0.]) tensor([0.8932, 0.1068], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 42 - 138: cat - cat || Loss: 0.4197903275489807\n",
      "tensor([1., 0.]) tensor([0.8935, 0.1065], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 42 - 139: cat - cat || Loss: 0.4195367693901062\n",
      "tensor([1., 0.]) tensor([0.8937, 0.1063], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 42 - 140: cat - cat || Loss: 0.4192838668823242\n",
      "tensor([1., 0.]) tensor([0.8940, 0.1060], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 42 - 141: cat - cat || Loss: 0.41903162002563477\n",
      "tensor([1., 0.]) tensor([0.8942, 0.1058], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 42 - 142: cat - cat || Loss: 0.41878005862236023\n",
      "tensor([1., 0.]) tensor([0.8945, 0.1055], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 42 - 143: cat - cat || Loss: 0.4185289740562439\n",
      "tensor([1., 0.]) tensor([0.8947, 0.1053], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 42 - 144: cat - cat || Loss: 0.41827869415283203\n",
      "tensor([1., 0.]) tensor([0.8950, 0.1050], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 42 - 145: cat - cat || Loss: 0.41802898049354553\n",
      "tensor([1., 0.]) tensor([0.8952, 0.1048], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 42 - 146: cat - cat || Loss: 0.41777995228767395\n",
      "tensor([1., 0.]) tensor([0.8955, 0.1045], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 42 - 147: cat - cat || Loss: 0.41753143072128296\n",
      "tensor([1., 0.]) tensor([0.8957, 0.1043], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 42 - 148: cat - cat || Loss: 0.4172835648059845\n",
      "tensor([1., 0.]) tensor([0.8960, 0.1040], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 42 - 149: cat - cat || Loss: 0.41703635454177856\n",
      "tensor([1., 0.]) tensor([0.8962, 0.1038], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 42 - 150: cat - cat || Loss: 0.4167896509170532\n",
      "tensor([1., 0.]) tensor([0.8965, 0.1035], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 42 - 151: cat - cat || Loss: 0.4165436923503876\n",
      "tensor([1., 0.]) tensor([0.8967, 0.1033], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 42 - 152: cat - cat || Loss: 0.41629835963249207\n",
      "tensor([1., 0.]) tensor([0.8970, 0.1030], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 42 - 153: cat - cat || Loss: 0.41605353355407715\n",
      "tensor([1., 0.]) tensor([0.8972, 0.1028], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 42 - 154: cat - cat || Loss: 0.41580936312675476\n",
      "tensor([1., 0.]) tensor([0.8975, 0.1025], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 42 - 155: cat - cat || Loss: 0.4155657887458801\n",
      "tensor([1., 0.]) tensor([0.8977, 0.1023], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 42 - 156: cat - cat || Loss: 0.4153228998184204\n",
      "tensor([1., 0.]) tensor([0.8979, 0.1021], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 42 - 157: cat - cat || Loss: 0.41508060693740845\n",
      "tensor([1., 0.]) tensor([0.8982, 0.1018], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 42 - 158: cat - cat || Loss: 0.41483891010284424\n",
      "tensor([1., 0.]) tensor([0.8984, 0.1016], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 42 - 159: cat - cat || Loss: 0.4145978093147278\n",
      "tensor([1., 0.]) tensor([0.8987, 0.1013], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 42 - 160: cat - cat || Loss: 0.4143572449684143\n",
      "tensor([1., 0.]) tensor([0.8989, 0.1011], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 42 - 161: cat - cat || Loss: 0.4141174256801605\n",
      "tensor([1., 0.]) tensor([0.8991, 0.1009], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 42 - 162: cat - cat || Loss: 0.4138781428337097\n",
      "tensor([1., 0.]) tensor([0.8994, 0.1006], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 42 - 163: cat - cat || Loss: 0.4136394262313843\n",
      "tensor([1., 0.]) tensor([0.8996, 0.1004], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 42 - 164: cat - cat || Loss: 0.413401335477829\n",
      "tensor([1., 0.]) tensor([0.8999, 0.1001], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 42 - 165: cat - cat || Loss: 0.41316384077072144\n",
      "tensor([1., 0.]) tensor([0.9001, 0.0999], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 42 - 166: cat - cat || Loss: 0.41292691230773926\n",
      "tensor([1., 0.]) tensor([0.9003, 0.0997], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 42 - 167: cat - cat || Loss: 0.4126906394958496\n",
      "tensor([1., 0.]) tensor([0.9006, 0.0994], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 42 - 168: cat - cat || Loss: 0.4124549329280853\n",
      "tensor([1., 0.]) tensor([0.9008, 0.0992], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 42 - 169: cat - cat || Loss: 0.41221970319747925\n",
      "tensor([1., 0.]) tensor([0.9010, 0.0990], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 42 - 170: cat - cat || Loss: 0.41198527812957764\n",
      "tensor([1., 0.]) tensor([0.9013, 0.0987], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 42 - 171: cat - cat || Loss: 0.4117513597011566\n",
      "tensor([1., 0.]) tensor([0.9015, 0.0985], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 42 - 172: cat - cat || Loss: 0.41151803731918335\n",
      "tensor([1., 0.]) tensor([0.9017, 0.0983], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 42 - 173: cat - cat || Loss: 0.4112853705883026\n",
      "tensor([1., 0.]) tensor([0.9020, 0.0980], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 42 - 174: cat - cat || Loss: 0.4110531806945801\n",
      "tensor([1., 0.]) tensor([0.9022, 0.0978], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 42 - 175: cat - cat || Loss: 0.4108216166496277\n",
      "tensor([1., 0.]) tensor([0.9024, 0.0976], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 42 - 176: cat - cat || Loss: 0.41059061884880066\n",
      "tensor([1., 0.]) tensor([0.9027, 0.0973], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 42 - 177: cat - cat || Loss: 0.4103602468967438\n",
      "tensor([1., 0.]) tensor([0.9029, 0.0971], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 42 - 178: cat - cat || Loss: 0.4101303219795227\n",
      "tensor([1., 0.]) tensor([0.9031, 0.0969], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 42 - 179: cat - cat || Loss: 0.40990111231803894\n",
      "tensor([1., 0.]) tensor([0.9034, 0.0966], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 42 - 180: cat - cat || Loss: 0.40967246890068054\n",
      "tensor([1., 0.]) tensor([0.9036, 0.0964], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 42 - 181: cat - cat || Loss: 0.40944433212280273\n",
      "tensor([1., 0.]) tensor([0.9038, 0.0962], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 42 - 182: cat - cat || Loss: 0.4092167615890503\n",
      "tensor([1., 0.]) tensor([0.9040, 0.0960], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 42 - 183: cat - cat || Loss: 0.40898990631103516\n",
      "tensor([1., 0.]) tensor([0.9043, 0.0957], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 42 - 184: cat - cat || Loss: 0.40876346826553345\n",
      "tensor([1., 0.]) tensor([0.9045, 0.0955], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 42 - 185: cat - cat || Loss: 0.4085376262664795\n",
      "tensor([1., 0.]) tensor([0.9047, 0.0953], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 42 - 186: cat - cat || Loss: 0.40831229090690613\n",
      "tensor([1., 0.]) tensor([0.9049, 0.0951], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 42 - 187: cat - cat || Loss: 0.4080875515937805\n",
      "tensor([1., 0.]) tensor([0.9052, 0.0948], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 42 - 188: cat - cat || Loss: 0.4078633785247803\n",
      "tensor([1., 0.]) tensor([0.9054, 0.0946], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 42 - 189: cat - cat || Loss: 0.407639741897583\n",
      "tensor([1., 0.]) tensor([0.9056, 0.0944], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 42 - 190: dog - cat || Loss: 1.2191067934036255\n",
      "tensor([0., 1.]) tensor([0.9058, 0.0942], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 42 - 191: dog - cat || Loss: 1.2192853689193726\n",
      "tensor([0., 1.]) tensor([0.9060, 0.0940], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 42 - 192: dog - cat || Loss: 1.2194238901138306\n",
      "tensor([0., 1.]) tensor([0.9062, 0.0938], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 42 - 193: dog - cat || Loss: 1.2195265293121338\n",
      "tensor([0., 1.]) tensor([0.9063, 0.0937], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 42 - 194: dog - cat || Loss: 1.2195969820022583\n",
      "tensor([0., 1.]) tensor([0.9063, 0.0937], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 42 - 195: dog - cat || Loss: 1.2196382284164429\n",
      "tensor([0., 1.]) tensor([0.9064, 0.0936], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 42 - 196: dog - cat || Loss: 1.2196534872055054\n",
      "tensor([0., 1.]) tensor([0.9064, 0.0936], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 42 - 197: dog - cat || Loss: 1.219645380973816\n",
      "tensor([0., 1.]) tensor([0.9064, 0.0936], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 42 - 198: dog - cat || Loss: 1.2196160554885864\n",
      "tensor([0., 1.]) tensor([0.9064, 0.0936], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 42 - 199: dog - cat || Loss: 1.2195677757263184\n",
      "tensor([0., 1.]) tensor([0.9063, 0.0937], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 42 - 200: dog - cat || Loss: 1.219502568244934\n",
      "tensor([0., 1.]) tensor([0.9062, 0.0938], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 42 - 201: dog - cat || Loss: 1.219421625137329\n",
      "tensor([0., 1.]) tensor([0.9062, 0.0938], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 42 - 202: dog - cat || Loss: 1.2193268537521362\n",
      "tensor([0., 1.]) tensor([0.9061, 0.0939], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 42 - 203: dog - cat || Loss: 1.21921968460083\n",
      "tensor([0., 1.]) tensor([0.9060, 0.0940], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 42 - 204: dog - cat || Loss: 1.2191011905670166\n",
      "tensor([0., 1.]) tensor([0.9058, 0.0942], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 42 - 205: dog - cat || Loss: 1.2189722061157227\n",
      "tensor([0., 1.]) tensor([0.9057, 0.0943], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 42 - 206: dog - cat || Loss: 1.2188341617584229\n",
      "tensor([0., 1.]) tensor([0.9056, 0.0944], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 42 - 207: dog - cat || Loss: 1.218687653541565\n",
      "tensor([0., 1.]) tensor([0.9054, 0.0946], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 42 - 208: dog - cat || Loss: 1.2185335159301758\n",
      "tensor([0., 1.]) tensor([0.9053, 0.0947], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 42 - 209: dog - cat || Loss: 1.2183725833892822\n",
      "tensor([0., 1.]) tensor([0.9051, 0.0949], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 42 - 210: dog - cat || Loss: 1.218205451965332\n",
      "tensor([0., 1.]) tensor([0.9049, 0.0951], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 42 - 211: dog - cat || Loss: 1.218032717704773\n",
      "tensor([0., 1.]) tensor([0.9048, 0.0952], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 42 - 212: dog - cat || Loss: 1.217854619026184\n",
      "tensor([0., 1.]) tensor([0.9046, 0.0954], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 42 - 213: dog - cat || Loss: 1.2176718711853027\n",
      "tensor([0., 1.]) tensor([0.9044, 0.0956], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 42 - 214: dog - cat || Loss: 1.217484951019287\n",
      "tensor([0., 1.]) tensor([0.9042, 0.0958], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 42 - 215: dog - cat || Loss: 1.2172940969467163\n",
      "tensor([0., 1.]) tensor([0.9040, 0.0960], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 42 - 216: dog - cat || Loss: 1.217099666595459\n",
      "tensor([0., 1.]) tensor([0.9038, 0.0962], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 42 - 217: dog - cat || Loss: 1.2169020175933838\n",
      "tensor([0., 1.]) tensor([0.9036, 0.0964], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 42 - 218: dog - cat || Loss: 1.2167011499404907\n",
      "tensor([0., 1.]) tensor([0.9034, 0.0966], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 42 - 219: dog - cat || Loss: 1.216497778892517\n",
      "tensor([0., 1.]) tensor([0.9032, 0.0968], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 42 - 220: dog - cat || Loss: 1.2162916660308838\n",
      "tensor([0., 1.]) tensor([0.9030, 0.0970], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 42 - 221: dog - cat || Loss: 1.2160835266113281\n",
      "tensor([0., 1.]) tensor([0.9028, 0.0972], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 42 - 222: dog - cat || Loss: 1.2158730030059814\n",
      "tensor([0., 1.]) tensor([0.9026, 0.0974], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 42 - 223: dog - cat || Loss: 1.2156604528427124\n",
      "tensor([0., 1.]) tensor([0.9024, 0.0976], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 42 - 224: dog - cat || Loss: 1.2154461145401\n",
      "tensor([0., 1.]) tensor([0.9022, 0.0978], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 42 - 225: dog - cat || Loss: 1.215230107307434\n",
      "tensor([0., 1.]) tensor([0.9020, 0.0980], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 42 - 226: dog - cat || Loss: 1.2150124311447144\n",
      "tensor([0., 1.]) tensor([0.9018, 0.0982], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 42 - 227: dog - cat || Loss: 1.21479332447052\n",
      "tensor([0., 1.]) tensor([0.9015, 0.0985], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 42 - 228: dog - cat || Loss: 1.2145726680755615\n",
      "tensor([0., 1.]) tensor([0.9013, 0.0987], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 42 - 229: dog - cat || Loss: 1.2143508195877075\n",
      "tensor([0., 1.]) tensor([0.9011, 0.0989], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 42 - 230: dog - cat || Loss: 1.214127540588379\n",
      "tensor([0., 1.]) tensor([0.9009, 0.0991], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 42 - 231: dog - cat || Loss: 1.2139033079147339\n",
      "tensor([0., 1.]) tensor([0.9006, 0.0994], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 42 - 232: dog - cat || Loss: 1.2136777639389038\n",
      "tensor([0., 1.]) tensor([0.9004, 0.0996], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 42 - 233: dog - cat || Loss: 1.2134513854980469\n",
      "tensor([0., 1.]) tensor([0.9002, 0.0998], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 42 - 234: dog - cat || Loss: 1.2132238149642944\n",
      "tensor([0., 1.]) tensor([0.9000, 0.1000], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 42 - 235: dog - cat || Loss: 1.2129952907562256\n",
      "tensor([0., 1.]) tensor([0.8997, 0.1003], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 42 - 236: dog - cat || Loss: 1.2127658128738403\n",
      "tensor([0., 1.]) tensor([0.8995, 0.1005], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 42 - 237: dog - cat || Loss: 1.2125353813171387\n",
      "tensor([0., 1.]) tensor([0.8993, 0.1007], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 42 - 238: dog - cat || Loss: 1.2123042345046997\n",
      "tensor([0., 1.]) tensor([0.8990, 0.1010], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 42 - 239: dog - cat || Loss: 1.2120721340179443\n",
      "tensor([0., 1.]) tensor([0.8988, 0.1012], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 42 - 240: dog - cat || Loss: 1.211839199066162\n",
      "tensor([0., 1.]) tensor([0.8986, 0.1014], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 42 - 241: dog - cat || Loss: 1.2116055488586426\n",
      "tensor([0., 1.]) tensor([0.8983, 0.1017], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 42 - 242: dog - cat || Loss: 1.2113710641860962\n",
      "tensor([0., 1.]) tensor([0.8981, 0.1019], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 42 - 243: dog - cat || Loss: 1.211135983467102\n",
      "tensor([0., 1.]) tensor([0.8979, 0.1021], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 42 - 244: dog - cat || Loss: 1.2108999490737915\n",
      "tensor([0., 1.]) tensor([0.8976, 0.1024], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 42 - 245: dog - cat || Loss: 1.2106635570526123\n",
      "tensor([0., 1.]) tensor([0.8974, 0.1026], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 42 - 246: dog - cat || Loss: 1.210425853729248\n",
      "tensor([0., 1.]) tensor([0.8972, 0.1028], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 42 - 247: dog - cat || Loss: 1.2101879119873047\n",
      "tensor([0., 1.]) tensor([0.8969, 0.1031], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 42 - 248: dog - cat || Loss: 1.2099491357803345\n",
      "tensor([0., 1.]) tensor([0.8967, 0.1033], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 42 - 249: dog - cat || Loss: 1.2097097635269165\n",
      "tensor([0., 1.]) tensor([0.8964, 0.1036], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 42 - 250: dog - cat || Loss: 1.2094696760177612\n",
      "tensor([0., 1.]) tensor([0.8962, 0.1038], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 42 - 251: dog - cat || Loss: 1.2092289924621582\n",
      "tensor([0., 1.]) tensor([0.8960, 0.1040], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 42 - 252: dog - cat || Loss: 1.2089874744415283\n",
      "tensor([0., 1.]) tensor([0.8957, 0.1043], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 42 - 253: dog - cat || Loss: 1.2087453603744507\n",
      "tensor([0., 1.]) tensor([0.8955, 0.1045], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 42 - 254: dog - cat || Loss: 1.2085028886795044\n",
      "tensor([0., 1.]) tensor([0.8952, 0.1048], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 42 - 255: dog - cat || Loss: 1.2082593441009521\n",
      "tensor([0., 1.]) tensor([0.8950, 0.1050], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 42 - 256: dog - cat || Loss: 1.2080153226852417\n",
      "tensor([0., 1.]) tensor([0.8948, 0.1052], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 42 - 257: dog - cat || Loss: 1.2077707052230835\n",
      "tensor([0., 1.]) tensor([0.8945, 0.1055], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 42 - 258: dog - cat || Loss: 1.2075254917144775\n",
      "tensor([0., 1.]) tensor([0.8943, 0.1057], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 42 - 259: dog - cat || Loss: 1.2072796821594238\n",
      "tensor([0., 1.]) tensor([0.8940, 0.1060], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 42 - 260: dog - cat || Loss: 1.2070329189300537\n",
      "tensor([0., 1.]) tensor([0.8938, 0.1062], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 42 - 261: dog - cat || Loss: 1.206786036491394\n",
      "tensor([0., 1.]) tensor([0.8935, 0.1065], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 42 - 262: dog - cat || Loss: 1.2065383195877075\n",
      "tensor([0., 1.]) tensor([0.8933, 0.1067], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 42 - 263: dog - cat || Loss: 1.2062897682189941\n",
      "tensor([0., 1.]) tensor([0.8930, 0.1070], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 42 - 264: dog - cat || Loss: 1.206040859222412\n",
      "tensor([0., 1.]) tensor([0.8928, 0.1072], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 42 - 265: dog - cat || Loss: 1.2057912349700928\n",
      "tensor([0., 1.]) tensor([0.8925, 0.1075], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 42 - 266: dog - cat || Loss: 1.2055410146713257\n",
      "tensor([0., 1.]) tensor([0.8923, 0.1077], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 42 - 267: dog - cat || Loss: 1.2052903175354004\n",
      "tensor([0., 1.]) tensor([0.8920, 0.1080], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 42 - 268: dog - cat || Loss: 1.2050385475158691\n",
      "tensor([0., 1.]) tensor([0.8918, 0.1082], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 42 - 269: dog - cat || Loss: 1.2047864198684692\n",
      "tensor([0., 1.]) tensor([0.8915, 0.1085], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 42 - 270: dog - cat || Loss: 1.2045336961746216\n",
      "tensor([0., 1.]) tensor([0.8913, 0.1087], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 42 - 271: dog - cat || Loss: 1.2042804956436157\n",
      "tensor([0., 1.]) tensor([0.8910, 0.1090], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 42 - 272: dog - cat || Loss: 1.2040263414382935\n",
      "tensor([0., 1.]) tensor([0.8908, 0.1092], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 42 - 273: dog - cat || Loss: 1.203771948814392\n",
      "tensor([0., 1.]) tensor([0.8905, 0.1095], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 42 - 274: dog - cat || Loss: 1.2035166025161743\n",
      "tensor([0., 1.]) tensor([0.8903, 0.1097], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 42 - 275: dog - cat || Loss: 1.2032607793807983\n",
      "tensor([0., 1.]) tensor([0.8900, 0.1100], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 42 - 276: dog - cat || Loss: 1.203004240989685\n",
      "tensor([0., 1.]) tensor([0.8897, 0.1103], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 42 - 277: dog - cat || Loss: 1.2027472257614136\n",
      "tensor([0., 1.]) tensor([0.8895, 0.1105], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 42 - 278: dog - cat || Loss: 1.2024894952774048\n",
      "tensor([0., 1.]) tensor([0.8892, 0.1108], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 42 - 279: dog - cat || Loss: 1.2022312879562378\n",
      "tensor([0., 1.]) tensor([0.8890, 0.1110], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 42 - 280: dog - cat || Loss: 1.2019723653793335\n",
      "tensor([0., 1.]) tensor([0.8887, 0.1113], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 42 - 281: dog - cat || Loss: 1.2017126083374023\n",
      "tensor([0., 1.]) tensor([0.8885, 0.1115], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 42 - 282: dog - cat || Loss: 1.2014524936676025\n",
      "tensor([0., 1.]) tensor([0.8882, 0.1118], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 42 - 283: dog - cat || Loss: 1.2011915445327759\n",
      "tensor([0., 1.]) tensor([0.8879, 0.1121], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 42 - 284: dog - cat || Loss: 1.2009299993515015\n",
      "tensor([0., 1.]) tensor([0.8877, 0.1123], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 42 - 285: dog - cat || Loss: 1.2006678581237793\n",
      "tensor([0., 1.]) tensor([0.8874, 0.1126], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 42 - 286: dog - cat || Loss: 1.2004051208496094\n",
      "tensor([0., 1.]) tensor([0.8871, 0.1129], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 42 - 287: dog - cat || Loss: 1.2001417875289917\n",
      "tensor([0., 1.]) tensor([0.8869, 0.1131], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 42 - 288: dog - cat || Loss: 1.1998777389526367\n",
      "tensor([0., 1.]) tensor([0.8866, 0.1134], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 42 - 289: dog - cat || Loss: 1.1996129751205444\n",
      "tensor([0., 1.]) tensor([0.8864, 0.1136], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 42 - 290: dog - cat || Loss: 1.199347734451294\n",
      "tensor([0., 1.]) tensor([0.8861, 0.1139], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 42 - 291: dog - cat || Loss: 1.1990818977355957\n",
      "tensor([0., 1.]) tensor([0.8858, 0.1142], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 42 - 292: dog - cat || Loss: 1.198815107345581\n",
      "tensor([0., 1.]) tensor([0.8856, 0.1144], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 42 - 293: dog - cat || Loss: 1.1985478401184082\n",
      "tensor([0., 1.]) tensor([0.8853, 0.1147], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 42 - 294: dog - cat || Loss: 1.1982800960540771\n",
      "tensor([0., 1.]) tensor([0.8850, 0.1150], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 42 - 295: dog - cat || Loss: 1.1980116367340088\n",
      "tensor([0., 1.]) tensor([0.8847, 0.1153], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 42 - 296: dog - cat || Loss: 1.1977423429489136\n",
      "tensor([0., 1.]) tensor([0.8845, 0.1155], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 42 - 297: dog - cat || Loss: 1.1974726915359497\n",
      "tensor([0., 1.]) tensor([0.8842, 0.1158], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 42 - 298: dog - cat || Loss: 1.197202205657959\n",
      "tensor([0., 1.]) tensor([0.8839, 0.1161], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 42 - 299: dog - cat || Loss: 1.1969311237335205\n",
      "tensor([0., 1.]) tensor([0.8837, 0.1163], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 42 - 300: dog - cat || Loss: 1.1966592073440552\n",
      "tensor([0., 1.]) tensor([0.8834, 0.1166], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 42 - 301: dog - cat || Loss: 1.1963869333267212\n",
      "tensor([0., 1.]) tensor([0.8831, 0.1169], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 42 - 302: dog - cat || Loss: 1.1961138248443604\n",
      "tensor([0., 1.]) tensor([0.8829, 0.1171], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 42 - 303: dog - cat || Loss: 1.1958402395248413\n",
      "tensor([0., 1.]) tensor([0.8826, 0.1174], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 42 - 304: dog - cat || Loss: 1.195565938949585\n",
      "tensor([0., 1.]) tensor([0.8823, 0.1177], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 42 - 305: dog - cat || Loss: 1.1952908039093018\n",
      "tensor([0., 1.]) tensor([0.8820, 0.1180], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 42 - 306: dog - cat || Loss: 1.1950150728225708\n",
      "tensor([0., 1.]) tensor([0.8818, 0.1182], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 42 - 307: dog - cat || Loss: 1.194738745689392\n",
      "tensor([0., 1.]) tensor([0.8815, 0.1185], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 42 - 308: dog - cat || Loss: 1.1944615840911865\n",
      "tensor([0., 1.]) tensor([0.8812, 0.1188], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 42 - 309: dog - cat || Loss: 1.1941841840744019\n",
      "tensor([0., 1.]) tensor([0.8809, 0.1191], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 42 - 310: dog - cat || Loss: 1.1939055919647217\n",
      "tensor([0., 1.]) tensor([0.8806, 0.1194], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 42 - 311: dog - cat || Loss: 1.1936266422271729\n",
      "tensor([0., 1.]) tensor([0.8804, 0.1196], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 42 - 312: dog - cat || Loss: 1.1933469772338867\n",
      "tensor([0., 1.]) tensor([0.8801, 0.1199], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 42 - 313: dog - cat || Loss: 1.1930667161941528\n",
      "tensor([0., 1.]) tensor([0.8798, 0.1202], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 42 - 314: dog - cat || Loss: 1.1927857398986816\n",
      "tensor([0., 1.]) tensor([0.8795, 0.1205], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 42 - 315: dog - cat || Loss: 1.1925040483474731\n",
      "tensor([0., 1.]) tensor([0.8792, 0.1208], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 42 - 316: dog - cat || Loss: 1.1922216415405273\n",
      "tensor([0., 1.]) tensor([0.8790, 0.1210], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 42 - 317: dog - cat || Loss: 1.1919387578964233\n",
      "tensor([0., 1.]) tensor([0.8787, 0.1213], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 42 - 318: dog - cat || Loss: 1.1916550397872925\n",
      "tensor([0., 1.]) tensor([0.8784, 0.1216], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 42 - 319: dog - cat || Loss: 1.1913708448410034\n",
      "tensor([0., 1.]) tensor([0.8781, 0.1219], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 42 - 320: dog - cat || Loss: 1.191085696220398\n",
      "tensor([0., 1.]) tensor([0.8778, 0.1222], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 42 - 321: dog - cat || Loss: 1.1907999515533447\n",
      "tensor([0., 1.]) tensor([0.8775, 0.1225], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 42 - 322: dog - cat || Loss: 1.1905137300491333\n",
      "tensor([0., 1.]) tensor([0.8773, 0.1227], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 42 - 323: dog - cat || Loss: 1.1902265548706055\n",
      "tensor([0., 1.]) tensor([0.8770, 0.1230], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 42 - 324: dog - cat || Loss: 1.1899387836456299\n",
      "tensor([0., 1.]) tensor([0.8767, 0.1233], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 42 - 325: dog - cat || Loss: 1.189650535583496\n",
      "tensor([0., 1.]) tensor([0.8764, 0.1236], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 42 - 326: dog - cat || Loss: 1.189361333847046\n",
      "tensor([0., 1.]) tensor([0.8761, 0.1239], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 42 - 327: dog - cat || Loss: 1.1890716552734375\n",
      "tensor([0., 1.]) tensor([0.8758, 0.1242], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 42 - 328: dog - cat || Loss: 1.1887812614440918\n",
      "tensor([0., 1.]) tensor([0.8755, 0.1245], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 42 - 329: dog - cat || Loss: 1.1884901523590088\n",
      "tensor([0., 1.]) tensor([0.8752, 0.1248], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 42 - 330: dog - cat || Loss: 1.1881980895996094\n",
      "tensor([0., 1.]) tensor([0.8749, 0.1251], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 42 - 331: dog - cat || Loss: 1.1879055500030518\n",
      "tensor([0., 1.]) tensor([0.8746, 0.1254], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 42 - 332: dog - cat || Loss: 1.1876124143600464\n",
      "tensor([0., 1.]) tensor([0.8744, 0.1256], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 42 - 333: dog - cat || Loss: 1.1873184442520142\n",
      "tensor([0., 1.]) tensor([0.8741, 0.1259], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 42 - 334: dog - cat || Loss: 1.1870237588882446\n",
      "tensor([0., 1.]) tensor([0.8738, 0.1262], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 42 - 335: dog - cat || Loss: 1.186728596687317\n",
      "tensor([0., 1.]) tensor([0.8735, 0.1265], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 42 - 336: dog - cat || Loss: 1.1864324808120728\n",
      "tensor([0., 1.]) tensor([0.8732, 0.1268], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 42 - 337: dog - cat || Loss: 1.1861358880996704\n",
      "tensor([0., 1.]) tensor([0.8729, 0.1271], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 42 - 338: dog - cat || Loss: 1.1858384609222412\n",
      "tensor([0., 1.]) tensor([0.8726, 0.1274], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 42 - 339: dog - cat || Loss: 1.1855404376983643\n",
      "tensor([0., 1.]) tensor([0.8723, 0.1277], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 42 - 340: dog - cat || Loss: 1.1852415800094604\n",
      "tensor([0., 1.]) tensor([0.8720, 0.1280], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 42 - 341: dog - cat || Loss: 1.1849421262741089\n",
      "tensor([0., 1.]) tensor([0.8717, 0.1283], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 42 - 342: dog - cat || Loss: 1.1846418380737305\n",
      "tensor([0., 1.]) tensor([0.8714, 0.1286], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 42 - 343: dog - cat || Loss: 1.1843410730361938\n",
      "tensor([0., 1.]) tensor([0.8711, 0.1289], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 42 - 344: dog - cat || Loss: 1.1840394735336304\n",
      "tensor([0., 1.]) tensor([0.8708, 0.1292], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 42 - 345: dog - cat || Loss: 1.18373703956604\n",
      "tensor([0., 1.]) tensor([0.8705, 0.1295], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 42 - 346: dog - cat || Loss: 1.183434009552002\n",
      "tensor([0., 1.]) tensor([0.8702, 0.1298], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 42 - 347: dog - cat || Loss: 1.1831302642822266\n",
      "tensor([0., 1.]) tensor([0.8699, 0.1301], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 42 - 348: dog - cat || Loss: 1.1828258037567139\n",
      "tensor([0., 1.]) tensor([0.8696, 0.1304], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 42 - 349: dog - cat || Loss: 1.1825207471847534\n",
      "tensor([0., 1.]) tensor([0.8693, 0.1307], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 42 - 350: dog - cat || Loss: 1.1822148561477661\n",
      "tensor([0., 1.]) tensor([0.8690, 0.1310], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 42 - 351: dog - cat || Loss: 1.1819082498550415\n",
      "tensor([0., 1.]) tensor([0.8686, 0.1314], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 42 - 352: dog - cat || Loss: 1.1816010475158691\n",
      "tensor([0., 1.]) tensor([0.8683, 0.1317], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 42 - 353: dog - cat || Loss: 1.1812928915023804\n",
      "tensor([0., 1.]) tensor([0.8680, 0.1320], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 42 - 354: dog - cat || Loss: 1.1809841394424438\n",
      "tensor([0., 1.]) tensor([0.8677, 0.1323], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 42 - 355: dog - cat || Loss: 1.18067467212677\n",
      "tensor([0., 1.]) tensor([0.8674, 0.1326], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 42 - 356: dog - cat || Loss: 1.1803646087646484\n",
      "tensor([0., 1.]) tensor([0.8671, 0.1329], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 42 - 357: dog - cat || Loss: 1.1800538301467896\n",
      "tensor([0., 1.]) tensor([0.8668, 0.1332], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 42 - 358: dog - cat || Loss: 1.1797422170639038\n",
      "tensor([0., 1.]) tensor([0.8665, 0.1335], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 42 - 359: dog - cat || Loss: 1.1794297695159912\n",
      "tensor([0., 1.]) tensor([0.8662, 0.1338], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 42 - 360: dog - cat || Loss: 1.1791166067123413\n",
      "tensor([0., 1.]) tensor([0.8659, 0.1341], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 42 - 361: dog - cat || Loss: 1.1788028478622437\n",
      "tensor([0., 1.]) tensor([0.8655, 0.1345], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 42 - 362: dog - cat || Loss: 1.1784883737564087\n",
      "tensor([0., 1.]) tensor([0.8652, 0.1348], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 42 - 363: dog - cat || Loss: 1.1781731843948364\n",
      "tensor([0., 1.]) tensor([0.8649, 0.1351], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 42 - 364: dog - cat || Loss: 1.1778572797775269\n",
      "tensor([0., 1.]) tensor([0.8646, 0.1354], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 42 - 365: dog - cat || Loss: 1.17754065990448\n",
      "tensor([0., 1.]) tensor([0.8643, 0.1357], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 42 - 366: dog - cat || Loss: 1.1772229671478271\n",
      "tensor([0., 1.]) tensor([0.8640, 0.1360], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 42 - 367: dog - cat || Loss: 1.1769047975540161\n",
      "tensor([0., 1.]) tensor([0.8636, 0.1364], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 42 - 368: dog - cat || Loss: 1.1765859127044678\n",
      "tensor([0., 1.]) tensor([0.8633, 0.1367], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 42 - 369: dog - cat || Loss: 1.1762661933898926\n",
      "tensor([0., 1.]) tensor([0.8630, 0.1370], grad_fn=<SoftmaxBackward0>)\n",
      "=====epoch:43=====\n",
      "Epoch 43 - 0: cat - cat || Loss: 0.4505775272846222\n",
      "tensor([1., 0.]) tensor([0.8627, 0.1373], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 43 - 1: cat - cat || Loss: 0.45083367824554443\n",
      "tensor([1., 0.]) tensor([0.8624, 0.1376], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 43 - 2: cat - cat || Loss: 0.45103204250335693\n",
      "tensor([1., 0.]) tensor([0.8622, 0.1378], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 43 - 3: cat - cat || Loss: 0.45117801427841187\n",
      "tensor([1., 0.]) tensor([0.8621, 0.1379], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 43 - 4: cat - cat || Loss: 0.45127689838409424\n",
      "tensor([1., 0.]) tensor([0.8620, 0.1380], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 43 - 5: cat - cat || Loss: 0.45133331418037415\n",
      "tensor([1., 0.]) tensor([0.8619, 0.1381], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 43 - 6: cat - cat || Loss: 0.45135149359703064\n",
      "tensor([1., 0.]) tensor([0.8619, 0.1381], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 43 - 7: cat - cat || Loss: 0.45133519172668457\n",
      "tensor([1., 0.]) tensor([0.8619, 0.1381], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 43 - 8: cat - cat || Loss: 0.4512879550457001\n",
      "tensor([1., 0.]) tensor([0.8620, 0.1380], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 43 - 9: cat - cat || Loss: 0.4512128233909607\n",
      "tensor([1., 0.]) tensor([0.8620, 0.1380], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 43 - 10: cat - cat || Loss: 0.4511125981807709\n",
      "tensor([1., 0.]) tensor([0.8621, 0.1379], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 43 - 11: cat - cat || Loss: 0.4509900212287903\n",
      "tensor([1., 0.]) tensor([0.8623, 0.1377], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 43 - 12: cat - cat || Loss: 0.45084714889526367\n",
      "tensor([1., 0.]) tensor([0.8624, 0.1376], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 43 - 13: cat - cat || Loss: 0.45068615674972534\n",
      "tensor([1., 0.]) tensor([0.8626, 0.1374], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 43 - 14: cat - cat || Loss: 0.4505089521408081\n",
      "tensor([1., 0.]) tensor([0.8628, 0.1372], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 43 - 15: cat - cat || Loss: 0.4503172039985657\n",
      "tensor([1., 0.]) tensor([0.8629, 0.1371], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 43 - 16: cat - cat || Loss: 0.45011237263679504\n",
      "tensor([1., 0.]) tensor([0.8631, 0.1369], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 43 - 17: cat - cat || Loss: 0.44989585876464844\n",
      "tensor([1., 0.]) tensor([0.8634, 0.1366], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 43 - 18: cat - cat || Loss: 0.44966885447502136\n",
      "tensor([1., 0.]) tensor([0.8636, 0.1364], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 43 - 19: cat - cat || Loss: 0.4494325518608093\n",
      "tensor([1., 0.]) tensor([0.8638, 0.1362], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 43 - 20: cat - cat || Loss: 0.44918787479400635\n",
      "tensor([1., 0.]) tensor([0.8641, 0.1359], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 43 - 21: cat - cat || Loss: 0.4489358961582184\n",
      "tensor([1., 0.]) tensor([0.8643, 0.1357], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 43 - 22: cat - cat || Loss: 0.44867730140686035\n",
      "tensor([1., 0.]) tensor([0.8646, 0.1354], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 43 - 23: cat - cat || Loss: 0.44841280579566956\n",
      "tensor([1., 0.]) tensor([0.8648, 0.1352], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 43 - 24: cat - cat || Loss: 0.4481430649757385\n",
      "tensor([1., 0.]) tensor([0.8651, 0.1349], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 43 - 25: cat - cat || Loss: 0.4478687644004822\n",
      "tensor([1., 0.]) tensor([0.8654, 0.1346], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 43 - 26: cat - cat || Loss: 0.4475904703140259\n",
      "tensor([1., 0.]) tensor([0.8657, 0.1343], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 43 - 27: cat - cat || Loss: 0.44730839133262634\n",
      "tensor([1., 0.]) tensor([0.8660, 0.1340], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 43 - 28: cat - cat || Loss: 0.44702327251434326\n",
      "tensor([1., 0.]) tensor([0.8662, 0.1338], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 43 - 29: cat - cat || Loss: 0.4467352032661438\n",
      "tensor([1., 0.]) tensor([0.8665, 0.1335], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 43 - 30: cat - cat || Loss: 0.44644492864608765\n",
      "tensor([1., 0.]) tensor([0.8668, 0.1332], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 43 - 31: cat - cat || Loss: 0.44615238904953003\n",
      "tensor([1., 0.]) tensor([0.8671, 0.1329], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 43 - 32: cat - cat || Loss: 0.4458580017089844\n",
      "tensor([1., 0.]) tensor([0.8674, 0.1326], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 43 - 33: cat - cat || Loss: 0.4455622434616089\n",
      "tensor([1., 0.]) tensor([0.8677, 0.1323], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 43 - 34: cat - cat || Loss: 0.445264995098114\n",
      "tensor([1., 0.]) tensor([0.8680, 0.1320], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 43 - 35: cat - cat || Loss: 0.4449666738510132\n",
      "tensor([1., 0.]) tensor([0.8683, 0.1317], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 43 - 36: cat - cat || Loss: 0.44466733932495117\n",
      "tensor([1., 0.]) tensor([0.8686, 0.1314], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 43 - 37: cat - cat || Loss: 0.44436734914779663\n",
      "tensor([1., 0.]) tensor([0.8689, 0.1311], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 43 - 38: cat - cat || Loss: 0.4440666437149048\n",
      "tensor([1., 0.]) tensor([0.8692, 0.1308], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 43 - 39: cat - cat || Loss: 0.44376540184020996\n",
      "tensor([1., 0.]) tensor([0.8695, 0.1305], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 43 - 40: cat - cat || Loss: 0.4434640407562256\n",
      "tensor([1., 0.]) tensor([0.8698, 0.1302], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 43 - 41: cat - cat || Loss: 0.443162202835083\n",
      "tensor([1., 0.]) tensor([0.8701, 0.1299], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 43 - 42: cat - cat || Loss: 0.44286027550697327\n",
      "tensor([1., 0.]) tensor([0.8704, 0.1296], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 43 - 43: cat - cat || Loss: 0.4425581395626068\n",
      "tensor([1., 0.]) tensor([0.8707, 0.1293], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 43 - 44: cat - cat || Loss: 0.44225627183914185\n",
      "tensor([1., 0.]) tensor([0.8710, 0.1290], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 43 - 45: cat - cat || Loss: 0.4419543147087097\n",
      "tensor([1., 0.]) tensor([0.8713, 0.1287], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 43 - 46: cat - cat || Loss: 0.4416525363922119\n",
      "tensor([1., 0.]) tensor([0.8716, 0.1284], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 43 - 47: cat - cat || Loss: 0.4413509666919708\n",
      "tensor([1., 0.]) tensor([0.8719, 0.1281], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 43 - 48: cat - cat || Loss: 0.4410496950149536\n",
      "tensor([1., 0.]) tensor([0.8722, 0.1278], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 43 - 49: cat - cat || Loss: 0.4407486915588379\n",
      "tensor([1., 0.]) tensor([0.8725, 0.1275], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 43 - 50: cat - cat || Loss: 0.44044798612594604\n",
      "tensor([1., 0.]) tensor([0.8728, 0.1272], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 43 - 51: cat - cat || Loss: 0.44014784693717957\n",
      "tensor([1., 0.]) tensor([0.8731, 0.1269], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 43 - 52: cat - cat || Loss: 0.4398479461669922\n",
      "tensor([1., 0.]) tensor([0.8734, 0.1266], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 43 - 53: cat - cat || Loss: 0.4395484924316406\n",
      "tensor([1., 0.]) tensor([0.8737, 0.1263], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 43 - 54: cat - cat || Loss: 0.43924960494041443\n",
      "tensor([1., 0.]) tensor([0.8740, 0.1260], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 43 - 55: cat - cat || Loss: 0.43895119428634644\n",
      "tensor([1., 0.]) tensor([0.8743, 0.1257], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 43 - 56: cat - cat || Loss: 0.4386533200740814\n",
      "tensor([1., 0.]) tensor([0.8746, 0.1254], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 43 - 57: cat - cat || Loss: 0.4383559226989746\n",
      "tensor([1., 0.]) tensor([0.8749, 0.1251], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 43 - 58: cat - cat || Loss: 0.4380592107772827\n",
      "tensor([1., 0.]) tensor([0.8752, 0.1248], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 43 - 59: cat - cat || Loss: 0.4377630352973938\n",
      "tensor([1., 0.]) tensor([0.8755, 0.1245], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 43 - 60: cat - cat || Loss: 0.43746742606163025\n",
      "tensor([1., 0.]) tensor([0.8758, 0.1242], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 43 - 61: cat - cat || Loss: 0.4371723532676697\n",
      "tensor([1., 0.]) tensor([0.8761, 0.1239], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 43 - 62: cat - cat || Loss: 0.43687793612480164\n",
      "tensor([1., 0.]) tensor([0.8764, 0.1236], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 43 - 63: cat - cat || Loss: 0.4365842044353485\n",
      "tensor([1., 0.]) tensor([0.8767, 0.1233], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 43 - 64: cat - cat || Loss: 0.436290979385376\n",
      "tensor([1., 0.]) tensor([0.8770, 0.1230], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 43 - 65: cat - cat || Loss: 0.43599843978881836\n",
      "tensor([1., 0.]) tensor([0.8773, 0.1227], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 43 - 66: cat - cat || Loss: 0.4357064962387085\n",
      "tensor([1., 0.]) tensor([0.8776, 0.1224], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 43 - 67: cat - cat || Loss: 0.4354153573513031\n",
      "tensor([1., 0.]) tensor([0.8778, 0.1222], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 43 - 68: cat - cat || Loss: 0.4351246953010559\n",
      "tensor([1., 0.]) tensor([0.8781, 0.1219], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 43 - 69: cat - cat || Loss: 0.4348347783088684\n",
      "tensor([1., 0.]) tensor([0.8784, 0.1216], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 43 - 70: cat - cat || Loss: 0.43454551696777344\n",
      "tensor([1., 0.]) tensor([0.8787, 0.1213], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 43 - 71: cat - cat || Loss: 0.434256911277771\n",
      "tensor([1., 0.]) tensor([0.8790, 0.1210], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 43 - 72: cat - cat || Loss: 0.4339689314365387\n",
      "tensor([1., 0.]) tensor([0.8793, 0.1207], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 43 - 73: cat - cat || Loss: 0.43368157744407654\n",
      "tensor([1., 0.]) tensor([0.8796, 0.1204], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 43 - 74: cat - cat || Loss: 0.4333949685096741\n",
      "tensor([1., 0.]) tensor([0.8799, 0.1201], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 43 - 75: cat - cat || Loss: 0.4331090450286865\n",
      "tensor([1., 0.]) tensor([0.8802, 0.1198], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 43 - 76: cat - cat || Loss: 0.4328238368034363\n",
      "tensor([1., 0.]) tensor([0.8804, 0.1196], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 43 - 77: cat - cat || Loss: 0.43253928422927856\n",
      "tensor([1., 0.]) tensor([0.8807, 0.1193], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 43 - 78: cat - cat || Loss: 0.4322553277015686\n",
      "tensor([1., 0.]) tensor([0.8810, 0.1190], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 43 - 79: cat - cat || Loss: 0.43197208642959595\n",
      "tensor([1., 0.]) tensor([0.8813, 0.1187], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 43 - 80: cat - cat || Loss: 0.4316895008087158\n",
      "tensor([1., 0.]) tensor([0.8816, 0.1184], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 43 - 81: cat - cat || Loss: 0.4314075708389282\n",
      "tensor([1., 0.]) tensor([0.8819, 0.1181], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 43 - 82: cat - cat || Loss: 0.4311264157295227\n",
      "tensor([1., 0.]) tensor([0.8821, 0.1179], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 43 - 83: cat - cat || Loss: 0.43084588646888733\n",
      "tensor([1., 0.]) tensor([0.8824, 0.1176], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 43 - 84: cat - cat || Loss: 0.43056613206863403\n",
      "tensor([1., 0.]) tensor([0.8827, 0.1173], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 43 - 85: cat - cat || Loss: 0.4302869439125061\n",
      "tensor([1., 0.]) tensor([0.8830, 0.1170], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 43 - 86: cat - cat || Loss: 0.4300084710121155\n",
      "tensor([1., 0.]) tensor([0.8833, 0.1167], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 43 - 87: cat - cat || Loss: 0.42973068356513977\n",
      "tensor([1., 0.]) tensor([0.8835, 0.1165], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 43 - 88: cat - cat || Loss: 0.4294535517692566\n",
      "tensor([1., 0.]) tensor([0.8838, 0.1162], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 43 - 89: cat - cat || Loss: 0.42917710542678833\n",
      "tensor([1., 0.]) tensor([0.8841, 0.1159], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 43 - 90: cat - cat || Loss: 0.4289013147354126\n",
      "tensor([1., 0.]) tensor([0.8844, 0.1156], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 43 - 91: cat - cat || Loss: 0.4286262094974518\n",
      "tensor([1., 0.]) tensor([0.8846, 0.1154], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 43 - 92: cat - cat || Loss: 0.4283517599105835\n",
      "tensor([1., 0.]) tensor([0.8849, 0.1151], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 43 - 93: cat - cat || Loss: 0.4280781149864197\n",
      "tensor([1., 0.]) tensor([0.8852, 0.1148], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 43 - 94: cat - cat || Loss: 0.42780497670173645\n",
      "tensor([1., 0.]) tensor([0.8855, 0.1145], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 43 - 95: cat - cat || Loss: 0.4275325536727905\n",
      "tensor([1., 0.]) tensor([0.8857, 0.1143], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 43 - 96: cat - cat || Loss: 0.4272608160972595\n",
      "tensor([1., 0.]) tensor([0.8860, 0.1140], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 43 - 97: cat - cat || Loss: 0.4269897937774658\n",
      "tensor([1., 0.]) tensor([0.8863, 0.1137], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 43 - 98: cat - cat || Loss: 0.4267193078994751\n",
      "tensor([1., 0.]) tensor([0.8865, 0.1135], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 43 - 99: cat - cat || Loss: 0.42644965648651123\n",
      "tensor([1., 0.]) tensor([0.8868, 0.1132], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 43 - 100: cat - cat || Loss: 0.42618054151535034\n",
      "tensor([1., 0.]) tensor([0.8871, 0.1129], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 43 - 101: cat - cat || Loss: 0.42591214179992676\n",
      "tensor([1., 0.]) tensor([0.8873, 0.1127], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 43 - 102: cat - cat || Loss: 0.4256444573402405\n",
      "tensor([1., 0.]) tensor([0.8876, 0.1124], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 43 - 103: cat - cat || Loss: 0.4253773093223572\n",
      "tensor([1., 0.]) tensor([0.8879, 0.1121], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 43 - 104: cat - cat || Loss: 0.4251108467578888\n",
      "tensor([1., 0.]) tensor([0.8882, 0.1118], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 43 - 105: cat - cat || Loss: 0.4248451888561249\n",
      "tensor([1., 0.]) tensor([0.8884, 0.1116], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 43 - 106: cat - cat || Loss: 0.42458003759384155\n",
      "tensor([1., 0.]) tensor([0.8887, 0.1113], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 43 - 107: cat - cat || Loss: 0.4243156313896179\n",
      "tensor([1., 0.]) tensor([0.8889, 0.1111], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 43 - 108: cat - cat || Loss: 0.4240518808364868\n",
      "tensor([1., 0.]) tensor([0.8892, 0.1108], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 43 - 109: cat - cat || Loss: 0.42378878593444824\n",
      "tensor([1., 0.]) tensor([0.8895, 0.1105], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 43 - 110: cat - cat || Loss: 0.4235262870788574\n",
      "tensor([1., 0.]) tensor([0.8897, 0.1103], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 43 - 111: cat - cat || Loss: 0.4232645034790039\n",
      "tensor([1., 0.]) tensor([0.8900, 0.1100], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 43 - 112: cat - cat || Loss: 0.42300325632095337\n",
      "tensor([1., 0.]) tensor([0.8903, 0.1097], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 43 - 113: cat - cat || Loss: 0.4227427840232849\n",
      "tensor([1., 0.]) tensor([0.8905, 0.1095], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 43 - 114: cat - cat || Loss: 0.42248284816741943\n",
      "tensor([1., 0.]) tensor([0.8908, 0.1092], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 43 - 115: cat - cat || Loss: 0.42222368717193604\n",
      "tensor([1., 0.]) tensor([0.8910, 0.1090], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 43 - 116: cat - cat || Loss: 0.4219651222229004\n",
      "tensor([1., 0.]) tensor([0.8913, 0.1087], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 43 - 117: cat - cat || Loss: 0.4217071533203125\n",
      "tensor([1., 0.]) tensor([0.8916, 0.1084], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 43 - 118: cat - cat || Loss: 0.42144984006881714\n",
      "tensor([1., 0.]) tensor([0.8918, 0.1082], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 43 - 119: cat - cat || Loss: 0.4211932420730591\n",
      "tensor([1., 0.]) tensor([0.8921, 0.1079], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 43 - 120: cat - cat || Loss: 0.420937180519104\n",
      "tensor([1., 0.]) tensor([0.8923, 0.1077], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 43 - 121: cat - cat || Loss: 0.42068177461624146\n",
      "tensor([1., 0.]) tensor([0.8926, 0.1074], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 43 - 122: cat - cat || Loss: 0.42042702436447144\n",
      "tensor([1., 0.]) tensor([0.8928, 0.1072], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 43 - 123: cat - cat || Loss: 0.42017295956611633\n",
      "tensor([1., 0.]) tensor([0.8931, 0.1069], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 43 - 124: cat - cat || Loss: 0.4199194014072418\n",
      "tensor([1., 0.]) tensor([0.8933, 0.1067], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 43 - 125: cat - cat || Loss: 0.4196666181087494\n",
      "tensor([1., 0.]) tensor([0.8936, 0.1064], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 43 - 126: cat - cat || Loss: 0.4194144010543823\n",
      "tensor([1., 0.]) tensor([0.8938, 0.1062], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 43 - 127: cat - cat || Loss: 0.4191627502441406\n",
      "tensor([1., 0.]) tensor([0.8941, 0.1059], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 43 - 128: cat - cat || Loss: 0.41891181468963623\n",
      "tensor([1., 0.]) tensor([0.8943, 0.1057], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 43 - 129: cat - cat || Loss: 0.4186614751815796\n",
      "tensor([1., 0.]) tensor([0.8946, 0.1054], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 43 - 130: cat - cat || Loss: 0.41841185092926025\n",
      "tensor([1., 0.]) tensor([0.8948, 0.1052], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 43 - 131: cat - cat || Loss: 0.4181627035140991\n",
      "tensor([1., 0.]) tensor([0.8951, 0.1049], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 43 - 132: cat - cat || Loss: 0.4179142415523529\n",
      "tensor([1., 0.]) tensor([0.8953, 0.1047], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 43 - 133: cat - cat || Loss: 0.417666494846344\n",
      "tensor([1., 0.]) tensor([0.8956, 0.1044], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 43 - 134: cat - cat || Loss: 0.4174191951751709\n",
      "tensor([1., 0.]) tensor([0.8958, 0.1042], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 43 - 135: cat - cat || Loss: 0.4171726703643799\n",
      "tensor([1., 0.]) tensor([0.8961, 0.1039], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 43 - 136: cat - cat || Loss: 0.41692668199539185\n",
      "tensor([1., 0.]) tensor([0.8963, 0.1037], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 43 - 137: cat - cat || Loss: 0.4166812300682068\n",
      "tensor([1., 0.]) tensor([0.8966, 0.1034], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 43 - 138: cat - cat || Loss: 0.4164365530014038\n",
      "tensor([1., 0.]) tensor([0.8968, 0.1032], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 43 - 139: cat - cat || Loss: 0.4161924123764038\n",
      "tensor([1., 0.]) tensor([0.8971, 0.1029], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 43 - 140: cat - cat || Loss: 0.4159488081932068\n",
      "tensor([1., 0.]) tensor([0.8973, 0.1027], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 43 - 141: cat - cat || Loss: 0.41570591926574707\n",
      "tensor([1., 0.]) tensor([0.8976, 0.1024], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 43 - 142: cat - cat || Loss: 0.4154636263847351\n",
      "tensor([1., 0.]) tensor([0.8978, 0.1022], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 43 - 143: cat - cat || Loss: 0.4152219593524933\n",
      "tensor([1., 0.]) tensor([0.8980, 0.1020], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 43 - 144: cat - cat || Loss: 0.41498082876205444\n",
      "tensor([1., 0.]) tensor([0.8983, 0.1017], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 43 - 145: cat - cat || Loss: 0.41474032402038574\n",
      "tensor([1., 0.]) tensor([0.8985, 0.1015], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 43 - 146: cat - cat || Loss: 0.41450047492980957\n",
      "tensor([1., 0.]) tensor([0.8988, 0.1012], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 43 - 147: cat - cat || Loss: 0.41426122188568115\n",
      "tensor([1., 0.]) tensor([0.8990, 0.1010], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 43 - 148: cat - cat || Loss: 0.4140225052833557\n",
      "tensor([1., 0.]) tensor([0.8992, 0.1008], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 43 - 149: cat - cat || Loss: 0.4137845039367676\n",
      "tensor([1., 0.]) tensor([0.8995, 0.1005], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 43 - 150: cat - cat || Loss: 0.41354697942733765\n",
      "tensor([1., 0.]) tensor([0.8997, 0.1003], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 43 - 151: cat - cat || Loss: 0.41331011056900024\n",
      "tensor([1., 0.]) tensor([0.9000, 0.1000], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 43 - 152: cat - cat || Loss: 0.4130738377571106\n",
      "tensor([1., 0.]) tensor([0.9002, 0.0998], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 43 - 153: cat - cat || Loss: 0.4128381013870239\n",
      "tensor([1., 0.]) tensor([0.9004, 0.0996], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 43 - 154: cat - cat || Loss: 0.4126030206680298\n",
      "tensor([1., 0.]) tensor([0.9007, 0.0993], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 43 - 155: cat - cat || Loss: 0.4123685359954834\n",
      "tensor([1., 0.]) tensor([0.9009, 0.0991], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 43 - 156: cat - cat || Loss: 0.41213458776474\n",
      "tensor([1., 0.]) tensor([0.9011, 0.0989], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 43 - 157: cat - cat || Loss: 0.41190141439437866\n",
      "tensor([1., 0.]) tensor([0.9014, 0.0986], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 43 - 158: cat - cat || Loss: 0.411668598651886\n",
      "tensor([1., 0.]) tensor([0.9016, 0.0984], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 43 - 159: cat - cat || Loss: 0.41143643856048584\n",
      "tensor([1., 0.]) tensor([0.9018, 0.0982], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 43 - 160: cat - cat || Loss: 0.41120487451553345\n",
      "tensor([1., 0.]) tensor([0.9021, 0.0979], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 43 - 161: cat - cat || Loss: 0.4109739661216736\n",
      "tensor([1., 0.]) tensor([0.9023, 0.0977], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 43 - 162: cat - cat || Loss: 0.4107435941696167\n",
      "tensor([1., 0.]) tensor([0.9025, 0.0975], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 43 - 163: cat - cat || Loss: 0.410513699054718\n",
      "tensor([1., 0.]) tensor([0.9027, 0.0973], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 43 - 164: cat - cat || Loss: 0.41028451919555664\n",
      "tensor([1., 0.]) tensor([0.9030, 0.0970], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 43 - 165: cat - cat || Loss: 0.41005587577819824\n",
      "tensor([1., 0.]) tensor([0.9032, 0.0968], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 43 - 166: cat - cat || Loss: 0.4098278284072876\n",
      "tensor([1., 0.]) tensor([0.9034, 0.0966], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 43 - 167: cat - cat || Loss: 0.40960031747817993\n",
      "tensor([1., 0.]) tensor([0.9037, 0.0963], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 43 - 168: cat - cat || Loss: 0.4093734622001648\n",
      "tensor([1., 0.]) tensor([0.9039, 0.0961], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 43 - 169: cat - cat || Loss: 0.4091470241546631\n",
      "tensor([1., 0.]) tensor([0.9041, 0.0959], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 43 - 170: cat - cat || Loss: 0.4089213013648987\n",
      "tensor([1., 0.]) tensor([0.9043, 0.0957], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 43 - 171: cat - cat || Loss: 0.40869617462158203\n",
      "tensor([1., 0.]) tensor([0.9046, 0.0954], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 43 - 172: cat - cat || Loss: 0.4084714651107788\n",
      "tensor([1., 0.]) tensor([0.9048, 0.0952], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 43 - 173: cat - cat || Loss: 0.4082474708557129\n",
      "tensor([1., 0.]) tensor([0.9050, 0.0950], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 43 - 174: cat - cat || Loss: 0.40802401304244995\n",
      "tensor([1., 0.]) tensor([0.9052, 0.0948], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 43 - 175: cat - cat || Loss: 0.40780109167099\n",
      "tensor([1., 0.]) tensor([0.9055, 0.0945], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 43 - 176: cat - cat || Loss: 0.4075787365436554\n",
      "tensor([1., 0.]) tensor([0.9057, 0.0943], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 43 - 177: cat - cat || Loss: 0.40735700726509094\n",
      "tensor([1., 0.]) tensor([0.9059, 0.0941], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 43 - 178: cat - cat || Loss: 0.4071356952190399\n",
      "tensor([1., 0.]) tensor([0.9061, 0.0939], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 43 - 179: cat - cat || Loss: 0.4069150686264038\n",
      "tensor([1., 0.]) tensor([0.9063, 0.0937], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 43 - 180: cat - cat || Loss: 0.4066949486732483\n",
      "tensor([1., 0.]) tensor([0.9066, 0.0934], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 43 - 181: cat - cat || Loss: 0.4064754545688629\n",
      "tensor([1., 0.]) tensor([0.9068, 0.0932], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 43 - 182: cat - cat || Loss: 0.4062564969062805\n",
      "tensor([1., 0.]) tensor([0.9070, 0.0930], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 43 - 183: cat - cat || Loss: 0.40603816509246826\n",
      "tensor([1., 0.]) tensor([0.9072, 0.0928], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 43 - 184: cat - cat || Loss: 0.4058203101158142\n",
      "tensor([1., 0.]) tensor([0.9074, 0.0926], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 43 - 185: cat - cat || Loss: 0.4056031405925751\n",
      "tensor([1., 0.]) tensor([0.9077, 0.0923], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 43 - 186: cat - cat || Loss: 0.4053863286972046\n",
      "tensor([1., 0.]) tensor([0.9079, 0.0921], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 43 - 187: cat - cat || Loss: 0.405170202255249\n",
      "tensor([1., 0.]) tensor([0.9081, 0.0919], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 43 - 188: cat - cat || Loss: 0.4049544632434845\n",
      "tensor([1., 0.]) tensor([0.9083, 0.0917], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 43 - 189: cat - cat || Loss: 0.4047393202781677\n",
      "tensor([1., 0.]) tensor([0.9085, 0.0915], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 43 - 190: dog - cat || Loss: 1.2219988107681274\n",
      "tensor([0., 1.]) tensor([0.9087, 0.0913], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 43 - 191: dog - cat || Loss: 1.2221704721450806\n",
      "tensor([0., 1.]) tensor([0.9089, 0.0911], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 43 - 192: dog - cat || Loss: 1.2223037481307983\n",
      "tensor([0., 1.]) tensor([0.9090, 0.0910], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 43 - 193: dog - cat || Loss: 1.2224024534225464\n",
      "tensor([0., 1.]) tensor([0.9091, 0.0909], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 43 - 194: dog - cat || Loss: 1.2224701642990112\n",
      "tensor([0., 1.]) tensor([0.9092, 0.0908], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 43 - 195: dog - cat || Loss: 1.2225102186203003\n",
      "tensor([0., 1.]) tensor([0.9092, 0.0908], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 43 - 196: dog - cat || Loss: 1.2225247621536255\n",
      "tensor([0., 1.]) tensor([0.9093, 0.0907], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 43 - 197: dog - cat || Loss: 1.2225168943405151\n",
      "tensor([0., 1.]) tensor([0.9093, 0.0907], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 43 - 198: dog - cat || Loss: 1.2224887609481812\n",
      "tensor([0., 1.]) tensor([0.9092, 0.0908], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 43 - 199: dog - cat || Loss: 1.222442388534546\n",
      "tensor([0., 1.]) tensor([0.9092, 0.0908], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 43 - 200: dog - cat || Loss: 1.2223796844482422\n",
      "tensor([0., 1.]) tensor([0.9091, 0.0909], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 43 - 201: dog - cat || Loss: 1.222301959991455\n",
      "tensor([0., 1.]) tensor([0.9090, 0.0910], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 43 - 202: dog - cat || Loss: 1.2222107648849487\n",
      "tensor([0., 1.]) tensor([0.9089, 0.0911], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 43 - 203: dog - cat || Loss: 1.2221076488494873\n",
      "tensor([0., 1.]) tensor([0.9088, 0.0912], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 43 - 204: dog - cat || Loss: 1.2219936847686768\n",
      "tensor([0., 1.]) tensor([0.9087, 0.0913], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 43 - 205: dog - cat || Loss: 1.221869707107544\n",
      "tensor([0., 1.]) tensor([0.9086, 0.0914], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 43 - 206: dog - cat || Loss: 1.2217367887496948\n",
      "tensor([0., 1.]) tensor([0.9085, 0.0915], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 43 - 207: dog - cat || Loss: 1.2215960025787354\n",
      "tensor([0., 1.]) tensor([0.9083, 0.0917], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 43 - 208: dog - cat || Loss: 1.2214478254318237\n",
      "tensor([0., 1.]) tensor([0.9082, 0.0918], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 43 - 209: dog - cat || Loss: 1.2212930917739868\n",
      "tensor([0., 1.]) tensor([0.9080, 0.0920], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 43 - 210: dog - cat || Loss: 1.2211322784423828\n",
      "tensor([0., 1.]) tensor([0.9079, 0.0921], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 43 - 211: dog - cat || Loss: 1.2209662199020386\n",
      "tensor([0., 1.]) tensor([0.9077, 0.0923], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 43 - 212: dog - cat || Loss: 1.220794916152954\n",
      "tensor([0., 1.]) tensor([0.9075, 0.0925], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 43 - 213: dog - cat || Loss: 1.2206193208694458\n",
      "tensor([0., 1.]) tensor([0.9074, 0.0926], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 43 - 214: dog - cat || Loss: 1.2204393148422241\n",
      "tensor([0., 1.]) tensor([0.9072, 0.0928], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 43 - 215: dog - cat || Loss: 1.2202558517456055\n",
      "tensor([0., 1.]) tensor([0.9070, 0.0930], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 43 - 216: dog - cat || Loss: 1.2200689315795898\n",
      "tensor([0., 1.]) tensor([0.9068, 0.0932], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 43 - 217: dog - cat || Loss: 1.2198786735534668\n",
      "tensor([0., 1.]) tensor([0.9066, 0.0934], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 43 - 218: dog - cat || Loss: 1.219685673713684\n",
      "tensor([0., 1.]) tensor([0.9064, 0.0936], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 43 - 219: dog - cat || Loss: 1.2194898128509521\n",
      "tensor([0., 1.]) tensor([0.9062, 0.0938], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 43 - 220: dog - cat || Loss: 1.2192918062210083\n",
      "tensor([0., 1.]) tensor([0.9060, 0.0940], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 43 - 221: dog - cat || Loss: 1.219091534614563\n",
      "tensor([0., 1.]) tensor([0.9058, 0.0942], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 43 - 222: dog - cat || Loss: 1.2188891172409058\n",
      "tensor([0., 1.]) tensor([0.9056, 0.0944], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 43 - 223: dog - cat || Loss: 1.2186846733093262\n",
      "tensor([0., 1.]) tensor([0.9054, 0.0946], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 43 - 224: dog - cat || Loss: 1.2184785604476929\n",
      "tensor([0., 1.]) tensor([0.9052, 0.0948], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 43 - 225: dog - cat || Loss: 1.2182708978652954\n",
      "tensor([0., 1.]) tensor([0.9050, 0.0950], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 43 - 226: dog - cat || Loss: 1.2180614471435547\n",
      "tensor([0., 1.]) tensor([0.9048, 0.0952], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 43 - 227: dog - cat || Loss: 1.217850685119629\n",
      "tensor([0., 1.]) tensor([0.9046, 0.0954], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 43 - 228: dog - cat || Loss: 1.2176384925842285\n",
      "tensor([0., 1.]) tensor([0.9044, 0.0956], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 43 - 229: dog - cat || Loss: 1.2174252271652222\n",
      "tensor([0., 1.]) tensor([0.9042, 0.0958], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 43 - 230: dog - cat || Loss: 1.2172105312347412\n",
      "tensor([0., 1.]) tensor([0.9039, 0.0961], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 43 - 231: dog - cat || Loss: 1.2169947624206543\n",
      "tensor([0., 1.]) tensor([0.9037, 0.0963], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 43 - 232: dog - cat || Loss: 1.216778039932251\n",
      "tensor([0., 1.]) tensor([0.9035, 0.0965], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 43 - 233: dog - cat || Loss: 1.2165601253509521\n",
      "tensor([0., 1.]) tensor([0.9033, 0.0967], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 43 - 234: dog - cat || Loss: 1.216341257095337\n",
      "tensor([0., 1.]) tensor([0.9031, 0.0969], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 43 - 235: dog - cat || Loss: 1.2161215543746948\n",
      "tensor([0., 1.]) tensor([0.9029, 0.0971], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 43 - 236: dog - cat || Loss: 1.2159007787704468\n",
      "tensor([0., 1.]) tensor([0.9026, 0.0974], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 43 - 237: dog - cat || Loss: 1.2156792879104614\n",
      "tensor([0., 1.]) tensor([0.9024, 0.0976], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 43 - 238: dog - cat || Loss: 1.2154568433761597\n",
      "tensor([0., 1.]) tensor([0.9022, 0.0978], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 43 - 239: dog - cat || Loss: 1.215233564376831\n",
      "tensor([0., 1.]) tensor([0.9020, 0.0980], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 43 - 240: dog - cat || Loss: 1.2150095701217651\n",
      "tensor([0., 1.]) tensor([0.9017, 0.0983], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 43 - 241: dog - cat || Loss: 1.214784860610962\n",
      "tensor([0., 1.]) tensor([0.9015, 0.0985], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 43 - 242: dog - cat || Loss: 1.2145594358444214\n",
      "tensor([0., 1.]) tensor([0.9013, 0.0987], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 43 - 243: dog - cat || Loss: 1.2143330574035645\n",
      "tensor([0., 1.]) tensor([0.9011, 0.0989], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 43 - 244: dog - cat || Loss: 1.2141063213348389\n",
      "tensor([0., 1.]) tensor([0.9008, 0.0992], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 43 - 245: dog - cat || Loss: 1.2138787508010864\n",
      "tensor([0., 1.]) tensor([0.9006, 0.0994], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 43 - 246: dog - cat || Loss: 1.2136503458023071\n",
      "tensor([0., 1.]) tensor([0.9004, 0.0996], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 43 - 247: dog - cat || Loss: 1.21342134475708\n",
      "tensor([0., 1.]) tensor([0.9002, 0.0998], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 43 - 248: dog - cat || Loss: 1.2131918668746948\n",
      "tensor([0., 1.]) tensor([0.8999, 0.1001], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 43 - 249: dog - cat || Loss: 1.2129614353179932\n",
      "tensor([0., 1.]) tensor([0.8997, 0.1003], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 43 - 250: dog - cat || Loss: 1.2127305269241333\n",
      "tensor([0., 1.]) tensor([0.8995, 0.1005], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 43 - 251: dog - cat || Loss: 1.2124990224838257\n",
      "tensor([0., 1.]) tensor([0.8992, 0.1008], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 43 - 252: dog - cat || Loss: 1.2122666835784912\n",
      "tensor([0., 1.]) tensor([0.8990, 0.1010], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 43 - 253: dog - cat || Loss: 1.2120338678359985\n",
      "tensor([0., 1.]) tensor([0.8988, 0.1012], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 43 - 254: dog - cat || Loss: 1.211800456047058\n",
      "tensor([0., 1.]) tensor([0.8985, 0.1015], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 43 - 255: dog - cat || Loss: 1.2115663290023804\n",
      "tensor([0., 1.]) tensor([0.8983, 0.1017], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 43 - 256: dog - cat || Loss: 1.2113317251205444\n",
      "tensor([0., 1.]) tensor([0.8981, 0.1019], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 43 - 257: dog - cat || Loss: 1.2110964059829712\n",
      "tensor([0., 1.]) tensor([0.8978, 0.1022], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 43 - 258: dog - cat || Loss: 1.2108603715896606\n",
      "tensor([0., 1.]) tensor([0.8976, 0.1024], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 43 - 259: dog - cat || Loss: 1.210623860359192\n",
      "tensor([0., 1.]) tensor([0.8974, 0.1026], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 43 - 260: dog - cat || Loss: 1.2103866338729858\n",
      "tensor([0., 1.]) tensor([0.8971, 0.1029], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 43 - 261: dog - cat || Loss: 1.2101490497589111\n",
      "tensor([0., 1.]) tensor([0.8969, 0.1031], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 43 - 262: dog - cat || Loss: 1.2099106311798096\n",
      "tensor([0., 1.]) tensor([0.8966, 0.1034], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 43 - 263: dog - cat || Loss: 1.2096717357635498\n",
      "tensor([0., 1.]) tensor([0.8964, 0.1036], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 43 - 264: dog - cat || Loss: 1.2094321250915527\n",
      "tensor([0., 1.]) tensor([0.8962, 0.1038], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 43 - 265: dog - cat || Loss: 1.209191918373108\n",
      "tensor([0., 1.]) tensor([0.8959, 0.1041], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 43 - 266: dog - cat || Loss: 1.2089512348175049\n",
      "tensor([0., 1.]) tensor([0.8957, 0.1043], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 43 - 267: dog - cat || Loss: 1.2087098360061646\n",
      "tensor([0., 1.]) tensor([0.8954, 0.1046], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 43 - 268: dog - cat || Loss: 1.208467960357666\n",
      "tensor([0., 1.]) tensor([0.8952, 0.1048], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 43 - 269: dog - cat || Loss: 1.2082253694534302\n",
      "tensor([0., 1.]) tensor([0.8950, 0.1050], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 43 - 270: dog - cat || Loss: 1.2079823017120361\n",
      "tensor([0., 1.]) tensor([0.8947, 0.1053], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 43 - 271: dog - cat || Loss: 1.2077383995056152\n",
      "tensor([0., 1.]) tensor([0.8945, 0.1055], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 43 - 272: dog - cat || Loss: 1.2074940204620361\n",
      "tensor([0., 1.]) tensor([0.8942, 0.1058], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 43 - 273: dog - cat || Loss: 1.2072489261627197\n",
      "tensor([0., 1.]) tensor([0.8940, 0.1060], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 43 - 274: dog - cat || Loss: 1.2070034742355347\n",
      "tensor([0., 1.]) tensor([0.8937, 0.1063], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 43 - 275: dog - cat || Loss: 1.2067571878433228\n",
      "tensor([0., 1.]) tensor([0.8935, 0.1065], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 43 - 276: dog - cat || Loss: 1.2065105438232422\n",
      "tensor([0., 1.]) tensor([0.8932, 0.1068], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 43 - 277: dog - cat || Loss: 1.2062631845474243\n",
      "tensor([0., 1.]) tensor([0.8930, 0.1070], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 43 - 278: dog - cat || Loss: 1.2060151100158691\n",
      "tensor([0., 1.]) tensor([0.8928, 0.1072], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 43 - 279: dog - cat || Loss: 1.2057665586471558\n",
      "tensor([0., 1.]) tensor([0.8925, 0.1075], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 43 - 280: dog - cat || Loss: 1.2055174112319946\n",
      "tensor([0., 1.]) tensor([0.8923, 0.1077], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 43 - 281: dog - cat || Loss: 1.2052674293518066\n",
      "tensor([0., 1.]) tensor([0.8920, 0.1080], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 43 - 282: dog - cat || Loss: 1.2050172090530396\n",
      "tensor([0., 1.]) tensor([0.8918, 0.1082], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 43 - 283: dog - cat || Loss: 1.2047661542892456\n",
      "tensor([0., 1.]) tensor([0.8915, 0.1085], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 43 - 284: dog - cat || Loss: 1.2045143842697144\n",
      "tensor([0., 1.]) tensor([0.8913, 0.1087], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 43 - 285: dog - cat || Loss: 1.2042622566223145\n",
      "tensor([0., 1.]) tensor([0.8910, 0.1090], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 43 - 286: dog - cat || Loss: 1.2040092945098877\n",
      "tensor([0., 1.]) tensor([0.8907, 0.1093], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 43 - 287: dog - cat || Loss: 1.2037558555603027\n",
      "tensor([0., 1.]) tensor([0.8905, 0.1095], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 43 - 288: dog - cat || Loss: 1.2035017013549805\n",
      "tensor([0., 1.]) tensor([0.8902, 0.1098], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 43 - 289: dog - cat || Loss: 1.2032469511032104\n",
      "tensor([0., 1.]) tensor([0.8900, 0.1100], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 43 - 290: dog - cat || Loss: 1.2029917240142822\n",
      "tensor([0., 1.]) tensor([0.8897, 0.1103], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 43 - 291: dog - cat || Loss: 1.2027356624603271\n",
      "tensor([0., 1.]) tensor([0.8895, 0.1105], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 43 - 292: dog - cat || Loss: 1.2024791240692139\n",
      "tensor([0., 1.]) tensor([0.8892, 0.1108], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 43 - 293: dog - cat || Loss: 1.2022218704223633\n",
      "tensor([0., 1.]) tensor([0.8890, 0.1110], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 43 - 294: dog - cat || Loss: 1.2019641399383545\n",
      "tensor([0., 1.]) tensor([0.8887, 0.1113], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 43 - 295: dog - cat || Loss: 1.2017056941986084\n",
      "tensor([0., 1.]) tensor([0.8884, 0.1116], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 43 - 296: dog - cat || Loss: 1.201446533203125\n",
      "tensor([0., 1.]) tensor([0.8882, 0.1118], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 43 - 297: dog - cat || Loss: 1.2011868953704834\n",
      "tensor([0., 1.]) tensor([0.8879, 0.1121], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 43 - 298: dog - cat || Loss: 1.2009265422821045\n",
      "tensor([0., 1.]) tensor([0.8877, 0.1123], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 43 - 299: dog - cat || Loss: 1.2006657123565674\n",
      "tensor([0., 1.]) tensor([0.8874, 0.1126], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 43 - 300: dog - cat || Loss: 1.2004039287567139\n",
      "tensor([0., 1.]) tensor([0.8871, 0.1129], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 43 - 301: dog - cat || Loss: 1.2001419067382812\n",
      "tensor([0., 1.]) tensor([0.8869, 0.1131], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 43 - 302: dog - cat || Loss: 1.1998789310455322\n",
      "tensor([0., 1.]) tensor([0.8866, 0.1134], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 43 - 303: dog - cat || Loss: 1.1996155977249146\n",
      "tensor([0., 1.]) tensor([0.8864, 0.1136], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 43 - 304: dog - cat || Loss: 1.1993515491485596\n",
      "tensor([0., 1.]) tensor([0.8861, 0.1139], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 43 - 305: dog - cat || Loss: 1.1990866661071777\n",
      "tensor([0., 1.]) tensor([0.8858, 0.1142], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 43 - 306: dog - cat || Loss: 1.1988213062286377\n",
      "tensor([0., 1.]) tensor([0.8856, 0.1144], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 43 - 307: dog - cat || Loss: 1.1985554695129395\n",
      "tensor([0., 1.]) tensor([0.8853, 0.1147], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 43 - 308: dog - cat || Loss: 1.1982886791229248\n",
      "tensor([0., 1.]) tensor([0.8850, 0.1150], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 43 - 309: dog - cat || Loss: 1.198021411895752\n",
      "tensor([0., 1.]) tensor([0.8848, 0.1152], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 43 - 310: dog - cat || Loss: 1.197753667831421\n",
      "tensor([0., 1.]) tensor([0.8845, 0.1155], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 43 - 311: dog - cat || Loss: 1.1974849700927734\n",
      "tensor([0., 1.]) tensor([0.8842, 0.1158], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 43 - 312: dog - cat || Loss: 1.1972157955169678\n",
      "tensor([0., 1.]) tensor([0.8840, 0.1160], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 43 - 313: dog - cat || Loss: 1.1969459056854248\n",
      "tensor([0., 1.]) tensor([0.8837, 0.1163], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 43 - 314: dog - cat || Loss: 1.1966755390167236\n",
      "tensor([0., 1.]) tensor([0.8834, 0.1166], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 43 - 315: dog - cat || Loss: 1.196404218673706\n",
      "tensor([0., 1.]) tensor([0.8831, 0.1169], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 43 - 316: dog - cat || Loss: 1.1961324214935303\n",
      "tensor([0., 1.]) tensor([0.8829, 0.1171], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 43 - 317: dog - cat || Loss: 1.1958600282669067\n",
      "tensor([0., 1.]) tensor([0.8826, 0.1174], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 43 - 318: dog - cat || Loss: 1.195586919784546\n",
      "tensor([0., 1.]) tensor([0.8823, 0.1177], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 43 - 319: dog - cat || Loss: 1.1953132152557373\n",
      "tensor([0., 1.]) tensor([0.8821, 0.1179], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 43 - 320: dog - cat || Loss: 1.1950387954711914\n",
      "tensor([0., 1.]) tensor([0.8818, 0.1182], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 43 - 321: dog - cat || Loss: 1.1947637796401978\n",
      "tensor([0., 1.]) tensor([0.8815, 0.1185], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 43 - 322: dog - cat || Loss: 1.1944881677627563\n",
      "tensor([0., 1.]) tensor([0.8812, 0.1188], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 43 - 323: dog - cat || Loss: 1.1942118406295776\n",
      "tensor([0., 1.]) tensor([0.8810, 0.1190], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 43 - 324: dog - cat || Loss: 1.1939347982406616\n",
      "tensor([0., 1.]) tensor([0.8807, 0.1193], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 43 - 325: dog - cat || Loss: 1.1936570405960083\n",
      "tensor([0., 1.]) tensor([0.8804, 0.1196], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 43 - 326: dog - cat || Loss: 1.1933786869049072\n",
      "tensor([0., 1.]) tensor([0.8801, 0.1199], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 43 - 327: dog - cat || Loss: 1.1930997371673584\n",
      "tensor([0., 1.]) tensor([0.8798, 0.1202], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 43 - 328: dog - cat || Loss: 1.1928201913833618\n",
      "tensor([0., 1.]) tensor([0.8796, 0.1204], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 43 - 329: dog - cat || Loss: 1.1925396919250488\n",
      "tensor([0., 1.]) tensor([0.8793, 0.1207], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 43 - 330: dog - cat || Loss: 1.1922588348388672\n",
      "tensor([0., 1.]) tensor([0.8790, 0.1210], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 43 - 331: dog - cat || Loss: 1.1919770240783691\n",
      "tensor([0., 1.]) tensor([0.8787, 0.1213], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 43 - 332: dog - cat || Loss: 1.1916948556900024\n",
      "tensor([0., 1.]) tensor([0.8784, 0.1216], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 43 - 333: dog - cat || Loss: 1.1914119720458984\n",
      "tensor([0., 1.]) tensor([0.8782, 0.1218], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 43 - 334: dog - cat || Loss: 1.191128134727478\n",
      "tensor([0., 1.]) tensor([0.8779, 0.1221], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 43 - 335: dog - cat || Loss: 1.1908438205718994\n",
      "tensor([0., 1.]) tensor([0.8776, 0.1224], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 43 - 336: dog - cat || Loss: 1.190558910369873\n",
      "tensor([0., 1.]) tensor([0.8773, 0.1227], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 43 - 337: dog - cat || Loss: 1.1902731657028198\n",
      "tensor([0., 1.]) tensor([0.8770, 0.1230], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 43 - 338: dog - cat || Loss: 1.1899867057800293\n",
      "tensor([0., 1.]) tensor([0.8767, 0.1233], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 43 - 339: dog - cat || Loss: 1.1896997690200806\n",
      "tensor([0., 1.]) tensor([0.8764, 0.1236], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 43 - 340: dog - cat || Loss: 1.189412236213684\n",
      "tensor([0., 1.]) tensor([0.8762, 0.1238], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 43 - 341: dog - cat || Loss: 1.1891237497329712\n",
      "tensor([0., 1.]) tensor([0.8759, 0.1241], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 43 - 342: dog - cat || Loss: 1.1888346672058105\n",
      "tensor([0., 1.]) tensor([0.8756, 0.1244], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 43 - 343: dog - cat || Loss: 1.1885448694229126\n",
      "tensor([0., 1.]) tensor([0.8753, 0.1247], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 43 - 344: dog - cat || Loss: 1.188254475593567\n",
      "tensor([0., 1.]) tensor([0.8750, 0.1250], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 43 - 345: dog - cat || Loss: 1.1879632472991943\n",
      "tensor([0., 1.]) tensor([0.8747, 0.1253], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 43 - 346: dog - cat || Loss: 1.1876715421676636\n",
      "tensor([0., 1.]) tensor([0.8744, 0.1256], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 43 - 347: dog - cat || Loss: 1.187379240989685\n",
      "tensor([0., 1.]) tensor([0.8741, 0.1259], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 43 - 348: dog - cat || Loss: 1.1870859861373901\n",
      "tensor([0., 1.]) tensor([0.8738, 0.1262], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 43 - 349: dog - cat || Loss: 1.1867921352386475\n",
      "tensor([0., 1.]) tensor([0.8735, 0.1265], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 43 - 350: dog - cat || Loss: 1.186497449874878\n",
      "tensor([0., 1.]) tensor([0.8732, 0.1268], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 43 - 351: dog - cat || Loss: 1.1862024068832397\n",
      "tensor([0., 1.]) tensor([0.8729, 0.1271], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 43 - 352: dog - cat || Loss: 1.1859064102172852\n",
      "tensor([0., 1.]) tensor([0.8726, 0.1274], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 43 - 353: dog - cat || Loss: 1.1856096982955933\n",
      "tensor([0., 1.]) tensor([0.8723, 0.1277], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 43 - 354: dog - cat || Loss: 1.1853123903274536\n",
      "tensor([0., 1.]) tensor([0.8721, 0.1279], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 43 - 355: dog - cat || Loss: 1.1850143671035767\n",
      "tensor([0., 1.]) tensor([0.8718, 0.1282], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 43 - 356: dog - cat || Loss: 1.184715747833252\n",
      "tensor([0., 1.]) tensor([0.8715, 0.1285], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 43 - 357: dog - cat || Loss: 1.1844162940979004\n",
      "tensor([0., 1.]) tensor([0.8712, 0.1288], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 43 - 358: dog - cat || Loss: 1.184116005897522\n",
      "tensor([0., 1.]) tensor([0.8709, 0.1291], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 43 - 359: dog - cat || Loss: 1.183815360069275\n",
      "tensor([0., 1.]) tensor([0.8706, 0.1294], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 43 - 360: dog - cat || Loss: 1.1835135221481323\n",
      "tensor([0., 1.]) tensor([0.8703, 0.1297], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 43 - 361: dog - cat || Loss: 1.1832115650177002\n",
      "tensor([0., 1.]) tensor([0.8699, 0.1301], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 43 - 362: dog - cat || Loss: 1.182908535003662\n",
      "tensor([0., 1.]) tensor([0.8696, 0.1304], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 43 - 363: dog - cat || Loss: 1.1826049089431763\n",
      "tensor([0., 1.]) tensor([0.8693, 0.1307], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 43 - 364: dog - cat || Loss: 1.1823005676269531\n",
      "tensor([0., 1.]) tensor([0.8690, 0.1310], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 43 - 365: dog - cat || Loss: 1.1819955110549927\n",
      "tensor([0., 1.]) tensor([0.8687, 0.1313], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 43 - 366: dog - cat || Loss: 1.1816896200180054\n",
      "tensor([0., 1.]) tensor([0.8684, 0.1316], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 43 - 367: dog - cat || Loss: 1.1813831329345703\n",
      "tensor([0., 1.]) tensor([0.8681, 0.1319], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 43 - 368: dog - cat || Loss: 1.181075930595398\n",
      "tensor([0., 1.]) tensor([0.8678, 0.1322], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 43 - 369: dog - cat || Loss: 1.1807680130004883\n",
      "tensor([0., 1.]) tensor([0.8675, 0.1325], grad_fn=<SoftmaxBackward0>)\n",
      "=====epoch:44=====\n",
      "Epoch 44 - 0: cat - cat || Loss: 0.44606396555900574\n",
      "tensor([1., 0.]) tensor([0.8672, 0.1328], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 44 - 1: cat - cat || Loss: 0.44631069898605347\n",
      "tensor([1., 0.]) tensor([0.8670, 0.1330], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 44 - 2: cat - cat || Loss: 0.44650179147720337\n",
      "tensor([1., 0.]) tensor([0.8668, 0.1332], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 44 - 3: cat - cat || Loss: 0.4466424286365509\n",
      "tensor([1., 0.]) tensor([0.8666, 0.1334], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 44 - 4: cat - cat || Loss: 0.44673770666122437\n",
      "tensor([1., 0.]) tensor([0.8665, 0.1335], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 44 - 5: cat - cat || Loss: 0.44679203629493713\n",
      "tensor([1., 0.]) tensor([0.8665, 0.1335], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 44 - 6: cat - cat || Loss: 0.4468095302581787\n",
      "tensor([1., 0.]) tensor([0.8665, 0.1335], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 44 - 7: cat - cat || Loss: 0.4467938244342804\n",
      "tensor([1., 0.]) tensor([0.8665, 0.1335], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 44 - 8: cat - cat || Loss: 0.4467483162879944\n",
      "tensor([1., 0.]) tensor([0.8665, 0.1335], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 44 - 9: cat - cat || Loss: 0.44667595624923706\n",
      "tensor([1., 0.]) tensor([0.8666, 0.1334], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 44 - 10: cat - cat || Loss: 0.4465793967247009\n",
      "tensor([1., 0.]) tensor([0.8667, 0.1333], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 44 - 11: cat - cat || Loss: 0.4464613199234009\n",
      "tensor([1., 0.]) tensor([0.8668, 0.1332], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 44 - 12: cat - cat || Loss: 0.4463237226009369\n",
      "tensor([1., 0.]) tensor([0.8669, 0.1331], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 44 - 13: cat - cat || Loss: 0.4461686611175537\n",
      "tensor([1., 0.]) tensor([0.8671, 0.1329], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 44 - 14: cat - cat || Loss: 0.4459979236125946\n",
      "tensor([1., 0.]) tensor([0.8673, 0.1327], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 44 - 15: cat - cat || Loss: 0.4458131194114685\n",
      "tensor([1., 0.]) tensor([0.8674, 0.1326], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 44 - 16: cat - cat || Loss: 0.4456157982349396\n",
      "tensor([1., 0.]) tensor([0.8676, 0.1324], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 44 - 17: cat - cat || Loss: 0.4454071521759033\n",
      "tensor([1., 0.]) tensor([0.8679, 0.1321], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 44 - 18: cat - cat || Loss: 0.44518858194351196\n",
      "tensor([1., 0.]) tensor([0.8681, 0.1319], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 44 - 19: cat - cat || Loss: 0.44496089220046997\n",
      "tensor([1., 0.]) tensor([0.8683, 0.1317], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 44 - 20: cat - cat || Loss: 0.4447252154350281\n",
      "tensor([1., 0.]) tensor([0.8685, 0.1315], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 44 - 21: cat - cat || Loss: 0.44448238611221313\n",
      "tensor([1., 0.]) tensor([0.8688, 0.1312], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 44 - 22: cat - cat || Loss: 0.4442332983016968\n",
      "tensor([1., 0.]) tensor([0.8690, 0.1310], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 44 - 23: cat - cat || Loss: 0.4439784288406372\n",
      "tensor([1., 0.]) tensor([0.8693, 0.1307], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 44 - 24: cat - cat || Loss: 0.4437185525894165\n",
      "tensor([1., 0.]) tensor([0.8695, 0.1305], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 44 - 25: cat - cat || Loss: 0.4434543251991272\n",
      "tensor([1., 0.]) tensor([0.8698, 0.1302], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 44 - 26: cat - cat || Loss: 0.44318610429763794\n",
      "tensor([1., 0.]) tensor([0.8701, 0.1299], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 44 - 27: cat - cat || Loss: 0.4429144263267517\n",
      "tensor([1., 0.]) tensor([0.8703, 0.1297], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 44 - 28: cat - cat || Loss: 0.4426397383213043\n",
      "tensor([1., 0.]) tensor([0.8706, 0.1294], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 44 - 29: cat - cat || Loss: 0.4423622786998749\n",
      "tensor([1., 0.]) tensor([0.8709, 0.1291], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 44 - 30: cat - cat || Loss: 0.44208258390426636\n",
      "tensor([1., 0.]) tensor([0.8712, 0.1288], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 44 - 31: cat - cat || Loss: 0.4418008625507355\n",
      "tensor([1., 0.]) tensor([0.8715, 0.1285], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 44 - 32: cat - cat || Loss: 0.44151726365089417\n",
      "tensor([1., 0.]) tensor([0.8717, 0.1283], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 44 - 33: cat - cat || Loss: 0.4412324130535126\n",
      "tensor([1., 0.]) tensor([0.8720, 0.1280], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 44 - 34: cat - cat || Loss: 0.4409460723400116\n",
      "tensor([1., 0.]) tensor([0.8723, 0.1277], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 44 - 35: cat - cat || Loss: 0.44065871834754944\n",
      "tensor([1., 0.]) tensor([0.8726, 0.1274], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 44 - 36: cat - cat || Loss: 0.44037050008773804\n",
      "tensor([1., 0.]) tensor([0.8729, 0.1271], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 44 - 37: cat - cat || Loss: 0.44008153676986694\n",
      "tensor([1., 0.]) tensor([0.8732, 0.1268], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 44 - 38: cat - cat || Loss: 0.4397919774055481\n",
      "tensor([1., 0.]) tensor([0.8735, 0.1265], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 44 - 39: cat - cat || Loss: 0.4395018219947815\n",
      "tensor([1., 0.]) tensor([0.8738, 0.1262], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 44 - 40: cat - cat || Loss: 0.43921154737472534\n",
      "tensor([1., 0.]) tensor([0.8741, 0.1259], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 44 - 41: cat - cat || Loss: 0.43892085552215576\n",
      "tensor([1., 0.]) tensor([0.8743, 0.1257], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 44 - 42: cat - cat || Loss: 0.4386301338672638\n",
      "tensor([1., 0.]) tensor([0.8746, 0.1254], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 44 - 43: cat - cat || Loss: 0.4383391737937927\n",
      "tensor([1., 0.]) tensor([0.8749, 0.1251], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 44 - 44: cat - cat || Loss: 0.43804842233657837\n",
      "tensor([1., 0.]) tensor([0.8752, 0.1248], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 44 - 45: cat - cat || Loss: 0.4377576410770416\n",
      "tensor([1., 0.]) tensor([0.8755, 0.1245], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 44 - 46: cat - cat || Loss: 0.4374670386314392\n",
      "tensor([1., 0.]) tensor([0.8758, 0.1242], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 44 - 47: cat - cat || Loss: 0.4371766448020935\n",
      "tensor([1., 0.]) tensor([0.8761, 0.1239], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 44 - 48: cat - cat || Loss: 0.4368865489959717\n",
      "tensor([1., 0.]) tensor([0.8764, 0.1236], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 44 - 49: cat - cat || Loss: 0.4365966022014618\n",
      "tensor([1., 0.]) tensor([0.8767, 0.1233], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 44 - 50: cat - cat || Loss: 0.43630707263946533\n",
      "tensor([1., 0.]) tensor([0.8770, 0.1230], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 44 - 51: cat - cat || Loss: 0.4360179901123047\n",
      "tensor([1., 0.]) tensor([0.8772, 0.1228], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 44 - 52: cat - cat || Loss: 0.4357292056083679\n",
      "tensor([1., 0.]) tensor([0.8775, 0.1225], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 44 - 53: cat - cat || Loss: 0.43544089794158936\n",
      "tensor([1., 0.]) tensor([0.8778, 0.1222], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 44 - 54: cat - cat || Loss: 0.435153067111969\n",
      "tensor([1., 0.]) tensor([0.8781, 0.1219], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 44 - 55: cat - cat || Loss: 0.4348657727241516\n",
      "tensor([1., 0.]) tensor([0.8784, 0.1216], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 44 - 56: cat - cat || Loss: 0.43457886576652527\n",
      "tensor([1., 0.]) tensor([0.8787, 0.1213], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 44 - 57: cat - cat || Loss: 0.4342924952507019\n",
      "tensor([1., 0.]) tensor([0.8790, 0.1210], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 44 - 58: cat - cat || Loss: 0.4340067505836487\n",
      "tensor([1., 0.]) tensor([0.8793, 0.1207], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 44 - 59: cat - cat || Loss: 0.43372151255607605\n",
      "tensor([1., 0.]) tensor([0.8795, 0.1205], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 44 - 60: cat - cat || Loss: 0.43343687057495117\n",
      "tensor([1., 0.]) tensor([0.8798, 0.1202], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 44 - 61: cat - cat || Loss: 0.4331527054309845\n",
      "tensor([1., 0.]) tensor([0.8801, 0.1199], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 44 - 62: cat - cat || Loss: 0.43286922574043274\n",
      "tensor([1., 0.]) tensor([0.8804, 0.1196], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 44 - 63: cat - cat || Loss: 0.43258634209632874\n",
      "tensor([1., 0.]) tensor([0.8807, 0.1193], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 44 - 64: cat - cat || Loss: 0.4323040544986725\n",
      "tensor([1., 0.]) tensor([0.8810, 0.1190], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 44 - 65: cat - cat || Loss: 0.4320223331451416\n",
      "tensor([1., 0.]) tensor([0.8812, 0.1188], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 44 - 66: cat - cat || Loss: 0.43174123764038086\n",
      "tensor([1., 0.]) tensor([0.8815, 0.1185], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 44 - 67: cat - cat || Loss: 0.4314609169960022\n",
      "tensor([1., 0.]) tensor([0.8818, 0.1182], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 44 - 68: cat - cat || Loss: 0.43118107318878174\n",
      "tensor([1., 0.]) tensor([0.8821, 0.1179], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 44 - 69: cat - cat || Loss: 0.4309018850326538\n",
      "tensor([1., 0.]) tensor([0.8824, 0.1176], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 44 - 70: cat - cat || Loss: 0.4306233525276184\n",
      "tensor([1., 0.]) tensor([0.8826, 0.1174], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 44 - 71: cat - cat || Loss: 0.4303455352783203\n",
      "tensor([1., 0.]) tensor([0.8829, 0.1171], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 44 - 72: cat - cat || Loss: 0.43006831407546997\n",
      "tensor([1., 0.]) tensor([0.8832, 0.1168], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 44 - 73: cat - cat || Loss: 0.4297916889190674\n",
      "tensor([1., 0.]) tensor([0.8835, 0.1165], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 44 - 74: cat - cat || Loss: 0.42951565980911255\n",
      "tensor([1., 0.]) tensor([0.8837, 0.1163], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 44 - 75: cat - cat || Loss: 0.4292404055595398\n",
      "tensor([1., 0.]) tensor([0.8840, 0.1160], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 44 - 76: cat - cat || Loss: 0.4289657771587372\n",
      "tensor([1., 0.]) tensor([0.8843, 0.1157], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 44 - 77: cat - cat || Loss: 0.4286918640136719\n",
      "tensor([1., 0.]) tensor([0.8846, 0.1154], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 44 - 78: cat - cat || Loss: 0.42841845750808716\n",
      "tensor([1., 0.]) tensor([0.8848, 0.1152], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 44 - 79: cat - cat || Loss: 0.4281458258628845\n",
      "tensor([1., 0.]) tensor([0.8851, 0.1149], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 44 - 80: cat - cat || Loss: 0.42787379026412964\n",
      "tensor([1., 0.]) tensor([0.8854, 0.1146], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 44 - 81: cat - cat || Loss: 0.4276023805141449\n",
      "tensor([1., 0.]) tensor([0.8857, 0.1143], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 44 - 82: cat - cat || Loss: 0.4273316264152527\n",
      "tensor([1., 0.]) tensor([0.8859, 0.1141], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 44 - 83: cat - cat || Loss: 0.42706161737442017\n",
      "tensor([1., 0.]) tensor([0.8862, 0.1138], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 44 - 84: cat - cat || Loss: 0.4267922639846802\n",
      "tensor([1., 0.]) tensor([0.8865, 0.1135], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 44 - 85: cat - cat || Loss: 0.42652350664138794\n",
      "tensor([1., 0.]) tensor([0.8867, 0.1133], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 44 - 86: cat - cat || Loss: 0.426255464553833\n",
      "tensor([1., 0.]) tensor([0.8870, 0.1130], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 44 - 87: cat - cat || Loss: 0.4259880781173706\n",
      "tensor([1., 0.]) tensor([0.8873, 0.1127], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 44 - 88: cat - cat || Loss: 0.4257212281227112\n",
      "tensor([1., 0.]) tensor([0.8875, 0.1125], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 44 - 89: cat - cat || Loss: 0.42545515298843384\n",
      "tensor([1., 0.]) tensor([0.8878, 0.1122], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 44 - 90: cat - cat || Loss: 0.42518967390060425\n",
      "tensor([1., 0.]) tensor([0.8881, 0.1119], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 44 - 91: cat - cat || Loss: 0.4249247908592224\n",
      "tensor([1., 0.]) tensor([0.8883, 0.1117], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 44 - 92: cat - cat || Loss: 0.4246606230735779\n",
      "tensor([1., 0.]) tensor([0.8886, 0.1114], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 44 - 93: cat - cat || Loss: 0.42439717054367065\n",
      "tensor([1., 0.]) tensor([0.8889, 0.1111], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 44 - 94: cat - cat || Loss: 0.4241342544555664\n",
      "tensor([1., 0.]) tensor([0.8891, 0.1109], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 44 - 95: cat - cat || Loss: 0.4238720238208771\n",
      "tensor([1., 0.]) tensor([0.8894, 0.1106], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 44 - 96: cat - cat || Loss: 0.42361050844192505\n",
      "tensor([1., 0.]) tensor([0.8897, 0.1103], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 44 - 97: cat - cat || Loss: 0.4233495593070984\n",
      "tensor([1., 0.]) tensor([0.8899, 0.1101], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 44 - 98: cat - cat || Loss: 0.42308923602104187\n",
      "tensor([1., 0.]) tensor([0.8902, 0.1098], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 44 - 99: cat - cat || Loss: 0.42282968759536743\n",
      "tensor([1., 0.]) tensor([0.8904, 0.1096], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 44 - 100: cat - cat || Loss: 0.42257067561149597\n",
      "tensor([1., 0.]) tensor([0.8907, 0.1093], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 44 - 101: cat - cat || Loss: 0.42231231927871704\n",
      "tensor([1., 0.]) tensor([0.8909, 0.1091], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 44 - 102: cat - cat || Loss: 0.422054648399353\n",
      "tensor([1., 0.]) tensor([0.8912, 0.1088], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 44 - 103: cat - cat || Loss: 0.42179757356643677\n",
      "tensor([1., 0.]) tensor([0.8915, 0.1085], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 44 - 104: cat - cat || Loss: 0.42154115438461304\n",
      "tensor([1., 0.]) tensor([0.8917, 0.1083], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 44 - 105: cat - cat || Loss: 0.4212854504585266\n",
      "tensor([1., 0.]) tensor([0.8920, 0.1080], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 44 - 106: cat - cat || Loss: 0.42103028297424316\n",
      "tensor([1., 0.]) tensor([0.8922, 0.1078], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 44 - 107: cat - cat || Loss: 0.42077580094337463\n",
      "tensor([1., 0.]) tensor([0.8925, 0.1075], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 44 - 108: cat - cat || Loss: 0.42052197456359863\n",
      "tensor([1., 0.]) tensor([0.8927, 0.1073], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 44 - 109: cat - cat || Loss: 0.420268714427948\n",
      "tensor([1., 0.]) tensor([0.8930, 0.1070], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 44 - 110: cat - cat || Loss: 0.4200161099433899\n",
      "tensor([1., 0.]) tensor([0.8932, 0.1068], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 44 - 111: cat - cat || Loss: 0.4197642207145691\n",
      "tensor([1., 0.]) tensor([0.8935, 0.1065], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 44 - 112: cat - cat || Loss: 0.4195128083229065\n",
      "tensor([1., 0.]) tensor([0.8937, 0.1063], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 44 - 113: cat - cat || Loss: 0.4192620813846588\n",
      "tensor([1., 0.]) tensor([0.8940, 0.1060], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 44 - 114: cat - cat || Loss: 0.4190119504928589\n",
      "tensor([1., 0.]) tensor([0.8942, 0.1058], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 44 - 115: cat - cat || Loss: 0.4187624752521515\n",
      "tensor([1., 0.]) tensor([0.8945, 0.1055], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 44 - 116: cat - cat || Loss: 0.4185136556625366\n",
      "tensor([1., 0.]) tensor([0.8947, 0.1053], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 44 - 117: cat - cat || Loss: 0.4182654619216919\n",
      "tensor([1., 0.]) tensor([0.8950, 0.1050], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 44 - 118: cat - cat || Loss: 0.41801783442497253\n",
      "tensor([1., 0.]) tensor([0.8952, 0.1048], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 44 - 119: cat - cat || Loss: 0.4177708923816681\n",
      "tensor([1., 0.]) tensor([0.8955, 0.1045], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 44 - 120: cat - cat || Loss: 0.4175244867801666\n",
      "tensor([1., 0.]) tensor([0.8957, 0.1043], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 44 - 121: cat - cat || Loss: 0.4172787070274353\n",
      "tensor([1., 0.]) tensor([0.8960, 0.1040], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 44 - 122: cat - cat || Loss: 0.4170336127281189\n",
      "tensor([1., 0.]) tensor([0.8962, 0.1038], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 44 - 123: cat - cat || Loss: 0.41678911447525024\n",
      "tensor([1., 0.]) tensor([0.8965, 0.1035], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 44 - 124: cat - cat || Loss: 0.41654521226882935\n",
      "tensor([1., 0.]) tensor([0.8967, 0.1033], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 44 - 125: cat - cat || Loss: 0.4163019359111786\n",
      "tensor([1., 0.]) tensor([0.8970, 0.1030], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 44 - 126: cat - cat || Loss: 0.41605931520462036\n",
      "tensor([1., 0.]) tensor([0.8972, 0.1028], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 44 - 127: cat - cat || Loss: 0.41581714153289795\n",
      "tensor([1., 0.]) tensor([0.8974, 0.1026], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 44 - 128: cat - cat || Loss: 0.4155757427215576\n",
      "tensor([1., 0.]) tensor([0.8977, 0.1023], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 44 - 129: cat - cat || Loss: 0.41533493995666504\n",
      "tensor([1., 0.]) tensor([0.8979, 0.1021], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 44 - 130: cat - cat || Loss: 0.4150947332382202\n",
      "tensor([1., 0.]) tensor([0.8982, 0.1018], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 44 - 131: cat - cat || Loss: 0.41485506296157837\n",
      "tensor([1., 0.]) tensor([0.8984, 0.1016], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 44 - 132: cat - cat || Loss: 0.4146159887313843\n",
      "tensor([1., 0.]) tensor([0.8986, 0.1014], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 44 - 133: cat - cat || Loss: 0.4143776297569275\n",
      "tensor([1., 0.]) tensor([0.8989, 0.1011], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 44 - 134: cat - cat || Loss: 0.4141397476196289\n",
      "tensor([1., 0.]) tensor([0.8991, 0.1009], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 44 - 135: cat - cat || Loss: 0.41390255093574524\n",
      "tensor([1., 0.]) tensor([0.8994, 0.1006], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 44 - 136: cat - cat || Loss: 0.41366589069366455\n",
      "tensor([1., 0.]) tensor([0.8996, 0.1004], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 44 - 137: cat - cat || Loss: 0.41342979669570923\n",
      "tensor([1., 0.]) tensor([0.8998, 0.1002], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 44 - 138: cat - cat || Loss: 0.4131944179534912\n",
      "tensor([1., 0.]) tensor([0.9001, 0.0999], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 44 - 139: cat - cat || Loss: 0.4129595160484314\n",
      "tensor([1., 0.]) tensor([0.9003, 0.0997], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 44 - 140: cat - cat || Loss: 0.4127252697944641\n",
      "tensor([1., 0.]) tensor([0.9005, 0.0995], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 44 - 141: cat - cat || Loss: 0.4124915897846222\n",
      "tensor([1., 0.]) tensor([0.9008, 0.0992], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 44 - 142: cat - cat || Loss: 0.4122585356235504\n",
      "tensor([1., 0.]) tensor([0.9010, 0.0990], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 44 - 143: cat - cat || Loss: 0.41202598810195923\n",
      "tensor([1., 0.]) tensor([0.9012, 0.0988], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 44 - 144: cat - cat || Loss: 0.41179412603378296\n",
      "tensor([1., 0.]) tensor([0.9015, 0.0985], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 44 - 145: cat - cat || Loss: 0.4115627408027649\n",
      "tensor([1., 0.]) tensor([0.9017, 0.0983], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 44 - 146: cat - cat || Loss: 0.41133207082748413\n",
      "tensor([1., 0.]) tensor([0.9019, 0.0981], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 44 - 147: cat - cat || Loss: 0.41110196709632874\n",
      "tensor([1., 0.]) tensor([0.9022, 0.0978], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 44 - 148: cat - cat || Loss: 0.41087234020233154\n",
      "tensor([1., 0.]) tensor([0.9024, 0.0976], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 44 - 149: cat - cat || Loss: 0.41064339876174927\n",
      "tensor([1., 0.]) tensor([0.9026, 0.0974], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 44 - 150: cat - cat || Loss: 0.4104148745536804\n",
      "tensor([1., 0.]) tensor([0.9028, 0.0972], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 44 - 151: cat - cat || Loss: 0.41018709540367126\n",
      "tensor([1., 0.]) tensor([0.9031, 0.0969], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 44 - 152: cat - cat || Loss: 0.4099598526954651\n",
      "tensor([1., 0.]) tensor([0.9033, 0.0967], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 44 - 153: cat - cat || Loss: 0.4097331762313843\n",
      "tensor([1., 0.]) tensor([0.9035, 0.0965], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 44 - 154: cat - cat || Loss: 0.40950706601142883\n",
      "tensor([1., 0.]) tensor([0.9038, 0.0962], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 44 - 155: cat - cat || Loss: 0.4092814326286316\n",
      "tensor([1., 0.]) tensor([0.9040, 0.0960], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 44 - 156: cat - cat || Loss: 0.40905654430389404\n",
      "tensor([1., 0.]) tensor([0.9042, 0.0958], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 44 - 157: cat - cat || Loss: 0.4088321924209595\n",
      "tensor([1., 0.]) tensor([0.9044, 0.0956], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 44 - 158: cat - cat || Loss: 0.40860825777053833\n",
      "tensor([1., 0.]) tensor([0.9047, 0.0953], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 44 - 159: cat - cat || Loss: 0.4083849787712097\n",
      "tensor([1., 0.]) tensor([0.9049, 0.0951], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 44 - 160: cat - cat || Loss: 0.40816229581832886\n",
      "tensor([1., 0.]) tensor([0.9051, 0.0949], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 44 - 161: cat - cat || Loss: 0.407940149307251\n",
      "tensor([1., 0.]) tensor([0.9053, 0.0947], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 44 - 162: cat - cat || Loss: 0.4077186584472656\n",
      "tensor([1., 0.]) tensor([0.9055, 0.0945], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 44 - 163: cat - cat || Loss: 0.4074976444244385\n",
      "tensor([1., 0.]) tensor([0.9058, 0.0942], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 44 - 164: cat - cat || Loss: 0.4072772264480591\n",
      "tensor([1., 0.]) tensor([0.9060, 0.0940], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 44 - 165: cat - cat || Loss: 0.40705734491348267\n",
      "tensor([1., 0.]) tensor([0.9062, 0.0938], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 44 - 166: cat - cat || Loss: 0.40683794021606445\n",
      "tensor([1., 0.]) tensor([0.9064, 0.0936], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 44 - 167: cat - cat || Loss: 0.40661919116973877\n",
      "tensor([1., 0.]) tensor([0.9066, 0.0934], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 44 - 168: cat - cat || Loss: 0.4064009487628937\n",
      "tensor([1., 0.]) tensor([0.9069, 0.0931], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 44 - 169: cat - cat || Loss: 0.40618324279785156\n",
      "tensor([1., 0.]) tensor([0.9071, 0.0929], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 44 - 170: cat - cat || Loss: 0.405966192483902\n",
      "tensor([1., 0.]) tensor([0.9073, 0.0927], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 44 - 171: cat - cat || Loss: 0.4057496190071106\n",
      "tensor([1., 0.]) tensor([0.9075, 0.0925], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 44 - 172: cat - cat || Loss: 0.4055335819721222\n",
      "tensor([1., 0.]) tensor([0.9077, 0.0923], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 44 - 173: cat - cat || Loss: 0.40531817078590393\n",
      "tensor([1., 0.]) tensor([0.9079, 0.0921], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 44 - 174: cat - cat || Loss: 0.4051032066345215\n",
      "tensor([1., 0.]) tensor([0.9082, 0.0918], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 44 - 175: cat - cat || Loss: 0.4048888087272644\n",
      "tensor([1., 0.]) tensor([0.9084, 0.0916], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 44 - 176: cat - cat || Loss: 0.4046749472618103\n",
      "tensor([1., 0.]) tensor([0.9086, 0.0914], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 44 - 177: cat - cat || Loss: 0.40446165204048157\n",
      "tensor([1., 0.]) tensor([0.9088, 0.0912], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 44 - 178: cat - cat || Loss: 0.4042489230632782\n",
      "tensor([1., 0.]) tensor([0.9090, 0.0910], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 44 - 179: cat - cat || Loss: 0.4040367007255554\n",
      "tensor([1., 0.]) tensor([0.9092, 0.0908], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 44 - 180: cat - cat || Loss: 0.40382498502731323\n",
      "tensor([1., 0.]) tensor([0.9094, 0.0906], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 44 - 181: cat - cat || Loss: 0.4036138355731964\n",
      "tensor([1., 0.]) tensor([0.9096, 0.0904], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 44 - 182: cat - cat || Loss: 0.40340325236320496\n",
      "tensor([1., 0.]) tensor([0.9099, 0.0901], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 44 - 183: cat - cat || Loss: 0.40319323539733887\n",
      "tensor([1., 0.]) tensor([0.9101, 0.0899], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 44 - 184: cat - cat || Loss: 0.4029836654663086\n",
      "tensor([1., 0.]) tensor([0.9103, 0.0897], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 44 - 185: cat - cat || Loss: 0.40277472138404846\n",
      "tensor([1., 0.]) tensor([0.9105, 0.0895], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 44 - 186: cat - cat || Loss: 0.402566134929657\n",
      "tensor([1., 0.]) tensor([0.9107, 0.0893], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 44 - 187: cat - cat || Loss: 0.40235817432403564\n",
      "tensor([1., 0.]) tensor([0.9109, 0.0891], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 44 - 188: cat - cat || Loss: 0.4021507203578949\n",
      "tensor([1., 0.]) tensor([0.9111, 0.0889], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 44 - 189: cat - cat || Loss: 0.40194374322891235\n",
      "tensor([1., 0.]) tensor([0.9113, 0.0887], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 44 - 190: dog - cat || Loss: 1.2247861623764038\n",
      "tensor([0., 1.]) tensor([0.9115, 0.0885], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 44 - 191: dog - cat || Loss: 1.2249513864517212\n",
      "tensor([0., 1.]) tensor([0.9117, 0.0883], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 44 - 192: dog - cat || Loss: 1.2250796556472778\n",
      "tensor([0., 1.]) tensor([0.9118, 0.0882], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 44 - 193: dog - cat || Loss: 1.2251747846603394\n",
      "tensor([0., 1.]) tensor([0.9119, 0.0881], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 44 - 194: dog - cat || Loss: 1.2252397537231445\n",
      "tensor([0., 1.]) tensor([0.9120, 0.0880], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 44 - 195: dog - cat || Loss: 1.2252782583236694\n",
      "tensor([0., 1.]) tensor([0.9120, 0.0880], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 44 - 196: dog - cat || Loss: 1.2252922058105469\n",
      "tensor([0., 1.]) tensor([0.9120, 0.0880], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 44 - 197: dog - cat || Loss: 1.2252846956253052\n",
      "tensor([0., 1.]) tensor([0.9120, 0.0880], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 44 - 198: dog - cat || Loss: 1.2252577543258667\n",
      "tensor([0., 1.]) tensor([0.9120, 0.0880], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 44 - 199: dog - cat || Loss: 1.2252131700515747\n",
      "tensor([0., 1.]) tensor([0.9120, 0.0880], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 44 - 200: dog - cat || Loss: 1.225152611732483\n",
      "tensor([0., 1.]) tensor([0.9119, 0.0881], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 44 - 201: dog - cat || Loss: 1.2250779867172241\n",
      "tensor([0., 1.]) tensor([0.9118, 0.0882], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 44 - 202: dog - cat || Loss: 1.2249903678894043\n",
      "tensor([0., 1.]) tensor([0.9117, 0.0883], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 44 - 203: dog - cat || Loss: 1.224891185760498\n",
      "tensor([0., 1.]) tensor([0.9116, 0.0884], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 44 - 204: dog - cat || Loss: 1.2247815132141113\n",
      "tensor([0., 1.]) tensor([0.9115, 0.0885], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 44 - 205: dog - cat || Loss: 1.22466242313385\n",
      "tensor([0., 1.]) tensor([0.9114, 0.0886], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 44 - 206: dog - cat || Loss: 1.2245346307754517\n",
      "tensor([0., 1.]) tensor([0.9113, 0.0887], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 44 - 207: dog - cat || Loss: 1.2243990898132324\n",
      "tensor([0., 1.]) tensor([0.9111, 0.0889], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 44 - 208: dog - cat || Loss: 1.2242565155029297\n",
      "tensor([0., 1.]) tensor([0.9110, 0.0890], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 44 - 209: dog - cat || Loss: 1.2241077423095703\n",
      "tensor([0., 1.]) tensor([0.9108, 0.0892], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 44 - 210: dog - cat || Loss: 1.223953127861023\n",
      "tensor([0., 1.]) tensor([0.9107, 0.0893], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 44 - 211: dog - cat || Loss: 1.2237932682037354\n",
      "tensor([0., 1.]) tensor([0.9105, 0.0895], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 44 - 212: dog - cat || Loss: 1.2236285209655762\n",
      "tensor([0., 1.]) tensor([0.9104, 0.0896], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 44 - 213: dog - cat || Loss: 1.2234594821929932\n",
      "tensor([0., 1.]) tensor([0.9102, 0.0898], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 44 - 214: dog - cat || Loss: 1.223286509513855\n",
      "tensor([0., 1.]) tensor([0.9100, 0.0900], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 44 - 215: dog - cat || Loss: 1.2231099605560303\n",
      "tensor([0., 1.]) tensor([0.9098, 0.0902], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 44 - 216: dog - cat || Loss: 1.2229301929473877\n",
      "tensor([0., 1.]) tensor([0.9097, 0.0903], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 44 - 217: dog - cat || Loss: 1.2227472066879272\n",
      "tensor([0., 1.]) tensor([0.9095, 0.0905], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 44 - 218: dog - cat || Loss: 1.2225614786148071\n",
      "tensor([0., 1.]) tensor([0.9093, 0.0907], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 44 - 219: dog - cat || Loss: 1.222373366355896\n",
      "tensor([0., 1.]) tensor([0.9091, 0.0909], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 44 - 220: dog - cat || Loss: 1.2221828699111938\n",
      "tensor([0., 1.]) tensor([0.9089, 0.0911], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 44 - 221: dog - cat || Loss: 1.2219901084899902\n",
      "tensor([0., 1.]) tensor([0.9087, 0.0913], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 44 - 222: dog - cat || Loss: 1.2217953205108643\n",
      "tensor([0., 1.]) tensor([0.9085, 0.0915], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 44 - 223: dog - cat || Loss: 1.221598744392395\n",
      "tensor([0., 1.]) tensor([0.9083, 0.0917], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 44 - 224: dog - cat || Loss: 1.221400499343872\n",
      "tensor([0., 1.]) tensor([0.9081, 0.0919], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 44 - 225: dog - cat || Loss: 1.221200704574585\n",
      "tensor([0., 1.]) tensor([0.9079, 0.0921], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 44 - 226: dog - cat || Loss: 1.2209993600845337\n",
      "tensor([0., 1.]) tensor([0.9077, 0.0923], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 44 - 227: dog - cat || Loss: 1.2207965850830078\n",
      "tensor([0., 1.]) tensor([0.9075, 0.0925], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 44 - 228: dog - cat || Loss: 1.2205924987792969\n",
      "tensor([0., 1.]) tensor([0.9073, 0.0927], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 44 - 229: dog - cat || Loss: 1.22038733959198\n",
      "tensor([0., 1.]) tensor([0.9071, 0.0929], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 44 - 230: dog - cat || Loss: 1.2201807498931885\n",
      "tensor([0., 1.]) tensor([0.9069, 0.0931], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 44 - 231: dog - cat || Loss: 1.2199732065200806\n",
      "tensor([0., 1.]) tensor([0.9067, 0.0933], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 44 - 232: dog - cat || Loss: 1.2197645902633667\n",
      "tensor([0., 1.]) tensor([0.9065, 0.0935], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 44 - 233: dog - cat || Loss: 1.2195550203323364\n",
      "tensor([0., 1.]) tensor([0.9063, 0.0937], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 44 - 234: dog - cat || Loss: 1.2193444967269897\n",
      "tensor([0., 1.]) tensor([0.9061, 0.0939], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 44 - 235: dog - cat || Loss: 1.2191331386566162\n",
      "tensor([0., 1.]) tensor([0.9059, 0.0941], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 44 - 236: dog - cat || Loss: 1.2189207077026367\n",
      "tensor([0., 1.]) tensor([0.9057, 0.0943], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 44 - 237: dog - cat || Loss: 1.21870756149292\n",
      "tensor([0., 1.]) tensor([0.9054, 0.0946], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 44 - 238: dog - cat || Loss: 1.2184937000274658\n",
      "tensor([0., 1.]) tensor([0.9052, 0.0948], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 44 - 239: dog - cat || Loss: 1.2182788848876953\n",
      "tensor([0., 1.]) tensor([0.9050, 0.0950], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 44 - 240: dog - cat || Loss: 1.218063473701477\n",
      "tensor([0., 1.]) tensor([0.9048, 0.0952], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 44 - 241: dog - cat || Loss: 1.217847228050232\n",
      "tensor([0., 1.]) tensor([0.9046, 0.0954], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 44 - 242: dog - cat || Loss: 1.21763014793396\n",
      "tensor([0., 1.]) tensor([0.9044, 0.0956], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 44 - 243: dog - cat || Loss: 1.2174124717712402\n",
      "tensor([0., 1.]) tensor([0.9042, 0.0958], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 44 - 244: dog - cat || Loss: 1.2171943187713623\n",
      "tensor([0., 1.]) tensor([0.9039, 0.0961], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 44 - 245: dog - cat || Loss: 1.216975212097168\n",
      "tensor([0., 1.]) tensor([0.9037, 0.0963], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 44 - 246: dog - cat || Loss: 1.2167555093765259\n",
      "tensor([0., 1.]) tensor([0.9035, 0.0965], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 44 - 247: dog - cat || Loss: 1.216535210609436\n",
      "tensor([0., 1.]) tensor([0.9033, 0.0967], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 44 - 248: dog - cat || Loss: 1.216314435005188\n",
      "tensor([0., 1.]) tensor([0.9031, 0.0969], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 44 - 249: dog - cat || Loss: 1.2160927057266235\n",
      "tensor([0., 1.]) tensor([0.9028, 0.0972], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 44 - 250: dog - cat || Loss: 1.2158706188201904\n",
      "tensor([0., 1.]) tensor([0.9026, 0.0974], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 44 - 251: dog - cat || Loss: 1.21564781665802\n",
      "tensor([0., 1.]) tensor([0.9024, 0.0976], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 44 - 252: dog - cat || Loss: 1.2154245376586914\n",
      "tensor([0., 1.]) tensor([0.9022, 0.0978], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 44 - 253: dog - cat || Loss: 1.2152003049850464\n",
      "tensor([0., 1.]) tensor([0.9019, 0.0981], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 44 - 254: dog - cat || Loss: 1.2149757146835327\n",
      "tensor([0., 1.]) tensor([0.9017, 0.0983], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 44 - 255: dog - cat || Loss: 1.2147505283355713\n",
      "tensor([0., 1.]) tensor([0.9015, 0.0985], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 44 - 256: dog - cat || Loss: 1.2145246267318726\n",
      "tensor([0., 1.]) tensor([0.9013, 0.0987], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 44 - 257: dog - cat || Loss: 1.2142982482910156\n",
      "tensor([0., 1.]) tensor([0.9010, 0.0990], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 44 - 258: dog - cat || Loss: 1.2140711545944214\n",
      "tensor([0., 1.]) tensor([0.9008, 0.0992], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 44 - 259: dog - cat || Loss: 1.213843584060669\n",
      "tensor([0., 1.]) tensor([0.9006, 0.0994], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 44 - 260: dog - cat || Loss: 1.2136154174804688\n",
      "tensor([0., 1.]) tensor([0.9004, 0.0996], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 44 - 261: dog - cat || Loss: 1.2133866548538208\n",
      "tensor([0., 1.]) tensor([0.9001, 0.0999], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 44 - 262: dog - cat || Loss: 1.2131574153900146\n",
      "tensor([0., 1.]) tensor([0.8999, 0.1001], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 44 - 263: dog - cat || Loss: 1.2129273414611816\n",
      "tensor([0., 1.]) tensor([0.8997, 0.1003], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 44 - 264: dog - cat || Loss: 1.2126970291137695\n",
      "tensor([0., 1.]) tensor([0.8994, 0.1006], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 44 - 265: dog - cat || Loss: 1.2124658823013306\n",
      "tensor([0., 1.]) tensor([0.8992, 0.1008], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 44 - 266: dog - cat || Loss: 1.212234377861023\n",
      "tensor([0., 1.]) tensor([0.8990, 0.1010], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 44 - 267: dog - cat || Loss: 1.212002158164978\n",
      "tensor([0., 1.]) tensor([0.8987, 0.1013], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 44 - 268: dog - cat || Loss: 1.2117692232131958\n",
      "tensor([0., 1.]) tensor([0.8985, 0.1015], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 44 - 269: dog - cat || Loss: 1.2115358114242554\n",
      "tensor([0., 1.]) tensor([0.8983, 0.1017], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 44 - 270: dog - cat || Loss: 1.2113019227981567\n",
      "tensor([0., 1.]) tensor([0.8980, 0.1020], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 44 - 271: dog - cat || Loss: 1.2110673189163208\n",
      "tensor([0., 1.]) tensor([0.8978, 0.1022], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 44 - 272: dog - cat || Loss: 1.210832118988037\n",
      "tensor([0., 1.]) tensor([0.8976, 0.1024], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 44 - 273: dog - cat || Loss: 1.2105964422225952\n",
      "tensor([0., 1.]) tensor([0.8973, 0.1027], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 44 - 274: dog - cat || Loss: 1.2103602886199951\n",
      "tensor([0., 1.]) tensor([0.8971, 0.1029], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 44 - 275: dog - cat || Loss: 1.2101231813430786\n",
      "tensor([0., 1.]) tensor([0.8969, 0.1031], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 44 - 276: dog - cat || Loss: 1.2098857164382935\n",
      "tensor([0., 1.]) tensor([0.8966, 0.1034], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 44 - 277: dog - cat || Loss: 1.20964777469635\n",
      "tensor([0., 1.]) tensor([0.8964, 0.1036], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 44 - 278: dog - cat || Loss: 1.2094091176986694\n",
      "tensor([0., 1.]) tensor([0.8961, 0.1039], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 44 - 279: dog - cat || Loss: 1.2091697454452515\n",
      "tensor([0., 1.]) tensor([0.8959, 0.1041], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 44 - 280: dog - cat || Loss: 1.2089300155639648\n",
      "tensor([0., 1.]) tensor([0.8957, 0.1043], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 44 - 281: dog - cat || Loss: 1.208689570426941\n",
      "tensor([0., 1.]) tensor([0.8954, 0.1046], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 44 - 282: dog - cat || Loss: 1.2084486484527588\n",
      "tensor([0., 1.]) tensor([0.8952, 0.1048], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 44 - 283: dog - cat || Loss: 1.208207130432129\n",
      "tensor([0., 1.]) tensor([0.8949, 0.1051], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 44 - 284: dog - cat || Loss: 1.2079648971557617\n",
      "tensor([0., 1.]) tensor([0.8947, 0.1053], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 44 - 285: dog - cat || Loss: 1.2077220678329468\n",
      "tensor([0., 1.]) tensor([0.8945, 0.1055], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 44 - 286: dog - cat || Loss: 1.2074787616729736\n",
      "tensor([0., 1.]) tensor([0.8942, 0.1058], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 44 - 287: dog - cat || Loss: 1.2072347402572632\n",
      "tensor([0., 1.]) tensor([0.8940, 0.1060], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 44 - 288: dog - cat || Loss: 1.2069902420043945\n",
      "tensor([0., 1.]) tensor([0.8937, 0.1063], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 44 - 289: dog - cat || Loss: 1.2067450284957886\n",
      "tensor([0., 1.]) tensor([0.8935, 0.1065], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 44 - 290: dog - cat || Loss: 1.2064993381500244\n",
      "tensor([0., 1.]) tensor([0.8932, 0.1068], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 44 - 291: dog - cat || Loss: 1.206252932548523\n",
      "tensor([0., 1.]) tensor([0.8930, 0.1070], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 44 - 292: dog - cat || Loss: 1.2060060501098633\n",
      "tensor([0., 1.]) tensor([0.8927, 0.1073], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 44 - 293: dog - cat || Loss: 1.2057584524154663\n",
      "tensor([0., 1.]) tensor([0.8925, 0.1075], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 44 - 294: dog - cat || Loss: 1.2055102586746216\n",
      "tensor([0., 1.]) tensor([0.8922, 0.1078], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 44 - 295: dog - cat || Loss: 1.2052615880966187\n",
      "tensor([0., 1.]) tensor([0.8920, 0.1080], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 44 - 296: dog - cat || Loss: 1.205012321472168\n",
      "tensor([0., 1.]) tensor([0.8918, 0.1082], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 44 - 297: dog - cat || Loss: 1.20476233959198\n",
      "tensor([0., 1.]) tensor([0.8915, 0.1085], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 44 - 298: dog - cat || Loss: 1.2045116424560547\n",
      "tensor([0., 1.]) tensor([0.8913, 0.1087], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 44 - 299: dog - cat || Loss: 1.2042605876922607\n",
      "tensor([0., 1.]) tensor([0.8910, 0.1090], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 44 - 300: dog - cat || Loss: 1.20400869846344\n",
      "tensor([0., 1.]) tensor([0.8907, 0.1093], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 44 - 301: dog - cat || Loss: 1.2037562131881714\n",
      "tensor([0., 1.]) tensor([0.8905, 0.1095], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 44 - 302: dog - cat || Loss: 1.2035034894943237\n",
      "tensor([0., 1.]) tensor([0.8902, 0.1098], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 44 - 303: dog - cat || Loss: 1.2032496929168701\n",
      "tensor([0., 1.]) tensor([0.8900, 0.1100], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 44 - 304: dog - cat || Loss: 1.2029955387115479\n",
      "tensor([0., 1.]) tensor([0.8897, 0.1103], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 44 - 305: dog - cat || Loss: 1.2027405500411987\n",
      "tensor([0., 1.]) tensor([0.8895, 0.1105], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 44 - 306: dog - cat || Loss: 1.202485203742981\n",
      "tensor([0., 1.]) tensor([0.8892, 0.1108], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 44 - 307: dog - cat || Loss: 1.2022291421890259\n",
      "tensor([0., 1.]) tensor([0.8890, 0.1110], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 44 - 308: dog - cat || Loss: 1.2019723653793335\n",
      "tensor([0., 1.]) tensor([0.8887, 0.1113], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 44 - 309: dog - cat || Loss: 1.201715111732483\n",
      "tensor([0., 1.]) tensor([0.8885, 0.1115], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 44 - 310: dog - cat || Loss: 1.2014570236206055\n",
      "tensor([0., 1.]) tensor([0.8882, 0.1118], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 44 - 311: dog - cat || Loss: 1.2011985778808594\n",
      "tensor([0., 1.]) tensor([0.8879, 0.1121], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 44 - 312: dog - cat || Loss: 1.200939416885376\n",
      "tensor([0., 1.]) tensor([0.8877, 0.1123], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 44 - 313: dog - cat || Loss: 1.2006795406341553\n",
      "tensor([0., 1.]) tensor([0.8874, 0.1126], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 44 - 314: dog - cat || Loss: 1.2004191875457764\n",
      "tensor([0., 1.]) tensor([0.8872, 0.1128], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 44 - 315: dog - cat || Loss: 1.2001581192016602\n",
      "tensor([0., 1.]) tensor([0.8869, 0.1131], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 44 - 316: dog - cat || Loss: 1.1998963356018066\n",
      "tensor([0., 1.]) tensor([0.8866, 0.1134], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 44 - 317: dog - cat || Loss: 1.199634075164795\n",
      "tensor([0., 1.]) tensor([0.8864, 0.1136], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 44 - 318: dog - cat || Loss: 1.199371099472046\n",
      "tensor([0., 1.]) tensor([0.8861, 0.1139], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 44 - 319: dog - cat || Loss: 1.1991076469421387\n",
      "tensor([0., 1.]) tensor([0.8858, 0.1142], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 44 - 320: dog - cat || Loss: 1.1988433599472046\n",
      "tensor([0., 1.]) tensor([0.8856, 0.1144], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 44 - 321: dog - cat || Loss: 1.1985783576965332\n",
      "tensor([0., 1.]) tensor([0.8853, 0.1147], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 44 - 322: dog - cat || Loss: 1.1983128786087036\n",
      "tensor([0., 1.]) tensor([0.8851, 0.1149], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 44 - 323: dog - cat || Loss: 1.1980466842651367\n",
      "tensor([0., 1.]) tensor([0.8848, 0.1152], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 44 - 324: dog - cat || Loss: 1.1977800130844116\n",
      "tensor([0., 1.]) tensor([0.8845, 0.1155], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 44 - 325: dog - cat || Loss: 1.1975126266479492\n",
      "tensor([0., 1.]) tensor([0.8843, 0.1157], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 44 - 326: dog - cat || Loss: 1.19724440574646\n",
      "tensor([0., 1.]) tensor([0.8840, 0.1160], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 44 - 327: dog - cat || Loss: 1.196975827217102\n",
      "tensor([0., 1.]) tensor([0.8837, 0.1163], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 44 - 328: dog - cat || Loss: 1.1967065334320068\n",
      "tensor([0., 1.]) tensor([0.8834, 0.1166], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 44 - 329: dog - cat || Loss: 1.1964365243911743\n",
      "tensor([0., 1.]) tensor([0.8832, 0.1168], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 44 - 330: dog - cat || Loss: 1.1961660385131836\n",
      "tensor([0., 1.]) tensor([0.8829, 0.1171], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 44 - 331: dog - cat || Loss: 1.1958945989608765\n",
      "tensor([0., 1.]) tensor([0.8826, 0.1174], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 44 - 332: dog - cat || Loss: 1.1956228017807007\n",
      "tensor([0., 1.]) tensor([0.8824, 0.1176], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 44 - 333: dog - cat || Loss: 1.195350170135498\n",
      "tensor([0., 1.]) tensor([0.8821, 0.1179], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 44 - 334: dog - cat || Loss: 1.195076823234558\n",
      "tensor([0., 1.]) tensor([0.8818, 0.1182], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 44 - 335: dog - cat || Loss: 1.1948031187057495\n",
      "tensor([0., 1.]) tensor([0.8815, 0.1185], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 44 - 336: dog - cat || Loss: 1.194528579711914\n",
      "tensor([0., 1.]) tensor([0.8813, 0.1187], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 44 - 337: dog - cat || Loss: 1.1942533254623413\n",
      "tensor([0., 1.]) tensor([0.8810, 0.1190], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 44 - 338: dog - cat || Loss: 1.1939775943756104\n",
      "tensor([0., 1.]) tensor([0.8807, 0.1193], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 44 - 339: dog - cat || Loss: 1.193701148033142\n",
      "tensor([0., 1.]) tensor([0.8804, 0.1196], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 44 - 340: dog - cat || Loss: 1.193423867225647\n",
      "tensor([0., 1.]) tensor([0.8802, 0.1198], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 44 - 341: dog - cat || Loss: 1.1931462287902832\n",
      "tensor([0., 1.]) tensor([0.8799, 0.1201], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 44 - 342: dog - cat || Loss: 1.1928675174713135\n",
      "tensor([0., 1.]) tensor([0.8796, 0.1204], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 44 - 343: dog - cat || Loss: 1.192588448524475\n",
      "tensor([0., 1.]) tensor([0.8793, 0.1207], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 44 - 344: dog - cat || Loss: 1.1923086643218994\n",
      "tensor([0., 1.]) tensor([0.8790, 0.1210], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 44 - 345: dog - cat || Loss: 1.1920281648635864\n",
      "tensor([0., 1.]) tensor([0.8788, 0.1212], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 44 - 346: dog - cat || Loss: 1.1917470693588257\n",
      "tensor([0., 1.]) tensor([0.8785, 0.1215], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 44 - 347: dog - cat || Loss: 1.1914653778076172\n",
      "tensor([0., 1.]) tensor([0.8782, 0.1218], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 44 - 348: dog - cat || Loss: 1.1911827325820923\n",
      "tensor([0., 1.]) tensor([0.8779, 0.1221], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 44 - 349: dog - cat || Loss: 1.1908997297286987\n",
      "tensor([0., 1.]) tensor([0.8776, 0.1224], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 44 - 350: dog - cat || Loss: 1.1906158924102783\n",
      "tensor([0., 1.]) tensor([0.8774, 0.1226], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 44 - 351: dog - cat || Loss: 1.1903314590454102\n",
      "tensor([0., 1.]) tensor([0.8771, 0.1229], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 44 - 352: dog - cat || Loss: 1.1900464296340942\n",
      "tensor([0., 1.]) tensor([0.8768, 0.1232], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 44 - 353: dog - cat || Loss: 1.1897605657577515\n",
      "tensor([0., 1.]) tensor([0.8765, 0.1235], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 44 - 354: dog - cat || Loss: 1.1894739866256714\n",
      "tensor([0., 1.]) tensor([0.8762, 0.1238], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 44 - 355: dog - cat || Loss: 1.1891868114471436\n",
      "tensor([0., 1.]) tensor([0.8759, 0.1241], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 44 - 356: dog - cat || Loss: 1.188899040222168\n",
      "tensor([0., 1.]) tensor([0.8756, 0.1244], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 44 - 357: dog - cat || Loss: 1.188610553741455\n",
      "tensor([0., 1.]) tensor([0.8753, 0.1247], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 44 - 358: dog - cat || Loss: 1.1883213520050049\n",
      "tensor([0., 1.]) tensor([0.8751, 0.1249], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 44 - 359: dog - cat || Loss: 1.1880314350128174\n",
      "tensor([0., 1.]) tensor([0.8748, 0.1252], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 44 - 360: dog - cat || Loss: 1.187740683555603\n",
      "tensor([0., 1.]) tensor([0.8745, 0.1255], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 44 - 361: dog - cat || Loss: 1.18744957447052\n",
      "tensor([0., 1.]) tensor([0.8742, 0.1258], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 44 - 362: dog - cat || Loss: 1.1871576309204102\n",
      "tensor([0., 1.]) tensor([0.8739, 0.1261], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 44 - 363: dog - cat || Loss: 1.1868650913238525\n",
      "tensor([0., 1.]) tensor([0.8736, 0.1264], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 44 - 364: dog - cat || Loss: 1.1865715980529785\n",
      "tensor([0., 1.]) tensor([0.8733, 0.1267], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 44 - 365: dog - cat || Loss: 1.1862778663635254\n",
      "tensor([0., 1.]) tensor([0.8730, 0.1270], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 44 - 366: dog - cat || Loss: 1.1859828233718872\n",
      "tensor([0., 1.]) tensor([0.8727, 0.1273], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 44 - 367: dog - cat || Loss: 1.185687780380249\n",
      "tensor([0., 1.]) tensor([0.8724, 0.1276], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 44 - 368: dog - cat || Loss: 1.1853915452957153\n",
      "tensor([0., 1.]) tensor([0.8721, 0.1279], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 44 - 369: dog - cat || Loss: 1.1850947141647339\n",
      "tensor([0., 1.]) tensor([0.8718, 0.1282], grad_fn=<SoftmaxBackward0>)\n",
      "=====epoch:45=====\n",
      "Epoch 45 - 0: cat - cat || Loss: 0.44172602891921997\n",
      "tensor([1., 0.]) tensor([0.8715, 0.1285], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 45 - 1: cat - cat || Loss: 0.4419638514518738\n",
      "tensor([1., 0.]) tensor([0.8713, 0.1287], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 45 - 2: cat - cat || Loss: 0.4421479105949402\n",
      "tensor([1., 0.]) tensor([0.8711, 0.1289], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 45 - 3: cat - cat || Loss: 0.4422835111618042\n",
      "tensor([1., 0.]) tensor([0.8710, 0.1290], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 45 - 4: cat - cat || Loss: 0.4423752427101135\n",
      "tensor([1., 0.]) tensor([0.8709, 0.1291], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 45 - 5: cat - cat || Loss: 0.4424275755882263\n",
      "tensor([1., 0.]) tensor([0.8708, 0.1292], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 45 - 6: cat - cat || Loss: 0.44244441390037537\n",
      "tensor([1., 0.]) tensor([0.8708, 0.1292], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 45 - 7: cat - cat || Loss: 0.4424293637275696\n",
      "tensor([1., 0.]) tensor([0.8708, 0.1292], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 45 - 8: cat - cat || Loss: 0.4423854649066925\n",
      "tensor([1., 0.]) tensor([0.8709, 0.1291], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 45 - 9: cat - cat || Loss: 0.4423157274723053\n",
      "tensor([1., 0.]) tensor([0.8709, 0.1291], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 45 - 10: cat - cat || Loss: 0.44222262501716614\n",
      "tensor([1., 0.]) tensor([0.8710, 0.1290], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 45 - 11: cat - cat || Loss: 0.44210878014564514\n",
      "tensor([1., 0.]) tensor([0.8712, 0.1288], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 45 - 12: cat - cat || Loss: 0.4419761300086975\n",
      "tensor([1., 0.]) tensor([0.8713, 0.1287], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 45 - 13: cat - cat || Loss: 0.4418266713619232\n",
      "tensor([1., 0.]) tensor([0.8714, 0.1286], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 45 - 14: cat - cat || Loss: 0.441662073135376\n",
      "tensor([1., 0.]) tensor([0.8716, 0.1284], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 45 - 15: cat - cat || Loss: 0.4414840340614319\n",
      "tensor([1., 0.]) tensor([0.8718, 0.1282], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 45 - 16: cat - cat || Loss: 0.44129377603530884\n",
      "tensor([1., 0.]) tensor([0.8720, 0.1280], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 45 - 17: cat - cat || Loss: 0.44109272956848145\n",
      "tensor([1., 0.]) tensor([0.8722, 0.1278], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 45 - 18: cat - cat || Loss: 0.4408820867538452\n",
      "tensor([1., 0.]) tensor([0.8724, 0.1276], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 45 - 19: cat - cat || Loss: 0.4406626224517822\n",
      "tensor([1., 0.]) tensor([0.8726, 0.1274], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 45 - 20: cat - cat || Loss: 0.4404354691505432\n",
      "tensor([1., 0.]) tensor([0.8728, 0.1272], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 45 - 21: cat - cat || Loss: 0.44020143151283264\n",
      "tensor([1., 0.]) tensor([0.8731, 0.1269], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 45 - 22: cat - cat || Loss: 0.439961314201355\n",
      "tensor([1., 0.]) tensor([0.8733, 0.1267], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 45 - 23: cat - cat || Loss: 0.43971574306488037\n",
      "tensor([1., 0.]) tensor([0.8735, 0.1265], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 45 - 24: cat - cat || Loss: 0.4394652843475342\n",
      "tensor([1., 0.]) tensor([0.8738, 0.1262], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 45 - 25: cat - cat || Loss: 0.43921056389808655\n",
      "tensor([1., 0.]) tensor([0.8741, 0.1259], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 45 - 26: cat - cat || Loss: 0.43895208835601807\n",
      "tensor([1., 0.]) tensor([0.8743, 0.1257], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 45 - 27: cat - cat || Loss: 0.43869030475616455\n",
      "tensor([1., 0.]) tensor([0.8746, 0.1254], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 45 - 28: cat - cat || Loss: 0.43842560052871704\n",
      "tensor([1., 0.]) tensor([0.8748, 0.1252], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 45 - 29: cat - cat || Loss: 0.43815821409225464\n",
      "tensor([1., 0.]) tensor([0.8751, 0.1249], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 45 - 30: cat - cat || Loss: 0.43788865208625793\n",
      "tensor([1., 0.]) tensor([0.8754, 0.1246], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 45 - 31: cat - cat || Loss: 0.43761706352233887\n",
      "tensor([1., 0.]) tensor([0.8756, 0.1244], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 45 - 32: cat - cat || Loss: 0.4373438358306885\n",
      "tensor([1., 0.]) tensor([0.8759, 0.1241], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 45 - 33: cat - cat || Loss: 0.43706923723220825\n",
      "tensor([1., 0.]) tensor([0.8762, 0.1238], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 45 - 34: cat - cat || Loss: 0.4367932975292206\n",
      "tensor([1., 0.]) tensor([0.8765, 0.1235], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 45 - 35: cat - cat || Loss: 0.4365164041519165\n",
      "tensor([1., 0.]) tensor([0.8767, 0.1233], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 45 - 36: cat - cat || Loss: 0.43623852729797363\n",
      "tensor([1., 0.]) tensor([0.8770, 0.1230], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 45 - 37: cat - cat || Loss: 0.435960054397583\n",
      "tensor([1., 0.]) tensor([0.8773, 0.1227], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 45 - 38: cat - cat || Loss: 0.43568098545074463\n",
      "tensor([1., 0.]) tensor([0.8776, 0.1224], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 45 - 39: cat - cat || Loss: 0.43540140986442566\n",
      "tensor([1., 0.]) tensor([0.8779, 0.1221], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 45 - 40: cat - cat || Loss: 0.43512171506881714\n",
      "tensor([1., 0.]) tensor([0.8781, 0.1219], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 45 - 41: cat - cat || Loss: 0.4348415732383728\n",
      "tensor([1., 0.]) tensor([0.8784, 0.1216], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 45 - 42: cat - cat || Loss: 0.43456143140792847\n",
      "tensor([1., 0.]) tensor([0.8787, 0.1213], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 45 - 43: cat - cat || Loss: 0.43428105115890503\n",
      "tensor([1., 0.]) tensor([0.8790, 0.1210], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 45 - 44: cat - cat || Loss: 0.4340008795261383\n",
      "tensor([1., 0.]) tensor([0.8793, 0.1207], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 45 - 45: cat - cat || Loss: 0.43372073769569397\n",
      "tensor([1., 0.]) tensor([0.8795, 0.1205], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 45 - 46: cat - cat || Loss: 0.433440625667572\n",
      "tensor([1., 0.]) tensor([0.8798, 0.1202], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 45 - 47: cat - cat || Loss: 0.4331609010696411\n",
      "tensor([1., 0.]) tensor([0.8801, 0.1199], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 45 - 48: cat - cat || Loss: 0.43288135528564453\n",
      "tensor([1., 0.]) tensor([0.8804, 0.1196], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 45 - 49: cat - cat || Loss: 0.43260207772254944\n",
      "tensor([1., 0.]) tensor([0.8807, 0.1193], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 45 - 50: cat - cat || Loss: 0.432323157787323\n",
      "tensor([1., 0.]) tensor([0.8809, 0.1191], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 45 - 51: cat - cat || Loss: 0.4320446252822876\n",
      "tensor([1., 0.]) tensor([0.8812, 0.1188], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 45 - 52: cat - cat || Loss: 0.43176645040512085\n",
      "tensor([1., 0.]) tensor([0.8815, 0.1185], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 45 - 53: cat - cat || Loss: 0.43148869276046753\n",
      "tensor([1., 0.]) tensor([0.8818, 0.1182], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 45 - 54: cat - cat || Loss: 0.4312114119529724\n",
      "tensor([1., 0.]) tensor([0.8821, 0.1179], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 45 - 55: cat - cat || Loss: 0.4309346675872803\n",
      "tensor([1., 0.]) tensor([0.8823, 0.1177], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 45 - 56: cat - cat || Loss: 0.43065834045410156\n",
      "tensor([1., 0.]) tensor([0.8826, 0.1174], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 45 - 57: cat - cat || Loss: 0.4303824305534363\n",
      "tensor([1., 0.]) tensor([0.8829, 0.1171], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 45 - 58: cat - cat || Loss: 0.4301071763038635\n",
      "tensor([1., 0.]) tensor([0.8832, 0.1168], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 45 - 59: cat - cat || Loss: 0.42983245849609375\n",
      "tensor([1., 0.]) tensor([0.8834, 0.1166], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 45 - 60: cat - cat || Loss: 0.42955824732780457\n",
      "tensor([1., 0.]) tensor([0.8837, 0.1163], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 45 - 61: cat - cat || Loss: 0.42928454279899597\n",
      "tensor([1., 0.]) tensor([0.8840, 0.1160], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 45 - 62: cat - cat || Loss: 0.4290114939212799\n",
      "tensor([1., 0.]) tensor([0.8843, 0.1157], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 45 - 63: cat - cat || Loss: 0.428739070892334\n",
      "tensor([1., 0.]) tensor([0.8845, 0.1155], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 45 - 64: cat - cat || Loss: 0.4284670948982239\n",
      "tensor([1., 0.]) tensor([0.8848, 0.1152], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 45 - 65: cat - cat || Loss: 0.4281958043575287\n",
      "tensor([1., 0.]) tensor([0.8851, 0.1149], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 45 - 66: cat - cat || Loss: 0.42792510986328125\n",
      "tensor([1., 0.]) tensor([0.8853, 0.1147], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 45 - 67: cat - cat || Loss: 0.42765510082244873\n",
      "tensor([1., 0.]) tensor([0.8856, 0.1144], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 45 - 68: cat - cat || Loss: 0.4273855686187744\n",
      "tensor([1., 0.]) tensor([0.8859, 0.1141], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 45 - 69: cat - cat || Loss: 0.4271168112754822\n",
      "tensor([1., 0.]) tensor([0.8861, 0.1139], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 45 - 70: cat - cat || Loss: 0.4268485903739929\n",
      "tensor([1., 0.]) tensor([0.8864, 0.1136], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 45 - 71: cat - cat || Loss: 0.4265810251235962\n",
      "tensor([1., 0.]) tensor([0.8867, 0.1133], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 45 - 72: cat - cat || Loss: 0.42631399631500244\n",
      "tensor([1., 0.]) tensor([0.8869, 0.1131], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 45 - 73: cat - cat || Loss: 0.426047682762146\n",
      "tensor([1., 0.]) tensor([0.8872, 0.1128], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 45 - 74: cat - cat || Loss: 0.42578190565109253\n",
      "tensor([1., 0.]) tensor([0.8875, 0.1125], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 45 - 75: cat - cat || Loss: 0.42551690340042114\n",
      "tensor([1., 0.]) tensor([0.8877, 0.1123], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 45 - 76: cat - cat || Loss: 0.4252524673938751\n",
      "tensor([1., 0.]) tensor([0.8880, 0.1120], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 45 - 77: cat - cat || Loss: 0.42498865723609924\n",
      "tensor([1., 0.]) tensor([0.8883, 0.1117], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 45 - 78: cat - cat || Loss: 0.4247254729270935\n",
      "tensor([1., 0.]) tensor([0.8885, 0.1115], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 45 - 79: cat - cat || Loss: 0.4244629144668579\n",
      "tensor([1., 0.]) tensor([0.8888, 0.1112], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 45 - 80: cat - cat || Loss: 0.42420095205307007\n",
      "tensor([1., 0.]) tensor([0.8891, 0.1109], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 45 - 81: cat - cat || Loss: 0.42393970489501953\n",
      "tensor([1., 0.]) tensor([0.8893, 0.1107], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 45 - 82: cat - cat || Loss: 0.42367902398109436\n",
      "tensor([1., 0.]) tensor([0.8896, 0.1104], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 45 - 83: cat - cat || Loss: 0.4234190285205841\n",
      "tensor([1., 0.]) tensor([0.8898, 0.1102], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 45 - 84: cat - cat || Loss: 0.4231596887111664\n",
      "tensor([1., 0.]) tensor([0.8901, 0.1099], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 45 - 85: cat - cat || Loss: 0.4229009747505188\n",
      "tensor([1., 0.]) tensor([0.8904, 0.1096], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 45 - 86: cat - cat || Loss: 0.42264285683631897\n",
      "tensor([1., 0.]) tensor([0.8906, 0.1094], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 45 - 87: cat - cat || Loss: 0.4223853647708893\n",
      "tensor([1., 0.]) tensor([0.8909, 0.1091], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 45 - 88: cat - cat || Loss: 0.4221285283565521\n",
      "tensor([1., 0.]) tensor([0.8911, 0.1089], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 45 - 89: cat - cat || Loss: 0.4218722879886627\n",
      "tensor([1., 0.]) tensor([0.8914, 0.1086], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 45 - 90: cat - cat || Loss: 0.421616792678833\n",
      "tensor([1., 0.]) tensor([0.8916, 0.1084], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 45 - 91: cat - cat || Loss: 0.4213617742061615\n",
      "tensor([1., 0.]) tensor([0.8919, 0.1081], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 45 - 92: cat - cat || Loss: 0.4211074709892273\n",
      "tensor([1., 0.]) tensor([0.8922, 0.1078], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 45 - 93: cat - cat || Loss: 0.42085379362106323\n",
      "tensor([1., 0.]) tensor([0.8924, 0.1076], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 45 - 94: cat - cat || Loss: 0.4206007122993469\n",
      "tensor([1., 0.]) tensor([0.8927, 0.1073], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 45 - 95: cat - cat || Loss: 0.42034828662872314\n",
      "tensor([1., 0.]) tensor([0.8929, 0.1071], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 45 - 96: cat - cat || Loss: 0.4200965166091919\n",
      "tensor([1., 0.]) tensor([0.8932, 0.1068], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 45 - 97: cat - cat || Loss: 0.4198453724384308\n",
      "tensor([1., 0.]) tensor([0.8934, 0.1066], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 45 - 98: cat - cat || Loss: 0.41959476470947266\n",
      "tensor([1., 0.]) tensor([0.8937, 0.1063], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 45 - 99: cat - cat || Loss: 0.4193449020385742\n",
      "tensor([1., 0.]) tensor([0.8939, 0.1061], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 45 - 100: cat - cat || Loss: 0.41909554600715637\n",
      "tensor([1., 0.]) tensor([0.8942, 0.1058], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 45 - 101: cat - cat || Loss: 0.41884690523147583\n",
      "tensor([1., 0.]) tensor([0.8944, 0.1056], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 45 - 102: cat - cat || Loss: 0.4185989201068878\n",
      "tensor([1., 0.]) tensor([0.8947, 0.1053], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 45 - 103: cat - cat || Loss: 0.41835150122642517\n",
      "tensor([1., 0.]) tensor([0.8949, 0.1051], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 45 - 104: cat - cat || Loss: 0.4181046485900879\n",
      "tensor([1., 0.]) tensor([0.8952, 0.1048], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 45 - 105: cat - cat || Loss: 0.4178585410118103\n",
      "tensor([1., 0.]) tensor([0.8954, 0.1046], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 45 - 106: cat - cat || Loss: 0.4176129698753357\n",
      "tensor([1., 0.]) tensor([0.8956, 0.1044], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 45 - 107: cat - cat || Loss: 0.41736793518066406\n",
      "tensor([1., 0.]) tensor([0.8959, 0.1041], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 45 - 108: cat - cat || Loss: 0.4171236753463745\n",
      "tensor([1., 0.]) tensor([0.8961, 0.1039], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 45 - 109: cat - cat || Loss: 0.41687989234924316\n",
      "tensor([1., 0.]) tensor([0.8964, 0.1036], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 45 - 110: cat - cat || Loss: 0.41663676500320435\n",
      "tensor([1., 0.]) tensor([0.8966, 0.1034], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 45 - 111: cat - cat || Loss: 0.41639435291290283\n",
      "tensor([1., 0.]) tensor([0.8969, 0.1031], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 45 - 112: cat - cat || Loss: 0.41615229845046997\n",
      "tensor([1., 0.]) tensor([0.8971, 0.1029], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 45 - 113: cat - cat || Loss: 0.41591107845306396\n",
      "tensor([1., 0.]) tensor([0.8974, 0.1026], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 45 - 114: cat - cat || Loss: 0.4156704246997833\n",
      "tensor([1., 0.]) tensor([0.8976, 0.1024], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 45 - 115: cat - cat || Loss: 0.41543030738830566\n",
      "tensor([1., 0.]) tensor([0.8978, 0.1022], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 45 - 116: cat - cat || Loss: 0.41519084572792053\n",
      "tensor([1., 0.]) tensor([0.8981, 0.1019], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 45 - 117: cat - cat || Loss: 0.4149519205093384\n",
      "tensor([1., 0.]) tensor([0.8983, 0.1017], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 45 - 118: cat - cat || Loss: 0.41471368074417114\n",
      "tensor([1., 0.]) tensor([0.8985, 0.1015], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 45 - 119: cat - cat || Loss: 0.41447603702545166\n",
      "tensor([1., 0.]) tensor([0.8988, 0.1012], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 45 - 120: cat - cat || Loss: 0.4142388701438904\n",
      "tensor([1., 0.]) tensor([0.8990, 0.1010], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 45 - 121: cat - cat || Loss: 0.41400235891342163\n",
      "tensor([1., 0.]) tensor([0.8993, 0.1007], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 45 - 122: cat - cat || Loss: 0.4137665331363678\n",
      "tensor([1., 0.]) tensor([0.8995, 0.1005], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 45 - 123: cat - cat || Loss: 0.41353124380111694\n",
      "tensor([1., 0.]) tensor([0.8997, 0.1003], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 45 - 124: cat - cat || Loss: 0.41329658031463623\n",
      "tensor([1., 0.]) tensor([0.9000, 0.1000], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 45 - 125: cat - cat || Loss: 0.4130624830722809\n",
      "tensor([1., 0.]) tensor([0.9002, 0.0998], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 45 - 126: cat - cat || Loss: 0.4128289818763733\n",
      "tensor([1., 0.]) tensor([0.9004, 0.0996], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 45 - 127: cat - cat || Loss: 0.41259604692459106\n",
      "tensor([1., 0.]) tensor([0.9007, 0.0993], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 45 - 128: cat - cat || Loss: 0.4123637080192566\n",
      "tensor([1., 0.]) tensor([0.9009, 0.0991], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 45 - 129: cat - cat || Loss: 0.4121319651603699\n",
      "tensor([1., 0.]) tensor([0.9011, 0.0989], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 45 - 130: cat - cat || Loss: 0.4119008183479309\n",
      "tensor([1., 0.]) tensor([0.9014, 0.0986], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 45 - 131: cat - cat || Loss: 0.4116702079772949\n",
      "tensor([1., 0.]) tensor([0.9016, 0.0984], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 45 - 132: cat - cat || Loss: 0.41144028306007385\n",
      "tensor([1., 0.]) tensor([0.9018, 0.0982], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 45 - 133: cat - cat || Loss: 0.4112108051776886\n",
      "tensor([1., 0.]) tensor([0.9021, 0.0979], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 45 - 134: cat - cat || Loss: 0.4109819233417511\n",
      "tensor([1., 0.]) tensor([0.9023, 0.0977], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 45 - 135: cat - cat || Loss: 0.4107537567615509\n",
      "tensor([1., 0.]) tensor([0.9025, 0.0975], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 45 - 136: cat - cat || Loss: 0.4105260372161865\n",
      "tensor([1., 0.]) tensor([0.9027, 0.0973], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 45 - 137: cat - cat || Loss: 0.4102988839149475\n",
      "tensor([1., 0.]) tensor([0.9030, 0.0970], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 45 - 138: cat - cat || Loss: 0.41007235646247864\n",
      "tensor([1., 0.]) tensor([0.9032, 0.0968], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 45 - 139: cat - cat || Loss: 0.40984636545181274\n",
      "tensor([1., 0.]) tensor([0.9034, 0.0966], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 45 - 140: cat - cat || Loss: 0.409621000289917\n",
      "tensor([1., 0.]) tensor([0.9036, 0.0964], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 45 - 141: cat - cat || Loss: 0.40939605236053467\n",
      "tensor([1., 0.]) tensor([0.9039, 0.0961], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 45 - 142: cat - cat || Loss: 0.4091718792915344\n",
      "tensor([1., 0.]) tensor([0.9041, 0.0959], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 45 - 143: cat - cat || Loss: 0.4089481234550476\n",
      "tensor([1., 0.]) tensor([0.9043, 0.0957], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 45 - 144: cat - cat || Loss: 0.4087250232696533\n",
      "tensor([1., 0.]) tensor([0.9045, 0.0955], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 45 - 145: cat - cat || Loss: 0.408502459526062\n",
      "tensor([1., 0.]) tensor([0.9048, 0.0952], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 45 - 146: cat - cat || Loss: 0.4082804322242737\n",
      "tensor([1., 0.]) tensor([0.9050, 0.0950], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 45 - 147: cat - cat || Loss: 0.4080589711666107\n",
      "tensor([1., 0.]) tensor([0.9052, 0.0948], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 45 - 148: cat - cat || Loss: 0.40783804655075073\n",
      "tensor([1., 0.]) tensor([0.9054, 0.0946], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 45 - 149: cat - cat || Loss: 0.4076177775859833\n",
      "tensor([1., 0.]) tensor([0.9056, 0.0944], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 45 - 150: cat - cat || Loss: 0.40739795565605164\n",
      "tensor([1., 0.]) tensor([0.9059, 0.0941], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 45 - 151: cat - cat || Loss: 0.4071788191795349\n",
      "tensor([1., 0.]) tensor([0.9061, 0.0939], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 45 - 152: cat - cat || Loss: 0.4069601893424988\n",
      "tensor([1., 0.]) tensor([0.9063, 0.0937], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 45 - 153: cat - cat || Loss: 0.4067420959472656\n",
      "tensor([1., 0.]) tensor([0.9065, 0.0935], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 45 - 154: cat - cat || Loss: 0.40652453899383545\n",
      "tensor([1., 0.]) tensor([0.9067, 0.0933], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 45 - 155: cat - cat || Loss: 0.40630754828453064\n",
      "tensor([1., 0.]) tensor([0.9070, 0.0930], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 45 - 156: cat - cat || Loss: 0.4060911238193512\n",
      "tensor([1., 0.]) tensor([0.9072, 0.0928], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 45 - 157: cat - cat || Loss: 0.4058753252029419\n",
      "tensor([1., 0.]) tensor([0.9074, 0.0926], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 45 - 158: cat - cat || Loss: 0.40565991401672363\n",
      "tensor([1., 0.]) tensor([0.9076, 0.0924], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 45 - 159: cat - cat || Loss: 0.4054451584815979\n",
      "tensor([1., 0.]) tensor([0.9078, 0.0922], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 45 - 160: cat - cat || Loss: 0.40523090958595276\n",
      "tensor([1., 0.]) tensor([0.9080, 0.0920], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 45 - 161: cat - cat || Loss: 0.40501728653907776\n",
      "tensor([1., 0.]) tensor([0.9082, 0.0918], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 45 - 162: cat - cat || Loss: 0.40480419993400574\n",
      "tensor([1., 0.]) tensor([0.9085, 0.0915], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 45 - 163: cat - cat || Loss: 0.40459150075912476\n",
      "tensor([1., 0.]) tensor([0.9087, 0.0913], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 45 - 164: cat - cat || Loss: 0.4043794572353363\n",
      "tensor([1., 0.]) tensor([0.9089, 0.0911], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 45 - 165: cat - cat || Loss: 0.40416792035102844\n",
      "tensor([1., 0.]) tensor([0.9091, 0.0909], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 45 - 166: cat - cat || Loss: 0.40395694971084595\n",
      "tensor([1., 0.]) tensor([0.9093, 0.0907], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 45 - 167: cat - cat || Loss: 0.40374648571014404\n",
      "tensor([1., 0.]) tensor([0.9095, 0.0905], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 45 - 168: cat - cat || Loss: 0.4035365879535675\n",
      "tensor([1., 0.]) tensor([0.9097, 0.0903], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 45 - 169: cat - cat || Loss: 0.4033271074295044\n",
      "tensor([1., 0.]) tensor([0.9099, 0.0901], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 45 - 170: cat - cat || Loss: 0.4031182825565338\n",
      "tensor([1., 0.]) tensor([0.9101, 0.0899], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 45 - 171: cat - cat || Loss: 0.40290993452072144\n",
      "tensor([1., 0.]) tensor([0.9104, 0.0896], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 45 - 172: cat - cat || Loss: 0.40270209312438965\n",
      "tensor([1., 0.]) tensor([0.9106, 0.0894], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 45 - 173: cat - cat || Loss: 0.4024948477745056\n",
      "tensor([1., 0.]) tensor([0.9108, 0.0892], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 45 - 174: cat - cat || Loss: 0.4022880494594574\n",
      "tensor([1., 0.]) tensor([0.9110, 0.0890], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 45 - 175: cat - cat || Loss: 0.40208181738853455\n",
      "tensor([1., 0.]) tensor([0.9112, 0.0888], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 45 - 176: cat - cat || Loss: 0.4018760919570923\n",
      "tensor([1., 0.]) tensor([0.9114, 0.0886], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 45 - 177: cat - cat || Loss: 0.4016709327697754\n",
      "tensor([1., 0.]) tensor([0.9116, 0.0884], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 45 - 178: cat - cat || Loss: 0.4014662206172943\n",
      "tensor([1., 0.]) tensor([0.9118, 0.0882], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 45 - 179: cat - cat || Loss: 0.401262104511261\n",
      "tensor([1., 0.]) tensor([0.9120, 0.0880], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 45 - 180: cat - cat || Loss: 0.4010583758354187\n",
      "tensor([1., 0.]) tensor([0.9122, 0.0878], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 45 - 181: cat - cat || Loss: 0.40085524320602417\n",
      "tensor([1., 0.]) tensor([0.9124, 0.0876], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 45 - 182: cat - cat || Loss: 0.40065258741378784\n",
      "tensor([1., 0.]) tensor([0.9126, 0.0874], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 45 - 183: cat - cat || Loss: 0.40045058727264404\n",
      "tensor([1., 0.]) tensor([0.9128, 0.0872], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 45 - 184: cat - cat || Loss: 0.4002488851547241\n",
      "tensor([1., 0.]) tensor([0.9130, 0.0870], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 45 - 185: cat - cat || Loss: 0.40004783868789673\n",
      "tensor([1., 0.]) tensor([0.9132, 0.0868], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 45 - 186: cat - cat || Loss: 0.3998470902442932\n",
      "tensor([1., 0.]) tensor([0.9134, 0.0866], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 45 - 187: cat - cat || Loss: 0.39964696764945984\n",
      "tensor([1., 0.]) tensor([0.9136, 0.0864], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 45 - 188: cat - cat || Loss: 0.39944732189178467\n",
      "tensor([1., 0.]) tensor([0.9138, 0.0862], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 45 - 189: cat - cat || Loss: 0.3992481231689453\n",
      "tensor([1., 0.]) tensor([0.9140, 0.0860], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 45 - 190: dog - cat || Loss: 1.2274738550186157\n",
      "tensor([0., 1.]) tensor([0.9142, 0.0858], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 45 - 191: dog - cat || Loss: 1.2276328802108765\n",
      "tensor([0., 1.]) tensor([0.9144, 0.0856], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 45 - 192: dog - cat || Loss: 1.227756381034851\n",
      "tensor([0., 1.]) tensor([0.9145, 0.0855], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 45 - 193: dog - cat || Loss: 1.227847695350647\n",
      "tensor([0., 1.]) tensor([0.9146, 0.0854], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 45 - 194: dog - cat || Loss: 1.2279103994369507\n",
      "tensor([0., 1.]) tensor([0.9146, 0.0854], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 45 - 195: dog - cat || Loss: 1.2279472351074219\n",
      "tensor([0., 1.]) tensor([0.9147, 0.0853], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 45 - 196: dog - cat || Loss: 1.2279610633850098\n",
      "tensor([0., 1.]) tensor([0.9147, 0.0853], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 45 - 197: dog - cat || Loss: 1.2279536724090576\n",
      "tensor([0., 1.]) tensor([0.9147, 0.0853], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 45 - 198: dog - cat || Loss: 1.2279276847839355\n",
      "tensor([0., 1.]) tensor([0.9147, 0.0853], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 45 - 199: dog - cat || Loss: 1.2278846502304077\n",
      "tensor([0., 1.]) tensor([0.9146, 0.0854], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 45 - 200: dog - cat || Loss: 1.2278263568878174\n",
      "tensor([0., 1.]) tensor([0.9146, 0.0854], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 45 - 201: dog - cat || Loss: 1.2277544736862183\n",
      "tensor([0., 1.]) tensor([0.9145, 0.0855], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 45 - 202: dog - cat || Loss: 1.2276701927185059\n",
      "tensor([0., 1.]) tensor([0.9144, 0.0856], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 45 - 203: dog - cat || Loss: 1.2275747060775757\n",
      "tensor([0., 1.]) tensor([0.9143, 0.0857], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 45 - 204: dog - cat || Loss: 1.2274689674377441\n",
      "tensor([0., 1.]) tensor([0.9142, 0.0858], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 45 - 205: dog - cat || Loss: 1.2273542881011963\n",
      "tensor([0., 1.]) tensor([0.9141, 0.0859], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 45 - 206: dog - cat || Loss: 1.2272312641143799\n",
      "tensor([0., 1.]) tensor([0.9140, 0.0860], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 45 - 207: dog - cat || Loss: 1.2271009683609009\n",
      "tensor([0., 1.]) tensor([0.9138, 0.0862], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 45 - 208: dog - cat || Loss: 1.2269636392593384\n",
      "tensor([0., 1.]) tensor([0.9137, 0.0863], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 45 - 209: dog - cat || Loss: 1.226820468902588\n",
      "tensor([0., 1.]) tensor([0.9136, 0.0864], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 45 - 210: dog - cat || Loss: 1.226671576499939\n",
      "tensor([0., 1.]) tensor([0.9134, 0.0866], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 45 - 211: dog - cat || Loss: 1.226517677307129\n",
      "tensor([0., 1.]) tensor([0.9133, 0.0867], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 45 - 212: dog - cat || Loss: 1.226359248161316\n",
      "tensor([0., 1.]) tensor([0.9131, 0.0869], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 45 - 213: dog - cat || Loss: 1.226196527481079\n",
      "tensor([0., 1.]) tensor([0.9129, 0.0871], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 45 - 214: dog - cat || Loss: 1.2260301113128662\n",
      "tensor([0., 1.]) tensor([0.9128, 0.0872], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 45 - 215: dog - cat || Loss: 1.2258602380752563\n",
      "tensor([0., 1.]) tensor([0.9126, 0.0874], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 45 - 216: dog - cat || Loss: 1.2256871461868286\n",
      "tensor([0., 1.]) tensor([0.9124, 0.0876], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 45 - 217: dog - cat || Loss: 1.225511074066162\n",
      "tensor([0., 1.]) tensor([0.9122, 0.0878], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 45 - 218: dog - cat || Loss: 1.225332498550415\n",
      "tensor([0., 1.]) tensor([0.9121, 0.0879], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 45 - 219: dog - cat || Loss: 1.2251513004302979\n",
      "tensor([0., 1.]) tensor([0.9119, 0.0881], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 45 - 220: dog - cat || Loss: 1.2249679565429688\n",
      "tensor([0., 1.]) tensor([0.9117, 0.0883], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 45 - 221: dog - cat || Loss: 1.2247824668884277\n",
      "tensor([0., 1.]) tensor([0.9115, 0.0885], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 45 - 222: dog - cat || Loss: 1.224595069885254\n",
      "tensor([0., 1.]) tensor([0.9113, 0.0887], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 45 - 223: dog - cat || Loss: 1.2244058847427368\n",
      "tensor([0., 1.]) tensor([0.9111, 0.0889], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 45 - 224: dog - cat || Loss: 1.224215030670166\n",
      "tensor([0., 1.]) tensor([0.9110, 0.0890], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 45 - 225: dog - cat || Loss: 1.224022626876831\n",
      "tensor([0., 1.]) tensor([0.9108, 0.0892], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 45 - 226: dog - cat || Loss: 1.2238290309906006\n",
      "tensor([0., 1.]) tensor([0.9106, 0.0894], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 45 - 227: dog - cat || Loss: 1.223633885383606\n",
      "tensor([0., 1.]) tensor([0.9104, 0.0896], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 45 - 228: dog - cat || Loss: 1.2234373092651367\n",
      "tensor([0., 1.]) tensor([0.9102, 0.0898], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 45 - 229: dog - cat || Loss: 1.2232400178909302\n",
      "tensor([0., 1.]) tensor([0.9100, 0.0900], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 45 - 230: dog - cat || Loss: 1.223041296005249\n",
      "tensor([0., 1.]) tensor([0.9098, 0.0902], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 45 - 231: dog - cat || Loss: 1.222841501235962\n",
      "tensor([0., 1.]) tensor([0.9096, 0.0904], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 45 - 232: dog - cat || Loss: 1.222640872001648\n",
      "tensor([0., 1.]) tensor([0.9094, 0.0906], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 45 - 233: dog - cat || Loss: 1.2224392890930176\n",
      "tensor([0., 1.]) tensor([0.9092, 0.0908], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 45 - 234: dog - cat || Loss: 1.2222367525100708\n",
      "tensor([0., 1.]) tensor([0.9090, 0.0910], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 45 - 235: dog - cat || Loss: 1.2220332622528076\n",
      "tensor([0., 1.]) tensor([0.9088, 0.0912], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 45 - 236: dog - cat || Loss: 1.2218289375305176\n",
      "tensor([0., 1.]) tensor([0.9086, 0.0914], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 45 - 237: dog - cat || Loss: 1.2216237783432007\n",
      "tensor([0., 1.]) tensor([0.9084, 0.0916], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 45 - 238: dog - cat || Loss: 1.221418023109436\n",
      "tensor([0., 1.]) tensor([0.9082, 0.0918], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 45 - 239: dog - cat || Loss: 1.221211314201355\n",
      "tensor([0., 1.]) tensor([0.9079, 0.0921], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 45 - 240: dog - cat || Loss: 1.2210040092468262\n",
      "tensor([0., 1.]) tensor([0.9077, 0.0923], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 45 - 241: dog - cat || Loss: 1.22079598903656\n",
      "tensor([0., 1.]) tensor([0.9075, 0.0925], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 45 - 242: dog - cat || Loss: 1.220587134361267\n",
      "tensor([0., 1.]) tensor([0.9073, 0.0927], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 45 - 243: dog - cat || Loss: 1.2203779220581055\n",
      "tensor([0., 1.]) tensor([0.9071, 0.0929], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 45 - 244: dog - cat || Loss: 1.2201677560806274\n",
      "tensor([0., 1.]) tensor([0.9069, 0.0931], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 45 - 245: dog - cat || Loss: 1.2199571132659912\n",
      "tensor([0., 1.]) tensor([0.9067, 0.0933], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 45 - 246: dog - cat || Loss: 1.2197457551956177\n",
      "tensor([0., 1.]) tensor([0.9065, 0.0935], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 45 - 247: dog - cat || Loss: 1.2195338010787964\n",
      "tensor([0., 1.]) tensor([0.9063, 0.0937], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 45 - 248: dog - cat || Loss: 1.2193212509155273\n",
      "tensor([0., 1.]) tensor([0.9061, 0.0939], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 45 - 249: dog - cat || Loss: 1.2191081047058105\n",
      "tensor([0., 1.]) tensor([0.9058, 0.0942], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 45 - 250: dog - cat || Loss: 1.2188942432403564\n",
      "tensor([0., 1.]) tensor([0.9056, 0.0944], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 45 - 251: dog - cat || Loss: 1.2186799049377441\n",
      "tensor([0., 1.]) tensor([0.9054, 0.0946], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 45 - 252: dog - cat || Loss: 1.2184650897979736\n",
      "tensor([0., 1.]) tensor([0.9052, 0.0948], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 45 - 253: dog - cat || Loss: 1.2182493209838867\n",
      "tensor([0., 1.]) tensor([0.9050, 0.0950], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 45 - 254: dog - cat || Loss: 1.2180333137512207\n",
      "tensor([0., 1.]) tensor([0.9048, 0.0952], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 45 - 255: dog - cat || Loss: 1.2178164720535278\n",
      "tensor([0., 1.]) tensor([0.9046, 0.0954], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 45 - 256: dog - cat || Loss: 1.2175991535186768\n",
      "tensor([0., 1.]) tensor([0.9043, 0.0957], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 45 - 257: dog - cat || Loss: 1.2173813581466675\n",
      "tensor([0., 1.]) tensor([0.9041, 0.0959], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 45 - 258: dog - cat || Loss: 1.217162847518921\n",
      "tensor([0., 1.]) tensor([0.9039, 0.0961], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 45 - 259: dog - cat || Loss: 1.2169438600540161\n",
      "tensor([0., 1.]) tensor([0.9037, 0.0963], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 45 - 260: dog - cat || Loss: 1.2167243957519531\n",
      "tensor([0., 1.]) tensor([0.9035, 0.0965], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 45 - 261: dog - cat || Loss: 1.2165043354034424\n",
      "tensor([0., 1.]) tensor([0.9032, 0.0968], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 45 - 262: dog - cat || Loss: 1.2162835597991943\n",
      "tensor([0., 1.]) tensor([0.9030, 0.0970], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 45 - 263: dog - cat || Loss: 1.216062307357788\n",
      "tensor([0., 1.]) tensor([0.9028, 0.0972], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 45 - 264: dog - cat || Loss: 1.215840458869934\n",
      "tensor([0., 1.]) tensor([0.9026, 0.0974], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 45 - 265: dog - cat || Loss: 1.2156181335449219\n",
      "tensor([0., 1.]) tensor([0.9024, 0.0976], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 45 - 266: dog - cat || Loss: 1.215395212173462\n",
      "tensor([0., 1.]) tensor([0.9021, 0.0979], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 45 - 267: dog - cat || Loss: 1.2151718139648438\n",
      "tensor([0., 1.]) tensor([0.9019, 0.0981], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 45 - 268: dog - cat || Loss: 1.2149477005004883\n",
      "tensor([0., 1.]) tensor([0.9017, 0.0983], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 45 - 269: dog - cat || Loss: 1.214722990989685\n",
      "tensor([0., 1.]) tensor([0.9015, 0.0985], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 45 - 270: dog - cat || Loss: 1.2144978046417236\n",
      "tensor([0., 1.]) tensor([0.9012, 0.0988], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 45 - 271: dog - cat || Loss: 1.2142722606658936\n",
      "tensor([0., 1.]) tensor([0.9010, 0.0990], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 45 - 272: dog - cat || Loss: 1.214045763015747\n",
      "tensor([0., 1.]) tensor([0.9008, 0.0992], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 45 - 273: dog - cat || Loss: 1.213819146156311\n",
      "tensor([0., 1.]) tensor([0.9006, 0.0994], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 45 - 274: dog - cat || Loss: 1.2135916948318481\n",
      "tensor([0., 1.]) tensor([0.9003, 0.0997], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 45 - 275: dog - cat || Loss: 1.2133636474609375\n",
      "tensor([0., 1.]) tensor([0.9001, 0.0999], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 45 - 276: dog - cat || Loss: 1.2131351232528687\n",
      "tensor([0., 1.]) tensor([0.8999, 0.1001], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 45 - 277: dog - cat || Loss: 1.2129061222076416\n",
      "tensor([0., 1.]) tensor([0.8996, 0.1004], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 45 - 278: dog - cat || Loss: 1.2126764059066772\n",
      "tensor([0., 1.]) tensor([0.8994, 0.1006], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 45 - 279: dog - cat || Loss: 1.2124462127685547\n",
      "tensor([0., 1.]) tensor([0.8992, 0.1008], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 45 - 280: dog - cat || Loss: 1.2122153043746948\n",
      "tensor([0., 1.]) tensor([0.8990, 0.1010], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 45 - 281: dog - cat || Loss: 1.2119839191436768\n",
      "tensor([0., 1.]) tensor([0.8987, 0.1013], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 45 - 282: dog - cat || Loss: 1.2117520570755005\n",
      "tensor([0., 1.]) tensor([0.8985, 0.1015], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 45 - 283: dog - cat || Loss: 1.2115195989608765\n",
      "tensor([0., 1.]) tensor([0.8983, 0.1017], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 45 - 284: dog - cat || Loss: 1.2112864255905151\n",
      "tensor([0., 1.]) tensor([0.8980, 0.1020], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 45 - 285: dog - cat || Loss: 1.211052656173706\n",
      "tensor([0., 1.]) tensor([0.8978, 0.1022], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 45 - 286: dog - cat || Loss: 1.2108185291290283\n",
      "tensor([0., 1.]) tensor([0.8976, 0.1024], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 45 - 287: dog - cat || Loss: 1.2105838060379028\n",
      "tensor([0., 1.]) tensor([0.8973, 0.1027], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 45 - 288: dog - cat || Loss: 1.21034836769104\n",
      "tensor([0., 1.]) tensor([0.8971, 0.1029], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 45 - 289: dog - cat || Loss: 1.2101125717163086\n",
      "tensor([0., 1.]) tensor([0.8969, 0.1031], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 45 - 290: dog - cat || Loss: 1.2098759412765503\n",
      "tensor([0., 1.]) tensor([0.8966, 0.1034], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 45 - 291: dog - cat || Loss: 1.2096388339996338\n",
      "tensor([0., 1.]) tensor([0.8964, 0.1036], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 45 - 292: dog - cat || Loss: 1.2094011306762695\n",
      "tensor([0., 1.]) tensor([0.8961, 0.1039], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 45 - 293: dog - cat || Loss: 1.2091628313064575\n",
      "tensor([0., 1.]) tensor([0.8959, 0.1041], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 45 - 294: dog - cat || Loss: 1.2089240550994873\n",
      "tensor([0., 1.]) tensor([0.8957, 0.1043], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 45 - 295: dog - cat || Loss: 1.2086846828460693\n",
      "tensor([0., 1.]) tensor([0.8954, 0.1046], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 45 - 296: dog - cat || Loss: 1.208444595336914\n",
      "tensor([0., 1.]) tensor([0.8952, 0.1048], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 45 - 297: dog - cat || Loss: 1.2082040309906006\n",
      "tensor([0., 1.]) tensor([0.8949, 0.1051], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 45 - 298: dog - cat || Loss: 1.2079628705978394\n",
      "tensor([0., 1.]) tensor([0.8947, 0.1053], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 45 - 299: dog - cat || Loss: 1.2077211141586304\n",
      "tensor([0., 1.]) tensor([0.8945, 0.1055], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 45 - 300: dog - cat || Loss: 1.2074787616729736\n",
      "tensor([0., 1.]) tensor([0.8942, 0.1058], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 45 - 301: dog - cat || Loss: 1.2072358131408691\n",
      "tensor([0., 1.]) tensor([0.8940, 0.1060], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 45 - 302: dog - cat || Loss: 1.2069923877716064\n",
      "tensor([0., 1.]) tensor([0.8937, 0.1063], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 45 - 303: dog - cat || Loss: 1.2067482471466064\n",
      "tensor([0., 1.]) tensor([0.8935, 0.1065], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 45 - 304: dog - cat || Loss: 1.2065035104751587\n",
      "tensor([0., 1.]) tensor([0.8932, 0.1068], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 45 - 305: dog - cat || Loss: 1.2062581777572632\n",
      "tensor([0., 1.]) tensor([0.8930, 0.1070], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 45 - 306: dog - cat || Loss: 1.20601224899292\n",
      "tensor([0., 1.]) tensor([0.8928, 0.1072], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 45 - 307: dog - cat || Loss: 1.2057658433914185\n",
      "tensor([0., 1.]) tensor([0.8925, 0.1075], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 45 - 308: dog - cat || Loss: 1.2055186033248901\n",
      "tensor([0., 1.]) tensor([0.8923, 0.1077], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 45 - 309: dog - cat || Loss: 1.2052710056304932\n",
      "tensor([0., 1.]) tensor([0.8920, 0.1080], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 45 - 310: dog - cat || Loss: 1.2050228118896484\n",
      "tensor([0., 1.]) tensor([0.8918, 0.1082], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 45 - 311: dog - cat || Loss: 1.2047737836837769\n",
      "tensor([0., 1.]) tensor([0.8915, 0.1085], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 45 - 312: dog - cat || Loss: 1.204524278640747\n",
      "tensor([0., 1.]) tensor([0.8913, 0.1087], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 45 - 313: dog - cat || Loss: 1.2042741775512695\n",
      "tensor([0., 1.]) tensor([0.8910, 0.1090], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 45 - 314: dog - cat || Loss: 1.2040234804153442\n",
      "tensor([0., 1.]) tensor([0.8908, 0.1092], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 45 - 315: dog - cat || Loss: 1.2037723064422607\n",
      "tensor([0., 1.]) tensor([0.8905, 0.1095], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 45 - 316: dog - cat || Loss: 1.2035201787948608\n",
      "tensor([0., 1.]) tensor([0.8903, 0.1097], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 45 - 317: dog - cat || Loss: 1.2032678127288818\n",
      "tensor([0., 1.]) tensor([0.8900, 0.1100], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 45 - 318: dog - cat || Loss: 1.203014612197876\n",
      "tensor([0., 1.]) tensor([0.8898, 0.1102], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 45 - 319: dog - cat || Loss: 1.202760934829712\n",
      "tensor([0., 1.]) tensor([0.8895, 0.1105], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 45 - 320: dog - cat || Loss: 1.2025065422058105\n",
      "tensor([0., 1.]) tensor([0.8892, 0.1108], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 45 - 321: dog - cat || Loss: 1.2022515535354614\n",
      "tensor([0., 1.]) tensor([0.8890, 0.1110], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 45 - 322: dog - cat || Loss: 1.201996088027954\n",
      "tensor([0., 1.]) tensor([0.8887, 0.1113], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 45 - 323: dog - cat || Loss: 1.20173978805542\n",
      "tensor([0., 1.]) tensor([0.8885, 0.1115], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 45 - 324: dog - cat || Loss: 1.201483130455017\n",
      "tensor([0., 1.]) tensor([0.8882, 0.1118], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 45 - 325: dog - cat || Loss: 1.2012256383895874\n",
      "tensor([0., 1.]) tensor([0.8880, 0.1120], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 45 - 326: dog - cat || Loss: 1.20096755027771\n",
      "tensor([0., 1.]) tensor([0.8877, 0.1123], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 45 - 327: dog - cat || Loss: 1.2007088661193848\n",
      "tensor([0., 1.]) tensor([0.8874, 0.1126], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 45 - 328: dog - cat || Loss: 1.200449824333191\n",
      "tensor([0., 1.]) tensor([0.8872, 0.1128], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 45 - 329: dog - cat || Loss: 1.2001898288726807\n",
      "tensor([0., 1.]) tensor([0.8869, 0.1131], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 45 - 330: dog - cat || Loss: 1.1999292373657227\n",
      "tensor([0., 1.]) tensor([0.8867, 0.1133], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 45 - 331: dog - cat || Loss: 1.1996681690216064\n",
      "tensor([0., 1.]) tensor([0.8864, 0.1136], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 45 - 332: dog - cat || Loss: 1.1994062662124634\n",
      "tensor([0., 1.]) tensor([0.8861, 0.1139], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 45 - 333: dog - cat || Loss: 1.1991437673568726\n",
      "tensor([0., 1.]) tensor([0.8859, 0.1141], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 45 - 334: dog - cat || Loss: 1.1988807916641235\n",
      "tensor([0., 1.]) tensor([0.8856, 0.1144], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 45 - 335: dog - cat || Loss: 1.1986169815063477\n",
      "tensor([0., 1.]) tensor([0.8854, 0.1146], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 45 - 336: dog - cat || Loss: 1.1983528137207031\n",
      "tensor([0., 1.]) tensor([0.8851, 0.1149], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 45 - 337: dog - cat || Loss: 1.1980878114700317\n",
      "tensor([0., 1.]) tensor([0.8848, 0.1152], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 45 - 338: dog - cat || Loss: 1.1978222131729126\n",
      "tensor([0., 1.]) tensor([0.8846, 0.1154], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 45 - 339: dog - cat || Loss: 1.1975560188293457\n",
      "tensor([0., 1.]) tensor([0.8843, 0.1157], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 45 - 340: dog - cat || Loss: 1.197288990020752\n",
      "tensor([0., 1.]) tensor([0.8840, 0.1160], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 45 - 341: dog - cat || Loss: 1.1970216035842896\n",
      "tensor([0., 1.]) tensor([0.8838, 0.1162], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 45 - 342: dog - cat || Loss: 1.1967535018920898\n",
      "tensor([0., 1.]) tensor([0.8835, 0.1165], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 45 - 343: dog - cat || Loss: 1.1964846849441528\n",
      "tensor([0., 1.]) tensor([0.8832, 0.1168], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 45 - 344: dog - cat || Loss: 1.196215271949768\n",
      "tensor([0., 1.]) tensor([0.8830, 0.1170], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 45 - 345: dog - cat || Loss: 1.195945143699646\n",
      "tensor([0., 1.]) tensor([0.8827, 0.1173], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 45 - 346: dog - cat || Loss: 1.1956744194030762\n",
      "tensor([0., 1.]) tensor([0.8824, 0.1176], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 45 - 347: dog - cat || Loss: 1.1954030990600586\n",
      "tensor([0., 1.]) tensor([0.8821, 0.1179], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 45 - 348: dog - cat || Loss: 1.1951309442520142\n",
      "tensor([0., 1.]) tensor([0.8819, 0.1181], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 45 - 349: dog - cat || Loss: 1.194858431816101\n",
      "tensor([0., 1.]) tensor([0.8816, 0.1184], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 45 - 350: dog - cat || Loss: 1.1945850849151611\n",
      "tensor([0., 1.]) tensor([0.8813, 0.1187], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 45 - 351: dog - cat || Loss: 1.1943110227584839\n",
      "tensor([0., 1.]) tensor([0.8810, 0.1190], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 45 - 352: dog - cat || Loss: 1.1940364837646484\n",
      "tensor([0., 1.]) tensor([0.8808, 0.1192], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 45 - 353: dog - cat || Loss: 1.1937612295150757\n",
      "tensor([0., 1.]) tensor([0.8805, 0.1195], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 45 - 354: dog - cat || Loss: 1.1934852600097656\n",
      "tensor([0., 1.]) tensor([0.8802, 0.1198], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 45 - 355: dog - cat || Loss: 1.1932086944580078\n",
      "tensor([0., 1.]) tensor([0.8799, 0.1201], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 45 - 356: dog - cat || Loss: 1.1929312944412231\n",
      "tensor([0., 1.]) tensor([0.8797, 0.1203], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 45 - 357: dog - cat || Loss: 1.1926534175872803\n",
      "tensor([0., 1.]) tensor([0.8794, 0.1206], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 45 - 358: dog - cat || Loss: 1.1923749446868896\n",
      "tensor([0., 1.]) tensor([0.8791, 0.1209], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 45 - 359: dog - cat || Loss: 1.1920955181121826\n",
      "tensor([0., 1.]) tensor([0.8788, 0.1212], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 45 - 360: dog - cat || Loss: 1.1918156147003174\n",
      "tensor([0., 1.]) tensor([0.8786, 0.1214], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 45 - 361: dog - cat || Loss: 1.1915351152420044\n",
      "tensor([0., 1.]) tensor([0.8783, 0.1217], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 45 - 362: dog - cat || Loss: 1.191253900527954\n",
      "tensor([0., 1.]) tensor([0.8780, 0.1220], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 45 - 363: dog - cat || Loss: 1.1909719705581665\n",
      "tensor([0., 1.]) tensor([0.8777, 0.1223], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 45 - 364: dog - cat || Loss: 1.1906894445419312\n",
      "tensor([0., 1.]) tensor([0.8774, 0.1226], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 45 - 365: dog - cat || Loss: 1.1904062032699585\n",
      "tensor([0., 1.]) tensor([0.8771, 0.1229], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 45 - 366: dog - cat || Loss: 1.1901222467422485\n",
      "tensor([0., 1.]) tensor([0.8769, 0.1231], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 45 - 367: dog - cat || Loss: 1.1898375749588013\n",
      "tensor([0., 1.]) tensor([0.8766, 0.1234], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 45 - 368: dog - cat || Loss: 1.1895523071289062\n",
      "tensor([0., 1.]) tensor([0.8763, 0.1237], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 45 - 369: dog - cat || Loss: 1.1892664432525635\n",
      "tensor([0., 1.]) tensor([0.8760, 0.1240], grad_fn=<SoftmaxBackward0>)\n",
      "=====epoch:46=====\n",
      "Epoch 46 - 0: cat - cat || Loss: 0.4375436305999756\n",
      "tensor([1., 0.]) tensor([0.8757, 0.1243], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 46 - 1: cat - cat || Loss: 0.43777281045913696\n",
      "tensor([1., 0.]) tensor([0.8755, 0.1245], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 46 - 2: cat - cat || Loss: 0.4379502534866333\n",
      "tensor([1., 0.]) tensor([0.8753, 0.1247], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 46 - 3: cat - cat || Loss: 0.4380808472633362\n",
      "tensor([1., 0.]) tensor([0.8752, 0.1248], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 46 - 4: cat - cat || Loss: 0.43816930055618286\n",
      "tensor([1., 0.]) tensor([0.8751, 0.1249], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 46 - 5: cat - cat || Loss: 0.43821972608566284\n",
      "tensor([1., 0.]) tensor([0.8750, 0.1250], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 46 - 6: cat - cat || Loss: 0.43823590874671936\n",
      "tensor([1., 0.]) tensor([0.8750, 0.1250], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 46 - 7: cat - cat || Loss: 0.4382213354110718\n",
      "tensor([1., 0.]) tensor([0.8750, 0.1250], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 46 - 8: cat - cat || Loss: 0.43817904591560364\n",
      "tensor([1., 0.]) tensor([0.8751, 0.1249], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 46 - 9: cat - cat || Loss: 0.4381117820739746\n",
      "tensor([1., 0.]) tensor([0.8751, 0.1249], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 46 - 10: cat - cat || Loss: 0.43802204728126526\n",
      "tensor([1., 0.]) tensor([0.8752, 0.1248], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 46 - 11: cat - cat || Loss: 0.43791231513023376\n",
      "tensor([1., 0.]) tensor([0.8753, 0.1247], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 46 - 12: cat - cat || Loss: 0.4377844035625458\n",
      "tensor([1., 0.]) tensor([0.8755, 0.1245], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 46 - 13: cat - cat || Loss: 0.43764030933380127\n",
      "tensor([1., 0.]) tensor([0.8756, 0.1244], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 46 - 14: cat - cat || Loss: 0.43748167157173157\n",
      "tensor([1., 0.]) tensor([0.8758, 0.1242], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 46 - 15: cat - cat || Loss: 0.43731003999710083\n",
      "tensor([1., 0.]) tensor([0.8760, 0.1240], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 46 - 16: cat - cat || Loss: 0.43712669610977173\n",
      "tensor([1., 0.]) tensor([0.8761, 0.1239], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 46 - 17: cat - cat || Loss: 0.43693286180496216\n",
      "tensor([1., 0.]) tensor([0.8763, 0.1237], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 46 - 18: cat - cat || Loss: 0.4367297887802124\n",
      "tensor([1., 0.]) tensor([0.8765, 0.1235], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 46 - 19: cat - cat || Loss: 0.4365183115005493\n",
      "tensor([1., 0.]) tensor([0.8767, 0.1233], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 46 - 20: cat - cat || Loss: 0.43629932403564453\n",
      "tensor([1., 0.]) tensor([0.8770, 0.1230], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 46 - 21: cat - cat || Loss: 0.43607383966445923\n",
      "tensor([1., 0.]) tensor([0.8772, 0.1228], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 46 - 22: cat - cat || Loss: 0.43584245443344116\n",
      "tensor([1., 0.]) tensor([0.8774, 0.1226], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 46 - 23: cat - cat || Loss: 0.43560582399368286\n",
      "tensor([1., 0.]) tensor([0.8777, 0.1223], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 46 - 24: cat - cat || Loss: 0.4353645443916321\n",
      "tensor([1., 0.]) tensor([0.8779, 0.1221], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 46 - 25: cat - cat || Loss: 0.435119092464447\n",
      "tensor([1., 0.]) tensor([0.8781, 0.1219], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 46 - 26: cat - cat || Loss: 0.43487000465393066\n",
      "tensor([1., 0.]) tensor([0.8784, 0.1216], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 46 - 27: cat - cat || Loss: 0.4346177577972412\n",
      "tensor([1., 0.]) tensor([0.8786, 0.1214], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 46 - 28: cat - cat || Loss: 0.4343627095222473\n",
      "tensor([1., 0.]) tensor([0.8789, 0.1211], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 46 - 29: cat - cat || Loss: 0.4341050982475281\n",
      "tensor([1., 0.]) tensor([0.8792, 0.1208], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 46 - 30: cat - cat || Loss: 0.4338453412055969\n",
      "tensor([1., 0.]) tensor([0.8794, 0.1206], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 46 - 31: cat - cat || Loss: 0.43358373641967773\n",
      "tensor([1., 0.]) tensor([0.8797, 0.1203], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 46 - 32: cat - cat || Loss: 0.43332046270370483\n",
      "tensor([1., 0.]) tensor([0.8799, 0.1201], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 46 - 33: cat - cat || Loss: 0.43305593729019165\n",
      "tensor([1., 0.]) tensor([0.8802, 0.1198], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 46 - 34: cat - cat || Loss: 0.432790070772171\n",
      "tensor([1., 0.]) tensor([0.8805, 0.1195], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 46 - 35: cat - cat || Loss: 0.43252333998680115\n",
      "tensor([1., 0.]) tensor([0.8807, 0.1193], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 46 - 36: cat - cat || Loss: 0.43225571513175964\n",
      "tensor([1., 0.]) tensor([0.8810, 0.1190], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 46 - 37: cat - cat || Loss: 0.431987464427948\n",
      "tensor([1., 0.]) tensor([0.8813, 0.1187], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 46 - 38: cat - cat || Loss: 0.4317185878753662\n",
      "tensor([1., 0.]) tensor([0.8815, 0.1185], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 46 - 39: cat - cat || Loss: 0.4314493238925934\n",
      "tensor([1., 0.]) tensor([0.8818, 0.1182], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 46 - 40: cat - cat || Loss: 0.43117982149124146\n",
      "tensor([1., 0.]) tensor([0.8821, 0.1179], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 46 - 41: cat - cat || Loss: 0.4309099614620209\n",
      "tensor([1., 0.]) tensor([0.8824, 0.1176], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 46 - 42: cat - cat || Loss: 0.4306401312351227\n",
      "tensor([1., 0.]) tensor([0.8826, 0.1174], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 46 - 43: cat - cat || Loss: 0.4303700625896454\n",
      "tensor([1., 0.]) tensor([0.8829, 0.1171], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 46 - 44: cat - cat || Loss: 0.43010029196739197\n",
      "tensor([1., 0.]) tensor([0.8832, 0.1168], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 46 - 45: cat - cat || Loss: 0.429830402135849\n",
      "tensor([1., 0.]) tensor([0.8834, 0.1166], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 46 - 46: cat - cat || Loss: 0.42956072092056274\n",
      "tensor([1., 0.]) tensor([0.8837, 0.1163], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 46 - 47: cat - cat || Loss: 0.4292911887168884\n",
      "tensor([1., 0.]) tensor([0.8840, 0.1160], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 46 - 48: cat - cat || Loss: 0.429021954536438\n",
      "tensor([1., 0.]) tensor([0.8842, 0.1158], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 46 - 49: cat - cat || Loss: 0.4287530183792114\n",
      "tensor([1., 0.]) tensor([0.8845, 0.1155], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 46 - 50: cat - cat || Loss: 0.42848432064056396\n",
      "tensor([1., 0.]) tensor([0.8848, 0.1152], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 46 - 51: cat - cat || Loss: 0.4282160997390747\n",
      "tensor([1., 0.]) tensor([0.8850, 0.1150], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 46 - 52: cat - cat || Loss: 0.42794814705848694\n",
      "tensor([1., 0.]) tensor([0.8853, 0.1147], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 46 - 53: cat - cat || Loss: 0.42768073081970215\n",
      "tensor([1., 0.]) tensor([0.8856, 0.1144], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 46 - 54: cat - cat || Loss: 0.4274136424064636\n",
      "tensor([1., 0.]) tensor([0.8858, 0.1142], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 46 - 55: cat - cat || Loss: 0.4271470904350281\n",
      "tensor([1., 0.]) tensor([0.8861, 0.1139], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 46 - 56: cat - cat || Loss: 0.42688101530075073\n",
      "tensor([1., 0.]) tensor([0.8864, 0.1136], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 46 - 57: cat - cat || Loss: 0.4266153573989868\n",
      "tensor([1., 0.]) tensor([0.8866, 0.1134], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 46 - 58: cat - cat || Loss: 0.42635026574134827\n",
      "tensor([1., 0.]) tensor([0.8869, 0.1131], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 46 - 59: cat - cat || Loss: 0.4260857403278351\n",
      "tensor([1., 0.]) tensor([0.8872, 0.1128], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 46 - 60: cat - cat || Loss: 0.4258217215538025\n",
      "tensor([1., 0.]) tensor([0.8874, 0.1126], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 46 - 61: cat - cat || Loss: 0.4255582094192505\n",
      "tensor([1., 0.]) tensor([0.8877, 0.1123], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 46 - 62: cat - cat || Loss: 0.4252951741218567\n",
      "tensor([1., 0.]) tensor([0.8880, 0.1120], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 46 - 63: cat - cat || Loss: 0.42503297328948975\n",
      "tensor([1., 0.]) tensor([0.8882, 0.1118], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 46 - 64: cat - cat || Loss: 0.4247710704803467\n",
      "tensor([1., 0.]) tensor([0.8885, 0.1115], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 46 - 65: cat - cat || Loss: 0.4245098829269409\n",
      "tensor([1., 0.]) tensor([0.8888, 0.1112], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 46 - 66: cat - cat || Loss: 0.4242492914199829\n",
      "tensor([1., 0.]) tensor([0.8890, 0.1110], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 46 - 67: cat - cat || Loss: 0.42398929595947266\n",
      "tensor([1., 0.]) tensor([0.8893, 0.1107], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 46 - 68: cat - cat || Loss: 0.423729807138443\n",
      "tensor([1., 0.]) tensor([0.8895, 0.1105], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 46 - 69: cat - cat || Loss: 0.42347097396850586\n",
      "tensor([1., 0.]) tensor([0.8898, 0.1102], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 46 - 70: cat - cat || Loss: 0.4232126474380493\n",
      "tensor([1., 0.]) tensor([0.8900, 0.1100], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 46 - 71: cat - cat || Loss: 0.4229550361633301\n",
      "tensor([1., 0.]) tensor([0.8903, 0.1097], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 46 - 72: cat - cat || Loss: 0.4226979911327362\n",
      "tensor([1., 0.]) tensor([0.8906, 0.1094], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 46 - 73: cat - cat || Loss: 0.42244160175323486\n",
      "tensor([1., 0.]) tensor([0.8908, 0.1092], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 46 - 74: cat - cat || Loss: 0.4221857190132141\n",
      "tensor([1., 0.]) tensor([0.8911, 0.1089], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 46 - 75: cat - cat || Loss: 0.42193055152893066\n",
      "tensor([1., 0.]) tensor([0.8913, 0.1087], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 46 - 76: cat - cat || Loss: 0.4216759502887726\n",
      "tensor([1., 0.]) tensor([0.8916, 0.1084], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 46 - 77: cat - cat || Loss: 0.42142200469970703\n",
      "tensor([1., 0.]) tensor([0.8918, 0.1082], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 46 - 78: cat - cat || Loss: 0.42116856575012207\n",
      "tensor([1., 0.]) tensor([0.8921, 0.1079], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 46 - 79: cat - cat || Loss: 0.420915812253952\n",
      "tensor([1., 0.]) tensor([0.8923, 0.1077], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 46 - 80: cat - cat || Loss: 0.42066365480422974\n",
      "tensor([1., 0.]) tensor([0.8926, 0.1074], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 46 - 81: cat - cat || Loss: 0.4204121232032776\n",
      "tensor([1., 0.]) tensor([0.8928, 0.1072], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 46 - 82: cat - cat || Loss: 0.4201611578464508\n",
      "tensor([1., 0.]) tensor([0.8931, 0.1069], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 46 - 83: cat - cat || Loss: 0.41991090774536133\n",
      "tensor([1., 0.]) tensor([0.8934, 0.1066], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 46 - 84: cat - cat || Loss: 0.4196612536907196\n",
      "tensor([1., 0.]) tensor([0.8936, 0.1064], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 46 - 85: cat - cat || Loss: 0.41941219568252563\n",
      "tensor([1., 0.]) tensor([0.8938, 0.1062], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 46 - 86: cat - cat || Loss: 0.4191637933254242\n",
      "tensor([1., 0.]) tensor([0.8941, 0.1059], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 46 - 87: cat - cat || Loss: 0.4189159870147705\n",
      "tensor([1., 0.]) tensor([0.8943, 0.1057], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 46 - 88: cat - cat || Loss: 0.4186686873435974\n",
      "tensor([1., 0.]) tensor([0.8946, 0.1054], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 46 - 89: cat - cat || Loss: 0.4184221029281616\n",
      "tensor([1., 0.]) tensor([0.8948, 0.1052], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 46 - 90: cat - cat || Loss: 0.4181761145591736\n",
      "tensor([1., 0.]) tensor([0.8951, 0.1049], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 46 - 91: cat - cat || Loss: 0.4179306626319885\n",
      "tensor([1., 0.]) tensor([0.8953, 0.1047], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 46 - 92: cat - cat || Loss: 0.41768592596054077\n",
      "tensor([1., 0.]) tensor([0.8956, 0.1044], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 46 - 93: cat - cat || Loss: 0.41744178533554077\n",
      "tensor([1., 0.]) tensor([0.8958, 0.1042], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 46 - 94: cat - cat || Loss: 0.41719818115234375\n",
      "tensor([1., 0.]) tensor([0.8961, 0.1039], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 46 - 95: cat - cat || Loss: 0.41695523262023926\n",
      "tensor([1., 0.]) tensor([0.8963, 0.1037], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 46 - 96: cat - cat || Loss: 0.4167128801345825\n",
      "tensor([1., 0.]) tensor([0.8965, 0.1035], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 46 - 97: cat - cat || Loss: 0.41647112369537354\n",
      "tensor([1., 0.]) tensor([0.8968, 0.1032], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 46 - 98: cat - cat || Loss: 0.41622987389564514\n",
      "tensor([1., 0.]) tensor([0.8970, 0.1030], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 46 - 99: cat - cat || Loss: 0.41598939895629883\n",
      "tensor([1., 0.]) tensor([0.8973, 0.1027], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 46 - 100: cat - cat || Loss: 0.4157494306564331\n",
      "tensor([1., 0.]) tensor([0.8975, 0.1025], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 46 - 101: cat - cat || Loss: 0.41551005840301514\n",
      "tensor([1., 0.]) tensor([0.8978, 0.1022], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 46 - 102: cat - cat || Loss: 0.4152713418006897\n",
      "tensor([1., 0.]) tensor([0.8980, 0.1020], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 46 - 103: cat - cat || Loss: 0.41503310203552246\n",
      "tensor([1., 0.]) tensor([0.8982, 0.1018], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 46 - 104: cat - cat || Loss: 0.41479557752609253\n",
      "tensor([1., 0.]) tensor([0.8985, 0.1015], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 46 - 105: cat - cat || Loss: 0.4145585894584656\n",
      "tensor([1., 0.]) tensor([0.8987, 0.1013], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 46 - 106: cat - cat || Loss: 0.41432225704193115\n",
      "tensor([1., 0.]) tensor([0.8989, 0.1011], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 46 - 107: cat - cat || Loss: 0.4140864610671997\n",
      "tensor([1., 0.]) tensor([0.8992, 0.1008], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 46 - 108: cat - cat || Loss: 0.4138513207435608\n",
      "tensor([1., 0.]) tensor([0.8994, 0.1006], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 46 - 109: cat - cat || Loss: 0.41361677646636963\n",
      "tensor([1., 0.]) tensor([0.8996, 0.1004], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 46 - 110: cat - cat || Loss: 0.41338270902633667\n",
      "tensor([1., 0.]) tensor([0.8999, 0.1001], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 46 - 111: cat - cat || Loss: 0.4131494164466858\n",
      "tensor([1., 0.]) tensor([0.9001, 0.0999], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 46 - 112: cat - cat || Loss: 0.41291651129722595\n",
      "tensor([1., 0.]) tensor([0.9003, 0.0997], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 46 - 113: cat - cat || Loss: 0.41268429160118103\n",
      "tensor([1., 0.]) tensor([0.9006, 0.0994], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 46 - 114: cat - cat || Loss: 0.4124526381492615\n",
      "tensor([1., 0.]) tensor([0.9008, 0.0992], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 46 - 115: cat - cat || Loss: 0.4122215509414673\n",
      "tensor([1., 0.]) tensor([0.9010, 0.0990], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 46 - 116: cat - cat || Loss: 0.4119911193847656\n",
      "tensor([1., 0.]) tensor([0.9013, 0.0987], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 46 - 117: cat - cat || Loss: 0.41176122426986694\n",
      "tensor([1., 0.]) tensor([0.9015, 0.0985], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 46 - 118: cat - cat || Loss: 0.41153183579444885\n",
      "tensor([1., 0.]) tensor([0.9017, 0.0983], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 46 - 119: cat - cat || Loss: 0.41130316257476807\n",
      "tensor([1., 0.]) tensor([0.9020, 0.0980], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 46 - 120: cat - cat || Loss: 0.4110749363899231\n",
      "tensor([1., 0.]) tensor([0.9022, 0.0978], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 46 - 121: cat - cat || Loss: 0.4108473062515259\n",
      "tensor([1., 0.]) tensor([0.9024, 0.0976], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 46 - 122: cat - cat || Loss: 0.4106203317642212\n",
      "tensor([1., 0.]) tensor([0.9026, 0.0974], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 46 - 123: cat - cat || Loss: 0.4103938937187195\n",
      "tensor([1., 0.]) tensor([0.9029, 0.0971], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 46 - 124: cat - cat || Loss: 0.41016799211502075\n",
      "tensor([1., 0.]) tensor([0.9031, 0.0969], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 46 - 125: cat - cat || Loss: 0.40994277596473694\n",
      "tensor([1., 0.]) tensor([0.9033, 0.0967], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 46 - 126: cat - cat || Loss: 0.40971803665161133\n",
      "tensor([1., 0.]) tensor([0.9035, 0.0965], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 46 - 127: cat - cat || Loss: 0.4094938337802887\n",
      "tensor([1., 0.]) tensor([0.9038, 0.0962], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 46 - 128: cat - cat || Loss: 0.4092702269554138\n",
      "tensor([1., 0.]) tensor([0.9040, 0.0960], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 46 - 129: cat - cat || Loss: 0.4090472459793091\n",
      "tensor([1., 0.]) tensor([0.9042, 0.0958], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 46 - 130: cat - cat || Loss: 0.4088248014450073\n",
      "tensor([1., 0.]) tensor([0.9044, 0.0956], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 46 - 131: cat - cat || Loss: 0.40860286355018616\n",
      "tensor([1., 0.]) tensor([0.9047, 0.0953], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 46 - 132: cat - cat || Loss: 0.40838146209716797\n",
      "tensor([1., 0.]) tensor([0.9049, 0.0951], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 46 - 133: cat - cat || Loss: 0.4081607460975647\n",
      "tensor([1., 0.]) tensor([0.9051, 0.0949], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 46 - 134: cat - cat || Loss: 0.40794047713279724\n",
      "tensor([1., 0.]) tensor([0.9053, 0.0947], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 46 - 135: cat - cat || Loss: 0.4077209234237671\n",
      "tensor([1., 0.]) tensor([0.9055, 0.0945], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 46 - 136: cat - cat || Loss: 0.40750178694725037\n",
      "tensor([1., 0.]) tensor([0.9058, 0.0942], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 46 - 137: cat - cat || Loss: 0.4072831869125366\n",
      "tensor([1., 0.]) tensor([0.9060, 0.0940], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 46 - 138: cat - cat || Loss: 0.4070652723312378\n",
      "tensor([1., 0.]) tensor([0.9062, 0.0938], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 46 - 139: cat - cat || Loss: 0.4068477749824524\n",
      "tensor([1., 0.]) tensor([0.9064, 0.0936], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 46 - 140: cat - cat || Loss: 0.40663090348243713\n",
      "tensor([1., 0.]) tensor([0.9066, 0.0934], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 46 - 141: cat - cat || Loss: 0.4064145088195801\n",
      "tensor([1., 0.]) tensor([0.9068, 0.0932], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 46 - 142: cat - cat || Loss: 0.40619874000549316\n",
      "tensor([1., 0.]) tensor([0.9071, 0.0929], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 46 - 143: cat - cat || Loss: 0.40598344802856445\n",
      "tensor([1., 0.]) tensor([0.9073, 0.0927], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 46 - 144: cat - cat || Loss: 0.4057687520980835\n",
      "tensor([1., 0.]) tensor([0.9075, 0.0925], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 46 - 145: cat - cat || Loss: 0.40555456280708313\n",
      "tensor([1., 0.]) tensor([0.9077, 0.0923], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 46 - 146: cat - cat || Loss: 0.40534093976020813\n",
      "tensor([1., 0.]) tensor([0.9079, 0.0921], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 46 - 147: cat - cat || Loss: 0.4051279127597809\n",
      "tensor([1., 0.]) tensor([0.9081, 0.0919], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 46 - 148: cat - cat || Loss: 0.40491533279418945\n",
      "tensor([1., 0.]) tensor([0.9083, 0.0917], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 46 - 149: cat - cat || Loss: 0.4047033190727234\n",
      "tensor([1., 0.]) tensor([0.9086, 0.0914], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 46 - 150: cat - cat || Loss: 0.4044918119907379\n",
      "tensor([1., 0.]) tensor([0.9088, 0.0912], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 46 - 151: cat - cat || Loss: 0.4042809307575226\n",
      "tensor([1., 0.]) tensor([0.9090, 0.0910], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 46 - 152: cat - cat || Loss: 0.40407052636146545\n",
      "tensor([1., 0.]) tensor([0.9092, 0.0908], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 46 - 153: cat - cat || Loss: 0.4038606882095337\n",
      "tensor([1., 0.]) tensor([0.9094, 0.0906], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 46 - 154: cat - cat || Loss: 0.40365132689476013\n",
      "tensor([1., 0.]) tensor([0.9096, 0.0904], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 46 - 155: cat - cat || Loss: 0.40344250202178955\n",
      "tensor([1., 0.]) tensor([0.9098, 0.0902], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 46 - 156: cat - cat || Loss: 0.40323424339294434\n",
      "tensor([1., 0.]) tensor([0.9100, 0.0900], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 46 - 157: cat - cat || Loss: 0.4030265212059021\n",
      "tensor([1., 0.]) tensor([0.9102, 0.0898], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 46 - 158: cat - cat || Loss: 0.40281930565834045\n",
      "tensor([1., 0.]) tensor([0.9104, 0.0896], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 46 - 159: cat - cat || Loss: 0.4026125371456146\n",
      "tensor([1., 0.]) tensor([0.9106, 0.0894], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 46 - 160: cat - cat || Loss: 0.40240633487701416\n",
      "tensor([1., 0.]) tensor([0.9109, 0.0891], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 46 - 161: cat - cat || Loss: 0.4022008180618286\n",
      "tensor([1., 0.]) tensor([0.9111, 0.0889], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 46 - 162: cat - cat || Loss: 0.4019956886768341\n",
      "tensor([1., 0.]) tensor([0.9113, 0.0887], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 46 - 163: cat - cat || Loss: 0.4017910361289978\n",
      "tensor([1., 0.]) tensor([0.9115, 0.0885], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 46 - 164: cat - cat || Loss: 0.40158697962760925\n",
      "tensor([1., 0.]) tensor([0.9117, 0.0883], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 46 - 165: cat - cat || Loss: 0.4013834297657013\n",
      "tensor([1., 0.]) tensor([0.9119, 0.0881], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 46 - 166: cat - cat || Loss: 0.4011803865432739\n",
      "tensor([1., 0.]) tensor([0.9121, 0.0879], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 46 - 167: cat - cat || Loss: 0.40097784996032715\n",
      "tensor([1., 0.]) tensor([0.9123, 0.0877], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 46 - 168: cat - cat || Loss: 0.4007759094238281\n",
      "tensor([1., 0.]) tensor([0.9125, 0.0875], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 46 - 169: cat - cat || Loss: 0.40057429671287537\n",
      "tensor([1., 0.]) tensor([0.9127, 0.0873], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 46 - 170: cat - cat || Loss: 0.40037333965301514\n",
      "tensor([1., 0.]) tensor([0.9129, 0.0871], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 46 - 171: cat - cat || Loss: 0.4001728892326355\n",
      "tensor([1., 0.]) tensor([0.9131, 0.0869], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 46 - 172: cat - cat || Loss: 0.3999728858470917\n",
      "tensor([1., 0.]) tensor([0.9133, 0.0867], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 46 - 173: cat - cat || Loss: 0.3997734785079956\n",
      "tensor([1., 0.]) tensor([0.9135, 0.0865], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 46 - 174: cat - cat || Loss: 0.39957448840141296\n",
      "tensor([1., 0.]) tensor([0.9137, 0.0863], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 46 - 175: cat - cat || Loss: 0.3993760049343109\n",
      "tensor([1., 0.]) tensor([0.9139, 0.0861], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 46 - 176: cat - cat || Loss: 0.39917802810668945\n",
      "tensor([1., 0.]) tensor([0.9141, 0.0859], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 46 - 177: cat - cat || Loss: 0.39898064732551575\n",
      "tensor([1., 0.]) tensor([0.9143, 0.0857], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 46 - 178: cat - cat || Loss: 0.39878371357917786\n",
      "tensor([1., 0.]) tensor([0.9145, 0.0855], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 46 - 179: cat - cat || Loss: 0.39858725666999817\n",
      "tensor([1., 0.]) tensor([0.9147, 0.0853], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 46 - 180: cat - cat || Loss: 0.3983912765979767\n",
      "tensor([1., 0.]) tensor([0.9149, 0.0851], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 46 - 181: cat - cat || Loss: 0.39819586277008057\n",
      "tensor([1., 0.]) tensor([0.9151, 0.0849], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 46 - 182: cat - cat || Loss: 0.39800089597702026\n",
      "tensor([1., 0.]) tensor([0.9153, 0.0847], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 46 - 183: cat - cat || Loss: 0.3978064954280853\n",
      "tensor([1., 0.]) tensor([0.9155, 0.0845], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 46 - 184: cat - cat || Loss: 0.39761245250701904\n",
      "tensor([1., 0.]) tensor([0.9156, 0.0844], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 46 - 185: cat - cat || Loss: 0.3974190354347229\n",
      "tensor([1., 0.]) tensor([0.9158, 0.0842], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 46 - 186: cat - cat || Loss: 0.397225946187973\n",
      "tensor([1., 0.]) tensor([0.9160, 0.0840], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 46 - 187: cat - cat || Loss: 0.3970333933830261\n",
      "tensor([1., 0.]) tensor([0.9162, 0.0838], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 46 - 188: cat - cat || Loss: 0.3968413472175598\n",
      "tensor([1., 0.]) tensor([0.9164, 0.0836], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 46 - 189: cat - cat || Loss: 0.39664968848228455\n",
      "tensor([1., 0.]) tensor([0.9166, 0.0834], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 46 - 190: dog - cat || Loss: 1.2300647497177124\n",
      "tensor([0., 1.]) tensor([0.9168, 0.0832], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 46 - 191: dog - cat || Loss: 1.2302179336547852\n",
      "tensor([0., 1.]) tensor([0.9170, 0.0830], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 46 - 192: dog - cat || Loss: 1.2303365468978882\n",
      "tensor([0., 1.]) tensor([0.9171, 0.0829], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 46 - 193: dog - cat || Loss: 1.2304242849349976\n",
      "tensor([0., 1.]) tensor([0.9172, 0.0828], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 46 - 194: dog - cat || Loss: 1.2304847240447998\n",
      "tensor([0., 1.]) tensor([0.9172, 0.0828], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 46 - 195: dog - cat || Loss: 1.2305201292037964\n",
      "tensor([0., 1.]) tensor([0.9173, 0.0827], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 46 - 196: dog - cat || Loss: 1.2305331230163574\n",
      "tensor([0., 1.]) tensor([0.9173, 0.0827], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 46 - 197: dog - cat || Loss: 1.230526089668274\n",
      "tensor([0., 1.]) tensor([0.9173, 0.0827], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 46 - 198: dog - cat || Loss: 1.2305011749267578\n",
      "tensor([0., 1.]) tensor([0.9172, 0.0828], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 46 - 199: dog - cat || Loss: 1.2304595708847046\n",
      "tensor([0., 1.]) tensor([0.9172, 0.0828], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 46 - 200: dog - cat || Loss: 1.2304035425186157\n",
      "tensor([0., 1.]) tensor([0.9171, 0.0829], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 46 - 201: dog - cat || Loss: 1.2303341627120972\n",
      "tensor([0., 1.]) tensor([0.9171, 0.0829], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 46 - 202: dog - cat || Loss: 1.2302531003952026\n",
      "tensor([0., 1.]) tensor([0.9170, 0.0830], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 46 - 203: dog - cat || Loss: 1.230161190032959\n",
      "tensor([0., 1.]) tensor([0.9169, 0.0831], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 46 - 204: dog - cat || Loss: 1.2300596237182617\n",
      "tensor([0., 1.]) tensor([0.9168, 0.0832], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 46 - 205: dog - cat || Loss: 1.2299491167068481\n",
      "tensor([0., 1.]) tensor([0.9167, 0.0833], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 46 - 206: dog - cat || Loss: 1.2298307418823242\n",
      "tensor([0., 1.]) tensor([0.9166, 0.0834], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 46 - 207: dog - cat || Loss: 1.2297053337097168\n",
      "tensor([0., 1.]) tensor([0.9164, 0.0836], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 46 - 208: dog - cat || Loss: 1.2295732498168945\n",
      "tensor([0., 1.]) tensor([0.9163, 0.0837], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 46 - 209: dog - cat || Loss: 1.2294353246688843\n",
      "tensor([0., 1.]) tensor([0.9162, 0.0838], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 46 - 210: dog - cat || Loss: 1.2292922735214233\n",
      "tensor([0., 1.]) tensor([0.9160, 0.0840], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 46 - 211: dog - cat || Loss: 1.2291440963745117\n",
      "tensor([0., 1.]) tensor([0.9159, 0.0841], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 46 - 212: dog - cat || Loss: 1.2289915084838867\n",
      "tensor([0., 1.]) tensor([0.9157, 0.0843], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 46 - 213: dog - cat || Loss: 1.228835105895996\n",
      "tensor([0., 1.]) tensor([0.9156, 0.0844], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 46 - 214: dog - cat || Loss: 1.2286750078201294\n",
      "tensor([0., 1.]) tensor([0.9154, 0.0846], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 46 - 215: dog - cat || Loss: 1.2285112142562866\n",
      "tensor([0., 1.]) tensor([0.9152, 0.0848], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 46 - 216: dog - cat || Loss: 1.2283446788787842\n",
      "tensor([0., 1.]) tensor([0.9151, 0.0849], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 46 - 217: dog - cat || Loss: 1.2281752824783325\n",
      "tensor([0., 1.]) tensor([0.9149, 0.0851], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 46 - 218: dog - cat || Loss: 1.2280033826828003\n",
      "tensor([0., 1.]) tensor([0.9147, 0.0853], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 46 - 219: dog - cat || Loss: 1.2278289794921875\n",
      "tensor([0., 1.]) tensor([0.9146, 0.0854], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 46 - 220: dog - cat || Loss: 1.227652668952942\n",
      "tensor([0., 1.]) tensor([0.9144, 0.0856], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 46 - 221: dog - cat || Loss: 1.2274740934371948\n",
      "tensor([0., 1.]) tensor([0.9142, 0.0858], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 46 - 222: dog - cat || Loss: 1.2272937297821045\n",
      "tensor([0., 1.]) tensor([0.9140, 0.0860], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 46 - 223: dog - cat || Loss: 1.2271116971969604\n",
      "tensor([0., 1.]) tensor([0.9139, 0.0861], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 46 - 224: dog - cat || Loss: 1.2269281148910522\n",
      "tensor([0., 1.]) tensor([0.9137, 0.0863], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 46 - 225: dog - cat || Loss: 1.2267429828643799\n",
      "tensor([0., 1.]) tensor([0.9135, 0.0865], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 46 - 226: dog - cat || Loss: 1.226556420326233\n",
      "tensor([0., 1.]) tensor([0.9133, 0.0867], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 46 - 227: dog - cat || Loss: 1.2263689041137695\n",
      "tensor([0., 1.]) tensor([0.9131, 0.0869], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 46 - 228: dog - cat || Loss: 1.226179838180542\n",
      "tensor([0., 1.]) tensor([0.9129, 0.0871], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 46 - 229: dog - cat || Loss: 1.2259899377822876\n",
      "tensor([0., 1.]) tensor([0.9127, 0.0873], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 46 - 230: dog - cat || Loss: 1.225798487663269\n",
      "tensor([0., 1.]) tensor([0.9125, 0.0875], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 46 - 231: dog - cat || Loss: 1.2256063222885132\n",
      "tensor([0., 1.]) tensor([0.9123, 0.0877], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 46 - 232: dog - cat || Loss: 1.225413203239441\n",
      "tensor([0., 1.]) tensor([0.9122, 0.0878], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 46 - 233: dog - cat || Loss: 1.2252191305160522\n",
      "tensor([0., 1.]) tensor([0.9120, 0.0880], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 46 - 234: dog - cat || Loss: 1.2250241041183472\n",
      "tensor([0., 1.]) tensor([0.9118, 0.0882], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 46 - 235: dog - cat || Loss: 1.2248282432556152\n",
      "tensor([0., 1.]) tensor([0.9116, 0.0884], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 46 - 236: dog - cat || Loss: 1.2246317863464355\n",
      "tensor([0., 1.]) tensor([0.9114, 0.0886], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 46 - 237: dog - cat || Loss: 1.2244343757629395\n",
      "tensor([0., 1.]) tensor([0.9112, 0.0888], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 46 - 238: dog - cat || Loss: 1.224236249923706\n",
      "tensor([0., 1.]) tensor([0.9110, 0.0890], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 46 - 239: dog - cat || Loss: 1.2240372896194458\n",
      "tensor([0., 1.]) tensor([0.9108, 0.0892], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 46 - 240: dog - cat || Loss: 1.223837971687317\n",
      "tensor([0., 1.]) tensor([0.9106, 0.0894], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 46 - 241: dog - cat || Loss: 1.223637580871582\n",
      "tensor([0., 1.]) tensor([0.9104, 0.0896], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 46 - 242: dog - cat || Loss: 1.223436713218689\n",
      "tensor([0., 1.]) tensor([0.9102, 0.0898], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 46 - 243: dog - cat || Loss: 1.2232351303100586\n",
      "tensor([0., 1.]) tensor([0.9100, 0.0900], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 46 - 244: dog - cat || Loss: 1.2230329513549805\n",
      "tensor([0., 1.]) tensor([0.9098, 0.0902], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 46 - 245: dog - cat || Loss: 1.2228301763534546\n",
      "tensor([0., 1.]) tensor([0.9096, 0.0904], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 46 - 246: dog - cat || Loss: 1.222626805305481\n",
      "tensor([0., 1.]) tensor([0.9094, 0.0906], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 46 - 247: dog - cat || Loss: 1.2224225997924805\n",
      "tensor([0., 1.]) tensor([0.9092, 0.0908], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 46 - 248: dog - cat || Loss: 1.2222180366516113\n",
      "tensor([0., 1.]) tensor([0.9090, 0.0910], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 46 - 249: dog - cat || Loss: 1.2220128774642944\n",
      "tensor([0., 1.]) tensor([0.9088, 0.0912], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 46 - 250: dog - cat || Loss: 1.2218071222305298\n",
      "tensor([0., 1.]) tensor([0.9085, 0.0915], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 46 - 251: dog - cat || Loss: 1.221600890159607\n",
      "tensor([0., 1.]) tensor([0.9083, 0.0917], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 46 - 252: dog - cat || Loss: 1.2213938236236572\n",
      "tensor([0., 1.]) tensor([0.9081, 0.0919], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 46 - 253: dog - cat || Loss: 1.2211862802505493\n",
      "tensor([0., 1.]) tensor([0.9079, 0.0921], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 46 - 254: dog - cat || Loss: 1.2209782600402832\n",
      "tensor([0., 1.]) tensor([0.9077, 0.0923], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 46 - 255: dog - cat || Loss: 1.2207697629928589\n",
      "tensor([0., 1.]) tensor([0.9075, 0.0925], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 46 - 256: dog - cat || Loss: 1.2205605506896973\n",
      "tensor([0., 1.]) tensor([0.9073, 0.0927], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 46 - 257: dog - cat || Loss: 1.2203508615493774\n",
      "tensor([0., 1.]) tensor([0.9071, 0.0929], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 46 - 258: dog - cat || Loss: 1.2201405763626099\n",
      "tensor([0., 1.]) tensor([0.9069, 0.0931], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 46 - 259: dog - cat || Loss: 1.2199299335479736\n",
      "tensor([0., 1.]) tensor([0.9067, 0.0933], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 46 - 260: dog - cat || Loss: 1.2197184562683105\n",
      "tensor([0., 1.]) tensor([0.9065, 0.0935], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 46 - 261: dog - cat || Loss: 1.2195066213607788\n",
      "tensor([0., 1.]) tensor([0.9062, 0.0938], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 46 - 262: dog - cat || Loss: 1.2192941904067993\n",
      "tensor([0., 1.]) tensor([0.9060, 0.0940], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 46 - 263: dog - cat || Loss: 1.2190812826156616\n",
      "tensor([0., 1.]) tensor([0.9058, 0.0942], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 46 - 264: dog - cat || Loss: 1.2188677787780762\n",
      "tensor([0., 1.]) tensor([0.9056, 0.0944], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 46 - 265: dog - cat || Loss: 1.2186537981033325\n",
      "tensor([0., 1.]) tensor([0.9054, 0.0946], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 46 - 266: dog - cat || Loss: 1.2184391021728516\n",
      "tensor([0., 1.]) tensor([0.9052, 0.0948], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 46 - 267: dog - cat || Loss: 1.218224048614502\n",
      "tensor([0., 1.]) tensor([0.9050, 0.0950], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 46 - 268: dog - cat || Loss: 1.218008279800415\n",
      "tensor([0., 1.]) tensor([0.9047, 0.0953], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 46 - 269: dog - cat || Loss: 1.2177921533584595\n",
      "tensor([0., 1.]) tensor([0.9045, 0.0955], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 46 - 270: dog - cat || Loss: 1.2175753116607666\n",
      "tensor([0., 1.]) tensor([0.9043, 0.0957], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 46 - 271: dog - cat || Loss: 1.2173582315444946\n",
      "tensor([0., 1.]) tensor([0.9041, 0.0959], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 46 - 272: dog - cat || Loss: 1.2171400785446167\n",
      "tensor([0., 1.]) tensor([0.9039, 0.0961], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 46 - 273: dog - cat || Loss: 1.2169219255447388\n",
      "tensor([0., 1.]) tensor([0.9037, 0.0963], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 46 - 274: dog - cat || Loss: 1.216702938079834\n",
      "tensor([0., 1.]) tensor([0.9034, 0.0966], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 46 - 275: dog - cat || Loss: 1.216483473777771\n",
      "tensor([0., 1.]) tensor([0.9032, 0.0968], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 46 - 276: dog - cat || Loss: 1.2162635326385498\n",
      "tensor([0., 1.]) tensor([0.9030, 0.0970], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 46 - 277: dog - cat || Loss: 1.2160428762435913\n",
      "tensor([0., 1.]) tensor([0.9028, 0.0972], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 46 - 278: dog - cat || Loss: 1.2158218622207642\n",
      "tensor([0., 1.]) tensor([0.9026, 0.0974], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 46 - 279: dog - cat || Loss: 1.2156002521514893\n",
      "tensor([0., 1.]) tensor([0.9023, 0.0977], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 46 - 280: dog - cat || Loss: 1.2153780460357666\n",
      "tensor([0., 1.]) tensor([0.9021, 0.0979], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 46 - 281: dog - cat || Loss: 1.2151553630828857\n",
      "tensor([0., 1.]) tensor([0.9019, 0.0981], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 46 - 282: dog - cat || Loss: 1.214931845664978\n",
      "tensor([0., 1.]) tensor([0.9017, 0.0983], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 46 - 283: dog - cat || Loss: 1.2147082090377808\n",
      "tensor([0., 1.]) tensor([0.9014, 0.0986], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 46 - 284: dog - cat || Loss: 1.2144837379455566\n",
      "tensor([0., 1.]) tensor([0.9012, 0.0988], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 46 - 285: dog - cat || Loss: 1.2142586708068848\n",
      "tensor([0., 1.]) tensor([0.9010, 0.0990], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 46 - 286: dog - cat || Loss: 1.2140331268310547\n",
      "tensor([0., 1.]) tensor([0.9008, 0.0992], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 46 - 287: dog - cat || Loss: 1.2138071060180664\n",
      "tensor([0., 1.]) tensor([0.9005, 0.0995], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 46 - 288: dog - cat || Loss: 1.2135803699493408\n",
      "tensor([0., 1.]) tensor([0.9003, 0.0997], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 46 - 289: dog - cat || Loss: 1.213353157043457\n",
      "tensor([0., 1.]) tensor([0.9001, 0.0999], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 46 - 290: dog - cat || Loss: 1.2131255865097046\n",
      "tensor([0., 1.]) tensor([0.8999, 0.1001], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 46 - 291: dog - cat || Loss: 1.2128973007202148\n",
      "tensor([0., 1.]) tensor([0.8996, 0.1004], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 46 - 292: dog - cat || Loss: 1.2126682996749878\n",
      "tensor([0., 1.]) tensor([0.8994, 0.1006], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 46 - 293: dog - cat || Loss: 1.212438941001892\n",
      "tensor([0., 1.]) tensor([0.8992, 0.1008], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 46 - 294: dog - cat || Loss: 1.2122089862823486\n",
      "tensor([0., 1.]) tensor([0.8989, 0.1011], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 46 - 295: dog - cat || Loss: 1.2119783163070679\n",
      "tensor([0., 1.]) tensor([0.8987, 0.1013], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 46 - 296: dog - cat || Loss: 1.2117472887039185\n",
      "tensor([0., 1.]) tensor([0.8985, 0.1015], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 46 - 297: dog - cat || Loss: 1.2115157842636108\n",
      "tensor([0., 1.]) tensor([0.8983, 0.1017], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 46 - 298: dog - cat || Loss: 1.2112834453582764\n",
      "tensor([0., 1.]) tensor([0.8980, 0.1020], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 46 - 299: dog - cat || Loss: 1.2110506296157837\n",
      "tensor([0., 1.]) tensor([0.8978, 0.1022], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 46 - 300: dog - cat || Loss: 1.2108172178268433\n",
      "tensor([0., 1.]) tensor([0.8976, 0.1024], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 46 - 301: dog - cat || Loss: 1.210583209991455\n",
      "tensor([0., 1.]) tensor([0.8973, 0.1027], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 46 - 302: dog - cat || Loss: 1.2103488445281982\n",
      "tensor([0., 1.]) tensor([0.8971, 0.1029], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 46 - 303: dog - cat || Loss: 1.210113525390625\n",
      "tensor([0., 1.]) tensor([0.8969, 0.1031], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 46 - 304: dog - cat || Loss: 1.2098779678344727\n",
      "tensor([0., 1.]) tensor([0.8966, 0.1034], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 46 - 305: dog - cat || Loss: 1.209641695022583\n",
      "tensor([0., 1.]) tensor([0.8964, 0.1036], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 46 - 306: dog - cat || Loss: 1.2094049453735352\n",
      "tensor([0., 1.]) tensor([0.8961, 0.1039], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 46 - 307: dog - cat || Loss: 1.20916748046875\n",
      "tensor([0., 1.]) tensor([0.8959, 0.1041], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 46 - 308: dog - cat || Loss: 1.2089293003082275\n",
      "tensor([0., 1.]) tensor([0.8957, 0.1043], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 46 - 309: dog - cat || Loss: 1.208690881729126\n",
      "tensor([0., 1.]) tensor([0.8954, 0.1046], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 46 - 310: dog - cat || Loss: 1.2084518671035767\n",
      "tensor([0., 1.]) tensor([0.8952, 0.1048], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 46 - 311: dog - cat || Loss: 1.208211898803711\n",
      "tensor([0., 1.]) tensor([0.8950, 0.1050], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 46 - 312: dog - cat || Loss: 1.2079715728759766\n",
      "tensor([0., 1.]) tensor([0.8947, 0.1053], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 46 - 313: dog - cat || Loss: 1.2077306509017944\n",
      "tensor([0., 1.]) tensor([0.8945, 0.1055], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 46 - 314: dog - cat || Loss: 1.207489252090454\n",
      "tensor([0., 1.]) tensor([0.8942, 0.1058], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 46 - 315: dog - cat || Loss: 1.207247257232666\n",
      "tensor([0., 1.]) tensor([0.8940, 0.1060], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 46 - 316: dog - cat || Loss: 1.2070045471191406\n",
      "tensor([0., 1.]) tensor([0.8937, 0.1063], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 46 - 317: dog - cat || Loss: 1.2067612409591675\n",
      "tensor([0., 1.]) tensor([0.8935, 0.1065], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 46 - 318: dog - cat || Loss: 1.2065173387527466\n",
      "tensor([0., 1.]) tensor([0.8933, 0.1067], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 46 - 319: dog - cat || Loss: 1.2062729597091675\n",
      "tensor([0., 1.]) tensor([0.8930, 0.1070], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 46 - 320: dog - cat || Loss: 1.2060279846191406\n",
      "tensor([0., 1.]) tensor([0.8928, 0.1072], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 46 - 321: dog - cat || Loss: 1.2057822942733765\n",
      "tensor([0., 1.]) tensor([0.8925, 0.1075], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 46 - 322: dog - cat || Loss: 1.205535888671875\n",
      "tensor([0., 1.]) tensor([0.8923, 0.1077], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 46 - 323: dog - cat || Loss: 1.2052892446517944\n",
      "tensor([0., 1.]) tensor([0.8920, 0.1080], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 46 - 324: dog - cat || Loss: 1.205041766166687\n",
      "tensor([0., 1.]) tensor([0.8918, 0.1082], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 46 - 325: dog - cat || Loss: 1.2047938108444214\n",
      "tensor([0., 1.]) tensor([0.8915, 0.1085], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 46 - 326: dog - cat || Loss: 1.2045449018478394\n",
      "tensor([0., 1.]) tensor([0.8913, 0.1087], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 46 - 327: dog - cat || Loss: 1.2042958736419678\n",
      "tensor([0., 1.]) tensor([0.8910, 0.1090], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 46 - 328: dog - cat || Loss: 1.2040461301803589\n",
      "tensor([0., 1.]) tensor([0.8908, 0.1092], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 46 - 329: dog - cat || Loss: 1.2037955522537231\n",
      "tensor([0., 1.]) tensor([0.8905, 0.1095], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 46 - 330: dog - cat || Loss: 1.2035446166992188\n",
      "tensor([0., 1.]) tensor([0.8903, 0.1097], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 46 - 331: dog - cat || Loss: 1.203292965888977\n",
      "tensor([0., 1.]) tensor([0.8900, 0.1100], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 46 - 332: dog - cat || Loss: 1.2030407190322876\n",
      "tensor([0., 1.]) tensor([0.8898, 0.1102], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 46 - 333: dog - cat || Loss: 1.2027877569198608\n",
      "tensor([0., 1.]) tensor([0.8895, 0.1105], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 46 - 334: dog - cat || Loss: 1.2025341987609863\n",
      "tensor([0., 1.]) tensor([0.8893, 0.1107], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 46 - 335: dog - cat || Loss: 1.2022801637649536\n",
      "tensor([0., 1.]) tensor([0.8890, 0.1110], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 46 - 336: dog - cat || Loss: 1.2020255327224731\n",
      "tensor([0., 1.]) tensor([0.8888, 0.1112], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 46 - 337: dog - cat || Loss: 1.2017700672149658\n",
      "tensor([0., 1.]) tensor([0.8885, 0.1115], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 46 - 338: dog - cat || Loss: 1.2015140056610107\n",
      "tensor([0., 1.]) tensor([0.8883, 0.1117], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 46 - 339: dog - cat || Loss: 1.201257586479187\n",
      "tensor([0., 1.]) tensor([0.8880, 0.1120], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 46 - 340: dog - cat || Loss: 1.2010003328323364\n",
      "tensor([0., 1.]) tensor([0.8877, 0.1123], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 46 - 341: dog - cat || Loss: 1.2007426023483276\n",
      "tensor([0., 1.]) tensor([0.8875, 0.1125], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 46 - 342: dog - cat || Loss: 1.200484037399292\n",
      "tensor([0., 1.]) tensor([0.8872, 0.1128], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 46 - 343: dog - cat || Loss: 1.2002248764038086\n",
      "tensor([0., 1.]) tensor([0.8870, 0.1130], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 46 - 344: dog - cat || Loss: 1.199965238571167\n",
      "tensor([0., 1.]) tensor([0.8867, 0.1133], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 46 - 345: dog - cat || Loss: 1.1997050046920776\n",
      "tensor([0., 1.]) tensor([0.8864, 0.1136], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 46 - 346: dog - cat || Loss: 1.1994439363479614\n",
      "tensor([0., 1.]) tensor([0.8862, 0.1138], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 46 - 347: dog - cat || Loss: 1.199182391166687\n",
      "tensor([0., 1.]) tensor([0.8859, 0.1141], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 46 - 348: dog - cat || Loss: 1.1989200115203857\n",
      "tensor([0., 1.]) tensor([0.8857, 0.1143], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 46 - 349: dog - cat || Loss: 1.1986572742462158\n",
      "tensor([0., 1.]) tensor([0.8854, 0.1146], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 46 - 350: dog - cat || Loss: 1.198393702507019\n",
      "tensor([0., 1.]) tensor([0.8851, 0.1149], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 46 - 351: dog - cat || Loss: 1.198129653930664\n",
      "tensor([0., 1.]) tensor([0.8849, 0.1151], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 46 - 352: dog - cat || Loss: 1.1978647708892822\n",
      "tensor([0., 1.]) tensor([0.8846, 0.1154], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 46 - 353: dog - cat || Loss: 1.1975994110107422\n",
      "tensor([0., 1.]) tensor([0.8843, 0.1157], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 46 - 354: dog - cat || Loss: 1.1973332166671753\n",
      "tensor([0., 1.]) tensor([0.8841, 0.1159], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 46 - 355: dog - cat || Loss: 1.1970667839050293\n",
      "tensor([0., 1.]) tensor([0.8838, 0.1162], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 46 - 356: dog - cat || Loss: 1.1967992782592773\n",
      "tensor([0., 1.]) tensor([0.8835, 0.1165], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 46 - 357: dog - cat || Loss: 1.1965312957763672\n",
      "tensor([0., 1.]) tensor([0.8833, 0.1167], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 46 - 358: dog - cat || Loss: 1.1962625980377197\n",
      "tensor([0., 1.]) tensor([0.8830, 0.1170], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 46 - 359: dog - cat || Loss: 1.195993423461914\n",
      "tensor([0., 1.]) tensor([0.8827, 0.1173], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 46 - 360: dog - cat || Loss: 1.1957234144210815\n",
      "tensor([0., 1.]) tensor([0.8825, 0.1175], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 46 - 361: dog - cat || Loss: 1.1954529285430908\n",
      "tensor([0., 1.]) tensor([0.8822, 0.1178], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 46 - 362: dog - cat || Loss: 1.1951817274093628\n",
      "tensor([0., 1.]) tensor([0.8819, 0.1181], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 46 - 363: dog - cat || Loss: 1.1949098110198975\n",
      "tensor([0., 1.]) tensor([0.8816, 0.1184], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 46 - 364: dog - cat || Loss: 1.1946372985839844\n",
      "tensor([0., 1.]) tensor([0.8814, 0.1186], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 46 - 365: dog - cat || Loss: 1.194364309310913\n",
      "tensor([0., 1.]) tensor([0.8811, 0.1189], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 46 - 366: dog - cat || Loss: 1.1940903663635254\n",
      "tensor([0., 1.]) tensor([0.8808, 0.1192], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 46 - 367: dog - cat || Loss: 1.1938159465789795\n",
      "tensor([0., 1.]) tensor([0.8806, 0.1194], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 46 - 368: dog - cat || Loss: 1.1935406923294067\n",
      "tensor([0., 1.]) tensor([0.8803, 0.1197], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 46 - 369: dog - cat || Loss: 1.1932648420333862\n",
      "tensor([0., 1.]) tensor([0.8800, 0.1200], grad_fn=<SoftmaxBackward0>)\n",
      "=====epoch:47=====\n",
      "Epoch 47 - 0: cat - cat || Loss: 0.4335348606109619\n",
      "tensor([1., 0.]) tensor([0.8797, 0.1203], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 47 - 1: cat - cat || Loss: 0.43375587463378906\n",
      "tensor([1., 0.]) tensor([0.8795, 0.1205], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 47 - 2: cat - cat || Loss: 0.43392693996429443\n",
      "tensor([1., 0.]) tensor([0.8793, 0.1207], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 47 - 3: cat - cat || Loss: 0.4340529441833496\n",
      "tensor([1., 0.]) tensor([0.8792, 0.1208], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 47 - 4: cat - cat || Loss: 0.4341382384300232\n",
      "tensor([1., 0.]) tensor([0.8791, 0.1209], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 47 - 5: cat - cat || Loss: 0.4341868460178375\n",
      "tensor([1., 0.]) tensor([0.8791, 0.1209], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 47 - 6: cat - cat || Loss: 0.4342023730278015\n",
      "tensor([1., 0.]) tensor([0.8791, 0.1209], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 47 - 7: cat - cat || Loss: 0.43418827652931213\n",
      "tensor([1., 0.]) tensor([0.8791, 0.1209], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 47 - 8: cat - cat || Loss: 0.4341474771499634\n",
      "tensor([1., 0.]) tensor([0.8791, 0.1209], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 47 - 9: cat - cat || Loss: 0.43408262729644775\n",
      "tensor([1., 0.]) tensor([0.8792, 0.1208], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 47 - 10: cat - cat || Loss: 0.4339960813522339\n",
      "tensor([1., 0.]) tensor([0.8793, 0.1207], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 47 - 11: cat - cat || Loss: 0.4338902235031128\n",
      "tensor([1., 0.]) tensor([0.8794, 0.1206], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 47 - 12: cat - cat || Loss: 0.43376684188842773\n",
      "tensor([1., 0.]) tensor([0.8795, 0.1205], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 47 - 13: cat - cat || Loss: 0.4336279630661011\n",
      "tensor([1., 0.]) tensor([0.8796, 0.1204], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 47 - 14: cat - cat || Loss: 0.43347489833831787\n",
      "tensor([1., 0.]) tensor([0.8798, 0.1202], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 47 - 15: cat - cat || Loss: 0.43330931663513184\n",
      "tensor([1., 0.]) tensor([0.8800, 0.1200], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 47 - 16: cat - cat || Loss: 0.433132529258728\n",
      "tensor([1., 0.]) tensor([0.8801, 0.1199], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 47 - 17: cat - cat || Loss: 0.4329455494880676\n",
      "tensor([1., 0.]) tensor([0.8803, 0.1197], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 47 - 18: cat - cat || Loss: 0.4327497184276581\n",
      "tensor([1., 0.]) tensor([0.8805, 0.1195], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 47 - 19: cat - cat || Loss: 0.4325457811355591\n",
      "tensor([1., 0.]) tensor([0.8807, 0.1193], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 47 - 20: cat - cat || Loss: 0.4323345422744751\n",
      "tensor([1., 0.]) tensor([0.8809, 0.1191], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 47 - 21: cat - cat || Loss: 0.4321169853210449\n",
      "tensor([1., 0.]) tensor([0.8811, 0.1189], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 47 - 22: cat - cat || Loss: 0.43189382553100586\n",
      "tensor([1., 0.]) tensor([0.8814, 0.1186], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 47 - 23: cat - cat || Loss: 0.4316655397415161\n",
      "tensor([1., 0.]) tensor([0.8816, 0.1184], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 47 - 24: cat - cat || Loss: 0.431432843208313\n",
      "tensor([1., 0.]) tensor([0.8818, 0.1182], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 47 - 25: cat - cat || Loss: 0.4311961233615875\n",
      "tensor([1., 0.]) tensor([0.8821, 0.1179], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 47 - 26: cat - cat || Loss: 0.4309558868408203\n",
      "tensor([1., 0.]) tensor([0.8823, 0.1177], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 47 - 27: cat - cat || Loss: 0.43071258068084717\n",
      "tensor([1., 0.]) tensor([0.8825, 0.1175], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 47 - 28: cat - cat || Loss: 0.43046656250953674\n",
      "tensor([1., 0.]) tensor([0.8828, 0.1172], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 47 - 29: cat - cat || Loss: 0.4302181303501129\n",
      "tensor([1., 0.]) tensor([0.8830, 0.1170], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 47 - 30: cat - cat || Loss: 0.4299677014350891\n",
      "tensor([1., 0.]) tensor([0.8833, 0.1167], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 47 - 31: cat - cat || Loss: 0.4297153353691101\n",
      "tensor([1., 0.]) tensor([0.8835, 0.1165], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 47 - 32: cat - cat || Loss: 0.4294615089893341\n",
      "tensor([1., 0.]) tensor([0.8838, 0.1162], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 47 - 33: cat - cat || Loss: 0.42920640110969543\n",
      "tensor([1., 0.]) tensor([0.8841, 0.1159], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 47 - 34: cat - cat || Loss: 0.42895007133483887\n",
      "tensor([1., 0.]) tensor([0.8843, 0.1157], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 47 - 35: cat - cat || Loss: 0.4286927878856659\n",
      "tensor([1., 0.]) tensor([0.8846, 0.1154], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 47 - 36: cat - cat || Loss: 0.4284347891807556\n",
      "tensor([1., 0.]) tensor([0.8848, 0.1152], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 47 - 37: cat - cat || Loss: 0.4281761050224304\n",
      "tensor([1., 0.]) tensor([0.8851, 0.1149], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 47 - 38: cat - cat || Loss: 0.42791688442230225\n",
      "tensor([1., 0.]) tensor([0.8853, 0.1147], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 47 - 39: cat - cat || Loss: 0.42765718698501587\n",
      "tensor([1., 0.]) tensor([0.8856, 0.1144], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 47 - 40: cat - cat || Loss: 0.42739737033843994\n",
      "tensor([1., 0.]) tensor([0.8859, 0.1141], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 47 - 41: cat - cat || Loss: 0.42713719606399536\n",
      "tensor([1., 0.]) tensor([0.8861, 0.1139], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 47 - 42: cat - cat || Loss: 0.42687705159187317\n",
      "tensor([1., 0.]) tensor([0.8864, 0.1136], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 47 - 43: cat - cat || Loss: 0.42661672830581665\n",
      "tensor([1., 0.]) tensor([0.8866, 0.1134], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 47 - 44: cat - cat || Loss: 0.42635655403137207\n",
      "tensor([1., 0.]) tensor([0.8869, 0.1131], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 47 - 45: cat - cat || Loss: 0.4260963797569275\n",
      "tensor([1., 0.]) tensor([0.8872, 0.1128], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 47 - 46: cat - cat || Loss: 0.42583638429641724\n",
      "tensor([1., 0.]) tensor([0.8874, 0.1126], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 47 - 47: cat - cat || Loss: 0.4255765974521637\n",
      "tensor([1., 0.]) tensor([0.8877, 0.1123], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 47 - 48: cat - cat || Loss: 0.42531710863113403\n",
      "tensor([1., 0.]) tensor([0.8879, 0.1121], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 47 - 49: cat - cat || Loss: 0.4250578284263611\n",
      "tensor([1., 0.]) tensor([0.8882, 0.1118], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 47 - 50: cat - cat || Loss: 0.4247989058494568\n",
      "tensor([1., 0.]) tensor([0.8885, 0.1115], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 47 - 51: cat - cat || Loss: 0.42454034090042114\n",
      "tensor([1., 0.]) tensor([0.8887, 0.1113], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 47 - 52: cat - cat || Loss: 0.42428213357925415\n",
      "tensor([1., 0.]) tensor([0.8890, 0.1110], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 47 - 53: cat - cat || Loss: 0.4240243434906006\n",
      "tensor([1., 0.]) tensor([0.8892, 0.1108], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 47 - 54: cat - cat || Loss: 0.42376697063446045\n",
      "tensor([1., 0.]) tensor([0.8895, 0.1105], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 47 - 55: cat - cat || Loss: 0.4235100746154785\n",
      "tensor([1., 0.]) tensor([0.8898, 0.1102], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 47 - 56: cat - cat || Loss: 0.4232535660266876\n",
      "tensor([1., 0.]) tensor([0.8900, 0.1100], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 47 - 57: cat - cat || Loss: 0.4229975938796997\n",
      "tensor([1., 0.]) tensor([0.8903, 0.1097], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 47 - 58: cat - cat || Loss: 0.42274209856987\n",
      "tensor([1., 0.]) tensor([0.8905, 0.1095], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 47 - 59: cat - cat || Loss: 0.42248713970184326\n",
      "tensor([1., 0.]) tensor([0.8908, 0.1092], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 47 - 60: cat - cat || Loss: 0.4222326874732971\n",
      "tensor([1., 0.]) tensor([0.8910, 0.1090], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 47 - 61: cat - cat || Loss: 0.4219786822795868\n",
      "tensor([1., 0.]) tensor([0.8913, 0.1087], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 47 - 62: cat - cat || Loss: 0.42172539234161377\n",
      "tensor([1., 0.]) tensor([0.8915, 0.1085], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 47 - 63: cat - cat || Loss: 0.42147260904312134\n",
      "tensor([1., 0.]) tensor([0.8918, 0.1082], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 47 - 64: cat - cat || Loss: 0.4212203323841095\n",
      "tensor([1., 0.]) tensor([0.8920, 0.1080], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 47 - 65: cat - cat || Loss: 0.42096859216690063\n",
      "tensor([1., 0.]) tensor([0.8923, 0.1077], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 47 - 66: cat - cat || Loss: 0.42071741819381714\n",
      "tensor([1., 0.]) tensor([0.8925, 0.1075], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 47 - 67: cat - cat || Loss: 0.42046695947647095\n",
      "tensor([1., 0.]) tensor([0.8928, 0.1072], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 47 - 68: cat - cat || Loss: 0.4202168881893158\n",
      "tensor([1., 0.]) tensor([0.8930, 0.1070], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 47 - 69: cat - cat || Loss: 0.4199674427509308\n",
      "tensor([1., 0.]) tensor([0.8933, 0.1067], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 47 - 70: cat - cat || Loss: 0.4197187125682831\n",
      "tensor([1., 0.]) tensor([0.8935, 0.1065], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 47 - 71: cat - cat || Loss: 0.41947048902511597\n",
      "tensor([1., 0.]) tensor([0.8938, 0.1062], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 47 - 72: cat - cat || Loss: 0.41922277212142944\n",
      "tensor([1., 0.]) tensor([0.8940, 0.1060], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 47 - 73: cat - cat || Loss: 0.41897574067115784\n",
      "tensor([1., 0.]) tensor([0.8943, 0.1057], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 47 - 74: cat - cat || Loss: 0.4187292456626892\n",
      "tensor([1., 0.]) tensor([0.8945, 0.1055], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 47 - 75: cat - cat || Loss: 0.4184833765029907\n",
      "tensor([1., 0.]) tensor([0.8948, 0.1052], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 47 - 76: cat - cat || Loss: 0.4182380735874176\n",
      "tensor([1., 0.]) tensor([0.8950, 0.1050], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 47 - 77: cat - cat || Loss: 0.417993426322937\n",
      "tensor([1., 0.]) tensor([0.8953, 0.1047], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 47 - 78: cat - cat || Loss: 0.4177493453025818\n",
      "tensor([1., 0.]) tensor([0.8955, 0.1045], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 47 - 79: cat - cat || Loss: 0.4175058901309967\n",
      "tensor([1., 0.]) tensor([0.8958, 0.1042], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 47 - 80: cat - cat || Loss: 0.4172629714012146\n",
      "tensor([1., 0.]) tensor([0.8960, 0.1040], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 47 - 81: cat - cat || Loss: 0.41702064871788025\n",
      "tensor([1., 0.]) tensor([0.8962, 0.1038], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 47 - 82: cat - cat || Loss: 0.41677892208099365\n",
      "tensor([1., 0.]) tensor([0.8965, 0.1035], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 47 - 83: cat - cat || Loss: 0.416537880897522\n",
      "tensor([1., 0.]) tensor([0.8967, 0.1033], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 47 - 84: cat - cat || Loss: 0.41629743576049805\n",
      "tensor([1., 0.]) tensor([0.8970, 0.1030], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 47 - 85: cat - cat || Loss: 0.4160575270652771\n",
      "tensor([1., 0.]) tensor([0.8972, 0.1028], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 47 - 86: cat - cat || Loss: 0.4158182144165039\n",
      "tensor([1., 0.]) tensor([0.8974, 0.1026], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 47 - 87: cat - cat || Loss: 0.4155794382095337\n",
      "tensor([1., 0.]) tensor([0.8977, 0.1023], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 47 - 88: cat - cat || Loss: 0.4153413772583008\n",
      "tensor([1., 0.]) tensor([0.8979, 0.1021], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 47 - 89: cat - cat || Loss: 0.4151039123535156\n",
      "tensor([1., 0.]) tensor([0.8982, 0.1018], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 47 - 90: cat - cat || Loss: 0.41486698389053345\n",
      "tensor([1., 0.]) tensor([0.8984, 0.1016], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 47 - 91: cat - cat || Loss: 0.41463059186935425\n",
      "tensor([1., 0.]) tensor([0.8986, 0.1014], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 47 - 92: cat - cat || Loss: 0.41439491510391235\n",
      "tensor([1., 0.]) tensor([0.8989, 0.1011], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 47 - 93: cat - cat || Loss: 0.41415971517562866\n",
      "tensor([1., 0.]) tensor([0.8991, 0.1009], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 47 - 94: cat - cat || Loss: 0.4139251112937927\n",
      "tensor([1., 0.]) tensor([0.8993, 0.1007], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 47 - 95: cat - cat || Loss: 0.4136911630630493\n",
      "tensor([1., 0.]) tensor([0.8996, 0.1004], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 47 - 96: cat - cat || Loss: 0.4134577512741089\n",
      "tensor([1., 0.]) tensor([0.8998, 0.1002], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 47 - 97: cat - cat || Loss: 0.4132249355316162\n",
      "tensor([1., 0.]) tensor([0.9000, 0.1000], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 47 - 98: cat - cat || Loss: 0.4129926562309265\n",
      "tensor([1., 0.]) tensor([0.9003, 0.0997], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 47 - 99: cat - cat || Loss: 0.41276097297668457\n",
      "tensor([1., 0.]) tensor([0.9005, 0.0995], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 47 - 100: cat - cat || Loss: 0.412529855966568\n",
      "tensor([1., 0.]) tensor([0.9007, 0.0993], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 47 - 101: cat - cat || Loss: 0.41229939460754395\n",
      "tensor([1., 0.]) tensor([0.9010, 0.0990], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 47 - 102: cat - cat || Loss: 0.4120694696903229\n",
      "tensor([1., 0.]) tensor([0.9012, 0.0988], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 47 - 103: cat - cat || Loss: 0.4118400812149048\n",
      "tensor([1., 0.]) tensor([0.9014, 0.0986], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 47 - 104: cat - cat || Loss: 0.4116113781929016\n",
      "tensor([1., 0.]) tensor([0.9017, 0.0983], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 47 - 105: cat - cat || Loss: 0.4113832116127014\n",
      "tensor([1., 0.]) tensor([0.9019, 0.0981], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 47 - 106: cat - cat || Loss: 0.411155641078949\n",
      "tensor([1., 0.]) tensor([0.9021, 0.0979], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 47 - 107: cat - cat || Loss: 0.4109286367893219\n",
      "tensor([1., 0.]) tensor([0.9023, 0.0977], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 47 - 108: cat - cat || Loss: 0.4107021689414978\n",
      "tensor([1., 0.]) tensor([0.9026, 0.0974], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 47 - 109: cat - cat || Loss: 0.4104762673377991\n",
      "tensor([1., 0.]) tensor([0.9028, 0.0972], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 47 - 110: cat - cat || Loss: 0.4102509617805481\n",
      "tensor([1., 0.]) tensor([0.9030, 0.0970], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 47 - 111: cat - cat || Loss: 0.4100262522697449\n",
      "tensor([1., 0.]) tensor([0.9032, 0.0968], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 47 - 112: cat - cat || Loss: 0.40980207920074463\n",
      "tensor([1., 0.]) tensor([0.9035, 0.0965], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 47 - 113: cat - cat || Loss: 0.40957850217819214\n",
      "tensor([1., 0.]) tensor([0.9037, 0.0963], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 47 - 114: cat - cat || Loss: 0.4093554615974426\n",
      "tensor([1., 0.]) tensor([0.9039, 0.0961], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 47 - 115: cat - cat || Loss: 0.40913301706314087\n",
      "tensor([1., 0.]) tensor([0.9041, 0.0959], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 47 - 116: cat - cat || Loss: 0.4089111089706421\n",
      "tensor([1., 0.]) tensor([0.9044, 0.0956], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 47 - 117: cat - cat || Loss: 0.40868979692459106\n",
      "tensor([1., 0.]) tensor([0.9046, 0.0954], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 47 - 118: cat - cat || Loss: 0.408469021320343\n",
      "tensor([1., 0.]) tensor([0.9048, 0.0952], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 47 - 119: cat - cat || Loss: 0.40824878215789795\n",
      "tensor([1., 0.]) tensor([0.9050, 0.0950], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 47 - 120: cat - cat || Loss: 0.40802907943725586\n",
      "tensor([1., 0.]) tensor([0.9052, 0.0948], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 47 - 121: cat - cat || Loss: 0.40780991315841675\n",
      "tensor([1., 0.]) tensor([0.9055, 0.0945], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 47 - 122: cat - cat || Loss: 0.40759143233299255\n",
      "tensor([1., 0.]) tensor([0.9057, 0.0943], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 47 - 123: cat - cat || Loss: 0.4073733985424042\n",
      "tensor([1., 0.]) tensor([0.9059, 0.0941], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 47 - 124: cat - cat || Loss: 0.40715596079826355\n",
      "tensor([1., 0.]) tensor([0.9061, 0.0939], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 47 - 125: cat - cat || Loss: 0.4069390892982483\n",
      "tensor([1., 0.]) tensor([0.9063, 0.0937], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 47 - 126: cat - cat || Loss: 0.4067227244377136\n",
      "tensor([1., 0.]) tensor([0.9065, 0.0935], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 47 - 127: cat - cat || Loss: 0.40650683641433716\n",
      "tensor([1., 0.]) tensor([0.9068, 0.0932], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 47 - 128: cat - cat || Loss: 0.406291663646698\n",
      "tensor([1., 0.]) tensor([0.9070, 0.0930], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 47 - 129: cat - cat || Loss: 0.40607690811157227\n",
      "tensor([1., 0.]) tensor([0.9072, 0.0928], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 47 - 130: cat - cat || Loss: 0.4058627784252167\n",
      "tensor([1., 0.]) tensor([0.9074, 0.0926], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 47 - 131: cat - cat || Loss: 0.4056491553783417\n",
      "tensor([1., 0.]) tensor([0.9076, 0.0924], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 47 - 132: cat - cat || Loss: 0.40543603897094727\n",
      "tensor([1., 0.]) tensor([0.9078, 0.0922], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 47 - 133: cat - cat || Loss: 0.405223548412323\n",
      "tensor([1., 0.]) tensor([0.9080, 0.0920], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 47 - 134: cat - cat || Loss: 0.40501150488853455\n",
      "tensor([1., 0.]) tensor([0.9083, 0.0917], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 47 - 135: cat - cat || Loss: 0.4048001170158386\n",
      "tensor([1., 0.]) tensor([0.9085, 0.0915], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 47 - 136: cat - cat || Loss: 0.40458914637565613\n",
      "tensor([1., 0.]) tensor([0.9087, 0.0913], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 47 - 137: cat - cat || Loss: 0.4043787717819214\n",
      "tensor([1., 0.]) tensor([0.9089, 0.0911], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 47 - 138: cat - cat || Loss: 0.40416890382766724\n",
      "tensor([1., 0.]) tensor([0.9091, 0.0909], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 47 - 139: cat - cat || Loss: 0.40395957231521606\n",
      "tensor([1., 0.]) tensor([0.9093, 0.0907], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 47 - 140: cat - cat || Loss: 0.4037507474422455\n",
      "tensor([1., 0.]) tensor([0.9095, 0.0905], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 47 - 141: cat - cat || Loss: 0.40354251861572266\n",
      "tensor([1., 0.]) tensor([0.9097, 0.0903], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 47 - 142: cat - cat || Loss: 0.4033347964286804\n",
      "tensor([1., 0.]) tensor([0.9099, 0.0901], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 47 - 143: cat - cat || Loss: 0.4031274914741516\n",
      "tensor([1., 0.]) tensor([0.9101, 0.0899], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 47 - 144: cat - cat || Loss: 0.4029208719730377\n",
      "tensor([1., 0.]) tensor([0.9103, 0.0897], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 47 - 145: cat - cat || Loss: 0.40271472930908203\n",
      "tensor([1., 0.]) tensor([0.9105, 0.0895], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 47 - 146: cat - cat || Loss: 0.40250909328460693\n",
      "tensor([1., 0.]) tensor([0.9108, 0.0892], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 47 - 147: cat - cat || Loss: 0.4023039937019348\n",
      "tensor([1., 0.]) tensor([0.9110, 0.0890], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 47 - 148: cat - cat || Loss: 0.4020994007587433\n",
      "tensor([1., 0.]) tensor([0.9112, 0.0888], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 47 - 149: cat - cat || Loss: 0.4018953740596771\n",
      "tensor([1., 0.]) tensor([0.9114, 0.0886], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 47 - 150: cat - cat || Loss: 0.4016917943954468\n",
      "tensor([1., 0.]) tensor([0.9116, 0.0884], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 47 - 151: cat - cat || Loss: 0.4014887809753418\n",
      "tensor([1., 0.]) tensor([0.9118, 0.0882], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 47 - 152: cat - cat || Loss: 0.4012863039970398\n",
      "tensor([1., 0.]) tensor([0.9120, 0.0880], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 47 - 153: cat - cat || Loss: 0.4010842740535736\n",
      "tensor([1., 0.]) tensor([0.9122, 0.0878], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 47 - 154: cat - cat || Loss: 0.4008827805519104\n",
      "tensor([1., 0.]) tensor([0.9124, 0.0876], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 47 - 155: cat - cat || Loss: 0.40068182349205017\n",
      "tensor([1., 0.]) tensor([0.9126, 0.0874], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 47 - 156: cat - cat || Loss: 0.4004814028739929\n",
      "tensor([1., 0.]) tensor([0.9128, 0.0872], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 47 - 157: cat - cat || Loss: 0.40028145909309387\n",
      "tensor([1., 0.]) tensor([0.9130, 0.0870], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 47 - 158: cat - cat || Loss: 0.400081992149353\n",
      "tensor([1., 0.]) tensor([0.9132, 0.0868], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 47 - 159: cat - cat || Loss: 0.39988306164741516\n",
      "tensor([1., 0.]) tensor([0.9134, 0.0866], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 47 - 160: cat - cat || Loss: 0.3996846377849579\n",
      "tensor([1., 0.]) tensor([0.9136, 0.0864], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 47 - 161: cat - cat || Loss: 0.3994867503643036\n",
      "tensor([1., 0.]) tensor([0.9138, 0.0862], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 47 - 162: cat - cat || Loss: 0.3992893695831299\n",
      "tensor([1., 0.]) tensor([0.9140, 0.0860], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 47 - 163: cat - cat || Loss: 0.3990924060344696\n",
      "tensor([1., 0.]) tensor([0.9142, 0.0858], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 47 - 164: cat - cat || Loss: 0.3988960087299347\n",
      "tensor([1., 0.]) tensor([0.9144, 0.0856], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 47 - 165: cat - cat || Loss: 0.398700088262558\n",
      "tensor([1., 0.]) tensor([0.9146, 0.0854], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 47 - 166: cat - cat || Loss: 0.3985046148300171\n",
      "tensor([1., 0.]) tensor([0.9148, 0.0852], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 47 - 167: cat - cat || Loss: 0.3983096778392792\n",
      "tensor([1., 0.]) tensor([0.9150, 0.0850], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 47 - 168: cat - cat || Loss: 0.39811524748802185\n",
      "tensor([1., 0.]) tensor([0.9151, 0.0849], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 47 - 169: cat - cat || Loss: 0.39792123436927795\n",
      "tensor([1., 0.]) tensor([0.9153, 0.0847], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 47 - 170: cat - cat || Loss: 0.3977278172969818\n",
      "tensor([1., 0.]) tensor([0.9155, 0.0845], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 47 - 171: cat - cat || Loss: 0.39753490686416626\n",
      "tensor([1., 0.]) tensor([0.9157, 0.0843], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 47 - 172: cat - cat || Loss: 0.39734238386154175\n",
      "tensor([1., 0.]) tensor([0.9159, 0.0841], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 47 - 173: cat - cat || Loss: 0.397150456905365\n",
      "tensor([1., 0.]) tensor([0.9161, 0.0839], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 47 - 174: cat - cat || Loss: 0.3969589173793793\n",
      "tensor([1., 0.]) tensor([0.9163, 0.0837], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 47 - 175: cat - cat || Loss: 0.3967679440975189\n",
      "tensor([1., 0.]) tensor([0.9165, 0.0835], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 47 - 176: cat - cat || Loss: 0.3965773582458496\n",
      "tensor([1., 0.]) tensor([0.9167, 0.0833], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 47 - 177: cat - cat || Loss: 0.3963874280452728\n",
      "tensor([1., 0.]) tensor([0.9169, 0.0831], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 47 - 178: cat - cat || Loss: 0.3961978256702423\n",
      "tensor([1., 0.]) tensor([0.9171, 0.0829], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 47 - 179: cat - cat || Loss: 0.39600878953933716\n",
      "tensor([1., 0.]) tensor([0.9173, 0.0827], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 47 - 180: cat - cat || Loss: 0.39582014083862305\n",
      "tensor([1., 0.]) tensor([0.9174, 0.0826], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 47 - 181: cat - cat || Loss: 0.3956320285797119\n",
      "tensor([1., 0.]) tensor([0.9176, 0.0824], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 47 - 182: cat - cat || Loss: 0.3954443335533142\n",
      "tensor([1., 0.]) tensor([0.9178, 0.0822], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 47 - 183: cat - cat || Loss: 0.39525723457336426\n",
      "tensor([1., 0.]) tensor([0.9180, 0.0820], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 47 - 184: cat - cat || Loss: 0.3950704336166382\n",
      "tensor([1., 0.]) tensor([0.9182, 0.0818], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 47 - 185: cat - cat || Loss: 0.394884318113327\n",
      "tensor([1., 0.]) tensor([0.9184, 0.0816], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 47 - 186: cat - cat || Loss: 0.39469847083091736\n",
      "tensor([1., 0.]) tensor([0.9186, 0.0814], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 47 - 187: cat - cat || Loss: 0.3945131301879883\n",
      "tensor([1., 0.]) tensor([0.9187, 0.0813], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 47 - 188: cat - cat || Loss: 0.394328236579895\n",
      "tensor([1., 0.]) tensor([0.9189, 0.0811], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 47 - 189: cat - cat || Loss: 0.3941437602043152\n",
      "tensor([1., 0.]) tensor([0.9191, 0.0809], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 47 - 190: dog - cat || Loss: 1.2325637340545654\n",
      "tensor([0., 1.]) tensor([0.9193, 0.0807], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 47 - 191: dog - cat || Loss: 1.232710838317871\n",
      "tensor([0., 1.]) tensor([0.9194, 0.0806], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 47 - 192: dog - cat || Loss: 1.2328251600265503\n",
      "tensor([0., 1.]) tensor([0.9196, 0.0804], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 47 - 193: dog - cat || Loss: 1.232909917831421\n",
      "tensor([0., 1.]) tensor([0.9196, 0.0804], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 47 - 194: dog - cat || Loss: 1.232967734336853\n",
      "tensor([0., 1.]) tensor([0.9197, 0.0803], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 47 - 195: dog - cat || Loss: 1.2330020666122437\n",
      "tensor([0., 1.]) tensor([0.9197, 0.0803], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 47 - 196: dog - cat || Loss: 1.2330145835876465\n",
      "tensor([0., 1.]) tensor([0.9198, 0.0802], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 47 - 197: dog - cat || Loss: 1.2330076694488525\n",
      "tensor([0., 1.]) tensor([0.9197, 0.0803], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 47 - 198: dog - cat || Loss: 1.2329837083816528\n",
      "tensor([0., 1.]) tensor([0.9197, 0.0803], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 47 - 199: dog - cat || Loss: 1.2329437732696533\n",
      "tensor([0., 1.]) tensor([0.9197, 0.0803], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 47 - 200: dog - cat || Loss: 1.2328898906707764\n",
      "tensor([0., 1.]) tensor([0.9196, 0.0804], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 47 - 201: dog - cat || Loss: 1.2328232526779175\n",
      "tensor([0., 1.]) tensor([0.9196, 0.0804], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 47 - 202: dog - cat || Loss: 1.2327451705932617\n",
      "tensor([0., 1.]) tensor([0.9195, 0.0805], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 47 - 203: dog - cat || Loss: 1.2326565980911255\n",
      "tensor([0., 1.]) tensor([0.9194, 0.0806], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 47 - 204: dog - cat || Loss: 1.2325589656829834\n",
      "tensor([0., 1.]) tensor([0.9193, 0.0807], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 47 - 205: dog - cat || Loss: 1.232452630996704\n",
      "tensor([0., 1.]) tensor([0.9192, 0.0808], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 47 - 206: dog - cat || Loss: 1.232338786125183\n",
      "tensor([0., 1.]) tensor([0.9191, 0.0809], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 47 - 207: dog - cat || Loss: 1.2322181463241577\n",
      "tensor([0., 1.]) tensor([0.9190, 0.0810], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 47 - 208: dog - cat || Loss: 1.2320910692214966\n",
      "tensor([0., 1.]) tensor([0.9188, 0.0812], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 47 - 209: dog - cat || Loss: 1.2319583892822266\n",
      "tensor([0., 1.]) tensor([0.9187, 0.0813], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 47 - 210: dog - cat || Loss: 1.2318207025527954\n",
      "tensor([0., 1.]) tensor([0.9186, 0.0814], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 47 - 211: dog - cat || Loss: 1.2316782474517822\n",
      "tensor([0., 1.]) tensor([0.9184, 0.0816], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 47 - 212: dog - cat || Loss: 1.2315315008163452\n",
      "tensor([0., 1.]) tensor([0.9183, 0.0817], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 47 - 213: dog - cat || Loss: 1.2313810586929321\n",
      "tensor([0., 1.]) tensor([0.9181, 0.0819], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 47 - 214: dog - cat || Loss: 1.231226921081543\n",
      "tensor([0., 1.]) tensor([0.9180, 0.0820], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 47 - 215: dog - cat || Loss: 1.231069564819336\n",
      "tensor([0., 1.]) tensor([0.9178, 0.0822], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 47 - 216: dog - cat || Loss: 1.2309095859527588\n",
      "tensor([0., 1.]) tensor([0.9176, 0.0824], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 47 - 217: dog - cat || Loss: 1.2307465076446533\n",
      "tensor([0., 1.]) tensor([0.9175, 0.0825], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 47 - 218: dog - cat || Loss: 1.2305810451507568\n",
      "tensor([0., 1.]) tensor([0.9173, 0.0827], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 47 - 219: dog - cat || Loss: 1.2304134368896484\n",
      "tensor([0., 1.]) tensor([0.9172, 0.0828], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 47 - 220: dog - cat || Loss: 1.2302436828613281\n",
      "tensor([0., 1.]) tensor([0.9170, 0.0830], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 47 - 221: dog - cat || Loss: 1.230072021484375\n",
      "tensor([0., 1.]) tensor([0.9168, 0.0832], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 47 - 222: dog - cat || Loss: 1.2298986911773682\n",
      "tensor([0., 1.]) tensor([0.9166, 0.0834], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 47 - 223: dog - cat || Loss: 1.229723572731018\n",
      "tensor([0., 1.]) tensor([0.9165, 0.0835], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 47 - 224: dog - cat || Loss: 1.2295470237731934\n",
      "tensor([0., 1.]) tensor([0.9163, 0.0837], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 47 - 225: dog - cat || Loss: 1.229369044303894\n",
      "tensor([0., 1.]) tensor([0.9161, 0.0839], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 47 - 226: dog - cat || Loss: 1.2291896343231201\n",
      "tensor([0., 1.]) tensor([0.9159, 0.0841], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 47 - 227: dog - cat || Loss: 1.2290090322494507\n",
      "tensor([0., 1.]) tensor([0.9157, 0.0843], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 47 - 228: dog - cat || Loss: 1.2288273572921753\n",
      "tensor([0., 1.]) tensor([0.9156, 0.0844], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 47 - 229: dog - cat || Loss: 1.2286444902420044\n",
      "tensor([0., 1.]) tensor([0.9154, 0.0846], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 47 - 230: dog - cat || Loss: 1.2284607887268066\n",
      "tensor([0., 1.]) tensor([0.9152, 0.0848], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 47 - 231: dog - cat || Loss: 1.2282757759094238\n",
      "tensor([0., 1.]) tensor([0.9150, 0.0850], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 47 - 232: dog - cat || Loss: 1.2280899286270142\n",
      "tensor([0., 1.]) tensor([0.9148, 0.0852], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 47 - 233: dog - cat || Loss: 1.2279032468795776\n",
      "tensor([0., 1.]) tensor([0.9146, 0.0854], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 47 - 234: dog - cat || Loss: 1.2277159690856934\n",
      "tensor([0., 1.]) tensor([0.9145, 0.0855], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 47 - 235: dog - cat || Loss: 1.2275276184082031\n",
      "tensor([0., 1.]) tensor([0.9143, 0.0857], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 47 - 236: dog - cat || Loss: 1.2273385524749756\n",
      "tensor([0., 1.]) tensor([0.9141, 0.0859], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 47 - 237: dog - cat || Loss: 1.2271486520767212\n",
      "tensor([0., 1.]) tensor([0.9139, 0.0861], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 47 - 238: dog - cat || Loss: 1.2269582748413086\n",
      "tensor([0., 1.]) tensor([0.9137, 0.0863], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 47 - 239: dog - cat || Loss: 1.2267669439315796\n",
      "tensor([0., 1.]) tensor([0.9135, 0.0865], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 47 - 240: dog - cat || Loss: 1.2265750169754028\n",
      "tensor([0., 1.]) tensor([0.9133, 0.0867], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 47 - 241: dog - cat || Loss: 1.2263824939727783\n",
      "tensor([0., 1.]) tensor([0.9131, 0.0869], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 47 - 242: dog - cat || Loss: 1.2261892557144165\n",
      "tensor([0., 1.]) tensor([0.9129, 0.0871], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 47 - 243: dog - cat || Loss: 1.2259955406188965\n",
      "tensor([0., 1.]) tensor([0.9127, 0.0873], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 47 - 244: dog - cat || Loss: 1.2258009910583496\n",
      "tensor([0., 1.]) tensor([0.9125, 0.0875], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 47 - 245: dog - cat || Loss: 1.2256062030792236\n",
      "tensor([0., 1.]) tensor([0.9123, 0.0877], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 47 - 246: dog - cat || Loss: 1.2254103422164917\n",
      "tensor([0., 1.]) tensor([0.9121, 0.0879], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 47 - 247: dog - cat || Loss: 1.2252141237258911\n",
      "tensor([0., 1.]) tensor([0.9120, 0.0880], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 47 - 248: dog - cat || Loss: 1.2250174283981323\n",
      "tensor([0., 1.]) tensor([0.9118, 0.0882], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 47 - 249: dog - cat || Loss: 1.2248200178146362\n",
      "tensor([0., 1.]) tensor([0.9116, 0.0884], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 47 - 250: dog - cat || Loss: 1.2246222496032715\n",
      "tensor([0., 1.]) tensor([0.9114, 0.0886], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 47 - 251: dog - cat || Loss: 1.2244237661361694\n",
      "tensor([0., 1.]) tensor([0.9112, 0.0888], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 47 - 252: dog - cat || Loss: 1.2242248058319092\n",
      "tensor([0., 1.]) tensor([0.9110, 0.0890], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 47 - 253: dog - cat || Loss: 1.2240251302719116\n",
      "tensor([0., 1.]) tensor([0.9108, 0.0892], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 47 - 254: dog - cat || Loss: 1.2238250970840454\n",
      "tensor([0., 1.]) tensor([0.9106, 0.0894], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 47 - 255: dog - cat || Loss: 1.223624587059021\n",
      "tensor([0., 1.]) tensor([0.9104, 0.0896], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 47 - 256: dog - cat || Loss: 1.2234233617782593\n",
      "tensor([0., 1.]) tensor([0.9102, 0.0898], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 47 - 257: dog - cat || Loss: 1.223221778869629\n",
      "tensor([0., 1.]) tensor([0.9100, 0.0900], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 47 - 258: dog - cat || Loss: 1.2230194807052612\n",
      "tensor([0., 1.]) tensor([0.9098, 0.0902], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 47 - 259: dog - cat || Loss: 1.222816824913025\n",
      "tensor([0., 1.]) tensor([0.9096, 0.0904], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 47 - 260: dog - cat || Loss: 1.2226134538650513\n",
      "tensor([0., 1.]) tensor([0.9094, 0.0906], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 47 - 261: dog - cat || Loss: 1.222409725189209\n",
      "tensor([0., 1.]) tensor([0.9091, 0.0909], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 47 - 262: dog - cat || Loss: 1.222205400466919\n",
      "tensor([0., 1.]) tensor([0.9089, 0.0911], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 47 - 263: dog - cat || Loss: 1.2220005989074707\n",
      "tensor([0., 1.]) tensor([0.9087, 0.0913], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 47 - 264: dog - cat || Loss: 1.2217953205108643\n",
      "tensor([0., 1.]) tensor([0.9085, 0.0915], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 47 - 265: dog - cat || Loss: 1.22158944606781\n",
      "tensor([0., 1.]) tensor([0.9083, 0.0917], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 47 - 266: dog - cat || Loss: 1.2213832139968872\n",
      "tensor([0., 1.]) tensor([0.9081, 0.0919], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 47 - 267: dog - cat || Loss: 1.221176266670227\n",
      "tensor([0., 1.]) tensor([0.9079, 0.0921], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 47 - 268: dog - cat || Loss: 1.2209687232971191\n",
      "tensor([0., 1.]) tensor([0.9077, 0.0923], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 47 - 269: dog - cat || Loss: 1.2207608222961426\n",
      "tensor([0., 1.]) tensor([0.9075, 0.0925], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 47 - 270: dog - cat || Loss: 1.2205523252487183\n",
      "tensor([0., 1.]) tensor([0.9073, 0.0927], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 47 - 271: dog - cat || Loss: 1.2203433513641357\n",
      "tensor([0., 1.]) tensor([0.9071, 0.0929], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 47 - 272: dog - cat || Loss: 1.2201340198516846\n",
      "tensor([0., 1.]) tensor([0.9069, 0.0931], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 47 - 273: dog - cat || Loss: 1.219923973083496\n",
      "tensor([0., 1.]) tensor([0.9067, 0.0933], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 47 - 274: dog - cat || Loss: 1.2197134494781494\n",
      "tensor([0., 1.]) tensor([0.9065, 0.0935], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 47 - 275: dog - cat || Loss: 1.219502329826355\n",
      "tensor([0., 1.]) tensor([0.9062, 0.0938], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 47 - 276: dog - cat || Loss: 1.2192907333374023\n",
      "tensor([0., 1.]) tensor([0.9060, 0.0940], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 47 - 277: dog - cat || Loss: 1.2190786600112915\n",
      "tensor([0., 1.]) tensor([0.9058, 0.0942], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 47 - 278: dog - cat || Loss: 1.218865990638733\n",
      "tensor([0., 1.]) tensor([0.9056, 0.0944], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 47 - 279: dog - cat || Loss: 1.2186530828475952\n",
      "tensor([0., 1.]) tensor([0.9054, 0.0946], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 47 - 280: dog - cat || Loss: 1.2184391021728516\n",
      "tensor([0., 1.]) tensor([0.9052, 0.0948], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 47 - 281: dog - cat || Loss: 1.2182248830795288\n",
      "tensor([0., 1.]) tensor([0.9050, 0.0950], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 47 - 282: dog - cat || Loss: 1.2180103063583374\n",
      "tensor([0., 1.]) tensor([0.9047, 0.0953], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 47 - 283: dog - cat || Loss: 1.2177950143814087\n",
      "tensor([0., 1.]) tensor([0.9045, 0.0955], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 47 - 284: dog - cat || Loss: 1.2175791263580322\n",
      "tensor([0., 1.]) tensor([0.9043, 0.0957], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 47 - 285: dog - cat || Loss: 1.217362880706787\n",
      "tensor([0., 1.]) tensor([0.9041, 0.0959], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 47 - 286: dog - cat || Loss: 1.2171459197998047\n",
      "tensor([0., 1.]) tensor([0.9039, 0.0961], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 47 - 287: dog - cat || Loss: 1.2169287204742432\n",
      "tensor([0., 1.]) tensor([0.9037, 0.0963], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 47 - 288: dog - cat || Loss: 1.2167105674743652\n",
      "tensor([0., 1.]) tensor([0.9034, 0.0966], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 47 - 289: dog - cat || Loss: 1.2164921760559082\n",
      "tensor([0., 1.]) tensor([0.9032, 0.0968], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 47 - 290: dog - cat || Loss: 1.2162731885910034\n",
      "tensor([0., 1.]) tensor([0.9030, 0.0970], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 47 - 291: dog - cat || Loss: 1.2160537242889404\n",
      "tensor([0., 1.]) tensor([0.9028, 0.0972], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 47 - 292: dog - cat || Loss: 1.2158335447311401\n",
      "tensor([0., 1.]) tensor([0.9026, 0.0974], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 47 - 293: dog - cat || Loss: 1.2156128883361816\n",
      "tensor([0., 1.]) tensor([0.9024, 0.0976], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 47 - 294: dog - cat || Loss: 1.215391755104065\n",
      "tensor([0., 1.]) tensor([0.9021, 0.0979], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 47 - 295: dog - cat || Loss: 1.21517014503479\n",
      "tensor([0., 1.]) tensor([0.9019, 0.0981], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 47 - 296: dog - cat || Loss: 1.2149479389190674\n",
      "tensor([0., 1.]) tensor([0.9017, 0.0983], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 47 - 297: dog - cat || Loss: 1.2147250175476074\n",
      "tensor([0., 1.]) tensor([0.9015, 0.0985], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 47 - 298: dog - cat || Loss: 1.2145017385482788\n",
      "tensor([0., 1.]) tensor([0.9012, 0.0988], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 47 - 299: dog - cat || Loss: 1.2142778635025024\n",
      "tensor([0., 1.]) tensor([0.9010, 0.0990], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 47 - 300: dog - cat || Loss: 1.2140533924102783\n",
      "tensor([0., 1.]) tensor([0.9008, 0.0992], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 47 - 301: dog - cat || Loss: 1.213828444480896\n",
      "tensor([0., 1.]) tensor([0.9006, 0.0994], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 47 - 302: dog - cat || Loss: 1.2136027812957764\n",
      "tensor([0., 1.]) tensor([0.9003, 0.0997], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 47 - 303: dog - cat || Loss: 1.213376760482788\n",
      "tensor([0., 1.]) tensor([0.9001, 0.0999], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 47 - 304: dog - cat || Loss: 1.213149905204773\n",
      "tensor([0., 1.]) tensor([0.8999, 0.1001], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 47 - 305: dog - cat || Loss: 1.2129226922988892\n",
      "tensor([0., 1.]) tensor([0.8997, 0.1003], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 47 - 306: dog - cat || Loss: 1.2126948833465576\n",
      "tensor([0., 1.]) tensor([0.8994, 0.1006], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 47 - 307: dog - cat || Loss: 1.2124664783477783\n",
      "tensor([0., 1.]) tensor([0.8992, 0.1008], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 47 - 308: dog - cat || Loss: 1.2122375965118408\n",
      "tensor([0., 1.]) tensor([0.8990, 0.1010], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 47 - 309: dog - cat || Loss: 1.2120082378387451\n",
      "tensor([0., 1.]) tensor([0.8987, 0.1013], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 47 - 310: dog - cat || Loss: 1.2117780447006226\n",
      "tensor([0., 1.]) tensor([0.8985, 0.1015], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 47 - 311: dog - cat || Loss: 1.2115473747253418\n",
      "tensor([0., 1.]) tensor([0.8983, 0.1017], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 47 - 312: dog - cat || Loss: 1.2113163471221924\n",
      "tensor([0., 1.]) tensor([0.8981, 0.1019], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 47 - 313: dog - cat || Loss: 1.2110846042633057\n",
      "tensor([0., 1.]) tensor([0.8978, 0.1022], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 47 - 314: dog - cat || Loss: 1.2108522653579712\n",
      "tensor([0., 1.]) tensor([0.8976, 0.1024], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 47 - 315: dog - cat || Loss: 1.210619568824768\n",
      "tensor([0., 1.]) tensor([0.8974, 0.1026], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 47 - 316: dog - cat || Loss: 1.210386037826538\n",
      "tensor([0., 1.]) tensor([0.8971, 0.1029], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 47 - 317: dog - cat || Loss: 1.21015202999115\n",
      "tensor([0., 1.]) tensor([0.8969, 0.1031], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 47 - 318: dog - cat || Loss: 1.209917426109314\n",
      "tensor([0., 1.]) tensor([0.8967, 0.1033], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 47 - 319: dog - cat || Loss: 1.2096823453903198\n",
      "tensor([0., 1.]) tensor([0.8964, 0.1036], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 47 - 320: dog - cat || Loss: 1.2094465494155884\n",
      "tensor([0., 1.]) tensor([0.8962, 0.1038], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 47 - 321: dog - cat || Loss: 1.2092102766036987\n",
      "tensor([0., 1.]) tensor([0.8959, 0.1041], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 47 - 322: dog - cat || Loss: 1.2089735269546509\n",
      "tensor([0., 1.]) tensor([0.8957, 0.1043], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 47 - 323: dog - cat || Loss: 1.2087360620498657\n",
      "tensor([0., 1.]) tensor([0.8955, 0.1045], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 47 - 324: dog - cat || Loss: 1.2084978818893433\n",
      "tensor([0., 1.]) tensor([0.8952, 0.1048], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 47 - 325: dog - cat || Loss: 1.2082594633102417\n",
      "tensor([0., 1.]) tensor([0.8950, 0.1050], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 47 - 326: dog - cat || Loss: 1.2080202102661133\n",
      "tensor([0., 1.]) tensor([0.8948, 0.1052], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 47 - 327: dog - cat || Loss: 1.2077804803848267\n",
      "tensor([0., 1.]) tensor([0.8945, 0.1055], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 47 - 328: dog - cat || Loss: 1.2075401544570923\n",
      "tensor([0., 1.]) tensor([0.8943, 0.1057], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 47 - 329: dog - cat || Loss: 1.2072992324829102\n",
      "tensor([0., 1.]) tensor([0.8940, 0.1060], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 47 - 330: dog - cat || Loss: 1.2070577144622803\n",
      "tensor([0., 1.]) tensor([0.8938, 0.1062], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 47 - 331: dog - cat || Loss: 1.2068156003952026\n",
      "tensor([0., 1.]) tensor([0.8936, 0.1064], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 47 - 332: dog - cat || Loss: 1.2065730094909668\n",
      "tensor([0., 1.]) tensor([0.8933, 0.1067], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 47 - 333: dog - cat || Loss: 1.206329584121704\n",
      "tensor([0., 1.]) tensor([0.8931, 0.1069], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 47 - 334: dog - cat || Loss: 1.2060858011245728\n",
      "tensor([0., 1.]) tensor([0.8928, 0.1072], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 47 - 335: dog - cat || Loss: 1.205841302871704\n",
      "tensor([0., 1.]) tensor([0.8926, 0.1074], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 47 - 336: dog - cat || Loss: 1.2055964469909668\n",
      "tensor([0., 1.]) tensor([0.8923, 0.1077], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 47 - 337: dog - cat || Loss: 1.2053507566452026\n",
      "tensor([0., 1.]) tensor([0.8921, 0.1079], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 47 - 338: dog - cat || Loss: 1.2051044702529907\n",
      "tensor([0., 1.]) tensor([0.8918, 0.1082], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 47 - 339: dog - cat || Loss: 1.204857587814331\n",
      "tensor([0., 1.]) tensor([0.8916, 0.1084], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 47 - 340: dog - cat || Loss: 1.2046102285385132\n",
      "tensor([0., 1.]) tensor([0.8913, 0.1087], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 47 - 341: dog - cat || Loss: 1.204362154006958\n",
      "tensor([0., 1.]) tensor([0.8911, 0.1089], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 47 - 342: dog - cat || Loss: 1.2041136026382446\n",
      "tensor([0., 1.]) tensor([0.8909, 0.1091], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 47 - 343: dog - cat || Loss: 1.203864336013794\n",
      "tensor([0., 1.]) tensor([0.8906, 0.1094], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 47 - 344: dog - cat || Loss: 1.203614592552185\n",
      "tensor([0., 1.]) tensor([0.8904, 0.1096], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 47 - 345: dog - cat || Loss: 1.2033641338348389\n",
      "tensor([0., 1.]) tensor([0.8901, 0.1099], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 47 - 346: dog - cat || Loss: 1.203113079071045\n",
      "tensor([0., 1.]) tensor([0.8899, 0.1101], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 47 - 347: dog - cat || Loss: 1.2028615474700928\n",
      "tensor([0., 1.]) tensor([0.8896, 0.1104], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 47 - 348: dog - cat || Loss: 1.2026091814041138\n",
      "tensor([0., 1.]) tensor([0.8893, 0.1107], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 47 - 349: dog - cat || Loss: 1.202356219291687\n",
      "tensor([0., 1.]) tensor([0.8891, 0.1109], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 47 - 350: dog - cat || Loss: 1.202102780342102\n",
      "tensor([0., 1.]) tensor([0.8888, 0.1112], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 47 - 351: dog - cat || Loss: 1.2018487453460693\n",
      "tensor([0., 1.]) tensor([0.8886, 0.1114], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 47 - 352: dog - cat || Loss: 1.2015941143035889\n",
      "tensor([0., 1.]) tensor([0.8883, 0.1117], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 47 - 353: dog - cat || Loss: 1.201338768005371\n",
      "tensor([0., 1.]) tensor([0.8881, 0.1119], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 47 - 354: dog - cat || Loss: 1.2010828256607056\n",
      "tensor([0., 1.]) tensor([0.8878, 0.1122], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 47 - 355: dog - cat || Loss: 1.2008262872695923\n",
      "tensor([0., 1.]) tensor([0.8876, 0.1124], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 47 - 356: dog - cat || Loss: 1.2005690336227417\n",
      "tensor([0., 1.]) tensor([0.8873, 0.1127], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 47 - 357: dog - cat || Loss: 1.200311303138733\n",
      "tensor([0., 1.]) tensor([0.8870, 0.1130], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 47 - 358: dog - cat || Loss: 1.2000529766082764\n",
      "tensor([0., 1.]) tensor([0.8868, 0.1132], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 47 - 359: dog - cat || Loss: 1.1997939348220825\n",
      "tensor([0., 1.]) tensor([0.8865, 0.1135], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 47 - 360: dog - cat || Loss: 1.1995341777801514\n",
      "tensor([0., 1.]) tensor([0.8863, 0.1137], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 47 - 361: dog - cat || Loss: 1.199273943901062\n",
      "tensor([0., 1.]) tensor([0.8860, 0.1140], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 47 - 362: dog - cat || Loss: 1.199013113975525\n",
      "tensor([0., 1.]) tensor([0.8858, 0.1142], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 47 - 363: dog - cat || Loss: 1.19875168800354\n",
      "tensor([0., 1.]) tensor([0.8855, 0.1145], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 47 - 364: dog - cat || Loss: 1.1984894275665283\n",
      "tensor([0., 1.]) tensor([0.8852, 0.1148], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 47 - 365: dog - cat || Loss: 1.1982266902923584\n",
      "tensor([0., 1.]) tensor([0.8850, 0.1150], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 47 - 366: dog - cat || Loss: 1.1979632377624512\n",
      "tensor([0., 1.]) tensor([0.8847, 0.1153], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 47 - 367: dog - cat || Loss: 1.1976991891860962\n",
      "tensor([0., 1.]) tensor([0.8844, 0.1156], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 47 - 368: dog - cat || Loss: 1.197434663772583\n",
      "tensor([0., 1.]) tensor([0.8842, 0.1158], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 47 - 369: dog - cat || Loss: 1.197169303894043\n",
      "tensor([0., 1.]) tensor([0.8839, 0.1161], grad_fn=<SoftmaxBackward0>)\n",
      "=====epoch:48=====\n",
      "Epoch 48 - 0: cat - cat || Loss: 0.4296199679374695\n",
      "tensor([1., 0.]) tensor([0.8836, 0.1164], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 48 - 1: cat - cat || Loss: 0.4298325777053833\n",
      "tensor([1., 0.]) tensor([0.8834, 0.1166], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 48 - 2: cat - cat || Loss: 0.42999714612960815\n",
      "tensor([1., 0.]) tensor([0.8833, 0.1167], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 48 - 3: cat - cat || Loss: 0.4301183521747589\n",
      "tensor([1., 0.]) tensor([0.8831, 0.1169], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 48 - 4: cat - cat || Loss: 0.43020039796829224\n",
      "tensor([1., 0.]) tensor([0.8831, 0.1169], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 48 - 5: cat - cat || Loss: 0.4302471876144409\n",
      "tensor([1., 0.]) tensor([0.8830, 0.1170], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 48 - 6: cat - cat || Loss: 0.4302622079849243\n",
      "tensor([1., 0.]) tensor([0.8830, 0.1170], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 48 - 7: cat - cat || Loss: 0.4302486777305603\n",
      "tensor([1., 0.]) tensor([0.8830, 0.1170], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 48 - 8: cat - cat || Loss: 0.4302093982696533\n",
      "tensor([1., 0.]) tensor([0.8831, 0.1169], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 48 - 9: cat - cat || Loss: 0.4301469326019287\n",
      "tensor([1., 0.]) tensor([0.8831, 0.1169], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 48 - 10: cat - cat || Loss: 0.4300636947154999\n",
      "tensor([1., 0.]) tensor([0.8832, 0.1168], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 48 - 11: cat - cat || Loss: 0.4299618601799011\n",
      "tensor([1., 0.]) tensor([0.8833, 0.1167], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 48 - 12: cat - cat || Loss: 0.4298432469367981\n",
      "tensor([1., 0.]) tensor([0.8834, 0.1166], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 48 - 13: cat - cat || Loss: 0.4297094941139221\n",
      "tensor([1., 0.]) tensor([0.8836, 0.1164], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 48 - 14: cat - cat || Loss: 0.42956236004829407\n",
      "tensor([1., 0.]) tensor([0.8837, 0.1163], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 48 - 15: cat - cat || Loss: 0.42940306663513184\n",
      "tensor([1., 0.]) tensor([0.8839, 0.1161], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 48 - 16: cat - cat || Loss: 0.42923295497894287\n",
      "tensor([1., 0.]) tensor([0.8840, 0.1160], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 48 - 17: cat - cat || Loss: 0.42905306816101074\n",
      "tensor([1., 0.]) tensor([0.8842, 0.1158], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 48 - 18: cat - cat || Loss: 0.42886465787887573\n",
      "tensor([1., 0.]) tensor([0.8844, 0.1156], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 48 - 19: cat - cat || Loss: 0.42866846919059753\n",
      "tensor([1., 0.]) tensor([0.8846, 0.1154], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 48 - 20: cat - cat || Loss: 0.4284653067588806\n",
      "tensor([1., 0.]) tensor([0.8848, 0.1152], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 48 - 21: cat - cat || Loss: 0.428256094455719\n",
      "tensor([1., 0.]) tensor([0.8850, 0.1150], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 48 - 22: cat - cat || Loss: 0.42804139852523804\n",
      "tensor([1., 0.]) tensor([0.8852, 0.1148], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 48 - 23: cat - cat || Loss: 0.4278218150138855\n",
      "tensor([1., 0.]) tensor([0.8854, 0.1146], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 48 - 24: cat - cat || Loss: 0.42759791016578674\n",
      "tensor([1., 0.]) tensor([0.8857, 0.1143], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 48 - 25: cat - cat || Loss: 0.42737019062042236\n",
      "tensor([1., 0.]) tensor([0.8859, 0.1141], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 48 - 26: cat - cat || Loss: 0.42713916301727295\n",
      "tensor([1., 0.]) tensor([0.8861, 0.1139], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 48 - 27: cat - cat || Loss: 0.4269050657749176\n",
      "tensor([1., 0.]) tensor([0.8864, 0.1136], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 48 - 28: cat - cat || Loss: 0.4266684651374817\n",
      "tensor([1., 0.]) tensor([0.8866, 0.1134], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 48 - 29: cat - cat || Loss: 0.4264293909072876\n",
      "tensor([1., 0.]) tensor([0.8868, 0.1132], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 48 - 30: cat - cat || Loss: 0.42618846893310547\n",
      "tensor([1., 0.]) tensor([0.8871, 0.1129], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 48 - 31: cat - cat || Loss: 0.4259457290172577\n",
      "tensor([1., 0.]) tensor([0.8873, 0.1127], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 48 - 32: cat - cat || Loss: 0.4257015585899353\n",
      "tensor([1., 0.]) tensor([0.8876, 0.1124], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 48 - 33: cat - cat || Loss: 0.42545604705810547\n",
      "tensor([1., 0.]) tensor([0.8878, 0.1122], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 48 - 34: cat - cat || Loss: 0.42520952224731445\n",
      "tensor([1., 0.]) tensor([0.8881, 0.1119], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 48 - 35: cat - cat || Loss: 0.42496201395988464\n",
      "tensor([1., 0.]) tensor([0.8883, 0.1117], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 48 - 36: cat - cat || Loss: 0.42471379041671753\n",
      "tensor([1., 0.]) tensor([0.8885, 0.1115], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 48 - 37: cat - cat || Loss: 0.4244649410247803\n",
      "tensor([1., 0.]) tensor([0.8888, 0.1112], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 48 - 38: cat - cat || Loss: 0.4242155849933624\n",
      "tensor([1., 0.]) tensor([0.8890, 0.1110], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 48 - 39: cat - cat || Loss: 0.42396581172943115\n",
      "tensor([1., 0.]) tensor([0.8893, 0.1107], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 48 - 40: cat - cat || Loss: 0.42371588945388794\n",
      "tensor([1., 0.]) tensor([0.8895, 0.1105], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 48 - 41: cat - cat || Loss: 0.4234656095504761\n",
      "tensor([1., 0.]) tensor([0.8898, 0.1102], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 48 - 42: cat - cat || Loss: 0.4232153296470642\n",
      "tensor([1., 0.]) tensor([0.8900, 0.1100], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 48 - 43: cat - cat || Loss: 0.42296484112739563\n",
      "tensor([1., 0.]) tensor([0.8903, 0.1097], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 48 - 44: cat - cat || Loss: 0.4227146506309509\n",
      "tensor([1., 0.]) tensor([0.8905, 0.1095], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 48 - 45: cat - cat || Loss: 0.4224643111228943\n",
      "tensor([1., 0.]) tensor([0.8908, 0.1092], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 48 - 46: cat - cat || Loss: 0.42221421003341675\n",
      "tensor([1., 0.]) tensor([0.8910, 0.1090], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 48 - 47: cat - cat || Loss: 0.42196428775787354\n",
      "tensor([1., 0.]) tensor([0.8913, 0.1087], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 48 - 48: cat - cat || Loss: 0.4217146039009094\n",
      "tensor([1., 0.]) tensor([0.8915, 0.1085], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 48 - 49: cat - cat || Loss: 0.4214652180671692\n",
      "tensor([1., 0.]) tensor([0.8918, 0.1082], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 48 - 50: cat - cat || Loss: 0.42121613025665283\n",
      "tensor([1., 0.]) tensor([0.8920, 0.1080], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 48 - 51: cat - cat || Loss: 0.42096734046936035\n",
      "tensor([1., 0.]) tensor([0.8923, 0.1077], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 48 - 52: cat - cat || Loss: 0.4207189083099365\n",
      "tensor([1., 0.]) tensor([0.8925, 0.1075], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 48 - 53: cat - cat || Loss: 0.4204708933830261\n",
      "tensor([1., 0.]) tensor([0.8928, 0.1072], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 48 - 54: cat - cat || Loss: 0.42022332549095154\n",
      "tensor([1., 0.]) tensor([0.8930, 0.1070], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 48 - 55: cat - cat || Loss: 0.4199761748313904\n",
      "tensor([1., 0.]) tensor([0.8933, 0.1067], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 48 - 56: cat - cat || Loss: 0.41972941160202026\n",
      "tensor([1., 0.]) tensor([0.8935, 0.1065], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 48 - 57: cat - cat || Loss: 0.41948309540748596\n",
      "tensor([1., 0.]) tensor([0.8938, 0.1062], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 48 - 58: cat - cat || Loss: 0.419237345457077\n",
      "tensor([1., 0.]) tensor([0.8940, 0.1060], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 48 - 59: cat - cat || Loss: 0.4189920425415039\n",
      "tensor([1., 0.]) tensor([0.8943, 0.1057], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 48 - 60: cat - cat || Loss: 0.41874727606773376\n",
      "tensor([1., 0.]) tensor([0.8945, 0.1055], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 48 - 61: cat - cat || Loss: 0.41850292682647705\n",
      "tensor([1., 0.]) tensor([0.8948, 0.1052], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 48 - 62: cat - cat || Loss: 0.4182591438293457\n",
      "tensor([1., 0.]) tensor([0.8950, 0.1050], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 48 - 63: cat - cat || Loss: 0.4180159568786621\n",
      "tensor([1., 0.]) tensor([0.8952, 0.1048], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 48 - 64: cat - cat || Loss: 0.4177732467651367\n",
      "tensor([1., 0.]) tensor([0.8955, 0.1045], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 48 - 65: cat - cat || Loss: 0.4175310432910919\n",
      "tensor([1., 0.]) tensor([0.8957, 0.1043], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 48 - 66: cat - cat || Loss: 0.4172894358634949\n",
      "tensor([1., 0.]) tensor([0.8960, 0.1040], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 48 - 67: cat - cat || Loss: 0.41704845428466797\n",
      "tensor([1., 0.]) tensor([0.8962, 0.1038], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 48 - 68: cat - cat || Loss: 0.4168078899383545\n",
      "tensor([1., 0.]) tensor([0.8965, 0.1035], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 48 - 69: cat - cat || Loss: 0.41656792163848877\n",
      "tensor([1., 0.]) tensor([0.8967, 0.1033], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 48 - 70: cat - cat || Loss: 0.4163285493850708\n",
      "tensor([1., 0.]) tensor([0.8969, 0.1031], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 48 - 71: cat - cat || Loss: 0.4160897433757782\n",
      "tensor([1., 0.]) tensor([0.8972, 0.1028], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 48 - 72: cat - cat || Loss: 0.4158514738082886\n",
      "tensor([1., 0.]) tensor([0.8974, 0.1026], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 48 - 73: cat - cat || Loss: 0.4156138002872467\n",
      "tensor([1., 0.]) tensor([0.8976, 0.1024], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 48 - 74: cat - cat || Loss: 0.4153766334056854\n",
      "tensor([1., 0.]) tensor([0.8979, 0.1021], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 48 - 75: cat - cat || Loss: 0.41514015197753906\n",
      "tensor([1., 0.]) tensor([0.8981, 0.1019], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 48 - 76: cat - cat || Loss: 0.4149042069911957\n",
      "tensor([1., 0.]) tensor([0.8984, 0.1016], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 48 - 77: cat - cat || Loss: 0.41466888785362244\n",
      "tensor([1., 0.]) tensor([0.8986, 0.1014], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 48 - 78: cat - cat || Loss: 0.4144339859485626\n",
      "tensor([1., 0.]) tensor([0.8988, 0.1012], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 48 - 79: cat - cat || Loss: 0.4141997694969177\n",
      "tensor([1., 0.]) tensor([0.8991, 0.1009], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 48 - 80: cat - cat || Loss: 0.4139661192893982\n",
      "tensor([1., 0.]) tensor([0.8993, 0.1007], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 48 - 81: cat - cat || Loss: 0.4137330651283264\n",
      "tensor([1., 0.]) tensor([0.8995, 0.1005], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 48 - 82: cat - cat || Loss: 0.41350051760673523\n",
      "tensor([1., 0.]) tensor([0.8998, 0.1002], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 48 - 83: cat - cat || Loss: 0.4132686257362366\n",
      "tensor([1., 0.]) tensor([0.9000, 0.1000], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 48 - 84: cat - cat || Loss: 0.4130373001098633\n",
      "tensor([1., 0.]) tensor([0.9002, 0.0998], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 48 - 85: cat - cat || Loss: 0.41280651092529297\n",
      "tensor([1., 0.]) tensor([0.9005, 0.0995], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 48 - 86: cat - cat || Loss: 0.4125763177871704\n",
      "tensor([1., 0.]) tensor([0.9007, 0.0993], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 48 - 87: cat - cat || Loss: 0.4123467803001404\n",
      "tensor([1., 0.]) tensor([0.9009, 0.0991], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 48 - 88: cat - cat || Loss: 0.41211771965026855\n",
      "tensor([1., 0.]) tensor([0.9011, 0.0989], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 48 - 89: cat - cat || Loss: 0.41188928484916687\n",
      "tensor([1., 0.]) tensor([0.9014, 0.0986], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 48 - 90: cat - cat || Loss: 0.41166144609451294\n",
      "tensor([1., 0.]) tensor([0.9016, 0.0984], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 48 - 91: cat - cat || Loss: 0.4114340543746948\n",
      "tensor([1., 0.]) tensor([0.9018, 0.0982], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 48 - 92: cat - cat || Loss: 0.411207377910614\n",
      "tensor([1., 0.]) tensor([0.9021, 0.0979], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 48 - 93: cat - cat || Loss: 0.4109811782836914\n",
      "tensor([1., 0.]) tensor([0.9023, 0.0977], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 48 - 94: cat - cat || Loss: 0.4107555150985718\n",
      "tensor([1., 0.]) tensor([0.9025, 0.0975], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 48 - 95: cat - cat || Loss: 0.4105305075645447\n",
      "tensor([1., 0.]) tensor([0.9027, 0.0973], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 48 - 96: cat - cat || Loss: 0.41030603647232056\n",
      "tensor([1., 0.]) tensor([0.9030, 0.0970], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 48 - 97: cat - cat || Loss: 0.4100821614265442\n",
      "tensor([1., 0.]) tensor([0.9032, 0.0968], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 48 - 98: cat - cat || Loss: 0.409858763217926\n",
      "tensor([1., 0.]) tensor([0.9034, 0.0966], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 48 - 99: cat - cat || Loss: 0.4096359610557556\n",
      "tensor([1., 0.]) tensor([0.9036, 0.0964], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 48 - 100: cat - cat || Loss: 0.40941375494003296\n",
      "tensor([1., 0.]) tensor([0.9038, 0.0962], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 48 - 101: cat - cat || Loss: 0.4091920852661133\n",
      "tensor([1., 0.]) tensor([0.9041, 0.0959], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 48 - 102: cat - cat || Loss: 0.40897101163864136\n",
      "tensor([1., 0.]) tensor([0.9043, 0.0957], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 48 - 103: cat - cat || Loss: 0.40875038504600525\n",
      "tensor([1., 0.]) tensor([0.9045, 0.0955], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 48 - 104: cat - cat || Loss: 0.4085303843021393\n",
      "tensor([1., 0.]) tensor([0.9047, 0.0953], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 48 - 105: cat - cat || Loss: 0.4083109498023987\n",
      "tensor([1., 0.]) tensor([0.9050, 0.0950], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 48 - 106: cat - cat || Loss: 0.40809208154678345\n",
      "tensor([1., 0.]) tensor([0.9052, 0.0948], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 48 - 107: cat - cat || Loss: 0.4078736901283264\n",
      "tensor([1., 0.]) tensor([0.9054, 0.0946], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 48 - 108: cat - cat || Loss: 0.40765589475631714\n",
      "tensor([1., 0.]) tensor([0.9056, 0.0944], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 48 - 109: cat - cat || Loss: 0.4074386656284332\n",
      "tensor([1., 0.]) tensor([0.9058, 0.0942], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 48 - 110: cat - cat || Loss: 0.4072219729423523\n",
      "tensor([1., 0.]) tensor([0.9060, 0.0940], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 48 - 111: cat - cat || Loss: 0.4070059061050415\n",
      "tensor([1., 0.]) tensor([0.9063, 0.0937], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 48 - 112: cat - cat || Loss: 0.40679022669792175\n",
      "tensor([1., 0.]) tensor([0.9065, 0.0935], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 48 - 113: cat - cat || Loss: 0.40657520294189453\n",
      "tensor([1., 0.]) tensor([0.9067, 0.0933], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 48 - 114: cat - cat || Loss: 0.4063606560230255\n",
      "tensor([1., 0.]) tensor([0.9069, 0.0931], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 48 - 115: cat - cat || Loss: 0.40614670515060425\n",
      "tensor([1., 0.]) tensor([0.9071, 0.0929], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 48 - 116: cat - cat || Loss: 0.4059332609176636\n",
      "tensor([1., 0.]) tensor([0.9073, 0.0927], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 48 - 117: cat - cat || Loss: 0.40572041273117065\n",
      "tensor([1., 0.]) tensor([0.9075, 0.0925], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 48 - 118: cat - cat || Loss: 0.40550798177719116\n",
      "tensor([1., 0.]) tensor([0.9078, 0.0922], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 48 - 119: cat - cat || Loss: 0.4052962362766266\n",
      "tensor([1., 0.]) tensor([0.9080, 0.0920], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 48 - 120: cat - cat || Loss: 0.40508490800857544\n",
      "tensor([1., 0.]) tensor([0.9082, 0.0918], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 48 - 121: cat - cat || Loss: 0.40487411618232727\n",
      "tensor([1., 0.]) tensor([0.9084, 0.0916], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 48 - 122: cat - cat || Loss: 0.40466392040252686\n",
      "tensor([1., 0.]) tensor([0.9086, 0.0914], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 48 - 123: cat - cat || Loss: 0.4044542610645294\n",
      "tensor([1., 0.]) tensor([0.9088, 0.0912], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 48 - 124: cat - cat || Loss: 0.4042451083660126\n",
      "tensor([1., 0.]) tensor([0.9090, 0.0910], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 48 - 125: cat - cat || Loss: 0.4040365219116211\n",
      "tensor([1., 0.]) tensor([0.9092, 0.0908], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 48 - 126: cat - cat || Loss: 0.4038284420967102\n",
      "tensor([1., 0.]) tensor([0.9094, 0.0906], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 48 - 127: cat - cat || Loss: 0.40362077951431274\n",
      "tensor([1., 0.]) tensor([0.9096, 0.0904], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 48 - 128: cat - cat || Loss: 0.4034138321876526\n",
      "tensor([1., 0.]) tensor([0.9098, 0.0902], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 48 - 129: cat - cat || Loss: 0.40320733189582825\n",
      "tensor([1., 0.]) tensor([0.9101, 0.0899], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 48 - 130: cat - cat || Loss: 0.4030013680458069\n",
      "tensor([1., 0.]) tensor([0.9103, 0.0897], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 48 - 131: cat - cat || Loss: 0.4027958810329437\n",
      "tensor([1., 0.]) tensor([0.9105, 0.0895], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 48 - 132: cat - cat || Loss: 0.40259096026420593\n",
      "tensor([1., 0.]) tensor([0.9107, 0.0893], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 48 - 133: cat - cat || Loss: 0.4023865759372711\n",
      "tensor([1., 0.]) tensor([0.9109, 0.0891], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 48 - 134: cat - cat || Loss: 0.4021826684474945\n",
      "tensor([1., 0.]) tensor([0.9111, 0.0889], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 48 - 135: cat - cat || Loss: 0.4019792675971985\n",
      "tensor([1., 0.]) tensor([0.9113, 0.0887], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 48 - 136: cat - cat || Loss: 0.40177637338638306\n",
      "tensor([1., 0.]) tensor([0.9115, 0.0885], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 48 - 137: cat - cat || Loss: 0.401574045419693\n",
      "tensor([1., 0.]) tensor([0.9117, 0.0883], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 48 - 138: cat - cat || Loss: 0.4013722538948059\n",
      "tensor([1., 0.]) tensor([0.9119, 0.0881], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 48 - 139: cat - cat || Loss: 0.40117084980010986\n",
      "tensor([1., 0.]) tensor([0.9121, 0.0879], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 48 - 140: cat - cat || Loss: 0.4009700417518616\n",
      "tensor([1., 0.]) tensor([0.9123, 0.0877], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 48 - 141: cat - cat || Loss: 0.40076977014541626\n",
      "tensor([1., 0.]) tensor([0.9125, 0.0875], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 48 - 142: cat - cat || Loss: 0.4005699157714844\n",
      "tensor([1., 0.]) tensor([0.9127, 0.0873], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 48 - 143: cat - cat || Loss: 0.40037065744400024\n",
      "tensor([1., 0.]) tensor([0.9129, 0.0871], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 48 - 144: cat - cat || Loss: 0.4001719057559967\n",
      "tensor([1., 0.]) tensor([0.9131, 0.0869], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 48 - 145: cat - cat || Loss: 0.399973601102829\n",
      "tensor([1., 0.]) tensor([0.9133, 0.0867], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 48 - 146: cat - cat || Loss: 0.3997758626937866\n",
      "tensor([1., 0.]) tensor([0.9135, 0.0865], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 48 - 147: cat - cat || Loss: 0.39957869052886963\n",
      "tensor([1., 0.]) tensor([0.9137, 0.0863], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 48 - 148: cat - cat || Loss: 0.3993818163871765\n",
      "tensor([1., 0.]) tensor([0.9139, 0.0861], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 48 - 149: cat - cat || Loss: 0.3991855978965759\n",
      "tensor([1., 0.]) tensor([0.9141, 0.0859], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 48 - 150: cat - cat || Loss: 0.39898979663848877\n",
      "tensor([1., 0.]) tensor([0.9143, 0.0857], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 48 - 151: cat - cat || Loss: 0.398794561624527\n",
      "tensor([1., 0.]) tensor([0.9145, 0.0855], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 48 - 152: cat - cat || Loss: 0.398599773645401\n",
      "tensor([1., 0.]) tensor([0.9147, 0.0853], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 48 - 153: cat - cat || Loss: 0.3984054923057556\n",
      "tensor([1., 0.]) tensor([0.9149, 0.0851], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 48 - 154: cat - cat || Loss: 0.3982117176055908\n",
      "tensor([1., 0.]) tensor([0.9150, 0.0850], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 48 - 155: cat - cat || Loss: 0.39801841974258423\n",
      "tensor([1., 0.]) tensor([0.9152, 0.0848], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 48 - 156: cat - cat || Loss: 0.3978256583213806\n",
      "tensor([1., 0.]) tensor([0.9154, 0.0846], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 48 - 157: cat - cat || Loss: 0.39763343334198\n",
      "tensor([1., 0.]) tensor([0.9156, 0.0844], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 48 - 158: cat - cat || Loss: 0.3974415361881256\n",
      "tensor([1., 0.]) tensor([0.9158, 0.0842], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 48 - 159: cat - cat || Loss: 0.3972501754760742\n",
      "tensor([1., 0.]) tensor([0.9160, 0.0840], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 48 - 160: cat - cat || Loss: 0.3970593512058258\n",
      "tensor([1., 0.]) tensor([0.9162, 0.0838], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 48 - 161: cat - cat || Loss: 0.396869033575058\n",
      "tensor([1., 0.]) tensor([0.9164, 0.0836], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 48 - 162: cat - cat || Loss: 0.396679162979126\n",
      "tensor([1., 0.]) tensor([0.9166, 0.0834], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 48 - 163: cat - cat || Loss: 0.3964897394180298\n",
      "tensor([1., 0.]) tensor([0.9168, 0.0832], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 48 - 164: cat - cat || Loss: 0.3963008522987366\n",
      "tensor([1., 0.]) tensor([0.9170, 0.0830], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 48 - 165: cat - cat || Loss: 0.3961124122142792\n",
      "tensor([1., 0.]) tensor([0.9171, 0.0829], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 48 - 166: cat - cat || Loss: 0.39592444896698\n",
      "tensor([1., 0.]) tensor([0.9173, 0.0827], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 48 - 167: cat - cat || Loss: 0.3957369327545166\n",
      "tensor([1., 0.]) tensor([0.9175, 0.0825], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 48 - 168: cat - cat || Loss: 0.3955499529838562\n",
      "tensor([1., 0.]) tensor([0.9177, 0.0823], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 48 - 169: cat - cat || Loss: 0.39536333084106445\n",
      "tensor([1., 0.]) tensor([0.9179, 0.0821], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 48 - 170: cat - cat || Loss: 0.39517730474472046\n",
      "tensor([1., 0.]) tensor([0.9181, 0.0819], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 48 - 171: cat - cat || Loss: 0.3949917256832123\n",
      "tensor([1., 0.]) tensor([0.9183, 0.0817], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 48 - 172: cat - cat || Loss: 0.3948066830635071\n",
      "tensor([1., 0.]) tensor([0.9185, 0.0815], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 48 - 173: cat - cat || Loss: 0.3946220278739929\n",
      "tensor([1., 0.]) tensor([0.9186, 0.0814], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 48 - 174: cat - cat || Loss: 0.39443784952163696\n",
      "tensor([1., 0.]) tensor([0.9188, 0.0812], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 48 - 175: cat - cat || Loss: 0.3942541480064392\n",
      "tensor([1., 0.]) tensor([0.9190, 0.0810], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 48 - 176: cat - cat || Loss: 0.3940708637237549\n",
      "tensor([1., 0.]) tensor([0.9192, 0.0808], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 48 - 177: cat - cat || Loss: 0.39388811588287354\n",
      "tensor([1., 0.]) tensor([0.9194, 0.0806], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 48 - 178: cat - cat || Loss: 0.3937057554721832\n",
      "tensor([1., 0.]) tensor([0.9196, 0.0804], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 48 - 179: cat - cat || Loss: 0.3935238718986511\n",
      "tensor([1., 0.]) tensor([0.9197, 0.0803], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 48 - 180: cat - cat || Loss: 0.39334240555763245\n",
      "tensor([1., 0.]) tensor([0.9199, 0.0801], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 48 - 181: cat - cat || Loss: 0.39316147565841675\n",
      "tensor([1., 0.]) tensor([0.9201, 0.0799], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 48 - 182: cat - cat || Loss: 0.3929809629917145\n",
      "tensor([1., 0.]) tensor([0.9203, 0.0797], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 48 - 183: cat - cat || Loss: 0.3928009569644928\n",
      "tensor([1., 0.]) tensor([0.9205, 0.0795], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 48 - 184: cat - cat || Loss: 0.39262130856513977\n",
      "tensor([1., 0.]) tensor([0.9206, 0.0794], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 48 - 185: cat - cat || Loss: 0.3924421966075897\n",
      "tensor([1., 0.]) tensor([0.9208, 0.0792], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 48 - 186: cat - cat || Loss: 0.39226341247558594\n",
      "tensor([1., 0.]) tensor([0.9210, 0.0790], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 48 - 187: cat - cat || Loss: 0.3920851945877075\n",
      "tensor([1., 0.]) tensor([0.9212, 0.0788], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 48 - 188: cat - cat || Loss: 0.39190739393234253\n",
      "tensor([1., 0.]) tensor([0.9214, 0.0786], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 48 - 189: cat - cat || Loss: 0.3917299211025238\n",
      "tensor([1., 0.]) tensor([0.9215, 0.0785], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 48 - 190: dog - cat || Loss: 1.2349704504013062\n",
      "tensor([0., 1.]) tensor([0.9217, 0.0783], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 48 - 191: dog - cat || Loss: 1.235112190246582\n",
      "tensor([0., 1.]) tensor([0.9219, 0.0781], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 48 - 192: dog - cat || Loss: 1.2352218627929688\n",
      "tensor([0., 1.]) tensor([0.9220, 0.0780], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 48 - 193: dog - cat || Loss: 1.2353034019470215\n",
      "tensor([0., 1.]) tensor([0.9220, 0.0780], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 48 - 194: dog - cat || Loss: 1.2353591918945312\n",
      "tensor([0., 1.]) tensor([0.9221, 0.0779], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 48 - 195: dog - cat || Loss: 1.2353920936584473\n",
      "tensor([0., 1.]) tensor([0.9221, 0.0779], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 48 - 196: dog - cat || Loss: 1.235404133796692\n",
      "tensor([0., 1.]) tensor([0.9221, 0.0779], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 48 - 197: dog - cat || Loss: 1.2353976964950562\n",
      "tensor([0., 1.]) tensor([0.9221, 0.0779], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 48 - 198: dog - cat || Loss: 1.2353745698928833\n",
      "tensor([0., 1.]) tensor([0.9221, 0.0779], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 48 - 199: dog - cat || Loss: 1.2353363037109375\n",
      "tensor([0., 1.]) tensor([0.9221, 0.0779], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 48 - 200: dog - cat || Loss: 1.235284447669983\n",
      "tensor([0., 1.]) tensor([0.9220, 0.0780], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 48 - 201: dog - cat || Loss: 1.2352203130722046\n",
      "tensor([0., 1.]) tensor([0.9220, 0.0780], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 48 - 202: dog - cat || Loss: 1.2351452112197876\n",
      "tensor([0., 1.]) tensor([0.9219, 0.0781], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 48 - 203: dog - cat || Loss: 1.2350600957870483\n",
      "tensor([0., 1.]) tensor([0.9218, 0.0782], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 48 - 204: dog - cat || Loss: 1.2349661588668823\n",
      "tensor([0., 1.]) tensor([0.9217, 0.0783], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 48 - 205: dog - cat || Loss: 1.2348638772964478\n",
      "tensor([0., 1.]) tensor([0.9216, 0.0784], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 48 - 206: dog - cat || Loss: 1.2347543239593506\n",
      "tensor([0., 1.]) tensor([0.9215, 0.0785], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 48 - 207: dog - cat || Loss: 1.2346383333206177\n",
      "tensor([0., 1.]) tensor([0.9214, 0.0786], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 48 - 208: dog - cat || Loss: 1.2345160245895386\n",
      "tensor([0., 1.]) tensor([0.9213, 0.0787], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 48 - 209: dog - cat || Loss: 1.2343884706497192\n",
      "tensor([0., 1.]) tensor([0.9211, 0.0789], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 48 - 210: dog - cat || Loss: 1.2342559099197388\n",
      "tensor([0., 1.]) tensor([0.9210, 0.0790], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 48 - 211: dog - cat || Loss: 1.2341188192367554\n",
      "tensor([0., 1.]) tensor([0.9209, 0.0791], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 48 - 212: dog - cat || Loss: 1.2339775562286377\n",
      "tensor([0., 1.]) tensor([0.9207, 0.0793], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 48 - 213: dog - cat || Loss: 1.2338327169418335\n",
      "tensor([0., 1.]) tensor([0.9206, 0.0794], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 48 - 214: dog - cat || Loss: 1.2336841821670532\n",
      "tensor([0., 1.]) tensor([0.9204, 0.0796], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 48 - 215: dog - cat || Loss: 1.2335329055786133\n",
      "tensor([0., 1.]) tensor([0.9203, 0.0797], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 48 - 216: dog - cat || Loss: 1.2333787679672241\n",
      "tensor([0., 1.]) tensor([0.9201, 0.0799], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 48 - 217: dog - cat || Loss: 1.2332221269607544\n",
      "tensor([0., 1.]) tensor([0.9200, 0.0800], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 48 - 218: dog - cat || Loss: 1.2330628633499146\n",
      "tensor([0., 1.]) tensor([0.9198, 0.0802], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 48 - 219: dog - cat || Loss: 1.2329014539718628\n",
      "tensor([0., 1.]) tensor([0.9196, 0.0804], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 48 - 220: dog - cat || Loss: 1.2327380180358887\n",
      "tensor([0., 1.]) tensor([0.9195, 0.0805], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 48 - 221: dog - cat || Loss: 1.2325730323791504\n",
      "tensor([0., 1.]) tensor([0.9193, 0.0807], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 48 - 222: dog - cat || Loss: 1.2324060201644897\n",
      "tensor([0., 1.]) tensor([0.9191, 0.0809], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 48 - 223: dog - cat || Loss: 1.2322375774383545\n",
      "tensor([0., 1.]) tensor([0.9190, 0.0810], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 48 - 224: dog - cat || Loss: 1.2320674657821655\n",
      "tensor([0., 1.]) tensor([0.9188, 0.0812], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 48 - 225: dog - cat || Loss: 1.2318962812423706\n",
      "tensor([0., 1.]) tensor([0.9186, 0.0814], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 48 - 226: dog - cat || Loss: 1.2317237854003906\n",
      "tensor([0., 1.]) tensor([0.9185, 0.0815], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 48 - 227: dog - cat || Loss: 1.2315499782562256\n",
      "tensor([0., 1.]) tensor([0.9183, 0.0817], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 48 - 228: dog - cat || Loss: 1.231374979019165\n",
      "tensor([0., 1.]) tensor([0.9181, 0.0819], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 48 - 229: dog - cat || Loss: 1.231199026107788\n",
      "tensor([0., 1.]) tensor([0.9179, 0.0821], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 48 - 230: dog - cat || Loss: 1.2310220003128052\n",
      "tensor([0., 1.]) tensor([0.9178, 0.0822], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 48 - 231: dog - cat || Loss: 1.2308441400527954\n",
      "tensor([0., 1.]) tensor([0.9176, 0.0824], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 48 - 232: dog - cat || Loss: 1.2306653261184692\n",
      "tensor([0., 1.]) tensor([0.9174, 0.0826], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 48 - 233: dog - cat || Loss: 1.2304857969284058\n",
      "tensor([0., 1.]) tensor([0.9172, 0.0828], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 48 - 234: dog - cat || Loss: 1.2303054332733154\n",
      "tensor([0., 1.]) tensor([0.9170, 0.0830], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 48 - 235: dog - cat || Loss: 1.2301241159439087\n",
      "tensor([0., 1.]) tensor([0.9169, 0.0831], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 48 - 236: dog - cat || Loss: 1.2299420833587646\n",
      "tensor([0., 1.]) tensor([0.9167, 0.0833], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 48 - 237: dog - cat || Loss: 1.2297594547271729\n",
      "tensor([0., 1.]) tensor([0.9165, 0.0835], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 48 - 238: dog - cat || Loss: 1.2295758724212646\n",
      "tensor([0., 1.]) tensor([0.9163, 0.0837], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 48 - 239: dog - cat || Loss: 1.2293919324874878\n",
      "tensor([0., 1.]) tensor([0.9161, 0.0839], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 48 - 240: dog - cat || Loss: 1.2292072772979736\n",
      "tensor([0., 1.]) tensor([0.9159, 0.0841], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 48 - 241: dog - cat || Loss: 1.2290217876434326\n",
      "tensor([0., 1.]) tensor([0.9158, 0.0842], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 48 - 242: dog - cat || Loss: 1.228835940361023\n",
      "tensor([0., 1.]) tensor([0.9156, 0.0844], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 48 - 243: dog - cat || Loss: 1.2286494970321655\n",
      "tensor([0., 1.]) tensor([0.9154, 0.0846], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 48 - 244: dog - cat || Loss: 1.2284623384475708\n",
      "tensor([0., 1.]) tensor([0.9152, 0.0848], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 48 - 245: dog - cat || Loss: 1.2282748222351074\n",
      "tensor([0., 1.]) tensor([0.9150, 0.0850], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 48 - 246: dog - cat || Loss: 1.2280863523483276\n",
      "tensor([0., 1.]) tensor([0.9148, 0.0852], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 48 - 247: dog - cat || Loss: 1.2278975248336792\n",
      "tensor([0., 1.]) tensor([0.9146, 0.0854], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 48 - 248: dog - cat || Loss: 1.2277082204818726\n",
      "tensor([0., 1.]) tensor([0.9144, 0.0856], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 48 - 249: dog - cat || Loss: 1.2275183200836182\n",
      "tensor([0., 1.]) tensor([0.9143, 0.0857], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 48 - 250: dog - cat || Loss: 1.227327823638916\n",
      "tensor([0., 1.]) tensor([0.9141, 0.0859], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 48 - 251: dog - cat || Loss: 1.2271368503570557\n",
      "tensor([0., 1.]) tensor([0.9139, 0.0861], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 48 - 252: dog - cat || Loss: 1.2269452810287476\n",
      "tensor([0., 1.]) tensor([0.9137, 0.0863], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 48 - 253: dog - cat || Loss: 1.2267533540725708\n",
      "tensor([0., 1.]) tensor([0.9135, 0.0865], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 48 - 254: dog - cat || Loss: 1.2265607118606567\n",
      "tensor([0., 1.]) tensor([0.9133, 0.0867], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 48 - 255: dog - cat || Loss: 1.226367712020874\n",
      "tensor([0., 1.]) tensor([0.9131, 0.0869], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 48 - 256: dog - cat || Loss: 1.226174235343933\n",
      "tensor([0., 1.]) tensor([0.9129, 0.0871], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 48 - 257: dog - cat || Loss: 1.2259800434112549\n",
      "tensor([0., 1.]) tensor([0.9127, 0.0873], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 48 - 258: dog - cat || Loss: 1.225785493850708\n",
      "tensor([0., 1.]) tensor([0.9125, 0.0875], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 48 - 259: dog - cat || Loss: 1.225590467453003\n",
      "tensor([0., 1.]) tensor([0.9123, 0.0877], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 48 - 260: dog - cat || Loss: 1.2253947257995605\n",
      "tensor([0., 1.]) tensor([0.9121, 0.0879], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 48 - 261: dog - cat || Loss: 1.2251986265182495\n",
      "tensor([0., 1.]) tensor([0.9119, 0.0881], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 48 - 262: dog - cat || Loss: 1.2250021696090698\n",
      "tensor([0., 1.]) tensor([0.9117, 0.0883], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 48 - 263: dog - cat || Loss: 1.2248049974441528\n",
      "tensor([0., 1.]) tensor([0.9115, 0.0885], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 48 - 264: dog - cat || Loss: 1.2246073484420776\n",
      "tensor([0., 1.]) tensor([0.9113, 0.0887], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 48 - 265: dog - cat || Loss: 1.2244092226028442\n",
      "tensor([0., 1.]) tensor([0.9111, 0.0889], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 48 - 266: dog - cat || Loss: 1.2242107391357422\n",
      "tensor([0., 1.]) tensor([0.9109, 0.0891], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 48 - 267: dog - cat || Loss: 1.2240116596221924\n",
      "tensor([0., 1.]) tensor([0.9108, 0.0892], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 48 - 268: dog - cat || Loss: 1.2238121032714844\n",
      "tensor([0., 1.]) tensor([0.9106, 0.0894], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 48 - 269: dog - cat || Loss: 1.223611831665039\n",
      "tensor([0., 1.]) tensor([0.9104, 0.0896], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 48 - 270: dog - cat || Loss: 1.223411202430725\n",
      "tensor([0., 1.]) tensor([0.9101, 0.0899], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 48 - 271: dog - cat || Loss: 1.2232102155685425\n",
      "tensor([0., 1.]) tensor([0.9099, 0.0901], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 48 - 272: dog - cat || Loss: 1.2230085134506226\n",
      "tensor([0., 1.]) tensor([0.9097, 0.0903], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 48 - 273: dog - cat || Loss: 1.2228063344955444\n",
      "tensor([0., 1.]) tensor([0.9095, 0.0905], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 48 - 274: dog - cat || Loss: 1.2226037979125977\n",
      "tensor([0., 1.]) tensor([0.9093, 0.0907], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 48 - 275: dog - cat || Loss: 1.222400426864624\n",
      "tensor([0., 1.]) tensor([0.9091, 0.0909], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 48 - 276: dog - cat || Loss: 1.2221968173980713\n",
      "tensor([0., 1.]) tensor([0.9089, 0.0911], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 48 - 277: dog - cat || Loss: 1.22199285030365\n",
      "tensor([0., 1.]) tensor([0.9087, 0.0913], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 48 - 278: dog - cat || Loss: 1.2217881679534912\n",
      "tensor([0., 1.]) tensor([0.9085, 0.0915], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 48 - 279: dog - cat || Loss: 1.2215830087661743\n",
      "tensor([0., 1.]) tensor([0.9083, 0.0917], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 48 - 280: dog - cat || Loss: 1.2213772535324097\n",
      "tensor([0., 1.]) tensor([0.9081, 0.0919], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 48 - 281: dog - cat || Loss: 1.2211711406707764\n",
      "tensor([0., 1.]) tensor([0.9079, 0.0921], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 48 - 282: dog - cat || Loss: 1.2209644317626953\n",
      "tensor([0., 1.]) tensor([0.9077, 0.0923], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 48 - 283: dog - cat || Loss: 1.220757246017456\n",
      "tensor([0., 1.]) tensor([0.9075, 0.0925], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 48 - 284: dog - cat || Loss: 1.2205495834350586\n",
      "tensor([0., 1.]) tensor([0.9073, 0.0927], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 48 - 285: dog - cat || Loss: 1.2203413248062134\n",
      "tensor([0., 1.]) tensor([0.9071, 0.0929], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 48 - 286: dog - cat || Loss: 1.22013258934021\n",
      "tensor([0., 1.]) tensor([0.9069, 0.0931], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 48 - 287: dog - cat || Loss: 1.2199232578277588\n",
      "tensor([0., 1.]) tensor([0.9067, 0.0933], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 48 - 288: dog - cat || Loss: 1.219713568687439\n",
      "tensor([0., 1.]) tensor([0.9065, 0.0935], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 48 - 289: dog - cat || Loss: 1.2195031642913818\n",
      "tensor([0., 1.]) tensor([0.9062, 0.0938], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 48 - 290: dog - cat || Loss: 1.2192926406860352\n",
      "tensor([0., 1.]) tensor([0.9060, 0.0940], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 48 - 291: dog - cat || Loss: 1.2190812826156616\n",
      "tensor([0., 1.]) tensor([0.9058, 0.0942], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 48 - 292: dog - cat || Loss: 1.2188693284988403\n",
      "tensor([0., 1.]) tensor([0.9056, 0.0944], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 48 - 293: dog - cat || Loss: 1.2186570167541504\n",
      "tensor([0., 1.]) tensor([0.9054, 0.0946], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 48 - 294: dog - cat || Loss: 1.2184441089630127\n",
      "tensor([0., 1.]) tensor([0.9052, 0.0948], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 48 - 295: dog - cat || Loss: 1.2182308435440063\n",
      "tensor([0., 1.]) tensor([0.9050, 0.0950], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 48 - 296: dog - cat || Loss: 1.2180168628692627\n",
      "tensor([0., 1.]) tensor([0.9048, 0.0952], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 48 - 297: dog - cat || Loss: 1.2178025245666504\n",
      "tensor([0., 1.]) tensor([0.9045, 0.0955], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 48 - 298: dog - cat || Loss: 1.2175874710083008\n",
      "tensor([0., 1.]) tensor([0.9043, 0.0957], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 48 - 299: dog - cat || Loss: 1.217371940612793\n",
      "tensor([0., 1.]) tensor([0.9041, 0.0959], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 48 - 300: dog - cat || Loss: 1.217155933380127\n",
      "tensor([0., 1.]) tensor([0.9039, 0.0961], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 48 - 301: dog - cat || Loss: 1.2169392108917236\n",
      "tensor([0., 1.]) tensor([0.9037, 0.0963], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 48 - 302: dog - cat || Loss: 1.2167224884033203\n",
      "tensor([0., 1.]) tensor([0.9035, 0.0965], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 48 - 303: dog - cat || Loss: 1.2165048122406006\n",
      "tensor([0., 1.]) tensor([0.9032, 0.0968], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 48 - 304: dog - cat || Loss: 1.2162867784500122\n",
      "tensor([0., 1.]) tensor([0.9030, 0.0970], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 48 - 305: dog - cat || Loss: 1.216067910194397\n",
      "tensor([0., 1.]) tensor([0.9028, 0.0972], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 48 - 306: dog - cat || Loss: 1.2158488035202026\n",
      "tensor([0., 1.]) tensor([0.9026, 0.0974], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 48 - 307: dog - cat || Loss: 1.2156291007995605\n",
      "tensor([0., 1.]) tensor([0.9024, 0.0976], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 48 - 308: dog - cat || Loss: 1.2154088020324707\n",
      "tensor([0., 1.]) tensor([0.9021, 0.0979], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 48 - 309: dog - cat || Loss: 1.2151880264282227\n",
      "tensor([0., 1.]) tensor([0.9019, 0.0981], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 48 - 310: dog - cat || Loss: 1.2149666547775269\n",
      "tensor([0., 1.]) tensor([0.9017, 0.0983], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 48 - 311: dog - cat || Loss: 1.2147448062896729\n",
      "tensor([0., 1.]) tensor([0.9015, 0.0985], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 48 - 312: dog - cat || Loss: 1.214522361755371\n",
      "tensor([0., 1.]) tensor([0.9013, 0.0987], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 48 - 313: dog - cat || Loss: 1.2142994403839111\n",
      "tensor([0., 1.]) tensor([0.9010, 0.0990], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 48 - 314: dog - cat || Loss: 1.2140759229660034\n",
      "tensor([0., 1.]) tensor([0.9008, 0.0992], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 48 - 315: dog - cat || Loss: 1.2138519287109375\n",
      "tensor([0., 1.]) tensor([0.9006, 0.0994], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 48 - 316: dog - cat || Loss: 1.2136272192001343\n",
      "tensor([0., 1.]) tensor([0.9004, 0.0996], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 48 - 317: dog - cat || Loss: 1.2134021520614624\n",
      "tensor([0., 1.]) tensor([0.9001, 0.0999], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 48 - 318: dog - cat || Loss: 1.2131762504577637\n",
      "tensor([0., 1.]) tensor([0.8999, 0.1001], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 48 - 319: dog - cat || Loss: 1.2129501104354858\n",
      "tensor([0., 1.]) tensor([0.8997, 0.1003], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 48 - 320: dog - cat || Loss: 1.2127233743667603\n",
      "tensor([0., 1.]) tensor([0.8995, 0.1005], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 48 - 321: dog - cat || Loss: 1.2124959230422974\n",
      "tensor([0., 1.]) tensor([0.8992, 0.1008], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 48 - 322: dog - cat || Loss: 1.2122681140899658\n",
      "tensor([0., 1.]) tensor([0.8990, 0.1010], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 48 - 323: dog - cat || Loss: 1.2120394706726074\n",
      "tensor([0., 1.]) tensor([0.8988, 0.1012], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 48 - 324: dog - cat || Loss: 1.2118104696273804\n",
      "tensor([0., 1.]) tensor([0.8985, 0.1015], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 48 - 325: dog - cat || Loss: 1.2115808725357056\n",
      "tensor([0., 1.]) tensor([0.8983, 0.1017], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 48 - 326: dog - cat || Loss: 1.2113507986068726\n",
      "tensor([0., 1.]) tensor([0.8981, 0.1019], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 48 - 327: dog - cat || Loss: 1.2111201286315918\n",
      "tensor([0., 1.]) tensor([0.8979, 0.1021], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 48 - 328: dog - cat || Loss: 1.2108887434005737\n",
      "tensor([0., 1.]) tensor([0.8976, 0.1024], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 48 - 329: dog - cat || Loss: 1.210657000541687\n",
      "tensor([0., 1.]) tensor([0.8974, 0.1026], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 48 - 330: dog - cat || Loss: 1.210424542427063\n",
      "tensor([0., 1.]) tensor([0.8972, 0.1028], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 48 - 331: dog - cat || Loss: 1.2101914882659912\n",
      "tensor([0., 1.]) tensor([0.8969, 0.1031], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 48 - 332: dog - cat || Loss: 1.2099580764770508\n",
      "tensor([0., 1.]) tensor([0.8967, 0.1033], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 48 - 333: dog - cat || Loss: 1.2097238302230835\n",
      "tensor([0., 1.]) tensor([0.8965, 0.1035], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 48 - 334: dog - cat || Loss: 1.2094892263412476\n",
      "tensor([0., 1.]) tensor([0.8962, 0.1038], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 48 - 335: dog - cat || Loss: 1.2092539072036743\n",
      "tensor([0., 1.]) tensor([0.8960, 0.1040], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 48 - 336: dog - cat || Loss: 1.2090182304382324\n",
      "tensor([0., 1.]) tensor([0.8958, 0.1042], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 48 - 337: dog - cat || Loss: 1.2087818384170532\n",
      "tensor([0., 1.]) tensor([0.8955, 0.1045], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 48 - 338: dog - cat || Loss: 1.2085448503494263\n",
      "tensor([0., 1.]) tensor([0.8953, 0.1047], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 48 - 339: dog - cat || Loss: 1.2083073854446411\n",
      "tensor([0., 1.]) tensor([0.8950, 0.1050], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 48 - 340: dog - cat || Loss: 1.2080692052841187\n",
      "tensor([0., 1.]) tensor([0.8948, 0.1052], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 48 - 341: dog - cat || Loss: 1.207830548286438\n",
      "tensor([0., 1.]) tensor([0.8946, 0.1054], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 48 - 342: dog - cat || Loss: 1.20759117603302\n",
      "tensor([0., 1.]) tensor([0.8943, 0.1057], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 48 - 343: dog - cat || Loss: 1.2073513269424438\n",
      "tensor([0., 1.]) tensor([0.8941, 0.1059], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 48 - 344: dog - cat || Loss: 1.20711088180542\n",
      "tensor([0., 1.]) tensor([0.8938, 0.1062], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 48 - 345: dog - cat || Loss: 1.2068698406219482\n",
      "tensor([0., 1.]) tensor([0.8936, 0.1064], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 48 - 346: dog - cat || Loss: 1.2066282033920288\n",
      "tensor([0., 1.]) tensor([0.8934, 0.1066], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 48 - 347: dog - cat || Loss: 1.2063860893249512\n",
      "tensor([0., 1.]) tensor([0.8931, 0.1069], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 48 - 348: dog - cat || Loss: 1.2061432600021362\n",
      "tensor([0., 1.]) tensor([0.8929, 0.1071], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 48 - 349: dog - cat || Loss: 1.2058998346328735\n",
      "tensor([0., 1.]) tensor([0.8926, 0.1074], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 48 - 350: dog - cat || Loss: 1.2056560516357422\n",
      "tensor([0., 1.]) tensor([0.8924, 0.1076], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 48 - 351: dog - cat || Loss: 1.205411434173584\n",
      "tensor([0., 1.]) tensor([0.8921, 0.1079], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 48 - 352: dog - cat || Loss: 1.205166220664978\n",
      "tensor([0., 1.]) tensor([0.8919, 0.1081], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 48 - 353: dog - cat || Loss: 1.2049204111099243\n",
      "tensor([0., 1.]) tensor([0.8917, 0.1083], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 48 - 354: dog - cat || Loss: 1.2046741247177124\n",
      "tensor([0., 1.]) tensor([0.8914, 0.1086], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 48 - 355: dog - cat || Loss: 1.2044271230697632\n",
      "tensor([0., 1.]) tensor([0.8912, 0.1088], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 48 - 356: dog - cat || Loss: 1.2041796445846558\n",
      "tensor([0., 1.]) tensor([0.8909, 0.1091], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 48 - 357: dog - cat || Loss: 1.203931450843811\n",
      "tensor([0., 1.]) tensor([0.8907, 0.1093], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 48 - 358: dog - cat || Loss: 1.203682780265808\n",
      "tensor([0., 1.]) tensor([0.8904, 0.1096], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 48 - 359: dog - cat || Loss: 1.2034333944320679\n",
      "tensor([0., 1.]) tensor([0.8902, 0.1098], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 48 - 360: dog - cat || Loss: 1.2031834125518799\n",
      "tensor([0., 1.]) tensor([0.8899, 0.1101], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 48 - 361: dog - cat || Loss: 1.2029327154159546\n",
      "tensor([0., 1.]) tensor([0.8897, 0.1103], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 48 - 362: dog - cat || Loss: 1.2026816606521606\n",
      "tensor([0., 1.]) tensor([0.8894, 0.1106], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 48 - 363: dog - cat || Loss: 1.2024298906326294\n",
      "tensor([0., 1.]) tensor([0.8892, 0.1108], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 48 - 364: dog - cat || Loss: 1.2021774053573608\n",
      "tensor([0., 1.]) tensor([0.8889, 0.1111], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 48 - 365: dog - cat || Loss: 1.2019246816635132\n",
      "tensor([0., 1.]) tensor([0.8887, 0.1113], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 48 - 366: dog - cat || Loss: 1.2016708850860596\n",
      "tensor([0., 1.]) tensor([0.8884, 0.1116], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 48 - 367: dog - cat || Loss: 1.2014167308807373\n",
      "tensor([0., 1.]) tensor([0.8882, 0.1118], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 48 - 368: dog - cat || Loss: 1.2011619806289673\n",
      "tensor([0., 1.]) tensor([0.8879, 0.1121], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 48 - 369: dog - cat || Loss: 1.20090651512146\n",
      "tensor([0., 1.]) tensor([0.8876, 0.1124], grad_fn=<SoftmaxBackward0>)\n",
      "=====epoch:49=====\n",
      "Epoch 49 - 0: cat - cat || Loss: 0.4258728623390198\n",
      "tensor([1., 0.]) tensor([0.8874, 0.1126], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 49 - 1: cat - cat || Loss: 0.42607760429382324\n",
      "tensor([1., 0.]) tensor([0.8872, 0.1128], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 49 - 2: cat - cat || Loss: 0.42623603343963623\n",
      "tensor([1., 0.]) tensor([0.8870, 0.1130], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 49 - 3: cat - cat || Loss: 0.42635267972946167\n",
      "tensor([1., 0.]) tensor([0.8869, 0.1131], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 49 - 4: cat - cat || Loss: 0.42643171548843384\n",
      "tensor([1., 0.]) tensor([0.8868, 0.1132], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 49 - 5: cat - cat || Loss: 0.42647674679756165\n",
      "tensor([1., 0.]) tensor([0.8868, 0.1132], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 49 - 6: cat - cat || Loss: 0.4264911711215973\n",
      "tensor([1., 0.]) tensor([0.8868, 0.1132], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 49 - 7: cat - cat || Loss: 0.4264780580997467\n",
      "tensor([1., 0.]) tensor([0.8868, 0.1132], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 49 - 8: cat - cat || Loss: 0.4264402687549591\n",
      "tensor([1., 0.]) tensor([0.8868, 0.1132], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 49 - 9: cat - cat || Loss: 0.4263801574707031\n",
      "tensor([1., 0.]) tensor([0.8869, 0.1131], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 49 - 10: cat - cat || Loss: 0.4262999892234802\n",
      "tensor([1., 0.]) tensor([0.8870, 0.1130], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 49 - 11: cat - cat || Loss: 0.4262019395828247\n",
      "tensor([1., 0.]) tensor([0.8871, 0.1129], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 49 - 12: cat - cat || Loss: 0.42608773708343506\n",
      "tensor([1., 0.]) tensor([0.8872, 0.1128], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 49 - 13: cat - cat || Loss: 0.4259589910507202\n",
      "tensor([1., 0.]) tensor([0.8873, 0.1127], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 49 - 14: cat - cat || Loss: 0.42581722140312195\n",
      "tensor([1., 0.]) tensor([0.8874, 0.1126], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 49 - 15: cat - cat || Loss: 0.4256638288497925\n",
      "tensor([1., 0.]) tensor([0.8876, 0.1124], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 49 - 16: cat - cat || Loss: 0.4255000352859497\n",
      "tensor([1., 0.]) tensor([0.8878, 0.1122], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 49 - 17: cat - cat || Loss: 0.4253268837928772\n",
      "tensor([1., 0.]) tensor([0.8879, 0.1121], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 49 - 18: cat - cat || Loss: 0.4251454770565033\n",
      "tensor([1., 0.]) tensor([0.8881, 0.1119], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 49 - 19: cat - cat || Loss: 0.4249565303325653\n",
      "tensor([1., 0.]) tensor([0.8883, 0.1117], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 49 - 20: cat - cat || Loss: 0.4247609078884125\n",
      "tensor([1., 0.]) tensor([0.8885, 0.1115], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 49 - 21: cat - cat || Loss: 0.42455947399139404\n",
      "tensor([1., 0.]) tensor([0.8887, 0.1113], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 49 - 22: cat - cat || Loss: 0.4243526756763458\n",
      "tensor([1., 0.]) tensor([0.8889, 0.1111], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 49 - 23: cat - cat || Loss: 0.4241412878036499\n",
      "tensor([1., 0.]) tensor([0.8891, 0.1109], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 49 - 24: cat - cat || Loss: 0.4239256978034973\n",
      "tensor([1., 0.]) tensor([0.8893, 0.1107], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 49 - 25: cat - cat || Loss: 0.4237064719200134\n",
      "tensor([1., 0.]) tensor([0.8896, 0.1104], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 49 - 26: cat - cat || Loss: 0.42348402738571167\n",
      "tensor([1., 0.]) tensor([0.8898, 0.1102], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 49 - 27: cat - cat || Loss: 0.4232586622238159\n",
      "tensor([1., 0.]) tensor([0.8900, 0.1100], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 49 - 28: cat - cat || Loss: 0.4230308532714844\n",
      "tensor([1., 0.]) tensor([0.8902, 0.1098], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 49 - 29: cat - cat || Loss: 0.4228007197380066\n",
      "tensor([1., 0.]) tensor([0.8905, 0.1095], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 49 - 30: cat - cat || Loss: 0.42256873846054077\n",
      "tensor([1., 0.]) tensor([0.8907, 0.1093], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 49 - 31: cat - cat || Loss: 0.42233502864837646\n",
      "tensor([1., 0.]) tensor([0.8909, 0.1091], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 49 - 32: cat - cat || Loss: 0.4220999479293823\n",
      "tensor([1., 0.]) tensor([0.8912, 0.1088], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 49 - 33: cat - cat || Loss: 0.42186373472213745\n",
      "tensor([1., 0.]) tensor([0.8914, 0.1086], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 49 - 34: cat - cat || Loss: 0.42162632942199707\n",
      "tensor([1., 0.]) tensor([0.8916, 0.1084], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 49 - 35: cat - cat || Loss: 0.42138808965682983\n",
      "tensor([1., 0.]) tensor([0.8919, 0.1081], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 49 - 36: cat - cat || Loss: 0.4211491346359253\n",
      "tensor([1., 0.]) tensor([0.8921, 0.1079], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 49 - 37: cat - cat || Loss: 0.420909583568573\n",
      "tensor([1., 0.]) tensor([0.8924, 0.1076], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 49 - 38: cat - cat || Loss: 0.4206695556640625\n",
      "tensor([1., 0.]) tensor([0.8926, 0.1074], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 49 - 39: cat - cat || Loss: 0.4204291105270386\n",
      "tensor([1., 0.]) tensor([0.8928, 0.1072], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 49 - 40: cat - cat || Loss: 0.4201884865760803\n",
      "tensor([1., 0.]) tensor([0.8931, 0.1069], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 49 - 41: cat - cat || Loss: 0.4199475646018982\n",
      "tensor([1., 0.]) tensor([0.8933, 0.1067], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 49 - 42: cat - cat || Loss: 0.41970667243003845\n",
      "tensor([1., 0.]) tensor([0.8936, 0.1064], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 49 - 43: cat - cat || Loss: 0.419465571641922\n",
      "tensor([1., 0.]) tensor([0.8938, 0.1062], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 49 - 44: cat - cat || Loss: 0.41922467947006226\n",
      "tensor([1., 0.]) tensor([0.8940, 0.1060], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 49 - 45: cat - cat || Loss: 0.4189838171005249\n",
      "tensor([1., 0.]) tensor([0.8943, 0.1057], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 49 - 46: cat - cat || Loss: 0.4187430441379547\n",
      "tensor([1., 0.]) tensor([0.8945, 0.1055], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 49 - 47: cat - cat || Loss: 0.4185025095939636\n",
      "tensor([1., 0.]) tensor([0.8948, 0.1052], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 49 - 48: cat - cat || Loss: 0.4182621240615845\n",
      "tensor([1., 0.]) tensor([0.8950, 0.1050], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 49 - 49: cat - cat || Loss: 0.418022096157074\n",
      "tensor([1., 0.]) tensor([0.8952, 0.1048], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 49 - 50: cat - cat || Loss: 0.4177823066711426\n",
      "tensor([1., 0.]) tensor([0.8955, 0.1045], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 49 - 51: cat - cat || Loss: 0.4175429344177246\n",
      "tensor([1., 0.]) tensor([0.8957, 0.1043], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 49 - 52: cat - cat || Loss: 0.41730377078056335\n",
      "tensor([1., 0.]) tensor([0.8960, 0.1040], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 49 - 53: cat - cat || Loss: 0.4170650839805603\n",
      "tensor([1., 0.]) tensor([0.8962, 0.1038], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 49 - 54: cat - cat || Loss: 0.4168267250061035\n",
      "tensor([1., 0.]) tensor([0.8964, 0.1036], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 49 - 55: cat - cat || Loss: 0.41658881306648254\n",
      "tensor([1., 0.]) tensor([0.8967, 0.1033], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 49 - 56: cat - cat || Loss: 0.4163513779640198\n",
      "tensor([1., 0.]) tensor([0.8969, 0.1031], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 49 - 57: cat - cat || Loss: 0.41611433029174805\n",
      "tensor([1., 0.]) tensor([0.8971, 0.1029], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 49 - 58: cat - cat || Loss: 0.4158777594566345\n",
      "tensor([1., 0.]) tensor([0.8974, 0.1026], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 49 - 59: cat - cat || Loss: 0.415641725063324\n",
      "tensor([1., 0.]) tensor([0.8976, 0.1024], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 49 - 60: cat - cat || Loss: 0.41540616750717163\n",
      "tensor([1., 0.]) tensor([0.8979, 0.1021], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 49 - 61: cat - cat || Loss: 0.4151710271835327\n",
      "tensor([1., 0.]) tensor([0.8981, 0.1019], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 49 - 62: cat - cat || Loss: 0.4149364233016968\n",
      "tensor([1., 0.]) tensor([0.8983, 0.1017], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 49 - 63: cat - cat || Loss: 0.41470229625701904\n",
      "tensor([1., 0.]) tensor([0.8986, 0.1014], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 49 - 64: cat - cat || Loss: 0.41446876525878906\n",
      "tensor([1., 0.]) tensor([0.8988, 0.1012], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 49 - 65: cat - cat || Loss: 0.4142357110977173\n",
      "tensor([1., 0.]) tensor([0.8990, 0.1010], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 49 - 66: cat - cat || Loss: 0.4140031933784485\n",
      "tensor([1., 0.]) tensor([0.8993, 0.1007], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 49 - 67: cat - cat || Loss: 0.41377127170562744\n",
      "tensor([1., 0.]) tensor([0.8995, 0.1005], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 49 - 68: cat - cat || Loss: 0.413539856672287\n",
      "tensor([1., 0.]) tensor([0.8997, 0.1003], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 49 - 69: cat - cat || Loss: 0.41330891847610474\n",
      "tensor([1., 0.]) tensor([0.9000, 0.1000], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 49 - 70: cat - cat || Loss: 0.413078635931015\n",
      "tensor([1., 0.]) tensor([0.9002, 0.0998], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 49 - 71: cat - cat || Loss: 0.4128488600254059\n",
      "tensor([1., 0.]) tensor([0.9004, 0.0996], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 49 - 72: cat - cat || Loss: 0.41261956095695496\n",
      "tensor([1., 0.]) tensor([0.9006, 0.0994], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 49 - 73: cat - cat || Loss: 0.4123908281326294\n",
      "tensor([1., 0.]) tensor([0.9009, 0.0991], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 49 - 74: cat - cat || Loss: 0.4121626615524292\n",
      "tensor([1., 0.]) tensor([0.9011, 0.0989], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 49 - 75: cat - cat || Loss: 0.41193509101867676\n",
      "tensor([1., 0.]) tensor([0.9013, 0.0987], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 49 - 76: cat - cat || Loss: 0.4117080569267273\n",
      "tensor([1., 0.]) tensor([0.9016, 0.0984], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 49 - 77: cat - cat || Loss: 0.4114816188812256\n",
      "tensor([1., 0.]) tensor([0.9018, 0.0982], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 49 - 78: cat - cat || Loss: 0.4112555980682373\n",
      "tensor([1., 0.]) tensor([0.9020, 0.0980], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 49 - 79: cat - cat || Loss: 0.41103023290634155\n",
      "tensor([1., 0.]) tensor([0.9022, 0.0978], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 49 - 80: cat - cat || Loss: 0.4108054041862488\n",
      "tensor([1., 0.]) tensor([0.9025, 0.0975], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 49 - 81: cat - cat || Loss: 0.410581111907959\n",
      "tensor([1., 0.]) tensor([0.9027, 0.0973], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 49 - 82: cat - cat || Loss: 0.41035738587379456\n",
      "tensor([1., 0.]) tensor([0.9029, 0.0971], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 49 - 83: cat - cat || Loss: 0.4101341962814331\n",
      "tensor([1., 0.]) tensor([0.9031, 0.0969], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 49 - 84: cat - cat || Loss: 0.4099116325378418\n",
      "tensor([1., 0.]) tensor([0.9034, 0.0966], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 49 - 85: cat - cat || Loss: 0.4096894860267639\n",
      "tensor([1., 0.]) tensor([0.9036, 0.0964], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 49 - 86: cat - cat || Loss: 0.40946799516677856\n",
      "tensor([1., 0.]) tensor([0.9038, 0.0962], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 49 - 87: cat - cat || Loss: 0.4092470407485962\n",
      "tensor([1., 0.]) tensor([0.9040, 0.0960], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 49 - 88: cat - cat || Loss: 0.4090266227722168\n",
      "tensor([1., 0.]) tensor([0.9042, 0.0958], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 49 - 89: cat - cat || Loss: 0.40880680084228516\n",
      "tensor([1., 0.]) tensor([0.9045, 0.0955], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 49 - 90: cat - cat || Loss: 0.4085874557495117\n",
      "tensor([1., 0.]) tensor([0.9047, 0.0953], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 49 - 91: cat - cat || Loss: 0.40836870670318604\n",
      "tensor([1., 0.]) tensor([0.9049, 0.0951], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 49 - 92: cat - cat || Loss: 0.40815049409866333\n",
      "tensor([1., 0.]) tensor([0.9051, 0.0949], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 49 - 93: cat - cat || Loss: 0.4079328179359436\n",
      "tensor([1., 0.]) tensor([0.9053, 0.0947], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 49 - 94: cat - cat || Loss: 0.4077156186103821\n",
      "tensor([1., 0.]) tensor([0.9055, 0.0945], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 49 - 95: cat - cat || Loss: 0.4074990153312683\n",
      "tensor([1., 0.]) tensor([0.9058, 0.0942], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 49 - 96: cat - cat || Loss: 0.4072830080986023\n",
      "tensor([1., 0.]) tensor([0.9060, 0.0940], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 49 - 97: cat - cat || Loss: 0.4070674777030945\n",
      "tensor([1., 0.]) tensor([0.9062, 0.0938], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 49 - 98: cat - cat || Loss: 0.40685248374938965\n",
      "tensor([1., 0.]) tensor([0.9064, 0.0936], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 49 - 99: cat - cat || Loss: 0.4066380560398102\n",
      "tensor([1., 0.]) tensor([0.9066, 0.0934], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 49 - 100: cat - cat || Loss: 0.4064241945743561\n",
      "tensor([1., 0.]) tensor([0.9068, 0.0932], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 49 - 101: cat - cat || Loss: 0.4062107801437378\n",
      "tensor([1., 0.]) tensor([0.9071, 0.0929], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 49 - 102: cat - cat || Loss: 0.4059980511665344\n",
      "tensor([1., 0.]) tensor([0.9073, 0.0927], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 49 - 103: cat - cat || Loss: 0.4057856798171997\n",
      "tensor([1., 0.]) tensor([0.9075, 0.0925], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 49 - 104: cat - cat || Loss: 0.40557390451431274\n",
      "tensor([1., 0.]) tensor([0.9077, 0.0923], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 49 - 105: cat - cat || Loss: 0.4053627550601959\n",
      "tensor([1., 0.]) tensor([0.9079, 0.0921], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 49 - 106: cat - cat || Loss: 0.4051520824432373\n",
      "tensor([1., 0.]) tensor([0.9081, 0.0919], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 49 - 107: cat - cat || Loss: 0.4049418866634369\n",
      "tensor([1., 0.]) tensor([0.9083, 0.0917], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 49 - 108: cat - cat || Loss: 0.4047323167324066\n",
      "tensor([1., 0.]) tensor([0.9085, 0.0915], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 49 - 109: cat - cat || Loss: 0.40452316403388977\n",
      "tensor([1., 0.]) tensor([0.9087, 0.0913], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 49 - 110: cat - cat || Loss: 0.4043145775794983\n",
      "tensor([1., 0.]) tensor([0.9089, 0.0911], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 49 - 111: cat - cat || Loss: 0.4041065573692322\n",
      "tensor([1., 0.]) tensor([0.9092, 0.0908], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 49 - 112: cat - cat || Loss: 0.4038989543914795\n",
      "tensor([1., 0.]) tensor([0.9094, 0.0906], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 49 - 113: cat - cat || Loss: 0.40369197726249695\n",
      "tensor([1., 0.]) tensor([0.9096, 0.0904], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 49 - 114: cat - cat || Loss: 0.403485506772995\n",
      "tensor([1., 0.]) tensor([0.9098, 0.0902], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 49 - 115: cat - cat || Loss: 0.40327951312065125\n",
      "tensor([1., 0.]) tensor([0.9100, 0.0900], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 49 - 116: cat - cat || Loss: 0.40307408571243286\n",
      "tensor([1., 0.]) tensor([0.9102, 0.0898], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 49 - 117: cat - cat || Loss: 0.40286916494369507\n",
      "tensor([1., 0.]) tensor([0.9104, 0.0896], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 49 - 118: cat - cat || Loss: 0.40266481041908264\n",
      "tensor([1., 0.]) tensor([0.9106, 0.0894], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 49 - 119: cat - cat || Loss: 0.4024609327316284\n",
      "tensor([1., 0.]) tensor([0.9108, 0.0892], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 49 - 120: cat - cat || Loss: 0.4022575616836548\n",
      "tensor([1., 0.]) tensor([0.9110, 0.0890], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 49 - 121: cat - cat || Loss: 0.40205466747283936\n",
      "tensor([1., 0.]) tensor([0.9112, 0.0888], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 49 - 122: cat - cat || Loss: 0.40185242891311646\n",
      "tensor([1., 0.]) tensor([0.9114, 0.0886], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 49 - 123: cat - cat || Loss: 0.40165063738822937\n",
      "tensor([1., 0.]) tensor([0.9116, 0.0884], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 49 - 124: cat - cat || Loss: 0.40144938230514526\n",
      "tensor([1., 0.]) tensor([0.9118, 0.0882], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 49 - 125: cat - cat || Loss: 0.40124860405921936\n",
      "tensor([1., 0.]) tensor([0.9120, 0.0880], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 49 - 126: cat - cat || Loss: 0.40104836225509644\n",
      "tensor([1., 0.]) tensor([0.9122, 0.0878], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 49 - 127: cat - cat || Loss: 0.40084853768348694\n",
      "tensor([1., 0.]) tensor([0.9124, 0.0876], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 49 - 128: cat - cat || Loss: 0.4006493091583252\n",
      "tensor([1., 0.]) tensor([0.9126, 0.0874], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 49 - 129: cat - cat || Loss: 0.40045061707496643\n",
      "tensor([1., 0.]) tensor([0.9128, 0.0872], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 49 - 130: cat - cat || Loss: 0.40025240182876587\n",
      "tensor([1., 0.]) tensor([0.9130, 0.0870], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 49 - 131: cat - cat || Loss: 0.40005460381507874\n",
      "tensor([1., 0.]) tensor([0.9132, 0.0868], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 49 - 132: cat - cat || Loss: 0.39985737204551697\n",
      "tensor([1., 0.]) tensor([0.9134, 0.0866], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 49 - 133: cat - cat || Loss: 0.39966070652008057\n",
      "tensor([1., 0.]) tensor([0.9136, 0.0864], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 49 - 134: cat - cat || Loss: 0.3994644284248352\n",
      "tensor([1., 0.]) tensor([0.9138, 0.0862], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 49 - 135: cat - cat || Loss: 0.3992687165737152\n",
      "tensor([1., 0.]) tensor([0.9140, 0.0860], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 49 - 136: cat - cat || Loss: 0.39907345175743103\n",
      "tensor([1., 0.]) tensor([0.9142, 0.0858], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 49 - 137: cat - cat || Loss: 0.39887866377830505\n",
      "tensor([1., 0.]) tensor([0.9144, 0.0856], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 49 - 138: cat - cat || Loss: 0.39868444204330444\n",
      "tensor([1., 0.]) tensor([0.9146, 0.0854], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 49 - 139: cat - cat || Loss: 0.39849066734313965\n",
      "tensor([1., 0.]) tensor([0.9148, 0.0852], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 49 - 140: cat - cat || Loss: 0.39829736948013306\n",
      "tensor([1., 0.]) tensor([0.9150, 0.0850], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 49 - 141: cat - cat || Loss: 0.39810457825660706\n",
      "tensor([1., 0.]) tensor([0.9152, 0.0848], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 49 - 142: cat - cat || Loss: 0.39791229367256165\n",
      "tensor([1., 0.]) tensor([0.9153, 0.0847], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 49 - 143: cat - cat || Loss: 0.39772042632102966\n",
      "tensor([1., 0.]) tensor([0.9155, 0.0845], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 49 - 144: cat - cat || Loss: 0.39752915501594543\n",
      "tensor([1., 0.]) tensor([0.9157, 0.0843], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 49 - 145: cat - cat || Loss: 0.397338330745697\n",
      "tensor([1., 0.]) tensor([0.9159, 0.0841], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 49 - 146: cat - cat || Loss: 0.3971479535102844\n",
      "tensor([1., 0.]) tensor([0.9161, 0.0839], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 49 - 147: cat - cat || Loss: 0.3969581127166748\n",
      "tensor([1., 0.]) tensor([0.9163, 0.0837], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 49 - 148: cat - cat || Loss: 0.396768718957901\n",
      "tensor([1., 0.]) tensor([0.9165, 0.0835], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 49 - 149: cat - cat || Loss: 0.3965798616409302\n",
      "tensor([1., 0.]) tensor([0.9167, 0.0833], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 49 - 150: cat - cat || Loss: 0.3963913917541504\n",
      "tensor([1., 0.]) tensor([0.9169, 0.0831], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 49 - 151: cat - cat || Loss: 0.3962034285068512\n",
      "tensor([1., 0.]) tensor([0.9171, 0.0829], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 49 - 152: cat - cat || Loss: 0.396016001701355\n",
      "tensor([1., 0.]) tensor([0.9172, 0.0828], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 49 - 153: cat - cat || Loss: 0.3958289921283722\n",
      "tensor([1., 0.]) tensor([0.9174, 0.0826], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 49 - 154: cat - cat || Loss: 0.3956424593925476\n",
      "tensor([1., 0.]) tensor([0.9176, 0.0824], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 49 - 155: cat - cat || Loss: 0.39545637369155884\n",
      "tensor([1., 0.]) tensor([0.9178, 0.0822], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 49 - 156: cat - cat || Loss: 0.39527082443237305\n",
      "tensor([1., 0.]) tensor([0.9180, 0.0820], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 49 - 157: cat - cat || Loss: 0.39508578181266785\n",
      "tensor([1., 0.]) tensor([0.9182, 0.0818], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 49 - 158: cat - cat || Loss: 0.3949010372161865\n",
      "tensor([1., 0.]) tensor([0.9184, 0.0816], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 49 - 159: cat - cat || Loss: 0.39471691846847534\n",
      "tensor([1., 0.]) tensor([0.9185, 0.0815], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 49 - 160: cat - cat || Loss: 0.3945331573486328\n",
      "tensor([1., 0.]) tensor([0.9187, 0.0813], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 49 - 161: cat - cat || Loss: 0.39434999227523804\n",
      "tensor([1., 0.]) tensor([0.9189, 0.0811], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 49 - 162: cat - cat || Loss: 0.39416730403900146\n",
      "tensor([1., 0.]) tensor([0.9191, 0.0809], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 49 - 163: cat - cat || Loss: 0.393984854221344\n",
      "tensor([1., 0.]) tensor([0.9193, 0.0807], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 49 - 164: cat - cat || Loss: 0.39380308985710144\n",
      "tensor([1., 0.]) tensor([0.9195, 0.0805], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 49 - 165: cat - cat || Loss: 0.3936217129230499\n",
      "tensor([1., 0.]) tensor([0.9196, 0.0804], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 49 - 166: cat - cat || Loss: 0.39344078302383423\n",
      "tensor([1., 0.]) tensor([0.9198, 0.0802], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 49 - 167: cat - cat || Loss: 0.39326030015945435\n",
      "tensor([1., 0.]) tensor([0.9200, 0.0800], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 49 - 168: cat - cat || Loss: 0.3930802643299103\n",
      "tensor([1., 0.]) tensor([0.9202, 0.0798], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 49 - 169: cat - cat || Loss: 0.392900675535202\n",
      "tensor([1., 0.]) tensor([0.9204, 0.0796], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 49 - 170: cat - cat || Loss: 0.39272159337997437\n",
      "tensor([1., 0.]) tensor([0.9205, 0.0795], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 49 - 171: cat - cat || Loss: 0.39254292845726013\n",
      "tensor([1., 0.]) tensor([0.9207, 0.0793], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 49 - 172: cat - cat || Loss: 0.3923647403717041\n",
      "tensor([1., 0.]) tensor([0.9209, 0.0791], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 49 - 173: cat - cat || Loss: 0.3921869397163391\n",
      "tensor([1., 0.]) tensor([0.9211, 0.0789], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 49 - 174: cat - cat || Loss: 0.3920096158981323\n",
      "tensor([1., 0.]) tensor([0.9213, 0.0787], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 49 - 175: cat - cat || Loss: 0.39183273911476135\n",
      "tensor([1., 0.]) tensor([0.9214, 0.0786], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 49 - 176: cat - cat || Loss: 0.3916563391685486\n",
      "tensor([1., 0.]) tensor([0.9216, 0.0784], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 49 - 177: cat - cat || Loss: 0.39148038625717163\n",
      "tensor([1., 0.]) tensor([0.9218, 0.0782], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 49 - 178: cat - cat || Loss: 0.3913048207759857\n",
      "tensor([1., 0.]) tensor([0.9220, 0.0780], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 49 - 179: cat - cat || Loss: 0.391129732131958\n",
      "tensor([1., 0.]) tensor([0.9221, 0.0779], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 49 - 180: cat - cat || Loss: 0.39095503091812134\n",
      "tensor([1., 0.]) tensor([0.9223, 0.0777], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 49 - 181: cat - cat || Loss: 0.3907807767391205\n",
      "tensor([1., 0.]) tensor([0.9225, 0.0775], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 49 - 182: cat - cat || Loss: 0.39060699939727783\n",
      "tensor([1., 0.]) tensor([0.9227, 0.0773], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 49 - 183: cat - cat || Loss: 0.39043372869491577\n",
      "tensor([1., 0.]) tensor([0.9228, 0.0772], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 49 - 184: cat - cat || Loss: 0.3902607560157776\n",
      "tensor([1., 0.]) tensor([0.9230, 0.0770], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 49 - 185: cat - cat || Loss: 0.39008828997612\n",
      "tensor([1., 0.]) tensor([0.9232, 0.0768], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 49 - 186: cat - cat || Loss: 0.38991618156433105\n",
      "tensor([1., 0.]) tensor([0.9233, 0.0767], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 49 - 187: cat - cat || Loss: 0.3897445499897003\n",
      "tensor([1., 0.]) tensor([0.9235, 0.0765], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 49 - 188: cat - cat || Loss: 0.389573335647583\n",
      "tensor([1., 0.]) tensor([0.9237, 0.0763], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 49 - 189: cat - cat || Loss: 0.3894024193286896\n",
      "tensor([1., 0.]) tensor([0.9239, 0.0761], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 49 - 190: dog - cat || Loss: 1.2372913360595703\n",
      "tensor([0., 1.]) tensor([0.9240, 0.0760], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 49 - 191: dog - cat || Loss: 1.237427830696106\n",
      "tensor([0., 1.]) tensor([0.9242, 0.0758], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 49 - 192: dog - cat || Loss: 1.237533688545227\n",
      "tensor([0., 1.]) tensor([0.9243, 0.0757], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 49 - 193: dog - cat || Loss: 1.237612009048462\n",
      "tensor([0., 1.]) tensor([0.9244, 0.0756], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 49 - 194: dog - cat || Loss: 1.2376658916473389\n",
      "tensor([0., 1.]) tensor([0.9244, 0.0756], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 49 - 195: dog - cat || Loss: 1.2376974821090698\n",
      "tensor([0., 1.]) tensor([0.9244, 0.0756], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 49 - 196: dog - cat || Loss: 1.2377090454101562\n",
      "tensor([0., 1.]) tensor([0.9244, 0.0756], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 49 - 197: dog - cat || Loss: 1.23770272731781\n",
      "tensor([0., 1.]) tensor([0.9244, 0.0756], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 49 - 198: dog - cat || Loss: 1.237680435180664\n",
      "tensor([0., 1.]) tensor([0.9244, 0.0756], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 49 - 199: dog - cat || Loss: 1.2376434803009033\n",
      "tensor([0., 1.]) tensor([0.9244, 0.0756], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 49 - 200: dog - cat || Loss: 1.2375935316085815\n",
      "tensor([0., 1.]) tensor([0.9243, 0.0757], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 49 - 201: dog - cat || Loss: 1.2375319004058838\n",
      "tensor([0., 1.]) tensor([0.9243, 0.0757], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 49 - 202: dog - cat || Loss: 1.237459421157837\n",
      "tensor([0., 1.]) tensor([0.9242, 0.0758], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 49 - 203: dog - cat || Loss: 1.2373775243759155\n",
      "tensor([0., 1.]) tensor([0.9241, 0.0759], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 49 - 204: dog - cat || Loss: 1.237286925315857\n",
      "tensor([0., 1.]) tensor([0.9240, 0.0760], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 49 - 205: dog - cat || Loss: 1.237188458442688\n",
      "tensor([0., 1.]) tensor([0.9239, 0.0761], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 49 - 206: dog - cat || Loss: 1.237083077430725\n",
      "tensor([0., 1.]) tensor([0.9238, 0.0762], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 49 - 207: dog - cat || Loss: 1.2369712591171265\n",
      "tensor([0., 1.]) tensor([0.9237, 0.0763], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 49 - 208: dog - cat || Loss: 1.2368535995483398\n",
      "tensor([0., 1.]) tensor([0.9236, 0.0764], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 49 - 209: dog - cat || Loss: 1.2367305755615234\n",
      "tensor([0., 1.]) tensor([0.9235, 0.0765], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 49 - 210: dog - cat || Loss: 1.2366031408309937\n",
      "tensor([0., 1.]) tensor([0.9233, 0.0767], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 49 - 211: dog - cat || Loss: 1.2364710569381714\n",
      "tensor([0., 1.]) tensor([0.9232, 0.0768], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 49 - 212: dog - cat || Loss: 1.236335039138794\n",
      "tensor([0., 1.]) tensor([0.9231, 0.0769], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 49 - 213: dog - cat || Loss: 1.2361958026885986\n",
      "tensor([0., 1.]) tensor([0.9229, 0.0771], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 49 - 214: dog - cat || Loss: 1.2360529899597168\n",
      "tensor([0., 1.]) tensor([0.9228, 0.0772], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 49 - 215: dog - cat || Loss: 1.2359073162078857\n",
      "tensor([0., 1.]) tensor([0.9226, 0.0774], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 49 - 216: dog - cat || Loss: 1.2357590198516846\n",
      "tensor([0., 1.]) tensor([0.9225, 0.0775], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 49 - 217: dog - cat || Loss: 1.2356079816818237\n",
      "tensor([0., 1.]) tensor([0.9223, 0.0777], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 49 - 218: dog - cat || Loss: 1.2354546785354614\n",
      "tensor([0., 1.]) tensor([0.9222, 0.0778], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 49 - 219: dog - cat || Loss: 1.2352994680404663\n",
      "tensor([0., 1.]) tensor([0.9220, 0.0780], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 49 - 220: dog - cat || Loss: 1.2351422309875488\n",
      "tensor([0., 1.]) tensor([0.9219, 0.0781], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 49 - 221: dog - cat || Loss: 1.2349830865859985\n",
      "tensor([0., 1.]) tensor([0.9217, 0.0783], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 49 - 222: dog - cat || Loss: 1.2348226308822632\n",
      "tensor([0., 1.]) tensor([0.9216, 0.0784], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 49 - 223: dog - cat || Loss: 1.2346603870391846\n",
      "tensor([0., 1.]) tensor([0.9214, 0.0786], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 49 - 224: dog - cat || Loss: 1.234496831893921\n",
      "tensor([0., 1.]) tensor([0.9212, 0.0788], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 49 - 225: dog - cat || Loss: 1.2343319654464722\n",
      "tensor([0., 1.]) tensor([0.9211, 0.0789], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 49 - 226: dog - cat || Loss: 1.2341657876968384\n",
      "tensor([0., 1.]) tensor([0.9209, 0.0791], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 49 - 227: dog - cat || Loss: 1.233998417854309\n",
      "tensor([0., 1.]) tensor([0.9207, 0.0793], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 49 - 228: dog - cat || Loss: 1.2338300943374634\n",
      "tensor([0., 1.]) tensor([0.9206, 0.0794], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 49 - 229: dog - cat || Loss: 1.2336608171463013\n",
      "tensor([0., 1.]) tensor([0.9204, 0.0796], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 49 - 230: dog - cat || Loss: 1.2334905862808228\n",
      "tensor([0., 1.]) tensor([0.9202, 0.0798], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 49 - 231: dog - cat || Loss: 1.2333194017410278\n",
      "tensor([0., 1.]) tensor([0.9201, 0.0799], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 49 - 232: dog - cat || Loss: 1.2331472635269165\n",
      "tensor([0., 1.]) tensor([0.9199, 0.0801], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 49 - 233: dog - cat || Loss: 1.2329742908477783\n",
      "tensor([0., 1.]) tensor([0.9197, 0.0803], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 49 - 234: dog - cat || Loss: 1.2328007221221924\n",
      "tensor([0., 1.]) tensor([0.9195, 0.0805], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 49 - 235: dog - cat || Loss: 1.2326263189315796\n",
      "tensor([0., 1.]) tensor([0.9194, 0.0806], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 49 - 236: dog - cat || Loss: 1.232451319694519\n",
      "tensor([0., 1.]) tensor([0.9192, 0.0808], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 49 - 237: dog - cat || Loss: 1.2322754859924316\n",
      "tensor([0., 1.]) tensor([0.9190, 0.0810], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 49 - 238: dog - cat || Loss: 1.232098937034607\n",
      "tensor([0., 1.]) tensor([0.9188, 0.0812], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 49 - 239: dog - cat || Loss: 1.2319217920303345\n",
      "tensor([0., 1.]) tensor([0.9187, 0.0813], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 49 - 240: dog - cat || Loss: 1.2317440509796143\n",
      "tensor([0., 1.]) tensor([0.9185, 0.0815], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 49 - 241: dog - cat || Loss: 1.2315657138824463\n",
      "tensor([0., 1.]) tensor([0.9183, 0.0817], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 49 - 242: dog - cat || Loss: 1.2313868999481201\n",
      "tensor([0., 1.]) tensor([0.9181, 0.0819], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 49 - 243: dog - cat || Loss: 1.2312073707580566\n",
      "tensor([0., 1.]) tensor([0.9179, 0.0821], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 49 - 244: dog - cat || Loss: 1.2310272455215454\n",
      "tensor([0., 1.]) tensor([0.9178, 0.0822], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 49 - 245: dog - cat || Loss: 1.2308467626571655\n",
      "tensor([0., 1.]) tensor([0.9176, 0.0824], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 49 - 246: dog - cat || Loss: 1.2306654453277588\n",
      "tensor([0., 1.]) tensor([0.9174, 0.0826], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 49 - 247: dog - cat || Loss: 1.2304836511611938\n",
      "tensor([0., 1.]) tensor([0.9172, 0.0828], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 49 - 248: dog - cat || Loss: 1.2303016185760498\n",
      "tensor([0., 1.]) tensor([0.9170, 0.0830], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 49 - 249: dog - cat || Loss: 1.230118751525879\n",
      "tensor([0., 1.]) tensor([0.9169, 0.0831], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 49 - 250: dog - cat || Loss: 1.229935646057129\n",
      "tensor([0., 1.]) tensor([0.9167, 0.0833], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 49 - 251: dog - cat || Loss: 1.229751706123352\n",
      "tensor([0., 1.]) tensor([0.9165, 0.0835], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 49 - 252: dog - cat || Loss: 1.2295674085617065\n",
      "tensor([0., 1.]) tensor([0.9163, 0.0837], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 49 - 253: dog - cat || Loss: 1.2293826341629028\n",
      "tensor([0., 1.]) tensor([0.9161, 0.0839], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 49 - 254: dog - cat || Loss: 1.229197382926941\n",
      "tensor([0., 1.]) tensor([0.9159, 0.0841], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 49 - 255: dog - cat || Loss: 1.2290115356445312\n",
      "tensor([0., 1.]) tensor([0.9157, 0.0843], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 49 - 256: dog - cat || Loss: 1.2288252115249634\n",
      "tensor([0., 1.]) tensor([0.9156, 0.0844], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 49 - 257: dog - cat || Loss: 1.2286385297775269\n",
      "tensor([0., 1.]) tensor([0.9154, 0.0846], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 49 - 258: dog - cat || Loss: 1.2284512519836426\n",
      "tensor([0., 1.]) tensor([0.9152, 0.0848], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 49 - 259: dog - cat || Loss: 1.2282634973526\n",
      "tensor([0., 1.]) tensor([0.9150, 0.0850], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 49 - 260: dog - cat || Loss: 1.2280752658843994\n",
      "tensor([0., 1.]) tensor([0.9148, 0.0852], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 49 - 261: dog - cat || Loss: 1.22788667678833\n",
      "tensor([0., 1.]) tensor([0.9146, 0.0854], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 49 - 262: dog - cat || Loss: 1.2276973724365234\n",
      "tensor([0., 1.]) tensor([0.9144, 0.0856], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 49 - 263: dog - cat || Loss: 1.2275078296661377\n",
      "tensor([0., 1.]) tensor([0.9142, 0.0858], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 49 - 264: dog - cat || Loss: 1.2273175716400146\n",
      "tensor([0., 1.]) tensor([0.9141, 0.0859], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 49 - 265: dog - cat || Loss: 1.227126955986023\n",
      "tensor([0., 1.]) tensor([0.9139, 0.0861], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 49 - 266: dog - cat || Loss: 1.226935863494873\n",
      "tensor([0., 1.]) tensor([0.9137, 0.0863], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 49 - 267: dog - cat || Loss: 1.226744294166565\n",
      "tensor([0., 1.]) tensor([0.9135, 0.0865], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 49 - 268: dog - cat || Loss: 1.2265522480010986\n",
      "tensor([0., 1.]) tensor([0.9133, 0.0867], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 49 - 269: dog - cat || Loss: 1.2263597249984741\n",
      "tensor([0., 1.]) tensor([0.9131, 0.0869], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 49 - 270: dog - cat || Loss: 1.2261667251586914\n",
      "tensor([0., 1.]) tensor([0.9129, 0.0871], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 49 - 271: dog - cat || Loss: 1.225973129272461\n",
      "tensor([0., 1.]) tensor([0.9127, 0.0873], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 49 - 272: dog - cat || Loss: 1.2257791757583618\n",
      "tensor([0., 1.]) tensor([0.9125, 0.0875], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 49 - 273: dog - cat || Loss: 1.225584626197815\n",
      "tensor([0., 1.]) tensor([0.9123, 0.0877], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 49 - 274: dog - cat || Loss: 1.2253897190093994\n",
      "tensor([0., 1.]) tensor([0.9121, 0.0879], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 49 - 275: dog - cat || Loss: 1.2251942157745361\n",
      "tensor([0., 1.]) tensor([0.9119, 0.0881], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 49 - 276: dog - cat || Loss: 1.2249983549118042\n",
      "tensor([0., 1.]) tensor([0.9117, 0.0883], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 49 - 277: dog - cat || Loss: 1.2248018980026245\n",
      "tensor([0., 1.]) tensor([0.9115, 0.0885], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 49 - 278: dog - cat || Loss: 1.2246049642562866\n",
      "tensor([0., 1.]) tensor([0.9113, 0.0887], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 49 - 279: dog - cat || Loss: 1.22440767288208\n",
      "tensor([0., 1.]) tensor([0.9111, 0.0889], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 49 - 280: dog - cat || Loss: 1.2242097854614258\n",
      "tensor([0., 1.]) tensor([0.9109, 0.0891], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 49 - 281: dog - cat || Loss: 1.2240114212036133\n",
      "tensor([0., 1.]) tensor([0.9107, 0.0893], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 49 - 282: dog - cat || Loss: 1.2238125801086426\n",
      "tensor([0., 1.]) tensor([0.9106, 0.0894], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 49 - 283: dog - cat || Loss: 1.2236132621765137\n",
      "tensor([0., 1.]) tensor([0.9104, 0.0896], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 49 - 284: dog - cat || Loss: 1.223413348197937\n",
      "tensor([0., 1.]) tensor([0.9102, 0.0898], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 49 - 285: dog - cat || Loss: 1.2232129573822021\n",
      "tensor([0., 1.]) tensor([0.9100, 0.0900], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 49 - 286: dog - cat || Loss: 1.2230122089385986\n",
      "tensor([0., 1.]) tensor([0.9098, 0.0902], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 49 - 287: dog - cat || Loss: 1.2228108644485474\n",
      "tensor([0., 1.]) tensor([0.9095, 0.0905], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 49 - 288: dog - cat || Loss: 1.222609043121338\n",
      "tensor([0., 1.]) tensor([0.9093, 0.0907], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 49 - 289: dog - cat || Loss: 1.2224066257476807\n",
      "tensor([0., 1.]) tensor([0.9091, 0.0909], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 49 - 290: dog - cat || Loss: 1.2222038507461548\n",
      "tensor([0., 1.]) tensor([0.9089, 0.0911], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 49 - 291: dog - cat || Loss: 1.2220004796981812\n",
      "tensor([0., 1.]) tensor([0.9087, 0.0913], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 49 - 292: dog - cat || Loss: 1.2217966318130493\n",
      "tensor([0., 1.]) tensor([0.9085, 0.0915], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 49 - 293: dog - cat || Loss: 1.2215923070907593\n",
      "tensor([0., 1.]) tensor([0.9083, 0.0917], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 49 - 294: dog - cat || Loss: 1.221387505531311\n",
      "tensor([0., 1.]) tensor([0.9081, 0.0919], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 49 - 295: dog - cat || Loss: 1.221182107925415\n",
      "tensor([0., 1.]) tensor([0.9079, 0.0921], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 49 - 296: dog - cat || Loss: 1.2209762334823608\n",
      "tensor([0., 1.]) tensor([0.9077, 0.0923], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 49 - 297: dog - cat || Loss: 1.220770001411438\n",
      "tensor([0., 1.]) tensor([0.9075, 0.0925], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 49 - 298: dog - cat || Loss: 1.2205631732940674\n",
      "tensor([0., 1.]) tensor([0.9073, 0.0927], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 49 - 299: dog - cat || Loss: 1.220355749130249\n",
      "tensor([0., 1.]) tensor([0.9071, 0.0929], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 49 - 300: dog - cat || Loss: 1.2201478481292725\n",
      "tensor([0., 1.]) tensor([0.9069, 0.0931], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 49 - 301: dog - cat || Loss: 1.2199394702911377\n",
      "tensor([0., 1.]) tensor([0.9067, 0.0933], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 49 - 302: dog - cat || Loss: 1.2197306156158447\n",
      "tensor([0., 1.]) tensor([0.9065, 0.0935], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 49 - 303: dog - cat || Loss: 1.2195210456848145\n",
      "tensor([0., 1.]) tensor([0.9063, 0.0937], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 49 - 304: dog - cat || Loss: 1.219311237335205\n",
      "tensor([0., 1.]) tensor([0.9060, 0.0940], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 49 - 305: dog - cat || Loss: 1.2191005945205688\n",
      "tensor([0., 1.]) tensor([0.9058, 0.0942], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 49 - 306: dog - cat || Loss: 1.218889594078064\n",
      "tensor([0., 1.]) tensor([0.9056, 0.0944], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 49 - 307: dog - cat || Loss: 1.2186781167984009\n",
      "tensor([0., 1.]) tensor([0.9054, 0.0946], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 49 - 308: dog - cat || Loss: 1.2184661626815796\n",
      "tensor([0., 1.]) tensor([0.9052, 0.0948], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 49 - 309: dog - cat || Loss: 1.2182536125183105\n",
      "tensor([0., 1.]) tensor([0.9050, 0.0950], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 49 - 310: dog - cat || Loss: 1.2180405855178833\n",
      "tensor([0., 1.]) tensor([0.9048, 0.0952], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 49 - 311: dog - cat || Loss: 1.2178268432617188\n",
      "tensor([0., 1.]) tensor([0.9046, 0.0954], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 49 - 312: dog - cat || Loss: 1.217612862586975\n",
      "tensor([0., 1.]) tensor([0.9044, 0.0956], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 49 - 313: dog - cat || Loss: 1.2173981666564941\n",
      "tensor([0., 1.]) tensor([0.9041, 0.0959], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 49 - 314: dog - cat || Loss: 1.217182993888855\n",
      "tensor([0., 1.]) tensor([0.9039, 0.0961], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 49 - 315: dog - cat || Loss: 1.216967225074768\n",
      "tensor([0., 1.]) tensor([0.9037, 0.0963], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 49 - 316: dog - cat || Loss: 1.216750979423523\n",
      "tensor([0., 1.]) tensor([0.9035, 0.0965], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 49 - 317: dog - cat || Loss: 1.21653413772583\n",
      "tensor([0., 1.]) tensor([0.9033, 0.0967], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 49 - 318: dog - cat || Loss: 1.2163169384002686\n",
      "tensor([0., 1.]) tensor([0.9031, 0.0969], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 49 - 319: dog - cat || Loss: 1.2160992622375488\n",
      "tensor([0., 1.]) tensor([0.9028, 0.0972], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 49 - 320: dog - cat || Loss: 1.2158807516098022\n",
      "tensor([0., 1.]) tensor([0.9026, 0.0974], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 49 - 321: dog - cat || Loss: 1.2156617641448975\n",
      "tensor([0., 1.]) tensor([0.9024, 0.0976], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 49 - 322: dog - cat || Loss: 1.215442419052124\n",
      "tensor([0., 1.]) tensor([0.9022, 0.0978], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 49 - 323: dog - cat || Loss: 1.2152223587036133\n",
      "tensor([0., 1.]) tensor([0.9020, 0.0980], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 49 - 324: dog - cat || Loss: 1.2150019407272339\n",
      "tensor([0., 1.]) tensor([0.9017, 0.0983], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 49 - 325: dog - cat || Loss: 1.2147808074951172\n",
      "tensor([0., 1.]) tensor([0.9015, 0.0985], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 49 - 326: dog - cat || Loss: 1.2145591974258423\n",
      "tensor([0., 1.]) tensor([0.9013, 0.0987], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 49 - 327: dog - cat || Loss: 1.2143369913101196\n",
      "tensor([0., 1.]) tensor([0.9011, 0.0989], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 49 - 328: dog - cat || Loss: 1.2141143083572388\n",
      "tensor([0., 1.]) tensor([0.9009, 0.0991], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 49 - 329: dog - cat || Loss: 1.2138911485671997\n",
      "tensor([0., 1.]) tensor([0.9006, 0.0994], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 49 - 330: dog - cat || Loss: 1.213667392730713\n",
      "tensor([0., 1.]) tensor([0.9004, 0.0996], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 49 - 331: dog - cat || Loss: 1.2134429216384888\n",
      "tensor([0., 1.]) tensor([0.9002, 0.0998], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 49 - 332: dog - cat || Loss: 1.213218092918396\n",
      "tensor([0., 1.]) tensor([0.9000, 0.1000], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 49 - 333: dog - cat || Loss: 1.2129926681518555\n",
      "tensor([0., 1.]) tensor([0.8997, 0.1003], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 49 - 334: dog - cat || Loss: 1.2127666473388672\n",
      "tensor([0., 1.]) tensor([0.8995, 0.1005], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 49 - 335: dog - cat || Loss: 1.2125401496887207\n",
      "tensor([0., 1.]) tensor([0.8993, 0.1007], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 49 - 336: dog - cat || Loss: 1.2123130559921265\n",
      "tensor([0., 1.]) tensor([0.8991, 0.1009], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 49 - 337: dog - cat || Loss: 1.2120853662490845\n",
      "tensor([0., 1.]) tensor([0.8988, 0.1012], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 49 - 338: dog - cat || Loss: 1.2118573188781738\n",
      "tensor([0., 1.]) tensor([0.8986, 0.1014], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 49 - 339: dog - cat || Loss: 1.2116284370422363\n",
      "tensor([0., 1.]) tensor([0.8984, 0.1016], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 49 - 340: dog - cat || Loss: 1.2113990783691406\n",
      "tensor([0., 1.]) tensor([0.8981, 0.1019], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 49 - 341: dog - cat || Loss: 1.2111692428588867\n",
      "tensor([0., 1.]) tensor([0.8979, 0.1021], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 49 - 342: dog - cat || Loss: 1.2109386920928955\n",
      "tensor([0., 1.]) tensor([0.8977, 0.1023], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 49 - 343: dog - cat || Loss: 1.2107077836990356\n",
      "tensor([0., 1.]) tensor([0.8974, 0.1026], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 49 - 344: dog - cat || Loss: 1.210476279258728\n",
      "tensor([0., 1.]) tensor([0.8972, 0.1028], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 49 - 345: dog - cat || Loss: 1.2102441787719727\n",
      "tensor([0., 1.]) tensor([0.8970, 0.1030], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 49 - 346: dog - cat || Loss: 1.21001136302948\n",
      "tensor([0., 1.]) tensor([0.8967, 0.1033], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 49 - 347: dog - cat || Loss: 1.2097781896591187\n",
      "tensor([0., 1.]) tensor([0.8965, 0.1035], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 49 - 348: dog - cat || Loss: 1.20954430103302\n",
      "tensor([0., 1.]) tensor([0.8963, 0.1037], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 49 - 349: dog - cat || Loss: 1.2093099355697632\n",
      "tensor([0., 1.]) tensor([0.8960, 0.1040], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 49 - 350: dog - cat || Loss: 1.2090750932693481\n",
      "tensor([0., 1.]) tensor([0.8958, 0.1042], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 49 - 351: dog - cat || Loss: 1.2088395357131958\n",
      "tensor([0., 1.]) tensor([0.8956, 0.1044], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 49 - 352: dog - cat || Loss: 1.2086032629013062\n",
      "tensor([0., 1.]) tensor([0.8953, 0.1047], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 49 - 353: dog - cat || Loss: 1.2083666324615479\n",
      "tensor([0., 1.]) tensor([0.8951, 0.1049], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 49 - 354: dog - cat || Loss: 1.2081294059753418\n",
      "tensor([0., 1.]) tensor([0.8949, 0.1051], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 49 - 355: dog - cat || Loss: 1.207891583442688\n",
      "tensor([0., 1.]) tensor([0.8946, 0.1054], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 49 - 356: dog - cat || Loss: 1.2076530456542969\n",
      "tensor([0., 1.]) tensor([0.8944, 0.1056], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 49 - 357: dog - cat || Loss: 1.2074140310287476\n",
      "tensor([0., 1.]) tensor([0.8942, 0.1058], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 49 - 358: dog - cat || Loss: 1.20717453956604\n",
      "tensor([0., 1.]) tensor([0.8939, 0.1061], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 49 - 359: dog - cat || Loss: 1.2069343328475952\n",
      "tensor([0., 1.]) tensor([0.8937, 0.1063], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 49 - 360: dog - cat || Loss: 1.2066935300827026\n",
      "tensor([0., 1.]) tensor([0.8934, 0.1066], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 49 - 361: dog - cat || Loss: 1.2064522504806519\n",
      "tensor([0., 1.]) tensor([0.8932, 0.1068], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 49 - 362: dog - cat || Loss: 1.2062102556228638\n",
      "tensor([0., 1.]) tensor([0.8929, 0.1071], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 49 - 363: dog - cat || Loss: 1.205967664718628\n",
      "tensor([0., 1.]) tensor([0.8927, 0.1073], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 49 - 364: dog - cat || Loss: 1.2057244777679443\n",
      "tensor([0., 1.]) tensor([0.8925, 0.1075], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 49 - 365: dog - cat || Loss: 1.2054808139801025\n",
      "tensor([0., 1.]) tensor([0.8922, 0.1078], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 49 - 366: dog - cat || Loss: 1.205236554145813\n",
      "tensor([0., 1.]) tensor([0.8920, 0.1080], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 49 - 367: dog - cat || Loss: 1.2049916982650757\n",
      "tensor([0., 1.]) tensor([0.8917, 0.1083], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 49 - 368: dog - cat || Loss: 1.2047462463378906\n",
      "tensor([0., 1.]) tensor([0.8915, 0.1085], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 49 - 369: dog - cat || Loss: 1.2045000791549683\n",
      "tensor([0., 1.]) tensor([0.8912, 0.1088], grad_fn=<SoftmaxBackward0>)\n",
      "=====epoch:50=====\n",
      "Epoch 50 - 0: cat - cat || Loss: 0.42226988077163696\n",
      "tensor([1., 0.]) tensor([0.8910, 0.1090], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 50 - 1: cat - cat || Loss: 0.42246711254119873\n",
      "tensor([1., 0.]) tensor([0.8908, 0.1092], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 50 - 2: cat - cat || Loss: 0.4226197600364685\n",
      "tensor([1., 0.]) tensor([0.8906, 0.1094], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 50 - 3: cat - cat || Loss: 0.4227322041988373\n",
      "tensor([1., 0.]) tensor([0.8905, 0.1095], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 50 - 4: cat - cat || Loss: 0.42280828952789307\n",
      "tensor([1., 0.]) tensor([0.8905, 0.1095], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 50 - 5: cat - cat || Loss: 0.4228516221046448\n",
      "tensor([1., 0.]) tensor([0.8904, 0.1096], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 50 - 6: cat - cat || Loss: 0.4228655695915222\n",
      "tensor([1., 0.]) tensor([0.8904, 0.1096], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 50 - 7: cat - cat || Loss: 0.42285293340682983\n",
      "tensor([1., 0.]) tensor([0.8904, 0.1096], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 50 - 8: cat - cat || Loss: 0.4228164553642273\n",
      "tensor([1., 0.]) tensor([0.8904, 0.1096], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 50 - 9: cat - cat || Loss: 0.422758549451828\n",
      "tensor([1., 0.]) tensor([0.8905, 0.1095], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 50 - 10: cat - cat || Loss: 0.4226812720298767\n",
      "tensor([1., 0.]) tensor([0.8906, 0.1094], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 50 - 11: cat - cat || Loss: 0.42258673906326294\n",
      "tensor([1., 0.]) tensor([0.8907, 0.1093], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 50 - 12: cat - cat || Loss: 0.42247670888900757\n",
      "tensor([1., 0.]) tensor([0.8908, 0.1092], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 50 - 13: cat - cat || Loss: 0.4223526418209076\n",
      "tensor([1., 0.]) tensor([0.8909, 0.1091], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 50 - 14: cat - cat || Loss: 0.4222160875797272\n",
      "tensor([1., 0.]) tensor([0.8910, 0.1090], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 50 - 15: cat - cat || Loss: 0.4220682978630066\n",
      "tensor([1., 0.]) tensor([0.8912, 0.1088], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 50 - 16: cat - cat || Loss: 0.42191046476364136\n",
      "tensor([1., 0.]) tensor([0.8914, 0.1086], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 50 - 17: cat - cat || Loss: 0.4217436909675598\n",
      "tensor([1., 0.]) tensor([0.8915, 0.1085], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 50 - 18: cat - cat || Loss: 0.4215688705444336\n",
      "tensor([1., 0.]) tensor([0.8917, 0.1083], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 50 - 19: cat - cat || Loss: 0.42138683795928955\n",
      "tensor([1., 0.]) tensor([0.8919, 0.1081], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 50 - 20: cat - cat || Loss: 0.4211983382701874\n",
      "tensor([1., 0.]) tensor([0.8921, 0.1079], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 50 - 21: cat - cat || Loss: 0.4210042357444763\n",
      "tensor([1., 0.]) tensor([0.8923, 0.1077], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 50 - 22: cat - cat || Loss: 0.4208051562309265\n",
      "tensor([1., 0.]) tensor([0.8925, 0.1075], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 50 - 23: cat - cat || Loss: 0.42060142755508423\n",
      "tensor([1., 0.]) tensor([0.8927, 0.1073], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 50 - 24: cat - cat || Loss: 0.420393705368042\n",
      "tensor([1., 0.]) tensor([0.8929, 0.1071], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 50 - 25: cat - cat || Loss: 0.42018258571624756\n",
      "tensor([1., 0.]) tensor([0.8931, 0.1069], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 50 - 26: cat - cat || Loss: 0.41996824741363525\n",
      "tensor([1., 0.]) tensor([0.8933, 0.1067], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 50 - 27: cat - cat || Loss: 0.4197511672973633\n",
      "tensor([1., 0.]) tensor([0.8935, 0.1065], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 50 - 28: cat - cat || Loss: 0.4195317029953003\n",
      "tensor([1., 0.]) tensor([0.8937, 0.1063], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 50 - 29: cat - cat || Loss: 0.4193100035190582\n",
      "tensor([1., 0.]) tensor([0.8940, 0.1060], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 50 - 30: cat - cat || Loss: 0.41908660531044006\n",
      "tensor([1., 0.]) tensor([0.8942, 0.1058], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 50 - 31: cat - cat || Loss: 0.418861448764801\n",
      "tensor([1., 0.]) tensor([0.8944, 0.1056], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 50 - 32: cat - cat || Loss: 0.4186350107192993\n",
      "tensor([1., 0.]) tensor([0.8946, 0.1054], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 50 - 33: cat - cat || Loss: 0.4184074401855469\n",
      "tensor([1., 0.]) tensor([0.8949, 0.1051], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 50 - 34: cat - cat || Loss: 0.4181787967681885\n",
      "tensor([1., 0.]) tensor([0.8951, 0.1049], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 50 - 35: cat - cat || Loss: 0.41794928908348083\n",
      "tensor([1., 0.]) tensor([0.8953, 0.1047], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 50 - 36: cat - cat || Loss: 0.41771915555000305\n",
      "tensor([1., 0.]) tensor([0.8955, 0.1045], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 50 - 37: cat - cat || Loss: 0.4174883961677551\n",
      "tensor([1., 0.]) tensor([0.8958, 0.1042], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 50 - 38: cat - cat || Loss: 0.4172571301460266\n",
      "tensor([1., 0.]) tensor([0.8960, 0.1040], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 50 - 39: cat - cat || Loss: 0.4170255661010742\n",
      "tensor([1., 0.]) tensor([0.8962, 0.1038], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 50 - 40: cat - cat || Loss: 0.4167938828468323\n",
      "tensor([1., 0.]) tensor([0.8965, 0.1035], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 50 - 41: cat - cat || Loss: 0.4165618121623993\n",
      "tensor([1., 0.]) tensor([0.8967, 0.1033], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 50 - 42: cat - cat || Loss: 0.41632983088493347\n",
      "tensor([1., 0.]) tensor([0.8969, 0.1031], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 50 - 43: cat - cat || Loss: 0.41609764099121094\n",
      "tensor([1., 0.]) tensor([0.8972, 0.1028], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 50 - 44: cat - cat || Loss: 0.41586562991142273\n",
      "tensor([1., 0.]) tensor([0.8974, 0.1026], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 50 - 45: cat - cat || Loss: 0.4156336188316345\n",
      "tensor([1., 0.]) tensor([0.8976, 0.1024], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 50 - 46: cat - cat || Loss: 0.41540175676345825\n",
      "tensor([1., 0.]) tensor([0.8979, 0.1021], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 50 - 47: cat - cat || Loss: 0.4151700735092163\n",
      "tensor([1., 0.]) tensor([0.8981, 0.1019], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 50 - 48: cat - cat || Loss: 0.41493862867355347\n",
      "tensor([1., 0.]) tensor([0.8983, 0.1017], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 50 - 49: cat - cat || Loss: 0.4147074222564697\n",
      "tensor([1., 0.]) tensor([0.8986, 0.1014], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 50 - 50: cat - cat || Loss: 0.41447654366493225\n",
      "tensor([1., 0.]) tensor([0.8988, 0.1012], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 50 - 51: cat - cat || Loss: 0.41424599289894104\n",
      "tensor([1., 0.]) tensor([0.8990, 0.1010], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 50 - 52: cat - cat || Loss: 0.4140157699584961\n",
      "tensor([1., 0.]) tensor([0.8992, 0.1008], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 50 - 53: cat - cat || Loss: 0.413785845041275\n",
      "tensor([1., 0.]) tensor([0.8995, 0.1005], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 50 - 54: cat - cat || Loss: 0.4135563373565674\n",
      "tensor([1., 0.]) tensor([0.8997, 0.1003], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 50 - 55: cat - cat || Loss: 0.41332724690437317\n",
      "tensor([1., 0.]) tensor([0.8999, 0.1001], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 50 - 56: cat - cat || Loss: 0.4130985736846924\n",
      "tensor([1., 0.]) tensor([0.9002, 0.0998], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 50 - 57: cat - cat || Loss: 0.412870317697525\n",
      "tensor([1., 0.]) tensor([0.9004, 0.0996], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 50 - 58: cat - cat || Loss: 0.41264253854751587\n",
      "tensor([1., 0.]) tensor([0.9006, 0.0994], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 50 - 59: cat - cat || Loss: 0.41241520643234253\n",
      "tensor([1., 0.]) tensor([0.9008, 0.0992], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 50 - 60: cat - cat || Loss: 0.4121883511543274\n",
      "tensor([1., 0.]) tensor([0.9011, 0.0989], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 50 - 61: cat - cat || Loss: 0.41196194291114807\n",
      "tensor([1., 0.]) tensor([0.9013, 0.0987], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 50 - 62: cat - cat || Loss: 0.41173607110977173\n",
      "tensor([1., 0.]) tensor([0.9015, 0.0985], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 50 - 63: cat - cat || Loss: 0.4115106761455536\n",
      "tensor([1., 0.]) tensor([0.9018, 0.0982], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 50 - 64: cat - cat || Loss: 0.41128575801849365\n",
      "tensor([1., 0.]) tensor([0.9020, 0.0980], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 50 - 65: cat - cat || Loss: 0.4110614061355591\n",
      "tensor([1., 0.]) tensor([0.9022, 0.0978], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 50 - 66: cat - cat || Loss: 0.41083744168281555\n",
      "tensor([1., 0.]) tensor([0.9024, 0.0976], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 50 - 67: cat - cat || Loss: 0.4106141924858093\n",
      "tensor([1., 0.]) tensor([0.9026, 0.0974], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 50 - 68: cat - cat || Loss: 0.41039133071899414\n",
      "tensor([1., 0.]) tensor([0.9029, 0.0971], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 50 - 69: cat - cat || Loss: 0.41016897559165955\n",
      "tensor([1., 0.]) tensor([0.9031, 0.0969], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 50 - 70: cat - cat || Loss: 0.4099472165107727\n",
      "tensor([1., 0.]) tensor([0.9033, 0.0967], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 50 - 71: cat - cat || Loss: 0.40972596406936646\n",
      "tensor([1., 0.]) tensor([0.9035, 0.0965], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 50 - 72: cat - cat || Loss: 0.4095052182674408\n",
      "tensor([1., 0.]) tensor([0.9038, 0.0962], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 50 - 73: cat - cat || Loss: 0.40928491950035095\n",
      "tensor([1., 0.]) tensor([0.9040, 0.0960], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 50 - 74: cat - cat || Loss: 0.40906521677970886\n",
      "tensor([1., 0.]) tensor([0.9042, 0.0958], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 50 - 75: cat - cat || Loss: 0.4088461399078369\n",
      "tensor([1., 0.]) tensor([0.9044, 0.0956], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 50 - 76: cat - cat || Loss: 0.40862756967544556\n",
      "tensor([1., 0.]) tensor([0.9046, 0.0954], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 50 - 77: cat - cat || Loss: 0.4084095060825348\n",
      "tensor([1., 0.]) tensor([0.9049, 0.0951], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 50 - 78: cat - cat || Loss: 0.40819188952445984\n",
      "tensor([1., 0.]) tensor([0.9051, 0.0949], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 50 - 79: cat - cat || Loss: 0.40797489881515503\n",
      "tensor([1., 0.]) tensor([0.9053, 0.0947], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 50 - 80: cat - cat || Loss: 0.4077584147453308\n",
      "tensor([1., 0.]) tensor([0.9055, 0.0945], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 50 - 81: cat - cat || Loss: 0.4075424075126648\n",
      "tensor([1., 0.]) tensor([0.9057, 0.0943], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 50 - 82: cat - cat || Loss: 0.40732699632644653\n",
      "tensor([1., 0.]) tensor([0.9059, 0.0941], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 50 - 83: cat - cat || Loss: 0.407112181186676\n",
      "tensor([1., 0.]) tensor([0.9061, 0.0939], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 50 - 84: cat - cat || Loss: 0.4068979024887085\n",
      "tensor([1., 0.]) tensor([0.9064, 0.0936], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 50 - 85: cat - cat || Loss: 0.40668413043022156\n",
      "tensor([1., 0.]) tensor([0.9066, 0.0934], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 50 - 86: cat - cat || Loss: 0.4064708948135376\n",
      "tensor([1., 0.]) tensor([0.9068, 0.0932], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 50 - 87: cat - cat || Loss: 0.4062581956386566\n",
      "tensor([1., 0.]) tensor([0.9070, 0.0930], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 50 - 88: cat - cat || Loss: 0.406046062707901\n",
      "tensor([1., 0.]) tensor([0.9072, 0.0928], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 50 - 89: cat - cat || Loss: 0.40583449602127075\n",
      "tensor([1., 0.]) tensor([0.9074, 0.0926], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 50 - 90: cat - cat || Loss: 0.4056233763694763\n",
      "tensor([1., 0.]) tensor([0.9076, 0.0924], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 50 - 91: cat - cat || Loss: 0.40541279315948486\n",
      "tensor([1., 0.]) tensor([0.9078, 0.0922], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 50 - 92: cat - cat || Loss: 0.4052027463912964\n",
      "tensor([1., 0.]) tensor([0.9081, 0.0919], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 50 - 93: cat - cat || Loss: 0.4049932062625885\n",
      "tensor([1., 0.]) tensor([0.9083, 0.0917], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 50 - 94: cat - cat || Loss: 0.404784232378006\n",
      "tensor([1., 0.]) tensor([0.9085, 0.0915], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 50 - 95: cat - cat || Loss: 0.40457576513290405\n",
      "tensor([1., 0.]) tensor([0.9087, 0.0913], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 50 - 96: cat - cat || Loss: 0.4043678343296051\n",
      "tensor([1., 0.]) tensor([0.9089, 0.0911], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 50 - 97: cat - cat || Loss: 0.4041604697704315\n",
      "tensor([1., 0.]) tensor([0.9091, 0.0909], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 50 - 98: cat - cat || Loss: 0.40395355224609375\n",
      "tensor([1., 0.]) tensor([0.9093, 0.0907], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 50 - 99: cat - cat || Loss: 0.4037472605705261\n",
      "tensor([1., 0.]) tensor([0.9095, 0.0905], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 50 - 100: cat - cat || Loss: 0.4035413861274719\n",
      "tensor([1., 0.]) tensor([0.9097, 0.0903], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 50 - 101: cat - cat || Loss: 0.40333616733551025\n",
      "tensor([1., 0.]) tensor([0.9099, 0.0901], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 50 - 102: cat - cat || Loss: 0.403131365776062\n",
      "tensor([1., 0.]) tensor([0.9101, 0.0899], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 50 - 103: cat - cat || Loss: 0.402927041053772\n",
      "tensor([1., 0.]) tensor([0.9103, 0.0897], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 50 - 104: cat - cat || Loss: 0.4027233123779297\n",
      "tensor([1., 0.]) tensor([0.9105, 0.0895], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 50 - 105: cat - cat || Loss: 0.4025200307369232\n",
      "tensor([1., 0.]) tensor([0.9107, 0.0893], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 50 - 106: cat - cat || Loss: 0.4023173451423645\n",
      "tensor([1., 0.]) tensor([0.9109, 0.0891], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 50 - 107: cat - cat || Loss: 0.4021151065826416\n",
      "tensor([1., 0.]) tensor([0.9111, 0.0889], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 50 - 108: cat - cat || Loss: 0.40191343426704407\n",
      "tensor([1., 0.]) tensor([0.9113, 0.0887], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 50 - 109: cat - cat || Loss: 0.40171220898628235\n",
      "tensor([1., 0.]) tensor([0.9115, 0.0885], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 50 - 110: cat - cat || Loss: 0.4015114903450012\n",
      "tensor([1., 0.]) tensor([0.9118, 0.0882], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 50 - 111: cat - cat || Loss: 0.40131136775016785\n",
      "tensor([1., 0.]) tensor([0.9120, 0.0880], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 50 - 112: cat - cat || Loss: 0.40111157298088074\n",
      "tensor([1., 0.]) tensor([0.9122, 0.0878], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 50 - 113: cat - cat || Loss: 0.40091246366500854\n",
      "tensor([1., 0.]) tensor([0.9123, 0.0877], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 50 - 114: cat - cat || Loss: 0.4007137715816498\n",
      "tensor([1., 0.]) tensor([0.9125, 0.0875], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 50 - 115: cat - cat || Loss: 0.4005156457424164\n",
      "tensor([1., 0.]) tensor([0.9127, 0.0873], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 50 - 116: cat - cat || Loss: 0.4003180265426636\n",
      "tensor([1., 0.]) tensor([0.9129, 0.0871], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 50 - 117: cat - cat || Loss: 0.4001208543777466\n",
      "tensor([1., 0.]) tensor([0.9131, 0.0869], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 50 - 118: cat - cat || Loss: 0.3999241888523102\n",
      "tensor([1., 0.]) tensor([0.9133, 0.0867], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 50 - 119: cat - cat || Loss: 0.39972805976867676\n",
      "tensor([1., 0.]) tensor([0.9135, 0.0865], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 50 - 120: cat - cat || Loss: 0.39953234791755676\n",
      "tensor([1., 0.]) tensor([0.9137, 0.0863], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 50 - 121: cat - cat || Loss: 0.39933711290359497\n",
      "tensor([1., 0.]) tensor([0.9139, 0.0861], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 50 - 122: cat - cat || Loss: 0.39914247393608093\n",
      "tensor([1., 0.]) tensor([0.9141, 0.0859], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 50 - 123: cat - cat || Loss: 0.3989483118057251\n",
      "tensor([1., 0.]) tensor([0.9143, 0.0857], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 50 - 124: cat - cat || Loss: 0.39875468611717224\n",
      "tensor([1., 0.]) tensor([0.9145, 0.0855], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 50 - 125: cat - cat || Loss: 0.3985614776611328\n",
      "tensor([1., 0.]) tensor([0.9147, 0.0853], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 50 - 126: cat - cat || Loss: 0.398368775844574\n",
      "tensor([1., 0.]) tensor([0.9149, 0.0851], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 50 - 127: cat - cat || Loss: 0.39817652106285095\n",
      "tensor([1., 0.]) tensor([0.9151, 0.0849], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 50 - 128: cat - cat || Loss: 0.3979848325252533\n",
      "tensor([1., 0.]) tensor([0.9153, 0.0847], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 50 - 129: cat - cat || Loss: 0.39779356122016907\n",
      "tensor([1., 0.]) tensor([0.9155, 0.0845], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 50 - 130: cat - cat || Loss: 0.3976028561592102\n",
      "tensor([1., 0.]) tensor([0.9157, 0.0843], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 50 - 131: cat - cat || Loss: 0.39741250872612\n",
      "tensor([1., 0.]) tensor([0.9158, 0.0842], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 50 - 132: cat - cat || Loss: 0.39722269773483276\n",
      "tensor([1., 0.]) tensor([0.9160, 0.0840], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 50 - 133: cat - cat || Loss: 0.3970333933830261\n",
      "tensor([1., 0.]) tensor([0.9162, 0.0838], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 50 - 134: cat - cat || Loss: 0.3968445658683777\n",
      "tensor([1., 0.]) tensor([0.9164, 0.0836], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 50 - 135: cat - cat || Loss: 0.3966562747955322\n",
      "tensor([1., 0.]) tensor([0.9166, 0.0834], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 50 - 136: cat - cat || Loss: 0.3964684009552002\n",
      "tensor([1., 0.]) tensor([0.9168, 0.0832], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 50 - 137: cat - cat || Loss: 0.3962809443473816\n",
      "tensor([1., 0.]) tensor([0.9170, 0.0830], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 50 - 138: cat - cat || Loss: 0.39609402418136597\n",
      "tensor([1., 0.]) tensor([0.9172, 0.0828], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 50 - 139: cat - cat || Loss: 0.39590755105018616\n",
      "tensor([1., 0.]) tensor([0.9174, 0.0826], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 50 - 140: cat - cat || Loss: 0.39572152495384216\n",
      "tensor([1., 0.]) tensor([0.9175, 0.0825], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 50 - 141: cat - cat || Loss: 0.39553600549697876\n",
      "tensor([1., 0.]) tensor([0.9177, 0.0823], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 50 - 142: cat - cat || Loss: 0.39535099267959595\n",
      "tensor([1., 0.]) tensor([0.9179, 0.0821], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 50 - 143: cat - cat || Loss: 0.39516642689704895\n",
      "tensor([1., 0.]) tensor([0.9181, 0.0819], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 50 - 144: cat - cat || Loss: 0.39498236775398254\n",
      "tensor([1., 0.]) tensor([0.9183, 0.0817], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 50 - 145: cat - cat || Loss: 0.39479875564575195\n",
      "tensor([1., 0.]) tensor([0.9185, 0.0815], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 50 - 146: cat - cat || Loss: 0.3946155309677124\n",
      "tensor([1., 0.]) tensor([0.9186, 0.0814], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 50 - 147: cat - cat || Loss: 0.3944329023361206\n",
      "tensor([1., 0.]) tensor([0.9188, 0.0812], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 50 - 148: cat - cat || Loss: 0.39425066113471985\n",
      "tensor([1., 0.]) tensor([0.9190, 0.0810], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 50 - 149: cat - cat || Loss: 0.3940688967704773\n",
      "tensor([1., 0.]) tensor([0.9192, 0.0808], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 50 - 150: cat - cat || Loss: 0.3938874900341034\n",
      "tensor([1., 0.]) tensor([0.9194, 0.0806], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 50 - 151: cat - cat || Loss: 0.393706738948822\n",
      "tensor([1., 0.]) tensor([0.9196, 0.0804], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 50 - 152: cat - cat || Loss: 0.3935263156890869\n",
      "tensor([1., 0.]) tensor([0.9197, 0.0803], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 50 - 153: cat - cat || Loss: 0.3933463394641876\n",
      "tensor([1., 0.]) tensor([0.9199, 0.0801], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 50 - 154: cat - cat || Loss: 0.3931668996810913\n",
      "tensor([1., 0.]) tensor([0.9201, 0.0799], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 50 - 155: cat - cat || Loss: 0.39298781752586365\n",
      "tensor([1., 0.]) tensor([0.9203, 0.0797], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 50 - 156: cat - cat || Loss: 0.39280927181243896\n",
      "tensor([1., 0.]) tensor([0.9205, 0.0795], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 50 - 157: cat - cat || Loss: 0.3926312327384949\n",
      "tensor([1., 0.]) tensor([0.9206, 0.0794], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 50 - 158: cat - cat || Loss: 0.39245346188545227\n",
      "tensor([1., 0.]) tensor([0.9208, 0.0792], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 50 - 159: cat - cat || Loss: 0.3922762870788574\n",
      "tensor([1., 0.]) tensor([0.9210, 0.0790], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 50 - 160: cat - cat || Loss: 0.39209944009780884\n",
      "tensor([1., 0.]) tensor([0.9212, 0.0788], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 50 - 161: cat - cat || Loss: 0.39192312955856323\n",
      "tensor([1., 0.]) tensor([0.9213, 0.0787], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 50 - 162: cat - cat || Loss: 0.3917473554611206\n",
      "tensor([1., 0.]) tensor([0.9215, 0.0785], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 50 - 163: cat - cat || Loss: 0.39157184958457947\n",
      "tensor([1., 0.]) tensor([0.9217, 0.0783], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 50 - 164: cat - cat || Loss: 0.3913968801498413\n",
      "tensor([1., 0.]) tensor([0.9219, 0.0781], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 50 - 165: cat - cat || Loss: 0.39122235774993896\n",
      "tensor([1., 0.]) tensor([0.9220, 0.0780], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 50 - 166: cat - cat || Loss: 0.3910481631755829\n",
      "tensor([1., 0.]) tensor([0.9222, 0.0778], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 50 - 167: cat - cat || Loss: 0.39087456464767456\n",
      "tensor([1., 0.]) tensor([0.9224, 0.0776], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 50 - 168: cat - cat || Loss: 0.3907013237476349\n",
      "tensor([1., 0.]) tensor([0.9226, 0.0774], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 50 - 169: cat - cat || Loss: 0.39052850008010864\n",
      "tensor([1., 0.]) tensor([0.9227, 0.0773], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 50 - 170: cat - cat || Loss: 0.3903561532497406\n",
      "tensor([1., 0.]) tensor([0.9229, 0.0771], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 50 - 171: cat - cat || Loss: 0.39018431305885315\n",
      "tensor([1., 0.]) tensor([0.9231, 0.0769], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 50 - 172: cat - cat || Loss: 0.39001283049583435\n",
      "tensor([1., 0.]) tensor([0.9232, 0.0768], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 50 - 173: cat - cat || Loss: 0.38984179496765137\n",
      "tensor([1., 0.]) tensor([0.9234, 0.0766], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 50 - 174: cat - cat || Loss: 0.3896711766719818\n",
      "tensor([1., 0.]) tensor([0.9236, 0.0764], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 50 - 175: cat - cat || Loss: 0.3895009458065033\n",
      "tensor([1., 0.]) tensor([0.9238, 0.0762], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 50 - 176: cat - cat || Loss: 0.389331191778183\n",
      "tensor([1., 0.]) tensor([0.9239, 0.0761], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 50 - 177: cat - cat || Loss: 0.3891618251800537\n",
      "tensor([1., 0.]) tensor([0.9241, 0.0759], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 50 - 178: cat - cat || Loss: 0.38899287581443787\n",
      "tensor([1., 0.]) tensor([0.9243, 0.0757], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 50 - 179: cat - cat || Loss: 0.38882437348365784\n",
      "tensor([1., 0.]) tensor([0.9244, 0.0756], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 50 - 180: cat - cat || Loss: 0.38865622878074646\n",
      "tensor([1., 0.]) tensor([0.9246, 0.0754], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 50 - 181: cat - cat || Loss: 0.3884884715080261\n",
      "tensor([1., 0.]) tensor([0.9248, 0.0752], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 50 - 182: cat - cat || Loss: 0.3883212208747864\n",
      "tensor([1., 0.]) tensor([0.9249, 0.0751], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 50 - 183: cat - cat || Loss: 0.38815444707870483\n",
      "tensor([1., 0.]) tensor([0.9251, 0.0749], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 50 - 184: cat - cat || Loss: 0.38798788189888\n",
      "tensor([1., 0.]) tensor([0.9253, 0.0747], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 50 - 185: cat - cat || Loss: 0.38782188296318054\n",
      "tensor([1., 0.]) tensor([0.9254, 0.0746], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 50 - 186: cat - cat || Loss: 0.3876560926437378\n",
      "tensor([1., 0.]) tensor([0.9256, 0.0744], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 50 - 187: cat - cat || Loss: 0.38749080896377563\n",
      "tensor([1., 0.]) tensor([0.9258, 0.0742], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 50 - 188: cat - cat || Loss: 0.3873259127140045\n",
      "tensor([1., 0.]) tensor([0.9259, 0.0741], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 50 - 189: cat - cat || Loss: 0.38716137409210205\n",
      "tensor([1., 0.]) tensor([0.9261, 0.0739], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 50 - 190: dog - cat || Loss: 1.2395259141921997\n",
      "tensor([0., 1.]) tensor([0.9263, 0.0737], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 50 - 191: dog - cat || Loss: 1.2396574020385742\n",
      "tensor([0., 1.]) tensor([0.9264, 0.0736], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 50 - 192: dog - cat || Loss: 1.2397593259811401\n",
      "tensor([0., 1.]) tensor([0.9265, 0.0735], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 50 - 193: dog - cat || Loss: 1.2398347854614258\n",
      "tensor([0., 1.]) tensor([0.9266, 0.0734], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 50 - 194: dog - cat || Loss: 1.2398865222930908\n",
      "tensor([0., 1.]) tensor([0.9266, 0.0734], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 50 - 195: dog - cat || Loss: 1.2399169206619263\n",
      "tensor([0., 1.]) tensor([0.9267, 0.0733], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 50 - 196: dog - cat || Loss: 1.2399282455444336\n",
      "tensor([0., 1.]) tensor([0.9267, 0.0733], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 50 - 197: dog - cat || Loss: 1.2399221658706665\n",
      "tensor([0., 1.]) tensor([0.9267, 0.0733], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 50 - 198: dog - cat || Loss: 1.2399005889892578\n",
      "tensor([0., 1.]) tensor([0.9266, 0.0734], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 50 - 199: dog - cat || Loss: 1.2398650646209717\n",
      "tensor([0., 1.]) tensor([0.9266, 0.0734], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 50 - 200: dog - cat || Loss: 1.2398169040679932\n",
      "tensor([0., 1.]) tensor([0.9266, 0.0734], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 50 - 201: dog - cat || Loss: 1.2397575378417969\n",
      "tensor([0., 1.]) tensor([0.9265, 0.0735], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 50 - 202: dog - cat || Loss: 1.2396876811981201\n",
      "tensor([0., 1.]) tensor([0.9264, 0.0736], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 50 - 203: dog - cat || Loss: 1.239608645439148\n",
      "tensor([0., 1.]) tensor([0.9263, 0.0737], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 50 - 204: dog - cat || Loss: 1.2395215034484863\n",
      "tensor([0., 1.]) tensor([0.9263, 0.0737], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 50 - 205: dog - cat || Loss: 1.239426612854004\n",
      "tensor([0., 1.]) tensor([0.9262, 0.0738], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 50 - 206: dog - cat || Loss: 1.239324927330017\n",
      "tensor([0., 1.]) tensor([0.9261, 0.0739], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 50 - 207: dog - cat || Loss: 1.2392171621322632\n",
      "tensor([0., 1.]) tensor([0.9260, 0.0740], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 50 - 208: dog - cat || Loss: 1.2391037940979004\n",
      "tensor([0., 1.]) tensor([0.9258, 0.0742], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 50 - 209: dog - cat || Loss: 1.2389854192733765\n",
      "tensor([0., 1.]) tensor([0.9257, 0.0743], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 50 - 210: dog - cat || Loss: 1.23886239528656\n",
      "tensor([0., 1.]) tensor([0.9256, 0.0744], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 50 - 211: dog - cat || Loss: 1.2387351989746094\n",
      "tensor([0., 1.]) tensor([0.9255, 0.0745], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 50 - 212: dog - cat || Loss: 1.2386043071746826\n",
      "tensor([0., 1.]) tensor([0.9253, 0.0747], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 50 - 213: dog - cat || Loss: 1.2384700775146484\n",
      "tensor([0., 1.]) tensor([0.9252, 0.0748], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 50 - 214: dog - cat || Loss: 1.2383326292037964\n",
      "tensor([0., 1.]) tensor([0.9251, 0.0749], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 50 - 215: dog - cat || Loss: 1.2381922006607056\n",
      "tensor([0., 1.]) tensor([0.9249, 0.0751], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 50 - 216: dog - cat || Loss: 1.2380492687225342\n",
      "tensor([0., 1.]) tensor([0.9248, 0.0752], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 50 - 217: dog - cat || Loss: 1.2379037141799927\n",
      "tensor([0., 1.]) tensor([0.9246, 0.0754], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 50 - 218: dog - cat || Loss: 1.2377562522888184\n",
      "tensor([0., 1.]) tensor([0.9245, 0.0755], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 50 - 219: dog - cat || Loss: 1.2376066446304321\n",
      "tensor([0., 1.]) tensor([0.9243, 0.0757], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 50 - 220: dog - cat || Loss: 1.2374552488327026\n",
      "tensor([0., 1.]) tensor([0.9242, 0.0758], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 50 - 221: dog - cat || Loss: 1.2373020648956299\n",
      "tensor([0., 1.]) tensor([0.9240, 0.0760], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 50 - 222: dog - cat || Loss: 1.2371474504470825\n",
      "tensor([0., 1.]) tensor([0.9239, 0.0761], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 50 - 223: dog - cat || Loss: 1.236991286277771\n",
      "tensor([0., 1.]) tensor([0.9237, 0.0763], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 50 - 224: dog - cat || Loss: 1.2368338108062744\n",
      "tensor([0., 1.]) tensor([0.9236, 0.0764], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 50 - 225: dog - cat || Loss: 1.2366750240325928\n",
      "tensor([0., 1.]) tensor([0.9234, 0.0766], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 50 - 226: dog - cat || Loss: 1.2365151643753052\n",
      "tensor([0., 1.]) tensor([0.9233, 0.0767], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 50 - 227: dog - cat || Loss: 1.236354112625122\n",
      "tensor([0., 1.]) tensor([0.9231, 0.0769], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 50 - 228: dog - cat || Loss: 1.2361918687820435\n",
      "tensor([0., 1.]) tensor([0.9229, 0.0771], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 50 - 229: dog - cat || Loss: 1.2360289096832275\n",
      "tensor([0., 1.]) tensor([0.9228, 0.0772], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 50 - 230: dog - cat || Loss: 1.2358648777008057\n",
      "tensor([0., 1.]) tensor([0.9226, 0.0774], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 50 - 231: dog - cat || Loss: 1.235700011253357\n",
      "tensor([0., 1.]) tensor([0.9224, 0.0776], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 50 - 232: dog - cat || Loss: 1.2355341911315918\n",
      "tensor([0., 1.]) tensor([0.9223, 0.0777], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 50 - 233: dog - cat || Loss: 1.235368013381958\n",
      "tensor([0., 1.]) tensor([0.9221, 0.0779], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 50 - 234: dog - cat || Loss: 1.2352006435394287\n",
      "tensor([0., 1.]) tensor([0.9219, 0.0781], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 50 - 235: dog - cat || Loss: 1.2350326776504517\n",
      "tensor([0., 1.]) tensor([0.9218, 0.0782], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 50 - 236: dog - cat || Loss: 1.2348641157150269\n",
      "tensor([0., 1.]) tensor([0.9216, 0.0784], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 50 - 237: dog - cat || Loss: 1.2346947193145752\n",
      "tensor([0., 1.]) tensor([0.9214, 0.0786], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 50 - 238: dog - cat || Loss: 1.2345248460769653\n",
      "tensor([0., 1.]) tensor([0.9213, 0.0787], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 50 - 239: dog - cat || Loss: 1.2343542575836182\n",
      "tensor([0., 1.]) tensor([0.9211, 0.0789], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 50 - 240: dog - cat || Loss: 1.2341830730438232\n",
      "tensor([0., 1.]) tensor([0.9209, 0.0791], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 50 - 241: dog - cat || Loss: 1.2340112924575806\n",
      "tensor([0., 1.]) tensor([0.9207, 0.0793], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 50 - 242: dog - cat || Loss: 1.2338389158248901\n",
      "tensor([0., 1.]) tensor([0.9206, 0.0794], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 50 - 243: dog - cat || Loss: 1.2336660623550415\n",
      "tensor([0., 1.]) tensor([0.9204, 0.0796], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 50 - 244: dog - cat || Loss: 1.2334928512573242\n",
      "tensor([0., 1.]) tensor([0.9202, 0.0798], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 50 - 245: dog - cat || Loss: 1.2333186864852905\n",
      "tensor([0., 1.]) tensor([0.9201, 0.0799], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 50 - 246: dog - cat || Loss: 1.2331444025039673\n",
      "tensor([0., 1.]) tensor([0.9199, 0.0801], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 50 - 247: dog - cat || Loss: 1.2329692840576172\n",
      "tensor([0., 1.]) tensor([0.9197, 0.0803], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 50 - 248: dog - cat || Loss: 1.2327938079833984\n",
      "tensor([0., 1.]) tensor([0.9195, 0.0805], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 50 - 249: dog - cat || Loss: 1.232617735862732\n",
      "tensor([0., 1.]) tensor([0.9194, 0.0806], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 50 - 250: dog - cat || Loss: 1.2324411869049072\n",
      "tensor([0., 1.]) tensor([0.9192, 0.0808], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 50 - 251: dog - cat || Loss: 1.2322642803192139\n",
      "tensor([0., 1.]) tensor([0.9190, 0.0810], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 50 - 252: dog - cat || Loss: 1.2320870161056519\n",
      "tensor([0., 1.]) tensor([0.9188, 0.0812], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 50 - 253: dog - cat || Loss: 1.2319087982177734\n",
      "tensor([0., 1.]) tensor([0.9186, 0.0814], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 50 - 254: dog - cat || Loss: 1.231730341911316\n",
      "tensor([0., 1.]) tensor([0.9185, 0.0815], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 50 - 255: dog - cat || Loss: 1.2315514087677002\n",
      "tensor([0., 1.]) tensor([0.9183, 0.0817], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 50 - 256: dog - cat || Loss: 1.2313721179962158\n",
      "tensor([0., 1.]) tensor([0.9181, 0.0819], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 50 - 257: dog - cat || Loss: 1.2311923503875732\n",
      "tensor([0., 1.]) tensor([0.9179, 0.0821], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 50 - 258: dog - cat || Loss: 1.2310118675231934\n",
      "tensor([0., 1.]) tensor([0.9178, 0.0822], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 50 - 259: dog - cat || Loss: 1.2308311462402344\n",
      "tensor([0., 1.]) tensor([0.9176, 0.0824], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 50 - 260: dog - cat || Loss: 1.2306498289108276\n",
      "tensor([0., 1.]) tensor([0.9174, 0.0826], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 50 - 261: dog - cat || Loss: 1.2304680347442627\n",
      "tensor([0., 1.]) tensor([0.9172, 0.0828], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 50 - 262: dog - cat || Loss: 1.230285882949829\n",
      "tensor([0., 1.]) tensor([0.9170, 0.0830], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 50 - 263: dog - cat || Loss: 1.2301031351089478\n",
      "tensor([0., 1.]) tensor([0.9168, 0.0832], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 50 - 264: dog - cat || Loss: 1.2299200296401978\n",
      "tensor([0., 1.]) tensor([0.9167, 0.0833], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 50 - 265: dog - cat || Loss: 1.229736566543579\n",
      "tensor([0., 1.]) tensor([0.9165, 0.0835], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 50 - 266: dog - cat || Loss: 1.2295522689819336\n",
      "tensor([0., 1.]) tensor([0.9163, 0.0837], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 50 - 267: dog - cat || Loss: 1.229367971420288\n",
      "tensor([0., 1.]) tensor([0.9161, 0.0839], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 50 - 268: dog - cat || Loss: 1.2291829586029053\n",
      "tensor([0., 1.]) tensor([0.9159, 0.0841], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 50 - 269: dog - cat || Loss: 1.2289975881576538\n",
      "tensor([0., 1.]) tensor([0.9157, 0.0843], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 50 - 270: dog - cat || Loss: 1.228811502456665\n",
      "tensor([0., 1.]) tensor([0.9155, 0.0845], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 50 - 271: dog - cat || Loss: 1.2286252975463867\n",
      "tensor([0., 1.]) tensor([0.9154, 0.0846], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 50 - 272: dog - cat || Loss: 1.228438377380371\n",
      "tensor([0., 1.]) tensor([0.9152, 0.0848], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 50 - 273: dog - cat || Loss: 1.2282509803771973\n",
      "tensor([0., 1.]) tensor([0.9150, 0.0850], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 50 - 274: dog - cat || Loss: 1.2280632257461548\n",
      "tensor([0., 1.]) tensor([0.9148, 0.0852], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 50 - 275: dog - cat || Loss: 1.227874994277954\n",
      "tensor([0., 1.]) tensor([0.9146, 0.0854], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 50 - 276: dog - cat || Loss: 1.2276862859725952\n",
      "tensor([0., 1.]) tensor([0.9144, 0.0856], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 50 - 277: dog - cat || Loss: 1.2274969816207886\n",
      "tensor([0., 1.]) tensor([0.9142, 0.0858], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 50 - 278: dog - cat || Loss: 1.2273074388504028\n",
      "tensor([0., 1.]) tensor([0.9140, 0.0860], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 50 - 279: dog - cat || Loss: 1.2271173000335693\n",
      "tensor([0., 1.]) tensor([0.9139, 0.0861], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 50 - 280: dog - cat || Loss: 1.2269266843795776\n",
      "tensor([0., 1.]) tensor([0.9137, 0.0863], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 50 - 281: dog - cat || Loss: 1.2267357110977173\n",
      "tensor([0., 1.]) tensor([0.9135, 0.0865], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 50 - 282: dog - cat || Loss: 1.2265442609786987\n",
      "tensor([0., 1.]) tensor([0.9133, 0.0867], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 50 - 283: dog - cat || Loss: 1.2263522148132324\n",
      "tensor([0., 1.]) tensor([0.9131, 0.0869], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 50 - 284: dog - cat || Loss: 1.2261595726013184\n",
      "tensor([0., 1.]) tensor([0.9129, 0.0871], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 50 - 285: dog - cat || Loss: 1.2259665727615356\n",
      "tensor([0., 1.]) tensor([0.9127, 0.0873], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 50 - 286: dog - cat || Loss: 1.2257732152938843\n",
      "tensor([0., 1.]) tensor([0.9125, 0.0875], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 50 - 287: dog - cat || Loss: 1.2255792617797852\n",
      "tensor([0., 1.]) tensor([0.9123, 0.0877], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 50 - 288: dog - cat || Loss: 1.225385069847107\n",
      "tensor([0., 1.]) tensor([0.9121, 0.0879], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 50 - 289: dog - cat || Loss: 1.2251900434494019\n",
      "tensor([0., 1.]) tensor([0.9119, 0.0881], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 50 - 290: dog - cat || Loss: 1.2249947786331177\n",
      "tensor([0., 1.]) tensor([0.9117, 0.0883], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 50 - 291: dog - cat || Loss: 1.2247989177703857\n",
      "tensor([0., 1.]) tensor([0.9115, 0.0885], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 50 - 292: dog - cat || Loss: 1.2246025800704956\n",
      "tensor([0., 1.]) tensor([0.9113, 0.0887], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 50 - 293: dog - cat || Loss: 1.2244057655334473\n",
      "tensor([0., 1.]) tensor([0.9111, 0.0889], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 50 - 294: dog - cat || Loss: 1.2242085933685303\n",
      "tensor([0., 1.]) tensor([0.9109, 0.0891], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 50 - 295: dog - cat || Loss: 1.2240105867385864\n",
      "tensor([0., 1.]) tensor([0.9107, 0.0893], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 50 - 296: dog - cat || Loss: 1.2238123416900635\n",
      "tensor([0., 1.]) tensor([0.9106, 0.0894], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 50 - 297: dog - cat || Loss: 1.2236135005950928\n",
      "tensor([0., 1.]) tensor([0.9104, 0.0896], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 50 - 298: dog - cat || Loss: 1.223414421081543\n",
      "tensor([0., 1.]) tensor([0.9102, 0.0898], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 50 - 299: dog - cat || Loss: 1.2232147455215454\n",
      "tensor([0., 1.]) tensor([0.9100, 0.0900], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 50 - 300: dog - cat || Loss: 1.2230143547058105\n",
      "tensor([0., 1.]) tensor([0.9098, 0.0902], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 50 - 301: dog - cat || Loss: 1.222813606262207\n",
      "tensor([0., 1.]) tensor([0.9096, 0.0904], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 50 - 302: dog - cat || Loss: 1.2226125001907349\n",
      "tensor([0., 1.]) tensor([0.9094, 0.0906], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 50 - 303: dog - cat || Loss: 1.222410798072815\n",
      "tensor([0., 1.]) tensor([0.9091, 0.0909], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 50 - 304: dog - cat || Loss: 1.2222084999084473\n",
      "tensor([0., 1.]) tensor([0.9089, 0.0911], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 50 - 305: dog - cat || Loss: 1.222005844116211\n",
      "tensor([0., 1.]) tensor([0.9087, 0.0913], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 50 - 306: dog - cat || Loss: 1.2218025922775269\n",
      "tensor([0., 1.]) tensor([0.9085, 0.0915], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 50 - 307: dog - cat || Loss: 1.221598744392395\n",
      "tensor([0., 1.]) tensor([0.9083, 0.0917], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 50 - 308: dog - cat || Loss: 1.2213945388793945\n",
      "tensor([0., 1.]) tensor([0.9081, 0.0919], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 50 - 309: dog - cat || Loss: 1.2211899757385254\n",
      "tensor([0., 1.]) tensor([0.9079, 0.0921], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 50 - 310: dog - cat || Loss: 1.2209845781326294\n",
      "tensor([0., 1.]) tensor([0.9077, 0.0923], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 50 - 311: dog - cat || Loss: 1.2207788228988647\n",
      "tensor([0., 1.]) tensor([0.9075, 0.0925], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 50 - 312: dog - cat || Loss: 1.2205727100372314\n",
      "tensor([0., 1.]) tensor([0.9073, 0.0927], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 50 - 313: dog - cat || Loss: 1.2203658819198608\n",
      "tensor([0., 1.]) tensor([0.9071, 0.0929], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 50 - 314: dog - cat || Loss: 1.2201586961746216\n",
      "tensor([0., 1.]) tensor([0.9069, 0.0931], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 50 - 315: dog - cat || Loss: 1.2199509143829346\n",
      "tensor([0., 1.]) tensor([0.9067, 0.0933], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 50 - 316: dog - cat || Loss: 1.2197425365447998\n",
      "tensor([0., 1.]) tensor([0.9065, 0.0935], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 50 - 317: dog - cat || Loss: 1.219533920288086\n",
      "tensor([0., 1.]) tensor([0.9063, 0.0937], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 50 - 318: dog - cat || Loss: 1.2193244695663452\n",
      "tensor([0., 1.]) tensor([0.9061, 0.0939], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 50 - 319: dog - cat || Loss: 1.2191147804260254\n",
      "tensor([0., 1.]) tensor([0.9059, 0.0941], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 50 - 320: dog - cat || Loss: 1.2189044952392578\n",
      "tensor([0., 1.]) tensor([0.9056, 0.0944], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 50 - 321: dog - cat || Loss: 1.2186936140060425\n",
      "tensor([0., 1.]) tensor([0.9054, 0.0946], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 50 - 322: dog - cat || Loss: 1.2184823751449585\n",
      "tensor([0., 1.]) tensor([0.9052, 0.0948], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 50 - 323: dog - cat || Loss: 1.2182703018188477\n",
      "tensor([0., 1.]) tensor([0.9050, 0.0950], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 50 - 324: dog - cat || Loss: 1.2180579900741577\n",
      "tensor([0., 1.]) tensor([0.9048, 0.0952], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 50 - 325: dog - cat || Loss: 1.21784508228302\n",
      "tensor([0., 1.]) tensor([0.9046, 0.0954], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 50 - 326: dog - cat || Loss: 1.2176315784454346\n",
      "tensor([0., 1.]) tensor([0.9044, 0.0956], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 50 - 327: dog - cat || Loss: 1.217417597770691\n",
      "tensor([0., 1.]) tensor([0.9042, 0.0958], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 50 - 328: dog - cat || Loss: 1.217203140258789\n",
      "tensor([0., 1.]) tensor([0.9039, 0.0961], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 50 - 329: dog - cat || Loss: 1.2169880867004395\n",
      "tensor([0., 1.]) tensor([0.9037, 0.0963], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 50 - 330: dog - cat || Loss: 1.2167726755142212\n",
      "tensor([0., 1.]) tensor([0.9035, 0.0965], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 50 - 331: dog - cat || Loss: 1.216556429862976\n",
      "tensor([0., 1.]) tensor([0.9033, 0.0967], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 50 - 332: dog - cat || Loss: 1.2163399457931519\n",
      "tensor([0., 1.]) tensor([0.9031, 0.0969], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 50 - 333: dog - cat || Loss: 1.2161228656768799\n",
      "tensor([0., 1.]) tensor([0.9029, 0.0971], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 50 - 334: dog - cat || Loss: 1.215904951095581\n",
      "tensor([0., 1.]) tensor([0.9026, 0.0974], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 50 - 335: dog - cat || Loss: 1.2156866788864136\n",
      "tensor([0., 1.]) tensor([0.9024, 0.0976], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 50 - 336: dog - cat || Loss: 1.2154680490493774\n",
      "tensor([0., 1.]) tensor([0.9022, 0.0978], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 50 - 337: dog - cat || Loss: 1.215248703956604\n",
      "tensor([0., 1.]) tensor([0.9020, 0.0980], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 50 - 338: dog - cat || Loss: 1.2150288820266724\n",
      "tensor([0., 1.]) tensor([0.9018, 0.0982], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 50 - 339: dog - cat || Loss: 1.2148085832595825\n",
      "tensor([0., 1.]) tensor([0.9015, 0.0985], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 50 - 340: dog - cat || Loss: 1.2145875692367554\n",
      "tensor([0., 1.]) tensor([0.9013, 0.0987], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 50 - 341: dog - cat || Loss: 1.2143661975860596\n",
      "tensor([0., 1.]) tensor([0.9011, 0.0989], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 50 - 342: dog - cat || Loss: 1.214143991470337\n",
      "tensor([0., 1.]) tensor([0.9009, 0.0991], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 50 - 343: dog - cat || Loss: 1.2139215469360352\n",
      "tensor([0., 1.]) tensor([0.9007, 0.0993], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 50 - 344: dog - cat || Loss: 1.213698387145996\n",
      "tensor([0., 1.]) tensor([0.9004, 0.0996], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 50 - 345: dog - cat || Loss: 1.2134747505187988\n",
      "tensor([0., 1.]) tensor([0.9002, 0.0998], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 50 - 346: dog - cat || Loss: 1.2132506370544434\n",
      "tensor([0., 1.]) tensor([0.9000, 0.1000], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 50 - 347: dog - cat || Loss: 1.2130259275436401\n",
      "tensor([0., 1.]) tensor([0.8998, 0.1002], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 50 - 348: dog - cat || Loss: 1.2128005027770996\n",
      "tensor([0., 1.]) tensor([0.8995, 0.1005], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 50 - 349: dog - cat || Loss: 1.2125747203826904\n",
      "tensor([0., 1.]) tensor([0.8993, 0.1007], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 50 - 350: dog - cat || Loss: 1.2123481035232544\n",
      "tensor([0., 1.]) tensor([0.8991, 0.1009], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 50 - 351: dog - cat || Loss: 1.2121212482452393\n",
      "tensor([0., 1.]) tensor([0.8989, 0.1011], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 50 - 352: dog - cat || Loss: 1.2118935585021973\n",
      "tensor([0., 1.]) tensor([0.8986, 0.1014], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 50 - 353: dog - cat || Loss: 1.2116657495498657\n",
      "tensor([0., 1.]) tensor([0.8984, 0.1016], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 50 - 354: dog - cat || Loss: 1.2114369869232178\n",
      "tensor([0., 1.]) tensor([0.8982, 0.1018], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 50 - 355: dog - cat || Loss: 1.2112078666687012\n",
      "tensor([0., 1.]) tensor([0.8979, 0.1021], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 50 - 356: dog - cat || Loss: 1.2109781503677368\n",
      "tensor([0., 1.]) tensor([0.8977, 0.1023], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 50 - 357: dog - cat || Loss: 1.2107475996017456\n",
      "tensor([0., 1.]) tensor([0.8975, 0.1025], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 50 - 358: dog - cat || Loss: 1.2105169296264648\n",
      "tensor([0., 1.]) tensor([0.8973, 0.1027], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 50 - 359: dog - cat || Loss: 1.2102853059768677\n",
      "tensor([0., 1.]) tensor([0.8970, 0.1030], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 50 - 360: dog - cat || Loss: 1.2100533246994019\n",
      "tensor([0., 1.]) tensor([0.8968, 0.1032], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 50 - 361: dog - cat || Loss: 1.2098207473754883\n",
      "tensor([0., 1.]) tensor([0.8966, 0.1034], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 50 - 362: dog - cat || Loss: 1.209587574005127\n",
      "tensor([0., 1.]) tensor([0.8963, 0.1037], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 50 - 363: dog - cat || Loss: 1.209354043006897\n",
      "tensor([0., 1.]) tensor([0.8961, 0.1039], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 50 - 364: dog - cat || Loss: 1.2091195583343506\n",
      "tensor([0., 1.]) tensor([0.8959, 0.1041], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 50 - 365: dog - cat || Loss: 1.208884835243225\n",
      "tensor([0., 1.]) tensor([0.8956, 0.1044], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 50 - 366: dog - cat || Loss: 1.2086491584777832\n",
      "tensor([0., 1.]) tensor([0.8954, 0.1046], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 50 - 367: dog - cat || Loss: 1.2084133625030518\n",
      "tensor([0., 1.]) tensor([0.8952, 0.1048], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 50 - 368: dog - cat || Loss: 1.208176851272583\n",
      "tensor([0., 1.]) tensor([0.8949, 0.1051], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 50 - 369: dog - cat || Loss: 1.207939624786377\n",
      "tensor([0., 1.]) tensor([0.8947, 0.1053], grad_fn=<SoftmaxBackward0>)\n",
      "=====epoch:51=====\n",
      "Epoch 51 - 0: cat - cat || Loss: 0.41882145404815674\n",
      "tensor([1., 0.]) tensor([0.8944, 0.1056], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 51 - 1: cat - cat || Loss: 0.4190114438533783\n",
      "tensor([1., 0.]) tensor([0.8943, 0.1057], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 51 - 2: cat - cat || Loss: 0.4191586375236511\n",
      "tensor([1., 0.]) tensor([0.8941, 0.1059], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 51 - 3: cat - cat || Loss: 0.419266939163208\n",
      "tensor([1., 0.]) tensor([0.8940, 0.1060], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 51 - 4: cat - cat || Loss: 0.41934025287628174\n",
      "tensor([1., 0.]) tensor([0.8939, 0.1061], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 51 - 5: cat - cat || Loss: 0.41938209533691406\n",
      "tensor([1., 0.]) tensor([0.8939, 0.1061], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 51 - 6: cat - cat || Loss: 0.4193955063819885\n",
      "tensor([1., 0.]) tensor([0.8939, 0.1061], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 51 - 7: cat - cat || Loss: 0.4193832576274872\n",
      "tensor([1., 0.]) tensor([0.8939, 0.1061], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 51 - 8: cat - cat || Loss: 0.4193481206893921\n",
      "tensor([1., 0.]) tensor([0.8939, 0.1061], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 51 - 9: cat - cat || Loss: 0.4192923307418823\n",
      "tensor([1., 0.]) tensor([0.8940, 0.1060], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 51 - 10: cat - cat || Loss: 0.4192178249359131\n",
      "tensor([1., 0.]) tensor([0.8940, 0.1060], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 51 - 11: cat - cat || Loss: 0.4191267490386963\n",
      "tensor([1., 0.]) tensor([0.8941, 0.1059], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 51 - 12: cat - cat || Loss: 0.4190206527709961\n",
      "tensor([1., 0.]) tensor([0.8942, 0.1058], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 51 - 13: cat - cat || Loss: 0.41890108585357666\n",
      "tensor([1., 0.]) tensor([0.8944, 0.1056], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 51 - 14: cat - cat || Loss: 0.4187695384025574\n",
      "tensor([1., 0.]) tensor([0.8945, 0.1055], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 51 - 15: cat - cat || Loss: 0.4186270236968994\n",
      "tensor([1., 0.]) tensor([0.8946, 0.1054], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 51 - 16: cat - cat || Loss: 0.418474942445755\n",
      "tensor([1., 0.]) tensor([0.8948, 0.1052], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 51 - 17: cat - cat || Loss: 0.4183141589164734\n",
      "tensor([1., 0.]) tensor([0.8949, 0.1051], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 51 - 18: cat - cat || Loss: 0.41814565658569336\n",
      "tensor([1., 0.]) tensor([0.8951, 0.1049], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 51 - 19: cat - cat || Loss: 0.4179701805114746\n",
      "tensor([1., 0.]) tensor([0.8953, 0.1047], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 51 - 20: cat - cat || Loss: 0.4177885055541992\n",
      "tensor([1., 0.]) tensor([0.8955, 0.1045], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 51 - 21: cat - cat || Loss: 0.41760140657424927\n",
      "tensor([1., 0.]) tensor([0.8957, 0.1043], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 51 - 22: cat - cat || Loss: 0.4174094796180725\n",
      "tensor([1., 0.]) tensor([0.8959, 0.1041], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 51 - 23: cat - cat || Loss: 0.41721320152282715\n",
      "tensor([1., 0.]) tensor([0.8960, 0.1040], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 51 - 24: cat - cat || Loss: 0.4170129895210266\n",
      "tensor([1., 0.]) tensor([0.8962, 0.1038], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 51 - 25: cat - cat || Loss: 0.41680940985679626\n",
      "tensor([1., 0.]) tensor([0.8965, 0.1035], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 51 - 26: cat - cat || Loss: 0.41660284996032715\n",
      "tensor([1., 0.]) tensor([0.8967, 0.1033], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 51 - 27: cat - cat || Loss: 0.4163936376571655\n",
      "tensor([1., 0.]) tensor([0.8969, 0.1031], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 51 - 28: cat - cat || Loss: 0.41618219017982483\n",
      "tensor([1., 0.]) tensor([0.8971, 0.1029], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 51 - 29: cat - cat || Loss: 0.41596847772598267\n",
      "tensor([1., 0.]) tensor([0.8973, 0.1027], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 51 - 30: cat - cat || Loss: 0.4157531261444092\n",
      "tensor([1., 0.]) tensor([0.8975, 0.1025], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 51 - 31: cat - cat || Loss: 0.41553616523742676\n",
      "tensor([1., 0.]) tensor([0.8977, 0.1023], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 51 - 32: cat - cat || Loss: 0.4153178930282593\n",
      "tensor([1., 0.]) tensor([0.8979, 0.1021], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 51 - 33: cat - cat || Loss: 0.41509854793548584\n",
      "tensor([1., 0.]) tensor([0.8982, 0.1018], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 51 - 34: cat - cat || Loss: 0.41487812995910645\n",
      "tensor([1., 0.]) tensor([0.8984, 0.1016], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 51 - 35: cat - cat || Loss: 0.41465699672698975\n",
      "tensor([1., 0.]) tensor([0.8986, 0.1014], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 51 - 36: cat - cat || Loss: 0.41443514823913574\n",
      "tensor([1., 0.]) tensor([0.8988, 0.1012], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 51 - 37: cat - cat || Loss: 0.41421273350715637\n",
      "tensor([1., 0.]) tensor([0.8990, 0.1010], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 51 - 38: cat - cat || Loss: 0.4139898419380188\n",
      "tensor([1., 0.]) tensor([0.8993, 0.1007], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 51 - 39: cat - cat || Loss: 0.4137667417526245\n",
      "tensor([1., 0.]) tensor([0.8995, 0.1005], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 51 - 40: cat - cat || Loss: 0.4135434329509735\n",
      "tensor([1., 0.]) tensor([0.8997, 0.1003], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 51 - 41: cat - cat || Loss: 0.41331976652145386\n",
      "tensor([1., 0.]) tensor([0.8999, 0.1001], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 51 - 42: cat - cat || Loss: 0.41309618949890137\n",
      "tensor([1., 0.]) tensor([0.9002, 0.0998], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 51 - 43: cat - cat || Loss: 0.41287243366241455\n",
      "tensor([1., 0.]) tensor([0.9004, 0.0996], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 51 - 44: cat - cat || Loss: 0.41264888644218445\n",
      "tensor([1., 0.]) tensor([0.9006, 0.0994], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 51 - 45: cat - cat || Loss: 0.41242530941963196\n",
      "tensor([1., 0.]) tensor([0.9008, 0.0992], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 51 - 46: cat - cat || Loss: 0.4122018814086914\n",
      "tensor([1., 0.]) tensor([0.9011, 0.0989], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 51 - 47: cat - cat || Loss: 0.4119786024093628\n",
      "tensor([1., 0.]) tensor([0.9013, 0.0987], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 51 - 48: cat - cat || Loss: 0.41175562143325806\n",
      "tensor([1., 0.]) tensor([0.9015, 0.0985], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 51 - 49: cat - cat || Loss: 0.41153275966644287\n",
      "tensor([1., 0.]) tensor([0.9017, 0.0983], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 51 - 50: cat - cat || Loss: 0.4113102853298187\n",
      "tensor([1., 0.]) tensor([0.9020, 0.0980], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 51 - 51: cat - cat || Loss: 0.41108816862106323\n",
      "tensor([1., 0.]) tensor([0.9022, 0.0978], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 51 - 52: cat - cat || Loss: 0.41086626052856445\n",
      "tensor([1., 0.]) tensor([0.9024, 0.0976], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 51 - 53: cat - cat || Loss: 0.4106447398662567\n",
      "tensor([1., 0.]) tensor([0.9026, 0.0974], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 51 - 54: cat - cat || Loss: 0.4104236364364624\n",
      "tensor([1., 0.]) tensor([0.9028, 0.0972], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 51 - 55: cat - cat || Loss: 0.41020289063453674\n",
      "tensor([1., 0.]) tensor([0.9031, 0.0969], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 51 - 56: cat - cat || Loss: 0.4099826216697693\n",
      "tensor([1., 0.]) tensor([0.9033, 0.0967], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 51 - 57: cat - cat || Loss: 0.4097626805305481\n",
      "tensor([1., 0.]) tensor([0.9035, 0.0965], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 51 - 58: cat - cat || Loss: 0.4095432162284851\n",
      "tensor([1., 0.]) tensor([0.9037, 0.0963], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 51 - 59: cat - cat || Loss: 0.4093242883682251\n",
      "tensor([1., 0.]) tensor([0.9039, 0.0961], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 51 - 60: cat - cat || Loss: 0.40910571813583374\n",
      "tensor([1., 0.]) tensor([0.9042, 0.0958], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 51 - 61: cat - cat || Loss: 0.4088875651359558\n",
      "tensor([1., 0.]) tensor([0.9044, 0.0956], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 51 - 62: cat - cat || Loss: 0.4086698889732361\n",
      "tensor([1., 0.]) tensor([0.9046, 0.0954], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 51 - 63: cat - cat || Loss: 0.4084528684616089\n",
      "tensor([1., 0.]) tensor([0.9048, 0.0952], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 51 - 64: cat - cat || Loss: 0.40823620557785034\n",
      "tensor([1., 0.]) tensor([0.9050, 0.0950], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 51 - 65: cat - cat || Loss: 0.4080200791358948\n",
      "tensor([1., 0.]) tensor([0.9052, 0.0948], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 51 - 66: cat - cat || Loss: 0.40780431032180786\n",
      "tensor([1., 0.]) tensor([0.9055, 0.0945], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 51 - 67: cat - cat || Loss: 0.40758925676345825\n",
      "tensor([1., 0.]) tensor([0.9057, 0.0943], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 51 - 68: cat - cat || Loss: 0.4073745906352997\n",
      "tensor([1., 0.]) tensor([0.9059, 0.0941], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 51 - 69: cat - cat || Loss: 0.4071604609489441\n",
      "tensor([1., 0.]) tensor([0.9061, 0.0939], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 51 - 70: cat - cat || Loss: 0.4069468080997467\n",
      "tensor([1., 0.]) tensor([0.9063, 0.0937], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 51 - 71: cat - cat || Loss: 0.4067337214946747\n",
      "tensor([1., 0.]) tensor([0.9065, 0.0935], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 51 - 72: cat - cat || Loss: 0.4065210819244385\n",
      "tensor([1., 0.]) tensor([0.9067, 0.0933], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 51 - 73: cat - cat || Loss: 0.40630894899368286\n",
      "tensor([1., 0.]) tensor([0.9070, 0.0930], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 51 - 74: cat - cat || Loss: 0.40609729290008545\n",
      "tensor([1., 0.]) tensor([0.9072, 0.0928], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 51 - 75: cat - cat || Loss: 0.40588629245758057\n",
      "tensor([1., 0.]) tensor([0.9074, 0.0926], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 51 - 76: cat - cat || Loss: 0.4056757390499115\n",
      "tensor([1., 0.]) tensor([0.9076, 0.0924], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 51 - 77: cat - cat || Loss: 0.4054657518863678\n",
      "tensor([1., 0.]) tensor([0.9078, 0.0922], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 51 - 78: cat - cat || Loss: 0.4052561819553375\n",
      "tensor([1., 0.]) tensor([0.9080, 0.0920], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 51 - 79: cat - cat || Loss: 0.4050471782684326\n",
      "tensor([1., 0.]) tensor([0.9082, 0.0918], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 51 - 80: cat - cat || Loss: 0.4048386514186859\n",
      "tensor([1., 0.]) tensor([0.9084, 0.0916], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 51 - 81: cat - cat || Loss: 0.4046306610107422\n",
      "tensor([1., 0.]) tensor([0.9086, 0.0914], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 51 - 82: cat - cat || Loss: 0.4044231176376343\n",
      "tensor([1., 0.]) tensor([0.9088, 0.0912], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 51 - 83: cat - cat || Loss: 0.4042162299156189\n",
      "tensor([1., 0.]) tensor([0.9090, 0.0910], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 51 - 84: cat - cat || Loss: 0.4040098786354065\n",
      "tensor([1., 0.]) tensor([0.9093, 0.0907], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 51 - 85: cat - cat || Loss: 0.40380388498306274\n",
      "tensor([1., 0.]) tensor([0.9095, 0.0905], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 51 - 86: cat - cat || Loss: 0.40359851717948914\n",
      "tensor([1., 0.]) tensor([0.9097, 0.0903], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 51 - 87: cat - cat || Loss: 0.40339362621307373\n",
      "tensor([1., 0.]) tensor([0.9099, 0.0901], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 51 - 88: cat - cat || Loss: 0.4031892716884613\n",
      "tensor([1., 0.]) tensor([0.9101, 0.0899], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 51 - 89: cat - cat || Loss: 0.40298545360565186\n",
      "tensor([1., 0.]) tensor([0.9103, 0.0897], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 51 - 90: cat - cat || Loss: 0.402782142162323\n",
      "tensor([1., 0.]) tensor([0.9105, 0.0895], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 51 - 91: cat - cat || Loss: 0.40257924795150757\n",
      "tensor([1., 0.]) tensor([0.9107, 0.0893], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 51 - 92: cat - cat || Loss: 0.4023769795894623\n",
      "tensor([1., 0.]) tensor([0.9109, 0.0891], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 51 - 93: cat - cat || Loss: 0.4021752178668976\n",
      "tensor([1., 0.]) tensor([0.9111, 0.0889], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 51 - 94: cat - cat || Loss: 0.4019738435745239\n",
      "tensor([1., 0.]) tensor([0.9113, 0.0887], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 51 - 95: cat - cat || Loss: 0.401773065328598\n",
      "tensor([1., 0.]) tensor([0.9115, 0.0885], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 51 - 96: cat - cat || Loss: 0.4015728533267975\n",
      "tensor([1., 0.]) tensor([0.9117, 0.0883], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 51 - 97: cat - cat || Loss: 0.4013730585575104\n",
      "tensor([1., 0.]) tensor([0.9119, 0.0881], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 51 - 98: cat - cat || Loss: 0.40117377042770386\n",
      "tensor([1., 0.]) tensor([0.9121, 0.0879], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 51 - 99: cat - cat || Loss: 0.4009750485420227\n",
      "tensor([1., 0.]) tensor([0.9123, 0.0877], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 51 - 100: cat - cat || Loss: 0.40077677369117737\n",
      "tensor([1., 0.]) tensor([0.9125, 0.0875], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 51 - 101: cat - cat || Loss: 0.4005790054798126\n",
      "tensor([1., 0.]) tensor([0.9127, 0.0873], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 51 - 102: cat - cat || Loss: 0.40038174390792847\n",
      "tensor([1., 0.]) tensor([0.9129, 0.0871], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 51 - 103: cat - cat || Loss: 0.4001849889755249\n",
      "tensor([1., 0.]) tensor([0.9131, 0.0869], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 51 - 104: cat - cat || Loss: 0.39998868107795715\n",
      "tensor([1., 0.]) tensor([0.9133, 0.0867], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 51 - 105: cat - cat || Loss: 0.3997929096221924\n",
      "tensor([1., 0.]) tensor([0.9135, 0.0865], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 51 - 106: cat - cat || Loss: 0.3995976448059082\n",
      "tensor([1., 0.]) tensor([0.9137, 0.0863], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 51 - 107: cat - cat || Loss: 0.39940282702445984\n",
      "tensor([1., 0.]) tensor([0.9139, 0.0861], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 51 - 108: cat - cat || Loss: 0.39920860528945923\n",
      "tensor([1., 0.]) tensor([0.9141, 0.0859], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 51 - 109: cat - cat || Loss: 0.39901477098464966\n",
      "tensor([1., 0.]) tensor([0.9142, 0.0858], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 51 - 110: cat - cat || Loss: 0.3988214135169983\n",
      "tensor([1., 0.]) tensor([0.9144, 0.0856], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 51 - 111: cat - cat || Loss: 0.3986286520957947\n",
      "tensor([1., 0.]) tensor([0.9146, 0.0854], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 51 - 112: cat - cat || Loss: 0.3984362781047821\n",
      "tensor([1., 0.]) tensor([0.9148, 0.0852], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 51 - 113: cat - cat || Loss: 0.3982444703578949\n",
      "tensor([1., 0.]) tensor([0.9150, 0.0850], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 51 - 114: cat - cat || Loss: 0.3980531096458435\n",
      "tensor([1., 0.]) tensor([0.9152, 0.0848], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 51 - 115: cat - cat || Loss: 0.3978622555732727\n",
      "tensor([1., 0.]) tensor([0.9154, 0.0846], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 51 - 116: cat - cat || Loss: 0.3976718783378601\n",
      "tensor([1., 0.]) tensor([0.9156, 0.0844], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 51 - 117: cat - cat || Loss: 0.3974820375442505\n",
      "tensor([1., 0.]) tensor([0.9158, 0.0842], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 51 - 118: cat - cat || Loss: 0.3972925543785095\n",
      "tensor([1., 0.]) tensor([0.9160, 0.0840], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 51 - 119: cat - cat || Loss: 0.3971037268638611\n",
      "tensor([1., 0.]) tensor([0.9162, 0.0838], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 51 - 120: cat - cat || Loss: 0.3969151973724365\n",
      "tensor([1., 0.]) tensor([0.9163, 0.0837], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 51 - 121: cat - cat || Loss: 0.39672720432281494\n",
      "tensor([1., 0.]) tensor([0.9165, 0.0835], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 51 - 122: cat - cat || Loss: 0.39653971791267395\n",
      "tensor([1., 0.]) tensor([0.9167, 0.0833], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 51 - 123: cat - cat || Loss: 0.39635270833969116\n",
      "tensor([1., 0.]) tensor([0.9169, 0.0831], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 51 - 124: cat - cat || Loss: 0.3961661159992218\n",
      "tensor([1., 0.]) tensor([0.9171, 0.0829], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 51 - 125: cat - cat || Loss: 0.3959801197052002\n",
      "tensor([1., 0.]) tensor([0.9173, 0.0827], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 51 - 126: cat - cat || Loss: 0.39579451084136963\n",
      "tensor([1., 0.]) tensor([0.9175, 0.0825], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 51 - 127: cat - cat || Loss: 0.3956093192100525\n",
      "tensor([1., 0.]) tensor([0.9177, 0.0823], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 51 - 128: cat - cat || Loss: 0.3954247236251831\n",
      "tensor([1., 0.]) tensor([0.9178, 0.0822], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 51 - 129: cat - cat || Loss: 0.39524045586586\n",
      "tensor([1., 0.]) tensor([0.9180, 0.0820], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 51 - 130: cat - cat || Loss: 0.3950568437576294\n",
      "tensor([1., 0.]) tensor([0.9182, 0.0818], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 51 - 131: cat - cat || Loss: 0.3948734402656555\n",
      "tensor([1., 0.]) tensor([0.9184, 0.0816], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 51 - 132: cat - cat || Loss: 0.394690603017807\n",
      "tensor([1., 0.]) tensor([0.9186, 0.0814], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 51 - 133: cat - cat || Loss: 0.39450833201408386\n",
      "tensor([1., 0.]) tensor([0.9188, 0.0812], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 51 - 134: cat - cat || Loss: 0.39432644844055176\n",
      "tensor([1., 0.]) tensor([0.9189, 0.0811], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 51 - 135: cat - cat || Loss: 0.394145131111145\n",
      "tensor([1., 0.]) tensor([0.9191, 0.0809], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 51 - 136: cat - cat || Loss: 0.39396414160728455\n",
      "tensor([1., 0.]) tensor([0.9193, 0.0807], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 51 - 137: cat - cat || Loss: 0.3937835693359375\n",
      "tensor([1., 0.]) tensor([0.9195, 0.0805], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 51 - 138: cat - cat || Loss: 0.3936035931110382\n",
      "tensor([1., 0.]) tensor([0.9197, 0.0803], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 51 - 139: cat - cat || Loss: 0.39342403411865234\n",
      "tensor([1., 0.]) tensor([0.9198, 0.0802], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 51 - 140: cat - cat || Loss: 0.39324483275413513\n",
      "tensor([1., 0.]) tensor([0.9200, 0.0800], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 51 - 141: cat - cat || Loss: 0.3930661678314209\n",
      "tensor([1., 0.]) tensor([0.9202, 0.0798], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 51 - 142: cat - cat || Loss: 0.3928879201412201\n",
      "tensor([1., 0.]) tensor([0.9204, 0.0796], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 51 - 143: cat - cat || Loss: 0.3927101194858551\n",
      "tensor([1., 0.]) tensor([0.9206, 0.0794], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 51 - 144: cat - cat || Loss: 0.3925328552722931\n",
      "tensor([1., 0.]) tensor([0.9207, 0.0793], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 51 - 145: cat - cat || Loss: 0.3923559784889221\n",
      "tensor([1., 0.]) tensor([0.9209, 0.0791], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 51 - 146: cat - cat || Loss: 0.39217957854270935\n",
      "tensor([1., 0.]) tensor([0.9211, 0.0789], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 51 - 147: cat - cat || Loss: 0.3920036852359772\n",
      "tensor([1., 0.]) tensor([0.9213, 0.0787], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 51 - 148: cat - cat || Loss: 0.39182811975479126\n",
      "tensor([1., 0.]) tensor([0.9214, 0.0786], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 51 - 149: cat - cat || Loss: 0.39165306091308594\n",
      "tensor([1., 0.]) tensor([0.9216, 0.0784], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 51 - 150: cat - cat || Loss: 0.39147838950157166\n",
      "tensor([1., 0.]) tensor([0.9218, 0.0782], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 51 - 151: cat - cat || Loss: 0.39130425453186035\n",
      "tensor([1., 0.]) tensor([0.9220, 0.0780], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 51 - 152: cat - cat || Loss: 0.3911305367946625\n",
      "tensor([1., 0.]) tensor([0.9221, 0.0779], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 51 - 153: cat - cat || Loss: 0.39095720648765564\n",
      "tensor([1., 0.]) tensor([0.9223, 0.0777], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 51 - 154: cat - cat || Loss: 0.3907843232154846\n",
      "tensor([1., 0.]) tensor([0.9225, 0.0775], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 51 - 155: cat - cat || Loss: 0.390611857175827\n",
      "tensor([1., 0.]) tensor([0.9226, 0.0774], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 51 - 156: cat - cat || Loss: 0.3904399275779724\n",
      "tensor([1., 0.]) tensor([0.9228, 0.0772], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 51 - 157: cat - cat || Loss: 0.3902684152126312\n",
      "tensor([1., 0.]) tensor([0.9230, 0.0770], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 51 - 158: cat - cat || Loss: 0.3900972604751587\n",
      "tensor([1., 0.]) tensor([0.9232, 0.0768], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 51 - 159: cat - cat || Loss: 0.3899265229701996\n",
      "tensor([1., 0.]) tensor([0.9233, 0.0767], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 51 - 160: cat - cat || Loss: 0.3897562623023987\n",
      "tensor([1., 0.]) tensor([0.9235, 0.0765], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 51 - 161: cat - cat || Loss: 0.389586478471756\n",
      "tensor([1., 0.]) tensor([0.9237, 0.0763], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 51 - 162: cat - cat || Loss: 0.3894171416759491\n",
      "tensor([1., 0.]) tensor([0.9238, 0.0762], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 51 - 163: cat - cat || Loss: 0.3892481327056885\n",
      "tensor([1., 0.]) tensor([0.9240, 0.0760], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 51 - 164: cat - cat || Loss: 0.38907966017723083\n",
      "tensor([1., 0.]) tensor([0.9242, 0.0758], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 51 - 165: cat - cat || Loss: 0.38891154527664185\n",
      "tensor([1., 0.]) tensor([0.9244, 0.0756], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 51 - 166: cat - cat || Loss: 0.38874387741088867\n",
      "tensor([1., 0.]) tensor([0.9245, 0.0755], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 51 - 167: cat - cat || Loss: 0.3885766267776489\n",
      "tensor([1., 0.]) tensor([0.9247, 0.0753], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 51 - 168: cat - cat || Loss: 0.3884097635746002\n",
      "tensor([1., 0.]) tensor([0.9249, 0.0751], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 51 - 169: cat - cat || Loss: 0.38824334740638733\n",
      "tensor([1., 0.]) tensor([0.9250, 0.0750], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 51 - 170: cat - cat || Loss: 0.38807734847068787\n",
      "tensor([1., 0.]) tensor([0.9252, 0.0748], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 51 - 171: cat - cat || Loss: 0.387911856174469\n",
      "tensor([1., 0.]) tensor([0.9253, 0.0747], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 51 - 172: cat - cat || Loss: 0.3877466917037964\n",
      "tensor([1., 0.]) tensor([0.9255, 0.0745], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 51 - 173: cat - cat || Loss: 0.3875819742679596\n",
      "tensor([1., 0.]) tensor([0.9257, 0.0743], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 51 - 174: cat - cat || Loss: 0.38741761445999146\n",
      "tensor([1., 0.]) tensor([0.9258, 0.0742], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 51 - 175: cat - cat || Loss: 0.38725367188453674\n",
      "tensor([1., 0.]) tensor([0.9260, 0.0740], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 51 - 176: cat - cat || Loss: 0.38709014654159546\n",
      "tensor([1., 0.]) tensor([0.9262, 0.0738], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 51 - 177: cat - cat || Loss: 0.38692718744277954\n",
      "tensor([1., 0.]) tensor([0.9263, 0.0737], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 51 - 178: cat - cat || Loss: 0.3867644667625427\n",
      "tensor([1., 0.]) tensor([0.9265, 0.0735], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 51 - 179: cat - cat || Loss: 0.3866022229194641\n",
      "tensor([1., 0.]) tensor([0.9267, 0.0733], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 51 - 180: cat - cat || Loss: 0.3864403963088989\n",
      "tensor([1., 0.]) tensor([0.9268, 0.0732], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 51 - 181: cat - cat || Loss: 0.38627898693084717\n",
      "tensor([1., 0.]) tensor([0.9270, 0.0730], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 51 - 182: cat - cat || Loss: 0.38611793518066406\n",
      "tensor([1., 0.]) tensor([0.9271, 0.0729], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 51 - 183: cat - cat || Loss: 0.3859574496746063\n",
      "tensor([1., 0.]) tensor([0.9273, 0.0727], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 51 - 184: cat - cat || Loss: 0.3857971429824829\n",
      "tensor([1., 0.]) tensor([0.9275, 0.0725], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 51 - 185: cat - cat || Loss: 0.3856373727321625\n",
      "tensor([1., 0.]) tensor([0.9276, 0.0724], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 51 - 186: cat - cat || Loss: 0.38547784090042114\n",
      "tensor([1., 0.]) tensor([0.9278, 0.0722], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 51 - 187: cat - cat || Loss: 0.385318785905838\n",
      "tensor([1., 0.]) tensor([0.9279, 0.0721], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 51 - 188: cat - cat || Loss: 0.38516005873680115\n",
      "tensor([1., 0.]) tensor([0.9281, 0.0719], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 51 - 189: cat - cat || Loss: 0.38500159978866577\n",
      "tensor([1., 0.]) tensor([0.9283, 0.0717], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 51 - 190: dog - cat || Loss: 1.2416797876358032\n",
      "tensor([0., 1.]) tensor([0.9284, 0.0716], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 51 - 191: dog - cat || Loss: 1.2418062686920166\n",
      "tensor([0., 1.]) tensor([0.9285, 0.0715], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 51 - 192: dog - cat || Loss: 1.241904377937317\n",
      "tensor([0., 1.]) tensor([0.9286, 0.0714], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 51 - 193: dog - cat || Loss: 1.2419770956039429\n",
      "tensor([0., 1.]) tensor([0.9287, 0.0713], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 51 - 194: dog - cat || Loss: 1.242026925086975\n",
      "tensor([0., 1.]) tensor([0.9288, 0.0712], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 51 - 195: dog - cat || Loss: 1.2420562505722046\n",
      "tensor([0., 1.]) tensor([0.9288, 0.0712], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 51 - 196: dog - cat || Loss: 1.2420669794082642\n",
      "tensor([0., 1.]) tensor([0.9288, 0.0712], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 51 - 197: dog - cat || Loss: 1.2420611381530762\n",
      "tensor([0., 1.]) tensor([0.9288, 0.0712], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 51 - 198: dog - cat || Loss: 1.2420403957366943\n",
      "tensor([0., 1.]) tensor([0.9288, 0.0712], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 51 - 199: dog - cat || Loss: 1.2420063018798828\n",
      "tensor([0., 1.]) tensor([0.9287, 0.0713], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 51 - 200: dog - cat || Loss: 1.241960048675537\n",
      "tensor([0., 1.]) tensor([0.9287, 0.0713], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 51 - 201: dog - cat || Loss: 1.2419025897979736\n",
      "tensor([0., 1.]) tensor([0.9286, 0.0714], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 51 - 202: dog - cat || Loss: 1.2418357133865356\n",
      "tensor([0., 1.]) tensor([0.9286, 0.0714], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 51 - 203: dog - cat || Loss: 1.2417595386505127\n",
      "tensor([0., 1.]) tensor([0.9285, 0.0715], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 51 - 204: dog - cat || Loss: 1.241675615310669\n",
      "tensor([0., 1.]) tensor([0.9284, 0.0716], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 51 - 205: dog - cat || Loss: 1.241584300994873\n",
      "tensor([0., 1.]) tensor([0.9283, 0.0717], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 51 - 206: dog - cat || Loss: 1.2414865493774414\n",
      "tensor([0., 1.]) tensor([0.9282, 0.0718], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 51 - 207: dog - cat || Loss: 1.2413828372955322\n",
      "tensor([0., 1.]) tensor([0.9281, 0.0719], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 51 - 208: dog - cat || Loss: 1.2412737607955933\n",
      "tensor([0., 1.]) tensor([0.9280, 0.0720], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 51 - 209: dog - cat || Loss: 1.2411599159240723\n",
      "tensor([0., 1.]) tensor([0.9279, 0.0721], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 51 - 210: dog - cat || Loss: 1.241041660308838\n",
      "tensor([0., 1.]) tensor([0.9278, 0.0722], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 51 - 211: dog - cat || Loss: 1.2409192323684692\n",
      "tensor([0., 1.]) tensor([0.9277, 0.0723], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 51 - 212: dog - cat || Loss: 1.2407933473587036\n",
      "tensor([0., 1.]) tensor([0.9275, 0.0725], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 51 - 213: dog - cat || Loss: 1.2406641244888306\n",
      "tensor([0., 1.]) tensor([0.9274, 0.0726], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 51 - 214: dog - cat || Loss: 1.2405318021774292\n",
      "tensor([0., 1.]) tensor([0.9273, 0.0727], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 51 - 215: dog - cat || Loss: 1.2403967380523682\n",
      "tensor([0., 1.]) tensor([0.9271, 0.0729], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 51 - 216: dog - cat || Loss: 1.2402592897415161\n",
      "tensor([0., 1.]) tensor([0.9270, 0.0730], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 51 - 217: dog - cat || Loss: 1.240119218826294\n",
      "tensor([0., 1.]) tensor([0.9269, 0.0731], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 51 - 218: dog - cat || Loss: 1.2399773597717285\n",
      "tensor([0., 1.]) tensor([0.9267, 0.0733], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 51 - 219: dog - cat || Loss: 1.2398333549499512\n",
      "tensor([0., 1.]) tensor([0.9266, 0.0734], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 51 - 220: dog - cat || Loss: 1.2396876811981201\n",
      "tensor([0., 1.]) tensor([0.9264, 0.0736], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 51 - 221: dog - cat || Loss: 1.2395403385162354\n",
      "tensor([0., 1.]) tensor([0.9263, 0.0737], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 51 - 222: dog - cat || Loss: 1.2393914461135864\n",
      "tensor([0., 1.]) tensor([0.9261, 0.0739], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 51 - 223: dog - cat || Loss: 1.239241123199463\n",
      "tensor([0., 1.]) tensor([0.9260, 0.0740], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 51 - 224: dog - cat || Loss: 1.2390896081924438\n",
      "tensor([0., 1.]) tensor([0.9258, 0.0742], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 51 - 225: dog - cat || Loss: 1.2389367818832397\n",
      "tensor([0., 1.]) tensor([0.9257, 0.0743], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 51 - 226: dog - cat || Loss: 1.2387830018997192\n",
      "tensor([0., 1.]) tensor([0.9255, 0.0745], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 51 - 227: dog - cat || Loss: 1.2386279106140137\n",
      "tensor([0., 1.]) tensor([0.9254, 0.0746], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 51 - 228: dog - cat || Loss: 1.2384718656539917\n",
      "tensor([0., 1.]) tensor([0.9252, 0.0748], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 51 - 229: dog - cat || Loss: 1.2383151054382324\n",
      "tensor([0., 1.]) tensor([0.9251, 0.0749], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 51 - 230: dog - cat || Loss: 1.2381571531295776\n",
      "tensor([0., 1.]) tensor([0.9249, 0.0751], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 51 - 231: dog - cat || Loss: 1.2379987239837646\n",
      "tensor([0., 1.]) tensor([0.9247, 0.0753], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 51 - 232: dog - cat || Loss: 1.2378392219543457\n",
      "tensor([0., 1.]) tensor([0.9246, 0.0754], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 51 - 233: dog - cat || Loss: 1.2376787662506104\n",
      "tensor([0., 1.]) tensor([0.9244, 0.0756], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 51 - 234: dog - cat || Loss: 1.237518072128296\n",
      "tensor([0., 1.]) tensor([0.9243, 0.0757], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 51 - 235: dog - cat || Loss: 1.2373565435409546\n",
      "tensor([0., 1.]) tensor([0.9241, 0.0759], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 51 - 236: dog - cat || Loss: 1.2371941804885864\n",
      "tensor([0., 1.]) tensor([0.9239, 0.0761], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 51 - 237: dog - cat || Loss: 1.2370312213897705\n",
      "tensor([0., 1.]) tensor([0.9238, 0.0762], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 51 - 238: dog - cat || Loss: 1.236867904663086\n",
      "tensor([0., 1.]) tensor([0.9236, 0.0764], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 51 - 239: dog - cat || Loss: 1.236703634262085\n",
      "tensor([0., 1.]) tensor([0.9234, 0.0766], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 51 - 240: dog - cat || Loss: 1.2365388870239258\n",
      "tensor([0., 1.]) tensor([0.9233, 0.0767], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 51 - 241: dog - cat || Loss: 1.2363736629486084\n",
      "tensor([0., 1.]) tensor([0.9231, 0.0769], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 51 - 242: dog - cat || Loss: 1.2362078428268433\n",
      "tensor([0., 1.]) tensor([0.9229, 0.0771], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 51 - 243: dog - cat || Loss: 1.23604154586792\n",
      "tensor([0., 1.]) tensor([0.9228, 0.0772], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 51 - 244: dog - cat || Loss: 1.2358747720718384\n",
      "tensor([0., 1.]) tensor([0.9226, 0.0774], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 51 - 245: dog - cat || Loss: 1.235707402229309\n",
      "tensor([0., 1.]) tensor([0.9224, 0.0776], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 51 - 246: dog - cat || Loss: 1.2355395555496216\n",
      "tensor([0., 1.]) tensor([0.9223, 0.0777], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 51 - 247: dog - cat || Loss: 1.2353712320327759\n",
      "tensor([0., 1.]) tensor([0.9221, 0.0779], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 51 - 248: dog - cat || Loss: 1.2352023124694824\n",
      "tensor([0., 1.]) tensor([0.9219, 0.0781], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 51 - 249: dog - cat || Loss: 1.2350329160690308\n",
      "tensor([0., 1.]) tensor([0.9218, 0.0782], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 51 - 250: dog - cat || Loss: 1.23486328125\n",
      "tensor([0., 1.]) tensor([0.9216, 0.0784], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 51 - 251: dog - cat || Loss: 1.2346930503845215\n",
      "tensor([0., 1.]) tensor([0.9214, 0.0786], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 51 - 252: dog - cat || Loss: 1.2345223426818848\n",
      "tensor([0., 1.]) tensor([0.9213, 0.0787], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 51 - 253: dog - cat || Loss: 1.2343509197235107\n",
      "tensor([0., 1.]) tensor([0.9211, 0.0789], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 51 - 254: dog - cat || Loss: 1.2341794967651367\n",
      "tensor([0., 1.]) tensor([0.9209, 0.0791], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 51 - 255: dog - cat || Loss: 1.2340073585510254\n",
      "tensor([0., 1.]) tensor([0.9207, 0.0793], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 51 - 256: dog - cat || Loss: 1.2338347434997559\n",
      "tensor([0., 1.]) tensor([0.9206, 0.0794], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 51 - 257: dog - cat || Loss: 1.2336616516113281\n",
      "tensor([0., 1.]) tensor([0.9204, 0.0796], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 51 - 258: dog - cat || Loss: 1.2334882020950317\n",
      "tensor([0., 1.]) tensor([0.9202, 0.0798], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 51 - 259: dog - cat || Loss: 1.2333143949508667\n",
      "tensor([0., 1.]) tensor([0.9201, 0.0799], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 51 - 260: dog - cat || Loss: 1.2331398725509644\n",
      "tensor([0., 1.]) tensor([0.9199, 0.0801], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 51 - 261: dog - cat || Loss: 1.232965111732483\n",
      "tensor([0., 1.]) tensor([0.9197, 0.0803], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 51 - 262: dog - cat || Loss: 1.2327897548675537\n",
      "tensor([0., 1.]) tensor([0.9195, 0.0805], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 51 - 263: dog - cat || Loss: 1.2326140403747559\n",
      "tensor([0., 1.]) tensor([0.9194, 0.0806], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 51 - 264: dog - cat || Loss: 1.2324379682540894\n",
      "tensor([0., 1.]) tensor([0.9192, 0.0808], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 51 - 265: dog - cat || Loss: 1.2322611808776855\n",
      "tensor([0., 1.]) tensor([0.9190, 0.0810], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 51 - 266: dog - cat || Loss: 1.2320842742919922\n",
      "tensor([0., 1.]) tensor([0.9188, 0.0812], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 51 - 267: dog - cat || Loss: 1.231906771659851\n",
      "tensor([0., 1.]) tensor([0.9186, 0.0814], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 51 - 268: dog - cat || Loss: 1.2317286729812622\n",
      "tensor([0., 1.]) tensor([0.9185, 0.0815], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 51 - 269: dog - cat || Loss: 1.2315503358840942\n",
      "tensor([0., 1.]) tensor([0.9183, 0.0817], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 51 - 270: dog - cat || Loss: 1.2313714027404785\n",
      "tensor([0., 1.]) tensor([0.9181, 0.0819], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 51 - 271: dog - cat || Loss: 1.2311922311782837\n",
      "tensor([0., 1.]) tensor([0.9179, 0.0821], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 51 - 272: dog - cat || Loss: 1.2310124635696411\n",
      "tensor([0., 1.]) tensor([0.9178, 0.0822], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 51 - 273: dog - cat || Loss: 1.2308322191238403\n",
      "tensor([0., 1.]) tensor([0.9176, 0.0824], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 51 - 274: dog - cat || Loss: 1.2306517362594604\n",
      "tensor([0., 1.]) tensor([0.9174, 0.0826], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 51 - 275: dog - cat || Loss: 1.2304705381393433\n",
      "tensor([0., 1.]) tensor([0.9172, 0.0828], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 51 - 276: dog - cat || Loss: 1.230289101600647\n",
      "tensor([0., 1.]) tensor([0.9170, 0.0830], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 51 - 277: dog - cat || Loss: 1.2301069498062134\n",
      "tensor([0., 1.]) tensor([0.9168, 0.0832], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 51 - 278: dog - cat || Loss: 1.2299245595932007\n",
      "tensor([0., 1.]) tensor([0.9167, 0.0833], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 51 - 279: dog - cat || Loss: 1.2297416925430298\n",
      "tensor([0., 1.]) tensor([0.9165, 0.0835], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 51 - 280: dog - cat || Loss: 1.2295582294464111\n",
      "tensor([0., 1.]) tensor([0.9163, 0.0837], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 51 - 281: dog - cat || Loss: 1.2293744087219238\n",
      "tensor([0., 1.]) tensor([0.9161, 0.0839], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 51 - 282: dog - cat || Loss: 1.2291902303695679\n",
      "tensor([0., 1.]) tensor([0.9159, 0.0841], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 51 - 283: dog - cat || Loss: 1.2290055751800537\n",
      "tensor([0., 1.]) tensor([0.9157, 0.0843], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 51 - 284: dog - cat || Loss: 1.2288203239440918\n",
      "tensor([0., 1.]) tensor([0.9156, 0.0844], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 51 - 285: dog - cat || Loss: 1.2286347150802612\n",
      "tensor([0., 1.]) tensor([0.9154, 0.0846], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 51 - 286: dog - cat || Loss: 1.228448748588562\n",
      "tensor([0., 1.]) tensor([0.9152, 0.0848], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 51 - 287: dog - cat || Loss: 1.2282620668411255\n",
      "tensor([0., 1.]) tensor([0.9150, 0.0850], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 51 - 288: dog - cat || Loss: 1.2280751466751099\n",
      "tensor([0., 1.]) tensor([0.9148, 0.0852], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 51 - 289: dog - cat || Loss: 1.227887511253357\n",
      "tensor([0., 1.]) tensor([0.9146, 0.0854], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 51 - 290: dog - cat || Loss: 1.227699637413025\n",
      "tensor([0., 1.]) tensor([0.9144, 0.0856], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 51 - 291: dog - cat || Loss: 1.2275112867355347\n",
      "tensor([0., 1.]) tensor([0.9142, 0.0858], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 51 - 292: dog - cat || Loss: 1.2273224592208862\n",
      "tensor([0., 1.]) tensor([0.9141, 0.0859], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 51 - 293: dog - cat || Loss: 1.22713303565979\n",
      "tensor([0., 1.]) tensor([0.9139, 0.0861], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 51 - 294: dog - cat || Loss: 1.2269432544708252\n",
      "tensor([0., 1.]) tensor([0.9137, 0.0863], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 51 - 295: dog - cat || Loss: 1.2267531156539917\n",
      "tensor([0., 1.]) tensor([0.9135, 0.0865], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 51 - 296: dog - cat || Loss: 1.226562261581421\n",
      "tensor([0., 1.]) tensor([0.9133, 0.0867], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 51 - 297: dog - cat || Loss: 1.2263710498809814\n",
      "tensor([0., 1.]) tensor([0.9131, 0.0869], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 51 - 298: dog - cat || Loss: 1.2261793613433838\n",
      "tensor([0., 1.]) tensor([0.9129, 0.0871], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 51 - 299: dog - cat || Loss: 1.2259873151779175\n",
      "tensor([0., 1.]) tensor([0.9127, 0.0873], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 51 - 300: dog - cat || Loss: 1.2257945537567139\n",
      "tensor([0., 1.]) tensor([0.9125, 0.0875], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 51 - 301: dog - cat || Loss: 1.2256015539169312\n",
      "tensor([0., 1.]) tensor([0.9123, 0.0877], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 51 - 302: dog - cat || Loss: 1.2254079580307007\n",
      "tensor([0., 1.]) tensor([0.9121, 0.0879], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 51 - 303: dog - cat || Loss: 1.225213885307312\n",
      "tensor([0., 1.]) tensor([0.9120, 0.0880], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 51 - 304: dog - cat || Loss: 1.2250194549560547\n",
      "tensor([0., 1.]) tensor([0.9118, 0.0882], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 51 - 305: dog - cat || Loss: 1.2248244285583496\n",
      "tensor([0., 1.]) tensor([0.9116, 0.0884], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 51 - 306: dog - cat || Loss: 1.2246290445327759\n",
      "tensor([0., 1.]) tensor([0.9114, 0.0886], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 51 - 307: dog - cat || Loss: 1.2244329452514648\n",
      "tensor([0., 1.]) tensor([0.9112, 0.0888], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 51 - 308: dog - cat || Loss: 1.2242366075515747\n",
      "tensor([0., 1.]) tensor([0.9110, 0.0890], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 51 - 309: dog - cat || Loss: 1.2240396738052368\n",
      "tensor([0., 1.]) tensor([0.9108, 0.0892], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 51 - 310: dog - cat || Loss: 1.2238422632217407\n",
      "tensor([0., 1.]) tensor([0.9106, 0.0894], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 51 - 311: dog - cat || Loss: 1.2236443758010864\n",
      "tensor([0., 1.]) tensor([0.9104, 0.0896], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 51 - 312: dog - cat || Loss: 1.2234458923339844\n",
      "tensor([0., 1.]) tensor([0.9102, 0.0898], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 51 - 313: dog - cat || Loss: 1.2232470512390137\n",
      "tensor([0., 1.]) tensor([0.9100, 0.0900], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 51 - 314: dog - cat || Loss: 1.2230478525161743\n",
      "tensor([0., 1.]) tensor([0.9098, 0.0902], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 51 - 315: dog - cat || Loss: 1.2228479385375977\n",
      "tensor([0., 1.]) tensor([0.9096, 0.0904], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 51 - 316: dog - cat || Loss: 1.2226475477218628\n",
      "tensor([0., 1.]) tensor([0.9094, 0.0906], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 51 - 317: dog - cat || Loss: 1.2224467992782593\n",
      "tensor([0., 1.]) tensor([0.9092, 0.0908], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 51 - 318: dog - cat || Loss: 1.222245454788208\n",
      "tensor([0., 1.]) tensor([0.9090, 0.0910], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 51 - 319: dog - cat || Loss: 1.2220436334609985\n",
      "tensor([0., 1.]) tensor([0.9088, 0.0912], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 51 - 320: dog - cat || Loss: 1.2218414545059204\n",
      "tensor([0., 1.]) tensor([0.9086, 0.0914], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 51 - 321: dog - cat || Loss: 1.221638560295105\n",
      "tensor([0., 1.]) tensor([0.9084, 0.0916], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 51 - 322: dog - cat || Loss: 1.221435308456421\n",
      "tensor([0., 1.]) tensor([0.9082, 0.0918], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 51 - 323: dog - cat || Loss: 1.221231460571289\n",
      "tensor([0., 1.]) tensor([0.9080, 0.0920], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 51 - 324: dog - cat || Loss: 1.221027135848999\n",
      "tensor([0., 1.]) tensor([0.9078, 0.0922], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 51 - 325: dog - cat || Loss: 1.2208224534988403\n",
      "tensor([0., 1.]) tensor([0.9076, 0.0924], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 51 - 326: dog - cat || Loss: 1.2206170558929443\n",
      "tensor([0., 1.]) tensor([0.9074, 0.0926], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 51 - 327: dog - cat || Loss: 1.2204113006591797\n",
      "tensor([0., 1.]) tensor([0.9071, 0.0929], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 51 - 328: dog - cat || Loss: 1.2202049493789673\n",
      "tensor([0., 1.]) tensor([0.9069, 0.0931], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 51 - 329: dog - cat || Loss: 1.2199981212615967\n",
      "tensor([0., 1.]) tensor([0.9067, 0.0933], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 51 - 330: dog - cat || Loss: 1.2197908163070679\n",
      "tensor([0., 1.]) tensor([0.9065, 0.0935], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 51 - 331: dog - cat || Loss: 1.2195830345153809\n",
      "tensor([0., 1.]) tensor([0.9063, 0.0937], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 51 - 332: dog - cat || Loss: 1.219374656677246\n",
      "tensor([0., 1.]) tensor([0.9061, 0.0939], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 51 - 333: dog - cat || Loss: 1.2191658020019531\n",
      "tensor([0., 1.]) tensor([0.9059, 0.0941], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 51 - 334: dog - cat || Loss: 1.2189563512802124\n",
      "tensor([0., 1.]) tensor([0.9057, 0.0943], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 51 - 335: dog - cat || Loss: 1.2187466621398926\n",
      "tensor([0., 1.]) tensor([0.9055, 0.0945], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 51 - 336: dog - cat || Loss: 1.218536138534546\n",
      "tensor([0., 1.]) tensor([0.9053, 0.0947], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 51 - 337: dog - cat || Loss: 1.2183252573013306\n",
      "tensor([0., 1.]) tensor([0.9051, 0.0949], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 51 - 338: dog - cat || Loss: 1.218113660812378\n",
      "tensor([0., 1.]) tensor([0.9049, 0.0951], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 51 - 339: dog - cat || Loss: 1.2179018259048462\n",
      "tensor([0., 1.]) tensor([0.9046, 0.0954], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 51 - 340: dog - cat || Loss: 1.2176895141601562\n",
      "tensor([0., 1.]) tensor([0.9044, 0.0956], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 51 - 341: dog - cat || Loss: 1.2174763679504395\n",
      "tensor([0., 1.]) tensor([0.9042, 0.0958], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 51 - 342: dog - cat || Loss: 1.217262864112854\n",
      "tensor([0., 1.]) tensor([0.9040, 0.0960], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 51 - 343: dog - cat || Loss: 1.2170487642288208\n",
      "tensor([0., 1.]) tensor([0.9038, 0.0962], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 51 - 344: dog - cat || Loss: 1.216834306716919\n",
      "tensor([0., 1.]) tensor([0.9036, 0.0964], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 51 - 345: dog - cat || Loss: 1.2166190147399902\n",
      "tensor([0., 1.]) tensor([0.9034, 0.0966], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 51 - 346: dog - cat || Loss: 1.2164034843444824\n",
      "tensor([0., 1.]) tensor([0.9031, 0.0969], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 51 - 347: dog - cat || Loss: 1.2161873579025269\n",
      "tensor([0., 1.]) tensor([0.9029, 0.0971], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 51 - 348: dog - cat || Loss: 1.215970754623413\n",
      "tensor([0., 1.]) tensor([0.9027, 0.0973], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 51 - 349: dog - cat || Loss: 1.215753436088562\n",
      "tensor([0., 1.]) tensor([0.9025, 0.0975], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 51 - 350: dog - cat || Loss: 1.2155356407165527\n",
      "tensor([0., 1.]) tensor([0.9023, 0.0977], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 51 - 351: dog - cat || Loss: 1.2153173685073853\n",
      "tensor([0., 1.]) tensor([0.9021, 0.0979], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 51 - 352: dog - cat || Loss: 1.2150986194610596\n",
      "tensor([0., 1.]) tensor([0.9018, 0.0982], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 51 - 353: dog - cat || Loss: 1.2148792743682861\n",
      "tensor([0., 1.]) tensor([0.9016, 0.0984], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 51 - 354: dog - cat || Loss: 1.2146592140197754\n",
      "tensor([0., 1.]) tensor([0.9014, 0.0986], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 51 - 355: dog - cat || Loss: 1.2144389152526855\n",
      "tensor([0., 1.]) tensor([0.9012, 0.0988], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 51 - 356: dog - cat || Loss: 1.214218020439148\n",
      "tensor([0., 1.]) tensor([0.9010, 0.0990], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 51 - 357: dog - cat || Loss: 1.213996410369873\n",
      "tensor([0., 1.]) tensor([0.9007, 0.0993], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 51 - 358: dog - cat || Loss: 1.213774561882019\n",
      "tensor([0., 1.]) tensor([0.9005, 0.0995], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 51 - 359: dog - cat || Loss: 1.2135517597198486\n",
      "tensor([0., 1.]) tensor([0.9003, 0.0997], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 51 - 360: dog - cat || Loss: 1.2133285999298096\n",
      "tensor([0., 1.]) tensor([0.9001, 0.0999], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 51 - 361: dog - cat || Loss: 1.2131049633026123\n",
      "tensor([0., 1.]) tensor([0.8998, 0.1002], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 51 - 362: dog - cat || Loss: 1.2128807306289673\n",
      "tensor([0., 1.]) tensor([0.8996, 0.1004], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 51 - 363: dog - cat || Loss: 1.2126559019088745\n",
      "tensor([0., 1.]) tensor([0.8994, 0.1006], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 51 - 364: dog - cat || Loss: 1.2124305963516235\n",
      "tensor([0., 1.]) tensor([0.8992, 0.1008], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 51 - 365: dog - cat || Loss: 1.2122048139572144\n",
      "tensor([0., 1.]) tensor([0.8989, 0.1011], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 51 - 366: dog - cat || Loss: 1.2119783163070679\n",
      "tensor([0., 1.]) tensor([0.8987, 0.1013], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 51 - 367: dog - cat || Loss: 1.2117513418197632\n",
      "tensor([0., 1.]) tensor([0.8985, 0.1015], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 51 - 368: dog - cat || Loss: 1.2115237712860107\n",
      "tensor([0., 1.]) tensor([0.8983, 0.1017], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 51 - 369: dog - cat || Loss: 1.2112956047058105\n",
      "tensor([0., 1.]) tensor([0.8980, 0.1020], grad_fn=<SoftmaxBackward0>)\n",
      "=====epoch:52=====\n",
      "Epoch 52 - 0: cat - cat || Loss: 0.41545629501342773\n",
      "tensor([1., 0.]) tensor([0.8978, 0.1022], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 52 - 1: cat - cat || Loss: 0.41563910245895386\n",
      "tensor([1., 0.]) tensor([0.8976, 0.1024], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 52 - 2: cat - cat || Loss: 0.4157806932926178\n",
      "tensor([1., 0.]) tensor([0.8975, 0.1025], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 52 - 3: cat - cat || Loss: 0.41588476300239563\n",
      "tensor([1., 0.]) tensor([0.8974, 0.1026], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 52 - 4: cat - cat || Loss: 0.4159553349018097\n",
      "tensor([1., 0.]) tensor([0.8973, 0.1027], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 52 - 5: cat - cat || Loss: 0.4159955382347107\n",
      "tensor([1., 0.]) tensor([0.8973, 0.1027], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 52 - 6: cat - cat || Loss: 0.4160084128379822\n",
      "tensor([1., 0.]) tensor([0.8973, 0.1027], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 52 - 7: cat - cat || Loss: 0.4159967303276062\n",
      "tensor([1., 0.]) tensor([0.8973, 0.1027], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 52 - 8: cat - cat || Loss: 0.41596296429634094\n",
      "tensor([1., 0.]) tensor([0.8973, 0.1027], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 52 - 9: cat - cat || Loss: 0.4159092307090759\n",
      "tensor([1., 0.]) tensor([0.8974, 0.1026], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 52 - 10: cat - cat || Loss: 0.4158375859260559\n",
      "tensor([1., 0.]) tensor([0.8974, 0.1026], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 52 - 11: cat - cat || Loss: 0.4157499670982361\n",
      "tensor([1., 0.]) tensor([0.8975, 0.1025], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 52 - 12: cat - cat || Loss: 0.415647953748703\n",
      "tensor([1., 0.]) tensor([0.8976, 0.1024], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 52 - 13: cat - cat || Loss: 0.4155328869819641\n",
      "tensor([1., 0.]) tensor([0.8977, 0.1023], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 52 - 14: cat - cat || Loss: 0.4154062867164612\n",
      "tensor([1., 0.]) tensor([0.8979, 0.1021], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 52 - 15: cat - cat || Loss: 0.41526931524276733\n",
      "tensor([1., 0.]) tensor([0.8980, 0.1020], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 52 - 16: cat - cat || Loss: 0.41512301564216614\n",
      "tensor([1., 0.]) tensor([0.8981, 0.1019], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 52 - 17: cat - cat || Loss: 0.4149683117866516\n",
      "tensor([1., 0.]) tensor([0.8983, 0.1017], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 52 - 18: cat - cat || Loss: 0.4148062467575073\n",
      "tensor([1., 0.]) tensor([0.8985, 0.1015], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 52 - 19: cat - cat || Loss: 0.41463756561279297\n",
      "tensor([1., 0.]) tensor([0.8986, 0.1014], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 52 - 20: cat - cat || Loss: 0.41446277499198914\n",
      "tensor([1., 0.]) tensor([0.8988, 0.1012], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 52 - 21: cat - cat || Loss: 0.4142828583717346\n",
      "tensor([1., 0.]) tensor([0.8990, 0.1010], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 52 - 22: cat - cat || Loss: 0.41409832239151\n",
      "tensor([1., 0.]) tensor([0.8992, 0.1008], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 52 - 23: cat - cat || Loss: 0.4139094948768616\n",
      "tensor([1., 0.]) tensor([0.8994, 0.1006], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 52 - 24: cat - cat || Loss: 0.4137169420719147\n",
      "tensor([1., 0.]) tensor([0.8995, 0.1005], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 52 - 25: cat - cat || Loss: 0.4135211706161499\n",
      "tensor([1., 0.]) tensor([0.8997, 0.1003], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 52 - 26: cat - cat || Loss: 0.41332247853279114\n",
      "tensor([1., 0.]) tensor([0.8999, 0.1001], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 52 - 27: cat - cat || Loss: 0.4131212830543518\n",
      "tensor([1., 0.]) tensor([0.9001, 0.0999], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 52 - 28: cat - cat || Loss: 0.4129178524017334\n",
      "tensor([1., 0.]) tensor([0.9003, 0.0997], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 52 - 29: cat - cat || Loss: 0.4127123951911926\n",
      "tensor([1., 0.]) tensor([0.9005, 0.0995], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 52 - 30: cat - cat || Loss: 0.41250526905059814\n",
      "tensor([1., 0.]) tensor([0.9008, 0.0992], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 52 - 31: cat - cat || Loss: 0.4122965633869171\n",
      "tensor([1., 0.]) tensor([0.9010, 0.0990], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 52 - 32: cat - cat || Loss: 0.4120866060256958\n",
      "tensor([1., 0.]) tensor([0.9012, 0.0988], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 52 - 33: cat - cat || Loss: 0.41187572479248047\n",
      "tensor([1., 0.]) tensor([0.9014, 0.0986], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 52 - 34: cat - cat || Loss: 0.4116637706756592\n",
      "tensor([1., 0.]) tensor([0.9016, 0.0984], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 52 - 35: cat - cat || Loss: 0.4114510416984558\n",
      "tensor([1., 0.]) tensor([0.9018, 0.0982], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 52 - 36: cat - cat || Loss: 0.4112377166748047\n",
      "tensor([1., 0.]) tensor([0.9020, 0.0980], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 52 - 37: cat - cat || Loss: 0.4110237956047058\n",
      "tensor([1., 0.]) tensor([0.9022, 0.0978], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 52 - 38: cat - cat || Loss: 0.4108094871044159\n",
      "tensor([1., 0.]) tensor([0.9025, 0.0975], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 52 - 39: cat - cat || Loss: 0.4105948209762573\n",
      "tensor([1., 0.]) tensor([0.9027, 0.0973], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 52 - 40: cat - cat || Loss: 0.4103800654411316\n",
      "tensor([1., 0.]) tensor([0.9029, 0.0971], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 52 - 41: cat - cat || Loss: 0.4101649820804596\n",
      "tensor([1., 0.]) tensor([0.9031, 0.0969], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 52 - 42: cat - cat || Loss: 0.4099498987197876\n",
      "tensor([1., 0.]) tensor([0.9033, 0.0967], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 52 - 43: cat - cat || Loss: 0.40973472595214844\n",
      "tensor([1., 0.]) tensor([0.9035, 0.0965], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 52 - 44: cat - cat || Loss: 0.4095197319984436\n",
      "tensor([1., 0.]) tensor([0.9037, 0.0963], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 52 - 45: cat - cat || Loss: 0.40930473804473877\n",
      "tensor([1., 0.]) tensor([0.9040, 0.0960], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 52 - 46: cat - cat || Loss: 0.4090898334980011\n",
      "tensor([1., 0.]) tensor([0.9042, 0.0958], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 52 - 47: cat - cat || Loss: 0.40887510776519775\n",
      "tensor([1., 0.]) tensor([0.9044, 0.0956], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 52 - 48: cat - cat || Loss: 0.4086606502532959\n",
      "tensor([1., 0.]) tensor([0.9046, 0.0954], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 52 - 49: cat - cat || Loss: 0.40844637155532837\n",
      "tensor([1., 0.]) tensor([0.9048, 0.0952], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 52 - 50: cat - cat || Loss: 0.4082324206829071\n",
      "tensor([1., 0.]) tensor([0.9050, 0.0950], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 52 - 51: cat - cat || Loss: 0.4080187678337097\n",
      "tensor([1., 0.]) tensor([0.9052, 0.0948], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 52 - 52: cat - cat || Loss: 0.40780535340309143\n",
      "tensor([1., 0.]) tensor([0.9055, 0.0945], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 52 - 53: cat - cat || Loss: 0.4075923264026642\n",
      "tensor([1., 0.]) tensor([0.9057, 0.0943], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 52 - 54: cat - cat || Loss: 0.4073796272277832\n",
      "tensor([1., 0.]) tensor([0.9059, 0.0941], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 52 - 55: cat - cat || Loss: 0.40716734528541565\n",
      "tensor([1., 0.]) tensor([0.9061, 0.0939], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 52 - 56: cat - cat || Loss: 0.4069555103778839\n",
      "tensor([1., 0.]) tensor([0.9063, 0.0937], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 52 - 57: cat - cat || Loss: 0.40674400329589844\n",
      "tensor([1., 0.]) tensor([0.9065, 0.0935], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 52 - 58: cat - cat || Loss: 0.40653300285339355\n",
      "tensor([1., 0.]) tensor([0.9067, 0.0933], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 52 - 59: cat - cat || Loss: 0.4063223600387573\n",
      "tensor([1., 0.]) tensor([0.9069, 0.0931], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 52 - 60: cat - cat || Loss: 0.4061121940612793\n",
      "tensor([1., 0.]) tensor([0.9071, 0.0929], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 52 - 61: cat - cat || Loss: 0.40590235590934753\n",
      "tensor([1., 0.]) tensor([0.9074, 0.0926], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 52 - 62: cat - cat || Loss: 0.40569305419921875\n",
      "tensor([1., 0.]) tensor([0.9076, 0.0924], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 52 - 63: cat - cat || Loss: 0.40548425912857056\n",
      "tensor([1., 0.]) tensor([0.9078, 0.0922], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 52 - 64: cat - cat || Loss: 0.405275821685791\n",
      "tensor([1., 0.]) tensor([0.9080, 0.0920], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 52 - 65: cat - cat || Loss: 0.40506792068481445\n",
      "tensor([1., 0.]) tensor([0.9082, 0.0918], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 52 - 66: cat - cat || Loss: 0.4048605263233185\n",
      "tensor([1., 0.]) tensor([0.9084, 0.0916], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 52 - 67: cat - cat || Loss: 0.4046536087989807\n",
      "tensor([1., 0.]) tensor([0.9086, 0.0914], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 52 - 68: cat - cat || Loss: 0.40444713830947876\n",
      "tensor([1., 0.]) tensor([0.9088, 0.0912], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 52 - 69: cat - cat || Loss: 0.4042411148548126\n",
      "tensor([1., 0.]) tensor([0.9090, 0.0910], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 52 - 70: cat - cat || Loss: 0.40403562784194946\n",
      "tensor([1., 0.]) tensor([0.9092, 0.0908], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 52 - 71: cat - cat || Loss: 0.4038305878639221\n",
      "tensor([1., 0.]) tensor([0.9094, 0.0906], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 52 - 72: cat - cat || Loss: 0.40362611413002014\n",
      "tensor([1., 0.]) tensor([0.9096, 0.0904], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 52 - 73: cat - cat || Loss: 0.4034220278263092\n",
      "tensor([1., 0.]) tensor([0.9098, 0.0902], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 52 - 74: cat - cat || Loss: 0.40321850776672363\n",
      "tensor([1., 0.]) tensor([0.9100, 0.0900], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 52 - 75: cat - cat || Loss: 0.4030154347419739\n",
      "tensor([1., 0.]) tensor([0.9102, 0.0898], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 52 - 76: cat - cat || Loss: 0.4028129279613495\n",
      "tensor([1., 0.]) tensor([0.9104, 0.0896], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 52 - 77: cat - cat || Loss: 0.4026109278202057\n",
      "tensor([1., 0.]) tensor([0.9107, 0.0893], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 52 - 78: cat - cat || Loss: 0.40240931510925293\n",
      "tensor([1., 0.]) tensor([0.9109, 0.0891], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 52 - 79: cat - cat || Loss: 0.40220826864242554\n",
      "tensor([1., 0.]) tensor([0.9111, 0.0889], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 52 - 80: cat - cat || Loss: 0.40200769901275635\n",
      "tensor([1., 0.]) tensor([0.9113, 0.0887], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 52 - 81: cat - cat || Loss: 0.4018075466156006\n",
      "tensor([1., 0.]) tensor([0.9115, 0.0885], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 52 - 82: cat - cat || Loss: 0.4016079604625702\n",
      "tensor([1., 0.]) tensor([0.9117, 0.0883], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 52 - 83: cat - cat || Loss: 0.4014089107513428\n",
      "tensor([1., 0.]) tensor([0.9119, 0.0881], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 52 - 84: cat - cat || Loss: 0.40121036767959595\n",
      "tensor([1., 0.]) tensor([0.9121, 0.0879], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 52 - 85: cat - cat || Loss: 0.4010123014450073\n",
      "tensor([1., 0.]) tensor([0.9122, 0.0878], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 52 - 86: cat - cat || Loss: 0.4008146822452545\n",
      "tensor([1., 0.]) tensor([0.9124, 0.0876], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 52 - 87: cat - cat || Loss: 0.4006175994873047\n",
      "tensor([1., 0.]) tensor([0.9126, 0.0874], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 52 - 88: cat - cat || Loss: 0.40042102336883545\n",
      "tensor([1., 0.]) tensor([0.9128, 0.0872], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 52 - 89: cat - cat || Loss: 0.4002249538898468\n",
      "tensor([1., 0.]) tensor([0.9130, 0.0870], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 52 - 90: cat - cat || Loss: 0.40002936124801636\n",
      "tensor([1., 0.]) tensor([0.9132, 0.0868], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 52 - 91: cat - cat || Loss: 0.39983418583869934\n",
      "tensor([1., 0.]) tensor([0.9134, 0.0866], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 52 - 92: cat - cat || Loss: 0.3996396064758301\n",
      "tensor([1., 0.]) tensor([0.9136, 0.0864], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 52 - 93: cat - cat || Loss: 0.3994455337524414\n",
      "tensor([1., 0.]) tensor([0.9138, 0.0862], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 52 - 94: cat - cat || Loss: 0.3992518186569214\n",
      "tensor([1., 0.]) tensor([0.9140, 0.0860], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 52 - 95: cat - cat || Loss: 0.39905866980552673\n",
      "tensor([1., 0.]) tensor([0.9142, 0.0858], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 52 - 96: cat - cat || Loss: 0.3988659977912903\n",
      "tensor([1., 0.]) tensor([0.9144, 0.0856], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 52 - 97: cat - cat || Loss: 0.3986738324165344\n",
      "tensor([1., 0.]) tensor([0.9146, 0.0854], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 52 - 98: cat - cat || Loss: 0.39848214387893677\n",
      "tensor([1., 0.]) tensor([0.9148, 0.0852], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 52 - 99: cat - cat || Loss: 0.3982910215854645\n",
      "tensor([1., 0.]) tensor([0.9150, 0.0850], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 52 - 100: cat - cat || Loss: 0.3981002867221832\n",
      "tensor([1., 0.]) tensor([0.9152, 0.0848], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 52 - 101: cat - cat || Loss: 0.39791005849838257\n",
      "tensor([1., 0.]) tensor([0.9154, 0.0846], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 52 - 102: cat - cat || Loss: 0.3977203071117401\n",
      "tensor([1., 0.]) tensor([0.9155, 0.0845], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 52 - 103: cat - cat || Loss: 0.39753100275993347\n",
      "tensor([1., 0.]) tensor([0.9157, 0.0843], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 52 - 104: cat - cat || Loss: 0.3973422348499298\n",
      "tensor([1., 0.]) tensor([0.9159, 0.0841], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 52 - 105: cat - cat || Loss: 0.39715391397476196\n",
      "tensor([1., 0.]) tensor([0.9161, 0.0839], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 52 - 106: cat - cat || Loss: 0.3969660997390747\n",
      "tensor([1., 0.]) tensor([0.9163, 0.0837], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 52 - 107: cat - cat || Loss: 0.3967787027359009\n",
      "tensor([1., 0.]) tensor([0.9165, 0.0835], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 52 - 108: cat - cat || Loss: 0.39659178256988525\n",
      "tensor([1., 0.]) tensor([0.9167, 0.0833], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 52 - 109: cat - cat || Loss: 0.396405428647995\n",
      "tensor([1., 0.]) tensor([0.9169, 0.0831], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 52 - 110: cat - cat || Loss: 0.3962194323539734\n",
      "tensor([1., 0.]) tensor([0.9170, 0.0830], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 52 - 111: cat - cat || Loss: 0.39603400230407715\n",
      "tensor([1., 0.]) tensor([0.9172, 0.0828], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 52 - 112: cat - cat || Loss: 0.39584892988204956\n",
      "tensor([1., 0.]) tensor([0.9174, 0.0826], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 52 - 113: cat - cat || Loss: 0.39566439390182495\n",
      "tensor([1., 0.]) tensor([0.9176, 0.0824], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 52 - 114: cat - cat || Loss: 0.39548036456108093\n",
      "tensor([1., 0.]) tensor([0.9178, 0.0822], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 52 - 115: cat - cat || Loss: 0.39529672265052795\n",
      "tensor([1., 0.]) tensor([0.9180, 0.0820], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 52 - 116: cat - cat || Loss: 0.3951135575771332\n",
      "tensor([1., 0.]) tensor([0.9181, 0.0819], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 52 - 117: cat - cat || Loss: 0.3949309289455414\n",
      "tensor([1., 0.]) tensor([0.9183, 0.0817], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 52 - 118: cat - cat || Loss: 0.39474862813949585\n",
      "tensor([1., 0.]) tensor([0.9185, 0.0815], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 52 - 119: cat - cat || Loss: 0.39456695318222046\n",
      "tensor([1., 0.]) tensor([0.9187, 0.0813], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 52 - 120: cat - cat || Loss: 0.3943856358528137\n",
      "tensor([1., 0.]) tensor([0.9189, 0.0811], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 52 - 121: cat - cat || Loss: 0.3942047953605652\n",
      "tensor([1., 0.]) tensor([0.9191, 0.0809], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 52 - 122: cat - cat || Loss: 0.39402443170547485\n",
      "tensor([1., 0.]) tensor([0.9192, 0.0808], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 52 - 123: cat - cat || Loss: 0.3938445448875427\n",
      "tensor([1., 0.]) tensor([0.9194, 0.0806], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 52 - 124: cat - cat || Loss: 0.393665075302124\n",
      "tensor([1., 0.]) tensor([0.9196, 0.0804], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 52 - 125: cat - cat || Loss: 0.39348605275154114\n",
      "tensor([1., 0.]) tensor([0.9198, 0.0802], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 52 - 126: cat - cat || Loss: 0.39330750703811646\n",
      "tensor([1., 0.]) tensor([0.9200, 0.0800], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 52 - 127: cat - cat || Loss: 0.3931293785572052\n",
      "tensor([1., 0.]) tensor([0.9201, 0.0799], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 52 - 128: cat - cat || Loss: 0.39295172691345215\n",
      "tensor([1., 0.]) tensor([0.9203, 0.0797], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 52 - 129: cat - cat || Loss: 0.3927745819091797\n",
      "tensor([1., 0.]) tensor([0.9205, 0.0795], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 52 - 130: cat - cat || Loss: 0.39259785413742065\n",
      "tensor([1., 0.]) tensor([0.9207, 0.0793], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 52 - 131: cat - cat || Loss: 0.39242154359817505\n",
      "tensor([1., 0.]) tensor([0.9208, 0.0792], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 52 - 132: cat - cat || Loss: 0.3922456204891205\n",
      "tensor([1., 0.]) tensor([0.9210, 0.0790], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 52 - 133: cat - cat || Loss: 0.3920702636241913\n",
      "tensor([1., 0.]) tensor([0.9212, 0.0788], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 52 - 134: cat - cat || Loss: 0.39189526438713074\n",
      "tensor([1., 0.]) tensor([0.9214, 0.0786], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 52 - 135: cat - cat || Loss: 0.39172083139419556\n",
      "tensor([1., 0.]) tensor([0.9215, 0.0785], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 52 - 136: cat - cat || Loss: 0.39154672622680664\n",
      "tensor([1., 0.]) tensor([0.9217, 0.0783], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 52 - 137: cat - cat || Loss: 0.39137303829193115\n",
      "tensor([1., 0.]) tensor([0.9219, 0.0781], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 52 - 138: cat - cat || Loss: 0.39119982719421387\n",
      "tensor([1., 0.]) tensor([0.9221, 0.0779], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 52 - 139: cat - cat || Loss: 0.3910270929336548\n",
      "tensor([1., 0.]) tensor([0.9222, 0.0778], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 52 - 140: cat - cat || Loss: 0.39085474610328674\n",
      "tensor([1., 0.]) tensor([0.9224, 0.0776], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 52 - 141: cat - cat || Loss: 0.3906828463077545\n",
      "tensor([1., 0.]) tensor([0.9226, 0.0774], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 52 - 142: cat - cat || Loss: 0.3905113935470581\n",
      "tensor([1., 0.]) tensor([0.9228, 0.0772], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 52 - 143: cat - cat || Loss: 0.39034032821655273\n",
      "tensor([1., 0.]) tensor([0.9229, 0.0771], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 52 - 144: cat - cat || Loss: 0.39016979932785034\n",
      "tensor([1., 0.]) tensor([0.9231, 0.0769], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 52 - 145: cat - cat || Loss: 0.3899996280670166\n",
      "tensor([1., 0.]) tensor([0.9233, 0.0767], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 52 - 146: cat - cat || Loss: 0.3898299038410187\n",
      "tensor([1., 0.]) tensor([0.9234, 0.0766], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 52 - 147: cat - cat || Loss: 0.38966065645217896\n",
      "tensor([1., 0.]) tensor([0.9236, 0.0764], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 52 - 148: cat - cat || Loss: 0.3894917368888855\n",
      "tensor([1., 0.]) tensor([0.9238, 0.0762], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 52 - 149: cat - cat || Loss: 0.389323353767395\n",
      "tensor([1., 0.]) tensor([0.9239, 0.0761], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 52 - 150: cat - cat || Loss: 0.38915523886680603\n",
      "tensor([1., 0.]) tensor([0.9241, 0.0759], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 52 - 151: cat - cat || Loss: 0.3889877200126648\n",
      "tensor([1., 0.]) tensor([0.9243, 0.0757], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 52 - 152: cat - cat || Loss: 0.3888205289840698\n",
      "tensor([1., 0.]) tensor([0.9244, 0.0756], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 52 - 153: cat - cat || Loss: 0.3886537551879883\n",
      "tensor([1., 0.]) tensor([0.9246, 0.0754], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 52 - 154: cat - cat || Loss: 0.38848742842674255\n",
      "tensor([1., 0.]) tensor([0.9248, 0.0752], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 52 - 155: cat - cat || Loss: 0.3883214294910431\n",
      "tensor([1., 0.]) tensor([0.9249, 0.0751], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 52 - 156: cat - cat || Loss: 0.3881560266017914\n",
      "tensor([1., 0.]) tensor([0.9251, 0.0749], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 52 - 157: cat - cat || Loss: 0.3879910111427307\n",
      "tensor([1., 0.]) tensor([0.9253, 0.0747], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 52 - 158: cat - cat || Loss: 0.38782623410224915\n",
      "tensor([1., 0.]) tensor([0.9254, 0.0746], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 52 - 159: cat - cat || Loss: 0.38766202330589294\n",
      "tensor([1., 0.]) tensor([0.9256, 0.0744], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 52 - 160: cat - cat || Loss: 0.387498140335083\n",
      "tensor([1., 0.]) tensor([0.9258, 0.0742], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 52 - 161: cat - cat || Loss: 0.38733476400375366\n",
      "tensor([1., 0.]) tensor([0.9259, 0.0741], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 52 - 162: cat - cat || Loss: 0.38717174530029297\n",
      "tensor([1., 0.]) tensor([0.9261, 0.0739], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 52 - 163: cat - cat || Loss: 0.3870090842247009\n",
      "tensor([1., 0.]) tensor([0.9263, 0.0737], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 52 - 164: cat - cat || Loss: 0.3868468999862671\n",
      "tensor([1., 0.]) tensor([0.9264, 0.0736], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 52 - 165: cat - cat || Loss: 0.3866851329803467\n",
      "tensor([1., 0.]) tensor([0.9266, 0.0734], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 52 - 166: cat - cat || Loss: 0.3865237534046173\n",
      "tensor([1., 0.]) tensor([0.9267, 0.0733], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 52 - 167: cat - cat || Loss: 0.386362761259079\n",
      "tensor([1., 0.]) tensor([0.9269, 0.0731], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 52 - 168: cat - cat || Loss: 0.38620221614837646\n",
      "tensor([1., 0.]) tensor([0.9271, 0.0729], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 52 - 169: cat - cat || Loss: 0.38604193925857544\n",
      "tensor([1., 0.]) tensor([0.9272, 0.0728], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 52 - 170: cat - cat || Loss: 0.385882169008255\n",
      "tensor([1., 0.]) tensor([0.9274, 0.0726], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 52 - 171: cat - cat || Loss: 0.3857228457927704\n",
      "tensor([1., 0.]) tensor([0.9275, 0.0725], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 52 - 172: cat - cat || Loss: 0.38556382060050964\n",
      "tensor([1., 0.]) tensor([0.9277, 0.0723], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 52 - 173: cat - cat || Loss: 0.3854052722454071\n",
      "tensor([1., 0.]) tensor([0.9279, 0.0721], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 52 - 174: cat - cat || Loss: 0.3852471113204956\n",
      "tensor([1., 0.]) tensor([0.9280, 0.0720], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 52 - 175: cat - cat || Loss: 0.38508927822113037\n",
      "tensor([1., 0.]) tensor([0.9282, 0.0718], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 52 - 176: cat - cat || Loss: 0.3849318027496338\n",
      "tensor([1., 0.]) tensor([0.9283, 0.0717], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 52 - 177: cat - cat || Loss: 0.3847748935222626\n",
      "tensor([1., 0.]) tensor([0.9285, 0.0715], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 52 - 178: cat - cat || Loss: 0.38461825251579285\n",
      "tensor([1., 0.]) tensor([0.9286, 0.0714], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 52 - 179: cat - cat || Loss: 0.38446199893951416\n",
      "tensor([1., 0.]) tensor([0.9288, 0.0712], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 52 - 180: cat - cat || Loss: 0.3843061625957489\n",
      "tensor([1., 0.]) tensor([0.9290, 0.0710], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 52 - 181: cat - cat || Loss: 0.3841506838798523\n",
      "tensor([1., 0.]) tensor([0.9291, 0.0709], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 52 - 182: cat - cat || Loss: 0.38399559259414673\n",
      "tensor([1., 0.]) tensor([0.9293, 0.0707], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 52 - 183: cat - cat || Loss: 0.383840948343277\n",
      "tensor([1., 0.]) tensor([0.9294, 0.0706], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 52 - 184: cat - cat || Loss: 0.38368654251098633\n",
      "tensor([1., 0.]) tensor([0.9296, 0.0704], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 52 - 185: cat - cat || Loss: 0.38353264331817627\n",
      "tensor([1., 0.]) tensor([0.9297, 0.0703], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 52 - 186: cat - cat || Loss: 0.3833789825439453\n",
      "tensor([1., 0.]) tensor([0.9299, 0.0701], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 52 - 187: cat - cat || Loss: 0.38322579860687256\n",
      "tensor([1., 0.]) tensor([0.9300, 0.0700], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 52 - 188: cat - cat || Loss: 0.38307279348373413\n",
      "tensor([1., 0.]) tensor([0.9302, 0.0698], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 52 - 189: cat - cat || Loss: 0.3829202353954315\n",
      "tensor([1., 0.]) tensor([0.9303, 0.0697], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 52 - 190: dog - cat || Loss: 1.2437553405761719\n",
      "tensor([0., 1.]) tensor([0.9305, 0.0695], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 52 - 191: dog - cat || Loss: 1.2438771724700928\n",
      "tensor([0., 1.]) tensor([0.9306, 0.0694], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 52 - 192: dog - cat || Loss: 1.243971586227417\n",
      "tensor([0., 1.]) tensor([0.9307, 0.0693], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 52 - 193: dog - cat || Loss: 1.2440415620803833\n",
      "tensor([0., 1.]) tensor([0.9308, 0.0692], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 52 - 194: dog - cat || Loss: 1.2440896034240723\n",
      "tensor([0., 1.]) tensor([0.9308, 0.0692], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 52 - 195: dog - cat || Loss: 1.2441178560256958\n",
      "tensor([0., 1.]) tensor([0.9309, 0.0691], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 52 - 196: dog - cat || Loss: 1.2441283464431763\n",
      "tensor([0., 1.]) tensor([0.9309, 0.0691], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 52 - 197: dog - cat || Loss: 1.2441226243972778\n",
      "tensor([0., 1.]) tensor([0.9309, 0.0691], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 52 - 198: dog - cat || Loss: 1.2441024780273438\n",
      "tensor([0., 1.]) tensor([0.9308, 0.0692], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 52 - 199: dog - cat || Loss: 1.2440695762634277\n",
      "tensor([0., 1.]) tensor([0.9308, 0.0692], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 52 - 200: dog - cat || Loss: 1.2440249919891357\n",
      "tensor([0., 1.]) tensor([0.9308, 0.0692], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 52 - 201: dog - cat || Loss: 1.2439699172973633\n",
      "tensor([0., 1.]) tensor([0.9307, 0.0693], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 52 - 202: dog - cat || Loss: 1.2439050674438477\n",
      "tensor([0., 1.]) tensor([0.9306, 0.0694], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 52 - 203: dog - cat || Loss: 1.243831753730774\n",
      "tensor([0., 1.]) tensor([0.9306, 0.0694], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 52 - 204: dog - cat || Loss: 1.243751049041748\n",
      "tensor([0., 1.]) tensor([0.9305, 0.0695], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 52 - 205: dog - cat || Loss: 1.24366295337677\n",
      "tensor([0., 1.]) tensor([0.9304, 0.0696], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 52 - 206: dog - cat || Loss: 1.2435688972473145\n",
      "tensor([0., 1.]) tensor([0.9303, 0.0697], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 52 - 207: dog - cat || Loss: 1.243468999862671\n",
      "tensor([0., 1.]) tensor([0.9302, 0.0698], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 52 - 208: dog - cat || Loss: 1.243363857269287\n",
      "tensor([0., 1.]) tensor([0.9301, 0.0699], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 52 - 209: dog - cat || Loss: 1.2432540655136108\n",
      "tensor([0., 1.]) tensor([0.9300, 0.0700], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 52 - 210: dog - cat || Loss: 1.2431399822235107\n",
      "tensor([0., 1.]) tensor([0.9299, 0.0701], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 52 - 211: dog - cat || Loss: 1.2430223226547241\n",
      "tensor([0., 1.]) tensor([0.9298, 0.0702], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 52 - 212: dog - cat || Loss: 1.2429008483886719\n",
      "tensor([0., 1.]) tensor([0.9296, 0.0704], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 52 - 213: dog - cat || Loss: 1.2427762746810913\n",
      "tensor([0., 1.]) tensor([0.9295, 0.0705], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 52 - 214: dog - cat || Loss: 1.242648959159851\n",
      "tensor([0., 1.]) tensor([0.9294, 0.0706], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 52 - 215: dog - cat || Loss: 1.2425187826156616\n",
      "tensor([0., 1.]) tensor([0.9293, 0.0707], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 52 - 216: dog - cat || Loss: 1.2423863410949707\n",
      "tensor([0., 1.]) tensor([0.9291, 0.0709], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 52 - 217: dog - cat || Loss: 1.2422515153884888\n",
      "tensor([0., 1.]) tensor([0.9290, 0.0710], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 52 - 218: dog - cat || Loss: 1.242114782333374\n",
      "tensor([0., 1.]) tensor([0.9289, 0.0711], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 52 - 219: dog - cat || Loss: 1.241976022720337\n",
      "tensor([0., 1.]) tensor([0.9287, 0.0713], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 52 - 220: dog - cat || Loss: 1.2418358325958252\n",
      "tensor([0., 1.]) tensor([0.9286, 0.0714], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 52 - 221: dog - cat || Loss: 1.2416937351226807\n",
      "tensor([0., 1.]) tensor([0.9284, 0.0716], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 52 - 222: dog - cat || Loss: 1.2415504455566406\n",
      "tensor([0., 1.]) tensor([0.9283, 0.0717], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 52 - 223: dog - cat || Loss: 1.2414056062698364\n",
      "tensor([0., 1.]) tensor([0.9281, 0.0719], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 52 - 224: dog - cat || Loss: 1.2412595748901367\n",
      "tensor([0., 1.]) tensor([0.9280, 0.0720], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 52 - 225: dog - cat || Loss: 1.241112470626831\n",
      "tensor([0., 1.]) tensor([0.9279, 0.0721], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 52 - 226: dog - cat || Loss: 1.2409640550613403\n",
      "tensor([0., 1.]) tensor([0.9277, 0.0723], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 52 - 227: dog - cat || Loss: 1.2408149242401123\n",
      "tensor([0., 1.]) tensor([0.9276, 0.0724], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 52 - 228: dog - cat || Loss: 1.2406646013259888\n",
      "tensor([0., 1.]) tensor([0.9274, 0.0726], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 52 - 229: dog - cat || Loss: 1.2405136823654175\n",
      "tensor([0., 1.]) tensor([0.9273, 0.0727], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 52 - 230: dog - cat || Loss: 1.2403613328933716\n",
      "tensor([0., 1.]) tensor([0.9271, 0.0729], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 52 - 231: dog - cat || Loss: 1.240208625793457\n",
      "tensor([0., 1.]) tensor([0.9269, 0.0731], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 52 - 232: dog - cat || Loss: 1.2400550842285156\n",
      "tensor([0., 1.]) tensor([0.9268, 0.0732], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 52 - 233: dog - cat || Loss: 1.239900827407837\n",
      "tensor([0., 1.]) tensor([0.9266, 0.0734], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 52 - 234: dog - cat || Loss: 1.239745855331421\n",
      "tensor([0., 1.]) tensor([0.9265, 0.0735], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 52 - 235: dog - cat || Loss: 1.2395902872085571\n",
      "tensor([0., 1.]) tensor([0.9263, 0.0737], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 52 - 236: dog - cat || Loss: 1.2394341230392456\n",
      "tensor([0., 1.]) tensor([0.9262, 0.0738], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 52 - 237: dog - cat || Loss: 1.2392772436141968\n",
      "tensor([0., 1.]) tensor([0.9260, 0.0740], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 52 - 238: dog - cat || Loss: 1.2391196489334106\n",
      "tensor([0., 1.]) tensor([0.9259, 0.0741], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 52 - 239: dog - cat || Loss: 1.2389615774154663\n",
      "tensor([0., 1.]) tensor([0.9257, 0.0743], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 52 - 240: dog - cat || Loss: 1.2388030290603638\n",
      "tensor([0., 1.]) tensor([0.9255, 0.0745], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 52 - 241: dog - cat || Loss: 1.2386438846588135\n",
      "tensor([0., 1.]) tensor([0.9254, 0.0746], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 52 - 242: dog - cat || Loss: 1.2384841442108154\n",
      "tensor([0., 1.]) tensor([0.9252, 0.0748], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 52 - 243: dog - cat || Loss: 1.2383241653442383\n",
      "tensor([0., 1.]) tensor([0.9251, 0.0749], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 52 - 244: dog - cat || Loss: 1.2381634712219238\n",
      "tensor([0., 1.]) tensor([0.9249, 0.0751], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 52 - 245: dog - cat || Loss: 1.2380024194717407\n",
      "tensor([0., 1.]) tensor([0.9247, 0.0753], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 52 - 246: dog - cat || Loss: 1.2378406524658203\n",
      "tensor([0., 1.]) tensor([0.9246, 0.0754], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 52 - 247: dog - cat || Loss: 1.2376786470413208\n",
      "tensor([0., 1.]) tensor([0.9244, 0.0756], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 52 - 248: dog - cat || Loss: 1.237515926361084\n",
      "tensor([0., 1.]) tensor([0.9243, 0.0757], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 52 - 249: dog - cat || Loss: 1.237352967262268\n",
      "tensor([0., 1.]) tensor([0.9241, 0.0759], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 52 - 250: dog - cat || Loss: 1.237189531326294\n",
      "tensor([0., 1.]) tensor([0.9239, 0.0761], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 52 - 251: dog - cat || Loss: 1.237025499343872\n",
      "tensor([0., 1.]) tensor([0.9238, 0.0762], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 52 - 252: dog - cat || Loss: 1.2368611097335815\n",
      "tensor([0., 1.]) tensor([0.9236, 0.0764], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 52 - 253: dog - cat || Loss: 1.2366963624954224\n",
      "tensor([0., 1.]) tensor([0.9234, 0.0766], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 52 - 254: dog - cat || Loss: 1.2365309000015259\n",
      "tensor([0., 1.]) tensor([0.9233, 0.0767], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 52 - 255: dog - cat || Loss: 1.2363653182983398\n",
      "tensor([0., 1.]) tensor([0.9231, 0.0769], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 52 - 256: dog - cat || Loss: 1.2361990213394165\n",
      "tensor([0., 1.]) tensor([0.9229, 0.0771], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 52 - 257: dog - cat || Loss: 1.236032485961914\n",
      "tensor([0., 1.]) tensor([0.9228, 0.0772], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 52 - 258: dog - cat || Loss: 1.235865592956543\n",
      "tensor([0., 1.]) tensor([0.9226, 0.0774], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 52 - 259: dog - cat || Loss: 1.2356981039047241\n",
      "tensor([0., 1.]) tensor([0.9224, 0.0776], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 52 - 260: dog - cat || Loss: 1.2355302572250366\n",
      "tensor([0., 1.]) tensor([0.9223, 0.0777], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 52 - 261: dog - cat || Loss: 1.2353618144989014\n",
      "tensor([0., 1.]) tensor([0.9221, 0.0779], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 52 - 262: dog - cat || Loss: 1.235193133354187\n",
      "tensor([0., 1.]) tensor([0.9219, 0.0781], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 52 - 263: dog - cat || Loss: 1.235023856163025\n",
      "tensor([0., 1.]) tensor([0.9218, 0.0782], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 52 - 264: dog - cat || Loss: 1.2348543405532837\n",
      "tensor([0., 1.]) tensor([0.9216, 0.0784], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 52 - 265: dog - cat || Loss: 1.2346843481063843\n",
      "tensor([0., 1.]) tensor([0.9214, 0.0786], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 52 - 266: dog - cat || Loss: 1.234513759613037\n",
      "tensor([0., 1.]) tensor([0.9213, 0.0787], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 52 - 267: dog - cat || Loss: 1.2343430519104004\n",
      "tensor([0., 1.]) tensor([0.9211, 0.0789], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 52 - 268: dog - cat || Loss: 1.2341715097427368\n",
      "tensor([0., 1.]) tensor([0.9209, 0.0791], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 52 - 269: dog - cat || Loss: 1.2339998483657837\n",
      "tensor([0., 1.]) tensor([0.9207, 0.0793], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 52 - 270: dog - cat || Loss: 1.2338277101516724\n",
      "tensor([0., 1.]) tensor([0.9206, 0.0794], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 52 - 271: dog - cat || Loss: 1.2336550951004028\n",
      "tensor([0., 1.]) tensor([0.9204, 0.0796], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 52 - 272: dog - cat || Loss: 1.233482003211975\n",
      "tensor([0., 1.]) tensor([0.9202, 0.0798], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 52 - 273: dog - cat || Loss: 1.2333084344863892\n",
      "tensor([0., 1.]) tensor([0.9200, 0.0800], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 52 - 274: dog - cat || Loss: 1.2331346273422241\n",
      "tensor([0., 1.]) tensor([0.9199, 0.0801], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 52 - 275: dog - cat || Loss: 1.2329602241516113\n",
      "tensor([0., 1.]) tensor([0.9197, 0.0803], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 52 - 276: dog - cat || Loss: 1.2327854633331299\n",
      "tensor([0., 1.]) tensor([0.9195, 0.0805], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 52 - 277: dog - cat || Loss: 1.2326103448867798\n",
      "tensor([0., 1.]) tensor([0.9193, 0.0807], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 52 - 278: dog - cat || Loss: 1.232434630393982\n",
      "tensor([0., 1.]) tensor([0.9192, 0.0808], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 52 - 279: dog - cat || Loss: 1.2322585582733154\n",
      "tensor([0., 1.]) tensor([0.9190, 0.0810], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 52 - 280: dog - cat || Loss: 1.2320821285247803\n",
      "tensor([0., 1.]) tensor([0.9188, 0.0812], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 52 - 281: dog - cat || Loss: 1.2319049835205078\n",
      "tensor([0., 1.]) tensor([0.9186, 0.0814], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 52 - 282: dog - cat || Loss: 1.2317277193069458\n",
      "tensor([0., 1.]) tensor([0.9185, 0.0815], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 52 - 283: dog - cat || Loss: 1.2315499782562256\n",
      "tensor([0., 1.]) tensor([0.9183, 0.0817], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 52 - 284: dog - cat || Loss: 1.231371521949768\n",
      "tensor([0., 1.]) tensor([0.9181, 0.0819], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 52 - 285: dog - cat || Loss: 1.2311930656433105\n",
      "tensor([0., 1.]) tensor([0.9179, 0.0821], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 52 - 286: dog - cat || Loss: 1.2310137748718262\n",
      "tensor([0., 1.]) tensor([0.9178, 0.0822], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 52 - 287: dog - cat || Loss: 1.2308341264724731\n",
      "tensor([0., 1.]) tensor([0.9176, 0.0824], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 52 - 288: dog - cat || Loss: 1.2306541204452515\n",
      "tensor([0., 1.]) tensor([0.9174, 0.0826], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 52 - 289: dog - cat || Loss: 1.2304736375808716\n",
      "tensor([0., 1.]) tensor([0.9172, 0.0828], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 52 - 290: dog - cat || Loss: 1.2302926778793335\n",
      "tensor([0., 1.]) tensor([0.9170, 0.0830], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 52 - 291: dog - cat || Loss: 1.2301114797592163\n",
      "tensor([0., 1.]) tensor([0.9168, 0.0832], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 52 - 292: dog - cat || Loss: 1.2299294471740723\n",
      "tensor([0., 1.]) tensor([0.9167, 0.0833], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 52 - 293: dog - cat || Loss: 1.2297474145889282\n",
      "tensor([0., 1.]) tensor([0.9165, 0.0835], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 52 - 294: dog - cat || Loss: 1.2295645475387573\n",
      "tensor([0., 1.]) tensor([0.9163, 0.0837], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 52 - 295: dog - cat || Loss: 1.2293814420700073\n",
      "tensor([0., 1.]) tensor([0.9161, 0.0839], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 52 - 296: dog - cat || Loss: 1.2291977405548096\n",
      "tensor([0., 1.]) tensor([0.9159, 0.0841], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 52 - 297: dog - cat || Loss: 1.2290136814117432\n",
      "tensor([0., 1.]) tensor([0.9158, 0.0842], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 52 - 298: dog - cat || Loss: 1.2288291454315186\n",
      "tensor([0., 1.]) tensor([0.9156, 0.0844], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 52 - 299: dog - cat || Loss: 1.2286440134048462\n",
      "tensor([0., 1.]) tensor([0.9154, 0.0846], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 52 - 300: dog - cat || Loss: 1.2284586429595947\n",
      "tensor([0., 1.]) tensor([0.9152, 0.0848], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 52 - 301: dog - cat || Loss: 1.228272795677185\n",
      "tensor([0., 1.]) tensor([0.9150, 0.0850], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 52 - 302: dog - cat || Loss: 1.2280864715576172\n",
      "tensor([0., 1.]) tensor([0.9148, 0.0852], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 52 - 303: dog - cat || Loss: 1.2278996706008911\n",
      "tensor([0., 1.]) tensor([0.9146, 0.0854], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 52 - 304: dog - cat || Loss: 1.2277123928070068\n",
      "tensor([0., 1.]) tensor([0.9145, 0.0855], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 52 - 305: dog - cat || Loss: 1.2275246381759644\n",
      "tensor([0., 1.]) tensor([0.9143, 0.0857], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 52 - 306: dog - cat || Loss: 1.2273364067077637\n",
      "tensor([0., 1.]) tensor([0.9141, 0.0859], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 52 - 307: dog - cat || Loss: 1.2271478176116943\n",
      "tensor([0., 1.]) tensor([0.9139, 0.0861], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 52 - 308: dog - cat || Loss: 1.2269586324691772\n",
      "tensor([0., 1.]) tensor([0.9137, 0.0863], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 52 - 309: dog - cat || Loss: 1.226769208908081\n",
      "tensor([0., 1.]) tensor([0.9135, 0.0865], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 52 - 310: dog - cat || Loss: 1.226578950881958\n",
      "tensor([0., 1.]) tensor([0.9133, 0.0867], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 52 - 311: dog - cat || Loss: 1.2263883352279663\n",
      "tensor([0., 1.]) tensor([0.9131, 0.0869], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 52 - 312: dog - cat || Loss: 1.2261974811553955\n",
      "tensor([0., 1.]) tensor([0.9129, 0.0871], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 52 - 313: dog - cat || Loss: 1.226006031036377\n",
      "tensor([0., 1.]) tensor([0.9127, 0.0873], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 52 - 314: dog - cat || Loss: 1.2258139848709106\n",
      "tensor([0., 1.]) tensor([0.9126, 0.0874], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 52 - 315: dog - cat || Loss: 1.2256217002868652\n",
      "tensor([0., 1.]) tensor([0.9124, 0.0876], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 52 - 316: dog - cat || Loss: 1.225428819656372\n",
      "tensor([0., 1.]) tensor([0.9122, 0.0878], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 52 - 317: dog - cat || Loss: 1.2252354621887207\n",
      "tensor([0., 1.]) tensor([0.9120, 0.0880], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 52 - 318: dog - cat || Loss: 1.2250415086746216\n",
      "tensor([0., 1.]) tensor([0.9118, 0.0882], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 52 - 319: dog - cat || Loss: 1.224847435951233\n",
      "tensor([0., 1.]) tensor([0.9116, 0.0884], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 52 - 320: dog - cat || Loss: 1.2246525287628174\n",
      "tensor([0., 1.]) tensor([0.9114, 0.0886], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 52 - 321: dog - cat || Loss: 1.2244573831558228\n",
      "tensor([0., 1.]) tensor([0.9112, 0.0888], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 52 - 322: dog - cat || Loss: 1.2242616415023804\n",
      "tensor([0., 1.]) tensor([0.9110, 0.0890], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 52 - 323: dog - cat || Loss: 1.2240654230117798\n",
      "tensor([0., 1.]) tensor([0.9108, 0.0892], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 52 - 324: dog - cat || Loss: 1.223868727684021\n",
      "tensor([0., 1.]) tensor([0.9106, 0.0894], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 52 - 325: dog - cat || Loss: 1.223671555519104\n",
      "tensor([0., 1.]) tensor([0.9104, 0.0896], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 52 - 326: dog - cat || Loss: 1.2234737873077393\n",
      "tensor([0., 1.]) tensor([0.9102, 0.0898], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 52 - 327: dog - cat || Loss: 1.2232757806777954\n",
      "tensor([0., 1.]) tensor([0.9100, 0.0900], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 52 - 328: dog - cat || Loss: 1.2230770587921143\n",
      "tensor([0., 1.]) tensor([0.9098, 0.0902], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 52 - 329: dog - cat || Loss: 1.2228779792785645\n",
      "tensor([0., 1.]) tensor([0.9096, 0.0904], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 52 - 330: dog - cat || Loss: 1.222678303718567\n",
      "tensor([0., 1.]) tensor([0.9094, 0.0906], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 52 - 331: dog - cat || Loss: 1.2224782705307007\n",
      "tensor([0., 1.]) tensor([0.9092, 0.0908], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 52 - 332: dog - cat || Loss: 1.2222776412963867\n",
      "tensor([0., 1.]) tensor([0.9090, 0.0910], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 52 - 333: dog - cat || Loss: 1.2220765352249146\n",
      "tensor([0., 1.]) tensor([0.9088, 0.0912], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 52 - 334: dog - cat || Loss: 1.2218749523162842\n",
      "tensor([0., 1.]) tensor([0.9086, 0.0914], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 52 - 335: dog - cat || Loss: 1.2216728925704956\n",
      "tensor([0., 1.]) tensor([0.9084, 0.0916], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 52 - 336: dog - cat || Loss: 1.2214704751968384\n",
      "tensor([0., 1.]) tensor([0.9082, 0.0918], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 52 - 337: dog - cat || Loss: 1.2212673425674438\n",
      "tensor([0., 1.]) tensor([0.9080, 0.0920], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 52 - 338: dog - cat || Loss: 1.2210637331008911\n",
      "tensor([0., 1.]) tensor([0.9078, 0.0922], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 52 - 339: dog - cat || Loss: 1.2208596467971802\n",
      "tensor([0., 1.]) tensor([0.9076, 0.0924], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 52 - 340: dog - cat || Loss: 1.220655083656311\n",
      "tensor([0., 1.]) tensor([0.9074, 0.0926], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 52 - 341: dog - cat || Loss: 1.2204501628875732\n",
      "tensor([0., 1.]) tensor([0.9072, 0.0928], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 52 - 342: dog - cat || Loss: 1.2202444076538086\n",
      "tensor([0., 1.]) tensor([0.9070, 0.0930], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 52 - 343: dog - cat || Loss: 1.2200385332107544\n",
      "tensor([0., 1.]) tensor([0.9068, 0.0932], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 52 - 344: dog - cat || Loss: 1.2198318243026733\n",
      "tensor([0., 1.]) tensor([0.9066, 0.0934], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 52 - 345: dog - cat || Loss: 1.2196247577667236\n",
      "tensor([0., 1.]) tensor([0.9064, 0.0936], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 52 - 346: dog - cat || Loss: 1.2194170951843262\n",
      "tensor([0., 1.]) tensor([0.9062, 0.0938], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 52 - 347: dog - cat || Loss: 1.2192089557647705\n",
      "tensor([0., 1.]) tensor([0.9059, 0.0941], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 52 - 348: dog - cat || Loss: 1.2190003395080566\n",
      "tensor([0., 1.]) tensor([0.9057, 0.0943], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 52 - 349: dog - cat || Loss: 1.2187912464141846\n",
      "tensor([0., 1.]) tensor([0.9055, 0.0945], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 52 - 350: dog - cat || Loss: 1.2185816764831543\n",
      "tensor([0., 1.]) tensor([0.9053, 0.0947], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 52 - 351: dog - cat || Loss: 1.2183713912963867\n",
      "tensor([0., 1.]) tensor([0.9051, 0.0949], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 52 - 352: dog - cat || Loss: 1.218160629272461\n",
      "tensor([0., 1.]) tensor([0.9049, 0.0951], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 52 - 353: dog - cat || Loss: 1.2179495096206665\n",
      "tensor([0., 1.]) tensor([0.9047, 0.0953], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 52 - 354: dog - cat || Loss: 1.2177376747131348\n",
      "tensor([0., 1.]) tensor([0.9045, 0.0955], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 52 - 355: dog - cat || Loss: 1.2175254821777344\n",
      "tensor([0., 1.]) tensor([0.9043, 0.0957], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 52 - 356: dog - cat || Loss: 1.2173126935958862\n",
      "tensor([0., 1.]) tensor([0.9041, 0.0959], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 52 - 357: dog - cat || Loss: 1.2170994281768799\n",
      "tensor([0., 1.]) tensor([0.9038, 0.0962], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 52 - 358: dog - cat || Loss: 1.2168856859207153\n",
      "tensor([0., 1.]) tensor([0.9036, 0.0964], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 52 - 359: dog - cat || Loss: 1.216671347618103\n",
      "tensor([0., 1.]) tensor([0.9034, 0.0966], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 52 - 360: dog - cat || Loss: 1.216456413269043\n",
      "tensor([0., 1.]) tensor([0.9032, 0.0968], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 52 - 361: dog - cat || Loss: 1.2162410020828247\n",
      "tensor([0., 1.]) tensor([0.9030, 0.0970], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 52 - 362: dog - cat || Loss: 1.2160249948501587\n",
      "tensor([0., 1.]) tensor([0.9028, 0.0972], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 52 - 363: dog - cat || Loss: 1.2158087491989136\n",
      "tensor([0., 1.]) tensor([0.9025, 0.0975], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 52 - 364: dog - cat || Loss: 1.215591549873352\n",
      "tensor([0., 1.]) tensor([0.9023, 0.0977], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 52 - 365: dog - cat || Loss: 1.215374231338501\n",
      "tensor([0., 1.]) tensor([0.9021, 0.0979], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 52 - 366: dog - cat || Loss: 1.215156078338623\n",
      "tensor([0., 1.]) tensor([0.9019, 0.0981], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 52 - 367: dog - cat || Loss: 1.2149375677108765\n",
      "tensor([0., 1.]) tensor([0.9017, 0.0983], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 52 - 368: dog - cat || Loss: 1.2147184610366821\n",
      "tensor([0., 1.]) tensor([0.9015, 0.0985], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 52 - 369: dog - cat || Loss: 1.21449875831604\n",
      "tensor([0., 1.]) tensor([0.9012, 0.0988], grad_fn=<SoftmaxBackward0>)\n",
      "=====epoch:53=====\n",
      "Epoch 53 - 0: cat - cat || Loss: 0.41224467754364014\n",
      "tensor([1., 0.]) tensor([0.9010, 0.0990], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 53 - 1: cat - cat || Loss: 0.41242074966430664\n",
      "tensor([1., 0.]) tensor([0.9008, 0.0992], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 53 - 2: cat - cat || Loss: 0.41255712509155273\n",
      "tensor([1., 0.]) tensor([0.9007, 0.0993], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 53 - 3: cat - cat || Loss: 0.41265738010406494\n",
      "tensor([1., 0.]) tensor([0.9006, 0.0994], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 53 - 4: cat - cat || Loss: 0.4127252697944641\n",
      "tensor([1., 0.]) tensor([0.9005, 0.0995], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 53 - 5: cat - cat || Loss: 0.4127640128135681\n",
      "tensor([1., 0.]) tensor([0.9005, 0.0995], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 53 - 6: cat - cat || Loss: 0.4127764403820038\n",
      "tensor([1., 0.]) tensor([0.9005, 0.0995], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 53 - 7: cat - cat || Loss: 0.41276517510414124\n",
      "tensor([1., 0.]) tensor([0.9005, 0.0995], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 53 - 8: cat - cat || Loss: 0.4127326011657715\n",
      "tensor([1., 0.]) tensor([0.9005, 0.0995], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 53 - 9: cat - cat || Loss: 0.4126809239387512\n",
      "tensor([1., 0.]) tensor([0.9006, 0.0994], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 53 - 10: cat - cat || Loss: 0.4126119017601013\n",
      "tensor([1., 0.]) tensor([0.9006, 0.0994], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 53 - 11: cat - cat || Loss: 0.41252750158309937\n",
      "tensor([1., 0.]) tensor([0.9007, 0.0993], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 53 - 12: cat - cat || Loss: 0.41242924332618713\n",
      "tensor([1., 0.]) tensor([0.9008, 0.0992], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 53 - 13: cat - cat || Loss: 0.41231852769851685\n",
      "tensor([1., 0.]) tensor([0.9009, 0.0991], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 53 - 14: cat - cat || Loss: 0.41219663619995117\n",
      "tensor([1., 0.]) tensor([0.9011, 0.0989], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 53 - 15: cat - cat || Loss: 0.41206464171409607\n",
      "tensor([1., 0.]) tensor([0.9012, 0.0988], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 53 - 16: cat - cat || Loss: 0.41192376613616943\n",
      "tensor([1., 0.]) tensor([0.9013, 0.0987], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 53 - 17: cat - cat || Loss: 0.4117748737335205\n",
      "tensor([1., 0.]) tensor([0.9015, 0.0985], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 53 - 18: cat - cat || Loss: 0.41161882877349854\n",
      "tensor([1., 0.]) tensor([0.9016, 0.0984], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 53 - 19: cat - cat || Loss: 0.4114563465118408\n",
      "tensor([1., 0.]) tensor([0.9018, 0.0982], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 53 - 20: cat - cat || Loss: 0.4112880229949951\n",
      "tensor([1., 0.]) tensor([0.9020, 0.0980], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 53 - 21: cat - cat || Loss: 0.41111481189727783\n",
      "tensor([1., 0.]) tensor([0.9021, 0.0979], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 53 - 22: cat - cat || Loss: 0.41093701124191284\n",
      "tensor([1., 0.]) tensor([0.9023, 0.0977], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 53 - 23: cat - cat || Loss: 0.4107552766799927\n",
      "tensor([1., 0.]) tensor([0.9025, 0.0975], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 53 - 24: cat - cat || Loss: 0.41056978702545166\n",
      "tensor([1., 0.]) tensor([0.9027, 0.0973], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 53 - 25: cat - cat || Loss: 0.4103813171386719\n",
      "tensor([1., 0.]) tensor([0.9029, 0.0971], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 53 - 26: cat - cat || Loss: 0.4101899564266205\n",
      "tensor([1., 0.]) tensor([0.9031, 0.0969], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 53 - 27: cat - cat || Loss: 0.4099962115287781\n",
      "tensor([1., 0.]) tensor([0.9033, 0.0967], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 53 - 28: cat - cat || Loss: 0.40980035066604614\n",
      "tensor([1., 0.]) tensor([0.9035, 0.0965], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 53 - 29: cat - cat || Loss: 0.40960246324539185\n",
      "tensor([1., 0.]) tensor([0.9037, 0.0963], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 53 - 30: cat - cat || Loss: 0.4094030261039734\n",
      "tensor([1., 0.]) tensor([0.9039, 0.0961], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 53 - 31: cat - cat || Loss: 0.40920203924179077\n",
      "tensor([1., 0.]) tensor([0.9041, 0.0959], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 53 - 32: cat - cat || Loss: 0.40899986028671265\n",
      "tensor([1., 0.]) tensor([0.9043, 0.0957], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 53 - 33: cat - cat || Loss: 0.4087967872619629\n",
      "tensor([1., 0.]) tensor([0.9045, 0.0955], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 53 - 34: cat - cat || Loss: 0.4085926413536072\n",
      "tensor([1., 0.]) tensor([0.9047, 0.0953], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 53 - 35: cat - cat || Loss: 0.40838780999183655\n",
      "tensor([1., 0.]) tensor([0.9049, 0.0951], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 53 - 36: cat - cat || Loss: 0.40818241238594055\n",
      "tensor([1., 0.]) tensor([0.9051, 0.0949], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 53 - 37: cat - cat || Loss: 0.4079764485359192\n",
      "tensor([1., 0.]) tensor([0.9053, 0.0947], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 53 - 38: cat - cat || Loss: 0.407770037651062\n",
      "tensor([1., 0.]) tensor([0.9055, 0.0945], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 53 - 39: cat - cat || Loss: 0.40756335854530334\n",
      "tensor([1., 0.]) tensor([0.9057, 0.0943], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 53 - 40: cat - cat || Loss: 0.4073566198348999\n",
      "tensor([1., 0.]) tensor([0.9059, 0.0941], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 53 - 41: cat - cat || Loss: 0.4071494936943054\n",
      "tensor([1., 0.]) tensor([0.9061, 0.0939], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 53 - 42: cat - cat || Loss: 0.40694236755371094\n",
      "tensor([1., 0.]) tensor([0.9063, 0.0937], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 53 - 43: cat - cat || Loss: 0.4067351818084717\n",
      "tensor([1., 0.]) tensor([0.9065, 0.0935], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 53 - 44: cat - cat || Loss: 0.40652820467948914\n",
      "tensor([1., 0.]) tensor([0.9067, 0.0933], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 53 - 45: cat - cat || Loss: 0.4063211679458618\n",
      "tensor([1., 0.]) tensor([0.9069, 0.0931], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 53 - 46: cat - cat || Loss: 0.40611428022384644\n",
      "tensor([1., 0.]) tensor([0.9071, 0.0929], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 53 - 47: cat - cat || Loss: 0.4059075713157654\n",
      "tensor([1., 0.]) tensor([0.9074, 0.0926], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 53 - 48: cat - cat || Loss: 0.4057011306285858\n",
      "tensor([1., 0.]) tensor([0.9076, 0.0924], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 53 - 49: cat - cat || Loss: 0.4054948091506958\n",
      "tensor([1., 0.]) tensor([0.9078, 0.0922], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 53 - 50: cat - cat || Loss: 0.40528884530067444\n",
      "tensor([1., 0.]) tensor([0.9080, 0.0920], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 53 - 51: cat - cat || Loss: 0.4050831198692322\n",
      "tensor([1., 0.]) tensor([0.9082, 0.0918], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 53 - 52: cat - cat || Loss: 0.4048776626586914\n",
      "tensor([1., 0.]) tensor([0.9084, 0.0916], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 53 - 53: cat - cat || Loss: 0.4046725928783417\n",
      "tensor([1., 0.]) tensor([0.9086, 0.0914], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 53 - 54: cat - cat || Loss: 0.4044678509235382\n",
      "tensor([1., 0.]) tensor([0.9088, 0.0912], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 53 - 55: cat - cat || Loss: 0.4042634963989258\n",
      "tensor([1., 0.]) tensor([0.9090, 0.0910], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 53 - 56: cat - cat || Loss: 0.4040594696998596\n",
      "tensor([1., 0.]) tensor([0.9092, 0.0908], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 53 - 57: cat - cat || Loss: 0.4038558006286621\n",
      "tensor([1., 0.]) tensor([0.9094, 0.0906], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 53 - 58: cat - cat || Loss: 0.4036526679992676\n",
      "tensor([1., 0.]) tensor([0.9096, 0.0904], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 53 - 59: cat - cat || Loss: 0.4034498929977417\n",
      "tensor([1., 0.]) tensor([0.9098, 0.0902], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 53 - 60: cat - cat || Loss: 0.4032474756240845\n",
      "tensor([1., 0.]) tensor([0.9100, 0.0900], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 53 - 61: cat - cat || Loss: 0.40304550528526306\n",
      "tensor([1., 0.]) tensor([0.9102, 0.0898], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 53 - 62: cat - cat || Loss: 0.40284398198127747\n",
      "tensor([1., 0.]) tensor([0.9104, 0.0896], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 53 - 63: cat - cat || Loss: 0.4026429057121277\n",
      "tensor([1., 0.]) tensor([0.9106, 0.0894], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 53 - 64: cat - cat || Loss: 0.4024422764778137\n",
      "tensor([1., 0.]) tensor([0.9108, 0.0892], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 53 - 65: cat - cat || Loss: 0.40224212408065796\n",
      "tensor([1., 0.]) tensor([0.9110, 0.0890], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 53 - 66: cat - cat || Loss: 0.40204232931137085\n",
      "tensor([1., 0.]) tensor([0.9112, 0.0888], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 53 - 67: cat - cat || Loss: 0.40184319019317627\n",
      "tensor([1., 0.]) tensor([0.9114, 0.0886], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 53 - 68: cat - cat || Loss: 0.40164434909820557\n",
      "tensor([1., 0.]) tensor([0.9116, 0.0884], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 53 - 69: cat - cat || Loss: 0.40144604444503784\n",
      "tensor([1., 0.]) tensor([0.9118, 0.0882], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 53 - 70: cat - cat || Loss: 0.4012482166290283\n",
      "tensor([1., 0.]) tensor([0.9120, 0.0880], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 53 - 71: cat - cat || Loss: 0.401050865650177\n",
      "tensor([1., 0.]) tensor([0.9122, 0.0878], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 53 - 72: cat - cat || Loss: 0.4008539319038391\n",
      "tensor([1., 0.]) tensor([0.9124, 0.0876], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 53 - 73: cat - cat || Loss: 0.4006575047969818\n",
      "tensor([1., 0.]) tensor([0.9126, 0.0874], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 53 - 74: cat - cat || Loss: 0.40046149492263794\n",
      "tensor([1., 0.]) tensor([0.9128, 0.0872], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 53 - 75: cat - cat || Loss: 0.40026605129241943\n",
      "tensor([1., 0.]) tensor([0.9130, 0.0870], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 53 - 76: cat - cat || Loss: 0.40007108449935913\n",
      "tensor([1., 0.]) tensor([0.9132, 0.0868], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 53 - 77: cat - cat || Loss: 0.39987659454345703\n",
      "tensor([1., 0.]) tensor([0.9134, 0.0866], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 53 - 78: cat - cat || Loss: 0.39968249201774597\n",
      "tensor([1., 0.]) tensor([0.9136, 0.0864], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 53 - 79: cat - cat || Loss: 0.3994889259338379\n",
      "tensor([1., 0.]) tensor([0.9138, 0.0862], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 53 - 80: cat - cat || Loss: 0.3992958664894104\n",
      "tensor([1., 0.]) tensor([0.9140, 0.0860], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 53 - 81: cat - cat || Loss: 0.39910322427749634\n",
      "tensor([1., 0.]) tensor([0.9142, 0.0858], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 53 - 82: cat - cat || Loss: 0.3989110589027405\n",
      "tensor([1., 0.]) tensor([0.9144, 0.0856], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 53 - 83: cat - cat || Loss: 0.39871945977211\n",
      "tensor([1., 0.]) tensor([0.9145, 0.0855], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 53 - 84: cat - cat || Loss: 0.3985283076763153\n",
      "tensor([1., 0.]) tensor([0.9147, 0.0853], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 53 - 85: cat - cat || Loss: 0.39833760261535645\n",
      "tensor([1., 0.]) tensor([0.9149, 0.0851], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 53 - 86: cat - cat || Loss: 0.3981474041938782\n",
      "tensor([1., 0.]) tensor([0.9151, 0.0849], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 53 - 87: cat - cat || Loss: 0.39795762300491333\n",
      "tensor([1., 0.]) tensor([0.9153, 0.0847], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 53 - 88: cat - cat || Loss: 0.39776837825775146\n",
      "tensor([1., 0.]) tensor([0.9155, 0.0845], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 53 - 89: cat - cat || Loss: 0.3975796103477478\n",
      "tensor([1., 0.]) tensor([0.9157, 0.0843], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 53 - 90: cat - cat || Loss: 0.39739125967025757\n",
      "tensor([1., 0.]) tensor([0.9159, 0.0841], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 53 - 91: cat - cat || Loss: 0.39720335602760315\n",
      "tensor([1., 0.]) tensor([0.9161, 0.0839], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 53 - 92: cat - cat || Loss: 0.3970160186290741\n",
      "tensor([1., 0.]) tensor([0.9162, 0.0838], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 53 - 93: cat - cat || Loss: 0.39682912826538086\n",
      "tensor([1., 0.]) tensor([0.9164, 0.0836], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 53 - 94: cat - cat || Loss: 0.39664268493652344\n",
      "tensor([1., 0.]) tensor([0.9166, 0.0834], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 53 - 95: cat - cat || Loss: 0.3964567184448242\n",
      "tensor([1., 0.]) tensor([0.9168, 0.0832], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 53 - 96: cat - cat || Loss: 0.3962711989879608\n",
      "tensor([1., 0.]) tensor([0.9170, 0.0830], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 53 - 97: cat - cat || Loss: 0.3960861563682556\n",
      "tensor([1., 0.]) tensor([0.9172, 0.0828], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 53 - 98: cat - cat || Loss: 0.39590153098106384\n",
      "tensor([1., 0.]) tensor([0.9174, 0.0826], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 53 - 99: cat - cat || Loss: 0.3957175314426422\n",
      "tensor([1., 0.]) tensor([0.9175, 0.0825], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 53 - 100: cat - cat || Loss: 0.39553385972976685\n",
      "tensor([1., 0.]) tensor([0.9177, 0.0823], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 53 - 101: cat - cat || Loss: 0.39535075426101685\n",
      "tensor([1., 0.]) tensor([0.9179, 0.0821], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 53 - 102: cat - cat || Loss: 0.3951680660247803\n",
      "tensor([1., 0.]) tensor([0.9181, 0.0819], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 53 - 103: cat - cat || Loss: 0.3949858248233795\n",
      "tensor([1., 0.]) tensor([0.9183, 0.0817], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 53 - 104: cat - cat || Loss: 0.39480406045913696\n",
      "tensor([1., 0.]) tensor([0.9185, 0.0815], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 53 - 105: cat - cat || Loss: 0.3946227431297302\n",
      "tensor([1., 0.]) tensor([0.9186, 0.0814], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 53 - 106: cat - cat || Loss: 0.3944419026374817\n",
      "tensor([1., 0.]) tensor([0.9188, 0.0812], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 53 - 107: cat - cat || Loss: 0.39426153898239136\n",
      "tensor([1., 0.]) tensor([0.9190, 0.0810], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 53 - 108: cat - cat || Loss: 0.39408159255981445\n",
      "tensor([1., 0.]) tensor([0.9192, 0.0808], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 53 - 109: cat - cat || Loss: 0.39390212297439575\n",
      "tensor([1., 0.]) tensor([0.9194, 0.0806], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 53 - 110: cat - cat || Loss: 0.3937230706214905\n",
      "tensor([1., 0.]) tensor([0.9195, 0.0805], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 53 - 111: cat - cat || Loss: 0.3935445547103882\n",
      "tensor([1., 0.]) tensor([0.9197, 0.0803], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 53 - 112: cat - cat || Loss: 0.3933663070201874\n",
      "tensor([1., 0.]) tensor([0.9199, 0.0801], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 53 - 113: cat - cat || Loss: 0.3931887149810791\n",
      "tensor([1., 0.]) tensor([0.9201, 0.0799], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 53 - 114: cat - cat || Loss: 0.3930114209651947\n",
      "tensor([1., 0.]) tensor([0.9203, 0.0797], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 53 - 115: cat - cat || Loss: 0.3928346633911133\n",
      "tensor([1., 0.]) tensor([0.9204, 0.0796], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 53 - 116: cat - cat || Loss: 0.3926583528518677\n",
      "tensor([1., 0.]) tensor([0.9206, 0.0794], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 53 - 117: cat - cat || Loss: 0.3924824297428131\n",
      "tensor([1., 0.]) tensor([0.9208, 0.0792], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 53 - 118: cat - cat || Loss: 0.39230698347091675\n",
      "tensor([1., 0.]) tensor([0.9210, 0.0790], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 53 - 119: cat - cat || Loss: 0.392132043838501\n",
      "tensor([1., 0.]) tensor([0.9211, 0.0789], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 53 - 120: cat - cat || Loss: 0.39195743203163147\n",
      "tensor([1., 0.]) tensor([0.9213, 0.0787], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 53 - 121: cat - cat || Loss: 0.39178329706192017\n",
      "tensor([1., 0.]) tensor([0.9215, 0.0785], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 53 - 122: cat - cat || Loss: 0.39160963892936707\n",
      "tensor([1., 0.]) tensor([0.9217, 0.0783], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 53 - 123: cat - cat || Loss: 0.39143648743629456\n",
      "tensor([1., 0.]) tensor([0.9218, 0.0782], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 53 - 124: cat - cat || Loss: 0.3912637233734131\n",
      "tensor([1., 0.]) tensor([0.9220, 0.0780], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 53 - 125: cat - cat || Loss: 0.39109140634536743\n",
      "tensor([1., 0.]) tensor([0.9222, 0.0778], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 53 - 126: cat - cat || Loss: 0.39091944694519043\n",
      "tensor([1., 0.]) tensor([0.9223, 0.0777], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 53 - 127: cat - cat || Loss: 0.39074790477752686\n",
      "tensor([1., 0.]) tensor([0.9225, 0.0775], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 53 - 128: cat - cat || Loss: 0.39057692885398865\n",
      "tensor([1., 0.]) tensor([0.9227, 0.0773], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 53 - 129: cat - cat || Loss: 0.3904063105583191\n",
      "tensor([1., 0.]) tensor([0.9229, 0.0771], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 53 - 130: cat - cat || Loss: 0.3902361989021301\n",
      "tensor([1., 0.]) tensor([0.9230, 0.0770], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 53 - 131: cat - cat || Loss: 0.39006638526916504\n",
      "tensor([1., 0.]) tensor([0.9232, 0.0768], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 53 - 132: cat - cat || Loss: 0.38989704847335815\n",
      "tensor([1., 0.]) tensor([0.9234, 0.0766], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 53 - 133: cat - cat || Loss: 0.3897281885147095\n",
      "tensor([1., 0.]) tensor([0.9235, 0.0765], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 53 - 134: cat - cat || Loss: 0.38955968618392944\n",
      "tensor([1., 0.]) tensor([0.9237, 0.0763], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 53 - 135: cat - cat || Loss: 0.3893917202949524\n",
      "tensor([1., 0.]) tensor([0.9239, 0.0761], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 53 - 136: cat - cat || Loss: 0.389224112033844\n",
      "tensor([1., 0.]) tensor([0.9240, 0.0760], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 53 - 137: cat - cat || Loss: 0.38905689120292664\n",
      "tensor([1., 0.]) tensor([0.9242, 0.0758], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 53 - 138: cat - cat || Loss: 0.3888901472091675\n",
      "tensor([1., 0.]) tensor([0.9244, 0.0756], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 53 - 139: cat - cat || Loss: 0.38872379064559937\n",
      "tensor([1., 0.]) tensor([0.9245, 0.0755], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 53 - 140: cat - cat || Loss: 0.3885578513145447\n",
      "tensor([1., 0.]) tensor([0.9247, 0.0753], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 53 - 141: cat - cat || Loss: 0.38839229941368103\n",
      "tensor([1., 0.]) tensor([0.9249, 0.0751], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 53 - 142: cat - cat || Loss: 0.38822731375694275\n",
      "tensor([1., 0.]) tensor([0.9250, 0.0750], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 53 - 143: cat - cat || Loss: 0.3880625367164612\n",
      "tensor([1., 0.]) tensor([0.9252, 0.0748], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 53 - 144: cat - cat || Loss: 0.38789835572242737\n",
      "tensor([1., 0.]) tensor([0.9254, 0.0746], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 53 - 145: cat - cat || Loss: 0.38773447275161743\n",
      "tensor([1., 0.]) tensor([0.9255, 0.0745], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 53 - 146: cat - cat || Loss: 0.3875710666179657\n",
      "tensor([1., 0.]) tensor([0.9257, 0.0743], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 53 - 147: cat - cat || Loss: 0.3874080777168274\n",
      "tensor([1., 0.]) tensor([0.9259, 0.0741], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 53 - 148: cat - cat || Loss: 0.3872454762458801\n",
      "tensor([1., 0.]) tensor([0.9260, 0.0740], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 53 - 149: cat - cat || Loss: 0.3870832622051239\n",
      "tensor([1., 0.]) tensor([0.9262, 0.0738], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 53 - 150: cat - cat || Loss: 0.38692140579223633\n",
      "tensor([1., 0.]) tensor([0.9263, 0.0737], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 53 - 151: cat - cat || Loss: 0.38675999641418457\n",
      "tensor([1., 0.]) tensor([0.9265, 0.0735], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 53 - 152: cat - cat || Loss: 0.3865990936756134\n",
      "tensor([1., 0.]) tensor([0.9267, 0.0733], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 53 - 153: cat - cat || Loss: 0.3864384591579437\n",
      "tensor([1., 0.]) tensor([0.9268, 0.0732], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 53 - 154: cat - cat || Loss: 0.38627833127975464\n",
      "tensor([1., 0.]) tensor([0.9270, 0.0730], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 53 - 155: cat - cat || Loss: 0.3861185312271118\n",
      "tensor([1., 0.]) tensor([0.9271, 0.0729], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 53 - 156: cat - cat || Loss: 0.3859591484069824\n",
      "tensor([1., 0.]) tensor([0.9273, 0.0727], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 53 - 157: cat - cat || Loss: 0.38580024242401123\n",
      "tensor([1., 0.]) tensor([0.9275, 0.0725], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 53 - 158: cat - cat || Loss: 0.38564160466194153\n",
      "tensor([1., 0.]) tensor([0.9276, 0.0724], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 53 - 159: cat - cat || Loss: 0.38548341393470764\n",
      "tensor([1., 0.]) tensor([0.9278, 0.0722], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 53 - 160: cat - cat || Loss: 0.3853256404399872\n",
      "tensor([1., 0.]) tensor([0.9279, 0.0721], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 53 - 161: cat - cat || Loss: 0.38516831398010254\n",
      "tensor([1., 0.]) tensor([0.9281, 0.0719], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 53 - 162: cat - cat || Loss: 0.38501134514808655\n",
      "tensor([1., 0.]) tensor([0.9283, 0.0717], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 53 - 163: cat - cat || Loss: 0.38485467433929443\n",
      "tensor([1., 0.]) tensor([0.9284, 0.0716], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 53 - 164: cat - cat || Loss: 0.3846985399723053\n",
      "tensor([1., 0.]) tensor([0.9286, 0.0714], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 53 - 165: cat - cat || Loss: 0.38454270362854004\n",
      "tensor([1., 0.]) tensor([0.9287, 0.0713], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 53 - 166: cat - cat || Loss: 0.3843872547149658\n",
      "tensor([1., 0.]) tensor([0.9289, 0.0711], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 53 - 167: cat - cat || Loss: 0.38423222303390503\n",
      "tensor([1., 0.]) tensor([0.9290, 0.0710], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 53 - 168: cat - cat || Loss: 0.3840775787830353\n",
      "tensor([1., 0.]) tensor([0.9292, 0.0708], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 53 - 169: cat - cat || Loss: 0.3839232921600342\n",
      "tensor([1., 0.]) tensor([0.9293, 0.0707], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 53 - 170: cat - cat || Loss: 0.3837693929672241\n",
      "tensor([1., 0.]) tensor([0.9295, 0.0705], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 53 - 171: cat - cat || Loss: 0.38361597061157227\n",
      "tensor([1., 0.]) tensor([0.9296, 0.0704], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 53 - 172: cat - cat || Loss: 0.3834627866744995\n",
      "tensor([1., 0.]) tensor([0.9298, 0.0702], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 53 - 173: cat - cat || Loss: 0.38331010937690735\n",
      "tensor([1., 0.]) tensor([0.9300, 0.0700], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 53 - 174: cat - cat || Loss: 0.38315773010253906\n",
      "tensor([1., 0.]) tensor([0.9301, 0.0699], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 53 - 175: cat - cat || Loss: 0.3830057680606842\n",
      "tensor([1., 0.]) tensor([0.9303, 0.0697], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 53 - 176: cat - cat || Loss: 0.3828541338443756\n",
      "tensor([1., 0.]) tensor([0.9304, 0.0696], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 53 - 177: cat - cat || Loss: 0.38270291686058044\n",
      "tensor([1., 0.]) tensor([0.9306, 0.0694], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 53 - 178: cat - cat || Loss: 0.38255205750465393\n",
      "tensor([1., 0.]) tensor([0.9307, 0.0693], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 53 - 179: cat - cat || Loss: 0.38240158557891846\n",
      "tensor([1., 0.]) tensor([0.9309, 0.0691], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 53 - 180: cat - cat || Loss: 0.38225147128105164\n",
      "tensor([1., 0.]) tensor([0.9310, 0.0690], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 53 - 181: cat - cat || Loss: 0.3821016848087311\n",
      "tensor([1., 0.]) tensor([0.9312, 0.0688], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 53 - 182: cat - cat || Loss: 0.38195228576660156\n",
      "tensor([1., 0.]) tensor([0.9313, 0.0687], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 53 - 183: cat - cat || Loss: 0.38180333375930786\n",
      "tensor([1., 0.]) tensor([0.9315, 0.0685], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 53 - 184: cat - cat || Loss: 0.3816545605659485\n",
      "tensor([1., 0.]) tensor([0.9316, 0.0684], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 53 - 185: cat - cat || Loss: 0.3815063238143921\n",
      "tensor([1., 0.]) tensor([0.9318, 0.0682], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 53 - 186: cat - cat || Loss: 0.3813582956790924\n",
      "tensor([1., 0.]) tensor([0.9319, 0.0681], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 53 - 187: cat - cat || Loss: 0.3812107443809509\n",
      "tensor([1., 0.]) tensor([0.9321, 0.0679], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 53 - 188: cat - cat || Loss: 0.38106346130371094\n",
      "tensor([1., 0.]) tensor([0.9322, 0.0678], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 53 - 189: cat - cat || Loss: 0.3809165358543396\n",
      "tensor([1., 0.]) tensor([0.9323, 0.0677], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 53 - 190: dog - cat || Loss: 1.245753526687622\n",
      "tensor([0., 1.]) tensor([0.9325, 0.0675], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 53 - 191: dog - cat || Loss: 1.2458709478378296\n",
      "tensor([0., 1.]) tensor([0.9326, 0.0674], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 53 - 192: dog - cat || Loss: 1.2459617853164673\n",
      "tensor([0., 1.]) tensor([0.9327, 0.0673], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 53 - 193: dog - cat || Loss: 1.2460291385650635\n",
      "tensor([0., 1.]) tensor([0.9328, 0.0672], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 53 - 194: dog - cat || Loss: 1.2460755109786987\n",
      "tensor([0., 1.]) tensor([0.9328, 0.0672], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 53 - 195: dog - cat || Loss: 1.2461026906967163\n",
      "tensor([0., 1.]) tensor([0.9328, 0.0672], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 53 - 196: dog - cat || Loss: 1.246112585067749\n",
      "tensor([0., 1.]) tensor([0.9329, 0.0671], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 53 - 197: dog - cat || Loss: 1.2461072206497192\n",
      "tensor([0., 1.]) tensor([0.9328, 0.0672], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 53 - 198: dog - cat || Loss: 1.246087908744812\n",
      "tensor([0., 1.]) tensor([0.9328, 0.0672], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 53 - 199: dog - cat || Loss: 1.246056079864502\n",
      "tensor([0., 1.]) tensor([0.9328, 0.0672], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 53 - 200: dog - cat || Loss: 1.2460131645202637\n",
      "tensor([0., 1.]) tensor([0.9328, 0.0672], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 53 - 201: dog - cat || Loss: 1.245959997177124\n",
      "tensor([0., 1.]) tensor([0.9327, 0.0673], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 53 - 202: dog - cat || Loss: 1.2458977699279785\n",
      "tensor([0., 1.]) tensor([0.9326, 0.0674], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 53 - 203: dog - cat || Loss: 1.2458274364471436\n",
      "tensor([0., 1.]) tensor([0.9326, 0.0674], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 53 - 204: dog - cat || Loss: 1.2457493543624878\n",
      "tensor([0., 1.]) tensor([0.9325, 0.0675], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 53 - 205: dog - cat || Loss: 1.2456647157669067\n",
      "tensor([0., 1.]) tensor([0.9324, 0.0676], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 53 - 206: dog - cat || Loss: 1.2455739974975586\n",
      "tensor([0., 1.]) tensor([0.9323, 0.0677], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 53 - 207: dog - cat || Loss: 1.2454777956008911\n",
      "tensor([0., 1.]) tensor([0.9322, 0.0678], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 53 - 208: dog - cat || Loss: 1.2453765869140625\n",
      "tensor([0., 1.]) tensor([0.9321, 0.0679], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 53 - 209: dog - cat || Loss: 1.2452709674835205\n",
      "tensor([0., 1.]) tensor([0.9320, 0.0680], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 53 - 210: dog - cat || Loss: 1.2451610565185547\n",
      "tensor([0., 1.]) tensor([0.9319, 0.0681], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 53 - 211: dog - cat || Loss: 1.2450475692749023\n",
      "tensor([0., 1.]) tensor([0.9318, 0.0682], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 53 - 212: dog - cat || Loss: 1.244930624961853\n",
      "tensor([0., 1.]) tensor([0.9317, 0.0683], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 53 - 213: dog - cat || Loss: 1.244810700416565\n",
      "tensor([0., 1.]) tensor([0.9315, 0.0685], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 53 - 214: dog - cat || Loss: 1.2446880340576172\n",
      "tensor([0., 1.]) tensor([0.9314, 0.0686], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 53 - 215: dog - cat || Loss: 1.2445627450942993\n",
      "tensor([0., 1.]) tensor([0.9313, 0.0687], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 53 - 216: dog - cat || Loss: 1.2444350719451904\n",
      "tensor([0., 1.]) tensor([0.9312, 0.0688], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 53 - 217: dog - cat || Loss: 1.2443053722381592\n",
      "tensor([0., 1.]) tensor([0.9310, 0.0690], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 53 - 218: dog - cat || Loss: 1.244173526763916\n",
      "tensor([0., 1.]) tensor([0.9309, 0.0691], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 53 - 219: dog - cat || Loss: 1.2440400123596191\n",
      "tensor([0., 1.]) tensor([0.9308, 0.0692], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 53 - 220: dog - cat || Loss: 1.243904948234558\n",
      "tensor([0., 1.]) tensor([0.9306, 0.0694], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 53 - 221: dog - cat || Loss: 1.2437684535980225\n",
      "tensor([0., 1.]) tensor([0.9305, 0.0695], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 53 - 222: dog - cat || Loss: 1.2436301708221436\n",
      "tensor([0., 1.]) tensor([0.9304, 0.0696], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 53 - 223: dog - cat || Loss: 1.2434905767440796\n",
      "tensor([0., 1.]) tensor([0.9302, 0.0698], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 53 - 224: dog - cat || Loss: 1.2433501482009888\n",
      "tensor([0., 1.]) tensor([0.9301, 0.0699], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 53 - 225: dog - cat || Loss: 1.243208408355713\n",
      "tensor([0., 1.]) tensor([0.9299, 0.0701], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 53 - 226: dog - cat || Loss: 1.2430654764175415\n",
      "tensor([0., 1.]) tensor([0.9298, 0.0702], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 53 - 227: dog - cat || Loss: 1.2429217100143433\n",
      "tensor([0., 1.]) tensor([0.9297, 0.0703], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 53 - 228: dog - cat || Loss: 1.2427771091461182\n",
      "tensor([0., 1.]) tensor([0.9295, 0.0705], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 53 - 229: dog - cat || Loss: 1.2426316738128662\n",
      "tensor([0., 1.]) tensor([0.9294, 0.0706], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 53 - 230: dog - cat || Loss: 1.2424851655960083\n",
      "tensor([0., 1.]) tensor([0.9292, 0.0708], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 53 - 231: dog - cat || Loss: 1.2423380613327026\n",
      "tensor([0., 1.]) tensor([0.9291, 0.0709], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 53 - 232: dog - cat || Loss: 1.2421903610229492\n",
      "tensor([0., 1.]) tensor([0.9289, 0.0711], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 53 - 233: dog - cat || Loss: 1.2420417070388794\n",
      "tensor([0., 1.]) tensor([0.9288, 0.0712], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 53 - 234: dog - cat || Loss: 1.2418923377990723\n",
      "tensor([0., 1.]) tensor([0.9286, 0.0714], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 53 - 235: dog - cat || Loss: 1.241742730140686\n",
      "tensor([0., 1.]) tensor([0.9285, 0.0715], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 53 - 236: dog - cat || Loss: 1.2415920495986938\n",
      "tensor([0., 1.]) tensor([0.9283, 0.0717], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 53 - 237: dog - cat || Loss: 1.2414411306381226\n",
      "tensor([0., 1.]) tensor([0.9282, 0.0718], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 53 - 238: dog - cat || Loss: 1.2412896156311035\n",
      "tensor([0., 1.]) tensor([0.9280, 0.0720], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 53 - 239: dog - cat || Loss: 1.2411373853683472\n",
      "tensor([0., 1.]) tensor([0.9279, 0.0721], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 53 - 240: dog - cat || Loss: 1.240984559059143\n",
      "tensor([0., 1.]) tensor([0.9277, 0.0723], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 53 - 241: dog - cat || Loss: 1.2408312559127808\n",
      "tensor([0., 1.]) tensor([0.9276, 0.0724], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 53 - 242: dog - cat || Loss: 1.2406775951385498\n",
      "tensor([0., 1.]) tensor([0.9274, 0.0726], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 53 - 243: dog - cat || Loss: 1.2405234575271606\n",
      "tensor([0., 1.]) tensor([0.9273, 0.0727], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 53 - 244: dog - cat || Loss: 1.2403687238693237\n",
      "tensor([0., 1.]) tensor([0.9271, 0.0729], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 53 - 245: dog - cat || Loss: 1.2402136325836182\n",
      "tensor([0., 1.]) tensor([0.9270, 0.0730], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 53 - 246: dog - cat || Loss: 1.2400580644607544\n",
      "tensor([0., 1.]) tensor([0.9268, 0.0732], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 53 - 247: dog - cat || Loss: 1.2399019002914429\n",
      "tensor([0., 1.]) tensor([0.9266, 0.0734], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 53 - 248: dog - cat || Loss: 1.2397453784942627\n",
      "tensor([0., 1.]) tensor([0.9265, 0.0735], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 53 - 249: dog - cat || Loss: 1.2395883798599243\n",
      "tensor([0., 1.]) tensor([0.9263, 0.0737], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 53 - 250: dog - cat || Loss: 1.2394307851791382\n",
      "tensor([0., 1.]) tensor([0.9262, 0.0738], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 53 - 251: dog - cat || Loss: 1.2392730712890625\n",
      "tensor([0., 1.]) tensor([0.9260, 0.0740], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 53 - 252: dog - cat || Loss: 1.239114761352539\n",
      "tensor([0., 1.]) tensor([0.9259, 0.0741], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 53 - 253: dog - cat || Loss: 1.238956093788147\n",
      "tensor([0., 1.]) tensor([0.9257, 0.0743], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 53 - 254: dog - cat || Loss: 1.2387970685958862\n",
      "tensor([0., 1.]) tensor([0.9255, 0.0745], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 53 - 255: dog - cat || Loss: 1.2386374473571777\n",
      "tensor([0., 1.]) tensor([0.9254, 0.0746], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 53 - 256: dog - cat || Loss: 1.238477349281311\n",
      "tensor([0., 1.]) tensor([0.9252, 0.0748], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 53 - 257: dog - cat || Loss: 1.2383170127868652\n",
      "tensor([0., 1.]) tensor([0.9251, 0.0749], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 53 - 258: dog - cat || Loss: 1.2381561994552612\n",
      "tensor([0., 1.]) tensor([0.9249, 0.0751], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 53 - 259: dog - cat || Loss: 1.2379950284957886\n",
      "tensor([0., 1.]) tensor([0.9247, 0.0753], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 53 - 260: dog - cat || Loss: 1.2378332614898682\n",
      "tensor([0., 1.]) tensor([0.9246, 0.0754], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 53 - 261: dog - cat || Loss: 1.237671136856079\n",
      "tensor([0., 1.]) tensor([0.9244, 0.0756], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 53 - 262: dog - cat || Loss: 1.2375088930130005\n",
      "tensor([0., 1.]) tensor([0.9242, 0.0758], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 53 - 263: dog - cat || Loss: 1.2373460531234741\n",
      "tensor([0., 1.]) tensor([0.9241, 0.0759], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 53 - 264: dog - cat || Loss: 1.2371827363967896\n",
      "tensor([0., 1.]) tensor([0.9239, 0.0761], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 53 - 265: dog - cat || Loss: 1.2370189428329468\n",
      "tensor([0., 1.]) tensor([0.9238, 0.0762], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 53 - 266: dog - cat || Loss: 1.2368547916412354\n",
      "tensor([0., 1.]) tensor([0.9236, 0.0764], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 53 - 267: dog - cat || Loss: 1.2366902828216553\n",
      "tensor([0., 1.]) tensor([0.9234, 0.0766], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 53 - 268: dog - cat || Loss: 1.2365251779556274\n",
      "tensor([0., 1.]) tensor([0.9233, 0.0767], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 53 - 269: dog - cat || Loss: 1.23635995388031\n",
      "tensor([0., 1.]) tensor([0.9231, 0.0769], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 53 - 270: dog - cat || Loss: 1.236194133758545\n",
      "tensor([0., 1.]) tensor([0.9229, 0.0771], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 53 - 271: dog - cat || Loss: 1.2360280752182007\n",
      "tensor([0., 1.]) tensor([0.9228, 0.0772], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 53 - 272: dog - cat || Loss: 1.2358614206314087\n",
      "tensor([0., 1.]) tensor([0.9226, 0.0774], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 53 - 273: dog - cat || Loss: 1.2356942892074585\n",
      "tensor([0., 1.]) tensor([0.9224, 0.0776], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 53 - 274: dog - cat || Loss: 1.2355268001556396\n",
      "tensor([0., 1.]) tensor([0.9223, 0.0777], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 53 - 275: dog - cat || Loss: 1.2353590726852417\n",
      "tensor([0., 1.]) tensor([0.9221, 0.0779], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 53 - 276: dog - cat || Loss: 1.2351908683776855\n",
      "tensor([0., 1.]) tensor([0.9219, 0.0781], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 53 - 277: dog - cat || Loss: 1.2350223064422607\n",
      "tensor([0., 1.]) tensor([0.9218, 0.0782], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 53 - 278: dog - cat || Loss: 1.2348531484603882\n",
      "tensor([0., 1.]) tensor([0.9216, 0.0784], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 53 - 279: dog - cat || Loss: 1.2346837520599365\n",
      "tensor([0., 1.]) tensor([0.9214, 0.0786], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 53 - 280: dog - cat || Loss: 1.2345136404037476\n",
      "tensor([0., 1.]) tensor([0.9213, 0.0787], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 53 - 281: dog - cat || Loss: 1.234343409538269\n",
      "tensor([0., 1.]) tensor([0.9211, 0.0789], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 53 - 282: dog - cat || Loss: 1.2341724634170532\n",
      "tensor([0., 1.]) tensor([0.9209, 0.0791], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 53 - 283: dog - cat || Loss: 1.2340013980865479\n",
      "tensor([0., 1.]) tensor([0.9207, 0.0793], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 53 - 284: dog - cat || Loss: 1.2338297367095947\n",
      "tensor([0., 1.]) tensor([0.9206, 0.0794], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 53 - 285: dog - cat || Loss: 1.2336578369140625\n",
      "tensor([0., 1.]) tensor([0.9204, 0.0796], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 53 - 286: dog - cat || Loss: 1.2334853410720825\n",
      "tensor([0., 1.]) tensor([0.9202, 0.0798], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 53 - 287: dog - cat || Loss: 1.2333124876022339\n",
      "tensor([0., 1.]) tensor([0.9201, 0.0799], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 53 - 288: dog - cat || Loss: 1.2331390380859375\n",
      "tensor([0., 1.]) tensor([0.9199, 0.0801], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 53 - 289: dog - cat || Loss: 1.2329654693603516\n",
      "tensor([0., 1.]) tensor([0.9197, 0.0803], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 53 - 290: dog - cat || Loss: 1.2327913045883179\n",
      "tensor([0., 1.]) tensor([0.9195, 0.0805], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 53 - 291: dog - cat || Loss: 1.232616662979126\n",
      "tensor([0., 1.]) tensor([0.9194, 0.0806], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 53 - 292: dog - cat || Loss: 1.2324415445327759\n",
      "tensor([0., 1.]) tensor([0.9192, 0.0808], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 53 - 293: dog - cat || Loss: 1.2322661876678467\n",
      "tensor([0., 1.]) tensor([0.9190, 0.0810], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 53 - 294: dog - cat || Loss: 1.2320902347564697\n",
      "tensor([0., 1.]) tensor([0.9188, 0.0812], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 53 - 295: dog - cat || Loss: 1.2319140434265137\n",
      "tensor([0., 1.]) tensor([0.9187, 0.0813], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 53 - 296: dog - cat || Loss: 1.2317372560501099\n",
      "tensor([0., 1.]) tensor([0.9185, 0.0815], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 53 - 297: dog - cat || Loss: 1.231560230255127\n",
      "tensor([0., 1.]) tensor([0.9183, 0.0817], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 53 - 298: dog - cat || Loss: 1.2313824892044067\n",
      "tensor([0., 1.]) tensor([0.9181, 0.0819], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 53 - 299: dog - cat || Loss: 1.2312045097351074\n",
      "tensor([0., 1.]) tensor([0.9179, 0.0821], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 53 - 300: dog - cat || Loss: 1.2310259342193604\n",
      "tensor([0., 1.]) tensor([0.9178, 0.0822], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 53 - 301: dog - cat || Loss: 1.2308471202850342\n",
      "tensor([0., 1.]) tensor([0.9176, 0.0824], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 53 - 302: dog - cat || Loss: 1.2306677103042603\n",
      "tensor([0., 1.]) tensor([0.9174, 0.0826], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 53 - 303: dog - cat || Loss: 1.2304878234863281\n",
      "tensor([0., 1.]) tensor([0.9172, 0.0828], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 53 - 304: dog - cat || Loss: 1.230307698249817\n",
      "tensor([0., 1.]) tensor([0.9170, 0.0830], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 53 - 305: dog - cat || Loss: 1.230126976966858\n",
      "tensor([0., 1.]) tensor([0.9169, 0.0831], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 53 - 306: dog - cat || Loss: 1.2299457788467407\n",
      "tensor([0., 1.]) tensor([0.9167, 0.0833], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 53 - 307: dog - cat || Loss: 1.2297642230987549\n",
      "tensor([0., 1.]) tensor([0.9165, 0.0835], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 53 - 308: dog - cat || Loss: 1.2295820713043213\n",
      "tensor([0., 1.]) tensor([0.9163, 0.0837], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 53 - 309: dog - cat || Loss: 1.2293996810913086\n",
      "tensor([0., 1.]) tensor([0.9161, 0.0839], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 53 - 310: dog - cat || Loss: 1.2292166948318481\n",
      "tensor([0., 1.]) tensor([0.9160, 0.0840], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 53 - 311: dog - cat || Loss: 1.229033350944519\n",
      "tensor([0., 1.]) tensor([0.9158, 0.0842], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 53 - 312: dog - cat || Loss: 1.2288495302200317\n",
      "tensor([0., 1.]) tensor([0.9156, 0.0844], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 53 - 313: dog - cat || Loss: 1.2286653518676758\n",
      "tensor([0., 1.]) tensor([0.9154, 0.0846], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 53 - 314: dog - cat || Loss: 1.2284804582595825\n",
      "tensor([0., 1.]) tensor([0.9152, 0.0848], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 53 - 315: dog - cat || Loss: 1.2282953262329102\n",
      "tensor([0., 1.]) tensor([0.9150, 0.0850], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 53 - 316: dog - cat || Loss: 1.2281097173690796\n",
      "tensor([0., 1.]) tensor([0.9148, 0.0852], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 53 - 317: dog - cat || Loss: 1.2279236316680908\n",
      "tensor([0., 1.]) tensor([0.9147, 0.0853], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 53 - 318: dog - cat || Loss: 1.2277369499206543\n",
      "tensor([0., 1.]) tensor([0.9145, 0.0855], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 53 - 319: dog - cat || Loss: 1.2275500297546387\n",
      "tensor([0., 1.]) tensor([0.9143, 0.0857], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 53 - 320: dog - cat || Loss: 1.2273626327514648\n",
      "tensor([0., 1.]) tensor([0.9141, 0.0859], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 53 - 321: dog - cat || Loss: 1.2271745204925537\n",
      "tensor([0., 1.]) tensor([0.9139, 0.0861], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 53 - 322: dog - cat || Loss: 1.226986289024353\n",
      "tensor([0., 1.]) tensor([0.9137, 0.0863], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 53 - 323: dog - cat || Loss: 1.2267972230911255\n",
      "tensor([0., 1.]) tensor([0.9135, 0.0865], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 53 - 324: dog - cat || Loss: 1.2266080379486084\n",
      "tensor([0., 1.]) tensor([0.9133, 0.0867], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 53 - 325: dog - cat || Loss: 1.2264182567596436\n",
      "tensor([0., 1.]) tensor([0.9132, 0.0868], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 53 - 326: dog - cat || Loss: 1.226227879524231\n",
      "tensor([0., 1.]) tensor([0.9130, 0.0870], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 53 - 327: dog - cat || Loss: 1.2260371446609497\n",
      "tensor([0., 1.]) tensor([0.9128, 0.0872], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 53 - 328: dog - cat || Loss: 1.2258460521697998\n",
      "tensor([0., 1.]) tensor([0.9126, 0.0874], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 53 - 329: dog - cat || Loss: 1.2256542444229126\n",
      "tensor([0., 1.]) tensor([0.9124, 0.0876], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 53 - 330: dog - cat || Loss: 1.2254620790481567\n",
      "tensor([0., 1.]) tensor([0.9122, 0.0878], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 53 - 331: dog - cat || Loss: 1.2252694368362427\n",
      "tensor([0., 1.]) tensor([0.9120, 0.0880], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 53 - 332: dog - cat || Loss: 1.22507643699646\n",
      "tensor([0., 1.]) tensor([0.9118, 0.0882], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 53 - 333: dog - cat || Loss: 1.22488272190094\n",
      "tensor([0., 1.]) tensor([0.9116, 0.0884], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 53 - 334: dog - cat || Loss: 1.2246886491775513\n",
      "tensor([0., 1.]) tensor([0.9114, 0.0886], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 53 - 335: dog - cat || Loss: 1.2244939804077148\n",
      "tensor([0., 1.]) tensor([0.9112, 0.0888], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 53 - 336: dog - cat || Loss: 1.2242990732192993\n",
      "tensor([0., 1.]) tensor([0.9110, 0.0890], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 53 - 337: dog - cat || Loss: 1.2241034507751465\n",
      "tensor([0., 1.]) tensor([0.9108, 0.0892], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 53 - 338: dog - cat || Loss: 1.223907470703125\n",
      "tensor([0., 1.]) tensor([0.9106, 0.0894], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 53 - 339: dog - cat || Loss: 1.2237111330032349\n",
      "tensor([0., 1.]) tensor([0.9104, 0.0896], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 53 - 340: dog - cat || Loss: 1.2235140800476074\n",
      "tensor([0., 1.]) tensor([0.9103, 0.0897], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 53 - 341: dog - cat || Loss: 1.2233166694641113\n",
      "tensor([0., 1.]) tensor([0.9101, 0.0899], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 53 - 342: dog - cat || Loss: 1.2231186628341675\n",
      "tensor([0., 1.]) tensor([0.9099, 0.0901], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 53 - 343: dog - cat || Loss: 1.222920298576355\n",
      "tensor([0., 1.]) tensor([0.9097, 0.0903], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 53 - 344: dog - cat || Loss: 1.2227213382720947\n",
      "tensor([0., 1.]) tensor([0.9095, 0.0905], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 53 - 345: dog - cat || Loss: 1.2225220203399658\n",
      "tensor([0., 1.]) tensor([0.9093, 0.0907], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 53 - 346: dog - cat || Loss: 1.2223219871520996\n",
      "tensor([0., 1.]) tensor([0.9091, 0.0909], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 53 - 347: dog - cat || Loss: 1.2221215963363647\n",
      "tensor([0., 1.]) tensor([0.9089, 0.0911], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 53 - 348: dog - cat || Loss: 1.2219207286834717\n",
      "tensor([0., 1.]) tensor([0.9087, 0.0913], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 53 - 349: dog - cat || Loss: 1.22171950340271\n",
      "tensor([0., 1.]) tensor([0.9085, 0.0915], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 53 - 350: dog - cat || Loss: 1.2215174436569214\n",
      "tensor([0., 1.]) tensor([0.9083, 0.0917], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 53 - 351: dog - cat || Loss: 1.2213151454925537\n",
      "tensor([0., 1.]) tensor([0.9081, 0.0919], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 53 - 352: dog - cat || Loss: 1.2211122512817383\n",
      "tensor([0., 1.]) tensor([0.9079, 0.0921], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 53 - 353: dog - cat || Loss: 1.220908761024475\n",
      "tensor([0., 1.]) tensor([0.9076, 0.0924], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 53 - 354: dog - cat || Loss: 1.2207046747207642\n",
      "tensor([0., 1.]) tensor([0.9074, 0.0926], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 53 - 355: dog - cat || Loss: 1.2205005884170532\n",
      "tensor([0., 1.]) tensor([0.9072, 0.0928], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 53 - 356: dog - cat || Loss: 1.2202956676483154\n",
      "tensor([0., 1.]) tensor([0.9070, 0.0930], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 53 - 357: dog - cat || Loss: 1.2200901508331299\n",
      "tensor([0., 1.]) tensor([0.9068, 0.0932], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 53 - 358: dog - cat || Loss: 1.2198843955993652\n",
      "tensor([0., 1.]) tensor([0.9066, 0.0934], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 53 - 359: dog - cat || Loss: 1.2196779251098633\n",
      "tensor([0., 1.]) tensor([0.9064, 0.0936], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 53 - 360: dog - cat || Loss: 1.2194709777832031\n",
      "tensor([0., 1.]) tensor([0.9062, 0.0938], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 53 - 361: dog - cat || Loss: 1.2192636728286743\n",
      "tensor([0., 1.]) tensor([0.9060, 0.0940], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 53 - 362: dog - cat || Loss: 1.2190555334091187\n",
      "tensor([0., 1.]) tensor([0.9058, 0.0942], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 53 - 363: dog - cat || Loss: 1.2188472747802734\n",
      "tensor([0., 1.]) tensor([0.9056, 0.0944], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 53 - 364: dog - cat || Loss: 1.2186381816864014\n",
      "tensor([0., 1.]) tensor([0.9054, 0.0946], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 53 - 365: dog - cat || Loss: 1.2184288501739502\n",
      "tensor([0., 1.]) tensor([0.9052, 0.0948], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 53 - 366: dog - cat || Loss: 1.2182186841964722\n",
      "tensor([0., 1.]) tensor([0.9050, 0.0950], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 53 - 367: dog - cat || Loss: 1.218008279800415\n",
      "tensor([0., 1.]) tensor([0.9047, 0.0953], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 53 - 368: dog - cat || Loss: 1.2177971601486206\n",
      "tensor([0., 1.]) tensor([0.9045, 0.0955], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 53 - 369: dog - cat || Loss: 1.217585563659668\n",
      "tensor([0., 1.]) tensor([0.9043, 0.0957], grad_fn=<SoftmaxBackward0>)\n",
      "=====epoch:54=====\n",
      "Epoch 54 - 0: cat - cat || Loss: 0.40914976596832275\n",
      "tensor([1., 0.]) tensor([0.9041, 0.0959], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 54 - 1: cat - cat || Loss: 0.40931928157806396\n",
      "tensor([1., 0.]) tensor([0.9039, 0.0961], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 54 - 2: cat - cat || Loss: 0.40945056080818176\n",
      "tensor([1., 0.]) tensor([0.9038, 0.0962], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 54 - 3: cat - cat || Loss: 0.4095471501350403\n",
      "tensor([1., 0.]) tensor([0.9037, 0.0963], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 54 - 4: cat - cat || Loss: 0.4096125364303589\n",
      "tensor([1., 0.]) tensor([0.9036, 0.0964], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 54 - 5: cat - cat || Loss: 0.4096498191356659\n",
      "tensor([1., 0.]) tensor([0.9036, 0.0964], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 54 - 6: cat - cat || Loss: 0.40966176986694336\n",
      "tensor([1., 0.]) tensor([0.9036, 0.0964], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 54 - 7: cat - cat || Loss: 0.40965092182159424\n",
      "tensor([1., 0.]) tensor([0.9036, 0.0964], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 54 - 8: cat - cat || Loss: 0.4096195697784424\n",
      "tensor([1., 0.]) tensor([0.9036, 0.0964], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 54 - 9: cat - cat || Loss: 0.40956974029541016\n",
      "tensor([1., 0.]) tensor([0.9037, 0.0963], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 54 - 10: cat - cat || Loss: 0.4095032513141632\n",
      "tensor([1., 0.]) tensor([0.9038, 0.0962], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 54 - 11: cat - cat || Loss: 0.40942198038101196\n",
      "tensor([1., 0.]) tensor([0.9038, 0.0962], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 54 - 12: cat - cat || Loss: 0.40932732820510864\n",
      "tensor([1., 0.]) tensor([0.9039, 0.0961], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 54 - 13: cat - cat || Loss: 0.4092206358909607\n",
      "tensor([1., 0.]) tensor([0.9040, 0.0960], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 54 - 14: cat - cat || Loss: 0.4091032147407532\n",
      "tensor([1., 0.]) tensor([0.9042, 0.0958], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 54 - 15: cat - cat || Loss: 0.40897613763809204\n",
      "tensor([1., 0.]) tensor([0.9043, 0.0957], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 54 - 16: cat - cat || Loss: 0.40884044766426086\n",
      "tensor([1., 0.]) tensor([0.9044, 0.0956], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 54 - 17: cat - cat || Loss: 0.4086969494819641\n",
      "tensor([1., 0.]) tensor([0.9046, 0.0954], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 54 - 18: cat - cat || Loss: 0.40854668617248535\n",
      "tensor([1., 0.]) tensor([0.9047, 0.0953], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 54 - 19: cat - cat || Loss: 0.40839019417762756\n",
      "tensor([1., 0.]) tensor([0.9049, 0.0951], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 54 - 20: cat - cat || Loss: 0.4082281291484833\n",
      "tensor([1., 0.]) tensor([0.9050, 0.0950], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 54 - 21: cat - cat || Loss: 0.4080612361431122\n",
      "tensor([1., 0.]) tensor([0.9052, 0.0948], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 54 - 22: cat - cat || Loss: 0.40789005160331726\n",
      "tensor([1., 0.]) tensor([0.9054, 0.0946], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 54 - 23: cat - cat || Loss: 0.4077149033546448\n",
      "tensor([1., 0.]) tensor([0.9055, 0.0945], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 54 - 24: cat - cat || Loss: 0.4075363874435425\n",
      "tensor([1., 0.]) tensor([0.9057, 0.0943], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 54 - 25: cat - cat || Loss: 0.40735477209091187\n",
      "tensor([1., 0.]) tensor([0.9059, 0.0941], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 54 - 26: cat - cat || Loss: 0.40717053413391113\n",
      "tensor([1., 0.]) tensor([0.9061, 0.0939], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 54 - 27: cat - cat || Loss: 0.4069838523864746\n",
      "tensor([1., 0.]) tensor([0.9063, 0.0937], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 54 - 28: cat - cat || Loss: 0.4067952632904053\n",
      "tensor([1., 0.]) tensor([0.9065, 0.0935], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 54 - 29: cat - cat || Loss: 0.4066046476364136\n",
      "tensor([1., 0.]) tensor([0.9067, 0.0933], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 54 - 30: cat - cat || Loss: 0.40641260147094727\n",
      "tensor([1., 0.]) tensor([0.9068, 0.0932], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 54 - 31: cat - cat || Loss: 0.40621909499168396\n",
      "tensor([1., 0.]) tensor([0.9070, 0.0930], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 54 - 32: cat - cat || Loss: 0.4060244560241699\n",
      "tensor([1., 0.]) tensor([0.9072, 0.0928], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 54 - 33: cat - cat || Loss: 0.4058288335800171\n",
      "tensor([1., 0.]) tensor([0.9074, 0.0926], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 54 - 34: cat - cat || Loss: 0.40563225746154785\n",
      "tensor([1., 0.]) tensor([0.9076, 0.0924], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 54 - 35: cat - cat || Loss: 0.4054350256919861\n",
      "tensor([1., 0.]) tensor([0.9078, 0.0922], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 54 - 36: cat - cat || Loss: 0.40523719787597656\n",
      "tensor([1., 0.]) tensor([0.9080, 0.0920], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 54 - 37: cat - cat || Loss: 0.4050389230251312\n",
      "tensor([1., 0.]) tensor([0.9082, 0.0918], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 54 - 38: cat - cat || Loss: 0.40484023094177246\n",
      "tensor([1., 0.]) tensor([0.9084, 0.0916], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 54 - 39: cat - cat || Loss: 0.40464115142822266\n",
      "tensor([1., 0.]) tensor([0.9086, 0.0914], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 54 - 40: cat - cat || Loss: 0.4044420123100281\n",
      "tensor([1., 0.]) tensor([0.9088, 0.0912], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 54 - 41: cat - cat || Loss: 0.4042426347732544\n",
      "tensor([1., 0.]) tensor([0.9090, 0.0910], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 54 - 42: cat - cat || Loss: 0.40404319763183594\n",
      "tensor([1., 0.]) tensor([0.9092, 0.0908], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 54 - 43: cat - cat || Loss: 0.4038437008857727\n",
      "tensor([1., 0.]) tensor([0.9094, 0.0906], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 54 - 44: cat - cat || Loss: 0.403644323348999\n",
      "tensor([1., 0.]) tensor([0.9096, 0.0904], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 54 - 45: cat - cat || Loss: 0.40344494581222534\n",
      "tensor([1., 0.]) tensor([0.9098, 0.0902], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 54 - 46: cat - cat || Loss: 0.4032456874847412\n",
      "tensor([1., 0.]) tensor([0.9100, 0.0900], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 54 - 47: cat - cat || Loss: 0.4030466377735138\n",
      "tensor([1., 0.]) tensor([0.9102, 0.0898], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 54 - 48: cat - cat || Loss: 0.4028477668762207\n",
      "tensor([1., 0.]) tensor([0.9104, 0.0896], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 54 - 49: cat - cat || Loss: 0.4026491641998291\n",
      "tensor([1., 0.]) tensor([0.9106, 0.0894], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 54 - 50: cat - cat || Loss: 0.4024507701396942\n",
      "tensor([1., 0.]) tensor([0.9108, 0.0892], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 54 - 51: cat - cat || Loss: 0.4022527039051056\n",
      "tensor([1., 0.]) tensor([0.9110, 0.0890], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 54 - 52: cat - cat || Loss: 0.40205487608909607\n",
      "tensor([1., 0.]) tensor([0.9112, 0.0888], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 54 - 53: cat - cat || Loss: 0.4018574357032776\n",
      "tensor([1., 0.]) tensor([0.9114, 0.0886], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 54 - 54: cat - cat || Loss: 0.401660293340683\n",
      "tensor([1., 0.]) tensor([0.9116, 0.0884], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 54 - 55: cat - cat || Loss: 0.40146347880363464\n",
      "tensor([1., 0.]) tensor([0.9118, 0.0882], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 54 - 56: cat - cat || Loss: 0.40126705169677734\n",
      "tensor([1., 0.]) tensor([0.9120, 0.0880], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 54 - 57: cat - cat || Loss: 0.4010709822177887\n",
      "tensor([1., 0.]) tensor([0.9122, 0.0878], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 54 - 58: cat - cat || Loss: 0.40087538957595825\n",
      "tensor([1., 0.]) tensor([0.9124, 0.0876], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 54 - 59: cat - cat || Loss: 0.4006801247596741\n",
      "tensor([1., 0.]) tensor([0.9126, 0.0874], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 54 - 60: cat - cat || Loss: 0.4004852771759033\n",
      "tensor([1., 0.]) tensor([0.9128, 0.0872], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 54 - 61: cat - cat || Loss: 0.4002908170223236\n",
      "tensor([1., 0.]) tensor([0.9130, 0.0870], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 54 - 62: cat - cat || Loss: 0.4000967741012573\n",
      "tensor([1., 0.]) tensor([0.9132, 0.0868], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 54 - 63: cat - cat || Loss: 0.39990323781967163\n",
      "tensor([1., 0.]) tensor([0.9134, 0.0866], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 54 - 64: cat - cat || Loss: 0.399710088968277\n",
      "tensor([1., 0.]) tensor([0.9136, 0.0864], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 54 - 65: cat - cat || Loss: 0.39951735734939575\n",
      "tensor([1., 0.]) tensor([0.9137, 0.0863], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 54 - 66: cat - cat || Loss: 0.39932507276535034\n",
      "tensor([1., 0.]) tensor([0.9139, 0.0861], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 54 - 67: cat - cat || Loss: 0.3991332948207855\n",
      "tensor([1., 0.]) tensor([0.9141, 0.0859], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 54 - 68: cat - cat || Loss: 0.39894190430641174\n",
      "tensor([1., 0.]) tensor([0.9143, 0.0857], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 54 - 69: cat - cat || Loss: 0.39875102043151855\n",
      "tensor([1., 0.]) tensor([0.9145, 0.0855], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 54 - 70: cat - cat || Loss: 0.3985605537891388\n",
      "tensor([1., 0.]) tensor([0.9147, 0.0853], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 54 - 71: cat - cat || Loss: 0.39837056398391724\n",
      "tensor([1., 0.]) tensor([0.9149, 0.0851], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 54 - 72: cat - cat || Loss: 0.3981809616088867\n",
      "tensor([1., 0.]) tensor([0.9151, 0.0849], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 54 - 73: cat - cat || Loss: 0.3979918360710144\n",
      "tensor([1., 0.]) tensor([0.9153, 0.0847], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 54 - 74: cat - cat || Loss: 0.3978031873703003\n",
      "tensor([1., 0.]) tensor([0.9155, 0.0845], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 54 - 75: cat - cat || Loss: 0.3976150453090668\n",
      "tensor([1., 0.]) tensor([0.9156, 0.0844], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 54 - 76: cat - cat || Loss: 0.39742740988731384\n",
      "tensor([1., 0.]) tensor([0.9158, 0.0842], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 54 - 77: cat - cat || Loss: 0.39724019169807434\n",
      "tensor([1., 0.]) tensor([0.9160, 0.0840], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 54 - 78: cat - cat || Loss: 0.3970533013343811\n",
      "tensor([1., 0.]) tensor([0.9162, 0.0838], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 54 - 79: cat - cat || Loss: 0.39686697721481323\n",
      "tensor([1., 0.]) tensor([0.9164, 0.0836], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 54 - 80: cat - cat || Loss: 0.3966811001300812\n",
      "tensor([1., 0.]) tensor([0.9166, 0.0834], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 54 - 81: cat - cat || Loss: 0.39649567008018494\n",
      "tensor([1., 0.]) tensor([0.9168, 0.0832], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 54 - 82: cat - cat || Loss: 0.3963106870651245\n",
      "tensor([1., 0.]) tensor([0.9170, 0.0830], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 54 - 83: cat - cat || Loss: 0.3961262106895447\n",
      "tensor([1., 0.]) tensor([0.9171, 0.0829], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 54 - 84: cat - cat || Loss: 0.3959422707557678\n",
      "tensor([1., 0.]) tensor([0.9173, 0.0827], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 54 - 85: cat - cat || Loss: 0.3957586884498596\n",
      "tensor([1., 0.]) tensor([0.9175, 0.0825], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 54 - 86: cat - cat || Loss: 0.395575612783432\n",
      "tensor([1., 0.]) tensor([0.9177, 0.0823], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 54 - 87: cat - cat || Loss: 0.3953929543495178\n",
      "tensor([1., 0.]) tensor([0.9179, 0.0821], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 54 - 88: cat - cat || Loss: 0.39521077275276184\n",
      "tensor([1., 0.]) tensor([0.9181, 0.0819], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 54 - 89: cat - cat || Loss: 0.39502906799316406\n",
      "tensor([1., 0.]) tensor([0.9182, 0.0818], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 54 - 90: cat - cat || Loss: 0.3948477804660797\n",
      "tensor([1., 0.]) tensor([0.9184, 0.0816], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 54 - 91: cat - cat || Loss: 0.3946669399738312\n",
      "tensor([1., 0.]) tensor([0.9186, 0.0814], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 54 - 92: cat - cat || Loss: 0.3944866359233856\n",
      "tensor([1., 0.]) tensor([0.9188, 0.0812], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 54 - 93: cat - cat || Loss: 0.3943067193031311\n",
      "tensor([1., 0.]) tensor([0.9190, 0.0810], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 54 - 94: cat - cat || Loss: 0.39412721991539\n",
      "tensor([1., 0.]) tensor([0.9191, 0.0809], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 54 - 95: cat - cat || Loss: 0.39394819736480713\n",
      "tensor([1., 0.]) tensor([0.9193, 0.0807], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 54 - 96: cat - cat || Loss: 0.39376968145370483\n",
      "tensor([1., 0.]) tensor([0.9195, 0.0805], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 54 - 97: cat - cat || Loss: 0.39359158277511597\n",
      "tensor([1., 0.]) tensor([0.9197, 0.0803], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 54 - 98: cat - cat || Loss: 0.3934139013290405\n",
      "tensor([1., 0.]) tensor([0.9198, 0.0802], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 54 - 99: cat - cat || Loss: 0.39323675632476807\n",
      "tensor([1., 0.]) tensor([0.9200, 0.0800], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 54 - 100: cat - cat || Loss: 0.39305993914604187\n",
      "tensor([1., 0.]) tensor([0.9202, 0.0798], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 54 - 101: cat - cat || Loss: 0.39288365840911865\n",
      "tensor([1., 0.]) tensor([0.9204, 0.0796], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 54 - 102: cat - cat || Loss: 0.39270779490470886\n",
      "tensor([1., 0.]) tensor([0.9206, 0.0794], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 54 - 103: cat - cat || Loss: 0.3925323486328125\n",
      "tensor([1., 0.]) tensor([0.9207, 0.0793], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 54 - 104: cat - cat || Loss: 0.3923574388027191\n",
      "tensor([1., 0.]) tensor([0.9209, 0.0791], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 54 - 105: cat - cat || Loss: 0.3921828866004944\n",
      "tensor([1., 0.]) tensor([0.9211, 0.0789], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 54 - 106: cat - cat || Loss: 0.3920087516307831\n",
      "tensor([1., 0.]) tensor([0.9213, 0.0787], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 54 - 107: cat - cat || Loss: 0.3918350636959076\n",
      "tensor([1., 0.]) tensor([0.9214, 0.0786], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 54 - 108: cat - cat || Loss: 0.3916618824005127\n",
      "tensor([1., 0.]) tensor([0.9216, 0.0784], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 54 - 109: cat - cat || Loss: 0.3914891481399536\n",
      "tensor([1., 0.]) tensor([0.9218, 0.0782], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 54 - 110: cat - cat || Loss: 0.391316682100296\n",
      "tensor([1., 0.]) tensor([0.9219, 0.0781], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 54 - 111: cat - cat || Loss: 0.39114487171173096\n",
      "tensor([1., 0.]) tensor([0.9221, 0.0779], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 54 - 112: cat - cat || Loss: 0.3909732699394226\n",
      "tensor([1., 0.]) tensor([0.9223, 0.0777], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 54 - 113: cat - cat || Loss: 0.3908022344112396\n",
      "tensor([1., 0.]) tensor([0.9225, 0.0775], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 54 - 114: cat - cat || Loss: 0.39063161611557007\n",
      "tensor([1., 0.]) tensor([0.9226, 0.0774], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 54 - 115: cat - cat || Loss: 0.39046141505241394\n",
      "tensor([1., 0.]) tensor([0.9228, 0.0772], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 54 - 116: cat - cat || Loss: 0.39029166102409363\n",
      "tensor([1., 0.]) tensor([0.9230, 0.0770], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 54 - 117: cat - cat || Loss: 0.39012235403060913\n",
      "tensor([1., 0.]) tensor([0.9231, 0.0769], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 54 - 118: cat - cat || Loss: 0.38995349407196045\n",
      "tensor([1., 0.]) tensor([0.9233, 0.0767], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 54 - 119: cat - cat || Loss: 0.3897850513458252\n",
      "tensor([1., 0.]) tensor([0.9235, 0.0765], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 54 - 120: cat - cat || Loss: 0.3896169364452362\n",
      "tensor([1., 0.]) tensor([0.9236, 0.0764], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 54 - 121: cat - cat || Loss: 0.3894492983818054\n",
      "tensor([1., 0.]) tensor([0.9238, 0.0762], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 54 - 122: cat - cat || Loss: 0.38928207755088806\n",
      "tensor([1., 0.]) tensor([0.9240, 0.0760], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 54 - 123: cat - cat || Loss: 0.38911542296409607\n",
      "tensor([1., 0.]) tensor([0.9241, 0.0759], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 54 - 124: cat - cat || Loss: 0.3889489769935608\n",
      "tensor([1., 0.]) tensor([0.9243, 0.0757], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 54 - 125: cat - cat || Loss: 0.3887830972671509\n",
      "tensor([1., 0.]) tensor([0.9245, 0.0755], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 54 - 126: cat - cat || Loss: 0.3886175751686096\n",
      "tensor([1., 0.]) tensor([0.9246, 0.0754], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 54 - 127: cat - cat || Loss: 0.38845235109329224\n",
      "tensor([1., 0.]) tensor([0.9248, 0.0752], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 54 - 128: cat - cat || Loss: 0.3882877826690674\n",
      "tensor([1., 0.]) tensor([0.9250, 0.0750], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 54 - 129: cat - cat || Loss: 0.3881235122680664\n",
      "tensor([1., 0.]) tensor([0.9251, 0.0749], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 54 - 130: cat - cat || Loss: 0.38795968890190125\n",
      "tensor([1., 0.]) tensor([0.9253, 0.0747], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 54 - 131: cat - cat || Loss: 0.38779622316360474\n",
      "tensor([1., 0.]) tensor([0.9255, 0.0745], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 54 - 132: cat - cat || Loss: 0.38763314485549927\n",
      "tensor([1., 0.]) tensor([0.9256, 0.0744], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 54 - 133: cat - cat || Loss: 0.38747063279151917\n",
      "tensor([1., 0.]) tensor([0.9258, 0.0742], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 54 - 134: cat - cat || Loss: 0.38730835914611816\n",
      "tensor([1., 0.]) tensor([0.9260, 0.0740], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 54 - 135: cat - cat || Loss: 0.38714659214019775\n",
      "tensor([1., 0.]) tensor([0.9261, 0.0739], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 54 - 136: cat - cat || Loss: 0.386985182762146\n",
      "tensor([1., 0.]) tensor([0.9263, 0.0737], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 54 - 137: cat - cat || Loss: 0.38682422041893005\n",
      "tensor([1., 0.]) tensor([0.9264, 0.0736], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 54 - 138: cat - cat || Loss: 0.38666367530822754\n",
      "tensor([1., 0.]) tensor([0.9266, 0.0734], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 54 - 139: cat - cat || Loss: 0.3865034878253937\n",
      "tensor([1., 0.]) tensor([0.9268, 0.0732], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 54 - 140: cat - cat || Loss: 0.38634368777275085\n",
      "tensor([1., 0.]) tensor([0.9269, 0.0731], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 54 - 141: cat - cat || Loss: 0.38618430495262146\n",
      "tensor([1., 0.]) tensor([0.9271, 0.0729], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 54 - 142: cat - cat || Loss: 0.3860253691673279\n",
      "tensor([1., 0.]) tensor([0.9272, 0.0728], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 54 - 143: cat - cat || Loss: 0.38586676120758057\n",
      "tensor([1., 0.]) tensor([0.9274, 0.0726], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 54 - 144: cat - cat || Loss: 0.38570865988731384\n",
      "tensor([1., 0.]) tensor([0.9276, 0.0724], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 54 - 145: cat - cat || Loss: 0.38555091619491577\n",
      "tensor([1., 0.]) tensor([0.9277, 0.0723], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 54 - 146: cat - cat || Loss: 0.38539350032806396\n",
      "tensor([1., 0.]) tensor([0.9279, 0.0721], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 54 - 147: cat - cat || Loss: 0.38523656129837036\n",
      "tensor([1., 0.]) tensor([0.9280, 0.0720], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 54 - 148: cat - cat || Loss: 0.38507992029190063\n",
      "tensor([1., 0.]) tensor([0.9282, 0.0718], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 54 - 149: cat - cat || Loss: 0.3849238157272339\n",
      "tensor([1., 0.]) tensor([0.9283, 0.0717], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 54 - 150: cat - cat || Loss: 0.38476791977882385\n",
      "tensor([1., 0.]) tensor([0.9285, 0.0715], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 54 - 151: cat - cat || Loss: 0.3846125304698944\n",
      "tensor([1., 0.]) tensor([0.9286, 0.0714], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 54 - 152: cat - cat || Loss: 0.3844575583934784\n",
      "tensor([1., 0.]) tensor([0.9288, 0.0712], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 54 - 153: cat - cat || Loss: 0.38430291414260864\n",
      "tensor([1., 0.]) tensor([0.9290, 0.0710], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 54 - 154: cat - cat || Loss: 0.38414865732192993\n",
      "tensor([1., 0.]) tensor([0.9291, 0.0709], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 54 - 155: cat - cat || Loss: 0.38399478793144226\n",
      "tensor([1., 0.]) tensor([0.9293, 0.0707], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 54 - 156: cat - cat || Loss: 0.383841335773468\n",
      "tensor([1., 0.]) tensor([0.9294, 0.0706], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 54 - 157: cat - cat || Loss: 0.3836883008480072\n",
      "tensor([1., 0.]) tensor([0.9296, 0.0704], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 54 - 158: cat - cat || Loss: 0.3835355043411255\n",
      "tensor([1., 0.]) tensor([0.9297, 0.0703], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 54 - 159: cat - cat || Loss: 0.38338324427604675\n",
      "tensor([1., 0.]) tensor([0.9299, 0.0701], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 54 - 160: cat - cat || Loss: 0.3832312524318695\n",
      "tensor([1., 0.]) tensor([0.9300, 0.0700], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 54 - 161: cat - cat || Loss: 0.38307976722717285\n",
      "tensor([1., 0.]) tensor([0.9302, 0.0698], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 54 - 162: cat - cat || Loss: 0.3829285800457001\n",
      "tensor([1., 0.]) tensor([0.9303, 0.0697], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 54 - 163: cat - cat || Loss: 0.38277775049209595\n",
      "tensor([1., 0.]) tensor([0.9305, 0.0695], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 54 - 164: cat - cat || Loss: 0.38262730836868286\n",
      "tensor([1., 0.]) tensor([0.9306, 0.0694], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 54 - 165: cat - cat || Loss: 0.3824772834777832\n",
      "tensor([1., 0.]) tensor([0.9308, 0.0692], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 54 - 166: cat - cat || Loss: 0.3823276162147522\n",
      "tensor([1., 0.]) tensor([0.9309, 0.0691], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 54 - 167: cat - cat || Loss: 0.38217830657958984\n",
      "tensor([1., 0.]) tensor([0.9311, 0.0689], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 54 - 168: cat - cat || Loss: 0.38202935457229614\n",
      "tensor([1., 0.]) tensor([0.9312, 0.0688], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 54 - 169: cat - cat || Loss: 0.3818807899951935\n",
      "tensor([1., 0.]) tensor([0.9314, 0.0686], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 54 - 170: cat - cat || Loss: 0.3817325830459595\n",
      "tensor([1., 0.]) tensor([0.9315, 0.0685], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 54 - 171: cat - cat || Loss: 0.3815847635269165\n",
      "tensor([1., 0.]) tensor([0.9317, 0.0683], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 54 - 172: cat - cat || Loss: 0.3814372420310974\n",
      "tensor([1., 0.]) tensor([0.9318, 0.0682], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 54 - 173: cat - cat || Loss: 0.3812901973724365\n",
      "tensor([1., 0.]) tensor([0.9320, 0.0680], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 54 - 174: cat - cat || Loss: 0.3811434805393219\n",
      "tensor([1., 0.]) tensor([0.9321, 0.0679], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 54 - 175: cat - cat || Loss: 0.38099709153175354\n",
      "tensor([1., 0.]) tensor([0.9323, 0.0677], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 54 - 176: cat - cat || Loss: 0.3808510899543762\n",
      "tensor([1., 0.]) tensor([0.9324, 0.0676], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 54 - 177: cat - cat || Loss: 0.38070544600486755\n",
      "tensor([1., 0.]) tensor([0.9326, 0.0674], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 54 - 178: cat - cat || Loss: 0.38056015968322754\n",
      "tensor([1., 0.]) tensor([0.9327, 0.0673], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 54 - 179: cat - cat || Loss: 0.3804152309894562\n",
      "tensor([1., 0.]) tensor([0.9328, 0.0672], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 54 - 180: cat - cat || Loss: 0.3802706301212311\n",
      "tensor([1., 0.]) tensor([0.9330, 0.0670], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 54 - 181: cat - cat || Loss: 0.380126416683197\n",
      "tensor([1., 0.]) tensor([0.9331, 0.0669], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 54 - 182: cat - cat || Loss: 0.3799825608730316\n",
      "tensor([1., 0.]) tensor([0.9333, 0.0667], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 54 - 183: cat - cat || Loss: 0.37983906269073486\n",
      "tensor([1., 0.]) tensor([0.9334, 0.0666], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 54 - 184: cat - cat || Loss: 0.3796957731246948\n",
      "tensor([1., 0.]) tensor([0.9336, 0.0664], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 54 - 185: cat - cat || Loss: 0.37955302000045776\n",
      "tensor([1., 0.]) tensor([0.9337, 0.0663], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 54 - 186: cat - cat || Loss: 0.37941041588783264\n",
      "tensor([1., 0.]) tensor([0.9339, 0.0661], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 54 - 187: cat - cat || Loss: 0.37926825881004333\n",
      "tensor([1., 0.]) tensor([0.9340, 0.0660], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 54 - 188: cat - cat || Loss: 0.37912634015083313\n",
      "tensor([1., 0.]) tensor([0.9341, 0.0659], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 54 - 189: cat - cat || Loss: 0.37898480892181396\n",
      "tensor([1., 0.]) tensor([0.9343, 0.0657], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 54 - 190: dog - cat || Loss: 1.2476798295974731\n",
      "tensor([0., 1.]) tensor([0.9344, 0.0656], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 54 - 191: dog - cat || Loss: 1.2477928400039673\n",
      "tensor([0., 1.]) tensor([0.9345, 0.0655], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 54 - 192: dog - cat || Loss: 1.2478805780410767\n",
      "tensor([0., 1.]) tensor([0.9346, 0.0654], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 54 - 193: dog - cat || Loss: 1.2479455471038818\n",
      "tensor([0., 1.]) tensor([0.9347, 0.0653], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 54 - 194: dog - cat || Loss: 1.2479901313781738\n",
      "tensor([0., 1.]) tensor([0.9347, 0.0653], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 54 - 195: dog - cat || Loss: 1.2480162382125854\n",
      "tensor([0., 1.]) tensor([0.9348, 0.0652], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 54 - 196: dog - cat || Loss: 1.2480257749557495\n",
      "tensor([0., 1.]) tensor([0.9348, 0.0652], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 54 - 197: dog - cat || Loss: 1.2480205297470093\n",
      "tensor([0., 1.]) tensor([0.9348, 0.0652], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 54 - 198: dog - cat || Loss: 1.2480019330978394\n",
      "tensor([0., 1.]) tensor([0.9347, 0.0653], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 54 - 199: dog - cat || Loss: 1.2479712963104248\n",
      "tensor([0., 1.]) tensor([0.9347, 0.0653], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 54 - 200: dog - cat || Loss: 1.2479299306869507\n",
      "tensor([0., 1.]) tensor([0.9347, 0.0653], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 54 - 201: dog - cat || Loss: 1.2478785514831543\n",
      "tensor([0., 1.]) tensor([0.9346, 0.0654], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 54 - 202: dog - cat || Loss: 1.2478184700012207\n",
      "tensor([0., 1.]) tensor([0.9346, 0.0654], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 54 - 203: dog - cat || Loss: 1.2477505207061768\n",
      "tensor([0., 1.]) tensor([0.9345, 0.0655], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 54 - 204: dog - cat || Loss: 1.2476754188537598\n",
      "tensor([0., 1.]) tensor([0.9344, 0.0656], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 54 - 205: dog - cat || Loss: 1.247593879699707\n",
      "tensor([0., 1.]) tensor([0.9343, 0.0657], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 54 - 206: dog - cat || Loss: 1.2475063800811768\n",
      "tensor([0., 1.]) tensor([0.9342, 0.0658], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 54 - 207: dog - cat || Loss: 1.2474136352539062\n",
      "tensor([0., 1.]) tensor([0.9342, 0.0658], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 54 - 208: dog - cat || Loss: 1.2473161220550537\n",
      "tensor([0., 1.]) tensor([0.9341, 0.0659], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 54 - 209: dog - cat || Loss: 1.2472143173217773\n",
      "tensor([0., 1.]) tensor([0.9340, 0.0660], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 54 - 210: dog - cat || Loss: 1.2471084594726562\n",
      "tensor([0., 1.]) tensor([0.9338, 0.0662], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 54 - 211: dog - cat || Loss: 1.2469992637634277\n",
      "tensor([0., 1.]) tensor([0.9337, 0.0663], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 54 - 212: dog - cat || Loss: 1.2468864917755127\n",
      "tensor([0., 1.]) tensor([0.9336, 0.0664], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 54 - 213: dog - cat || Loss: 1.2467708587646484\n",
      "tensor([0., 1.]) tensor([0.9335, 0.0665], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 54 - 214: dog - cat || Loss: 1.246652603149414\n",
      "tensor([0., 1.]) tensor([0.9334, 0.0666], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 54 - 215: dog - cat || Loss: 1.2465319633483887\n",
      "tensor([0., 1.]) tensor([0.9333, 0.0667], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 54 - 216: dog - cat || Loss: 1.2464090585708618\n",
      "tensor([0., 1.]) tensor([0.9331, 0.0669], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 54 - 217: dog - cat || Loss: 1.246283769607544\n",
      "tensor([0., 1.]) tensor([0.9330, 0.0670], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 54 - 218: dog - cat || Loss: 1.246156930923462\n",
      "tensor([0., 1.]) tensor([0.9329, 0.0671], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 54 - 219: dog - cat || Loss: 1.2460280656814575\n",
      "tensor([0., 1.]) tensor([0.9328, 0.0672], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 54 - 220: dog - cat || Loss: 1.245897889137268\n",
      "tensor([0., 1.]) tensor([0.9326, 0.0674], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 54 - 221: dog - cat || Loss: 1.2457661628723145\n",
      "tensor([0., 1.]) tensor([0.9325, 0.0675], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 54 - 222: dog - cat || Loss: 1.2456331253051758\n",
      "tensor([0., 1.]) tensor([0.9324, 0.0676], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 54 - 223: dog - cat || Loss: 1.245498776435852\n",
      "tensor([0., 1.]) tensor([0.9322, 0.0678], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 54 - 224: dog - cat || Loss: 1.2453632354736328\n",
      "tensor([0., 1.]) tensor([0.9321, 0.0679], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 54 - 225: dog - cat || Loss: 1.2452266216278076\n",
      "tensor([0., 1.]) tensor([0.9320, 0.0680], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 54 - 226: dog - cat || Loss: 1.245089054107666\n",
      "tensor([0., 1.]) tensor([0.9318, 0.0682], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 54 - 227: dog - cat || Loss: 1.244950532913208\n",
      "tensor([0., 1.]) tensor([0.9317, 0.0683], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 54 - 228: dog - cat || Loss: 1.2448110580444336\n",
      "tensor([0., 1.]) tensor([0.9315, 0.0685], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 54 - 229: dog - cat || Loss: 1.244671106338501\n",
      "tensor([0., 1.]) tensor([0.9314, 0.0686], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 54 - 230: dog - cat || Loss: 1.2445299625396729\n",
      "tensor([0., 1.]) tensor([0.9313, 0.0687], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 54 - 231: dog - cat || Loss: 1.2443879842758179\n",
      "tensor([0., 1.]) tensor([0.9311, 0.0689], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 54 - 232: dog - cat || Loss: 1.2442454099655151\n",
      "tensor([0., 1.]) tensor([0.9310, 0.0690], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 54 - 233: dog - cat || Loss: 1.2441024780273438\n",
      "tensor([0., 1.]) tensor([0.9308, 0.0692], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 54 - 234: dog - cat || Loss: 1.243958592414856\n",
      "tensor([0., 1.]) tensor([0.9307, 0.0693], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 54 - 235: dog - cat || Loss: 1.24381422996521\n",
      "tensor([0., 1.]) tensor([0.9306, 0.0694], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 54 - 236: dog - cat || Loss: 1.2436693906784058\n",
      "tensor([0., 1.]) tensor([0.9304, 0.0696], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 54 - 237: dog - cat || Loss: 1.2435237169265747\n",
      "tensor([0., 1.]) tensor([0.9303, 0.0697], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 54 - 238: dog - cat || Loss: 1.243377685546875\n",
      "tensor([0., 1.]) tensor([0.9301, 0.0699], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 54 - 239: dog - cat || Loss: 1.2432310581207275\n",
      "tensor([0., 1.]) tensor([0.9300, 0.0700], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 54 - 240: dog - cat || Loss: 1.2430838346481323\n",
      "tensor([0., 1.]) tensor([0.9298, 0.0702], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 54 - 241: dog - cat || Loss: 1.242936134338379\n",
      "tensor([0., 1.]) tensor([0.9297, 0.0703], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 54 - 242: dog - cat || Loss: 1.2427881956100464\n",
      "tensor([0., 1.]) tensor([0.9295, 0.0705], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 54 - 243: dog - cat || Loss: 1.2426395416259766\n",
      "tensor([0., 1.]) tensor([0.9294, 0.0706], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 54 - 244: dog - cat || Loss: 1.242490530014038\n",
      "tensor([0., 1.]) tensor([0.9292, 0.0708], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 54 - 245: dog - cat || Loss: 1.2423410415649414\n",
      "tensor([0., 1.]) tensor([0.9291, 0.0709], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 54 - 246: dog - cat || Loss: 1.2421910762786865\n",
      "tensor([0., 1.]) tensor([0.9289, 0.0711], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 54 - 247: dog - cat || Loss: 1.2420406341552734\n",
      "tensor([0., 1.]) tensor([0.9288, 0.0712], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 54 - 248: dog - cat || Loss: 1.2418899536132812\n",
      "tensor([0., 1.]) tensor([0.9286, 0.0714], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 54 - 249: dog - cat || Loss: 1.2417385578155518\n",
      "tensor([0., 1.]) tensor([0.9285, 0.0715], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 54 - 250: dog - cat || Loss: 1.2415870428085327\n",
      "tensor([0., 1.]) tensor([0.9283, 0.0717], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 54 - 251: dog - cat || Loss: 1.2414348125457764\n",
      "tensor([0., 1.]) tensor([0.9282, 0.0718], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 54 - 252: dog - cat || Loss: 1.241282343864441\n",
      "tensor([0., 1.]) tensor([0.9280, 0.0720], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 54 - 253: dog - cat || Loss: 1.2411293983459473\n",
      "tensor([0., 1.]) tensor([0.9279, 0.0721], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 54 - 254: dog - cat || Loss: 1.2409762144088745\n",
      "tensor([0., 1.]) tensor([0.9277, 0.0723], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 54 - 255: dog - cat || Loss: 1.240822434425354\n",
      "tensor([0., 1.]) tensor([0.9276, 0.0724], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 54 - 256: dog - cat || Loss: 1.2406681776046753\n",
      "tensor([0., 1.]) tensor([0.9274, 0.0726], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 54 - 257: dog - cat || Loss: 1.2405136823654175\n",
      "tensor([0., 1.]) tensor([0.9273, 0.0727], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 54 - 258: dog - cat || Loss: 1.240358829498291\n",
      "tensor([0., 1.]) tensor([0.9271, 0.0729], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 54 - 259: dog - cat || Loss: 1.2402034997940063\n",
      "tensor([0., 1.]) tensor([0.9269, 0.0731], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 54 - 260: dog - cat || Loss: 1.240047812461853\n",
      "tensor([0., 1.]) tensor([0.9268, 0.0732], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 54 - 261: dog - cat || Loss: 1.2398916482925415\n",
      "tensor([0., 1.]) tensor([0.9266, 0.0734], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 54 - 262: dog - cat || Loss: 1.2397351264953613\n",
      "tensor([0., 1.]) tensor([0.9265, 0.0735], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 54 - 263: dog - cat || Loss: 1.2395782470703125\n",
      "tensor([0., 1.]) tensor([0.9263, 0.0737], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 54 - 264: dog - cat || Loss: 1.2394208908081055\n",
      "tensor([0., 1.]) tensor([0.9262, 0.0738], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 54 - 265: dog - cat || Loss: 1.2392631769180298\n",
      "tensor([0., 1.]) tensor([0.9260, 0.0740], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 54 - 266: dog - cat || Loss: 1.2391051054000854\n",
      "tensor([0., 1.]) tensor([0.9258, 0.0742], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 54 - 267: dog - cat || Loss: 1.2389466762542725\n",
      "tensor([0., 1.]) tensor([0.9257, 0.0743], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 54 - 268: dog - cat || Loss: 1.2387876510620117\n",
      "tensor([0., 1.]) tensor([0.9255, 0.0745], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 54 - 269: dog - cat || Loss: 1.2386283874511719\n",
      "tensor([0., 1.]) tensor([0.9254, 0.0746], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 54 - 270: dog - cat || Loss: 1.2384686470031738\n",
      "tensor([0., 1.]) tensor([0.9252, 0.0748], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 54 - 271: dog - cat || Loss: 1.2383086681365967\n",
      "tensor([0., 1.]) tensor([0.9250, 0.0750], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 54 - 272: dog - cat || Loss: 1.2381482124328613\n",
      "tensor([0., 1.]) tensor([0.9249, 0.0751], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 54 - 273: dog - cat || Loss: 1.2379871606826782\n",
      "tensor([0., 1.]) tensor([0.9247, 0.0753], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 54 - 274: dog - cat || Loss: 1.237825870513916\n",
      "tensor([0., 1.]) tensor([0.9246, 0.0754], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 54 - 275: dog - cat || Loss: 1.2376642227172852\n",
      "tensor([0., 1.]) tensor([0.9244, 0.0756], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 54 - 276: dog - cat || Loss: 1.2375022172927856\n",
      "tensor([0., 1.]) tensor([0.9242, 0.0758], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 54 - 277: dog - cat || Loss: 1.237339735031128\n",
      "tensor([0., 1.]) tensor([0.9241, 0.0759], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 54 - 278: dog - cat || Loss: 1.2371768951416016\n",
      "tensor([0., 1.]) tensor([0.9239, 0.0761], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 54 - 279: dog - cat || Loss: 1.237013578414917\n",
      "tensor([0., 1.]) tensor([0.9238, 0.0762], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 54 - 280: dog - cat || Loss: 1.2368497848510742\n",
      "tensor([0., 1.]) tensor([0.9236, 0.0764], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 54 - 281: dog - cat || Loss: 1.2366857528686523\n",
      "tensor([0., 1.]) tensor([0.9234, 0.0766], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 54 - 282: dog - cat || Loss: 1.2365213632583618\n",
      "tensor([0., 1.]) tensor([0.9233, 0.0767], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 54 - 283: dog - cat || Loss: 1.236356258392334\n",
      "tensor([0., 1.]) tensor([0.9231, 0.0769], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 54 - 284: dog - cat || Loss: 1.2361910343170166\n",
      "tensor([0., 1.]) tensor([0.9229, 0.0771], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 54 - 285: dog - cat || Loss: 1.236025333404541\n",
      "tensor([0., 1.]) tensor([0.9228, 0.0772], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 54 - 286: dog - cat || Loss: 1.2358592748641968\n",
      "tensor([0., 1.]) tensor([0.9226, 0.0774], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 54 - 287: dog - cat || Loss: 1.2356926202774048\n",
      "tensor([0., 1.]) tensor([0.9224, 0.0776], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 54 - 288: dog - cat || Loss: 1.2355256080627441\n",
      "tensor([0., 1.]) tensor([0.9223, 0.0777], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 54 - 289: dog - cat || Loss: 1.2353582382202148\n",
      "tensor([0., 1.]) tensor([0.9221, 0.0779], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 54 - 290: dog - cat || Loss: 1.235190510749817\n",
      "tensor([0., 1.]) tensor([0.9219, 0.0781], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 54 - 291: dog - cat || Loss: 1.2350224256515503\n",
      "tensor([0., 1.]) tensor([0.9218, 0.0782], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 54 - 292: dog - cat || Loss: 1.2348536252975464\n",
      "tensor([0., 1.]) tensor([0.9216, 0.0784], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 54 - 293: dog - cat || Loss: 1.234684705734253\n",
      "tensor([0., 1.]) tensor([0.9214, 0.0786], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 54 - 294: dog - cat || Loss: 1.2345151901245117\n",
      "tensor([0., 1.]) tensor([0.9213, 0.0787], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 54 - 295: dog - cat || Loss: 1.2343453168869019\n",
      "tensor([0., 1.]) tensor([0.9211, 0.0789], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 54 - 296: dog - cat || Loss: 1.2341750860214233\n",
      "tensor([0., 1.]) tensor([0.9209, 0.0791], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 54 - 297: dog - cat || Loss: 1.2340044975280762\n",
      "tensor([0., 1.]) tensor([0.9207, 0.0793], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 54 - 298: dog - cat || Loss: 1.2338334321975708\n",
      "tensor([0., 1.]) tensor([0.9206, 0.0794], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 54 - 299: dog - cat || Loss: 1.2336618900299072\n",
      "tensor([0., 1.]) tensor([0.9204, 0.0796], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 54 - 300: dog - cat || Loss: 1.2334898710250854\n",
      "tensor([0., 1.]) tensor([0.9202, 0.0798], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 54 - 301: dog - cat || Loss: 1.2333176136016846\n",
      "tensor([0., 1.]) tensor([0.9201, 0.0799], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 54 - 302: dog - cat || Loss: 1.233144760131836\n",
      "tensor([0., 1.]) tensor([0.9199, 0.0801], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 54 - 303: dog - cat || Loss: 1.2329715490341187\n",
      "tensor([0., 1.]) tensor([0.9197, 0.0803], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 54 - 304: dog - cat || Loss: 1.2327979803085327\n",
      "tensor([0., 1.]) tensor([0.9195, 0.0805], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 54 - 305: dog - cat || Loss: 1.232623815536499\n",
      "tensor([0., 1.]) tensor([0.9194, 0.0806], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 54 - 306: dog - cat || Loss: 1.2324494123458862\n",
      "tensor([0., 1.]) tensor([0.9192, 0.0808], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 54 - 307: dog - cat || Loss: 1.2322745323181152\n",
      "tensor([0., 1.]) tensor([0.9190, 0.0810], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 54 - 308: dog - cat || Loss: 1.2320990562438965\n",
      "tensor([0., 1.]) tensor([0.9188, 0.0812], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 54 - 309: dog - cat || Loss: 1.231923222541809\n",
      "tensor([0., 1.]) tensor([0.9187, 0.0813], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 54 - 310: dog - cat || Loss: 1.231747031211853\n",
      "tensor([0., 1.]) tensor([0.9185, 0.0815], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 54 - 311: dog - cat || Loss: 1.2315703630447388\n",
      "tensor([0., 1.]) tensor([0.9183, 0.0817], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 54 - 312: dog - cat || Loss: 1.2313932180404663\n",
      "tensor([0., 1.]) tensor([0.9181, 0.0819], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 54 - 313: dog - cat || Loss: 1.2312155961990356\n",
      "tensor([0., 1.]) tensor([0.9180, 0.0820], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 54 - 314: dog - cat || Loss: 1.2310377359390259\n",
      "tensor([0., 1.]) tensor([0.9178, 0.0822], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 54 - 315: dog - cat || Loss: 1.230859398841858\n",
      "tensor([0., 1.]) tensor([0.9176, 0.0824], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 54 - 316: dog - cat || Loss: 1.2306804656982422\n",
      "tensor([0., 1.]) tensor([0.9174, 0.0826], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 54 - 317: dog - cat || Loss: 1.2305011749267578\n",
      "tensor([0., 1.]) tensor([0.9172, 0.0828], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 54 - 318: dog - cat || Loss: 1.2303216457366943\n",
      "tensor([0., 1.]) tensor([0.9171, 0.0829], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 54 - 319: dog - cat || Loss: 1.230141282081604\n",
      "tensor([0., 1.]) tensor([0.9169, 0.0831], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 54 - 320: dog - cat || Loss: 1.2299607992172241\n",
      "tensor([0., 1.]) tensor([0.9167, 0.0833], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 54 - 321: dog - cat || Loss: 1.2297797203063965\n",
      "tensor([0., 1.]) tensor([0.9165, 0.0835], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 54 - 322: dog - cat || Loss: 1.229598045349121\n",
      "tensor([0., 1.]) tensor([0.9163, 0.0837], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 54 - 323: dog - cat || Loss: 1.2294161319732666\n",
      "tensor([0., 1.]) tensor([0.9162, 0.0838], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 54 - 324: dog - cat || Loss: 1.229233741760254\n",
      "tensor([0., 1.]) tensor([0.9160, 0.0840], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 54 - 325: dog - cat || Loss: 1.229050874710083\n",
      "tensor([0., 1.]) tensor([0.9158, 0.0842], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 54 - 326: dog - cat || Loss: 1.228867530822754\n",
      "tensor([0., 1.]) tensor([0.9156, 0.0844], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 54 - 327: dog - cat || Loss: 1.2286837100982666\n",
      "tensor([0., 1.]) tensor([0.9154, 0.0846], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 54 - 328: dog - cat || Loss: 1.2284995317459106\n",
      "tensor([0., 1.]) tensor([0.9152, 0.0848], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 54 - 329: dog - cat || Loss: 1.2283148765563965\n",
      "tensor([0., 1.]) tensor([0.9151, 0.0849], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 54 - 330: dog - cat || Loss: 1.2281298637390137\n",
      "tensor([0., 1.]) tensor([0.9149, 0.0851], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 54 - 331: dog - cat || Loss: 1.2279441356658936\n",
      "tensor([0., 1.]) tensor([0.9147, 0.0853], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 54 - 332: dog - cat || Loss: 1.2277582883834839\n",
      "tensor([0., 1.]) tensor([0.9145, 0.0855], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 54 - 333: dog - cat || Loss: 1.227571725845337\n",
      "tensor([0., 1.]) tensor([0.9143, 0.0857], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 54 - 334: dog - cat || Loss: 1.2273845672607422\n",
      "tensor([0., 1.]) tensor([0.9141, 0.0859], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 54 - 335: dog - cat || Loss: 1.227197289466858\n",
      "tensor([0., 1.]) tensor([0.9139, 0.0861], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 54 - 336: dog - cat || Loss: 1.2270092964172363\n",
      "tensor([0., 1.]) tensor([0.9137, 0.0863], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 54 - 337: dog - cat || Loss: 1.2268210649490356\n",
      "tensor([0., 1.]) tensor([0.9136, 0.0864], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 54 - 338: dog - cat || Loss: 1.2266321182250977\n",
      "tensor([0., 1.]) tensor([0.9134, 0.0866], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 54 - 339: dog - cat || Loss: 1.2264429330825806\n",
      "tensor([0., 1.]) tensor([0.9132, 0.0868], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 54 - 340: dog - cat || Loss: 1.2262531518936157\n",
      "tensor([0., 1.]) tensor([0.9130, 0.0870], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 54 - 341: dog - cat || Loss: 1.2260630130767822\n",
      "tensor([0., 1.]) tensor([0.9128, 0.0872], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 54 - 342: dog - cat || Loss: 1.225872278213501\n",
      "tensor([0., 1.]) tensor([0.9126, 0.0874], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 54 - 343: dog - cat || Loss: 1.2256810665130615\n",
      "tensor([0., 1.]) tensor([0.9124, 0.0876], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 54 - 344: dog - cat || Loss: 1.225489616394043\n",
      "tensor([0., 1.]) tensor([0.9122, 0.0878], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 54 - 345: dog - cat || Loss: 1.225297451019287\n",
      "tensor([0., 1.]) tensor([0.9120, 0.0880], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 54 - 346: dog - cat || Loss: 1.2251049280166626\n",
      "tensor([0., 1.]) tensor([0.9118, 0.0882], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 54 - 347: dog - cat || Loss: 1.2249118089675903\n",
      "tensor([0., 1.]) tensor([0.9117, 0.0883], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 54 - 348: dog - cat || Loss: 1.2247183322906494\n",
      "tensor([0., 1.]) tensor([0.9115, 0.0885], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 54 - 349: dog - cat || Loss: 1.2245242595672607\n",
      "tensor([0., 1.]) tensor([0.9113, 0.0887], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 54 - 350: dog - cat || Loss: 1.224329948425293\n",
      "tensor([0., 1.]) tensor([0.9111, 0.0889], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 54 - 351: dog - cat || Loss: 1.224134922027588\n",
      "tensor([0., 1.]) tensor([0.9109, 0.0891], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 54 - 352: dog - cat || Loss: 1.2239394187927246\n",
      "tensor([0., 1.]) tensor([0.9107, 0.0893], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 54 - 353: dog - cat || Loss: 1.2237435579299927\n",
      "tensor([0., 1.]) tensor([0.9105, 0.0895], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 54 - 354: dog - cat || Loss: 1.2235469818115234\n",
      "tensor([0., 1.]) tensor([0.9103, 0.0897], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 54 - 355: dog - cat || Loss: 1.2233502864837646\n",
      "tensor([0., 1.]) tensor([0.9101, 0.0899], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 54 - 356: dog - cat || Loss: 1.2231528759002686\n",
      "tensor([0., 1.]) tensor([0.9099, 0.0901], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 54 - 357: dog - cat || Loss: 1.2229549884796143\n",
      "tensor([0., 1.]) tensor([0.9097, 0.0903], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 54 - 358: dog - cat || Loss: 1.2227566242218018\n",
      "tensor([0., 1.]) tensor([0.9095, 0.0905], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 54 - 359: dog - cat || Loss: 1.222557783126831\n",
      "tensor([0., 1.]) tensor([0.9093, 0.0907], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 54 - 360: dog - cat || Loss: 1.2223583459854126\n",
      "tensor([0., 1.]) tensor([0.9091, 0.0909], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 54 - 361: dog - cat || Loss: 1.222158670425415\n",
      "tensor([0., 1.]) tensor([0.9089, 0.0911], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 54 - 362: dog - cat || Loss: 1.2219583988189697\n",
      "tensor([0., 1.]) tensor([0.9087, 0.0913], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 54 - 363: dog - cat || Loss: 1.2217575311660767\n",
      "tensor([0., 1.]) tensor([0.9085, 0.0915], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 54 - 364: dog - cat || Loss: 1.2215561866760254\n",
      "tensor([0., 1.]) tensor([0.9083, 0.0917], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 54 - 365: dog - cat || Loss: 1.221354365348816\n",
      "tensor([0., 1.]) tensor([0.9081, 0.0919], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 54 - 366: dog - cat || Loss: 1.2211520671844482\n",
      "tensor([0., 1.]) tensor([0.9079, 0.0921], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 54 - 367: dog - cat || Loss: 1.2209492921829224\n",
      "tensor([0., 1.]) tensor([0.9077, 0.0923], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 54 - 368: dog - cat || Loss: 1.2207460403442383\n",
      "tensor([0., 1.]) tensor([0.9075, 0.0925], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 54 - 369: dog - cat || Loss: 1.2205421924591064\n",
      "tensor([0., 1.]) tensor([0.9073, 0.0927], grad_fn=<SoftmaxBackward0>)\n",
      "=====epoch:55=====\n",
      "Epoch 55 - 0: cat - cat || Loss: 0.4061853587627411\n",
      "tensor([1., 0.]) tensor([0.9071, 0.0929], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 55 - 1: cat - cat || Loss: 0.40634870529174805\n",
      "tensor([1., 0.]) tensor([0.9069, 0.0931], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 55 - 2: cat - cat || Loss: 0.4064752161502838\n",
      "tensor([1., 0.]) tensor([0.9068, 0.0932], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 55 - 3: cat - cat || Loss: 0.4065682888031006\n",
      "tensor([1., 0.]) tensor([0.9067, 0.0933], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 55 - 4: cat - cat || Loss: 0.4066312611103058\n",
      "tensor([1., 0.]) tensor([0.9066, 0.0934], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 55 - 5: cat - cat || Loss: 0.40666717290878296\n",
      "tensor([1., 0.]) tensor([0.9066, 0.0934], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 55 - 6: cat - cat || Loss: 0.4066786766052246\n",
      "tensor([1., 0.]) tensor([0.9066, 0.0934], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 55 - 7: cat - cat || Loss: 0.4066682457923889\n",
      "tensor([1., 0.]) tensor([0.9066, 0.0934], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 55 - 8: cat - cat || Loss: 0.406637966632843\n",
      "tensor([1., 0.]) tensor([0.9066, 0.0934], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 55 - 9: cat - cat || Loss: 0.4065900146961212\n",
      "tensor([1., 0.]) tensor([0.9067, 0.0933], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 55 - 10: cat - cat || Loss: 0.40652596950531006\n",
      "tensor([1., 0.]) tensor([0.9067, 0.0933], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 55 - 11: cat - cat || Loss: 0.4064476191997528\n",
      "tensor([1., 0.]) tensor([0.9068, 0.0932], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 55 - 12: cat - cat || Loss: 0.4063565135002136\n",
      "tensor([1., 0.]) tensor([0.9069, 0.0931], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 55 - 13: cat - cat || Loss: 0.40625372529029846\n",
      "tensor([1., 0.]) tensor([0.9070, 0.0930], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 55 - 14: cat - cat || Loss: 0.4061405658721924\n",
      "tensor([1., 0.]) tensor([0.9071, 0.0929], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 55 - 15: cat - cat || Loss: 0.40601813793182373\n",
      "tensor([1., 0.]) tensor([0.9072, 0.0928], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 55 - 16: cat - cat || Loss: 0.4058874547481537\n",
      "tensor([1., 0.]) tensor([0.9074, 0.0926], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 55 - 17: cat - cat || Loss: 0.40574920177459717\n",
      "tensor([1., 0.]) tensor([0.9075, 0.0925], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 55 - 18: cat - cat || Loss: 0.40560442209243774\n",
      "tensor([1., 0.]) tensor([0.9077, 0.0923], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 55 - 19: cat - cat || Loss: 0.4054536819458008\n",
      "tensor([1., 0.]) tensor([0.9078, 0.0922], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 55 - 20: cat - cat || Loss: 0.40529757738113403\n",
      "tensor([1., 0.]) tensor([0.9080, 0.0920], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 55 - 21: cat - cat || Loss: 0.40513676404953003\n",
      "tensor([1., 0.]) tensor([0.9081, 0.0919], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 55 - 22: cat - cat || Loss: 0.4049718677997589\n",
      "tensor([1., 0.]) tensor([0.9083, 0.0917], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 55 - 23: cat - cat || Loss: 0.4048031270503998\n",
      "tensor([1., 0.]) tensor([0.9085, 0.0915], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 55 - 24: cat - cat || Loss: 0.4046310782432556\n",
      "tensor([1., 0.]) tensor([0.9086, 0.0914], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 55 - 25: cat - cat || Loss: 0.40445616841316223\n",
      "tensor([1., 0.]) tensor([0.9088, 0.0912], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 55 - 26: cat - cat || Loss: 0.4042786657810211\n",
      "tensor([1., 0.]) tensor([0.9090, 0.0910], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 55 - 27: cat - cat || Loss: 0.40409889817237854\n",
      "tensor([1., 0.]) tensor([0.9092, 0.0908], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 55 - 28: cat - cat || Loss: 0.403917133808136\n",
      "tensor([1., 0.]) tensor([0.9093, 0.0907], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 55 - 29: cat - cat || Loss: 0.40373358130455017\n",
      "tensor([1., 0.]) tensor([0.9095, 0.0905], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 55 - 30: cat - cat || Loss: 0.40354856848716736\n",
      "tensor([1., 0.]) tensor([0.9097, 0.0903], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 55 - 31: cat - cat || Loss: 0.4033621549606323\n",
      "tensor([1., 0.]) tensor([0.9099, 0.0901], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 55 - 32: cat - cat || Loss: 0.40317460894584656\n",
      "tensor([1., 0.]) tensor([0.9101, 0.0899], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 55 - 33: cat - cat || Loss: 0.40298619866371155\n",
      "tensor([1., 0.]) tensor([0.9103, 0.0897], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 55 - 34: cat - cat || Loss: 0.4027968645095825\n",
      "tensor([1., 0.]) tensor([0.9105, 0.0895], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 55 - 35: cat - cat || Loss: 0.4026068449020386\n",
      "tensor([1., 0.]) tensor([0.9107, 0.0893], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 55 - 36: cat - cat || Loss: 0.4024162292480469\n",
      "tensor([1., 0.]) tensor([0.9108, 0.0892], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 55 - 37: cat - cat || Loss: 0.40222519636154175\n",
      "tensor([1., 0.]) tensor([0.9110, 0.0890], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 55 - 38: cat - cat || Loss: 0.4020337760448456\n",
      "tensor([1., 0.]) tensor([0.9112, 0.0888], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 55 - 39: cat - cat || Loss: 0.4018420875072479\n",
      "tensor([1., 0.]) tensor([0.9114, 0.0886], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 55 - 40: cat - cat || Loss: 0.40165024995803833\n",
      "tensor([1., 0.]) tensor([0.9116, 0.0884], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 55 - 41: cat - cat || Loss: 0.40145814418792725\n",
      "tensor([1., 0.]) tensor([0.9118, 0.0882], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 55 - 42: cat - cat || Loss: 0.40126603841781616\n",
      "tensor([1., 0.]) tensor([0.9120, 0.0880], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 55 - 43: cat - cat || Loss: 0.4010738134384155\n",
      "tensor([1., 0.]) tensor([0.9122, 0.0878], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 55 - 44: cat - cat || Loss: 0.4008818566799164\n",
      "tensor([1., 0.]) tensor([0.9124, 0.0876], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 55 - 45: cat - cat || Loss: 0.4006896913051605\n",
      "tensor([1., 0.]) tensor([0.9126, 0.0874], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 55 - 46: cat - cat || Loss: 0.4004978537559509\n",
      "tensor([1., 0.]) tensor([0.9128, 0.0872], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 55 - 47: cat - cat || Loss: 0.4003060460090637\n",
      "tensor([1., 0.]) tensor([0.9130, 0.0870], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 55 - 48: cat - cat || Loss: 0.4001145362854004\n",
      "tensor([1., 0.]) tensor([0.9131, 0.0869], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 55 - 49: cat - cat || Loss: 0.3999232053756714\n",
      "tensor([1., 0.]) tensor([0.9133, 0.0867], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 55 - 50: cat - cat || Loss: 0.3997320234775543\n",
      "tensor([1., 0.]) tensor([0.9135, 0.0865], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 55 - 51: cat - cat || Loss: 0.3995411992073059\n",
      "tensor([1., 0.]) tensor([0.9137, 0.0863], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 55 - 52: cat - cat || Loss: 0.39935067296028137\n",
      "tensor([1., 0.]) tensor([0.9139, 0.0861], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 55 - 53: cat - cat || Loss: 0.39916035532951355\n",
      "tensor([1., 0.]) tensor([0.9141, 0.0859], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 55 - 54: cat - cat || Loss: 0.3989705443382263\n",
      "tensor([1., 0.]) tensor([0.9143, 0.0857], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 55 - 55: cat - cat || Loss: 0.3987809419631958\n",
      "tensor([1., 0.]) tensor([0.9145, 0.0855], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 55 - 56: cat - cat || Loss: 0.39859166741371155\n",
      "tensor([1., 0.]) tensor([0.9147, 0.0853], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 55 - 57: cat - cat || Loss: 0.3984028398990631\n",
      "tensor([1., 0.]) tensor([0.9149, 0.0851], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 55 - 58: cat - cat || Loss: 0.39821434020996094\n",
      "tensor([1., 0.]) tensor([0.9150, 0.0850], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 55 - 59: cat - cat || Loss: 0.3980262279510498\n",
      "tensor([1., 0.]) tensor([0.9152, 0.0848], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 55 - 60: cat - cat || Loss: 0.3978385329246521\n",
      "tensor([1., 0.]) tensor([0.9154, 0.0846], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 55 - 61: cat - cat || Loss: 0.39765122532844543\n",
      "tensor([1., 0.]) tensor([0.9156, 0.0844], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 55 - 62: cat - cat || Loss: 0.3974642753601074\n",
      "tensor([1., 0.]) tensor([0.9158, 0.0842], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 55 - 63: cat - cat || Loss: 0.39727783203125\n",
      "tensor([1., 0.]) tensor([0.9160, 0.0840], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 55 - 64: cat - cat || Loss: 0.39709168672561646\n",
      "tensor([1., 0.]) tensor([0.9162, 0.0838], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 55 - 65: cat - cat || Loss: 0.3969060480594635\n",
      "tensor([1., 0.]) tensor([0.9164, 0.0836], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 55 - 66: cat - cat || Loss: 0.3967207670211792\n",
      "tensor([1., 0.]) tensor([0.9165, 0.0835], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 55 - 67: cat - cat || Loss: 0.39653605222702026\n",
      "tensor([1., 0.]) tensor([0.9167, 0.0833], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 55 - 68: cat - cat || Loss: 0.3963516354560852\n",
      "tensor([1., 0.]) tensor([0.9169, 0.0831], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 55 - 69: cat - cat || Loss: 0.3961676359176636\n",
      "tensor([1., 0.]) tensor([0.9171, 0.0829], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 55 - 70: cat - cat || Loss: 0.3959841728210449\n",
      "tensor([1., 0.]) tensor([0.9173, 0.0827], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 55 - 71: cat - cat || Loss: 0.3958011865615845\n",
      "tensor([1., 0.]) tensor([0.9175, 0.0825], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 55 - 72: cat - cat || Loss: 0.3956185579299927\n",
      "tensor([1., 0.]) tensor([0.9176, 0.0824], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 55 - 73: cat - cat || Loss: 0.3954363465309143\n",
      "tensor([1., 0.]) tensor([0.9178, 0.0822], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 55 - 74: cat - cat || Loss: 0.39525455236434937\n",
      "tensor([1., 0.]) tensor([0.9180, 0.0820], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 55 - 75: cat - cat || Loss: 0.3950733542442322\n",
      "tensor([1., 0.]) tensor([0.9182, 0.0818], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 55 - 76: cat - cat || Loss: 0.39489251375198364\n",
      "tensor([1., 0.]) tensor([0.9184, 0.0816], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 55 - 77: cat - cat || Loss: 0.3947121500968933\n",
      "tensor([1., 0.]) tensor([0.9185, 0.0815], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 55 - 78: cat - cat || Loss: 0.3945322036743164\n",
      "tensor([1., 0.]) tensor([0.9187, 0.0813], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 55 - 79: cat - cat || Loss: 0.39435267448425293\n",
      "tensor([1., 0.]) tensor([0.9189, 0.0811], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 55 - 80: cat - cat || Loss: 0.39417368173599243\n",
      "tensor([1., 0.]) tensor([0.9191, 0.0809], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 55 - 81: cat - cat || Loss: 0.3939950466156006\n",
      "tensor([1., 0.]) tensor([0.9193, 0.0807], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 55 - 82: cat - cat || Loss: 0.39381691813468933\n",
      "tensor([1., 0.]) tensor([0.9194, 0.0806], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 55 - 83: cat - cat || Loss: 0.3936391770839691\n",
      "tensor([1., 0.]) tensor([0.9196, 0.0804], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 55 - 84: cat - cat || Loss: 0.39346200227737427\n",
      "tensor([1., 0.]) tensor([0.9198, 0.0802], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 55 - 85: cat - cat || Loss: 0.3932851552963257\n",
      "tensor([1., 0.]) tensor([0.9200, 0.0800], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 55 - 86: cat - cat || Loss: 0.3931087255477905\n",
      "tensor([1., 0.]) tensor([0.9202, 0.0798], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 55 - 87: cat - cat || Loss: 0.3929327726364136\n",
      "tensor([1., 0.]) tensor([0.9203, 0.0797], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 55 - 88: cat - cat || Loss: 0.3927572965621948\n",
      "tensor([1., 0.]) tensor([0.9205, 0.0795], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 55 - 89: cat - cat || Loss: 0.3925822377204895\n",
      "tensor([1., 0.]) tensor([0.9207, 0.0793], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 55 - 90: cat - cat || Loss: 0.3924075961112976\n",
      "tensor([1., 0.]) tensor([0.9209, 0.0791], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 55 - 91: cat - cat || Loss: 0.39223340153694153\n",
      "tensor([1., 0.]) tensor([0.9210, 0.0790], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 55 - 92: cat - cat || Loss: 0.39205968379974365\n",
      "tensor([1., 0.]) tensor([0.9212, 0.0788], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 55 - 93: cat - cat || Loss: 0.3918864130973816\n",
      "tensor([1., 0.]) tensor([0.9214, 0.0786], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 55 - 94: cat - cat || Loss: 0.3917134404182434\n",
      "tensor([1., 0.]) tensor([0.9215, 0.0785], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 55 - 95: cat - cat || Loss: 0.3915410041809082\n",
      "tensor([1., 0.]) tensor([0.9217, 0.0783], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 55 - 96: cat - cat || Loss: 0.3913690447807312\n",
      "tensor([1., 0.]) tensor([0.9219, 0.0781], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 55 - 97: cat - cat || Loss: 0.39119741320610046\n",
      "tensor([1., 0.]) tensor([0.9221, 0.0779], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 55 - 98: cat - cat || Loss: 0.39102622866630554\n",
      "tensor([1., 0.]) tensor([0.9222, 0.0778], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 55 - 99: cat - cat || Loss: 0.390855610370636\n",
      "tensor([1., 0.]) tensor([0.9224, 0.0776], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 55 - 100: cat - cat || Loss: 0.3906852900981903\n",
      "tensor([1., 0.]) tensor([0.9226, 0.0774], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 55 - 101: cat - cat || Loss: 0.39051544666290283\n",
      "tensor([1., 0.]) tensor([0.9227, 0.0773], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 55 - 102: cat - cat || Loss: 0.3903460204601288\n",
      "tensor([1., 0.]) tensor([0.9229, 0.0771], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 55 - 103: cat - cat || Loss: 0.3901769518852234\n",
      "tensor([1., 0.]) tensor([0.9231, 0.0769], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 55 - 104: cat - cat || Loss: 0.3900083601474762\n",
      "tensor([1., 0.]) tensor([0.9233, 0.0767], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 55 - 105: cat - cat || Loss: 0.3898402452468872\n",
      "tensor([1., 0.]) tensor([0.9234, 0.0766], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 55 - 106: cat - cat || Loss: 0.38967248797416687\n",
      "tensor([1., 0.]) tensor([0.9236, 0.0764], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 55 - 107: cat - cat || Loss: 0.38950517773628235\n",
      "tensor([1., 0.]) tensor([0.9238, 0.0762], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 55 - 108: cat - cat || Loss: 0.38933831453323364\n",
      "tensor([1., 0.]) tensor([0.9239, 0.0761], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 55 - 109: cat - cat || Loss: 0.38917192816734314\n",
      "tensor([1., 0.]) tensor([0.9241, 0.0759], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 55 - 110: cat - cat || Loss: 0.3890058398246765\n",
      "tensor([1., 0.]) tensor([0.9243, 0.0757], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 55 - 111: cat - cat || Loss: 0.3888402283191681\n",
      "tensor([1., 0.]) tensor([0.9244, 0.0756], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 55 - 112: cat - cat || Loss: 0.3886749744415283\n",
      "tensor([1., 0.]) tensor([0.9246, 0.0754], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 55 - 113: cat - cat || Loss: 0.38851025700569153\n",
      "tensor([1., 0.]) tensor([0.9248, 0.0752], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 55 - 114: cat - cat || Loss: 0.3883458077907562\n",
      "tensor([1., 0.]) tensor([0.9249, 0.0751], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 55 - 115: cat - cat || Loss: 0.3881818652153015\n",
      "tensor([1., 0.]) tensor([0.9251, 0.0749], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 55 - 116: cat - cat || Loss: 0.38801833987236023\n",
      "tensor([1., 0.]) tensor([0.9252, 0.0748], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 55 - 117: cat - cat || Loss: 0.3878552317619324\n",
      "tensor([1., 0.]) tensor([0.9254, 0.0746], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 55 - 118: cat - cat || Loss: 0.3876924514770508\n",
      "tensor([1., 0.]) tensor([0.9256, 0.0744], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 55 - 119: cat - cat || Loss: 0.38753020763397217\n",
      "tensor([1., 0.]) tensor([0.9257, 0.0743], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 55 - 120: cat - cat || Loss: 0.38736826181411743\n",
      "tensor([1., 0.]) tensor([0.9259, 0.0741], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 55 - 121: cat - cat || Loss: 0.3872067928314209\n",
      "tensor([1., 0.]) tensor([0.9261, 0.0739], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 55 - 122: cat - cat || Loss: 0.387045681476593\n",
      "tensor([1., 0.]) tensor([0.9262, 0.0738], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 55 - 123: cat - cat || Loss: 0.3868851065635681\n",
      "tensor([1., 0.]) tensor([0.9264, 0.0736], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 55 - 124: cat - cat || Loss: 0.3867247700691223\n",
      "tensor([1., 0.]) tensor([0.9265, 0.0735], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 55 - 125: cat - cat || Loss: 0.3865649402141571\n",
      "tensor([1., 0.]) tensor([0.9267, 0.0733], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 55 - 126: cat - cat || Loss: 0.38640546798706055\n",
      "tensor([1., 0.]) tensor([0.9269, 0.0731], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 55 - 127: cat - cat || Loss: 0.38624635338783264\n",
      "tensor([1., 0.]) tensor([0.9270, 0.0730], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 55 - 128: cat - cat || Loss: 0.3860877454280853\n",
      "tensor([1., 0.]) tensor([0.9272, 0.0728], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 55 - 129: cat - cat || Loss: 0.3859294056892395\n",
      "tensor([1., 0.]) tensor([0.9273, 0.0727], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 55 - 130: cat - cat || Loss: 0.38577163219451904\n",
      "tensor([1., 0.]) tensor([0.9275, 0.0725], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 55 - 131: cat - cat || Loss: 0.3856141269207001\n",
      "tensor([1., 0.]) tensor([0.9276, 0.0724], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 55 - 132: cat - cat || Loss: 0.38545697927474976\n",
      "tensor([1., 0.]) tensor([0.9278, 0.0722], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 55 - 133: cat - cat || Loss: 0.3853003680706024\n",
      "tensor([1., 0.]) tensor([0.9280, 0.0720], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 55 - 134: cat - cat || Loss: 0.38514408469200134\n",
      "tensor([1., 0.]) tensor([0.9281, 0.0719], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 55 - 135: cat - cat || Loss: 0.38498827815055847\n",
      "tensor([1., 0.]) tensor([0.9283, 0.0717], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 55 - 136: cat - cat || Loss: 0.3848327696323395\n",
      "tensor([1., 0.]) tensor([0.9284, 0.0716], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 55 - 137: cat - cat || Loss: 0.3846776485443115\n",
      "tensor([1., 0.]) tensor([0.9286, 0.0714], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 55 - 138: cat - cat || Loss: 0.3845229744911194\n",
      "tensor([1., 0.]) tensor([0.9287, 0.0713], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 55 - 139: cat - cat || Loss: 0.3843685984611511\n",
      "tensor([1., 0.]) tensor([0.9289, 0.0711], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 55 - 140: cat - cat || Loss: 0.3842145800590515\n",
      "tensor([1., 0.]) tensor([0.9290, 0.0710], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 55 - 141: cat - cat || Loss: 0.3840610682964325\n",
      "tensor([1., 0.]) tensor([0.9292, 0.0708], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 55 - 142: cat - cat || Loss: 0.38390791416168213\n",
      "tensor([1., 0.]) tensor([0.9294, 0.0706], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 55 - 143: cat - cat || Loss: 0.383755087852478\n",
      "tensor([1., 0.]) tensor([0.9295, 0.0705], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 55 - 144: cat - cat || Loss: 0.38360273838043213\n",
      "tensor([1., 0.]) tensor([0.9297, 0.0703], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 55 - 145: cat - cat || Loss: 0.3834506869316101\n",
      "tensor([1., 0.]) tensor([0.9298, 0.0702], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 55 - 146: cat - cat || Loss: 0.3832990825176239\n",
      "tensor([1., 0.]) tensor([0.9300, 0.0700], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 55 - 147: cat - cat || Loss: 0.38314783573150635\n",
      "tensor([1., 0.]) tensor([0.9301, 0.0699], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 55 - 148: cat - cat || Loss: 0.38299694657325745\n",
      "tensor([1., 0.]) tensor([0.9303, 0.0697], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 55 - 149: cat - cat || Loss: 0.382846474647522\n",
      "tensor([1., 0.]) tensor([0.9304, 0.0696], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 55 - 150: cat - cat || Loss: 0.38269633054733276\n",
      "tensor([1., 0.]) tensor([0.9306, 0.0694], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 55 - 151: cat - cat || Loss: 0.3825465738773346\n",
      "tensor([1., 0.]) tensor([0.9307, 0.0693], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 55 - 152: cat - cat || Loss: 0.3823971748352051\n",
      "tensor([1., 0.]) tensor([0.9309, 0.0691], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 55 - 153: cat - cat || Loss: 0.3822481334209442\n",
      "tensor([1., 0.]) tensor([0.9310, 0.0690], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 55 - 154: cat - cat || Loss: 0.38209956884384155\n",
      "tensor([1., 0.]) tensor([0.9312, 0.0688], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 55 - 155: cat - cat || Loss: 0.3819512128829956\n",
      "tensor([1., 0.]) tensor([0.9313, 0.0687], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 55 - 156: cat - cat || Loss: 0.381803423166275\n",
      "tensor([1., 0.]) tensor([0.9315, 0.0685], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 55 - 157: cat - cat || Loss: 0.3816559314727783\n",
      "tensor([1., 0.]) tensor([0.9316, 0.0684], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 55 - 158: cat - cat || Loss: 0.3815087080001831\n",
      "tensor([1., 0.]) tensor([0.9318, 0.0682], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 55 - 159: cat - cat || Loss: 0.3813619315624237\n",
      "tensor([1., 0.]) tensor([0.9319, 0.0681], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 55 - 160: cat - cat || Loss: 0.38121548295021057\n",
      "tensor([1., 0.]) tensor([0.9320, 0.0680], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 55 - 161: cat - cat || Loss: 0.38106948137283325\n",
      "tensor([1., 0.]) tensor([0.9322, 0.0678], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 55 - 162: cat - cat || Loss: 0.3809238374233246\n",
      "tensor([1., 0.]) tensor([0.9323, 0.0677], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 55 - 163: cat - cat || Loss: 0.3807784616947174\n",
      "tensor([1., 0.]) tensor([0.9325, 0.0675], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 55 - 164: cat - cat || Loss: 0.38063347339630127\n",
      "tensor([1., 0.]) tensor([0.9326, 0.0674], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 55 - 165: cat - cat || Loss: 0.38048893213272095\n",
      "tensor([1., 0.]) tensor([0.9328, 0.0672], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 55 - 166: cat - cat || Loss: 0.38034459948539734\n",
      "tensor([1., 0.]) tensor([0.9329, 0.0671], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 55 - 167: cat - cat || Loss: 0.38020071387290955\n",
      "tensor([1., 0.]) tensor([0.9331, 0.0669], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 55 - 168: cat - cat || Loss: 0.3800572156906128\n",
      "tensor([1., 0.]) tensor([0.9332, 0.0668], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 55 - 169: cat - cat || Loss: 0.37991398572921753\n",
      "tensor([1., 0.]) tensor([0.9333, 0.0667], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 55 - 170: cat - cat || Loss: 0.3797711730003357\n",
      "tensor([1., 0.]) tensor([0.9335, 0.0665], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 55 - 171: cat - cat || Loss: 0.3796287477016449\n",
      "tensor([1., 0.]) tensor([0.9336, 0.0664], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 55 - 172: cat - cat || Loss: 0.3794865906238556\n",
      "tensor([1., 0.]) tensor([0.9338, 0.0662], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 55 - 173: cat - cat || Loss: 0.3793448805809021\n",
      "tensor([1., 0.]) tensor([0.9339, 0.0661], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 55 - 174: cat - cat || Loss: 0.3792033791542053\n",
      "tensor([1., 0.]) tensor([0.9341, 0.0659], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 55 - 175: cat - cat || Loss: 0.379062294960022\n",
      "tensor([1., 0.]) tensor([0.9342, 0.0658], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 55 - 176: cat - cat || Loss: 0.37892162799835205\n",
      "tensor([1., 0.]) tensor([0.9343, 0.0657], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 55 - 177: cat - cat || Loss: 0.3787812292575836\n",
      "tensor([1., 0.]) tensor([0.9345, 0.0655], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 55 - 178: cat - cat || Loss: 0.3786412179470062\n",
      "tensor([1., 0.]) tensor([0.9346, 0.0654], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 55 - 179: cat - cat || Loss: 0.3785015642642975\n",
      "tensor([1., 0.]) tensor([0.9348, 0.0652], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 55 - 180: cat - cat || Loss: 0.378362238407135\n",
      "tensor([1., 0.]) tensor([0.9349, 0.0651], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 55 - 181: cat - cat || Loss: 0.3782232403755188\n",
      "tensor([1., 0.]) tensor([0.9350, 0.0650], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 55 - 182: cat - cat || Loss: 0.37808454036712646\n",
      "tensor([1., 0.]) tensor([0.9352, 0.0648], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 55 - 183: cat - cat || Loss: 0.37794628739356995\n",
      "tensor([1., 0.]) tensor([0.9353, 0.0647], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 55 - 184: cat - cat || Loss: 0.37780827283859253\n",
      "tensor([1., 0.]) tensor([0.9355, 0.0645], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 55 - 185: cat - cat || Loss: 0.37767064571380615\n",
      "tensor([1., 0.]) tensor([0.9356, 0.0644], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 55 - 186: cat - cat || Loss: 0.3775332272052765\n",
      "tensor([1., 0.]) tensor([0.9357, 0.0643], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 55 - 187: cat - cat || Loss: 0.37739628553390503\n",
      "tensor([1., 0.]) tensor([0.9359, 0.0641], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 55 - 188: cat - cat || Loss: 0.3772595524787903\n",
      "tensor([1., 0.]) tensor([0.9360, 0.0640], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 55 - 189: cat - cat || Loss: 0.3771231174468994\n",
      "tensor([1., 0.]) tensor([0.9361, 0.0639], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 55 - 190: dog - cat || Loss: 1.249536395072937\n",
      "tensor([0., 1.]) tensor([0.9363, 0.0637], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 55 - 191: dog - cat || Loss: 1.2496453523635864\n",
      "tensor([0., 1.]) tensor([0.9364, 0.0636], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 55 - 192: dog - cat || Loss: 1.2497297525405884\n",
      "tensor([0., 1.]) tensor([0.9365, 0.0635], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 55 - 193: dog - cat || Loss: 1.2497923374176025\n",
      "tensor([0., 1.]) tensor([0.9365, 0.0635], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 55 - 194: dog - cat || Loss: 1.2498352527618408\n",
      "tensor([0., 1.]) tensor([0.9366, 0.0634], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 55 - 195: dog - cat || Loss: 1.249860405921936\n",
      "tensor([0., 1.]) tensor([0.9366, 0.0634], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 55 - 196: dog - cat || Loss: 1.2498698234558105\n",
      "tensor([0., 1.]) tensor([0.9366, 0.0634], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 55 - 197: dog - cat || Loss: 1.2498645782470703\n",
      "tensor([0., 1.]) tensor([0.9366, 0.0634], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 55 - 198: dog - cat || Loss: 1.2498466968536377\n",
      "tensor([0., 1.]) tensor([0.9366, 0.0634], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 55 - 199: dog - cat || Loss: 1.2498172521591187\n",
      "tensor([0., 1.]) tensor([0.9366, 0.0634], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 55 - 200: dog - cat || Loss: 1.2497773170471191\n",
      "tensor([0., 1.]) tensor([0.9365, 0.0635], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 55 - 201: dog - cat || Loss: 1.2497278451919556\n",
      "tensor([0., 1.]) tensor([0.9365, 0.0635], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 55 - 202: dog - cat || Loss: 1.249670147895813\n",
      "tensor([0., 1.]) tensor([0.9364, 0.0636], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 55 - 203: dog - cat || Loss: 1.24960458278656\n",
      "tensor([0., 1.]) tensor([0.9363, 0.0637], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 55 - 204: dog - cat || Loss: 1.2495322227478027\n",
      "tensor([0., 1.]) tensor([0.9363, 0.0637], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 55 - 205: dog - cat || Loss: 1.2494535446166992\n",
      "tensor([0., 1.]) tensor([0.9362, 0.0638], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 55 - 206: dog - cat || Loss: 1.2493692636489868\n",
      "tensor([0., 1.]) tensor([0.9361, 0.0639], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 55 - 207: dog - cat || Loss: 1.2492799758911133\n",
      "tensor([0., 1.]) tensor([0.9360, 0.0640], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 55 - 208: dog - cat || Loss: 1.2491859197616577\n",
      "tensor([0., 1.]) tensor([0.9359, 0.0641], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 55 - 209: dog - cat || Loss: 1.2490878105163574\n",
      "tensor([0., 1.]) tensor([0.9358, 0.0642], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 55 - 210: dog - cat || Loss: 1.248985767364502\n",
      "tensor([0., 1.]) tensor([0.9357, 0.0643], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 55 - 211: dog - cat || Loss: 1.248880386352539\n",
      "tensor([0., 1.]) tensor([0.9356, 0.0644], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 55 - 212: dog - cat || Loss: 1.2487717866897583\n",
      "tensor([0., 1.]) tensor([0.9355, 0.0645], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 55 - 213: dog - cat || Loss: 1.2486605644226074\n",
      "tensor([0., 1.]) tensor([0.9354, 0.0646], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 55 - 214: dog - cat || Loss: 1.2485464811325073\n",
      "tensor([0., 1.]) tensor([0.9353, 0.0647], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 55 - 215: dog - cat || Loss: 1.2484302520751953\n",
      "tensor([0., 1.]) tensor([0.9352, 0.0648], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 55 - 216: dog - cat || Loss: 1.2483117580413818\n",
      "tensor([0., 1.]) tensor([0.9351, 0.0649], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 55 - 217: dog - cat || Loss: 1.248191237449646\n",
      "tensor([0., 1.]) tensor([0.9349, 0.0651], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 55 - 218: dog - cat || Loss: 1.248068928718567\n",
      "tensor([0., 1.]) tensor([0.9348, 0.0652], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 55 - 219: dog - cat || Loss: 1.2479450702667236\n",
      "tensor([0., 1.]) tensor([0.9347, 0.0653], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 55 - 220: dog - cat || Loss: 1.2478195428848267\n",
      "tensor([0., 1.]) tensor([0.9346, 0.0654], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 55 - 221: dog - cat || Loss: 1.247692584991455\n",
      "tensor([0., 1.]) tensor([0.9344, 0.0656], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 55 - 222: dog - cat || Loss: 1.2475643157958984\n",
      "tensor([0., 1.]) tensor([0.9343, 0.0657], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 55 - 223: dog - cat || Loss: 1.2474348545074463\n",
      "tensor([0., 1.]) tensor([0.9342, 0.0658], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 55 - 224: dog - cat || Loss: 1.2473043203353882\n",
      "tensor([0., 1.]) tensor([0.9340, 0.0660], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 55 - 225: dog - cat || Loss: 1.2471728324890137\n",
      "tensor([0., 1.]) tensor([0.9339, 0.0661], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 55 - 226: dog - cat || Loss: 1.2470402717590332\n",
      "tensor([0., 1.]) tensor([0.9338, 0.0662], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 55 - 227: dog - cat || Loss: 1.2469067573547363\n",
      "tensor([0., 1.]) tensor([0.9336, 0.0664], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 55 - 228: dog - cat || Loss: 1.2467724084854126\n",
      "tensor([0., 1.]) tensor([0.9335, 0.0665], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 55 - 229: dog - cat || Loss: 1.2466374635696411\n",
      "tensor([0., 1.]) tensor([0.9334, 0.0666], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 55 - 230: dog - cat || Loss: 1.2465015649795532\n",
      "tensor([0., 1.]) tensor([0.9332, 0.0668], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 55 - 231: dog - cat || Loss: 1.246364951133728\n",
      "tensor([0., 1.]) tensor([0.9331, 0.0669], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 55 - 232: dog - cat || Loss: 1.2462276220321655\n",
      "tensor([0., 1.]) tensor([0.9330, 0.0670], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 55 - 233: dog - cat || Loss: 1.2460896968841553\n",
      "tensor([0., 1.]) tensor([0.9328, 0.0672], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 55 - 234: dog - cat || Loss: 1.2459512948989868\n",
      "tensor([0., 1.]) tensor([0.9327, 0.0673], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 55 - 235: dog - cat || Loss: 1.2458122968673706\n",
      "tensor([0., 1.]) tensor([0.9326, 0.0674], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 55 - 236: dog - cat || Loss: 1.245672583580017\n",
      "tensor([0., 1.]) tensor([0.9324, 0.0676], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 55 - 237: dog - cat || Loss: 1.2455322742462158\n",
      "tensor([0., 1.]) tensor([0.9323, 0.0677], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 55 - 238: dog - cat || Loss: 1.245391607284546\n",
      "tensor([0., 1.]) tensor([0.9321, 0.0679], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 55 - 239: dog - cat || Loss: 1.2452504634857178\n",
      "tensor([0., 1.]) tensor([0.9320, 0.0680], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 55 - 240: dog - cat || Loss: 1.2451086044311523\n",
      "tensor([0., 1.]) tensor([0.9318, 0.0682], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 55 - 241: dog - cat || Loss: 1.2449663877487183\n",
      "tensor([0., 1.]) tensor([0.9317, 0.0683], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 55 - 242: dog - cat || Loss: 1.244823694229126\n",
      "tensor([0., 1.]) tensor([0.9316, 0.0684], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 55 - 243: dog - cat || Loss: 1.2446805238723755\n",
      "tensor([0., 1.]) tensor([0.9314, 0.0686], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 55 - 244: dog - cat || Loss: 1.2445369958877563\n",
      "tensor([0., 1.]) tensor([0.9313, 0.0687], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 55 - 245: dog - cat || Loss: 1.2443931102752686\n",
      "tensor([0., 1.]) tensor([0.9311, 0.0689], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 55 - 246: dog - cat || Loss: 1.244248628616333\n",
      "tensor([0., 1.]) tensor([0.9310, 0.0690], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 55 - 247: dog - cat || Loss: 1.2441037893295288\n",
      "tensor([0., 1.]) tensor([0.9308, 0.0692], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 55 - 248: dog - cat || Loss: 1.2439584732055664\n",
      "tensor([0., 1.]) tensor([0.9307, 0.0693], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 55 - 249: dog - cat || Loss: 1.2438127994537354\n",
      "tensor([0., 1.]) tensor([0.9306, 0.0694], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 55 - 250: dog - cat || Loss: 1.2436667680740356\n",
      "tensor([0., 1.]) tensor([0.9304, 0.0696], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 55 - 251: dog - cat || Loss: 1.2435202598571777\n",
      "tensor([0., 1.]) tensor([0.9303, 0.0697], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 55 - 252: dog - cat || Loss: 1.2433735132217407\n",
      "tensor([0., 1.]) tensor([0.9301, 0.0699], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 55 - 253: dog - cat || Loss: 1.2432260513305664\n",
      "tensor([0., 1.]) tensor([0.9300, 0.0700], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 55 - 254: dog - cat || Loss: 1.243078351020813\n",
      "tensor([0., 1.]) tensor([0.9298, 0.0702], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 55 - 255: dog - cat || Loss: 1.242930293083191\n",
      "tensor([0., 1.]) tensor([0.9297, 0.0703], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 55 - 256: dog - cat || Loss: 1.2427817583084106\n",
      "tensor([0., 1.]) tensor([0.9295, 0.0705], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 55 - 257: dog - cat || Loss: 1.2426329851150513\n",
      "tensor([0., 1.]) tensor([0.9294, 0.0706], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 55 - 258: dog - cat || Loss: 1.2424836158752441\n",
      "tensor([0., 1.]) tensor([0.9292, 0.0708], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 55 - 259: dog - cat || Loss: 1.2423341274261475\n",
      "tensor([0., 1.]) tensor([0.9291, 0.0709], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 55 - 260: dog - cat || Loss: 1.242184042930603\n",
      "tensor([0., 1.]) tensor([0.9289, 0.0711], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 55 - 261: dog - cat || Loss: 1.242033839225769\n",
      "tensor([0., 1.]) tensor([0.9288, 0.0712], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 55 - 262: dog - cat || Loss: 1.2418830394744873\n",
      "tensor([0., 1.]) tensor([0.9286, 0.0714], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 55 - 263: dog - cat || Loss: 1.241731882095337\n",
      "tensor([0., 1.]) tensor([0.9285, 0.0715], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 55 - 264: dog - cat || Loss: 1.2415802478790283\n",
      "tensor([0., 1.]) tensor([0.9283, 0.0717], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 55 - 265: dog - cat || Loss: 1.2414283752441406\n",
      "tensor([0., 1.]) tensor([0.9282, 0.0718], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 55 - 266: dog - cat || Loss: 1.2412760257720947\n",
      "tensor([0., 1.]) tensor([0.9280, 0.0720], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 55 - 267: dog - cat || Loss: 1.2411236763000488\n",
      "tensor([0., 1.]) tensor([0.9279, 0.0721], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 55 - 268: dog - cat || Loss: 1.2409703731536865\n",
      "tensor([0., 1.]) tensor([0.9277, 0.0723], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 55 - 269: dog - cat || Loss: 1.2408169507980347\n",
      "tensor([0., 1.]) tensor([0.9276, 0.0724], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 55 - 270: dog - cat || Loss: 1.2406631708145142\n",
      "tensor([0., 1.]) tensor([0.9274, 0.0726], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 55 - 271: dog - cat || Loss: 1.240509033203125\n",
      "tensor([0., 1.]) tensor([0.9272, 0.0728], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 55 - 272: dog - cat || Loss: 1.2403544187545776\n",
      "tensor([0., 1.]) tensor([0.9271, 0.0729], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 55 - 273: dog - cat || Loss: 1.2401995658874512\n",
      "tensor([0., 1.]) tensor([0.9269, 0.0731], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 55 - 274: dog - cat || Loss: 1.2400442361831665\n",
      "tensor([0., 1.]) tensor([0.9268, 0.0732], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 55 - 275: dog - cat || Loss: 1.2398884296417236\n",
      "tensor([0., 1.]) tensor([0.9266, 0.0734], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 55 - 276: dog - cat || Loss: 1.2397323846817017\n",
      "tensor([0., 1.]) tensor([0.9265, 0.0735], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 55 - 277: dog - cat || Loss: 1.2395758628845215\n",
      "tensor([0., 1.]) tensor([0.9263, 0.0737], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 55 - 278: dog - cat || Loss: 1.2394191026687622\n",
      "tensor([0., 1.]) tensor([0.9262, 0.0738], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 55 - 279: dog - cat || Loss: 1.2392617464065552\n",
      "tensor([0., 1.]) tensor([0.9260, 0.0740], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 55 - 280: dog - cat || Loss: 1.239104151725769\n",
      "tensor([0., 1.]) tensor([0.9258, 0.0742], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 55 - 281: dog - cat || Loss: 1.2389460802078247\n",
      "tensor([0., 1.]) tensor([0.9257, 0.0743], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 55 - 282: dog - cat || Loss: 1.2387876510620117\n",
      "tensor([0., 1.]) tensor([0.9255, 0.0745], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 55 - 283: dog - cat || Loss: 1.2386287450790405\n",
      "tensor([0., 1.]) tensor([0.9254, 0.0746], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 55 - 284: dog - cat || Loss: 1.2384696006774902\n",
      "tensor([0., 1.]) tensor([0.9252, 0.0748], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 55 - 285: dog - cat || Loss: 1.2383100986480713\n",
      "tensor([0., 1.]) tensor([0.9250, 0.0750], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 55 - 286: dog - cat || Loss: 1.2381500005722046\n",
      "tensor([0., 1.]) tensor([0.9249, 0.0751], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 55 - 287: dog - cat || Loss: 1.2379895448684692\n",
      "tensor([0., 1.]) tensor([0.9247, 0.0753], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 55 - 288: dog - cat || Loss: 1.2378289699554443\n",
      "tensor([0., 1.]) tensor([0.9246, 0.0754], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 55 - 289: dog - cat || Loss: 1.2376675605773926\n",
      "tensor([0., 1.]) tensor([0.9244, 0.0756], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 55 - 290: dog - cat || Loss: 1.2375062704086304\n",
      "tensor([0., 1.]) tensor([0.9242, 0.0758], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 55 - 291: dog - cat || Loss: 1.2373441457748413\n",
      "tensor([0., 1.]) tensor([0.9241, 0.0759], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 55 - 292: dog - cat || Loss: 1.2371816635131836\n",
      "tensor([0., 1.]) tensor([0.9239, 0.0761], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 55 - 293: dog - cat || Loss: 1.2370189428329468\n",
      "tensor([0., 1.]) tensor([0.9238, 0.0762], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 55 - 294: dog - cat || Loss: 1.2368557453155518\n",
      "tensor([0., 1.]) tensor([0.9236, 0.0764], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 55 - 295: dog - cat || Loss: 1.236692190170288\n",
      "tensor([0., 1.]) tensor([0.9234, 0.0766], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 55 - 296: dog - cat || Loss: 1.2365282773971558\n",
      "tensor([0., 1.]) tensor([0.9233, 0.0767], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 55 - 297: dog - cat || Loss: 1.2363640069961548\n",
      "tensor([0., 1.]) tensor([0.9231, 0.0769], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 55 - 298: dog - cat || Loss: 1.2361990213394165\n",
      "tensor([0., 1.]) tensor([0.9229, 0.0771], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 55 - 299: dog - cat || Loss: 1.2360339164733887\n",
      "tensor([0., 1.]) tensor([0.9228, 0.0772], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 55 - 300: dog - cat || Loss: 1.2358683347702026\n",
      "tensor([0., 1.]) tensor([0.9226, 0.0774], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 55 - 301: dog - cat || Loss: 1.2357022762298584\n",
      "tensor([0., 1.]) tensor([0.9224, 0.0776], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 55 - 302: dog - cat || Loss: 1.235535979270935\n",
      "tensor([0., 1.]) tensor([0.9223, 0.0777], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 55 - 303: dog - cat || Loss: 1.2353692054748535\n",
      "tensor([0., 1.]) tensor([0.9221, 0.0779], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 55 - 304: dog - cat || Loss: 1.2352019548416138\n",
      "tensor([0., 1.]) tensor([0.9219, 0.0781], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 55 - 305: dog - cat || Loss: 1.2350342273712158\n",
      "tensor([0., 1.]) tensor([0.9218, 0.0782], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 55 - 306: dog - cat || Loss: 1.2348663806915283\n",
      "tensor([0., 1.]) tensor([0.9216, 0.0784], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 55 - 307: dog - cat || Loss: 1.2346978187561035\n",
      "tensor([0., 1.]) tensor([0.9214, 0.0786], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 55 - 308: dog - cat || Loss: 1.2345290184020996\n",
      "tensor([0., 1.]) tensor([0.9213, 0.0787], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 55 - 309: dog - cat || Loss: 1.2343597412109375\n",
      "tensor([0., 1.]) tensor([0.9211, 0.0789], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 55 - 310: dog - cat || Loss: 1.2341899871826172\n",
      "tensor([0., 1.]) tensor([0.9209, 0.0791], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 55 - 311: dog - cat || Loss: 1.2340198755264282\n",
      "tensor([0., 1.]) tensor([0.9208, 0.0792], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 55 - 312: dog - cat || Loss: 1.2338494062423706\n",
      "tensor([0., 1.]) tensor([0.9206, 0.0794], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 55 - 313: dog - cat || Loss: 1.2336783409118652\n",
      "tensor([0., 1.]) tensor([0.9204, 0.0796], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 55 - 314: dog - cat || Loss: 1.2335069179534912\n",
      "tensor([0., 1.]) tensor([0.9202, 0.0798], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 55 - 315: dog - cat || Loss: 1.233335256576538\n",
      "tensor([0., 1.]) tensor([0.9201, 0.0799], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 55 - 316: dog - cat || Loss: 1.2331629991531372\n",
      "tensor([0., 1.]) tensor([0.9199, 0.0801], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 55 - 317: dog - cat || Loss: 1.2329902648925781\n",
      "tensor([0., 1.]) tensor([0.9197, 0.0803], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 55 - 318: dog - cat || Loss: 1.23281729221344\n",
      "tensor([0., 1.]) tensor([0.9196, 0.0804], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 55 - 319: dog - cat || Loss: 1.2326438426971436\n",
      "tensor([0., 1.]) tensor([0.9194, 0.0806], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 55 - 320: dog - cat || Loss: 1.2324700355529785\n",
      "tensor([0., 1.]) tensor([0.9192, 0.0808], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 55 - 321: dog - cat || Loss: 1.2322956323623657\n",
      "tensor([0., 1.]) tensor([0.9190, 0.0810], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 55 - 322: dog - cat || Loss: 1.2321207523345947\n",
      "tensor([0., 1.]) tensor([0.9189, 0.0811], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 55 - 323: dog - cat || Loss: 1.2319456338882446\n",
      "tensor([0., 1.]) tensor([0.9187, 0.0813], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 55 - 324: dog - cat || Loss: 1.2317699193954468\n",
      "tensor([0., 1.]) tensor([0.9185, 0.0815], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 55 - 325: dog - cat || Loss: 1.2315939664840698\n",
      "tensor([0., 1.]) tensor([0.9183, 0.0817], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 55 - 326: dog - cat || Loss: 1.2314174175262451\n",
      "tensor([0., 1.]) tensor([0.9182, 0.0818], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 55 - 327: dog - cat || Loss: 1.2312405109405518\n",
      "tensor([0., 1.]) tensor([0.9180, 0.0820], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 55 - 328: dog - cat || Loss: 1.2310631275177002\n",
      "tensor([0., 1.]) tensor([0.9178, 0.0822], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 55 - 329: dog - cat || Loss: 1.2308852672576904\n",
      "tensor([0., 1.]) tensor([0.9176, 0.0824], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 55 - 330: dog - cat || Loss: 1.2307071685791016\n",
      "tensor([0., 1.]) tensor([0.9174, 0.0826], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 55 - 331: dog - cat || Loss: 1.2305283546447754\n",
      "tensor([0., 1.]) tensor([0.9173, 0.0827], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 55 - 332: dog - cat || Loss: 1.2303493022918701\n",
      "tensor([0., 1.]) tensor([0.9171, 0.0829], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 55 - 333: dog - cat || Loss: 1.230169653892517\n",
      "tensor([0., 1.]) tensor([0.9169, 0.0831], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 55 - 334: dog - cat || Loss: 1.2299896478652954\n",
      "tensor([0., 1.]) tensor([0.9167, 0.0833], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 55 - 335: dog - cat || Loss: 1.2298091650009155\n",
      "tensor([0., 1.]) tensor([0.9165, 0.0835], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 55 - 336: dog - cat || Loss: 1.2296284437179565\n",
      "tensor([0., 1.]) tensor([0.9164, 0.0836], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 55 - 337: dog - cat || Loss: 1.2294471263885498\n",
      "tensor([0., 1.]) tensor([0.9162, 0.0838], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 55 - 338: dog - cat || Loss: 1.2292650938034058\n",
      "tensor([0., 1.]) tensor([0.9160, 0.0840], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 55 - 339: dog - cat || Loss: 1.2290829420089722\n",
      "tensor([0., 1.]) tensor([0.9158, 0.0842], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 55 - 340: dog - cat || Loss: 1.2289001941680908\n",
      "tensor([0., 1.]) tensor([0.9156, 0.0844], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 55 - 341: dog - cat || Loss: 1.2287172079086304\n",
      "tensor([0., 1.]) tensor([0.9155, 0.0845], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 55 - 342: dog - cat || Loss: 1.228533387184143\n",
      "tensor([0., 1.]) tensor([0.9153, 0.0847], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 55 - 343: dog - cat || Loss: 1.2283494472503662\n",
      "tensor([0., 1.]) tensor([0.9151, 0.0849], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 55 - 344: dog - cat || Loss: 1.2281650304794312\n",
      "tensor([0., 1.]) tensor([0.9149, 0.0851], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 55 - 345: dog - cat || Loss: 1.2279798984527588\n",
      "tensor([0., 1.]) tensor([0.9147, 0.0853], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 55 - 346: dog - cat || Loss: 1.2277945280075073\n",
      "tensor([0., 1.]) tensor([0.9145, 0.0855], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 55 - 347: dog - cat || Loss: 1.227608561515808\n",
      "tensor([0., 1.]) tensor([0.9143, 0.0857], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 55 - 348: dog - cat || Loss: 1.2274222373962402\n",
      "tensor([0., 1.]) tensor([0.9142, 0.0858], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 55 - 349: dog - cat || Loss: 1.2272354364395142\n",
      "tensor([0., 1.]) tensor([0.9140, 0.0860], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 55 - 350: dog - cat || Loss: 1.2270481586456299\n",
      "tensor([0., 1.]) tensor([0.9138, 0.0862], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 55 - 351: dog - cat || Loss: 1.2268604040145874\n",
      "tensor([0., 1.]) tensor([0.9136, 0.0864], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 55 - 352: dog - cat || Loss: 1.2266722917556763\n",
      "tensor([0., 1.]) tensor([0.9134, 0.0866], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 55 - 353: dog - cat || Loss: 1.226483702659607\n",
      "tensor([0., 1.]) tensor([0.9132, 0.0868], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 55 - 354: dog - cat || Loss: 1.2262945175170898\n",
      "tensor([0., 1.]) tensor([0.9130, 0.0870], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 55 - 355: dog - cat || Loss: 1.226104974746704\n",
      "tensor([0., 1.]) tensor([0.9128, 0.0872], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 55 - 356: dog - cat || Loss: 1.2259148359298706\n",
      "tensor([0., 1.]) tensor([0.9127, 0.0873], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 55 - 357: dog - cat || Loss: 1.225724220275879\n",
      "tensor([0., 1.]) tensor([0.9125, 0.0875], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 55 - 358: dog - cat || Loss: 1.2255332469940186\n",
      "tensor([0., 1.]) tensor([0.9123, 0.0877], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 55 - 359: dog - cat || Loss: 1.2253416776657104\n",
      "tensor([0., 1.]) tensor([0.9121, 0.0879], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 55 - 360: dog - cat || Loss: 1.2251498699188232\n",
      "tensor([0., 1.]) tensor([0.9119, 0.0881], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 55 - 361: dog - cat || Loss: 1.2249574661254883\n",
      "tensor([0., 1.]) tensor([0.9117, 0.0883], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 55 - 362: dog - cat || Loss: 1.2247644662857056\n",
      "tensor([0., 1.]) tensor([0.9115, 0.0885], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 55 - 363: dog - cat || Loss: 1.2245711088180542\n",
      "tensor([0., 1.]) tensor([0.9113, 0.0887], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 55 - 364: dog - cat || Loss: 1.224377155303955\n",
      "tensor([0., 1.]) tensor([0.9111, 0.0889], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 55 - 365: dog - cat || Loss: 1.2241830825805664\n",
      "tensor([0., 1.]) tensor([0.9109, 0.0891], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 55 - 366: dog - cat || Loss: 1.2239880561828613\n",
      "tensor([0., 1.]) tensor([0.9107, 0.0893], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 55 - 367: dog - cat || Loss: 1.2237927913665771\n",
      "tensor([0., 1.]) tensor([0.9105, 0.0895], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 55 - 368: dog - cat || Loss: 1.2235970497131348\n",
      "tensor([0., 1.]) tensor([0.9103, 0.0897], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 55 - 369: dog - cat || Loss: 1.223400592803955\n",
      "tensor([0., 1.]) tensor([0.9101, 0.0899], grad_fn=<SoftmaxBackward0>)\n",
      "=====epoch:56=====\n",
      "Epoch 56 - 0: cat - cat || Loss: 0.40331941843032837\n",
      "tensor([1., 0.]) tensor([0.9099, 0.0901], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 56 - 1: cat - cat || Loss: 0.40347668528556824\n",
      "tensor([1., 0.]) tensor([0.9098, 0.0902], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 56 - 2: cat - cat || Loss: 0.4035985469818115\n",
      "tensor([1., 0.]) tensor([0.9097, 0.0903], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 56 - 3: cat - cat || Loss: 0.40368813276290894\n",
      "tensor([1., 0.]) tensor([0.9096, 0.0904], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 56 - 4: cat - cat || Loss: 0.40374886989593506\n",
      "tensor([1., 0.]) tensor([0.9095, 0.0905], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 56 - 5: cat - cat || Loss: 0.4037834405899048\n",
      "tensor([1., 0.]) tensor([0.9095, 0.0905], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 56 - 6: cat - cat || Loss: 0.40379446744918823\n",
      "tensor([1., 0.]) tensor([0.9095, 0.0905], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 56 - 7: cat - cat || Loss: 0.40378445386886597\n",
      "tensor([1., 0.]) tensor([0.9095, 0.0905], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 56 - 8: cat - cat || Loss: 0.4037553369998932\n",
      "tensor([1., 0.]) tensor([0.9095, 0.0905], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 56 - 9: cat - cat || Loss: 0.4037090539932251\n",
      "tensor([1., 0.]) tensor([0.9096, 0.0904], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 56 - 10: cat - cat || Loss: 0.40364742279052734\n",
      "tensor([1., 0.]) tensor([0.9096, 0.0904], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 56 - 11: cat - cat || Loss: 0.4035719633102417\n",
      "tensor([1., 0.]) tensor([0.9097, 0.0903], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 56 - 12: cat - cat || Loss: 0.40348416566848755\n",
      "tensor([1., 0.]) tensor([0.9098, 0.0902], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 56 - 13: cat - cat || Loss: 0.4033851623535156\n",
      "tensor([1., 0.]) tensor([0.9099, 0.0901], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 56 - 14: cat - cat || Loss: 0.4032762348651886\n",
      "tensor([1., 0.]) tensor([0.9100, 0.0900], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 56 - 15: cat - cat || Loss: 0.4031583070755005\n",
      "tensor([1., 0.]) tensor([0.9101, 0.0899], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 56 - 16: cat - cat || Loss: 0.4030323624610901\n",
      "tensor([1., 0.]) tensor([0.9102, 0.0898], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 56 - 17: cat - cat || Loss: 0.4028991758823395\n",
      "tensor([1., 0.]) tensor([0.9104, 0.0896], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 56 - 18: cat - cat || Loss: 0.4027597904205322\n",
      "tensor([1., 0.]) tensor([0.9105, 0.0895], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 56 - 19: cat - cat || Loss: 0.4026145339012146\n",
      "tensor([1., 0.]) tensor([0.9106, 0.0894], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 56 - 20: cat - cat || Loss: 0.4024641811847687\n",
      "tensor([1., 0.]) tensor([0.9108, 0.0892], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 56 - 21: cat - cat || Loss: 0.4023093283176422\n",
      "tensor([1., 0.]) tensor([0.9110, 0.0890], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 56 - 22: cat - cat || Loss: 0.40215054154396057\n",
      "tensor([1., 0.]) tensor([0.9111, 0.0889], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 56 - 23: cat - cat || Loss: 0.40198805928230286\n",
      "tensor([1., 0.]) tensor([0.9113, 0.0887], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 56 - 24: cat - cat || Loss: 0.40182238817214966\n",
      "tensor([1., 0.]) tensor([0.9114, 0.0886], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 56 - 25: cat - cat || Loss: 0.401653915643692\n",
      "tensor([1., 0.]) tensor([0.9116, 0.0884], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 56 - 26: cat - cat || Loss: 0.4014829099178314\n",
      "tensor([1., 0.]) tensor([0.9118, 0.0882], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 56 - 27: cat - cat || Loss: 0.4013098478317261\n",
      "tensor([1., 0.]) tensor([0.9120, 0.0880], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 56 - 28: cat - cat || Loss: 0.40113478899002075\n",
      "tensor([1., 0.]) tensor([0.9121, 0.0879], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 56 - 29: cat - cat || Loss: 0.40095797181129456\n",
      "tensor([1., 0.]) tensor([0.9123, 0.0877], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 56 - 30: cat - cat || Loss: 0.4007798433303833\n",
      "tensor([1., 0.]) tensor([0.9125, 0.0875], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 56 - 31: cat - cat || Loss: 0.40060025453567505\n",
      "tensor([1., 0.]) tensor([0.9127, 0.0873], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 56 - 32: cat - cat || Loss: 0.4004197120666504\n",
      "tensor([1., 0.]) tensor([0.9128, 0.0872], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 56 - 33: cat - cat || Loss: 0.4002382755279541\n",
      "tensor([1., 0.]) tensor([0.9130, 0.0870], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 56 - 34: cat - cat || Loss: 0.4000558853149414\n",
      "tensor([1., 0.]) tensor([0.9132, 0.0868], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 56 - 35: cat - cat || Loss: 0.39987292885780334\n",
      "tensor([1., 0.]) tensor([0.9134, 0.0866], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 56 - 36: cat - cat || Loss: 0.3996894061565399\n",
      "tensor([1., 0.]) tensor([0.9136, 0.0864], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 56 - 37: cat - cat || Loss: 0.39950546622276306\n",
      "tensor([1., 0.]) tensor([0.9138, 0.0862], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 56 - 38: cat - cat || Loss: 0.39932113885879517\n",
      "tensor([1., 0.]) tensor([0.9139, 0.0861], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 56 - 39: cat - cat || Loss: 0.399136483669281\n",
      "tensor([1., 0.]) tensor([0.9141, 0.0859], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 56 - 40: cat - cat || Loss: 0.3989517390727997\n",
      "tensor([1., 0.]) tensor([0.9143, 0.0857], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 56 - 41: cat - cat || Loss: 0.39876675605773926\n",
      "tensor([1., 0.]) tensor([0.9145, 0.0855], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 56 - 42: cat - cat || Loss: 0.39858177304267883\n",
      "tensor([1., 0.]) tensor([0.9147, 0.0853], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 56 - 43: cat - cat || Loss: 0.39839667081832886\n",
      "tensor([1., 0.]) tensor([0.9149, 0.0851], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 56 - 44: cat - cat || Loss: 0.398211807012558\n",
      "tensor([1., 0.]) tensor([0.9150, 0.0850], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 56 - 45: cat - cat || Loss: 0.39802688360214233\n",
      "tensor([1., 0.]) tensor([0.9152, 0.0848], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 56 - 46: cat - cat || Loss: 0.39784204959869385\n",
      "tensor([1., 0.]) tensor([0.9154, 0.0846], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 56 - 47: cat - cat || Loss: 0.3976573944091797\n",
      "tensor([1., 0.]) tensor([0.9156, 0.0844], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 56 - 48: cat - cat || Loss: 0.39747291803359985\n",
      "tensor([1., 0.]) tensor([0.9158, 0.0842], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 56 - 49: cat - cat || Loss: 0.3972887396812439\n",
      "tensor([1., 0.]) tensor([0.9160, 0.0840], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 56 - 50: cat - cat || Loss: 0.3971046507358551\n",
      "tensor([1., 0.]) tensor([0.9162, 0.0838], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 56 - 51: cat - cat || Loss: 0.39692097902297974\n",
      "tensor([1., 0.]) tensor([0.9163, 0.0837], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 56 - 52: cat - cat || Loss: 0.3967374861240387\n",
      "tensor([1., 0.]) tensor([0.9165, 0.0835], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 56 - 53: cat - cat || Loss: 0.39655429124832153\n",
      "tensor([1., 0.]) tensor([0.9167, 0.0833], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 56 - 54: cat - cat || Loss: 0.39637142419815063\n",
      "tensor([1., 0.]) tensor([0.9169, 0.0831], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 56 - 55: cat - cat || Loss: 0.396188884973526\n",
      "tensor([1., 0.]) tensor([0.9171, 0.0829], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 56 - 56: cat - cat || Loss: 0.39600670337677\n",
      "tensor([1., 0.]) tensor([0.9173, 0.0827], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 56 - 57: cat - cat || Loss: 0.3958248496055603\n",
      "tensor([1., 0.]) tensor([0.9174, 0.0826], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 56 - 58: cat - cat || Loss: 0.3956433832645416\n",
      "tensor([1., 0.]) tensor([0.9176, 0.0824], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 56 - 59: cat - cat || Loss: 0.395462304353714\n",
      "tensor([1., 0.]) tensor([0.9178, 0.0822], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 56 - 60: cat - cat || Loss: 0.3952815532684326\n",
      "tensor([1., 0.]) tensor([0.9180, 0.0820], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 56 - 61: cat - cat || Loss: 0.3951011598110199\n",
      "tensor([1., 0.]) tensor([0.9182, 0.0818], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 56 - 62: cat - cat || Loss: 0.394921213388443\n",
      "tensor([1., 0.]) tensor([0.9183, 0.0817], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 56 - 63: cat - cat || Loss: 0.3947416841983795\n",
      "tensor([1., 0.]) tensor([0.9185, 0.0815], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 56 - 64: cat - cat || Loss: 0.3945624530315399\n",
      "tensor([1., 0.]) tensor([0.9187, 0.0813], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 56 - 65: cat - cat || Loss: 0.3943837583065033\n",
      "tensor([1., 0.]) tensor([0.9189, 0.0811], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 56 - 66: cat - cat || Loss: 0.39420536160469055\n",
      "tensor([1., 0.]) tensor([0.9191, 0.0809], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 56 - 67: cat - cat || Loss: 0.3940275013446808\n",
      "tensor([1., 0.]) tensor([0.9192, 0.0808], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 56 - 68: cat - cat || Loss: 0.3938499391078949\n",
      "tensor([1., 0.]) tensor([0.9194, 0.0806], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 56 - 69: cat - cat || Loss: 0.3936728239059448\n",
      "tensor([1., 0.]) tensor([0.9196, 0.0804], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 56 - 70: cat - cat || Loss: 0.3934960961341858\n",
      "tensor([1., 0.]) tensor([0.9198, 0.0802], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 56 - 71: cat - cat || Loss: 0.39331990480422974\n",
      "tensor([1., 0.]) tensor([0.9199, 0.0801], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 56 - 72: cat - cat || Loss: 0.39314407110214233\n",
      "tensor([1., 0.]) tensor([0.9201, 0.0799], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 56 - 73: cat - cat || Loss: 0.3929685950279236\n",
      "tensor([1., 0.]) tensor([0.9203, 0.0797], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 56 - 74: cat - cat || Loss: 0.39279359579086304\n",
      "tensor([1., 0.]) tensor([0.9205, 0.0795], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 56 - 75: cat - cat || Loss: 0.3926190733909607\n",
      "tensor([1., 0.]) tensor([0.9206, 0.0794], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 56 - 76: cat - cat || Loss: 0.3924449682235718\n",
      "tensor([1., 0.]) tensor([0.9208, 0.0792], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 56 - 77: cat - cat || Loss: 0.39227133989334106\n",
      "tensor([1., 0.]) tensor([0.9210, 0.0790], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 56 - 78: cat - cat || Loss: 0.39209800958633423\n",
      "tensor([1., 0.]) tensor([0.9212, 0.0788], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 56 - 79: cat - cat || Loss: 0.3919251263141632\n",
      "tensor([1., 0.]) tensor([0.9213, 0.0787], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 56 - 80: cat - cat || Loss: 0.3917527496814728\n",
      "tensor([1., 0.]) tensor([0.9215, 0.0785], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 56 - 81: cat - cat || Loss: 0.3915806710720062\n",
      "tensor([1., 0.]) tensor([0.9217, 0.0783], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 56 - 82: cat - cat || Loss: 0.39140909910202026\n",
      "tensor([1., 0.]) tensor([0.9219, 0.0781], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 56 - 83: cat - cat || Loss: 0.3912380039691925\n",
      "tensor([1., 0.]) tensor([0.9220, 0.0780], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 56 - 84: cat - cat || Loss: 0.39106735587120056\n",
      "tensor([1., 0.]) tensor([0.9222, 0.0778], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 56 - 85: cat - cat || Loss: 0.39089709520339966\n",
      "tensor([1., 0.]) tensor([0.9224, 0.0776], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 56 - 86: cat - cat || Loss: 0.390727162361145\n",
      "tensor([1., 0.]) tensor([0.9225, 0.0775], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 56 - 87: cat - cat || Loss: 0.39055776596069336\n",
      "tensor([1., 0.]) tensor([0.9227, 0.0773], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 56 - 88: cat - cat || Loss: 0.39038869738578796\n",
      "tensor([1., 0.]) tensor([0.9229, 0.0771], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 56 - 89: cat - cat || Loss: 0.39022013545036316\n",
      "tensor([1., 0.]) tensor([0.9230, 0.0770], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 56 - 90: cat - cat || Loss: 0.390051931142807\n",
      "tensor([1., 0.]) tensor([0.9232, 0.0768], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 56 - 91: cat - cat || Loss: 0.38988417387008667\n",
      "tensor([1., 0.]) tensor([0.9234, 0.0766], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 56 - 92: cat - cat || Loss: 0.3897169232368469\n",
      "tensor([1., 0.]) tensor([0.9235, 0.0765], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 56 - 93: cat - cat || Loss: 0.38955003023147583\n",
      "tensor([1., 0.]) tensor([0.9237, 0.0763], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 56 - 94: cat - cat || Loss: 0.3893834352493286\n",
      "tensor([1., 0.]) tensor([0.9239, 0.0761], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 56 - 95: cat - cat || Loss: 0.3892173767089844\n",
      "tensor([1., 0.]) tensor([0.9240, 0.0760], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 56 - 96: cat - cat || Loss: 0.38905179500579834\n",
      "tensor([1., 0.]) tensor([0.9242, 0.0758], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 56 - 97: cat - cat || Loss: 0.3888865113258362\n",
      "tensor([1., 0.]) tensor([0.9244, 0.0756], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 56 - 98: cat - cat || Loss: 0.38872164487838745\n",
      "tensor([1., 0.]) tensor([0.9245, 0.0755], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 56 - 99: cat - cat || Loss: 0.3885572850704193\n",
      "tensor([1., 0.]) tensor([0.9247, 0.0753], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 56 - 100: cat - cat || Loss: 0.3883932828903198\n",
      "tensor([1., 0.]) tensor([0.9249, 0.0751], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 56 - 101: cat - cat || Loss: 0.38822969794273376\n",
      "tensor([1., 0.]) tensor([0.9250, 0.0750], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 56 - 102: cat - cat || Loss: 0.38806650042533875\n",
      "tensor([1., 0.]) tensor([0.9252, 0.0748], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 56 - 103: cat - cat || Loss: 0.38790372014045715\n",
      "tensor([1., 0.]) tensor([0.9254, 0.0746], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 56 - 104: cat - cat || Loss: 0.3877413868904114\n",
      "tensor([1., 0.]) tensor([0.9255, 0.0745], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 56 - 105: cat - cat || Loss: 0.38757947087287903\n",
      "tensor([1., 0.]) tensor([0.9257, 0.0743], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 56 - 106: cat - cat || Loss: 0.38741791248321533\n",
      "tensor([1., 0.]) tensor([0.9258, 0.0742], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 56 - 107: cat - cat || Loss: 0.38725677132606506\n",
      "tensor([1., 0.]) tensor([0.9260, 0.0740], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 56 - 108: cat - cat || Loss: 0.387096107006073\n",
      "tensor([1., 0.]) tensor([0.9262, 0.0738], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 56 - 109: cat - cat || Loss: 0.3869357109069824\n",
      "tensor([1., 0.]) tensor([0.9263, 0.0737], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 56 - 110: cat - cat || Loss: 0.38677582144737244\n",
      "tensor([1., 0.]) tensor([0.9265, 0.0735], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 56 - 111: cat - cat || Loss: 0.3866163492202759\n",
      "tensor([1., 0.]) tensor([0.9266, 0.0734], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 56 - 112: cat - cat || Loss: 0.3864571452140808\n",
      "tensor([1., 0.]) tensor([0.9268, 0.0732], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 56 - 113: cat - cat || Loss: 0.3862984776496887\n",
      "tensor([1., 0.]) tensor([0.9270, 0.0730], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 56 - 114: cat - cat || Loss: 0.3861401677131653\n",
      "tensor([1., 0.]) tensor([0.9271, 0.0729], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 56 - 115: cat - cat || Loss: 0.3859822750091553\n",
      "tensor([1., 0.]) tensor([0.9273, 0.0727], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 56 - 116: cat - cat || Loss: 0.3858247697353363\n",
      "tensor([1., 0.]) tensor([0.9274, 0.0726], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 56 - 117: cat - cat || Loss: 0.385667622089386\n",
      "tensor([1., 0.]) tensor([0.9276, 0.0724], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 56 - 118: cat - cat || Loss: 0.3855108916759491\n",
      "tensor([1., 0.]) tensor([0.9278, 0.0722], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 56 - 119: cat - cat || Loss: 0.3853546380996704\n",
      "tensor([1., 0.]) tensor([0.9279, 0.0721], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 56 - 120: cat - cat || Loss: 0.3851986527442932\n",
      "tensor([1., 0.]) tensor([0.9281, 0.0719], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 56 - 121: cat - cat || Loss: 0.38504305481910706\n",
      "tensor([1., 0.]) tensor([0.9282, 0.0718], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 56 - 122: cat - cat || Loss: 0.3848879933357239\n",
      "tensor([1., 0.]) tensor([0.9284, 0.0716], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 56 - 123: cat - cat || Loss: 0.38473325967788696\n",
      "tensor([1., 0.]) tensor([0.9285, 0.0715], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 56 - 124: cat - cat || Loss: 0.3845788538455963\n",
      "tensor([1., 0.]) tensor([0.9287, 0.0713], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 56 - 125: cat - cat || Loss: 0.38442498445510864\n",
      "tensor([1., 0.]) tensor([0.9288, 0.0712], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 56 - 126: cat - cat || Loss: 0.3842713534832001\n",
      "tensor([1., 0.]) tensor([0.9290, 0.0710], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 56 - 127: cat - cat || Loss: 0.38411810994148254\n",
      "tensor([1., 0.]) tensor([0.9291, 0.0709], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 56 - 128: cat - cat || Loss: 0.38396531343460083\n",
      "tensor([1., 0.]) tensor([0.9293, 0.0707], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 56 - 129: cat - cat || Loss: 0.3838128447532654\n",
      "tensor([1., 0.]) tensor([0.9294, 0.0706], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 56 - 130: cat - cat || Loss: 0.38366085290908813\n",
      "tensor([1., 0.]) tensor([0.9296, 0.0704], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 56 - 131: cat - cat || Loss: 0.3835091292858124\n",
      "tensor([1., 0.]) tensor([0.9298, 0.0702], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 56 - 132: cat - cat || Loss: 0.38335782289505005\n",
      "tensor([1., 0.]) tensor([0.9299, 0.0701], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 56 - 133: cat - cat || Loss: 0.38320690393447876\n",
      "tensor([1., 0.]) tensor([0.9301, 0.0699], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 56 - 134: cat - cat || Loss: 0.3830564022064209\n",
      "tensor([1., 0.]) tensor([0.9302, 0.0698], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 56 - 135: cat - cat || Loss: 0.3829062581062317\n",
      "tensor([1., 0.]) tensor([0.9304, 0.0696], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 56 - 136: cat - cat || Loss: 0.38275647163391113\n",
      "tensor([1., 0.]) tensor([0.9305, 0.0695], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 56 - 137: cat - cat || Loss: 0.38260698318481445\n",
      "tensor([1., 0.]) tensor([0.9307, 0.0693], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 56 - 138: cat - cat || Loss: 0.38245803117752075\n",
      "tensor([1., 0.]) tensor([0.9308, 0.0692], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 56 - 139: cat - cat || Loss: 0.3823093771934509\n",
      "tensor([1., 0.]) tensor([0.9310, 0.0690], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 56 - 140: cat - cat || Loss: 0.382161021232605\n",
      "tensor([1., 0.]) tensor([0.9311, 0.0689], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 56 - 141: cat - cat || Loss: 0.38201314210891724\n",
      "tensor([1., 0.]) tensor([0.9312, 0.0688], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 56 - 142: cat - cat || Loss: 0.38186562061309814\n",
      "tensor([1., 0.]) tensor([0.9314, 0.0686], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 56 - 143: cat - cat || Loss: 0.38171839714050293\n",
      "tensor([1., 0.]) tensor([0.9315, 0.0685], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 56 - 144: cat - cat || Loss: 0.3815716803073883\n",
      "tensor([1., 0.]) tensor([0.9317, 0.0683], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 56 - 145: cat - cat || Loss: 0.38142523169517517\n",
      "tensor([1., 0.]) tensor([0.9318, 0.0682], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 56 - 146: cat - cat || Loss: 0.3812791705131531\n",
      "tensor([1., 0.]) tensor([0.9320, 0.0680], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 56 - 147: cat - cat || Loss: 0.381133496761322\n",
      "tensor([1., 0.]) tensor([0.9321, 0.0679], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 56 - 148: cat - cat || Loss: 0.38098812103271484\n",
      "tensor([1., 0.]) tensor([0.9323, 0.0677], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 56 - 149: cat - cat || Loss: 0.38084322214126587\n",
      "tensor([1., 0.]) tensor([0.9324, 0.0676], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 56 - 150: cat - cat || Loss: 0.380698561668396\n",
      "tensor([1., 0.]) tensor([0.9326, 0.0674], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 56 - 151: cat - cat || Loss: 0.38055434823036194\n",
      "tensor([1., 0.]) tensor([0.9327, 0.0673], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 56 - 152: cat - cat || Loss: 0.38041049242019653\n",
      "tensor([1., 0.]) tensor([0.9329, 0.0671], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 56 - 153: cat - cat || Loss: 0.380266934633255\n",
      "tensor([1., 0.]) tensor([0.9330, 0.0670], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 56 - 154: cat - cat || Loss: 0.3801237940788269\n",
      "tensor([1., 0.]) tensor([0.9331, 0.0669], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 56 - 155: cat - cat || Loss: 0.3799809217453003\n",
      "tensor([1., 0.]) tensor([0.9333, 0.0667], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 56 - 156: cat - cat || Loss: 0.3798385262489319\n",
      "tensor([1., 0.]) tensor([0.9334, 0.0666], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 56 - 157: cat - cat || Loss: 0.37969642877578735\n",
      "tensor([1., 0.]) tensor([0.9336, 0.0664], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 56 - 158: cat - cat || Loss: 0.3795546591281891\n",
      "tensor([1., 0.]) tensor([0.9337, 0.0663], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 56 - 159: cat - cat || Loss: 0.3794132173061371\n",
      "tensor([1., 0.]) tensor([0.9338, 0.0662], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 56 - 160: cat - cat || Loss: 0.3792721629142761\n",
      "tensor([1., 0.]) tensor([0.9340, 0.0660], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 56 - 161: cat - cat || Loss: 0.3791314959526062\n",
      "tensor([1., 0.]) tensor([0.9341, 0.0659], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 56 - 162: cat - cat || Loss: 0.37899112701416016\n",
      "tensor([1., 0.]) tensor([0.9343, 0.0657], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 56 - 163: cat - cat || Loss: 0.3788510859012604\n",
      "tensor([1., 0.]) tensor([0.9344, 0.0656], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 56 - 164: cat - cat || Loss: 0.37871140241622925\n",
      "tensor([1., 0.]) tensor([0.9346, 0.0654], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 56 - 165: cat - cat || Loss: 0.37857213616371155\n",
      "tensor([1., 0.]) tensor([0.9347, 0.0653], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 56 - 166: cat - cat || Loss: 0.37843313813209534\n",
      "tensor([1., 0.]) tensor([0.9348, 0.0652], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 56 - 167: cat - cat || Loss: 0.37829452753067017\n",
      "tensor([1., 0.]) tensor([0.9350, 0.0650], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 56 - 168: cat - cat || Loss: 0.37815624475479126\n",
      "tensor([1., 0.]) tensor([0.9351, 0.0649], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 56 - 169: cat - cat || Loss: 0.3780182898044586\n",
      "tensor([1., 0.]) tensor([0.9352, 0.0648], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 56 - 170: cat - cat || Loss: 0.37788066267967224\n",
      "tensor([1., 0.]) tensor([0.9354, 0.0646], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 56 - 171: cat - cat || Loss: 0.3777434527873993\n",
      "tensor([1., 0.]) tensor([0.9355, 0.0645], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 56 - 172: cat - cat || Loss: 0.37760651111602783\n",
      "tensor([1., 0.]) tensor([0.9357, 0.0643], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 56 - 173: cat - cat || Loss: 0.377469927072525\n",
      "tensor([1., 0.]) tensor([0.9358, 0.0642], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 56 - 174: cat - cat || Loss: 0.3773336708545685\n",
      "tensor([1., 0.]) tensor([0.9359, 0.0641], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 56 - 175: cat - cat || Loss: 0.377197802066803\n",
      "tensor([1., 0.]) tensor([0.9361, 0.0639], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 56 - 176: cat - cat || Loss: 0.37706220149993896\n",
      "tensor([1., 0.]) tensor([0.9362, 0.0638], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 56 - 177: cat - cat || Loss: 0.376926988363266\n",
      "tensor([1., 0.]) tensor([0.9363, 0.0637], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 56 - 178: cat - cat || Loss: 0.3767921030521393\n",
      "tensor([1., 0.]) tensor([0.9365, 0.0635], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 56 - 179: cat - cat || Loss: 0.37665751576423645\n",
      "tensor([1., 0.]) tensor([0.9366, 0.0634], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 56 - 180: cat - cat || Loss: 0.3765232264995575\n",
      "tensor([1., 0.]) tensor([0.9367, 0.0633], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 56 - 181: cat - cat || Loss: 0.3763893246650696\n",
      "tensor([1., 0.]) tensor([0.9369, 0.0631], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 56 - 182: cat - cat || Loss: 0.37625572085380554\n",
      "tensor([1., 0.]) tensor([0.9370, 0.0630], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 56 - 183: cat - cat || Loss: 0.3761225640773773\n",
      "tensor([1., 0.]) tensor([0.9371, 0.0629], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 56 - 184: cat - cat || Loss: 0.37598949670791626\n",
      "tensor([1., 0.]) tensor([0.9373, 0.0627], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 56 - 185: cat - cat || Loss: 0.3758569359779358\n",
      "tensor([1., 0.]) tensor([0.9374, 0.0626], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 56 - 186: cat - cat || Loss: 0.37572455406188965\n",
      "tensor([1., 0.]) tensor([0.9375, 0.0625], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 56 - 187: cat - cat || Loss: 0.37559252977371216\n",
      "tensor([1., 0.]) tensor([0.9377, 0.0623], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 56 - 188: cat - cat || Loss: 0.37546074390411377\n",
      "tensor([1., 0.]) tensor([0.9378, 0.0622], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 56 - 189: cat - cat || Loss: 0.3753293454647064\n",
      "tensor([1., 0.]) tensor([0.9379, 0.0621], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 56 - 190: dog - cat || Loss: 1.2513251304626465\n",
      "tensor([0., 1.]) tensor([0.9381, 0.0619], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 56 - 191: dog - cat || Loss: 1.2514301538467407\n",
      "tensor([0., 1.]) tensor([0.9382, 0.0618], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 56 - 192: dog - cat || Loss: 1.251511573791504\n",
      "tensor([0., 1.]) tensor([0.9382, 0.0618], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 56 - 193: dog - cat || Loss: 1.2515718936920166\n",
      "tensor([0., 1.]) tensor([0.9383, 0.0617], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 56 - 194: dog - cat || Loss: 1.2516131401062012\n",
      "tensor([0., 1.]) tensor([0.9384, 0.0616], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 56 - 195: dog - cat || Loss: 1.2516374588012695\n",
      "tensor([0., 1.]) tensor([0.9384, 0.0616], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 56 - 196: dog - cat || Loss: 1.2516463994979858\n",
      "tensor([0., 1.]) tensor([0.9384, 0.0616], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 56 - 197: dog - cat || Loss: 1.2516413927078247\n",
      "tensor([0., 1.]) tensor([0.9384, 0.0616], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 56 - 198: dog - cat || Loss: 1.2516241073608398\n",
      "tensor([0., 1.]) tensor([0.9384, 0.0616], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 56 - 199: dog - cat || Loss: 1.2515957355499268\n",
      "tensor([0., 1.]) tensor([0.9383, 0.0617], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 56 - 200: dog - cat || Loss: 1.2515573501586914\n",
      "tensor([0., 1.]) tensor([0.9383, 0.0617], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 56 - 201: dog - cat || Loss: 1.251509666442871\n",
      "tensor([0., 1.]) tensor([0.9382, 0.0618], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 56 - 202: dog - cat || Loss: 1.2514539957046509\n",
      "tensor([0., 1.]) tensor([0.9382, 0.0618], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 56 - 203: dog - cat || Loss: 1.2513909339904785\n",
      "tensor([0., 1.]) tensor([0.9381, 0.0619], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 56 - 204: dog - cat || Loss: 1.2513211965560913\n",
      "tensor([0., 1.]) tensor([0.9381, 0.0619], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 56 - 205: dog - cat || Loss: 1.251245379447937\n",
      "tensor([0., 1.]) tensor([0.9380, 0.0620], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 56 - 206: dog - cat || Loss: 1.251164197921753\n",
      "tensor([0., 1.]) tensor([0.9379, 0.0621], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 56 - 207: dog - cat || Loss: 1.2510781288146973\n",
      "tensor([0., 1.]) tensor([0.9378, 0.0622], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 56 - 208: dog - cat || Loss: 1.2509875297546387\n",
      "tensor([0., 1.]) tensor([0.9377, 0.0623], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 56 - 209: dog - cat || Loss: 1.250892996788025\n",
      "tensor([0., 1.]) tensor([0.9376, 0.0624], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 56 - 210: dog - cat || Loss: 1.250794768333435\n",
      "tensor([0., 1.]) tensor([0.9375, 0.0625], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 56 - 211: dog - cat || Loss: 1.2506930828094482\n",
      "tensor([0., 1.]) tensor([0.9374, 0.0626], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 56 - 212: dog - cat || Loss: 1.2505886554718018\n",
      "tensor([0., 1.]) tensor([0.9373, 0.0627], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 56 - 213: dog - cat || Loss: 1.250481367111206\n",
      "tensor([0., 1.]) tensor([0.9372, 0.0628], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 56 - 214: dog - cat || Loss: 1.2503714561462402\n",
      "tensor([0., 1.]) tensor([0.9371, 0.0629], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 56 - 215: dog - cat || Loss: 1.250259518623352\n",
      "tensor([0., 1.]) tensor([0.9370, 0.0630], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 56 - 216: dog - cat || Loss: 1.2501451969146729\n",
      "tensor([0., 1.]) tensor([0.9369, 0.0631], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 56 - 217: dog - cat || Loss: 1.2500290870666504\n",
      "tensor([0., 1.]) tensor([0.9368, 0.0632], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 56 - 218: dog - cat || Loss: 1.2499114274978638\n",
      "tensor([0., 1.]) tensor([0.9366, 0.0634], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 56 - 219: dog - cat || Loss: 1.2497919797897339\n",
      "tensor([0., 1.]) tensor([0.9365, 0.0635], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 56 - 220: dog - cat || Loss: 1.2496709823608398\n",
      "tensor([0., 1.]) tensor([0.9364, 0.0636], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 56 - 221: dog - cat || Loss: 1.2495487928390503\n",
      "tensor([0., 1.]) tensor([0.9363, 0.0637], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 56 - 222: dog - cat || Loss: 1.2494251728057861\n",
      "tensor([0., 1.]) tensor([0.9362, 0.0638], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 56 - 223: dog - cat || Loss: 1.2493005990982056\n",
      "tensor([0., 1.]) tensor([0.9360, 0.0640], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 56 - 224: dog - cat || Loss: 1.24917471408844\n",
      "tensor([0., 1.]) tensor([0.9359, 0.0641], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 56 - 225: dog - cat || Loss: 1.2490479946136475\n",
      "tensor([0., 1.]) tensor([0.9358, 0.0642], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 56 - 226: dog - cat || Loss: 1.248920202255249\n",
      "tensor([0., 1.]) tensor([0.9357, 0.0643], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 56 - 227: dog - cat || Loss: 1.2487916946411133\n",
      "tensor([0., 1.]) tensor([0.9355, 0.0645], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 56 - 228: dog - cat || Loss: 1.2486623525619507\n",
      "tensor([0., 1.]) tensor([0.9354, 0.0646], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 56 - 229: dog - cat || Loss: 1.2485321760177612\n",
      "tensor([0., 1.]) tensor([0.9353, 0.0647], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 56 - 230: dog - cat || Loss: 1.248401165008545\n",
      "tensor([0., 1.]) tensor([0.9351, 0.0649], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 56 - 231: dog - cat || Loss: 1.2482695579528809\n",
      "tensor([0., 1.]) tensor([0.9350, 0.0650], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 56 - 232: dog - cat || Loss: 1.2481374740600586\n",
      "tensor([0., 1.]) tensor([0.9349, 0.0651], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 56 - 233: dog - cat || Loss: 1.2480045557022095\n",
      "tensor([0., 1.]) tensor([0.9347, 0.0653], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 56 - 234: dog - cat || Loss: 1.247870922088623\n",
      "tensor([0., 1.]) tensor([0.9346, 0.0654], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 56 - 235: dog - cat || Loss: 1.247736930847168\n",
      "tensor([0., 1.]) tensor([0.9345, 0.0655], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 56 - 236: dog - cat || Loss: 1.2476024627685547\n",
      "tensor([0., 1.]) tensor([0.9343, 0.0657], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 56 - 237: dog - cat || Loss: 1.2474673986434937\n",
      "tensor([0., 1.]) tensor([0.9342, 0.0658], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 56 - 238: dog - cat || Loss: 1.2473318576812744\n",
      "tensor([0., 1.]) tensor([0.9341, 0.0659], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 56 - 239: dog - cat || Loss: 1.2471957206726074\n",
      "tensor([0., 1.]) tensor([0.9339, 0.0661], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 56 - 240: dog - cat || Loss: 1.2470592260360718\n",
      "tensor([0., 1.]) tensor([0.9338, 0.0662], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 56 - 241: dog - cat || Loss: 1.2469221353530884\n",
      "tensor([0., 1.]) tensor([0.9337, 0.0663], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 56 - 242: dog - cat || Loss: 1.2467848062515259\n",
      "tensor([0., 1.]) tensor([0.9335, 0.0665], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 56 - 243: dog - cat || Loss: 1.246646761894226\n",
      "tensor([0., 1.]) tensor([0.9334, 0.0666], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 56 - 244: dog - cat || Loss: 1.2465085983276367\n",
      "tensor([0., 1.]) tensor([0.9332, 0.0668], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 56 - 245: dog - cat || Loss: 1.2463698387145996\n",
      "tensor([0., 1.]) tensor([0.9331, 0.0669], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 56 - 246: dog - cat || Loss: 1.2462307214736938\n",
      "tensor([0., 1.]) tensor([0.9330, 0.0670], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 56 - 247: dog - cat || Loss: 1.2460911273956299\n",
      "tensor([0., 1.]) tensor([0.9328, 0.0672], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 56 - 248: dog - cat || Loss: 1.2459512948989868\n",
      "tensor([0., 1.]) tensor([0.9327, 0.0673], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 56 - 249: dog - cat || Loss: 1.2458109855651855\n",
      "tensor([0., 1.]) tensor([0.9325, 0.0675], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 56 - 250: dog - cat || Loss: 1.2456703186035156\n",
      "tensor([0., 1.]) tensor([0.9324, 0.0676], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 56 - 251: dog - cat || Loss: 1.245529055595398\n",
      "tensor([0., 1.]) tensor([0.9323, 0.0677], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 56 - 252: dog - cat || Loss: 1.2453875541687012\n",
      "tensor([0., 1.]) tensor([0.9321, 0.0679], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 56 - 253: dog - cat || Loss: 1.2452456951141357\n",
      "tensor([0., 1.]) tensor([0.9320, 0.0680], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 56 - 254: dog - cat || Loss: 1.2451034784317017\n",
      "tensor([0., 1.]) tensor([0.9318, 0.0682], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 56 - 255: dog - cat || Loss: 1.244960904121399\n",
      "tensor([0., 1.]) tensor([0.9317, 0.0683], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 56 - 256: dog - cat || Loss: 1.244817852973938\n",
      "tensor([0., 1.]) tensor([0.9316, 0.0684], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 56 - 257: dog - cat || Loss: 1.2446744441986084\n",
      "tensor([0., 1.]) tensor([0.9314, 0.0686], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 56 - 258: dog - cat || Loss: 1.2445307970046997\n",
      "tensor([0., 1.]) tensor([0.9313, 0.0687], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 56 - 259: dog - cat || Loss: 1.2443866729736328\n",
      "tensor([0., 1.]) tensor([0.9311, 0.0689], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 56 - 260: dog - cat || Loss: 1.2442420721054077\n",
      "tensor([0., 1.]) tensor([0.9310, 0.0690], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 56 - 261: dog - cat || Loss: 1.244097352027893\n",
      "tensor([0., 1.]) tensor([0.9308, 0.0692], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 56 - 262: dog - cat || Loss: 1.2439521551132202\n",
      "tensor([0., 1.]) tensor([0.9307, 0.0693], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 56 - 263: dog - cat || Loss: 1.2438066005706787\n",
      "tensor([0., 1.]) tensor([0.9305, 0.0695], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 56 - 264: dog - cat || Loss: 1.2436606884002686\n",
      "tensor([0., 1.]) tensor([0.9304, 0.0696], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 56 - 265: dog - cat || Loss: 1.2435144186019897\n",
      "tensor([0., 1.]) tensor([0.9303, 0.0697], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 56 - 266: dog - cat || Loss: 1.2433676719665527\n",
      "tensor([0., 1.]) tensor([0.9301, 0.0699], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 56 - 267: dog - cat || Loss: 1.2432206869125366\n",
      "tensor([0., 1.]) tensor([0.9300, 0.0700], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 56 - 268: dog - cat || Loss: 1.2430732250213623\n",
      "tensor([0., 1.]) tensor([0.9298, 0.0702], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 56 - 269: dog - cat || Loss: 1.2429255247116089\n",
      "tensor([0., 1.]) tensor([0.9297, 0.0703], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 56 - 270: dog - cat || Loss: 1.2427774667739868\n",
      "tensor([0., 1.]) tensor([0.9295, 0.0705], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 56 - 271: dog - cat || Loss: 1.2426289319992065\n",
      "tensor([0., 1.]) tensor([0.9294, 0.0706], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 56 - 272: dog - cat || Loss: 1.2424801588058472\n",
      "tensor([0., 1.]) tensor([0.9292, 0.0708], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 56 - 273: dog - cat || Loss: 1.2423309087753296\n",
      "tensor([0., 1.]) tensor([0.9291, 0.0709], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 56 - 274: dog - cat || Loss: 1.2421813011169434\n",
      "tensor([0., 1.]) tensor([0.9289, 0.0711], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 56 - 275: dog - cat || Loss: 1.242031216621399\n",
      "tensor([0., 1.]) tensor([0.9288, 0.0712], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 56 - 276: dog - cat || Loss: 1.241881012916565\n",
      "tensor([0., 1.]) tensor([0.9286, 0.0714], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 56 - 277: dog - cat || Loss: 1.2417302131652832\n",
      "tensor([0., 1.]) tensor([0.9285, 0.0715], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 56 - 278: dog - cat || Loss: 1.2415791749954224\n",
      "tensor([0., 1.]) tensor([0.9283, 0.0717], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 56 - 279: dog - cat || Loss: 1.2414277791976929\n",
      "tensor([0., 1.]) tensor([0.9282, 0.0718], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 56 - 280: dog - cat || Loss: 1.2412759065628052\n",
      "tensor([0., 1.]) tensor([0.9280, 0.0720], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 56 - 281: dog - cat || Loss: 1.2411236763000488\n",
      "tensor([0., 1.]) tensor([0.9279, 0.0721], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 56 - 282: dog - cat || Loss: 1.2409712076187134\n",
      "tensor([0., 1.]) tensor([0.9277, 0.0723], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 56 - 283: dog - cat || Loss: 1.2408182621002197\n",
      "tensor([0., 1.]) tensor([0.9276, 0.0724], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 56 - 284: dog - cat || Loss: 1.2406648397445679\n",
      "tensor([0., 1.]) tensor([0.9274, 0.0726], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 56 - 285: dog - cat || Loss: 1.240511178970337\n",
      "tensor([0., 1.]) tensor([0.9272, 0.0728], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 56 - 286: dog - cat || Loss: 1.2403572797775269\n",
      "tensor([0., 1.]) tensor([0.9271, 0.0729], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 56 - 287: dog - cat || Loss: 1.2402026653289795\n",
      "tensor([0., 1.]) tensor([0.9269, 0.0731], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 56 - 288: dog - cat || Loss: 1.240047812461853\n",
      "tensor([0., 1.]) tensor([0.9268, 0.0732], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 56 - 289: dog - cat || Loss: 1.239892601966858\n",
      "tensor([0., 1.]) tensor([0.9266, 0.0734], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 56 - 290: dog - cat || Loss: 1.2397371530532837\n",
      "tensor([0., 1.]) tensor([0.9265, 0.0735], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 56 - 291: dog - cat || Loss: 1.2395811080932617\n",
      "tensor([0., 1.]) tensor([0.9263, 0.0737], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 56 - 292: dog - cat || Loss: 1.239424705505371\n",
      "tensor([0., 1.]) tensor([0.9262, 0.0738], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 56 - 293: dog - cat || Loss: 1.2392679452896118\n",
      "tensor([0., 1.]) tensor([0.9260, 0.0740], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 56 - 294: dog - cat || Loss: 1.2391108274459839\n",
      "tensor([0., 1.]) tensor([0.9258, 0.0742], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 56 - 295: dog - cat || Loss: 1.2389532327651978\n",
      "tensor([0., 1.]) tensor([0.9257, 0.0743], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 56 - 296: dog - cat || Loss: 1.2387953996658325\n",
      "tensor([0., 1.]) tensor([0.9255, 0.0745], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 56 - 297: dog - cat || Loss: 1.238637089729309\n",
      "tensor([0., 1.]) tensor([0.9254, 0.0746], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 56 - 298: dog - cat || Loss: 1.238478422164917\n",
      "tensor([0., 1.]) tensor([0.9252, 0.0748], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 56 - 299: dog - cat || Loss: 1.2383193969726562\n",
      "tensor([0., 1.]) tensor([0.9251, 0.0749], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 56 - 300: dog - cat || Loss: 1.2381598949432373\n",
      "tensor([0., 1.]) tensor([0.9249, 0.0751], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 56 - 301: dog - cat || Loss: 1.2380000352859497\n",
      "tensor([0., 1.]) tensor([0.9247, 0.0753], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 56 - 302: dog - cat || Loss: 1.2378398180007935\n",
      "tensor([0., 1.]) tensor([0.9246, 0.0754], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 56 - 303: dog - cat || Loss: 1.237679123878479\n",
      "tensor([0., 1.]) tensor([0.9244, 0.0756], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 56 - 304: dog - cat || Loss: 1.237518072128296\n",
      "tensor([0., 1.]) tensor([0.9243, 0.0757], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 56 - 305: dog - cat || Loss: 1.2373565435409546\n",
      "tensor([0., 1.]) tensor([0.9241, 0.0759], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 56 - 306: dog - cat || Loss: 1.2371947765350342\n",
      "tensor([0., 1.]) tensor([0.9239, 0.0761], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 56 - 307: dog - cat || Loss: 1.237032413482666\n",
      "tensor([0., 1.]) tensor([0.9238, 0.0762], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 56 - 308: dog - cat || Loss: 1.2368699312210083\n",
      "tensor([0., 1.]) tensor([0.9236, 0.0764], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 56 - 309: dog - cat || Loss: 1.2367068529129028\n",
      "tensor([0., 1.]) tensor([0.9234, 0.0766], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 56 - 310: dog - cat || Loss: 1.2365434169769287\n",
      "tensor([0., 1.]) tensor([0.9233, 0.0767], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 56 - 311: dog - cat || Loss: 1.236379623413086\n",
      "tensor([0., 1.]) tensor([0.9231, 0.0769], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 56 - 312: dog - cat || Loss: 1.2362154722213745\n",
      "tensor([0., 1.]) tensor([0.9230, 0.0770], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 56 - 313: dog - cat || Loss: 1.2360506057739258\n",
      "tensor([0., 1.]) tensor([0.9228, 0.0772], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 56 - 314: dog - cat || Loss: 1.2358856201171875\n",
      "tensor([0., 1.]) tensor([0.9226, 0.0774], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 56 - 315: dog - cat || Loss: 1.235720157623291\n",
      "tensor([0., 1.]) tensor([0.9225, 0.0775], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 56 - 316: dog - cat || Loss: 1.2355544567108154\n",
      "tensor([0., 1.]) tensor([0.9223, 0.0777], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 56 - 317: dog - cat || Loss: 1.2353880405426025\n",
      "tensor([0., 1.]) tensor([0.9221, 0.0779], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 56 - 318: dog - cat || Loss: 1.2352213859558105\n",
      "tensor([0., 1.]) tensor([0.9220, 0.0780], grad_fn=<SoftmaxBackward0>)\n",
      "Epoch 56 - 319: dog - cat || Loss: 1.2350542545318604\n",
      "tensor([0., 1.]) tensor([0.9218, 0.0782], grad_fn=<SoftmaxBackward0>)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[25], line 27\u001b[0m\n\u001b[1;32m     23\u001b[0m   number_of_correct \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m     25\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[0;32m---> 27\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[1;32m     29\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[1;32m     30\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEpoch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m - \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mid\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mget_label(y)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m - \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mget_label(y_hat)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m || Loss: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mloss\u001b[38;5;241m.\u001b[39mitem()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/torch/_tensor.py:521\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    511\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    512\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    513\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    514\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    519\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[1;32m    520\u001b[0m     )\n\u001b[0;32m--> 521\u001b[0m torch\u001b[38;5;241m.\u001b[39mautograd\u001b[38;5;241m.\u001b[39mbackward(\n\u001b[1;32m    522\u001b[0m     \u001b[38;5;28mself\u001b[39m, gradient, retain_graph, create_graph, inputs\u001b[38;5;241m=\u001b[39minputs\n\u001b[1;32m    523\u001b[0m )\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/torch/autograd/__init__.py:289\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    284\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    286\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[1;32m    287\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    288\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 289\u001b[0m _engine_run_backward(\n\u001b[1;32m    290\u001b[0m     tensors,\n\u001b[1;32m    291\u001b[0m     grad_tensors_,\n\u001b[1;32m    292\u001b[0m     retain_graph,\n\u001b[1;32m    293\u001b[0m     create_graph,\n\u001b[1;32m    294\u001b[0m     inputs,\n\u001b[1;32m    295\u001b[0m     allow_unreachable\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m    296\u001b[0m     accumulate_grad\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m    297\u001b[0m )\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/torch/autograd/graph.py:769\u001b[0m, in \u001b[0;36m_engine_run_backward\u001b[0;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    767\u001b[0m     unregister_hooks \u001b[38;5;241m=\u001b[39m _register_logging_hooks_on_whole_graph(t_outputs)\n\u001b[1;32m    768\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 769\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m Variable\u001b[38;5;241m.\u001b[39m_execution_engine\u001b[38;5;241m.\u001b[39mrun_backward(  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[1;32m    770\u001b[0m         t_outputs, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs\n\u001b[1;32m    771\u001b[0m     )  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[1;32m    772\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    773\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m attach_logging_hooks:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model = ClassifierVGG16()\n",
    "# model = VGG16()\n",
    "print(get_label(model(x)))\n",
    "\n",
    "import torch.optim as optim\n",
    "\n",
    "optimizer = optim.SGD(model.parameters(), lr = 0.001, momentum = 0.9)\n",
    "\n",
    "loss_calculator = nn.CrossEntropyLoss()\n",
    "\n",
    "for epoch in range(100):\n",
    "  number_of_example = len(dataset)\n",
    "  number_of_correct = 0\n",
    "  print(f\"=====epoch:{epoch}=====\")\n",
    "  for id in range(number_of_example):\n",
    "    x, y = dataset[id]\n",
    "    y_hat = model(x)\n",
    "\n",
    "    # loss = ((y - y_hat) ** 2).mean()\n",
    "    loss = loss_calculator(y, y_hat)\n",
    "\n",
    "    if get_label(y_hat) == get_label(y):\n",
    "      number_of_correct += 1\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    loss.backward()\n",
    "\n",
    "    optimizer.step()\n",
    "    print(f\"Epoch {epoch} - {id}: {get_label(y)} - {get_label(y_hat)} || Loss: {loss.item()}\")\n",
    "    print(y, y_hat)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyMeh8+7BqFjyDtE333ycs6T",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
